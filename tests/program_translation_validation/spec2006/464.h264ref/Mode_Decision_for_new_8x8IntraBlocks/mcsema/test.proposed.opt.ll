; ModuleID = 'mcsema/test.proposed.inline.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%__bss_start_type = type <{ [8 x i8] }>
%G_0x6cb8f8_type = type <{ [8 x i8] }>
%G_0x6cb900_type = type <{ [8 x i8] }>
%G_0x6cc5f8_type = type <{ [8 x i8] }>
%G_0x6f6f90_type = type <{ [8 x i8] }>
%G_0x70fcf0_type = type <{ [8 x i8] }>
%G_0x726418_type = type <{ [8 x i8] }>
%G_0xd203__rip__type = type <{ [8 x i8] }>
%G_0xd848__rip__type = type <{ [8 x i8] }>
%G__0x6ccb00_type = type <{ [8 x i8] }>
%G__0x6cd4f0_type = type <{ [8 x i8] }>
%G__0x6d0920_type = type <{ [8 x i8] }>
%G__0x6d2ec0_type = type <{ [8 x i8] }>
%G__0x6d40f0_type = type <{ [8 x i8] }>
%G__0x6d4600_type = type <{ [8 x i8] }>
%G__0x6f6fa0_type = type <{ [8 x i8] }>
%G__0x6f8f20_type = type <{ [8 x i8] }>
%G__0x7107b0_type = type <{ [8 x i8] }>
%G__0x722ff0_type = type <{ [8 x i8] }>
%G__0x723720_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.anon = type { i64 }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque

@__bss_start = local_unnamed_addr global %__bss_start_type zeroinitializer
@G_0x6cb8f8 = local_unnamed_addr global %G_0x6cb8f8_type zeroinitializer
@G_0x6cb900 = local_unnamed_addr global %G_0x6cb900_type zeroinitializer
@G_0x6cc5f8 = local_unnamed_addr global %G_0x6cc5f8_type zeroinitializer
@G_0x6f6f90 = local_unnamed_addr global %G_0x6f6f90_type zeroinitializer
@G_0x70fcf0 = local_unnamed_addr global %G_0x70fcf0_type zeroinitializer
@G_0x726418 = local_unnamed_addr global %G_0x726418_type zeroinitializer
@G_0xd203__rip_ = global %G_0xd203__rip__type zeroinitializer
@G_0xd848__rip_ = global %G_0xd848__rip__type zeroinitializer
@G__0x6ccb00 = global %G__0x6ccb00_type zeroinitializer
@G__0x6cd4f0 = global %G__0x6cd4f0_type zeroinitializer
@G__0x6d0920 = global %G__0x6d0920_type zeroinitializer
@G__0x6d2ec0 = global %G__0x6d2ec0_type zeroinitializer
@G__0x6d40f0 = global %G__0x6d40f0_type zeroinitializer
@G__0x6d4600 = global %G__0x6d4600_type zeroinitializer
@G__0x6f6fa0 = global %G__0x6f6fa0_type zeroinitializer
@G__0x6f8f20 = global %G__0x6f8f20_type zeroinitializer
@G__0x7107b0 = global %G__0x7107b0_type zeroinitializer
@G__0x722ff0 = global %G__0x722ff0_type zeroinitializer
@G__0x723720 = global %G__0x723720_type zeroinitializer

declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

; Function Attrs: nounwind readnone
declare double @llvm.fabs.f64(double) #0

; Function Attrs: nounwind readnone
declare double @llvm.trunc.f64(double) #0

declare extern_weak x86_64_sysvcc i64 @floor(i64)

declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr

declare %struct.Memory* @sub_44b230.getLuma4x4Neighbour(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4a7680.intrapred_luma8x8(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_45f5b0.SATD8X8(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_49d6a0.store_coding_state_cs_cm(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4aa2f0.RDCost_for_8x8IntraBlocks(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_49d6c0.reset_coding_state_cs_cm(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_483520.RDCost_for_4x4Blocks_Chroma(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4aa740.dct_luma8x8(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_40acc0.dct_chroma4x4(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: alwaysinline
define %struct.Memory* @Mode_Decision_for_new_8x8IntraBlocks(%struct.State* noalias, i64, %struct.Memory* noalias) local_unnamed_addr #1 {
entry:
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP.i = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP.i, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %3, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  %10 = load i64, i64* %3, align 8
  store i64 %8, i64* %RBP.i, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0
  %RBX.i161 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %12 = load i64, i64* %RBX.i161, align 8
  %13 = add i64 %10, 4
  store i64 %13, i64* %3, align 8
  %14 = add i64 %7, -16
  %15 = inttoptr i64 %14 to i64*
  store i64 %12, i64* %15, align 8
  %16 = load i64, i64* %3, align 8
  %17 = add i64 %7, -1496
  store i64 %17, i64* %6, align 8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %RCX.i1692 = getelementptr inbounds %union.anon, %union.anon* %24, i64 0, i32 0
  store i64 4294967295, i64* %RCX.i1692, align 8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D.i1718 = bitcast %union.anon* %25 to i32*
  %26 = getelementptr inbounds %union.anon, %union.anon* %25, i64 0, i32 0
  store i64 0, i64* %26, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9.i = getelementptr inbounds %union.anon, %union.anon* %27, i64 0, i32 0
  %28 = load i64, i64* %RBP.i, align 8
  %29 = add i64 %28, -576
  store i64 %29, i64* %R9.i, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %RAX.i1763 = getelementptr inbounds %union.anon, %union.anon* %30, i64 0, i32 0
  store i64 4, i64* %RAX.i1763, align 8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %32 = add i64 %16, add (i64 ptrtoint (%G_0xd848__rip__type* @G_0xd848__rip_ to i64), i64 27)
  %33 = add i64 %16, 35
  store i64 %33, i64* %3, align 8
  %34 = inttoptr i64 %32 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = bitcast %union.VectorReg* %31 to double*
  %37 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %31, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %35, i64* %37, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %39 = bitcast i64* %38 to double*
  store double 0.000000e+00, double* %39, align 1
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %RDX.i1805 = getelementptr inbounds %union.anon, %union.anon* %40, i64 0, i32 0
  store i64 2, i64* %RDX.i1805, align 8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %42 = bitcast %union.VectorReg* %41 to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %42, align 1
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI.i1845 = bitcast %union.anon* %43 to i32*
  %44 = add i64 %28, -12
  %45 = load i32, i32* %EDI.i1845, align 4
  %46 = add i64 %16, 46
  store i64 %46, i64* %3, align 8
  %47 = inttoptr i64 %44 to i32*
  store i32 %45, i32* %47, align 4
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %49 = load i64, i64* %RBP.i, align 8
  %50 = add i64 %49, -24
  %51 = load i64, i64* %3, align 8
  %52 = add i64 %51, 5
  store i64 %52, i64* %3, align 8
  %53 = bitcast %union.VectorReg* %48 to double*
  %54 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %48, i64 0, i32 0, i32 0, i32 0, i64 0
  %55 = load i64, i64* %54, align 1
  %56 = inttoptr i64 %50 to i64*
  store i64 %55, i64* %56, align 8
  %57 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %RSI.i1889 = getelementptr inbounds %union.anon, %union.anon* %57, i64 0, i32 0
  %58 = load i64, i64* %RBP.i, align 8
  %59 = add i64 %58, -32
  %60 = load i64, i64* %RSI.i1889, align 8
  %61 = load i64, i64* %3, align 8
  %62 = add i64 %61, 4
  store i64 %62, i64* %3, align 8
  %63 = inttoptr i64 %59 to i64*
  store i64 %60, i64* %63, align 8
  %64 = load i64, i64* %RBP.i, align 8
  %65 = add i64 %64, -40
  %66 = load i64, i64* %3, align 8
  %67 = add i64 %66, 7
  store i64 %67, i64* %3, align 8
  %68 = inttoptr i64 %65 to i32*
  store i32 0, i32* %68, align 4
  %69 = load i64, i64* %RBP.i, align 8
  %70 = add i64 %69, -76
  %71 = load i64, i64* %3, align 8
  %72 = add i64 %71, 7
  store i64 %72, i64* %3, align 8
  %73 = inttoptr i64 %70 to i32*
  store i32 0, i32* %73, align 4
  %74 = load i64, i64* %RBP.i, align 8
  %75 = add i64 %74, -472
  %76 = load i64, i64* %3, align 8
  %77 = add i64 %76, 8
  store i64 %77, i64* %3, align 8
  %78 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %41, i64 0, i32 0, i32 0, i32 0, i64 0
  %79 = load i64, i64* %78, align 1
  %80 = inttoptr i64 %75 to i64*
  store i64 %79, i64* %80, align 8
  %RDI.i2141 = getelementptr inbounds %union.anon, %union.anon* %43, i64 0, i32 0
  %81 = load i64, i64* %RBP.i, align 8
  %82 = add i64 %81, -12
  %83 = load i64, i64* %3, align 8
  %84 = add i64 %83, 3
  store i64 %84, i64* %3, align 8
  %85 = inttoptr i64 %82 to i32*
  %86 = load i32, i32* %85, align 4
  %87 = zext i32 %86 to i64
  store i64 %87, i64* %RDI.i2141, align 8
  %EAX.i2159 = bitcast %union.anon* %30 to i32*
  %88 = add i64 %81, -1156
  %89 = load i32, i32* %EAX.i2159, align 4
  %90 = add i64 %83, 9
  store i64 %90, i64* %3, align 8
  %91 = inttoptr i64 %88 to i32*
  store i32 %89, i32* %91, align 4
  %92 = load i32, i32* %EDI.i1845, align 4
  %93 = zext i32 %92 to i64
  %94 = load i64, i64* %3, align 8
  store i64 %93, i64* %RAX.i1763, align 8
  %EDX.i2206 = bitcast %union.anon* %40 to i32*
  %95 = load i64, i64* %RBP.i, align 8
  %96 = add i64 %95, -1160
  %97 = load i32, i32* %EDX.i2206, align 4
  %98 = add i64 %94, 8
  store i64 %98, i64* %3, align 8
  %99 = inttoptr i64 %96 to i32*
  store i32 %97, i32* %99, align 4
  %100 = load i64, i64* %3, align 8
  %101 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %102 = load i32, i32* %EAX.i2159, align 8
  %103 = sext i32 %102 to i64
  %104 = lshr i64 %103, 32
  store i64 %104, i64* %101, align 8
  %105 = load i64, i64* %RBP.i, align 8
  %106 = add i64 %105, -1160
  %107 = add i64 %100, 7
  store i64 %107, i64* %3, align 8
  %108 = inttoptr i64 %106 to i32*
  %109 = load i32, i32* %108, align 4
  %110 = zext i32 %109 to i64
  store i64 %110, i64* %RDI.i2141, align 8
  %111 = add i64 %100, 9
  store i64 %111, i64* %3, align 8
  %112 = zext i32 %102 to i64
  %113 = sext i32 %109 to i64
  %114 = shl nuw i64 %104, 32
  %115 = or i64 %114, %112
  %116 = sdiv i64 %115, %113
  %117 = shl i64 %116, 32
  %118 = ashr exact i64 %117, 32
  %119 = icmp eq i64 %116, %118
  br i1 %119, label %122, label %120

; <label>:120:                                    ; preds = %entry
  %121 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %111, %struct.Memory* %2)
  %.pre = load i64, i64* %RDX.i1805, align 8
  %.pre501 = load i64, i64* %3, align 8
  %.pre502 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__edi.exit

; <label>:122:                                    ; preds = %entry
  %123 = srem i64 %115, %113
  %124 = and i64 %116, 4294967295
  store i64 %124, i64* %RAX.i1763, align 8
  %125 = and i64 %123, 4294967295
  store i64 %125, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__edi.exit

routine_idivl__edi.exit:                          ; preds = %122, %120
  %126 = phi i64 [ %.pre502, %120 ], [ %105, %122 ]
  %127 = phi i64 [ %.pre501, %120 ], [ %111, %122 ]
  %128 = phi i64 [ %.pre, %120 ], [ %125, %122 ]
  %129 = phi %struct.Memory* [ %121, %120 ], [ %2, %122 ]
  %.tr = trunc i64 %128 to i32
  %130 = shl i32 %.tr, 3
  %131 = zext i32 %130 to i64
  store i64 %131, i64* %RDX.i1805, align 8
  %132 = lshr i64 %128, 29
  %133 = trunc i64 %132 to i8
  %134 = and i8 %133, 1
  store i8 %134, i8* %18, align 1
  %135 = and i32 %130, 248
  %136 = tail call i32 @llvm.ctpop.i32(i32 %135)
  %137 = trunc i32 %136 to i8
  %138 = and i8 %137, 1
  %139 = xor i8 %138, 1
  store i8 %139, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %140 = icmp eq i32 %130, 0
  %141 = zext i1 %140 to i8
  store i8 %141, i8* %21, align 1
  %142 = lshr i32 %.tr, 28
  %143 = trunc i32 %142 to i8
  %144 = and i8 %143, 1
  store i8 %144, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %145 = add i64 %126, -484
  %146 = add i64 %127, 9
  store i64 %146, i64* %3, align 8
  %147 = inttoptr i64 %145 to i32*
  store i32 %130, i32* %147, align 4
  %148 = load i64, i64* %RBP.i, align 8
  %149 = add i64 %148, -12
  %150 = load i64, i64* %3, align 8
  %151 = add i64 %150, 3
  store i64 %151, i64* %3, align 8
  %152 = inttoptr i64 %149 to i32*
  %153 = load i32, i32* %152, align 4
  %154 = zext i32 %153 to i64
  store i64 %154, i64* %RAX.i1763, align 8
  %155 = sext i32 %153 to i64
  %156 = lshr i64 %155, 32
  store i64 %156, i64* %101, align 8
  %157 = load i32, i32* %EDI.i1845, align 4
  %158 = add i64 %150, 8
  store i64 %158, i64* %3, align 8
  %159 = sext i32 %157 to i64
  %160 = shl nuw i64 %156, 32
  %161 = or i64 %160, %154
  %162 = sdiv i64 %161, %159
  %163 = shl i64 %162, 32
  %164 = ashr exact i64 %163, 32
  %165 = icmp eq i64 %162, %164
  br i1 %165, label %168, label %166

; <label>:166:                                    ; preds = %routine_idivl__edi.exit
  %167 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %158, %struct.Memory* %129)
  %.pre503 = load i64, i64* %RAX.i1763, align 8
  %.pre504 = load i64, i64* %3, align 8
  %.pre505 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__edi.exit2483

; <label>:168:                                    ; preds = %routine_idivl__edi.exit
  %169 = srem i64 %161, %159
  %170 = and i64 %162, 4294967295
  store i64 %170, i64* %RAX.i1763, align 8
  %171 = and i64 %169, 4294967295
  store i64 %171, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__edi.exit2483

routine_idivl__edi.exit2483:                      ; preds = %168, %166
  %172 = phi i64 [ %.pre505, %166 ], [ %148, %168 ]
  %173 = phi i64 [ %.pre504, %166 ], [ %158, %168 ]
  %174 = phi i64 [ %.pre503, %166 ], [ %170, %168 ]
  %175 = phi %struct.Memory* [ %167, %166 ], [ %129, %168 ]
  %.tr123 = trunc i64 %174 to i32
  %176 = shl i32 %.tr123, 3
  %177 = zext i32 %176 to i64
  store i64 %177, i64* %RAX.i1763, align 8
  %178 = lshr i64 %174, 29
  %179 = trunc i64 %178 to i8
  %180 = and i8 %179, 1
  store i8 %180, i8* %18, align 1
  %181 = and i32 %176, 248
  %182 = tail call i32 @llvm.ctpop.i32(i32 %181)
  %183 = trunc i32 %182 to i8
  %184 = and i8 %183, 1
  %185 = xor i8 %184, 1
  store i8 %185, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %186 = icmp eq i32 %176, 0
  %187 = zext i1 %186 to i8
  store i8 %187, i8* %21, align 1
  %188 = lshr i32 %.tr123, 28
  %189 = trunc i32 %188 to i8
  %190 = and i8 %189, 1
  store i8 %190, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %191 = add i64 %172, -488
  %192 = add i64 %173, 9
  store i64 %192, i64* %3, align 8
  %193 = inttoptr i64 %191 to i32*
  store i32 %176, i32* %193, align 4
  %194 = load i64, i64* %3, align 8
  %195 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %195, i64* %RSI.i1889, align 8
  %196 = add i64 %195, 152
  %197 = add i64 %194, 14
  store i64 %197, i64* %3, align 8
  %198 = inttoptr i64 %196 to i32*
  %199 = load i32, i32* %198, align 4
  %200 = zext i32 %199 to i64
  store i64 %200, i64* %RAX.i1763, align 8
  %201 = load i64, i64* %RBP.i, align 8
  %202 = add i64 %201, -484
  %203 = add i64 %194, 20
  store i64 %203, i64* %3, align 8
  %204 = inttoptr i64 %202 to i32*
  %205 = load i32, i32* %204, align 4
  %206 = add i32 %205, %199
  %207 = zext i32 %206 to i64
  store i64 %207, i64* %RAX.i1763, align 8
  %208 = icmp ult i32 %206, %199
  %209 = icmp ult i32 %206, %205
  %210 = or i1 %208, %209
  %211 = zext i1 %210 to i8
  store i8 %211, i8* %18, align 1
  %212 = and i32 %206, 255
  %213 = tail call i32 @llvm.ctpop.i32(i32 %212)
  %214 = trunc i32 %213 to i8
  %215 = and i8 %214, 1
  %216 = xor i8 %215, 1
  store i8 %216, i8* %19, align 1
  %217 = xor i32 %205, %199
  %218 = xor i32 %217, %206
  %219 = lshr i32 %218, 4
  %220 = trunc i32 %219 to i8
  %221 = and i8 %220, 1
  store i8 %221, i8* %20, align 1
  %222 = icmp eq i32 %206, 0
  %223 = zext i1 %222 to i8
  store i8 %223, i8* %21, align 1
  %224 = lshr i32 %206, 31
  %225 = trunc i32 %224 to i8
  store i8 %225, i8* %22, align 1
  %226 = lshr i32 %199, 31
  %227 = lshr i32 %205, 31
  %228 = xor i32 %224, %226
  %229 = xor i32 %224, %227
  %230 = add nuw nsw i32 %228, %229
  %231 = icmp eq i32 %230, 2
  %232 = zext i1 %231 to i8
  store i8 %232, i8* %23, align 1
  %233 = add i64 %201, -492
  %234 = add i64 %194, 26
  store i64 %234, i64* %3, align 8
  %235 = inttoptr i64 %233 to i32*
  store i32 %206, i32* %235, align 4
  %236 = load i64, i64* %3, align 8
  %237 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %237, i64* %RSI.i1889, align 8
  %238 = add i64 %237, 156
  %239 = add i64 %236, 14
  store i64 %239, i64* %3, align 8
  %240 = inttoptr i64 %238 to i32*
  %241 = load i32, i32* %240, align 4
  %242 = zext i32 %241 to i64
  store i64 %242, i64* %RAX.i1763, align 8
  %243 = load i64, i64* %RBP.i, align 8
  %244 = add i64 %243, -488
  %245 = add i64 %236, 20
  store i64 %245, i64* %3, align 8
  %246 = inttoptr i64 %244 to i32*
  %247 = load i32, i32* %246, align 4
  %248 = add i32 %247, %241
  %249 = zext i32 %248 to i64
  store i64 %249, i64* %RAX.i1763, align 8
  %250 = icmp ult i32 %248, %241
  %251 = icmp ult i32 %248, %247
  %252 = or i1 %250, %251
  %253 = zext i1 %252 to i8
  store i8 %253, i8* %18, align 1
  %254 = and i32 %248, 255
  %255 = tail call i32 @llvm.ctpop.i32(i32 %254)
  %256 = trunc i32 %255 to i8
  %257 = and i8 %256, 1
  %258 = xor i8 %257, 1
  store i8 %258, i8* %19, align 1
  %259 = xor i32 %247, %241
  %260 = xor i32 %259, %248
  %261 = lshr i32 %260, 4
  %262 = trunc i32 %261 to i8
  %263 = and i8 %262, 1
  store i8 %263, i8* %20, align 1
  %264 = icmp eq i32 %248, 0
  %265 = zext i1 %264 to i8
  store i8 %265, i8* %21, align 1
  %266 = lshr i32 %248, 31
  %267 = trunc i32 %266 to i8
  store i8 %267, i8* %22, align 1
  %268 = lshr i32 %241, 31
  %269 = lshr i32 %247, 31
  %270 = xor i32 %266, %268
  %271 = xor i32 %266, %269
  %272 = add nuw nsw i32 %270, %271
  %273 = icmp eq i32 %272, 2
  %274 = zext i1 %273 to i8
  store i8 %274, i8* %23, align 1
  %275 = add i64 %243, -496
  %276 = add i64 %236, 26
  store i64 %276, i64* %3, align 8
  %277 = inttoptr i64 %275 to i32*
  store i32 %248, i32* %277, align 4
  %278 = load i64, i64* %3, align 8
  %279 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %279, i64* %RSI.i1889, align 8
  %280 = add i64 %279, 168
  %281 = add i64 %278, 14
  store i64 %281, i64* %3, align 8
  %282 = inttoptr i64 %280 to i32*
  %283 = load i32, i32* %282, align 4
  %284 = zext i32 %283 to i64
  store i64 %284, i64* %RAX.i1763, align 8
  %285 = load i64, i64* %RBP.i, align 8
  %286 = add i64 %285, -484
  %287 = add i64 %278, 20
  store i64 %287, i64* %3, align 8
  %288 = inttoptr i64 %286 to i32*
  %289 = load i32, i32* %288, align 4
  %290 = add i32 %289, %283
  %291 = zext i32 %290 to i64
  store i64 %291, i64* %RAX.i1763, align 8
  %292 = icmp ult i32 %290, %283
  %293 = icmp ult i32 %290, %289
  %294 = or i1 %292, %293
  %295 = zext i1 %294 to i8
  store i8 %295, i8* %18, align 1
  %296 = and i32 %290, 255
  %297 = tail call i32 @llvm.ctpop.i32(i32 %296)
  %298 = trunc i32 %297 to i8
  %299 = and i8 %298, 1
  %300 = xor i8 %299, 1
  store i8 %300, i8* %19, align 1
  %301 = xor i32 %289, %283
  %302 = xor i32 %301, %290
  %303 = lshr i32 %302, 4
  %304 = trunc i32 %303 to i8
  %305 = and i8 %304, 1
  store i8 %305, i8* %20, align 1
  %306 = icmp eq i32 %290, 0
  %307 = zext i1 %306 to i8
  store i8 %307, i8* %21, align 1
  %308 = lshr i32 %290, 31
  %309 = trunc i32 %308 to i8
  store i8 %309, i8* %22, align 1
  %310 = lshr i32 %283, 31
  %311 = lshr i32 %289, 31
  %312 = xor i32 %308, %310
  %313 = xor i32 %308, %311
  %314 = add nuw nsw i32 %312, %313
  %315 = icmp eq i32 %314, 2
  %316 = zext i1 %315 to i8
  store i8 %316, i8* %23, align 1
  %317 = add i64 %285, -500
  %318 = add i64 %278, 26
  store i64 %318, i64* %3, align 8
  %319 = inttoptr i64 %317 to i32*
  store i32 %290, i32* %319, align 4
  %320 = load i64, i64* %3, align 8
  %321 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %321, i64* %RSI.i1889, align 8
  %322 = add i64 %321, 172
  %323 = add i64 %320, 14
  store i64 %323, i64* %3, align 8
  %324 = inttoptr i64 %322 to i32*
  %325 = load i32, i32* %324, align 4
  %326 = zext i32 %325 to i64
  store i64 %326, i64* %RAX.i1763, align 8
  %327 = load i64, i64* %RBP.i, align 8
  %328 = add i64 %327, -488
  %329 = add i64 %320, 20
  store i64 %329, i64* %3, align 8
  %330 = inttoptr i64 %328 to i32*
  %331 = load i32, i32* %330, align 4
  %332 = add i32 %331, %325
  %333 = zext i32 %332 to i64
  store i64 %333, i64* %RAX.i1763, align 8
  %334 = icmp ult i32 %332, %325
  %335 = icmp ult i32 %332, %331
  %336 = or i1 %334, %335
  %337 = zext i1 %336 to i8
  store i8 %337, i8* %18, align 1
  %338 = and i32 %332, 255
  %339 = tail call i32 @llvm.ctpop.i32(i32 %338)
  %340 = trunc i32 %339 to i8
  %341 = and i8 %340, 1
  %342 = xor i8 %341, 1
  store i8 %342, i8* %19, align 1
  %343 = xor i32 %331, %325
  %344 = xor i32 %343, %332
  %345 = lshr i32 %344, 4
  %346 = trunc i32 %345 to i8
  %347 = and i8 %346, 1
  store i8 %347, i8* %20, align 1
  %348 = icmp eq i32 %332, 0
  %349 = zext i1 %348 to i8
  store i8 %349, i8* %21, align 1
  %350 = lshr i32 %332, 31
  %351 = trunc i32 %350 to i8
  store i8 %351, i8* %22, align 1
  %352 = lshr i32 %325, 31
  %353 = lshr i32 %331, 31
  %354 = xor i32 %350, %352
  %355 = xor i32 %350, %353
  %356 = add nuw nsw i32 %354, %355
  %357 = icmp eq i32 %356, 2
  %358 = zext i1 %357 to i8
  store i8 %358, i8* %23, align 1
  %359 = add i64 %327, -504
  %360 = add i64 %320, 26
  store i64 %360, i64* %3, align 8
  %361 = inttoptr i64 %359 to i32*
  store i32 %332, i32* %361, align 4
  %362 = load i64, i64* %RBP.i, align 8
  %363 = add i64 %362, -492
  %364 = load i64, i64* %3, align 8
  %365 = add i64 %364, 6
  store i64 %365, i64* %3, align 8
  %366 = inttoptr i64 %363 to i32*
  %367 = load i32, i32* %366, align 4
  %368 = zext i32 %367 to i64
  store i64 %368, i64* %RAX.i1763, align 8
  %369 = sext i32 %367 to i64
  %370 = lshr i64 %369, 32
  store i64 %370, i64* %101, align 8
  %371 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D.i4319 = bitcast %union.anon* %371 to i32*
  %372 = getelementptr inbounds %union.anon, %union.anon* %371, i64 0, i32 0
  %373 = add i64 %362, -1156
  %374 = add i64 %364, 14
  store i64 %374, i64* %3, align 8
  %375 = inttoptr i64 %373 to i32*
  %376 = load i32, i32* %375, align 4
  %377 = zext i32 %376 to i64
  store i64 %377, i64* %372, align 8
  %378 = add i64 %364, 17
  store i64 %378, i64* %3, align 8
  %379 = sext i32 %376 to i64
  %380 = shl nuw i64 %370, 32
  %381 = or i64 %380, %368
  %382 = sdiv i64 %381, %379
  %383 = shl i64 %382, 32
  %384 = ashr exact i64 %383, 32
  %385 = icmp eq i64 %382, %384
  br i1 %385, label %388, label %386

; <label>:386:                                    ; preds = %routine_idivl__edi.exit2483
  %387 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %378, %struct.Memory* %175)
  %.pre506 = load i64, i64* %RBP.i, align 8
  %.pre507 = load i32, i32* %EAX.i2159, align 4
  %.pre508 = load i64, i64* %3, align 8
  br label %routine_idivl__r10d.exit

; <label>:388:                                    ; preds = %routine_idivl__edi.exit2483
  %389 = srem i64 %381, %379
  %390 = and i64 %382, 4294967295
  store i64 %390, i64* %RAX.i1763, align 8
  %391 = and i64 %389, 4294967295
  store i64 %391, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %392 = trunc i64 %382 to i32
  br label %routine_idivl__r10d.exit

routine_idivl__r10d.exit:                         ; preds = %388, %386
  %393 = phi i64 [ %.pre508, %386 ], [ %378, %388 ]
  %394 = phi i32 [ %.pre507, %386 ], [ %392, %388 ]
  %395 = phi i64 [ %.pre506, %386 ], [ %362, %388 ]
  %396 = phi %struct.Memory* [ %387, %386 ], [ %175, %388 ]
  %397 = add i64 %395, -508
  %398 = add i64 %393, 6
  store i64 %398, i64* %3, align 8
  %399 = inttoptr i64 %397 to i32*
  store i32 %394, i32* %399, align 4
  %400 = load i64, i64* %RBP.i, align 8
  %401 = add i64 %400, -496
  %402 = load i64, i64* %3, align 8
  %403 = add i64 %402, 6
  store i64 %403, i64* %3, align 8
  %404 = inttoptr i64 %401 to i32*
  %405 = load i32, i32* %404, align 4
  %406 = zext i32 %405 to i64
  store i64 %406, i64* %RAX.i1763, align 8
  %407 = sext i32 %405 to i64
  %408 = lshr i64 %407, 32
  store i64 %408, i64* %101, align 8
  %409 = load i32, i32* %R10D.i4319, align 4
  %410 = add i64 %402, 10
  store i64 %410, i64* %3, align 8
  %411 = sext i32 %409 to i64
  %412 = shl nuw i64 %408, 32
  %413 = or i64 %412, %406
  %414 = sdiv i64 %413, %411
  %415 = shl i64 %414, 32
  %416 = ashr exact i64 %415, 32
  %417 = icmp eq i64 %414, %416
  br i1 %417, label %420, label %418

; <label>:418:                                    ; preds = %routine_idivl__r10d.exit
  %419 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %410, %struct.Memory* %396)
  %.pre509 = load i64, i64* %RBP.i, align 8
  %.pre510 = load i32, i32* %EAX.i2159, align 4
  %.pre511 = load i64, i64* %3, align 8
  br label %routine_idivl__r10d.exit6904

; <label>:420:                                    ; preds = %routine_idivl__r10d.exit
  %421 = srem i64 %413, %411
  %422 = and i64 %414, 4294967295
  store i64 %422, i64* %RAX.i1763, align 8
  %423 = and i64 %421, 4294967295
  store i64 %423, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %424 = trunc i64 %414 to i32
  br label %routine_idivl__r10d.exit6904

routine_idivl__r10d.exit6904:                     ; preds = %420, %418
  %425 = phi i64 [ %.pre511, %418 ], [ %410, %420 ]
  %426 = phi i32 [ %.pre510, %418 ], [ %424, %420 ]
  %427 = phi i64 [ %.pre509, %418 ], [ %400, %420 ]
  %428 = phi %struct.Memory* [ %419, %418 ], [ %396, %420 ]
  %429 = add i64 %427, -512
  %430 = add i64 %425, 6
  store i64 %430, i64* %3, align 8
  %431 = inttoptr i64 %429 to i32*
  store i32 %426, i32* %431, align 4
  %432 = load i64, i64* %RBP.i, align 8
  %433 = add i64 %432, -520
  %434 = load i64, i64* %3, align 8
  %435 = add i64 %434, 8
  store i64 %435, i64* %3, align 8
  %436 = load i64, i64* %37, align 1
  %437 = inttoptr i64 %433 to i64*
  store i64 %436, i64* %437, align 8
  %438 = load i64, i64* %3, align 8
  %439 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  %440 = load i64, i64* %RBP.i, align 8
  %441 = add i64 %440, -528
  %442 = add i64 %438, 15
  store i64 %442, i64* %3, align 8
  %443 = inttoptr i64 %441 to i64*
  store i64 %439, i64* %443, align 8
  %444 = load i64, i64* %3, align 8
  %445 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %445, i64* %RSI.i1889, align 8
  %446 = add i64 %445, 14168
  %447 = add i64 %444, 15
  store i64 %447, i64* %3, align 8
  %448 = inttoptr i64 %446 to i64*
  %449 = load i64, i64* %448, align 8
  store i64 %449, i64* %RSI.i1889, align 8
  %R11.i7712 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  store i64 %445, i64* %R11.i7712, align 8
  %450 = add i64 %445, 12
  %451 = add i64 %444, 27
  store i64 %451, i64* %3, align 8
  %452 = inttoptr i64 %450 to i32*
  %453 = load i32, i32* %452, align 4
  %454 = sext i32 %453 to i64
  %455 = mul nsw i64 %454, 632
  store i64 %455, i64* %R11.i7712, align 8
  %456 = lshr i64 %455, 63
  %457 = add i64 %455, %449
  store i64 %457, i64* %RSI.i1889, align 8
  %458 = icmp ult i64 %457, %449
  %459 = icmp ult i64 %457, %455
  %460 = or i1 %458, %459
  %461 = zext i1 %460 to i8
  store i8 %461, i8* %18, align 1
  %462 = trunc i64 %457 to i32
  %463 = and i32 %462, 255
  %464 = tail call i32 @llvm.ctpop.i32(i32 %463)
  %465 = trunc i32 %464 to i8
  %466 = and i8 %465, 1
  %467 = xor i8 %466, 1
  store i8 %467, i8* %19, align 1
  %468 = xor i64 %455, %449
  %469 = xor i64 %468, %457
  %470 = lshr i64 %469, 4
  %471 = trunc i64 %470 to i8
  %472 = and i8 %471, 1
  store i8 %472, i8* %20, align 1
  %473 = icmp eq i64 %457, 0
  %474 = zext i1 %473 to i8
  store i8 %474, i8* %21, align 1
  %475 = lshr i64 %457, 63
  %476 = trunc i64 %475 to i8
  store i8 %476, i8* %22, align 1
  %477 = lshr i64 %449, 63
  %478 = xor i64 %475, %477
  %479 = xor i64 %475, %456
  %480 = add nuw nsw i64 %478, %479
  %481 = icmp eq i64 %480, 2
  %482 = zext i1 %481 to i8
  store i8 %482, i8* %23, align 1
  %483 = add i64 %457, 524
  %484 = add i64 %444, 43
  store i64 %484, i64* %3, align 8
  %485 = inttoptr i64 %483 to i32*
  %486 = load i32, i32* %485, align 4
  %487 = zext i32 %486 to i64
  store i64 %487, i64* %RAX.i1763, align 8
  %488 = load i64, i64* %RBP.i, align 8
  %489 = add i64 %488, -632
  %490 = add i64 %444, 49
  store i64 %490, i64* %3, align 8
  %491 = inttoptr i64 %489 to i32*
  store i32 %486, i32* %491, align 4
  %492 = load i64, i64* %3, align 8
  %493 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %493, i64* %RSI.i1889, align 8
  %494 = add i64 %493, 12
  %495 = add i64 %492, 11
  store i64 %495, i64* %3, align 8
  %496 = inttoptr i64 %494 to i32*
  %497 = load i32, i32* %496, align 4
  %498 = zext i32 %497 to i64
  store i64 %498, i64* %RDI.i2141, align 8
  %499 = load i64, i64* %RBP.i, align 8
  %500 = add i64 %499, -484
  %501 = add i64 %492, 17
  store i64 %501, i64* %3, align 8
  %502 = inttoptr i64 %500 to i32*
  %503 = load i32, i32* %502, align 4
  %504 = zext i32 %503 to i64
  store i64 %504, i64* %RAX.i1763, align 8
  %505 = sext i32 %503 to i64
  %506 = lshr i64 %505, 32
  store i64 %506, i64* %101, align 8
  %507 = load i32, i32* %R10D.i4319, align 4
  %508 = add i64 %492, 21
  store i64 %508, i64* %3, align 8
  %509 = sext i32 %507 to i64
  %510 = shl nuw i64 %506, 32
  %511 = or i64 %510, %504
  %512 = sdiv i64 %511, %509
  %513 = shl i64 %512, 32
  %514 = ashr exact i64 %513, 32
  %515 = icmp eq i64 %512, %514
  br i1 %515, label %518, label %516

; <label>:516:                                    ; preds = %routine_idivl__r10d.exit6904
  %517 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %508, %struct.Memory* %428)
  %.pre512 = load i64, i64* %RBP.i, align 8
  %.pre513 = load i64, i64* %3, align 8
  %.pre514 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__r10d.exit7724

; <label>:518:                                    ; preds = %routine_idivl__r10d.exit6904
  %519 = srem i64 %511, %509
  %520 = and i64 %512, 4294967295
  store i64 %520, i64* %RAX.i1763, align 8
  %521 = and i64 %519, 4294967295
  store i64 %521, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %522 = trunc i64 %512 to i32
  br label %routine_idivl__r10d.exit7724

routine_idivl__r10d.exit7724:                     ; preds = %518, %516
  %523 = phi i32 [ %.pre514, %516 ], [ %522, %518 ]
  %524 = phi i64 [ %.pre513, %516 ], [ %508, %518 ]
  %525 = phi i64 [ %.pre512, %516 ], [ %499, %518 ]
  %526 = phi %struct.Memory* [ %517, %516 ], [ %428, %518 ]
  %527 = add i64 %525, -488
  %528 = add i64 %524, 6
  store i64 %528, i64* %3, align 8
  %529 = inttoptr i64 %527 to i32*
  %530 = load i32, i32* %529, align 4
  %531 = zext i32 %530 to i64
  store i64 %531, i64* %RBX.i161, align 8
  %532 = add i64 %525, -1164
  %533 = add i64 %524, 12
  store i64 %533, i64* %3, align 8
  %534 = inttoptr i64 %532 to i32*
  store i32 %523, i32* %534, align 4
  %EBX.i = bitcast %union.anon* %11 to i32*
  %535 = load i32, i32* %EBX.i, align 4
  %536 = zext i32 %535 to i64
  %537 = load i64, i64* %3, align 8
  store i64 %536, i64* %RAX.i1763, align 8
  %538 = sext i32 %535 to i64
  %539 = lshr i64 %538, 32
  store i64 %539, i64* %101, align 8
  %540 = load i32, i32* %R10D.i4319, align 4
  %541 = add i64 %537, 6
  store i64 %541, i64* %3, align 8
  %542 = sext i32 %540 to i64
  %543 = shl nuw i64 %539, 32
  %544 = or i64 %543, %536
  %545 = sdiv i64 %544, %542
  %546 = shl i64 %545, 32
  %547 = ashr exact i64 %546, 32
  %548 = icmp eq i64 %545, %547
  br i1 %548, label %551, label %549

; <label>:549:                                    ; preds = %routine_idivl__r10d.exit7724
  %550 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %541, %struct.Memory* %526)
  %.pre515 = load i64, i64* %3, align 8
  %.pre516 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__r10d.exit7710

; <label>:551:                                    ; preds = %routine_idivl__r10d.exit7724
  %552 = srem i64 %544, %542
  %553 = and i64 %545, 4294967295
  store i64 %553, i64* %RAX.i1763, align 8
  %554 = and i64 %552, 4294967295
  store i64 %554, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %555 = trunc i64 %545 to i32
  br label %routine_idivl__r10d.exit7710

routine_idivl__r10d.exit7710:                     ; preds = %551, %549
  %556 = phi i32 [ %.pre516, %549 ], [ %555, %551 ]
  %557 = phi i64 [ %.pre515, %549 ], [ %541, %551 ]
  %558 = phi %struct.Memory* [ %550, %549 ], [ %526, %551 ]
  %559 = load i64, i64* %RBP.i, align 8
  %560 = add i64 %559, -1164
  %561 = add i64 %557, 6
  store i64 %561, i64* %3, align 8
  %562 = inttoptr i64 %560 to i32*
  %563 = load i32, i32* %562, align 4
  %564 = zext i32 %563 to i64
  store i64 %564, i64* %RSI.i1889, align 8
  %565 = zext i32 %556 to i64
  store i64 %565, i64* %RDX.i1805, align 8
  %566 = add i64 %557, -364372
  %567 = add i64 %557, 13
  %568 = load i64, i64* %6, align 8
  %569 = add i64 %568, -8
  %570 = inttoptr i64 %569 to i64*
  store i64 %567, i64* %570, align 8
  store i64 %569, i64* %6, align 8
  store i64 %566, i64* %3, align 8
  %call2_4a418c = tail call %struct.Memory* @sub_44b230.getLuma4x4Neighbour(%struct.State* nonnull %0, i64 %566, %struct.Memory* %558)
  %ECX.i7699 = bitcast %union.anon* %24 to i32*
  %571 = load i64, i64* %3, align 8
  store i64 0, i64* %RCX.i1692, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  store i64 4294967295, i64* %26, align 8
  %572 = load i64, i64* %RBP.i, align 8
  %573 = add i64 %572, -600
  store i64 %573, i64* %R9.i, align 8
  store i64 4, i64* %RAX.i1763, align 8
  %574 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %574, i64* %R11.i7712, align 8
  %575 = add i64 %574, 12
  %576 = add i64 %571, 32
  store i64 %576, i64* %3, align 8
  %577 = inttoptr i64 %575 to i32*
  %578 = load i32, i32* %577, align 4
  %579 = zext i32 %578 to i64
  store i64 %579, i64* %RDI.i2141, align 8
  %580 = add i64 %572, -484
  %581 = add i64 %571, 38
  store i64 %581, i64* %3, align 8
  %582 = inttoptr i64 %580 to i32*
  %583 = load i32, i32* %582, align 4
  %584 = zext i32 %583 to i64
  store i64 %584, i64* %RDX.i1805, align 8
  %585 = add i64 %572, -1168
  %586 = add i64 %571, 44
  store i64 %586, i64* %3, align 8
  %587 = inttoptr i64 %585 to i32*
  store i32 4, i32* %587, align 4
  %588 = load i32, i32* %EDX.i2206, align 4
  %589 = zext i32 %588 to i64
  %590 = load i64, i64* %3, align 8
  store i64 %589, i64* %RAX.i1763, align 8
  %591 = sext i32 %588 to i64
  %592 = lshr i64 %591, 32
  store i64 %592, i64* %101, align 8
  %593 = load i64, i64* %RBP.i, align 8
  %594 = add i64 %593, -1168
  %595 = add i64 %590, 9
  store i64 %595, i64* %3, align 8
  %596 = inttoptr i64 %594 to i32*
  %597 = load i32, i32* %596, align 4
  %598 = zext i32 %597 to i64
  store i64 %598, i64* %RSI.i1889, align 8
  %ESI.i7670 = bitcast %union.anon* %57 to i32*
  %599 = add i64 %590, 11
  store i64 %599, i64* %3, align 8
  %600 = sext i32 %597 to i64
  %601 = shl nuw i64 %592, 32
  %602 = or i64 %601, %589
  %603 = sdiv i64 %602, %600
  %604 = shl i64 %603, 32
  %605 = ashr exact i64 %604, 32
  %606 = icmp eq i64 %603, %605
  br i1 %606, label %609, label %607

; <label>:607:                                    ; preds = %routine_idivl__r10d.exit7710
  %608 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %599, %struct.Memory* %call2_4a418c)
  %.pre517 = load i64, i64* %RBP.i, align 8
  %.pre518 = load i64, i64* %3, align 8
  %.pre519 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__esi.exit7671

; <label>:609:                                    ; preds = %routine_idivl__r10d.exit7710
  %610 = srem i64 %602, %600
  %611 = and i64 %603, 4294967295
  store i64 %611, i64* %RAX.i1763, align 8
  %612 = and i64 %610, 4294967295
  store i64 %612, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %613 = trunc i64 %603 to i32
  br label %routine_idivl__esi.exit7671

routine_idivl__esi.exit7671:                      ; preds = %609, %607
  %614 = phi i32 [ %.pre519, %607 ], [ %613, %609 ]
  %615 = phi i64 [ %.pre518, %607 ], [ %599, %609 ]
  %616 = phi i64 [ %.pre517, %607 ], [ %593, %609 ]
  %617 = phi %struct.Memory* [ %608, %607 ], [ %call2_4a418c, %609 ]
  %618 = add i64 %616, -488
  %619 = add i64 %615, 7
  store i64 %619, i64* %3, align 8
  %620 = inttoptr i64 %618 to i32*
  %621 = load i32, i32* %620, align 4
  %622 = zext i32 %621 to i64
  store i64 %622, i64* %372, align 8
  %623 = add i64 %616, -1172
  %624 = add i64 %615, 13
  store i64 %624, i64* %3, align 8
  %625 = inttoptr i64 %623 to i32*
  store i32 %614, i32* %625, align 4
  %626 = load i32, i32* %R10D.i4319, align 4
  %627 = zext i32 %626 to i64
  %628 = load i64, i64* %3, align 8
  store i64 %627, i64* %RAX.i1763, align 8
  %629 = sext i32 %626 to i64
  %630 = lshr i64 %629, 32
  store i64 %630, i64* %101, align 8
  %631 = load i32, i32* %ESI.i7670, align 4
  %632 = add i64 %628, 6
  store i64 %632, i64* %3, align 8
  %633 = sext i32 %631 to i64
  %634 = shl nuw i64 %630, 32
  %635 = or i64 %634, %627
  %636 = sdiv i64 %635, %633
  %637 = shl i64 %636, 32
  %638 = ashr exact i64 %637, 32
  %639 = icmp eq i64 %636, %638
  br i1 %639, label %642, label %640

; <label>:640:                                    ; preds = %routine_idivl__esi.exit7671
  %641 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %632, %struct.Memory* %617)
  %.pre520 = load i64, i64* %3, align 8
  %.pre521 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__esi.exit7656

; <label>:642:                                    ; preds = %routine_idivl__esi.exit7671
  %643 = srem i64 %635, %633
  %644 = and i64 %636, 4294967295
  store i64 %644, i64* %RAX.i1763, align 8
  %645 = and i64 %643, 4294967295
  store i64 %645, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %646 = trunc i64 %636 to i32
  br label %routine_idivl__esi.exit7656

routine_idivl__esi.exit7656:                      ; preds = %642, %640
  %647 = phi i32 [ %.pre521, %640 ], [ %646, %642 ]
  %648 = phi i64 [ %.pre520, %640 ], [ %632, %642 ]
  %649 = phi %struct.Memory* [ %641, %640 ], [ %617, %642 ]
  %650 = load i64, i64* %RBP.i, align 8
  %651 = add i64 %650, -1172
  %652 = add i64 %648, 6
  store i64 %652, i64* %3, align 8
  %653 = inttoptr i64 %651 to i32*
  %654 = load i32, i32* %653, align 4
  %655 = zext i32 %654 to i64
  store i64 %655, i64* %RSI.i1889, align 8
  %656 = zext i32 %647 to i64
  store i64 %656, i64* %RDX.i1805, align 8
  %657 = add i64 %648, -364459
  %658 = add i64 %648, 13
  %659 = load i64, i64* %6, align 8
  %660 = add i64 %659, -8
  %661 = inttoptr i64 %660 to i64*
  store i64 %658, i64* %661, align 8
  store i64 %660, i64* %6, align 8
  store i64 %657, i64* %3, align 8
  %call2_4a41e3 = tail call %struct.Memory* @sub_44b230.getLuma4x4Neighbour(%struct.State* nonnull %0, i64 %657, %struct.Memory* %649)
  %662 = load i64, i64* %3, align 8
  %663 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %663, i64* %R9.i, align 8
  %664 = add i64 %663, 216
  %665 = add i64 %662, 16
  store i64 %665, i64* %3, align 8
  %666 = inttoptr i64 %664 to i32*
  %667 = load i32, i32* %666, align 4
  store i8 0, i8* %18, align 1
  %668 = and i32 %667, 255
  %669 = tail call i32 @llvm.ctpop.i32(i32 %668)
  %670 = trunc i32 %669 to i8
  %671 = and i8 %670, 1
  %672 = xor i8 %671, 1
  store i8 %672, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %673 = icmp eq i32 %667, 0
  %674 = zext i1 %673 to i8
  store i8 %674, i8* %21, align 1
  %675 = lshr i32 %667, 31
  %676 = trunc i32 %675 to i8
  store i8 %676, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v809 = select i1 %673, i64 170, i64 22
  %677 = add i64 %662, %.v809
  store i64 %677, i64* %3, align 8
  br i1 %673, label %block_.L_4a4292, label %block_4a41fe

block_4a41fe:                                     ; preds = %routine_idivl__esi.exit7656
  %678 = load i64, i64* %RBP.i, align 8
  %679 = add i64 %678, -600
  %680 = add i64 %677, 7
  store i64 %680, i64* %3, align 8
  %681 = inttoptr i64 %679 to i32*
  %682 = load i32, i32* %681, align 4
  store i8 0, i8* %18, align 1
  %683 = and i32 %682, 255
  %684 = tail call i32 @llvm.ctpop.i32(i32 %683)
  %685 = trunc i32 %684 to i8
  %686 = and i8 %685, 1
  %687 = xor i8 %686, 1
  store i8 %687, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %688 = icmp eq i32 %682, 0
  %689 = zext i1 %688 to i8
  store i8 %689, i8* %21, align 1
  %690 = lshr i32 %682, 31
  %691 = trunc i32 %690 to i8
  store i8 %691, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v810 = select i1 %688, i64 49, i64 13
  %692 = add i64 %677, %.v810
  store i64 %692, i64* %3, align 8
  br i1 %688, label %block_.L_4a422f, label %block_4a420b

block_4a420b:                                     ; preds = %block_4a41fe
  %693 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %693, i64* %RAX.i1763, align 8
  %694 = add i64 %693, 71784
  %695 = add i64 %692, 15
  store i64 %695, i64* %3, align 8
  %696 = inttoptr i64 %694 to i64*
  %697 = load i64, i64* %696, align 8
  store i64 %697, i64* %RAX.i1763, align 8
  %698 = add i64 %678, -596
  %699 = add i64 %692, 22
  store i64 %699, i64* %3, align 8
  %700 = inttoptr i64 %698 to i32*
  %701 = load i32, i32* %700, align 4
  %702 = sext i32 %701 to i64
  store i64 %702, i64* %RCX.i1692, align 8
  %703 = shl nsw i64 %702, 2
  %704 = add i64 %703, %697
  %705 = add i64 %692, 25
  store i64 %705, i64* %3, align 8
  %706 = inttoptr i64 %704 to i32*
  %707 = load i32, i32* %706, align 4
  %708 = zext i32 %707 to i64
  store i64 %708, i64* %RDX.i1805, align 8
  %709 = add i64 %678, -1176
  %710 = add i64 %692, 31
  store i64 %710, i64* %3, align 8
  %711 = inttoptr i64 %709 to i32*
  store i32 %707, i32* %711, align 4
  %712 = load i64, i64* %3, align 8
  %713 = add i64 %712, 18
  br label %block_.L_4a423c

block_.L_4a422f:                                  ; preds = %block_4a41fe
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %714 = add i64 %678, -1176
  %715 = add i64 %692, 8
  store i64 %715, i64* %3, align 8
  %716 = inttoptr i64 %714 to i32*
  store i32 0, i32* %716, align 4
  %717 = load i64, i64* %3, align 8
  %718 = add i64 %717, 5
  store i64 %718, i64* %3, align 8
  br label %block_.L_4a423c

block_.L_4a423c:                                  ; preds = %block_.L_4a422f, %block_4a420b
  %storemerge = phi i64 [ %713, %block_4a420b ], [ %718, %block_.L_4a422f ]
  %719 = load i64, i64* %RBP.i, align 8
  %720 = add i64 %719, -1176
  %721 = add i64 %storemerge, 6
  store i64 %721, i64* %3, align 8
  %722 = inttoptr i64 %720 to i32*
  %723 = load i32, i32* %722, align 4
  %724 = zext i32 %723 to i64
  store i64 %724, i64* %RAX.i1763, align 8
  %725 = add i64 %719, -600
  %726 = add i64 %storemerge, 12
  store i64 %726, i64* %3, align 8
  %727 = inttoptr i64 %725 to i32*
  store i32 %723, i32* %727, align 4
  %728 = load i64, i64* %RBP.i, align 8
  %729 = add i64 %728, -576
  %730 = load i64, i64* %3, align 8
  %731 = add i64 %730, 7
  store i64 %731, i64* %3, align 8
  %732 = inttoptr i64 %729 to i32*
  %733 = load i32, i32* %732, align 4
  store i8 0, i8* %18, align 1
  %734 = and i32 %733, 255
  %735 = tail call i32 @llvm.ctpop.i32(i32 %734)
  %736 = trunc i32 %735 to i8
  %737 = and i8 %736, 1
  %738 = xor i8 %737, 1
  store i8 %738, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %739 = icmp eq i32 %733, 0
  %740 = zext i1 %739 to i8
  store i8 %740, i8* %21, align 1
  %741 = lshr i32 %733, 31
  %742 = trunc i32 %741 to i8
  store i8 %742, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v811 = select i1 %739, i64 49, i64 13
  %743 = add i64 %730, %.v811
  store i64 %743, i64* %3, align 8
  br i1 %739, label %block_.L_4a4279, label %block_4a4255

block_4a4255:                                     ; preds = %block_.L_4a423c
  %744 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %744, i64* %RAX.i1763, align 8
  %745 = add i64 %744, 71784
  %746 = add i64 %743, 15
  store i64 %746, i64* %3, align 8
  %747 = inttoptr i64 %745 to i64*
  %748 = load i64, i64* %747, align 8
  store i64 %748, i64* %RAX.i1763, align 8
  %749 = add i64 %728, -572
  %750 = add i64 %743, 22
  store i64 %750, i64* %3, align 8
  %751 = inttoptr i64 %749 to i32*
  %752 = load i32, i32* %751, align 4
  %753 = sext i32 %752 to i64
  store i64 %753, i64* %RCX.i1692, align 8
  %754 = shl nsw i64 %753, 2
  %755 = add i64 %754, %748
  %756 = add i64 %743, 25
  store i64 %756, i64* %3, align 8
  %757 = inttoptr i64 %755 to i32*
  %758 = load i32, i32* %757, align 4
  %759 = zext i32 %758 to i64
  store i64 %759, i64* %RDX.i1805, align 8
  %760 = add i64 %728, -1180
  %761 = add i64 %743, 31
  store i64 %761, i64* %3, align 8
  %762 = inttoptr i64 %760 to i32*
  store i32 %758, i32* %762, align 4
  %763 = load i64, i64* %3, align 8
  %764 = add i64 %763, 18
  br label %block_.L_4a4286

block_.L_4a4279:                                  ; preds = %block_.L_4a423c
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %765 = add i64 %728, -1180
  %766 = add i64 %743, 8
  store i64 %766, i64* %3, align 8
  %767 = inttoptr i64 %765 to i32*
  store i32 0, i32* %767, align 4
  %768 = load i64, i64* %3, align 8
  %769 = add i64 %768, 5
  store i64 %769, i64* %3, align 8
  br label %block_.L_4a4286

block_.L_4a4286:                                  ; preds = %block_.L_4a4279, %block_4a4255
  %storemerge125 = phi i64 [ %764, %block_4a4255 ], [ %769, %block_.L_4a4279 ]
  %770 = load i64, i64* %RBP.i, align 8
  %771 = add i64 %770, -1180
  %772 = add i64 %storemerge125, 6
  store i64 %772, i64* %3, align 8
  %773 = inttoptr i64 %771 to i32*
  %774 = load i32, i32* %773, align 4
  %775 = zext i32 %774 to i64
  store i64 %775, i64* %RAX.i1763, align 8
  %776 = add i64 %770, -576
  %777 = add i64 %storemerge125, 12
  store i64 %777, i64* %3, align 8
  %778 = inttoptr i64 %776 to i32*
  store i32 %774, i32* %778, align 4
  %.pre522 = load i64, i64* %3, align 8
  br label %block_.L_4a4292

block_.L_4a4292:                                  ; preds = %block_.L_4a4286, %routine_idivl__esi.exit7656
  %779 = phi i64 [ %.pre522, %block_.L_4a4286 ], [ %677, %routine_idivl__esi.exit7656 ]
  store i64 2, i64* %RAX.i1763, align 8
  %780 = load i64, i64* %RBP.i, align 8
  %781 = add i64 %780, -12
  %782 = add i64 %779, 8
  store i64 %782, i64* %3, align 8
  %783 = inttoptr i64 %781 to i32*
  %784 = load i32, i32* %783, align 4
  %785 = zext i32 %784 to i64
  store i64 %785, i64* %RCX.i1692, align 8
  %786 = add i64 %780, -1184
  %787 = add i64 %779, 14
  store i64 %787, i64* %3, align 8
  %788 = inttoptr i64 %786 to i32*
  store i32 2, i32* %788, align 4
  %789 = load i32, i32* %ECX.i7699, align 4
  %790 = zext i32 %789 to i64
  %791 = load i64, i64* %3, align 8
  store i64 %790, i64* %RAX.i1763, align 8
  %792 = sext i32 %789 to i64
  %793 = lshr i64 %792, 32
  store i64 %793, i64* %101, align 8
  %794 = load i64, i64* %RBP.i, align 8
  %795 = add i64 %794, -1184
  %796 = add i64 %791, 9
  store i64 %796, i64* %3, align 8
  %797 = inttoptr i64 %795 to i32*
  %798 = load i32, i32* %797, align 4
  %799 = zext i32 %798 to i64
  store i64 %799, i64* %RCX.i1692, align 8
  %800 = add i64 %791, 11
  store i64 %800, i64* %3, align 8
  %801 = sext i32 %798 to i64
  %802 = shl nuw i64 %793, 32
  %803 = or i64 %802, %790
  %804 = sdiv i64 %803, %801
  %805 = shl i64 %804, 32
  %806 = ashr exact i64 %805, 32
  %807 = icmp eq i64 %804, %806
  br i1 %807, label %810, label %808

; <label>:808:                                    ; preds = %block_.L_4a4292
  %809 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %800, %struct.Memory* %call2_4a41e3)
  %.pre523 = load i32, i32* %EAX.i2159, align 4
  %.pre524 = load i64, i64* %3, align 8
  %.pre525 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit7561

; <label>:810:                                    ; preds = %block_.L_4a4292
  %811 = srem i64 %803, %801
  %812 = and i64 %804, 4294967295
  store i64 %812, i64* %RAX.i1763, align 8
  %813 = and i64 %811, 4294967295
  store i64 %813, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %814 = trunc i64 %804 to i32
  br label %routine_idivl__ecx.exit7561

routine_idivl__ecx.exit7561:                      ; preds = %810, %808
  %815 = phi i64 [ %.pre525, %808 ], [ %794, %810 ]
  %816 = phi i64 [ %.pre524, %808 ], [ %800, %810 ]
  %817 = phi i32 [ %.pre523, %808 ], [ %814, %810 ]
  %818 = phi %struct.Memory* [ %809, %808 ], [ %call2_4a41e3, %810 ]
  store i8 0, i8* %18, align 1
  %819 = and i32 %817, 255
  %820 = tail call i32 @llvm.ctpop.i32(i32 %819)
  %821 = trunc i32 %820 to i8
  %822 = and i8 %821, 1
  %823 = xor i8 %822, 1
  store i8 %823, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %824 = icmp eq i32 %817, 0
  %825 = zext i1 %824 to i8
  store i8 %825, i8* %21, align 1
  %826 = lshr i32 %817, 31
  %827 = trunc i32 %826 to i8
  store i8 %827, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v760 = select i1 %824, i64 99, i64 9
  %828 = add i64 %816, %.v760
  %829 = add i64 %815, -600
  %830 = add i64 %828, 7
  store i64 %830, i64* %3, align 8
  %831 = inttoptr i64 %829 to i32*
  %832 = load i32, i32* %831, align 4
  store i8 0, i8* %18, align 1
  %833 = and i32 %832, 255
  %834 = tail call i32 @llvm.ctpop.i32(i32 %833)
  %835 = trunc i32 %834 to i8
  %836 = and i8 %835, 1
  %837 = xor i8 %836, 1
  store i8 %837, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %838 = icmp eq i32 %832, 0
  %839 = zext i1 %838 to i8
  store i8 %839, i8* %21, align 1
  %840 = lshr i32 %832, 31
  %841 = trunc i32 %840 to i8
  store i8 %841, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v812 = select i1 %838, i64 57, i64 13
  %842 = add i64 %828, %.v812
  store i64 %842, i64* %3, align 8
  br i1 %824, label %block_.L_4a430e, label %block_4a42b4

block_4a42b4:                                     ; preds = %routine_idivl__ecx.exit7561
  br i1 %838, label %block_.L_4a42ed, label %block_4a42c1

block_4a42c1:                                     ; preds = %block_4a42b4
  %843 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %843, i64* %RAX.i1763, align 8
  %844 = add i64 %843, 112
  %845 = add i64 %842, 12
  store i64 %845, i64* %3, align 8
  %846 = inttoptr i64 %844 to i64*
  %847 = load i64, i64* %846, align 8
  store i64 %847, i64* %RAX.i1763, align 8
  %848 = add i64 %815, -584
  %849 = add i64 %842, 19
  store i64 %849, i64* %3, align 8
  %850 = inttoptr i64 %848 to i32*
  %851 = load i32, i32* %850, align 4
  %852 = sext i32 %851 to i64
  store i64 %852, i64* %RCX.i1692, align 8
  %853 = shl nsw i64 %852, 3
  %854 = add i64 %853, %847
  %855 = add i64 %842, 23
  store i64 %855, i64* %3, align 8
  %856 = inttoptr i64 %854 to i64*
  %857 = load i64, i64* %856, align 8
  store i64 %857, i64* %RAX.i1763, align 8
  %858 = add i64 %815, -580
  %859 = add i64 %842, 30
  store i64 %859, i64* %3, align 8
  %860 = inttoptr i64 %858 to i32*
  %861 = load i32, i32* %860, align 4
  %862 = sext i32 %861 to i64
  store i64 %862, i64* %RCX.i1692, align 8
  %863 = shl nsw i64 %862, 2
  %864 = add i64 %863, %857
  %865 = add i64 %842, 33
  store i64 %865, i64* %3, align 8
  %866 = inttoptr i64 %864 to i32*
  %867 = load i32, i32* %866, align 4
  %868 = zext i32 %867 to i64
  store i64 %868, i64* %RDX.i1805, align 8
  %869 = add i64 %815, -1188
  %870 = add i64 %842, 39
  store i64 %870, i64* %3, align 8
  %871 = inttoptr i64 %869 to i32*
  store i32 %867, i32* %871, align 4
  %872 = load i64, i64* %3, align 8
  %873 = add i64 %872, 21
  br label %block_.L_4a42fd

block_.L_4a42ed:                                  ; preds = %block_4a42b4
  store i64 4294967295, i64* %RAX.i1763, align 8
  %874 = add i64 %815, -1188
  %875 = add i64 %842, 11
  store i64 %875, i64* %3, align 8
  %876 = inttoptr i64 %874 to i32*
  store i32 -1, i32* %876, align 4
  %877 = load i64, i64* %3, align 8
  %878 = add i64 %877, 5
  store i64 %878, i64* %3, align 8
  br label %block_.L_4a42fd

block_.L_4a42fd:                                  ; preds = %block_.L_4a42ed, %block_4a42c1
  %storemerge126 = phi i64 [ %873, %block_4a42c1 ], [ %878, %block_.L_4a42ed ]
  %879 = load i64, i64* %RBP.i, align 8
  %880 = add i64 %879, -1188
  %881 = add i64 %storemerge126, 6
  store i64 %881, i64* %3, align 8
  %882 = inttoptr i64 %880 to i32*
  %883 = load i32, i32* %882, align 4
  %884 = zext i32 %883 to i64
  store i64 %884, i64* %RAX.i1763, align 8
  %885 = add i64 %879, -544
  %886 = add i64 %storemerge126, 12
  store i64 %886, i64* %3, align 8
  %887 = inttoptr i64 %885 to i32*
  store i32 %883, i32* %887, align 4
  %888 = load i64, i64* %3, align 8
  %889 = add i64 %888, 90
  store i64 %889, i64* %3, align 8
  br label %block_.L_4a4363

block_.L_4a430e:                                  ; preds = %routine_idivl__ecx.exit7561
  br i1 %838, label %block_.L_4a4347, label %block_4a431b

block_4a431b:                                     ; preds = %block_.L_4a430e
  %890 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %890, i64* %RAX.i1763, align 8
  %891 = add i64 %890, 104
  %892 = add i64 %842, 12
  store i64 %892, i64* %3, align 8
  %893 = inttoptr i64 %891 to i64*
  %894 = load i64, i64* %893, align 8
  store i64 %894, i64* %RAX.i1763, align 8
  %895 = add i64 %815, -584
  %896 = add i64 %842, 19
  store i64 %896, i64* %3, align 8
  %897 = inttoptr i64 %895 to i32*
  %898 = load i32, i32* %897, align 4
  %899 = sext i32 %898 to i64
  store i64 %899, i64* %RCX.i1692, align 8
  %900 = shl nsw i64 %899, 3
  %901 = add i64 %900, %894
  %902 = add i64 %842, 23
  store i64 %902, i64* %3, align 8
  %903 = inttoptr i64 %901 to i64*
  %904 = load i64, i64* %903, align 8
  store i64 %904, i64* %RAX.i1763, align 8
  %905 = add i64 %815, -580
  %906 = add i64 %842, 30
  store i64 %906, i64* %3, align 8
  %907 = inttoptr i64 %905 to i32*
  %908 = load i32, i32* %907, align 4
  %909 = sext i32 %908 to i64
  store i64 %909, i64* %RCX.i1692, align 8
  %910 = shl nsw i64 %909, 2
  %911 = add i64 %910, %904
  %912 = add i64 %842, 33
  store i64 %912, i64* %3, align 8
  %913 = inttoptr i64 %911 to i32*
  %914 = load i32, i32* %913, align 4
  %915 = zext i32 %914 to i64
  store i64 %915, i64* %RDX.i1805, align 8
  %916 = add i64 %815, -1192
  %917 = add i64 %842, 39
  store i64 %917, i64* %3, align 8
  %918 = inttoptr i64 %916 to i32*
  store i32 %914, i32* %918, align 4
  %919 = load i64, i64* %3, align 8
  %920 = add i64 %919, 21
  br label %block_.L_4a4357

block_.L_4a4347:                                  ; preds = %block_.L_4a430e
  store i64 4294967295, i64* %RAX.i1763, align 8
  %921 = add i64 %815, -1192
  %922 = add i64 %842, 11
  store i64 %922, i64* %3, align 8
  %923 = inttoptr i64 %921 to i32*
  store i32 -1, i32* %923, align 4
  %924 = load i64, i64* %3, align 8
  %925 = add i64 %924, 5
  store i64 %925, i64* %3, align 8
  br label %block_.L_4a4357

block_.L_4a4357:                                  ; preds = %block_.L_4a4347, %block_4a431b
  %storemerge329 = phi i64 [ %920, %block_4a431b ], [ %925, %block_.L_4a4347 ]
  %926 = load i64, i64* %RBP.i, align 8
  %927 = add i64 %926, -1192
  %928 = add i64 %storemerge329, 6
  store i64 %928, i64* %3, align 8
  %929 = inttoptr i64 %927 to i32*
  %930 = load i32, i32* %929, align 4
  %931 = zext i32 %930 to i64
  store i64 %931, i64* %RAX.i1763, align 8
  %932 = add i64 %926, -544
  %933 = add i64 %storemerge329, 12
  store i64 %933, i64* %3, align 8
  %934 = inttoptr i64 %932 to i32*
  store i32 %930, i32* %934, align 4
  %.pre526 = load i64, i64* %3, align 8
  br label %block_.L_4a4363

block_.L_4a4363:                                  ; preds = %block_.L_4a4357, %block_.L_4a42fd
  %935 = phi i64 [ %.pre526, %block_.L_4a4357 ], [ %889, %block_.L_4a42fd ]
  store i64 2, i64* %RAX.i1763, align 8
  %936 = load i64, i64* %RBP.i, align 8
  %937 = add i64 %936, -12
  %938 = add i64 %935, 8
  store i64 %938, i64* %3, align 8
  %939 = inttoptr i64 %937 to i32*
  %940 = load i32, i32* %939, align 4
  %941 = zext i32 %940 to i64
  store i64 %941, i64* %RCX.i1692, align 8
  %942 = add i64 %936, -1196
  %943 = add i64 %935, 14
  store i64 %943, i64* %3, align 8
  %944 = inttoptr i64 %942 to i32*
  store i32 2, i32* %944, align 4
  %945 = load i32, i32* %ECX.i7699, align 4
  %946 = zext i32 %945 to i64
  %947 = load i64, i64* %3, align 8
  store i64 %946, i64* %RAX.i1763, align 8
  %948 = sext i32 %945 to i64
  %949 = lshr i64 %948, 32
  store i64 %949, i64* %101, align 8
  %950 = load i64, i64* %RBP.i, align 8
  %951 = add i64 %950, -1196
  %952 = add i64 %947, 9
  store i64 %952, i64* %3, align 8
  %953 = inttoptr i64 %951 to i32*
  %954 = load i32, i32* %953, align 4
  %955 = zext i32 %954 to i64
  store i64 %955, i64* %RCX.i1692, align 8
  %956 = add i64 %947, 11
  store i64 %956, i64* %3, align 8
  %957 = sext i32 %954 to i64
  %958 = shl nuw i64 %949, 32
  %959 = or i64 %958, %946
  %960 = sdiv i64 %959, %957
  %961 = shl i64 %960, 32
  %962 = ashr exact i64 %961, 32
  %963 = icmp eq i64 %960, %962
  br i1 %963, label %966, label %964

; <label>:964:                                    ; preds = %block_.L_4a4363
  %965 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %956, %struct.Memory* %818)
  %.pre527 = load i32, i32* %EDX.i2206, align 4
  %.pre528 = load i64, i64* %3, align 8
  %.pre529 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit7465

; <label>:966:                                    ; preds = %block_.L_4a4363
  %967 = srem i64 %959, %957
  %968 = and i64 %960, 4294967295
  store i64 %968, i64* %RAX.i1763, align 8
  %969 = and i64 %967, 4294967295
  store i64 %969, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %970 = trunc i64 %967 to i32
  br label %routine_idivl__ecx.exit7465

routine_idivl__ecx.exit7465:                      ; preds = %966, %964
  %971 = phi i64 [ %.pre529, %964 ], [ %950, %966 ]
  %972 = phi i64 [ %.pre528, %964 ], [ %956, %966 ]
  %973 = phi i32 [ %.pre527, %964 ], [ %970, %966 ]
  %974 = phi %struct.Memory* [ %965, %964 ], [ %818, %966 ]
  store i8 0, i8* %18, align 1
  %975 = and i32 %973, 255
  %976 = tail call i32 @llvm.ctpop.i32(i32 %975)
  %977 = trunc i32 %976 to i8
  %978 = and i8 %977, 1
  %979 = xor i8 %978, 1
  store i8 %979, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %980 = icmp eq i32 %973, 0
  %981 = zext i1 %980 to i8
  store i8 %981, i8* %21, align 1
  %982 = lshr i32 %973, 31
  %983 = trunc i32 %982 to i8
  store i8 %983, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v761 = select i1 %980, i64 99, i64 9
  %984 = add i64 %972, %.v761
  %985 = add i64 %971, -576
  %986 = add i64 %984, 7
  store i64 %986, i64* %3, align 8
  %987 = inttoptr i64 %985 to i32*
  %988 = load i32, i32* %987, align 4
  store i8 0, i8* %18, align 1
  %989 = and i32 %988, 255
  %990 = tail call i32 @llvm.ctpop.i32(i32 %989)
  %991 = trunc i32 %990 to i8
  %992 = and i8 %991, 1
  %993 = xor i8 %992, 1
  store i8 %993, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %994 = icmp eq i32 %988, 0
  %995 = zext i1 %994 to i8
  store i8 %995, i8* %21, align 1
  %996 = lshr i32 %988, 31
  %997 = trunc i32 %996 to i8
  store i8 %997, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v813 = select i1 %994, i64 57, i64 13
  %998 = add i64 %984, %.v813
  store i64 %998, i64* %3, align 8
  br i1 %980, label %block_.L_4a43df, label %block_4a4385

block_4a4385:                                     ; preds = %routine_idivl__ecx.exit7465
  br i1 %994, label %block_.L_4a43be, label %block_4a4392

block_4a4392:                                     ; preds = %block_4a4385
  %999 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %999, i64* %RAX.i1763, align 8
  %1000 = add i64 %999, 112
  %1001 = add i64 %998, 12
  store i64 %1001, i64* %3, align 8
  %1002 = inttoptr i64 %1000 to i64*
  %1003 = load i64, i64* %1002, align 8
  store i64 %1003, i64* %RAX.i1763, align 8
  %1004 = add i64 %971, -560
  %1005 = add i64 %998, 19
  store i64 %1005, i64* %3, align 8
  %1006 = inttoptr i64 %1004 to i32*
  %1007 = load i32, i32* %1006, align 4
  %1008 = sext i32 %1007 to i64
  store i64 %1008, i64* %RCX.i1692, align 8
  %1009 = shl nsw i64 %1008, 3
  %1010 = add i64 %1009, %1003
  %1011 = add i64 %998, 23
  store i64 %1011, i64* %3, align 8
  %1012 = inttoptr i64 %1010 to i64*
  %1013 = load i64, i64* %1012, align 8
  store i64 %1013, i64* %RAX.i1763, align 8
  %1014 = add i64 %971, -556
  %1015 = add i64 %998, 30
  store i64 %1015, i64* %3, align 8
  %1016 = inttoptr i64 %1014 to i32*
  %1017 = load i32, i32* %1016, align 4
  %1018 = sext i32 %1017 to i64
  store i64 %1018, i64* %RCX.i1692, align 8
  %1019 = shl nsw i64 %1018, 2
  %1020 = add i64 %1019, %1013
  %1021 = add i64 %998, 33
  store i64 %1021, i64* %3, align 8
  %1022 = inttoptr i64 %1020 to i32*
  %1023 = load i32, i32* %1022, align 4
  %1024 = zext i32 %1023 to i64
  store i64 %1024, i64* %RDX.i1805, align 8
  %1025 = add i64 %971, -1200
  %1026 = add i64 %998, 39
  store i64 %1026, i64* %3, align 8
  %1027 = inttoptr i64 %1025 to i32*
  store i32 %1023, i32* %1027, align 4
  %1028 = load i64, i64* %3, align 8
  %1029 = add i64 %1028, 21
  br label %block_.L_4a43ce

block_.L_4a43be:                                  ; preds = %block_4a4385
  store i64 4294967295, i64* %RAX.i1763, align 8
  %1030 = add i64 %971, -1200
  %1031 = add i64 %998, 11
  store i64 %1031, i64* %3, align 8
  %1032 = inttoptr i64 %1030 to i32*
  store i32 -1, i32* %1032, align 4
  %1033 = load i64, i64* %3, align 8
  %1034 = add i64 %1033, 5
  store i64 %1034, i64* %3, align 8
  br label %block_.L_4a43ce

block_.L_4a43ce:                                  ; preds = %block_.L_4a43be, %block_4a4392
  %storemerge127 = phi i64 [ %1029, %block_4a4392 ], [ %1034, %block_.L_4a43be ]
  %1035 = load i64, i64* %RBP.i, align 8
  %1036 = add i64 %1035, -1200
  %1037 = add i64 %storemerge127, 6
  store i64 %1037, i64* %3, align 8
  %1038 = inttoptr i64 %1036 to i32*
  %1039 = load i32, i32* %1038, align 4
  %1040 = zext i32 %1039 to i64
  store i64 %1040, i64* %RAX.i1763, align 8
  %1041 = add i64 %1035, -548
  %1042 = add i64 %storemerge127, 12
  store i64 %1042, i64* %3, align 8
  %1043 = inttoptr i64 %1041 to i32*
  store i32 %1039, i32* %1043, align 4
  %1044 = load i64, i64* %3, align 8
  %1045 = add i64 %1044, 90
  store i64 %1045, i64* %3, align 8
  br label %block_.L_4a4434

block_.L_4a43df:                                  ; preds = %routine_idivl__ecx.exit7465
  br i1 %994, label %block_.L_4a4418, label %block_4a43ec

block_4a43ec:                                     ; preds = %block_.L_4a43df
  %1046 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1046, i64* %RAX.i1763, align 8
  %1047 = add i64 %1046, 104
  %1048 = add i64 %998, 12
  store i64 %1048, i64* %3, align 8
  %1049 = inttoptr i64 %1047 to i64*
  %1050 = load i64, i64* %1049, align 8
  store i64 %1050, i64* %RAX.i1763, align 8
  %1051 = add i64 %971, -560
  %1052 = add i64 %998, 19
  store i64 %1052, i64* %3, align 8
  %1053 = inttoptr i64 %1051 to i32*
  %1054 = load i32, i32* %1053, align 4
  %1055 = sext i32 %1054 to i64
  store i64 %1055, i64* %RCX.i1692, align 8
  %1056 = shl nsw i64 %1055, 3
  %1057 = add i64 %1056, %1050
  %1058 = add i64 %998, 23
  store i64 %1058, i64* %3, align 8
  %1059 = inttoptr i64 %1057 to i64*
  %1060 = load i64, i64* %1059, align 8
  store i64 %1060, i64* %RAX.i1763, align 8
  %1061 = add i64 %971, -556
  %1062 = add i64 %998, 30
  store i64 %1062, i64* %3, align 8
  %1063 = inttoptr i64 %1061 to i32*
  %1064 = load i32, i32* %1063, align 4
  %1065 = sext i32 %1064 to i64
  store i64 %1065, i64* %RCX.i1692, align 8
  %1066 = shl nsw i64 %1065, 2
  %1067 = add i64 %1066, %1060
  %1068 = add i64 %998, 33
  store i64 %1068, i64* %3, align 8
  %1069 = inttoptr i64 %1067 to i32*
  %1070 = load i32, i32* %1069, align 4
  %1071 = zext i32 %1070 to i64
  store i64 %1071, i64* %RDX.i1805, align 8
  %1072 = add i64 %971, -1204
  %1073 = add i64 %998, 39
  store i64 %1073, i64* %3, align 8
  %1074 = inttoptr i64 %1072 to i32*
  store i32 %1070, i32* %1074, align 4
  %1075 = load i64, i64* %3, align 8
  %1076 = add i64 %1075, 21
  br label %block_.L_4a4428

block_.L_4a4418:                                  ; preds = %block_.L_4a43df
  store i64 4294967295, i64* %RAX.i1763, align 8
  %1077 = add i64 %971, -1204
  %1078 = add i64 %998, 11
  store i64 %1078, i64* %3, align 8
  %1079 = inttoptr i64 %1077 to i32*
  store i32 -1, i32* %1079, align 4
  %1080 = load i64, i64* %3, align 8
  %1081 = add i64 %1080, 5
  store i64 %1081, i64* %3, align 8
  br label %block_.L_4a4428

block_.L_4a4428:                                  ; preds = %block_.L_4a4418, %block_4a43ec
  %storemerge328 = phi i64 [ %1076, %block_4a43ec ], [ %1081, %block_.L_4a4418 ]
  %1082 = load i64, i64* %RBP.i, align 8
  %1083 = add i64 %1082, -1204
  %1084 = add i64 %storemerge328, 6
  store i64 %1084, i64* %3, align 8
  %1085 = inttoptr i64 %1083 to i32*
  %1086 = load i32, i32* %1085, align 4
  %1087 = zext i32 %1086 to i64
  store i64 %1087, i64* %RAX.i1763, align 8
  %1088 = add i64 %1082, -548
  %1089 = add i64 %storemerge328, 12
  store i64 %1089, i64* %3, align 8
  %1090 = inttoptr i64 %1088 to i32*
  store i32 %1086, i32* %1090, align 4
  %.pre530 = load i64, i64* %3, align 8
  br label %block_.L_4a4434

block_.L_4a4434:                                  ; preds = %block_.L_4a4428, %block_.L_4a43ce
  %1091 = phi i64 [ %.pre530, %block_.L_4a4428 ], [ %1045, %block_.L_4a43ce ]
  %1092 = load i64, i64* %RBP.i, align 8
  %1093 = add i64 %1092, -544
  %1094 = add i64 %1091, 7
  store i64 %1094, i64* %3, align 8
  %1095 = inttoptr i64 %1093 to i32*
  %1096 = load i32, i32* %1095, align 4
  store i8 0, i8* %18, align 1
  %1097 = and i32 %1096, 255
  %1098 = tail call i32 @llvm.ctpop.i32(i32 %1097)
  %1099 = trunc i32 %1098 to i8
  %1100 = and i8 %1099, 1
  %1101 = xor i8 %1100, 1
  store i8 %1101, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %1102 = icmp eq i32 %1096, 0
  %1103 = zext i1 %1102 to i8
  store i8 %1103, i8* %21, align 1
  %1104 = lshr i32 %1096, 31
  %1105 = trunc i32 %1104 to i8
  store i8 %1105, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %1106 = icmp ne i8 %1105, 0
  %.v = select i1 %1106, i64 19, i64 6
  %1107 = add i64 %1094, %.v
  store i64 %1107, i64* %3, align 8
  br i1 %1106, label %block_.L_4a444e, label %block_4a4441

block_4a4441:                                     ; preds = %block_.L_4a4434
  %1108 = add i64 %1092, -548
  %1109 = add i64 %1107, 7
  store i64 %1109, i64* %3, align 8
  %1110 = inttoptr i64 %1108 to i32*
  %1111 = load i32, i32* %1110, align 4
  store i8 0, i8* %18, align 1
  %1112 = and i32 %1111, 255
  %1113 = tail call i32 @llvm.ctpop.i32(i32 %1112)
  %1114 = trunc i32 %1113 to i8
  %1115 = and i8 %1114, 1
  %1116 = xor i8 %1115, 1
  store i8 %1116, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %1117 = icmp eq i32 %1111, 0
  %1118 = zext i1 %1117 to i8
  store i8 %1118, i8* %21, align 1
  %1119 = lshr i32 %1111, 31
  %1120 = trunc i32 %1119 to i8
  store i8 %1120, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %1121 = icmp ne i8 %1120, 0
  %.v330 = select i1 %1121, i64 6, i64 22
  %1122 = add i64 %1109, %.v330
  store i64 %1122, i64* %3, align 8
  br i1 %1121, label %block_.L_4a444e, label %block_.L_4a445e

block_.L_4a444e:                                  ; preds = %block_4a4441, %block_.L_4a4434
  %1123 = phi i64 [ %1122, %block_4a4441 ], [ %1107, %block_.L_4a4434 ]
  store i64 2, i64* %RAX.i1763, align 8
  %1124 = add i64 %1092, -1208
  %1125 = add i64 %1123, 11
  store i64 %1125, i64* %3, align 8
  %1126 = inttoptr i64 %1124 to i32*
  store i32 2, i32* %1126, align 4
  %1127 = load i64, i64* %3, align 8
  %1128 = add i64 %1127, 64
  store i64 %1128, i64* %3, align 8
  br label %block_.L_4a4499

block_.L_4a445e:                                  ; preds = %block_4a4441
  %1129 = add i64 %1122, 6
  store i64 %1129, i64* %3, align 8
  %1130 = load i32, i32* %1095, align 4
  %1131 = zext i32 %1130 to i64
  store i64 %1131, i64* %RAX.i1763, align 8
  %1132 = add i64 %1122, 12
  store i64 %1132, i64* %3, align 8
  %1133 = load i32, i32* %1110, align 4
  %1134 = sub i32 %1130, %1133
  %1135 = icmp ult i32 %1130, %1133
  %1136 = zext i1 %1135 to i8
  store i8 %1136, i8* %18, align 1
  %1137 = and i32 %1134, 255
  %1138 = tail call i32 @llvm.ctpop.i32(i32 %1137)
  %1139 = trunc i32 %1138 to i8
  %1140 = and i8 %1139, 1
  %1141 = xor i8 %1140, 1
  store i8 %1141, i8* %19, align 1
  %1142 = xor i32 %1133, %1130
  %1143 = xor i32 %1142, %1134
  %1144 = lshr i32 %1143, 4
  %1145 = trunc i32 %1144 to i8
  %1146 = and i8 %1145, 1
  store i8 %1146, i8* %20, align 1
  %1147 = icmp eq i32 %1134, 0
  %1148 = zext i1 %1147 to i8
  store i8 %1148, i8* %21, align 1
  %1149 = lshr i32 %1134, 31
  %1150 = trunc i32 %1149 to i8
  store i8 %1150, i8* %22, align 1
  %1151 = lshr i32 %1130, 31
  %1152 = lshr i32 %1133, 31
  %1153 = xor i32 %1152, %1151
  %1154 = xor i32 %1149, %1151
  %1155 = add nuw nsw i32 %1154, %1153
  %1156 = icmp eq i32 %1155, 2
  %1157 = zext i1 %1156 to i8
  store i8 %1157, i8* %23, align 1
  %1158 = icmp ne i8 %1150, 0
  %1159 = xor i1 %1158, %1156
  %.v814 = select i1 %1159, i64 18, i64 35
  %1160 = add i64 %1122, %.v814
  %1161 = add i64 %1160, 6
  store i64 %1161, i64* %3, align 8
  br i1 %1159, label %block_4a4470, label %block_.L_4a4481

block_4a4470:                                     ; preds = %block_.L_4a445e
  %1162 = load i32, i32* %1095, align 4
  %1163 = zext i32 %1162 to i64
  store i64 %1163, i64* %RAX.i1763, align 8
  %1164 = add i64 %1092, -1212
  %1165 = add i64 %1160, 12
  store i64 %1165, i64* %3, align 8
  %1166 = inttoptr i64 %1164 to i32*
  store i32 %1162, i32* %1166, align 4
  %1167 = load i64, i64* %3, align 8
  %1168 = add i64 %1167, 17
  store i64 %1168, i64* %3, align 8
  br label %block_.L_4a448d

block_.L_4a4481:                                  ; preds = %block_.L_4a445e
  %1169 = load i32, i32* %1110, align 4
  %1170 = zext i32 %1169 to i64
  store i64 %1170, i64* %RAX.i1763, align 8
  %1171 = add i64 %1092, -1212
  %1172 = add i64 %1160, 12
  store i64 %1172, i64* %3, align 8
  %1173 = inttoptr i64 %1171 to i32*
  store i32 %1169, i32* %1173, align 4
  %.pre531 = load i64, i64* %3, align 8
  br label %block_.L_4a448d

block_.L_4a448d:                                  ; preds = %block_.L_4a4481, %block_4a4470
  %1174 = phi i64 [ %.pre531, %block_.L_4a4481 ], [ %1168, %block_4a4470 ]
  %1175 = load i64, i64* %RBP.i, align 8
  %1176 = add i64 %1175, -1212
  %1177 = add i64 %1174, 6
  store i64 %1177, i64* %3, align 8
  %1178 = inttoptr i64 %1176 to i32*
  %1179 = load i32, i32* %1178, align 4
  %1180 = zext i32 %1179 to i64
  store i64 %1180, i64* %RAX.i1763, align 8
  %1181 = add i64 %1175, -1208
  %1182 = add i64 %1174, 12
  store i64 %1182, i64* %3, align 8
  %1183 = inttoptr i64 %1181 to i32*
  store i32 %1179, i32* %1183, align 4
  %.pre532 = load i64, i64* %3, align 8
  br label %block_.L_4a4499

block_.L_4a4499:                                  ; preds = %block_.L_4a448d, %block_.L_4a444e
  %1184 = phi i64 [ %.pre532, %block_.L_4a448d ], [ %1128, %block_.L_4a444e ]
  %1185 = load i64, i64* %RBP.i, align 8
  %1186 = add i64 %1185, -1208
  %1187 = add i64 %1184, 6
  store i64 %1187, i64* %3, align 8
  %1188 = inttoptr i64 %1186 to i32*
  %1189 = load i32, i32* %1188, align 4
  %1190 = zext i32 %1189 to i64
  store i64 %1190, i64* %RAX.i1763, align 8
  %1191 = add i64 %1185, -532
  store i64 %1191, i64* %RDX.i1805, align 8
  %1192 = add i64 %1185, -536
  store i64 %1192, i64* %RCX.i1692, align 8
  %1193 = add i64 %1185, -540
  store i64 %1193, i64* %26, align 8
  %1194 = add i64 %1185, -552
  %1195 = add i64 %1184, 33
  store i64 %1195, i64* %3, align 8
  %1196 = inttoptr i64 %1194 to i32*
  store i32 %1189, i32* %1196, align 4
  %1197 = load i64, i64* %RBP.i, align 8
  %1198 = add i64 %1197, -32
  %1199 = load i64, i64* %3, align 8
  %1200 = add i64 %1199, 4
  store i64 %1200, i64* %3, align 8
  %1201 = inttoptr i64 %1198 to i64*
  %1202 = load i64, i64* %1201, align 8
  store i64 %1202, i64* %RSI.i1889, align 8
  %1203 = add i64 %1199, 10
  store i64 %1203, i64* %3, align 8
  %1204 = inttoptr i64 %1202 to i32*
  store i32 2147483647, i32* %1204, align 4
  %1205 = load i64, i64* %RBP.i, align 8
  %1206 = add i64 %1205, -492
  %1207 = load i64, i64* %3, align 8
  %1208 = add i64 %1207, 6
  store i64 %1208, i64* %3, align 8
  %1209 = inttoptr i64 %1206 to i32*
  %1210 = load i32, i32* %1209, align 4
  %1211 = zext i32 %1210 to i64
  store i64 %1211, i64* %RDI.i2141, align 8
  %1212 = add i64 %1205, -496
  %1213 = add i64 %1207, 12
  store i64 %1213, i64* %3, align 8
  %1214 = inttoptr i64 %1212 to i32*
  %1215 = load i32, i32* %1214, align 4
  %1216 = zext i32 %1215 to i64
  store i64 %1216, i64* %RSI.i1889, align 8
  %1217 = add i64 %1207, 12732
  %1218 = add i64 %1207, 17
  %1219 = load i64, i64* %6, align 8
  %1220 = add i64 %1219, -8
  %1221 = inttoptr i64 %1220 to i64*
  store i64 %1218, i64* %1221, align 8
  store i64 %1220, i64* %6, align 8
  store i64 %1217, i64* %3, align 8
  %call2_4a44d0 = tail call %struct.Memory* @sub_4a7680.intrapred_luma8x8(%struct.State* nonnull %0, i64 %1217, %struct.Memory* %974)
  %1222 = load i64, i64* %RBP.i, align 8
  %1223 = add i64 %1222, -36
  %1224 = load i64, i64* %3, align 8
  %1225 = add i64 %1224, 7
  store i64 %1225, i64* %3, align 8
  %1226 = inttoptr i64 %1223 to i32*
  store i32 0, i32* %1226, align 4
  %R9D.i6640 = bitcast %union.anon* %27 to i32*
  %AL.i6276 = bitcast %union.anon* %30 to i8*
  %1227 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1228 = bitcast i64* %1227 to double*
  %DX.i5417 = bitcast %union.anon* %40 to i16*
  %CX.i4894 = bitcast %union.anon* %24 to i16*
  %1229 = bitcast %union.VectorReg* %41 to double*
  %1230 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576) to i32), i32 255))
  %1231 = trunc i32 %1230 to i8
  %1232 = and i8 %1231, 1
  %1233 = xor i8 %1232, 1
  %DI.i3531 = bitcast %union.anon* %43 to i16*
  %.pre533 = load i64, i64* %3, align 8
  br label %block_.L_4a44dc

block_.L_4a44dc:                                  ; preds = %block_.L_4a5f0c, %block_.L_4a4499
  %1234 = phi i64 [ %.pre533, %block_.L_4a4499 ], [ %13489, %block_.L_4a5f0c ]
  %MEMORY.12 = phi %struct.Memory* [ %call2_4a44d0, %block_.L_4a4499 ], [ %MEMORY.72, %block_.L_4a5f0c ]
  %1235 = load i64, i64* %RBP.i, align 8
  %1236 = add i64 %1235, -36
  %1237 = add i64 %1234, 4
  store i64 %1237, i64* %3, align 8
  %1238 = inttoptr i64 %1236 to i32*
  %1239 = load i32, i32* %1238, align 4
  %1240 = add i32 %1239, -9
  %1241 = icmp ult i32 %1239, 9
  %1242 = zext i1 %1241 to i8
  store i8 %1242, i8* %18, align 1
  %1243 = and i32 %1240, 255
  %1244 = tail call i32 @llvm.ctpop.i32(i32 %1243)
  %1245 = trunc i32 %1244 to i8
  %1246 = and i8 %1245, 1
  %1247 = xor i8 %1246, 1
  store i8 %1247, i8* %19, align 1
  %1248 = xor i32 %1240, %1239
  %1249 = lshr i32 %1248, 4
  %1250 = trunc i32 %1249 to i8
  %1251 = and i8 %1250, 1
  store i8 %1251, i8* %20, align 1
  %1252 = icmp eq i32 %1240, 0
  %1253 = zext i1 %1252 to i8
  store i8 %1253, i8* %21, align 1
  %1254 = lshr i32 %1240, 31
  %1255 = trunc i32 %1254 to i8
  store i8 %1255, i8* %22, align 1
  %1256 = lshr i32 %1239, 31
  %1257 = xor i32 %1254, %1256
  %1258 = add nuw nsw i32 %1257, %1256
  %1259 = icmp eq i32 %1258, 2
  %1260 = zext i1 %1259 to i8
  store i8 %1260, i8* %23, align 1
  %1261 = icmp ne i8 %1255, 0
  %1262 = xor i1 %1261, %1259
  %.v815 = select i1 %1262, i64 10, i64 6723
  %1263 = add i64 %1234, %.v815
  store i64 %1263, i64* %3, align 8
  br i1 %1262, label %block_4a44e6, label %block_.L_4a5f1f

block_4a44e6:                                     ; preds = %block_.L_4a44dc
  %1264 = add i64 %1263, 4
  store i64 %1264, i64* %3, align 8
  %1265 = load i32, i32* %1238, align 4
  %1266 = add i32 %1265, -2
  %1267 = icmp ult i32 %1265, 2
  %1268 = zext i1 %1267 to i8
  store i8 %1268, i8* %18, align 1
  %1269 = and i32 %1266, 255
  %1270 = tail call i32 @llvm.ctpop.i32(i32 %1269)
  %1271 = trunc i32 %1270 to i8
  %1272 = and i8 %1271, 1
  %1273 = xor i8 %1272, 1
  store i8 %1273, i8* %19, align 1
  %1274 = xor i32 %1266, %1265
  %1275 = lshr i32 %1274, 4
  %1276 = trunc i32 %1275 to i8
  %1277 = and i8 %1276, 1
  store i8 %1277, i8* %20, align 1
  %1278 = icmp eq i32 %1266, 0
  %1279 = zext i1 %1278 to i8
  store i8 %1279, i8* %21, align 1
  %1280 = lshr i32 %1266, 31
  %1281 = trunc i32 %1280 to i8
  store i8 %1281, i8* %22, align 1
  %1282 = lshr i32 %1265, 31
  %1283 = xor i32 %1280, %1282
  %1284 = add nuw nsw i32 %1283, %1282
  %1285 = icmp eq i32 %1284, 2
  %1286 = zext i1 %1285 to i8
  store i8 %1286, i8* %23, align 1
  %.v838 = select i1 %1278, i64 99, i64 10
  %1287 = add i64 %1263, %.v838
  store i64 %1287, i64* %3, align 8
  br i1 %1278, label %block_.L_4a4549, label %block_4a44f0

block_4a44f0:                                     ; preds = %block_4a44e6
  %1288 = add i64 %1287, 4
  store i64 %1288, i64* %3, align 8
  %1289 = load i32, i32* %1238, align 4
  store i8 0, i8* %18, align 1
  %1290 = and i32 %1289, 255
  %1291 = tail call i32 @llvm.ctpop.i32(i32 %1290)
  %1292 = trunc i32 %1291 to i8
  %1293 = and i8 %1292, 1
  %1294 = xor i8 %1293, 1
  store i8 %1294, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %1295 = icmp eq i32 %1289, 0
  %1296 = zext i1 %1295 to i8
  store i8 %1296, i8* %21, align 1
  %1297 = lshr i32 %1289, 31
  %1298 = trunc i32 %1297 to i8
  store i8 %1298, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v839 = select i1 %1295, i64 30, i64 10
  %1299 = add i64 %1287, %.v839
  store i64 %1299, i64* %3, align 8
  br i1 %1295, label %block_.L_4a450e, label %block_4a44fa

block_4a44fa:                                     ; preds = %block_4a44f0
  %1300 = add i64 %1299, 4
  store i64 %1300, i64* %3, align 8
  %1301 = load i32, i32* %1238, align 4
  %1302 = add i32 %1301, -7
  %1303 = icmp ult i32 %1301, 7
  %1304 = zext i1 %1303 to i8
  store i8 %1304, i8* %18, align 1
  %1305 = and i32 %1302, 255
  %1306 = tail call i32 @llvm.ctpop.i32(i32 %1305)
  %1307 = trunc i32 %1306 to i8
  %1308 = and i8 %1307, 1
  %1309 = xor i8 %1308, 1
  store i8 %1309, i8* %19, align 1
  %1310 = xor i32 %1302, %1301
  %1311 = lshr i32 %1310, 4
  %1312 = trunc i32 %1311 to i8
  %1313 = and i8 %1312, 1
  store i8 %1313, i8* %20, align 1
  %1314 = icmp eq i32 %1302, 0
  %1315 = zext i1 %1314 to i8
  store i8 %1315, i8* %21, align 1
  %1316 = lshr i32 %1302, 31
  %1317 = trunc i32 %1316 to i8
  store i8 %1317, i8* %22, align 1
  %1318 = lshr i32 %1301, 31
  %1319 = xor i32 %1316, %1318
  %1320 = add nuw nsw i32 %1319, %1318
  %1321 = icmp eq i32 %1320, 2
  %1322 = zext i1 %1321 to i8
  store i8 %1322, i8* %23, align 1
  %.v840 = select i1 %1314, i64 20, i64 10
  %1323 = add i64 %1299, %.v840
  store i64 %1323, i64* %3, align 8
  br i1 %1314, label %block_.L_4a450e, label %block_4a4504

block_4a4504:                                     ; preds = %block_4a44fa
  %1324 = add i64 %1323, 4
  store i64 %1324, i64* %3, align 8
  %1325 = load i32, i32* %1238, align 4
  %1326 = add i32 %1325, -3
  %1327 = icmp ult i32 %1325, 3
  %1328 = zext i1 %1327 to i8
  store i8 %1328, i8* %18, align 1
  %1329 = and i32 %1326, 255
  %1330 = tail call i32 @llvm.ctpop.i32(i32 %1329)
  %1331 = trunc i32 %1330 to i8
  %1332 = and i8 %1331, 1
  %1333 = xor i8 %1332, 1
  store i8 %1333, i8* %19, align 1
  %1334 = xor i32 %1326, %1325
  %1335 = lshr i32 %1334, 4
  %1336 = trunc i32 %1335 to i8
  %1337 = and i8 %1336, 1
  store i8 %1337, i8* %20, align 1
  %1338 = icmp eq i32 %1326, 0
  %1339 = zext i1 %1338 to i8
  store i8 %1339, i8* %21, align 1
  %1340 = lshr i32 %1326, 31
  %1341 = trunc i32 %1340 to i8
  store i8 %1341, i8* %22, align 1
  %1342 = lshr i32 %1325, 31
  %1343 = xor i32 %1340, %1342
  %1344 = add nuw nsw i32 %1343, %1342
  %1345 = icmp eq i32 %1344, 2
  %1346 = zext i1 %1345 to i8
  store i8 %1346, i8* %23, align 1
  %.v841 = select i1 %1338, i64 10, i64 23
  %1347 = add i64 %1323, %.v841
  store i64 %1347, i64* %3, align 8
  br i1 %1338, label %block_.L_4a450e, label %block_.L_4a451b

block_.L_4a450e:                                  ; preds = %block_4a4504, %block_4a44fa, %block_4a44f0
  %1348 = phi i64 [ %1347, %block_4a4504 ], [ %1323, %block_4a44fa ], [ %1299, %block_4a44f0 ]
  %1349 = add i64 %1235, -536
  %1350 = add i64 %1348, 7
  store i64 %1350, i64* %3, align 8
  %1351 = inttoptr i64 %1349 to i32*
  %1352 = load i32, i32* %1351, align 4
  store i8 0, i8* %18, align 1
  %1353 = and i32 %1352, 255
  %1354 = tail call i32 @llvm.ctpop.i32(i32 %1353)
  %1355 = trunc i32 %1354 to i8
  %1356 = and i8 %1355, 1
  %1357 = xor i8 %1356, 1
  store i8 %1357, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %1358 = icmp eq i32 %1352, 0
  %1359 = zext i1 %1358 to i8
  store i8 %1359, i8* %21, align 1
  %1360 = lshr i32 %1352, 31
  %1361 = trunc i32 %1360 to i8
  store i8 %1361, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v871 = select i1 %1358, i64 13, i64 59
  %1362 = add i64 %1348, %.v871
  store i64 %1362, i64* %3, align 8
  br i1 %1358, label %block_.L_4a451b, label %block_.L_4a4549

block_.L_4a451b:                                  ; preds = %block_.L_4a450e, %block_4a4504
  %1363 = phi i64 [ %1362, %block_.L_4a450e ], [ %1347, %block_4a4504 ]
  %1364 = add i64 %1363, 4
  store i64 %1364, i64* %3, align 8
  %1365 = load i32, i32* %1238, align 4
  %1366 = add i32 %1365, -1
  %1367 = icmp eq i32 %1365, 0
  %1368 = zext i1 %1367 to i8
  store i8 %1368, i8* %18, align 1
  %1369 = and i32 %1366, 255
  %1370 = tail call i32 @llvm.ctpop.i32(i32 %1369)
  %1371 = trunc i32 %1370 to i8
  %1372 = and i8 %1371, 1
  %1373 = xor i8 %1372, 1
  store i8 %1373, i8* %19, align 1
  %1374 = xor i32 %1366, %1365
  %1375 = lshr i32 %1374, 4
  %1376 = trunc i32 %1375 to i8
  %1377 = and i8 %1376, 1
  store i8 %1377, i8* %20, align 1
  %1378 = icmp eq i32 %1366, 0
  %1379 = zext i1 %1378 to i8
  store i8 %1379, i8* %21, align 1
  %1380 = lshr i32 %1366, 31
  %1381 = trunc i32 %1380 to i8
  store i8 %1381, i8* %22, align 1
  %1382 = lshr i32 %1365, 31
  %1383 = xor i32 %1380, %1382
  %1384 = add nuw nsw i32 %1383, %1382
  %1385 = icmp eq i32 %1384, 2
  %1386 = zext i1 %1385 to i8
  store i8 %1386, i8* %23, align 1
  %.v842 = select i1 %1378, i64 20, i64 10
  %1387 = add i64 %1363, %.v842
  store i64 %1387, i64* %3, align 8
  br i1 %1378, label %block_.L_4a452f, label %block_4a4525

block_4a4525:                                     ; preds = %block_.L_4a451b
  %1388 = add i64 %1387, 4
  store i64 %1388, i64* %3, align 8
  %1389 = load i32, i32* %1238, align 4
  %1390 = add i32 %1389, -8
  %1391 = icmp ult i32 %1389, 8
  %1392 = zext i1 %1391 to i8
  store i8 %1392, i8* %18, align 1
  %1393 = and i32 %1390, 255
  %1394 = tail call i32 @llvm.ctpop.i32(i32 %1393)
  %1395 = trunc i32 %1394 to i8
  %1396 = and i8 %1395, 1
  %1397 = xor i8 %1396, 1
  store i8 %1397, i8* %19, align 1
  %1398 = xor i32 %1390, %1389
  %1399 = lshr i32 %1398, 4
  %1400 = trunc i32 %1399 to i8
  %1401 = and i8 %1400, 1
  store i8 %1401, i8* %20, align 1
  %1402 = icmp eq i32 %1390, 0
  %1403 = zext i1 %1402 to i8
  store i8 %1403, i8* %21, align 1
  %1404 = lshr i32 %1390, 31
  %1405 = trunc i32 %1404 to i8
  store i8 %1405, i8* %22, align 1
  %1406 = lshr i32 %1389, 31
  %1407 = xor i32 %1404, %1406
  %1408 = add nuw nsw i32 %1407, %1406
  %1409 = icmp eq i32 %1408, 2
  %1410 = zext i1 %1409 to i8
  store i8 %1410, i8* %23, align 1
  %.v843 = select i1 %1402, i64 10, i64 23
  %1411 = add i64 %1387, %.v843
  store i64 %1411, i64* %3, align 8
  br i1 %1402, label %block_.L_4a452f, label %block_.L_4a453c

block_.L_4a452f:                                  ; preds = %block_4a4525, %block_.L_4a451b
  %1412 = phi i64 [ %1411, %block_4a4525 ], [ %1387, %block_.L_4a451b ]
  %1413 = add i64 %1235, -532
  %1414 = add i64 %1412, 7
  store i64 %1414, i64* %3, align 8
  %1415 = inttoptr i64 %1413 to i32*
  %1416 = load i32, i32* %1415, align 4
  store i8 0, i8* %18, align 1
  %1417 = and i32 %1416, 255
  %1418 = tail call i32 @llvm.ctpop.i32(i32 %1417)
  %1419 = trunc i32 %1418 to i8
  %1420 = and i8 %1419, 1
  %1421 = xor i8 %1420, 1
  store i8 %1421, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %1422 = icmp eq i32 %1416, 0
  %1423 = zext i1 %1422 to i8
  store i8 %1423, i8* %21, align 1
  %1424 = lshr i32 %1416, 31
  %1425 = trunc i32 %1424 to i8
  store i8 %1425, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v870 = select i1 %1422, i64 13, i64 26
  %1426 = add i64 %1412, %.v870
  store i64 %1426, i64* %3, align 8
  br i1 %1422, label %block_.L_4a453c, label %block_.L_4a4549

block_.L_4a453c:                                  ; preds = %block_.L_4a452f, %block_4a4525
  %1427 = phi i64 [ %1426, %block_.L_4a452f ], [ %1411, %block_4a4525 ]
  %1428 = add i64 %1235, -540
  %1429 = add i64 %1427, 7
  store i64 %1429, i64* %3, align 8
  %1430 = inttoptr i64 %1428 to i32*
  %1431 = load i32, i32* %1430, align 4
  store i8 0, i8* %18, align 1
  %1432 = and i32 %1431, 255
  %1433 = tail call i32 @llvm.ctpop.i32(i32 %1432)
  %1434 = trunc i32 %1433 to i8
  %1435 = and i8 %1434, 1
  %1436 = xor i8 %1435, 1
  store i8 %1436, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %1437 = icmp eq i32 %1431, 0
  %1438 = zext i1 %1437 to i8
  store i8 %1438, i8* %21, align 1
  %1439 = lshr i32 %1431, 31
  %1440 = trunc i32 %1439 to i8
  store i8 %1440, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v844 = select i1 %1437, i64 6608, i64 13
  %1441 = add i64 %1427, %.v844
  store i64 %1441, i64* %3, align 8
  br i1 %1437, label %block_.L_4a5f0c, label %block_.L_4a4549

block_.L_4a4549:                                  ; preds = %block_.L_4a452f, %block_.L_4a450e, %block_.L_4a453c, %block_4a44e6
  %1442 = phi i64 [ %1441, %block_.L_4a453c ], [ %1426, %block_.L_4a452f ], [ %1362, %block_.L_4a450e ], [ %1287, %block_4a44e6 ]
  %1443 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %1443, i64* %RAX.i1763, align 8
  %1444 = add i64 %1443, 2464
  %1445 = add i64 %1442, 15
  store i64 %1445, i64* %3, align 8
  %1446 = inttoptr i64 %1444 to i32*
  %1447 = load i32, i32* %1446, align 4
  store i8 0, i8* %18, align 1
  %1448 = and i32 %1447, 255
  %1449 = tail call i32 @llvm.ctpop.i32(i32 %1448)
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  %1452 = xor i8 %1451, 1
  store i8 %1452, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %1453 = icmp eq i32 %1447, 0
  %1454 = zext i1 %1453 to i8
  store i8 %1454, i8* %21, align 1
  %1455 = lshr i32 %1447, 31
  %1456 = trunc i32 %1455 to i8
  store i8 %1456, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v787 = select i1 %1453, i64 21, i64 329
  %1457 = add i64 %1442, %.v787
  store i64 %1457, i64* %3, align 8
  br i1 %1453, label %block_4a455e, label %block_.L_4a4692

block_4a455e:                                     ; preds = %block_.L_4a4549
  %1458 = add i64 %1235, -48
  %1459 = add i64 %1457, 7
  store i64 %1459, i64* %3, align 8
  %1460 = inttoptr i64 %1458 to i32*
  store i32 0, i32* %1460, align 4
  %1461 = load i64, i64* %RBP.i, align 8
  %1462 = add i64 %1461, -52
  %1463 = load i64, i64* %3, align 8
  %1464 = add i64 %1463, 7
  store i64 %1464, i64* %3, align 8
  %1465 = inttoptr i64 %1462 to i32*
  store i32 0, i32* %1465, align 4
  %.pre654 = load i64, i64* %3, align 8
  br label %block_.L_4a456c

block_.L_4a456c:                                  ; preds = %block_.L_4a45fe, %block_4a455e
  %1466 = phi i64 [ %1847, %block_.L_4a45fe ], [ %.pre654, %block_4a455e ]
  %1467 = load i64, i64* %RBP.i, align 8
  %1468 = add i64 %1467, -48
  %1469 = add i64 %1466, 4
  store i64 %1469, i64* %3, align 8
  %1470 = inttoptr i64 %1468 to i32*
  %1471 = load i32, i32* %1470, align 4
  %1472 = add i32 %1471, -8
  %1473 = icmp ult i32 %1471, 8
  %1474 = zext i1 %1473 to i8
  store i8 %1474, i8* %18, align 1
  %1475 = and i32 %1472, 255
  %1476 = tail call i32 @llvm.ctpop.i32(i32 %1475)
  %1477 = trunc i32 %1476 to i8
  %1478 = and i8 %1477, 1
  %1479 = xor i8 %1478, 1
  store i8 %1479, i8* %19, align 1
  %1480 = xor i32 %1472, %1471
  %1481 = lshr i32 %1480, 4
  %1482 = trunc i32 %1481 to i8
  %1483 = and i8 %1482, 1
  store i8 %1483, i8* %20, align 1
  %1484 = icmp eq i32 %1472, 0
  %1485 = zext i1 %1484 to i8
  store i8 %1485, i8* %21, align 1
  %1486 = lshr i32 %1472, 31
  %1487 = trunc i32 %1486 to i8
  store i8 %1487, i8* %22, align 1
  %1488 = lshr i32 %1471, 31
  %1489 = xor i32 %1486, %1488
  %1490 = add nuw nsw i32 %1489, %1488
  %1491 = icmp eq i32 %1490, 2
  %1492 = zext i1 %1491 to i8
  store i8 %1492, i8* %23, align 1
  %1493 = icmp ne i8 %1487, 0
  %1494 = xor i1 %1493, %1491
  %.v867 = select i1 %1494, i64 10, i64 165
  %1495 = add i64 %1466, %.v867
  store i64 %1495, i64* %3, align 8
  br i1 %1494, label %block_4a4576, label %block_.L_4a4611

block_4a4576:                                     ; preds = %block_.L_4a456c
  %1496 = add i64 %1467, -44
  %1497 = add i64 %1495, 7
  store i64 %1497, i64* %3, align 8
  %1498 = inttoptr i64 %1496 to i32*
  store i32 0, i32* %1498, align 4
  %.pre657 = load i64, i64* %3, align 8
  br label %block_.L_4a457d

block_.L_4a457d:                                  ; preds = %block_4a4587, %block_4a4576
  %1499 = phi i64 [ %1817, %block_4a4587 ], [ %.pre657, %block_4a4576 ]
  %1500 = load i64, i64* %RBP.i, align 8
  %1501 = add i64 %1500, -44
  %1502 = add i64 %1499, 4
  store i64 %1502, i64* %3, align 8
  %1503 = inttoptr i64 %1501 to i32*
  %1504 = load i32, i32* %1503, align 4
  %1505 = add i32 %1504, -8
  %1506 = icmp ult i32 %1504, 8
  %1507 = zext i1 %1506 to i8
  store i8 %1507, i8* %18, align 1
  %1508 = and i32 %1505, 255
  %1509 = tail call i32 @llvm.ctpop.i32(i32 %1508)
  %1510 = trunc i32 %1509 to i8
  %1511 = and i8 %1510, 1
  %1512 = xor i8 %1511, 1
  store i8 %1512, i8* %19, align 1
  %1513 = xor i32 %1505, %1504
  %1514 = lshr i32 %1513, 4
  %1515 = trunc i32 %1514 to i8
  %1516 = and i8 %1515, 1
  store i8 %1516, i8* %20, align 1
  %1517 = icmp eq i32 %1505, 0
  %1518 = zext i1 %1517 to i8
  store i8 %1518, i8* %21, align 1
  %1519 = lshr i32 %1505, 31
  %1520 = trunc i32 %1519 to i8
  store i8 %1520, i8* %22, align 1
  %1521 = lshr i32 %1504, 31
  %1522 = xor i32 %1519, %1521
  %1523 = add nuw nsw i32 %1522, %1521
  %1524 = icmp eq i32 %1523, 2
  %1525 = zext i1 %1524 to i8
  store i8 %1525, i8* %23, align 1
  %1526 = icmp ne i8 %1520, 0
  %1527 = xor i1 %1526, %1524
  %.v785 = select i1 %1527, i64 10, i64 129
  %1528 = add i64 %1499, %.v785
  store i64 %1528, i64* %3, align 8
  br i1 %1527, label %block_4a4587, label %block_.L_4a45fe

block_4a4587:                                     ; preds = %block_.L_4a457d
  %1529 = add i64 %1500, -528
  %1530 = add i64 %1528, 7
  store i64 %1530, i64* %3, align 8
  %1531 = inttoptr i64 %1529 to i64*
  %1532 = load i64, i64* %1531, align 8
  store i64 %1532, i64* %RAX.i1763, align 8
  %1533 = add i64 %1500, -504
  %1534 = add i64 %1528, 13
  store i64 %1534, i64* %3, align 8
  %1535 = inttoptr i64 %1533 to i32*
  %1536 = load i32, i32* %1535, align 4
  %1537 = zext i32 %1536 to i64
  store i64 %1537, i64* %RCX.i1692, align 8
  %1538 = add i64 %1500, -48
  %1539 = add i64 %1528, 16
  store i64 %1539, i64* %3, align 8
  %1540 = inttoptr i64 %1538 to i32*
  %1541 = load i32, i32* %1540, align 4
  %1542 = add i32 %1541, %1536
  %1543 = zext i32 %1542 to i64
  store i64 %1543, i64* %RCX.i1692, align 8
  %1544 = icmp ult i32 %1542, %1536
  %1545 = icmp ult i32 %1542, %1541
  %1546 = or i1 %1544, %1545
  %1547 = zext i1 %1546 to i8
  store i8 %1547, i8* %18, align 1
  %1548 = and i32 %1542, 255
  %1549 = tail call i32 @llvm.ctpop.i32(i32 %1548)
  %1550 = trunc i32 %1549 to i8
  %1551 = and i8 %1550, 1
  %1552 = xor i8 %1551, 1
  store i8 %1552, i8* %19, align 1
  %1553 = xor i32 %1541, %1536
  %1554 = xor i32 %1553, %1542
  %1555 = lshr i32 %1554, 4
  %1556 = trunc i32 %1555 to i8
  %1557 = and i8 %1556, 1
  store i8 %1557, i8* %20, align 1
  %1558 = icmp eq i32 %1542, 0
  %1559 = zext i1 %1558 to i8
  store i8 %1559, i8* %21, align 1
  %1560 = lshr i32 %1542, 31
  %1561 = trunc i32 %1560 to i8
  store i8 %1561, i8* %22, align 1
  %1562 = lshr i32 %1536, 31
  %1563 = lshr i32 %1541, 31
  %1564 = xor i32 %1560, %1562
  %1565 = xor i32 %1560, %1563
  %1566 = add nuw nsw i32 %1564, %1565
  %1567 = icmp eq i32 %1566, 2
  %1568 = zext i1 %1567 to i8
  store i8 %1568, i8* %23, align 1
  %1569 = sext i32 %1542 to i64
  store i64 %1569, i64* %RDX.i1805, align 8
  %1570 = shl nsw i64 %1569, 3
  %1571 = add i64 %1532, %1570
  %1572 = add i64 %1528, 23
  store i64 %1572, i64* %3, align 8
  %1573 = inttoptr i64 %1571 to i64*
  %1574 = load i64, i64* %1573, align 8
  store i64 %1574, i64* %RAX.i1763, align 8
  %1575 = add i64 %1500, -500
  %1576 = add i64 %1528, 29
  store i64 %1576, i64* %3, align 8
  %1577 = inttoptr i64 %1575 to i32*
  %1578 = load i32, i32* %1577, align 4
  %1579 = zext i32 %1578 to i64
  store i64 %1579, i64* %RCX.i1692, align 8
  %1580 = add i64 %1528, 32
  store i64 %1580, i64* %3, align 8
  %1581 = load i32, i32* %1503, align 4
  %1582 = add i32 %1581, %1578
  %1583 = zext i32 %1582 to i64
  store i64 %1583, i64* %RCX.i1692, align 8
  %1584 = icmp ult i32 %1582, %1578
  %1585 = icmp ult i32 %1582, %1581
  %1586 = or i1 %1584, %1585
  %1587 = zext i1 %1586 to i8
  store i8 %1587, i8* %18, align 1
  %1588 = and i32 %1582, 255
  %1589 = tail call i32 @llvm.ctpop.i32(i32 %1588)
  %1590 = trunc i32 %1589 to i8
  %1591 = and i8 %1590, 1
  %1592 = xor i8 %1591, 1
  store i8 %1592, i8* %19, align 1
  %1593 = xor i32 %1581, %1578
  %1594 = xor i32 %1593, %1582
  %1595 = lshr i32 %1594, 4
  %1596 = trunc i32 %1595 to i8
  %1597 = and i8 %1596, 1
  store i8 %1597, i8* %20, align 1
  %1598 = icmp eq i32 %1582, 0
  %1599 = zext i1 %1598 to i8
  store i8 %1599, i8* %21, align 1
  %1600 = lshr i32 %1582, 31
  %1601 = trunc i32 %1600 to i8
  store i8 %1601, i8* %22, align 1
  %1602 = lshr i32 %1578, 31
  %1603 = lshr i32 %1581, 31
  %1604 = xor i32 %1600, %1602
  %1605 = xor i32 %1600, %1603
  %1606 = add nuw nsw i32 %1604, %1605
  %1607 = icmp eq i32 %1606, 2
  %1608 = zext i1 %1607 to i8
  store i8 %1608, i8* %23, align 1
  %1609 = sext i32 %1582 to i64
  store i64 %1609, i64* %RDX.i1805, align 8
  %1610 = shl nsw i64 %1609, 1
  %1611 = add i64 %1574, %1610
  %1612 = add i64 %1528, 39
  store i64 %1612, i64* %3, align 8
  %1613 = inttoptr i64 %1611 to i16*
  %1614 = load i16, i16* %1613, align 2
  %1615 = zext i16 %1614 to i64
  store i64 %1615, i64* %RCX.i1692, align 8
  %1616 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %1617 = add i64 %1616, 7352
  store i64 %1617, i64* %RAX.i1763, align 8
  %1618 = icmp ugt i64 %1616, -7353
  %1619 = zext i1 %1618 to i8
  store i8 %1619, i8* %18, align 1
  %1620 = trunc i64 %1617 to i32
  %1621 = and i32 %1620, 255
  %1622 = tail call i32 @llvm.ctpop.i32(i32 %1621)
  %1623 = trunc i32 %1622 to i8
  %1624 = and i8 %1623, 1
  %1625 = xor i8 %1624, 1
  store i8 %1625, i8* %19, align 1
  %1626 = xor i64 %1616, 16
  %1627 = xor i64 %1626, %1617
  %1628 = lshr i64 %1627, 4
  %1629 = trunc i64 %1628 to i8
  %1630 = and i8 %1629, 1
  store i8 %1630, i8* %20, align 1
  %1631 = icmp eq i64 %1617, 0
  %1632 = zext i1 %1631 to i8
  store i8 %1632, i8* %21, align 1
  %1633 = lshr i64 %1617, 63
  %1634 = trunc i64 %1633 to i8
  store i8 %1634, i8* %22, align 1
  %1635 = lshr i64 %1616, 63
  %1636 = xor i64 %1633, %1635
  %1637 = add nuw nsw i64 %1636, %1633
  %1638 = icmp eq i64 %1637, 2
  %1639 = zext i1 %1638 to i8
  store i8 %1639, i8* %23, align 1
  %1640 = load i64, i64* %RBP.i, align 8
  %1641 = add i64 %1640, -36
  %1642 = add i64 %1528, 57
  store i64 %1642, i64* %3, align 8
  %1643 = inttoptr i64 %1641 to i32*
  %1644 = load i32, i32* %1643, align 4
  %1645 = sext i32 %1644 to i64
  %1646 = shl nsw i64 %1645, 7
  store i64 %1646, i64* %RDX.i1805, align 8
  %1647 = add i64 %1646, %1617
  store i64 %1647, i64* %RAX.i1763, align 8
  %1648 = icmp ult i64 %1647, %1617
  %1649 = icmp ult i64 %1647, %1646
  %1650 = or i1 %1648, %1649
  %1651 = zext i1 %1650 to i8
  store i8 %1651, i8* %18, align 1
  %1652 = trunc i64 %1647 to i32
  %1653 = and i32 %1652, 255
  %1654 = tail call i32 @llvm.ctpop.i32(i32 %1653)
  %1655 = trunc i32 %1654 to i8
  %1656 = and i8 %1655, 1
  %1657 = xor i8 %1656, 1
  store i8 %1657, i8* %19, align 1
  %1658 = xor i64 %1617, %1647
  %1659 = lshr i64 %1658, 4
  %1660 = trunc i64 %1659 to i8
  %1661 = and i8 %1660, 1
  store i8 %1661, i8* %20, align 1
  %1662 = icmp eq i64 %1647, 0
  %1663 = zext i1 %1662 to i8
  store i8 %1663, i8* %21, align 1
  %1664 = lshr i64 %1647, 63
  %1665 = trunc i64 %1664 to i8
  store i8 %1665, i8* %22, align 1
  %1666 = lshr i64 %1645, 56
  %1667 = and i64 %1666, 1
  %1668 = xor i64 %1664, %1633
  %1669 = xor i64 %1664, %1667
  %1670 = add nuw nsw i64 %1668, %1669
  %1671 = icmp eq i64 %1670, 2
  %1672 = zext i1 %1671 to i8
  store i8 %1672, i8* %23, align 1
  %1673 = add i64 %1640, -48
  %1674 = add i64 %1528, 68
  store i64 %1674, i64* %3, align 8
  %1675 = inttoptr i64 %1673 to i32*
  %1676 = load i32, i32* %1675, align 4
  %1677 = sext i32 %1676 to i64
  %1678 = shl nsw i64 %1677, 4
  store i64 %1678, i64* %RDX.i1805, align 8
  %1679 = add i64 %1678, %1647
  store i64 %1679, i64* %RAX.i1763, align 8
  %1680 = icmp ult i64 %1679, %1647
  %1681 = icmp ult i64 %1679, %1678
  %1682 = or i1 %1680, %1681
  %1683 = zext i1 %1682 to i8
  store i8 %1683, i8* %18, align 1
  %1684 = trunc i64 %1679 to i32
  %1685 = and i32 %1684, 255
  %1686 = tail call i32 @llvm.ctpop.i32(i32 %1685)
  %1687 = trunc i32 %1686 to i8
  %1688 = and i8 %1687, 1
  %1689 = xor i8 %1688, 1
  store i8 %1689, i8* %19, align 1
  %1690 = xor i64 %1678, %1647
  %1691 = xor i64 %1690, %1679
  %1692 = lshr i64 %1691, 4
  %1693 = trunc i64 %1692 to i8
  %1694 = and i8 %1693, 1
  store i8 %1694, i8* %20, align 1
  %1695 = icmp eq i64 %1679, 0
  %1696 = zext i1 %1695 to i8
  store i8 %1696, i8* %21, align 1
  %1697 = lshr i64 %1679, 63
  %1698 = trunc i64 %1697 to i8
  store i8 %1698, i8* %22, align 1
  %1699 = lshr i64 %1677, 59
  %1700 = and i64 %1699, 1
  %1701 = xor i64 %1697, %1664
  %1702 = xor i64 %1697, %1700
  %1703 = add nuw nsw i64 %1701, %1702
  %1704 = icmp eq i64 %1703, 2
  %1705 = zext i1 %1704 to i8
  store i8 %1705, i8* %23, align 1
  %1706 = load i64, i64* %RBP.i, align 8
  %1707 = add i64 %1706, -44
  %1708 = add i64 %1528, 79
  store i64 %1708, i64* %3, align 8
  %1709 = inttoptr i64 %1707 to i32*
  %1710 = load i32, i32* %1709, align 4
  %1711 = sext i32 %1710 to i64
  store i64 %1711, i64* %RDX.i1805, align 8
  %1712 = shl nsw i64 %1711, 1
  %1713 = add i64 %1712, %1679
  %1714 = add i64 %1528, 83
  store i64 %1714, i64* %3, align 8
  %1715 = inttoptr i64 %1713 to i16*
  %1716 = load i16, i16* %1715, align 2
  %1717 = zext i16 %1716 to i64
  store i64 %1717, i64* %RSI.i1889, align 8
  %1718 = load i64, i64* %RCX.i1692, align 8
  %1719 = zext i16 %1716 to i32
  %1720 = zext i16 %1716 to i64
  %1721 = trunc i64 %1718 to i32
  %1722 = sub i32 %1721, %1719
  %1723 = zext i32 %1722 to i64
  store i64 %1723, i64* %RCX.i1692, align 8
  %1724 = icmp ult i32 %1721, %1719
  %1725 = zext i1 %1724 to i8
  store i8 %1725, i8* %18, align 1
  %1726 = and i32 %1722, 255
  %1727 = tail call i32 @llvm.ctpop.i32(i32 %1726)
  %1728 = trunc i32 %1727 to i8
  %1729 = and i8 %1728, 1
  %1730 = xor i8 %1729, 1
  store i8 %1730, i8* %19, align 1
  %1731 = xor i64 %1720, %1718
  %1732 = trunc i64 %1731 to i32
  %1733 = xor i32 %1732, %1722
  %1734 = lshr i32 %1733, 4
  %1735 = trunc i32 %1734 to i8
  %1736 = and i8 %1735, 1
  store i8 %1736, i8* %20, align 1
  %1737 = icmp eq i32 %1722, 0
  %1738 = zext i1 %1737 to i8
  store i8 %1738, i8* %21, align 1
  %1739 = lshr i32 %1722, 31
  %1740 = trunc i32 %1739 to i8
  store i8 %1740, i8* %22, align 1
  %1741 = lshr i32 %1721, 31
  %1742 = xor i32 %1739, %1741
  %1743 = add nuw nsw i32 %1742, %1741
  %1744 = icmp eq i32 %1743, 2
  %1745 = zext i1 %1744 to i8
  store i8 %1745, i8* %23, align 1
  %1746 = add i64 %1706, -52
  %1747 = add i64 %1528, 89
  store i64 %1747, i64* %3, align 8
  %1748 = inttoptr i64 %1746 to i32*
  %1749 = load i32, i32* %1748, align 4
  %1750 = sext i32 %1749 to i64
  store i64 %1750, i64* %RAX.i1763, align 8
  %1751 = shl nsw i64 %1750, 2
  %1752 = add i64 %1706, -336
  %1753 = add i64 %1752, %1751
  %1754 = add i64 %1528, 96
  store i64 %1754, i64* %3, align 8
  %1755 = inttoptr i64 %1753 to i32*
  store i32 %1722, i32* %1755, align 4
  %1756 = load i64, i64* %RBP.i, align 8
  %1757 = add i64 %1756, -44
  %1758 = load i64, i64* %3, align 8
  %1759 = add i64 %1758, 3
  store i64 %1759, i64* %3, align 8
  %1760 = inttoptr i64 %1757 to i32*
  %1761 = load i32, i32* %1760, align 4
  %1762 = add i32 %1761, 1
  %1763 = zext i32 %1762 to i64
  store i64 %1763, i64* %RAX.i1763, align 8
  %1764 = icmp eq i32 %1761, -1
  %1765 = icmp eq i32 %1762, 0
  %1766 = or i1 %1764, %1765
  %1767 = zext i1 %1766 to i8
  store i8 %1767, i8* %18, align 1
  %1768 = and i32 %1762, 255
  %1769 = tail call i32 @llvm.ctpop.i32(i32 %1768)
  %1770 = trunc i32 %1769 to i8
  %1771 = and i8 %1770, 1
  %1772 = xor i8 %1771, 1
  store i8 %1772, i8* %19, align 1
  %1773 = xor i32 %1762, %1761
  %1774 = lshr i32 %1773, 4
  %1775 = trunc i32 %1774 to i8
  %1776 = and i8 %1775, 1
  store i8 %1776, i8* %20, align 1
  %1777 = zext i1 %1765 to i8
  store i8 %1777, i8* %21, align 1
  %1778 = lshr i32 %1762, 31
  %1779 = trunc i32 %1778 to i8
  store i8 %1779, i8* %22, align 1
  %1780 = lshr i32 %1761, 31
  %1781 = xor i32 %1778, %1780
  %1782 = add nuw nsw i32 %1781, %1778
  %1783 = icmp eq i32 %1782, 2
  %1784 = zext i1 %1783 to i8
  store i8 %1784, i8* %23, align 1
  %1785 = add i64 %1758, 9
  store i64 %1785, i64* %3, align 8
  store i32 %1762, i32* %1760, align 4
  %1786 = load i64, i64* %RBP.i, align 8
  %1787 = add i64 %1786, -52
  %1788 = load i64, i64* %3, align 8
  %1789 = add i64 %1788, 3
  store i64 %1789, i64* %3, align 8
  %1790 = inttoptr i64 %1787 to i32*
  %1791 = load i32, i32* %1790, align 4
  %1792 = add i32 %1791, 1
  %1793 = zext i32 %1792 to i64
  store i64 %1793, i64* %RAX.i1763, align 8
  %1794 = icmp eq i32 %1791, -1
  %1795 = icmp eq i32 %1792, 0
  %1796 = or i1 %1794, %1795
  %1797 = zext i1 %1796 to i8
  store i8 %1797, i8* %18, align 1
  %1798 = and i32 %1792, 255
  %1799 = tail call i32 @llvm.ctpop.i32(i32 %1798)
  %1800 = trunc i32 %1799 to i8
  %1801 = and i8 %1800, 1
  %1802 = xor i8 %1801, 1
  store i8 %1802, i8* %19, align 1
  %1803 = xor i32 %1792, %1791
  %1804 = lshr i32 %1803, 4
  %1805 = trunc i32 %1804 to i8
  %1806 = and i8 %1805, 1
  store i8 %1806, i8* %20, align 1
  %1807 = zext i1 %1795 to i8
  store i8 %1807, i8* %21, align 1
  %1808 = lshr i32 %1792, 31
  %1809 = trunc i32 %1808 to i8
  store i8 %1809, i8* %22, align 1
  %1810 = lshr i32 %1791, 31
  %1811 = xor i32 %1808, %1810
  %1812 = add nuw nsw i32 %1811, %1808
  %1813 = icmp eq i32 %1812, 2
  %1814 = zext i1 %1813 to i8
  store i8 %1814, i8* %23, align 1
  %1815 = add i64 %1788, 9
  store i64 %1815, i64* %3, align 8
  store i32 %1792, i32* %1790, align 4
  %1816 = load i64, i64* %3, align 8
  %1817 = add i64 %1816, -124
  store i64 %1817, i64* %3, align 8
  br label %block_.L_4a457d

block_.L_4a45fe:                                  ; preds = %block_.L_4a457d
  %1818 = add i64 %1500, -48
  %1819 = add i64 %1528, 8
  store i64 %1819, i64* %3, align 8
  %1820 = inttoptr i64 %1818 to i32*
  %1821 = load i32, i32* %1820, align 4
  %1822 = add i32 %1821, 1
  %1823 = zext i32 %1822 to i64
  store i64 %1823, i64* %RAX.i1763, align 8
  %1824 = icmp eq i32 %1821, -1
  %1825 = icmp eq i32 %1822, 0
  %1826 = or i1 %1824, %1825
  %1827 = zext i1 %1826 to i8
  store i8 %1827, i8* %18, align 1
  %1828 = and i32 %1822, 255
  %1829 = tail call i32 @llvm.ctpop.i32(i32 %1828)
  %1830 = trunc i32 %1829 to i8
  %1831 = and i8 %1830, 1
  %1832 = xor i8 %1831, 1
  store i8 %1832, i8* %19, align 1
  %1833 = xor i32 %1822, %1821
  %1834 = lshr i32 %1833, 4
  %1835 = trunc i32 %1834 to i8
  %1836 = and i8 %1835, 1
  store i8 %1836, i8* %20, align 1
  %1837 = zext i1 %1825 to i8
  store i8 %1837, i8* %21, align 1
  %1838 = lshr i32 %1822, 31
  %1839 = trunc i32 %1838 to i8
  store i8 %1839, i8* %22, align 1
  %1840 = lshr i32 %1821, 31
  %1841 = xor i32 %1838, %1840
  %1842 = add nuw nsw i32 %1841, %1838
  %1843 = icmp eq i32 %1842, 2
  %1844 = zext i1 %1843 to i8
  store i8 %1844, i8* %23, align 1
  %1845 = add i64 %1528, 14
  store i64 %1845, i64* %3, align 8
  store i32 %1822, i32* %1820, align 4
  %1846 = load i64, i64* %3, align 8
  %1847 = add i64 %1846, -160
  store i64 %1847, i64* %3, align 8
  br label %block_.L_4a456c

block_.L_4a4611:                                  ; preds = %block_.L_4a456c
  %1848 = add i64 %1467, -36
  %1849 = add i64 %1495, 3
  store i64 %1849, i64* %3, align 8
  %1850 = inttoptr i64 %1848 to i32*
  %1851 = load i32, i32* %1850, align 4
  %1852 = zext i32 %1851 to i64
  store i64 %1852, i64* %RAX.i1763, align 8
  %1853 = add i64 %1467, -552
  %1854 = add i64 %1495, 9
  store i64 %1854, i64* %3, align 8
  %1855 = inttoptr i64 %1853 to i32*
  %1856 = load i32, i32* %1855, align 4
  %1857 = sub i32 %1851, %1856
  %1858 = icmp ult i32 %1851, %1856
  %1859 = zext i1 %1858 to i8
  store i8 %1859, i8* %18, align 1
  %1860 = and i32 %1857, 255
  %1861 = tail call i32 @llvm.ctpop.i32(i32 %1860)
  %1862 = trunc i32 %1861 to i8
  %1863 = and i8 %1862, 1
  %1864 = xor i8 %1863, 1
  store i8 %1864, i8* %19, align 1
  %1865 = xor i32 %1856, %1851
  %1866 = xor i32 %1865, %1857
  %1867 = lshr i32 %1866, 4
  %1868 = trunc i32 %1867 to i8
  %1869 = and i8 %1868, 1
  store i8 %1869, i8* %20, align 1
  %1870 = icmp eq i32 %1857, 0
  %1871 = zext i1 %1870 to i8
  store i8 %1871, i8* %21, align 1
  %1872 = lshr i32 %1857, 31
  %1873 = trunc i32 %1872 to i8
  store i8 %1873, i8* %22, align 1
  %1874 = lshr i32 %1851, 31
  %1875 = lshr i32 %1856, 31
  %1876 = xor i32 %1875, %1874
  %1877 = xor i32 %1872, %1874
  %1878 = add nuw nsw i32 %1877, %1876
  %1879 = icmp eq i32 %1878, 2
  %1880 = zext i1 %1879 to i8
  store i8 %1880, i8* %23, align 1
  %.v868 = select i1 %1870, i64 15, i64 28
  %1881 = add i64 %1495, %.v868
  store i64 %1881, i64* %3, align 8
  br i1 %1870, label %block_4a4620, label %block_.L_4a462d

block_4a4620:                                     ; preds = %block_.L_4a4611
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %1882 = add i64 %1467, -1216
  %1883 = add i64 %1881, 8
  store i64 %1883, i64* %3, align 8
  %1884 = inttoptr i64 %1882 to i32*
  store i32 0, i32* %1884, align 4
  %1885 = load i64, i64* %3, align 8
  %1886 = add i64 %1885, 33
  store i64 %1886, i64* %3, align 8
  br label %block_.L_4a4649

block_.L_4a462d:                                  ; preds = %block_.L_4a4611
  %1887 = add i64 %1881, ptrtoint (%G_0xd203__rip__type* @G_0xd203__rip_ to i64)
  %1888 = add i64 %1881, 8
  store i64 %1888, i64* %3, align 8
  %1889 = inttoptr i64 %1887 to i64*
  %1890 = load i64, i64* %1889, align 8
  store i64 %1890, i64* %54, align 1
  store double 0.000000e+00, double* %1228, align 1
  %1891 = add i64 %1467, -24
  %1892 = add i64 %1881, 13
  store i64 %1892, i64* %3, align 8
  %1893 = bitcast i64 %1890 to double
  %1894 = inttoptr i64 %1891 to double*
  %1895 = load double, double* %1894, align 8
  %1896 = fmul double %1893, %1895
  store double %1896, double* %53, align 1
  store i64 0, i64* %1227, align 1
  %1897 = add i64 %1881, -668797
  %1898 = add i64 %1881, 18
  %1899 = load i64, i64* %6, align 8
  %1900 = add i64 %1899, -8
  %1901 = inttoptr i64 %1900 to i64*
  store i64 %1898, i64* %1901, align 8
  store i64 %1900, i64* %6, align 8
  store i64 %1897, i64* %3, align 8
  %1902 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 ptrtoint (i64 (i64)* @floor to i64), %struct.Memory* %MEMORY.12)
  %1903 = load i64, i64* %3, align 8
  %1904 = load double, double* %53, align 1
  %1905 = tail call double @llvm.trunc.f64(double %1904)
  %1906 = tail call double @llvm.fabs.f64(double %1905)
  %1907 = fcmp ogt double %1906, 0x41DFFFFFFFC00000
  %1908 = fptosi double %1905 to i32
  %1909 = zext i32 %1908 to i64
  %1910 = select i1 %1907, i64 2147483648, i64 %1909
  store i64 %1910, i64* %RAX.i1763, align 8
  %1911 = load i64, i64* %RBP.i, align 8
  %1912 = add i64 %1911, -1216
  %1913 = trunc i64 %1910 to i32
  %1914 = add i64 %1903, 10
  store i64 %1914, i64* %3, align 8
  %1915 = inttoptr i64 %1912 to i32*
  store i32 %1913, i32* %1915, align 4
  %.pre655 = load i64, i64* %3, align 8
  br label %block_.L_4a4649

block_.L_4a4649:                                  ; preds = %block_.L_4a462d, %block_4a4620
  %1916 = phi i64 [ %.pre655, %block_.L_4a462d ], [ %1886, %block_4a4620 ]
  %MEMORY.20 = phi %struct.Memory* [ %1902, %block_.L_4a462d ], [ %MEMORY.12, %block_4a4620 ]
  %1917 = load i64, i64* %RBP.i, align 8
  %1918 = add i64 %1917, -1216
  %1919 = add i64 %1916, 6
  store i64 %1919, i64* %3, align 8
  %1920 = inttoptr i64 %1918 to i32*
  %1921 = load i32, i32* %1920, align 4
  %1922 = zext i32 %1921 to i64
  store i64 %1922, i64* %RAX.i1763, align 8
  %1923 = add i64 %1917, -336
  store i64 %1923, i64* %RDI.i2141, align 8
  %1924 = add i64 %1917, -64
  %1925 = add i64 %1916, 16
  store i64 %1925, i64* %3, align 8
  %1926 = inttoptr i64 %1924 to i32*
  store i32 %1921, i32* %1926, align 4
  %1927 = load i64, i64* %3, align 8
  %1928 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %1928, i64* %RCX.i1692, align 8
  %1929 = add i64 %1928, 24
  %1930 = add i64 %1927, 11
  store i64 %1930, i64* %3, align 8
  %1931 = inttoptr i64 %1929 to i32*
  %1932 = load i32, i32* %1931, align 4
  %1933 = zext i32 %1932 to i64
  store i64 %1933, i64* %RSI.i1889, align 8
  %1934 = add i64 %1927, -282793
  %1935 = add i64 %1927, 16
  %1936 = load i64, i64* %6, align 8
  %1937 = add i64 %1936, -8
  %1938 = inttoptr i64 %1937 to i64*
  store i64 %1935, i64* %1938, align 8
  store i64 %1937, i64* %6, align 8
  store i64 %1934, i64* %3, align 8
  %call2_4a4664 = tail call %struct.Memory* @sub_45f5b0.SATD8X8(%struct.State* nonnull %0, i64 %1934, %struct.Memory* %MEMORY.20)
  %1939 = load i64, i64* %RAX.i1763, align 8
  %1940 = load i64, i64* %RBP.i, align 8
  %1941 = add i64 %1940, -64
  %1942 = load i64, i64* %3, align 8
  %1943 = add i64 %1942, 3
  store i64 %1943, i64* %3, align 8
  %1944 = trunc i64 %1939 to i32
  %1945 = inttoptr i64 %1941 to i32*
  %1946 = load i32, i32* %1945, align 4
  %1947 = add i32 %1946, %1944
  %1948 = zext i32 %1947 to i64
  store i64 %1948, i64* %RAX.i1763, align 8
  %1949 = icmp ult i32 %1947, %1944
  %1950 = icmp ult i32 %1947, %1946
  %1951 = or i1 %1949, %1950
  %1952 = zext i1 %1951 to i8
  store i8 %1952, i8* %18, align 1
  %1953 = and i32 %1947, 255
  %1954 = tail call i32 @llvm.ctpop.i32(i32 %1953)
  %1955 = trunc i32 %1954 to i8
  %1956 = and i8 %1955, 1
  %1957 = xor i8 %1956, 1
  store i8 %1957, i8* %19, align 1
  %1958 = xor i32 %1946, %1944
  %1959 = xor i32 %1958, %1947
  %1960 = lshr i32 %1959, 4
  %1961 = trunc i32 %1960 to i8
  %1962 = and i8 %1961, 1
  store i8 %1962, i8* %20, align 1
  %1963 = icmp eq i32 %1947, 0
  %1964 = zext i1 %1963 to i8
  store i8 %1964, i8* %21, align 1
  %1965 = lshr i32 %1947, 31
  %1966 = trunc i32 %1965 to i8
  store i8 %1966, i8* %22, align 1
  %1967 = lshr i32 %1944, 31
  %1968 = lshr i32 %1946, 31
  %1969 = xor i32 %1965, %1967
  %1970 = xor i32 %1965, %1968
  %1971 = add nuw nsw i32 %1969, %1970
  %1972 = icmp eq i32 %1971, 2
  %1973 = zext i1 %1972 to i8
  store i8 %1973, i8* %23, align 1
  %1974 = add i64 %1942, 6
  store i64 %1974, i64* %3, align 8
  store i32 %1947, i32* %1945, align 4
  %1975 = load i64, i64* %RBP.i, align 8
  %1976 = add i64 %1975, -64
  %1977 = load i64, i64* %3, align 8
  %1978 = add i64 %1977, 3
  store i64 %1978, i64* %3, align 8
  %1979 = inttoptr i64 %1976 to i32*
  %1980 = load i32, i32* %1979, align 4
  %1981 = zext i32 %1980 to i64
  store i64 %1981, i64* %RAX.i1763, align 8
  %1982 = add i64 %1975, -32
  %1983 = add i64 %1977, 7
  store i64 %1983, i64* %3, align 8
  %1984 = inttoptr i64 %1982 to i64*
  %1985 = load i64, i64* %1984, align 8
  store i64 %1985, i64* %RCX.i1692, align 8
  %1986 = add i64 %1977, 9
  store i64 %1986, i64* %3, align 8
  %1987 = inttoptr i64 %1985 to i32*
  %1988 = load i32, i32* %1987, align 4
  %1989 = sub i32 %1980, %1988
  %1990 = icmp ult i32 %1980, %1988
  %1991 = zext i1 %1990 to i8
  store i8 %1991, i8* %18, align 1
  %1992 = and i32 %1989, 255
  %1993 = tail call i32 @llvm.ctpop.i32(i32 %1992)
  %1994 = trunc i32 %1993 to i8
  %1995 = and i8 %1994, 1
  %1996 = xor i8 %1995, 1
  store i8 %1996, i8* %19, align 1
  %1997 = xor i32 %1988, %1980
  %1998 = xor i32 %1997, %1989
  %1999 = lshr i32 %1998, 4
  %2000 = trunc i32 %1999 to i8
  %2001 = and i8 %2000, 1
  store i8 %2001, i8* %20, align 1
  %2002 = icmp eq i32 %1989, 0
  %2003 = zext i1 %2002 to i8
  store i8 %2003, i8* %21, align 1
  %2004 = lshr i32 %1989, 31
  %2005 = trunc i32 %2004 to i8
  store i8 %2005, i8* %22, align 1
  %2006 = lshr i32 %1980, 31
  %2007 = lshr i32 %1988, 31
  %2008 = xor i32 %2007, %2006
  %2009 = xor i32 %2004, %2006
  %2010 = add nuw nsw i32 %2009, %2008
  %2011 = icmp eq i32 %2010, 2
  %2012 = zext i1 %2011 to i8
  store i8 %2012, i8* %23, align 1
  %2013 = icmp ne i8 %2005, 0
  %2014 = xor i1 %2013, %2011
  %.v869 = select i1 %2014, i64 15, i64 30
  %2015 = add i64 %1977, %.v869
  store i64 %2015, i64* %3, align 8
  br i1 %2014, label %block_4a467e, label %block_.L_4a468d

block_4a467e:                                     ; preds = %block_.L_4a4649
  %2016 = add i64 %1975, -36
  %2017 = add i64 %2015, 3
  store i64 %2017, i64* %3, align 8
  %2018 = inttoptr i64 %2016 to i32*
  %2019 = load i32, i32* %2018, align 4
  %2020 = zext i32 %2019 to i64
  store i64 %2020, i64* %RAX.i1763, align 8
  %2021 = add i64 %1975, -40
  %2022 = add i64 %2015, 6
  store i64 %2022, i64* %3, align 8
  %2023 = inttoptr i64 %2021 to i32*
  store i32 %2019, i32* %2023, align 4
  %2024 = load i64, i64* %RBP.i, align 8
  %2025 = add i64 %2024, -64
  %2026 = load i64, i64* %3, align 8
  %2027 = add i64 %2026, 3
  store i64 %2027, i64* %3, align 8
  %2028 = inttoptr i64 %2025 to i32*
  %2029 = load i32, i32* %2028, align 4
  %2030 = zext i32 %2029 to i64
  store i64 %2030, i64* %RAX.i1763, align 8
  %2031 = add i64 %2024, -32
  %2032 = add i64 %2026, 7
  store i64 %2032, i64* %3, align 8
  %2033 = inttoptr i64 %2031 to i64*
  %2034 = load i64, i64* %2033, align 8
  store i64 %2034, i64* %RCX.i1692, align 8
  %2035 = add i64 %2026, 9
  store i64 %2035, i64* %3, align 8
  %2036 = inttoptr i64 %2034 to i32*
  store i32 %2029, i32* %2036, align 4
  %.pre656 = load i64, i64* %3, align 8
  br label %block_.L_4a468d

block_.L_4a468d:                                  ; preds = %block_.L_4a4649, %block_4a467e
  %2037 = phi i64 [ %2015, %block_.L_4a4649 ], [ %.pre656, %block_4a467e ]
  %2038 = add i64 %2037, 6266
  br label %block_.L_4a5f07

block_.L_4a4692:                                  ; preds = %block_.L_4a4549
  %2039 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %2039, i64* %RAX.i1763, align 8
  %2040 = add i64 %2039, 72724
  %2041 = add i64 %1457, 15
  store i64 %2041, i64* %3, align 8
  %2042 = inttoptr i64 %2040 to i32*
  %2043 = load i32, i32* %2042, align 4
  store i8 0, i8* %18, align 1
  %2044 = and i32 %2043, 255
  %2045 = tail call i32 @llvm.ctpop.i32(i32 %2044)
  %2046 = trunc i32 %2045 to i8
  %2047 = and i8 %2046, 1
  %2048 = xor i8 %2047, 1
  store i8 %2048, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %2049 = icmp eq i32 %2043, 0
  %2050 = zext i1 %2049 to i8
  store i8 %2050, i8* %21, align 1
  %2051 = lshr i32 %2043, 31
  %2052 = trunc i32 %2051 to i8
  store i8 %2052, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v786 = select i1 %2049, i64 21, i64 733
  %2053 = add i64 %1457, %.v786
  %2054 = add i64 %1235, -48
  %2055 = add i64 %2053, 7
  store i64 %2055, i64* %3, align 8
  %2056 = inttoptr i64 %2054 to i32*
  store i32 0, i32* %2056, align 4
  %.pre658 = load i64, i64* %3, align 8
  br i1 %2049, label %block_.L_4a46ae.preheader, label %block_.L_4a4976.preheader

block_.L_4a4976.preheader:                        ; preds = %block_.L_4a4692
  br label %block_.L_4a4976

block_.L_4a46ae.preheader:                        ; preds = %block_.L_4a4692
  br label %block_.L_4a46ae

block_.L_4a46ae:                                  ; preds = %block_.L_4a46ae.preheader, %block_.L_4a47a9
  %2057 = phi i64 [ %2652, %block_.L_4a47a9 ], [ %.pre658, %block_.L_4a46ae.preheader ]
  %2058 = load i64, i64* %RBP.i, align 8
  %2059 = add i64 %2058, -48
  %2060 = add i64 %2057, 4
  store i64 %2060, i64* %3, align 8
  %2061 = inttoptr i64 %2059 to i32*
  %2062 = load i32, i32* %2061, align 4
  %2063 = add i32 %2062, -8
  %2064 = icmp ult i32 %2062, 8
  %2065 = zext i1 %2064 to i8
  store i8 %2065, i8* %18, align 1
  %2066 = and i32 %2063, 255
  %2067 = tail call i32 @llvm.ctpop.i32(i32 %2066)
  %2068 = trunc i32 %2067 to i8
  %2069 = and i8 %2068, 1
  %2070 = xor i8 %2069, 1
  store i8 %2070, i8* %19, align 1
  %2071 = xor i32 %2063, %2062
  %2072 = lshr i32 %2071, 4
  %2073 = trunc i32 %2072 to i8
  %2074 = and i8 %2073, 1
  store i8 %2074, i8* %20, align 1
  %2075 = icmp eq i32 %2063, 0
  %2076 = zext i1 %2075 to i8
  store i8 %2076, i8* %21, align 1
  %2077 = lshr i32 %2063, 31
  %2078 = trunc i32 %2077 to i8
  store i8 %2078, i8* %22, align 1
  %2079 = lshr i32 %2062, 31
  %2080 = xor i32 %2077, %2079
  %2081 = add nuw nsw i32 %2080, %2079
  %2082 = icmp eq i32 %2081, 2
  %2083 = zext i1 %2082 to i8
  store i8 %2083, i8* %23, align 1
  %2084 = icmp ne i8 %2078, 0
  %2085 = xor i1 %2084, %2082
  %.v864 = select i1 %2085, i64 10, i64 270
  %2086 = add i64 %2057, %.v864
  store i64 %2086, i64* %3, align 8
  br i1 %2085, label %block_4a46b8, label %block_.L_4a47bc

block_4a46b8:                                     ; preds = %block_.L_4a46ae
  %2087 = add i64 %2058, -44
  %2088 = add i64 %2086, 7
  store i64 %2088, i64* %3, align 8
  %2089 = inttoptr i64 %2087 to i32*
  store i32 0, i32* %2089, align 4
  %.pre666 = load i64, i64* %3, align 8
  br label %block_.L_4a46bf

block_.L_4a46bf:                                  ; preds = %block_4a46c9, %block_4a46b8
  %2090 = phi i64 [ %2622, %block_4a46c9 ], [ %.pre666, %block_4a46b8 ]
  %2091 = load i64, i64* %RBP.i, align 8
  %2092 = add i64 %2091, -44
  %2093 = add i64 %2090, 4
  store i64 %2093, i64* %3, align 8
  %2094 = inttoptr i64 %2092 to i32*
  %2095 = load i32, i32* %2094, align 4
  %2096 = add i32 %2095, -8
  %2097 = icmp ult i32 %2095, 8
  %2098 = zext i1 %2097 to i8
  store i8 %2098, i8* %18, align 1
  %2099 = and i32 %2096, 255
  %2100 = tail call i32 @llvm.ctpop.i32(i32 %2099)
  %2101 = trunc i32 %2100 to i8
  %2102 = and i8 %2101, 1
  %2103 = xor i8 %2102, 1
  store i8 %2103, i8* %19, align 1
  %2104 = xor i32 %2096, %2095
  %2105 = lshr i32 %2104, 4
  %2106 = trunc i32 %2105 to i8
  %2107 = and i8 %2106, 1
  store i8 %2107, i8* %20, align 1
  %2108 = icmp eq i32 %2096, 0
  %2109 = zext i1 %2108 to i8
  store i8 %2109, i8* %21, align 1
  %2110 = lshr i32 %2096, 31
  %2111 = trunc i32 %2110 to i8
  store i8 %2111, i8* %22, align 1
  %2112 = lshr i32 %2095, 31
  %2113 = xor i32 %2110, %2112
  %2114 = add nuw nsw i32 %2113, %2112
  %2115 = icmp eq i32 %2114, 2
  %2116 = zext i1 %2115 to i8
  store i8 %2116, i8* %23, align 1
  %2117 = icmp ne i8 %2111, 0
  %2118 = xor i1 %2117, %2115
  %.v791 = select i1 %2118, i64 10, i64 234
  %2119 = add i64 %2090, %.v791
  store i64 %2119, i64* %3, align 8
  br i1 %2118, label %block_4a46c9, label %block_.L_4a47a9

block_4a46c9:                                     ; preds = %block_.L_4a46bf
  %2120 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %2121 = add i64 %2120, 7352
  store i64 %2121, i64* %RAX.i1763, align 8
  %2122 = icmp ugt i64 %2120, -7353
  %2123 = zext i1 %2122 to i8
  store i8 %2123, i8* %18, align 1
  %2124 = trunc i64 %2121 to i32
  %2125 = and i32 %2124, 255
  %2126 = tail call i32 @llvm.ctpop.i32(i32 %2125)
  %2127 = trunc i32 %2126 to i8
  %2128 = and i8 %2127, 1
  %2129 = xor i8 %2128, 1
  store i8 %2129, i8* %19, align 1
  %2130 = xor i64 %2120, 16
  %2131 = xor i64 %2130, %2121
  %2132 = lshr i64 %2131, 4
  %2133 = trunc i64 %2132 to i8
  %2134 = and i8 %2133, 1
  store i8 %2134, i8* %20, align 1
  %2135 = icmp eq i64 %2121, 0
  %2136 = zext i1 %2135 to i8
  store i8 %2136, i8* %21, align 1
  %2137 = lshr i64 %2121, 63
  %2138 = trunc i64 %2137 to i8
  store i8 %2138, i8* %22, align 1
  %2139 = lshr i64 %2120, 63
  %2140 = xor i64 %2137, %2139
  %2141 = add nuw nsw i64 %2140, %2137
  %2142 = icmp eq i64 %2141, 2
  %2143 = zext i1 %2142 to i8
  store i8 %2143, i8* %23, align 1
  %2144 = add i64 %2091, -36
  %2145 = add i64 %2119, 18
  store i64 %2145, i64* %3, align 8
  %2146 = inttoptr i64 %2144 to i32*
  %2147 = load i32, i32* %2146, align 4
  %2148 = sext i32 %2147 to i64
  %2149 = shl nsw i64 %2148, 7
  store i64 %2149, i64* %RCX.i1692, align 8
  %2150 = add i64 %2149, %2121
  store i64 %2150, i64* %RAX.i1763, align 8
  %2151 = icmp ult i64 %2150, %2121
  %2152 = icmp ult i64 %2150, %2149
  %2153 = or i1 %2151, %2152
  %2154 = zext i1 %2153 to i8
  store i8 %2154, i8* %18, align 1
  %2155 = trunc i64 %2150 to i32
  %2156 = and i32 %2155, 255
  %2157 = tail call i32 @llvm.ctpop.i32(i32 %2156)
  %2158 = trunc i32 %2157 to i8
  %2159 = and i8 %2158, 1
  %2160 = xor i8 %2159, 1
  store i8 %2160, i8* %19, align 1
  %2161 = xor i64 %2121, %2150
  %2162 = lshr i64 %2161, 4
  %2163 = trunc i64 %2162 to i8
  %2164 = and i8 %2163, 1
  store i8 %2164, i8* %20, align 1
  %2165 = icmp eq i64 %2150, 0
  %2166 = zext i1 %2165 to i8
  store i8 %2166, i8* %21, align 1
  %2167 = lshr i64 %2150, 63
  %2168 = trunc i64 %2167 to i8
  store i8 %2168, i8* %22, align 1
  %2169 = lshr i64 %2148, 56
  %2170 = and i64 %2169, 1
  %2171 = xor i64 %2167, %2137
  %2172 = xor i64 %2167, %2170
  %2173 = add nuw nsw i64 %2171, %2172
  %2174 = icmp eq i64 %2173, 2
  %2175 = zext i1 %2174 to i8
  store i8 %2175, i8* %23, align 1
  %2176 = load i64, i64* %RBP.i, align 8
  %2177 = add i64 %2176, -48
  %2178 = add i64 %2119, 29
  store i64 %2178, i64* %3, align 8
  %2179 = inttoptr i64 %2177 to i32*
  %2180 = load i32, i32* %2179, align 4
  %2181 = sext i32 %2180 to i64
  %2182 = shl nsw i64 %2181, 4
  store i64 %2182, i64* %RCX.i1692, align 8
  %2183 = add i64 %2182, %2150
  store i64 %2183, i64* %RAX.i1763, align 8
  %2184 = icmp ult i64 %2183, %2150
  %2185 = icmp ult i64 %2183, %2182
  %2186 = or i1 %2184, %2185
  %2187 = zext i1 %2186 to i8
  store i8 %2187, i8* %18, align 1
  %2188 = trunc i64 %2183 to i32
  %2189 = and i32 %2188, 255
  %2190 = tail call i32 @llvm.ctpop.i32(i32 %2189)
  %2191 = trunc i32 %2190 to i8
  %2192 = and i8 %2191, 1
  %2193 = xor i8 %2192, 1
  store i8 %2193, i8* %19, align 1
  %2194 = xor i64 %2182, %2150
  %2195 = xor i64 %2194, %2183
  %2196 = lshr i64 %2195, 4
  %2197 = trunc i64 %2196 to i8
  %2198 = and i8 %2197, 1
  store i8 %2198, i8* %20, align 1
  %2199 = icmp eq i64 %2183, 0
  %2200 = zext i1 %2199 to i8
  store i8 %2200, i8* %21, align 1
  %2201 = lshr i64 %2183, 63
  %2202 = trunc i64 %2201 to i8
  store i8 %2202, i8* %22, align 1
  %2203 = lshr i64 %2181, 59
  %2204 = and i64 %2203, 1
  %2205 = xor i64 %2201, %2167
  %2206 = xor i64 %2201, %2204
  %2207 = add nuw nsw i64 %2205, %2206
  %2208 = icmp eq i64 %2207, 2
  %2209 = zext i1 %2208 to i8
  store i8 %2209, i8* %23, align 1
  %2210 = add i64 %2176, -44
  %2211 = add i64 %2119, 40
  store i64 %2211, i64* %3, align 8
  %2212 = inttoptr i64 %2210 to i32*
  %2213 = load i32, i32* %2212, align 4
  %2214 = sext i32 %2213 to i64
  store i64 %2214, i64* %RCX.i1692, align 8
  %2215 = shl nsw i64 %2214, 1
  %2216 = add i64 %2215, %2183
  %2217 = add i64 %2119, 44
  store i64 %2217, i64* %3, align 8
  %2218 = inttoptr i64 %2216 to i16*
  %2219 = load i16, i16* %2218, align 2
  store i16 %2219, i16* %DX.i5417, align 2
  %2220 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %2221 = add i64 %2220, 12600
  store i64 %2221, i64* %RAX.i1763, align 8
  %2222 = icmp ugt i64 %2220, -12601
  %2223 = zext i1 %2222 to i8
  store i8 %2223, i8* %18, align 1
  %2224 = trunc i64 %2221 to i32
  %2225 = and i32 %2224, 255
  %2226 = tail call i32 @llvm.ctpop.i32(i32 %2225)
  %2227 = trunc i32 %2226 to i8
  %2228 = and i8 %2227, 1
  %2229 = xor i8 %2228, 1
  store i8 %2229, i8* %19, align 1
  %2230 = xor i64 %2220, 16
  %2231 = xor i64 %2230, %2221
  %2232 = lshr i64 %2231, 4
  %2233 = trunc i64 %2232 to i8
  %2234 = and i8 %2233, 1
  store i8 %2234, i8* %20, align 1
  %2235 = icmp eq i64 %2221, 0
  %2236 = zext i1 %2235 to i8
  store i8 %2236, i8* %21, align 1
  %2237 = lshr i64 %2221, 63
  %2238 = trunc i64 %2237 to i8
  store i8 %2238, i8* %22, align 1
  %2239 = lshr i64 %2220, 63
  %2240 = xor i64 %2237, %2239
  %2241 = add nuw nsw i64 %2240, %2237
  %2242 = icmp eq i64 %2241, 2
  %2243 = zext i1 %2242 to i8
  store i8 %2243, i8* %23, align 1
  %2244 = load i64, i64* %RBP.i, align 8
  %2245 = add i64 %2244, -484
  %2246 = add i64 %2119, 64
  store i64 %2246, i64* %3, align 8
  %2247 = inttoptr i64 %2245 to i32*
  %2248 = load i32, i32* %2247, align 4
  %2249 = zext i32 %2248 to i64
  store i64 %2249, i64* %RSI.i1889, align 8
  %2250 = add i64 %2244, -44
  %2251 = add i64 %2119, 67
  store i64 %2251, i64* %3, align 8
  %2252 = inttoptr i64 %2250 to i32*
  %2253 = load i32, i32* %2252, align 4
  %2254 = add i32 %2253, %2248
  %2255 = zext i32 %2254 to i64
  store i64 %2255, i64* %RSI.i1889, align 8
  %2256 = sext i32 %2254 to i64
  %2257 = shl nsw i64 %2256, 5
  store i64 %2257, i64* %RCX.i1692, align 8
  %2258 = load i64, i64* %RAX.i1763, align 8
  %2259 = add i64 %2257, %2258
  store i64 %2259, i64* %RAX.i1763, align 8
  %2260 = icmp ult i64 %2259, %2258
  %2261 = icmp ult i64 %2259, %2257
  %2262 = or i1 %2260, %2261
  %2263 = zext i1 %2262 to i8
  store i8 %2263, i8* %18, align 1
  %2264 = trunc i64 %2259 to i32
  %2265 = and i32 %2264, 255
  %2266 = tail call i32 @llvm.ctpop.i32(i32 %2265)
  %2267 = trunc i32 %2266 to i8
  %2268 = and i8 %2267, 1
  %2269 = xor i8 %2268, 1
  store i8 %2269, i8* %19, align 1
  %2270 = xor i64 %2258, %2259
  %2271 = lshr i64 %2270, 4
  %2272 = trunc i64 %2271 to i8
  %2273 = and i8 %2272, 1
  store i8 %2273, i8* %20, align 1
  %2274 = icmp eq i64 %2259, 0
  %2275 = zext i1 %2274 to i8
  store i8 %2275, i8* %21, align 1
  %2276 = lshr i64 %2259, 63
  %2277 = trunc i64 %2276 to i8
  store i8 %2277, i8* %22, align 1
  %2278 = lshr i64 %2258, 63
  %2279 = lshr i64 %2256, 58
  %2280 = and i64 %2279, 1
  %2281 = xor i64 %2276, %2278
  %2282 = xor i64 %2276, %2280
  %2283 = add nuw nsw i64 %2281, %2282
  %2284 = icmp eq i64 %2283, 2
  %2285 = zext i1 %2284 to i8
  store i8 %2285, i8* %23, align 1
  %2286 = load i64, i64* %RBP.i, align 8
  %2287 = add i64 %2286, -488
  %2288 = add i64 %2119, 83
  store i64 %2288, i64* %3, align 8
  %2289 = inttoptr i64 %2287 to i32*
  %2290 = load i32, i32* %2289, align 4
  %2291 = zext i32 %2290 to i64
  store i64 %2291, i64* %RSI.i1889, align 8
  %2292 = add i64 %2286, -48
  %2293 = add i64 %2119, 86
  store i64 %2293, i64* %3, align 8
  %2294 = inttoptr i64 %2292 to i32*
  %2295 = load i32, i32* %2294, align 4
  %2296 = add i32 %2295, %2290
  %2297 = zext i32 %2296 to i64
  store i64 %2297, i64* %RSI.i1889, align 8
  %2298 = icmp ult i32 %2296, %2290
  %2299 = icmp ult i32 %2296, %2295
  %2300 = or i1 %2298, %2299
  %2301 = zext i1 %2300 to i8
  store i8 %2301, i8* %18, align 1
  %2302 = and i32 %2296, 255
  %2303 = tail call i32 @llvm.ctpop.i32(i32 %2302)
  %2304 = trunc i32 %2303 to i8
  %2305 = and i8 %2304, 1
  %2306 = xor i8 %2305, 1
  store i8 %2306, i8* %19, align 1
  %2307 = xor i32 %2295, %2290
  %2308 = xor i32 %2307, %2296
  %2309 = lshr i32 %2308, 4
  %2310 = trunc i32 %2309 to i8
  %2311 = and i8 %2310, 1
  store i8 %2311, i8* %20, align 1
  %2312 = icmp eq i32 %2296, 0
  %2313 = zext i1 %2312 to i8
  store i8 %2313, i8* %21, align 1
  %2314 = lshr i32 %2296, 31
  %2315 = trunc i32 %2314 to i8
  store i8 %2315, i8* %22, align 1
  %2316 = lshr i32 %2290, 31
  %2317 = lshr i32 %2295, 31
  %2318 = xor i32 %2314, %2316
  %2319 = xor i32 %2314, %2317
  %2320 = add nuw nsw i32 %2318, %2319
  %2321 = icmp eq i32 %2320, 2
  %2322 = zext i1 %2321 to i8
  store i8 %2322, i8* %23, align 1
  %2323 = sext i32 %2296 to i64
  store i64 %2323, i64* %RCX.i1692, align 8
  %2324 = shl nsw i64 %2323, 1
  %2325 = add i64 %2259, %2324
  %2326 = load i16, i16* %DX.i5417, align 2
  %2327 = add i64 %2119, 93
  store i64 %2327, i64* %3, align 8
  %2328 = inttoptr i64 %2325 to i16*
  store i16 %2326, i16* %2328, align 2
  %2329 = load i64, i64* %RBP.i, align 8
  %2330 = add i64 %2329, -528
  %2331 = load i64, i64* %3, align 8
  %2332 = add i64 %2331, 7
  store i64 %2332, i64* %3, align 8
  %2333 = inttoptr i64 %2330 to i64*
  %2334 = load i64, i64* %2333, align 8
  store i64 %2334, i64* %RAX.i1763, align 8
  %2335 = add i64 %2329, -504
  %2336 = add i64 %2331, 13
  store i64 %2336, i64* %3, align 8
  %2337 = inttoptr i64 %2335 to i32*
  %2338 = load i32, i32* %2337, align 4
  %2339 = zext i32 %2338 to i64
  store i64 %2339, i64* %RSI.i1889, align 8
  %2340 = add i64 %2329, -48
  %2341 = add i64 %2331, 16
  store i64 %2341, i64* %3, align 8
  %2342 = inttoptr i64 %2340 to i32*
  %2343 = load i32, i32* %2342, align 4
  %2344 = add i32 %2343, %2338
  %2345 = zext i32 %2344 to i64
  store i64 %2345, i64* %RSI.i1889, align 8
  %2346 = icmp ult i32 %2344, %2338
  %2347 = icmp ult i32 %2344, %2343
  %2348 = or i1 %2346, %2347
  %2349 = zext i1 %2348 to i8
  store i8 %2349, i8* %18, align 1
  %2350 = and i32 %2344, 255
  %2351 = tail call i32 @llvm.ctpop.i32(i32 %2350)
  %2352 = trunc i32 %2351 to i8
  %2353 = and i8 %2352, 1
  %2354 = xor i8 %2353, 1
  store i8 %2354, i8* %19, align 1
  %2355 = xor i32 %2343, %2338
  %2356 = xor i32 %2355, %2344
  %2357 = lshr i32 %2356, 4
  %2358 = trunc i32 %2357 to i8
  %2359 = and i8 %2358, 1
  store i8 %2359, i8* %20, align 1
  %2360 = icmp eq i32 %2344, 0
  %2361 = zext i1 %2360 to i8
  store i8 %2361, i8* %21, align 1
  %2362 = lshr i32 %2344, 31
  %2363 = trunc i32 %2362 to i8
  store i8 %2363, i8* %22, align 1
  %2364 = lshr i32 %2338, 31
  %2365 = lshr i32 %2343, 31
  %2366 = xor i32 %2362, %2364
  %2367 = xor i32 %2362, %2365
  %2368 = add nuw nsw i32 %2366, %2367
  %2369 = icmp eq i32 %2368, 2
  %2370 = zext i1 %2369 to i8
  store i8 %2370, i8* %23, align 1
  %2371 = sext i32 %2344 to i64
  store i64 %2371, i64* %RCX.i1692, align 8
  %2372 = shl nsw i64 %2371, 3
  %2373 = add i64 %2334, %2372
  %2374 = add i64 %2331, 23
  store i64 %2374, i64* %3, align 8
  %2375 = inttoptr i64 %2373 to i64*
  %2376 = load i64, i64* %2375, align 8
  store i64 %2376, i64* %RAX.i1763, align 8
  %2377 = add i64 %2329, -500
  %2378 = add i64 %2331, 29
  store i64 %2378, i64* %3, align 8
  %2379 = inttoptr i64 %2377 to i32*
  %2380 = load i32, i32* %2379, align 4
  %2381 = zext i32 %2380 to i64
  store i64 %2381, i64* %RSI.i1889, align 8
  %2382 = add i64 %2329, -44
  %2383 = add i64 %2331, 32
  store i64 %2383, i64* %3, align 8
  %2384 = inttoptr i64 %2382 to i32*
  %2385 = load i32, i32* %2384, align 4
  %2386 = add i32 %2385, %2380
  %2387 = zext i32 %2386 to i64
  store i64 %2387, i64* %RSI.i1889, align 8
  %2388 = icmp ult i32 %2386, %2380
  %2389 = icmp ult i32 %2386, %2385
  %2390 = or i1 %2388, %2389
  %2391 = zext i1 %2390 to i8
  store i8 %2391, i8* %18, align 1
  %2392 = and i32 %2386, 255
  %2393 = tail call i32 @llvm.ctpop.i32(i32 %2392)
  %2394 = trunc i32 %2393 to i8
  %2395 = and i8 %2394, 1
  %2396 = xor i8 %2395, 1
  store i8 %2396, i8* %19, align 1
  %2397 = xor i32 %2385, %2380
  %2398 = xor i32 %2397, %2386
  %2399 = lshr i32 %2398, 4
  %2400 = trunc i32 %2399 to i8
  %2401 = and i8 %2400, 1
  store i8 %2401, i8* %20, align 1
  %2402 = icmp eq i32 %2386, 0
  %2403 = zext i1 %2402 to i8
  store i8 %2403, i8* %21, align 1
  %2404 = lshr i32 %2386, 31
  %2405 = trunc i32 %2404 to i8
  store i8 %2405, i8* %22, align 1
  %2406 = lshr i32 %2380, 31
  %2407 = lshr i32 %2385, 31
  %2408 = xor i32 %2404, %2406
  %2409 = xor i32 %2404, %2407
  %2410 = add nuw nsw i32 %2408, %2409
  %2411 = icmp eq i32 %2410, 2
  %2412 = zext i1 %2411 to i8
  store i8 %2412, i8* %23, align 1
  %2413 = sext i32 %2386 to i64
  store i64 %2413, i64* %RCX.i1692, align 8
  %2414 = shl nsw i64 %2413, 1
  %2415 = add i64 %2376, %2414
  %2416 = add i64 %2331, 39
  store i64 %2416, i64* %3, align 8
  %2417 = inttoptr i64 %2415 to i16*
  %2418 = load i16, i16* %2417, align 2
  %2419 = zext i16 %2418 to i64
  store i64 %2419, i64* %RSI.i1889, align 8
  %2420 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %2421 = add i64 %2420, 7352
  store i64 %2421, i64* %RAX.i1763, align 8
  %2422 = icmp ugt i64 %2420, -7353
  %2423 = zext i1 %2422 to i8
  store i8 %2423, i8* %18, align 1
  %2424 = trunc i64 %2421 to i32
  %2425 = and i32 %2424, 255
  %2426 = tail call i32 @llvm.ctpop.i32(i32 %2425)
  %2427 = trunc i32 %2426 to i8
  %2428 = and i8 %2427, 1
  %2429 = xor i8 %2428, 1
  store i8 %2429, i8* %19, align 1
  %2430 = xor i64 %2420, 16
  %2431 = xor i64 %2430, %2421
  %2432 = lshr i64 %2431, 4
  %2433 = trunc i64 %2432 to i8
  %2434 = and i8 %2433, 1
  store i8 %2434, i8* %20, align 1
  %2435 = icmp eq i64 %2421, 0
  %2436 = zext i1 %2435 to i8
  store i8 %2436, i8* %21, align 1
  %2437 = lshr i64 %2421, 63
  %2438 = trunc i64 %2437 to i8
  store i8 %2438, i8* %22, align 1
  %2439 = lshr i64 %2420, 63
  %2440 = xor i64 %2437, %2439
  %2441 = add nuw nsw i64 %2440, %2437
  %2442 = icmp eq i64 %2441, 2
  %2443 = zext i1 %2442 to i8
  store i8 %2443, i8* %23, align 1
  %2444 = load i64, i64* %RBP.i, align 8
  %2445 = add i64 %2444, -36
  %2446 = add i64 %2331, 57
  store i64 %2446, i64* %3, align 8
  %2447 = inttoptr i64 %2445 to i32*
  %2448 = load i32, i32* %2447, align 4
  %2449 = sext i32 %2448 to i64
  %2450 = shl nsw i64 %2449, 7
  store i64 %2450, i64* %RCX.i1692, align 8
  %2451 = add i64 %2450, %2421
  store i64 %2451, i64* %RAX.i1763, align 8
  %2452 = icmp ult i64 %2451, %2421
  %2453 = icmp ult i64 %2451, %2450
  %2454 = or i1 %2452, %2453
  %2455 = zext i1 %2454 to i8
  store i8 %2455, i8* %18, align 1
  %2456 = trunc i64 %2451 to i32
  %2457 = and i32 %2456, 255
  %2458 = tail call i32 @llvm.ctpop.i32(i32 %2457)
  %2459 = trunc i32 %2458 to i8
  %2460 = and i8 %2459, 1
  %2461 = xor i8 %2460, 1
  store i8 %2461, i8* %19, align 1
  %2462 = xor i64 %2421, %2451
  %2463 = lshr i64 %2462, 4
  %2464 = trunc i64 %2463 to i8
  %2465 = and i8 %2464, 1
  store i8 %2465, i8* %20, align 1
  %2466 = icmp eq i64 %2451, 0
  %2467 = zext i1 %2466 to i8
  store i8 %2467, i8* %21, align 1
  %2468 = lshr i64 %2451, 63
  %2469 = trunc i64 %2468 to i8
  store i8 %2469, i8* %22, align 1
  %2470 = lshr i64 %2449, 56
  %2471 = and i64 %2470, 1
  %2472 = xor i64 %2468, %2437
  %2473 = xor i64 %2468, %2471
  %2474 = add nuw nsw i64 %2472, %2473
  %2475 = icmp eq i64 %2474, 2
  %2476 = zext i1 %2475 to i8
  store i8 %2476, i8* %23, align 1
  %2477 = add i64 %2444, -48
  %2478 = add i64 %2331, 68
  store i64 %2478, i64* %3, align 8
  %2479 = inttoptr i64 %2477 to i32*
  %2480 = load i32, i32* %2479, align 4
  %2481 = sext i32 %2480 to i64
  %2482 = shl nsw i64 %2481, 4
  store i64 %2482, i64* %RCX.i1692, align 8
  %2483 = add i64 %2482, %2451
  store i64 %2483, i64* %RAX.i1763, align 8
  %2484 = icmp ult i64 %2483, %2451
  %2485 = icmp ult i64 %2483, %2482
  %2486 = or i1 %2484, %2485
  %2487 = zext i1 %2486 to i8
  store i8 %2487, i8* %18, align 1
  %2488 = trunc i64 %2483 to i32
  %2489 = and i32 %2488, 255
  %2490 = tail call i32 @llvm.ctpop.i32(i32 %2489)
  %2491 = trunc i32 %2490 to i8
  %2492 = and i8 %2491, 1
  %2493 = xor i8 %2492, 1
  store i8 %2493, i8* %19, align 1
  %2494 = xor i64 %2482, %2451
  %2495 = xor i64 %2494, %2483
  %2496 = lshr i64 %2495, 4
  %2497 = trunc i64 %2496 to i8
  %2498 = and i8 %2497, 1
  store i8 %2498, i8* %20, align 1
  %2499 = icmp eq i64 %2483, 0
  %2500 = zext i1 %2499 to i8
  store i8 %2500, i8* %21, align 1
  %2501 = lshr i64 %2483, 63
  %2502 = trunc i64 %2501 to i8
  store i8 %2502, i8* %22, align 1
  %2503 = lshr i64 %2481, 59
  %2504 = and i64 %2503, 1
  %2505 = xor i64 %2501, %2468
  %2506 = xor i64 %2501, %2504
  %2507 = add nuw nsw i64 %2505, %2506
  %2508 = icmp eq i64 %2507, 2
  %2509 = zext i1 %2508 to i8
  store i8 %2509, i8* %23, align 1
  %2510 = load i64, i64* %RBP.i, align 8
  %2511 = add i64 %2510, -44
  %2512 = add i64 %2331, 79
  store i64 %2512, i64* %3, align 8
  %2513 = inttoptr i64 %2511 to i32*
  %2514 = load i32, i32* %2513, align 4
  %2515 = sext i32 %2514 to i64
  store i64 %2515, i64* %RCX.i1692, align 8
  %2516 = shl nsw i64 %2515, 1
  %2517 = add i64 %2516, %2483
  %2518 = add i64 %2331, 83
  store i64 %2518, i64* %3, align 8
  %2519 = inttoptr i64 %2517 to i16*
  %2520 = load i16, i16* %2519, align 2
  %2521 = zext i16 %2520 to i64
  store i64 %2521, i64* %RDI.i2141, align 8
  %2522 = load i64, i64* %RSI.i1889, align 8
  %2523 = zext i16 %2520 to i64
  %2524 = sub i64 %2522, %2523
  %2525 = and i64 %2524, 4294967295
  store i64 %2525, i64* %RSI.i1889, align 8
  %2526 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %2527 = add i64 %2526, 13112
  store i64 %2527, i64* %RAX.i1763, align 8
  %2528 = icmp ugt i64 %2526, -13113
  %2529 = zext i1 %2528 to i8
  store i8 %2529, i8* %18, align 1
  %2530 = trunc i64 %2527 to i32
  %2531 = and i32 %2530, 255
  %2532 = tail call i32 @llvm.ctpop.i32(i32 %2531)
  %2533 = trunc i32 %2532 to i8
  %2534 = and i8 %2533, 1
  %2535 = xor i8 %2534, 1
  store i8 %2535, i8* %19, align 1
  %2536 = xor i64 %2526, 16
  %2537 = xor i64 %2536, %2527
  %2538 = lshr i64 %2537, 4
  %2539 = trunc i64 %2538 to i8
  %2540 = and i8 %2539, 1
  store i8 %2540, i8* %20, align 1
  %2541 = icmp eq i64 %2527, 0
  %2542 = zext i1 %2541 to i8
  store i8 %2542, i8* %21, align 1
  %2543 = lshr i64 %2527, 63
  %2544 = trunc i64 %2543 to i8
  store i8 %2544, i8* %22, align 1
  %2545 = lshr i64 %2526, 63
  %2546 = xor i64 %2543, %2545
  %2547 = add nuw nsw i64 %2546, %2543
  %2548 = icmp eq i64 %2547, 2
  %2549 = zext i1 %2548 to i8
  store i8 %2549, i8* %23, align 1
  %2550 = add i64 %2331, 103
  store i64 %2550, i64* %3, align 8
  %2551 = load i32, i32* %2513, align 4
  %2552 = sext i32 %2551 to i64
  %2553 = shl nsw i64 %2552, 6
  store i64 %2553, i64* %RCX.i1692, align 8
  %2554 = add i64 %2553, %2527
  store i64 %2554, i64* %RAX.i1763, align 8
  %2555 = icmp ult i64 %2554, %2527
  %2556 = icmp ult i64 %2554, %2553
  %2557 = or i1 %2555, %2556
  %2558 = zext i1 %2557 to i8
  store i8 %2558, i8* %18, align 1
  %2559 = trunc i64 %2554 to i32
  %2560 = and i32 %2559, 255
  %2561 = tail call i32 @llvm.ctpop.i32(i32 %2560)
  %2562 = trunc i32 %2561 to i8
  %2563 = and i8 %2562, 1
  %2564 = xor i8 %2563, 1
  store i8 %2564, i8* %19, align 1
  %2565 = xor i64 %2527, %2554
  %2566 = lshr i64 %2565, 4
  %2567 = trunc i64 %2566 to i8
  %2568 = and i8 %2567, 1
  store i8 %2568, i8* %20, align 1
  %2569 = icmp eq i64 %2554, 0
  %2570 = zext i1 %2569 to i8
  store i8 %2570, i8* %21, align 1
  %2571 = lshr i64 %2554, 63
  %2572 = trunc i64 %2571 to i8
  store i8 %2572, i8* %22, align 1
  %2573 = lshr i64 %2552, 57
  %2574 = and i64 %2573, 1
  %2575 = xor i64 %2571, %2543
  %2576 = xor i64 %2571, %2574
  %2577 = add nuw nsw i64 %2575, %2576
  %2578 = icmp eq i64 %2577, 2
  %2579 = zext i1 %2578 to i8
  store i8 %2579, i8* %23, align 1
  %2580 = load i64, i64* %RBP.i, align 8
  %2581 = add i64 %2580, -48
  %2582 = add i64 %2331, 114
  store i64 %2582, i64* %3, align 8
  %2583 = inttoptr i64 %2581 to i32*
  %2584 = load i32, i32* %2583, align 4
  %2585 = sext i32 %2584 to i64
  store i64 %2585, i64* %RCX.i1692, align 8
  %2586 = shl nsw i64 %2585, 2
  %2587 = add i64 %2586, %2554
  %2588 = load i32, i32* %ESI.i7670, align 4
  %2589 = add i64 %2331, 117
  store i64 %2589, i64* %3, align 8
  %2590 = inttoptr i64 %2587 to i32*
  store i32 %2588, i32* %2590, align 4
  %2591 = load i64, i64* %RBP.i, align 8
  %2592 = add i64 %2591, -44
  %2593 = load i64, i64* %3, align 8
  %2594 = add i64 %2593, 3
  store i64 %2594, i64* %3, align 8
  %2595 = inttoptr i64 %2592 to i32*
  %2596 = load i32, i32* %2595, align 4
  %2597 = add i32 %2596, 1
  %2598 = zext i32 %2597 to i64
  store i64 %2598, i64* %RAX.i1763, align 8
  %2599 = icmp eq i32 %2596, -1
  %2600 = icmp eq i32 %2597, 0
  %2601 = or i1 %2599, %2600
  %2602 = zext i1 %2601 to i8
  store i8 %2602, i8* %18, align 1
  %2603 = and i32 %2597, 255
  %2604 = tail call i32 @llvm.ctpop.i32(i32 %2603)
  %2605 = trunc i32 %2604 to i8
  %2606 = and i8 %2605, 1
  %2607 = xor i8 %2606, 1
  store i8 %2607, i8* %19, align 1
  %2608 = xor i32 %2597, %2596
  %2609 = lshr i32 %2608, 4
  %2610 = trunc i32 %2609 to i8
  %2611 = and i8 %2610, 1
  store i8 %2611, i8* %20, align 1
  %2612 = zext i1 %2600 to i8
  store i8 %2612, i8* %21, align 1
  %2613 = lshr i32 %2597, 31
  %2614 = trunc i32 %2613 to i8
  store i8 %2614, i8* %22, align 1
  %2615 = lshr i32 %2596, 31
  %2616 = xor i32 %2613, %2615
  %2617 = add nuw nsw i32 %2616, %2613
  %2618 = icmp eq i32 %2617, 2
  %2619 = zext i1 %2618 to i8
  store i8 %2619, i8* %23, align 1
  %2620 = add i64 %2593, 9
  store i64 %2620, i64* %3, align 8
  store i32 %2597, i32* %2595, align 4
  %2621 = load i64, i64* %3, align 8
  %2622 = add i64 %2621, -229
  store i64 %2622, i64* %3, align 8
  br label %block_.L_4a46bf

block_.L_4a47a9:                                  ; preds = %block_.L_4a46bf
  %2623 = add i64 %2091, -48
  %2624 = add i64 %2119, 8
  store i64 %2624, i64* %3, align 8
  %2625 = inttoptr i64 %2623 to i32*
  %2626 = load i32, i32* %2625, align 4
  %2627 = add i32 %2626, 1
  %2628 = zext i32 %2627 to i64
  store i64 %2628, i64* %RAX.i1763, align 8
  %2629 = icmp eq i32 %2626, -1
  %2630 = icmp eq i32 %2627, 0
  %2631 = or i1 %2629, %2630
  %2632 = zext i1 %2631 to i8
  store i8 %2632, i8* %18, align 1
  %2633 = and i32 %2627, 255
  %2634 = tail call i32 @llvm.ctpop.i32(i32 %2633)
  %2635 = trunc i32 %2634 to i8
  %2636 = and i8 %2635, 1
  %2637 = xor i8 %2636, 1
  store i8 %2637, i8* %19, align 1
  %2638 = xor i32 %2627, %2626
  %2639 = lshr i32 %2638, 4
  %2640 = trunc i32 %2639 to i8
  %2641 = and i8 %2640, 1
  store i8 %2641, i8* %20, align 1
  %2642 = zext i1 %2630 to i8
  store i8 %2642, i8* %21, align 1
  %2643 = lshr i32 %2627, 31
  %2644 = trunc i32 %2643 to i8
  store i8 %2644, i8* %22, align 1
  %2645 = lshr i32 %2626, 31
  %2646 = xor i32 %2643, %2645
  %2647 = add nuw nsw i32 %2646, %2643
  %2648 = icmp eq i32 %2647, 2
  %2649 = zext i1 %2648 to i8
  store i8 %2649, i8* %23, align 1
  %2650 = add i64 %2119, 14
  store i64 %2650, i64* %3, align 8
  store i32 %2627, i32* %2625, align 4
  %2651 = load i64, i64* %3, align 8
  %2652 = add i64 %2651, -265
  store i64 %2652, i64* %3, align 8
  br label %block_.L_4a46ae

block_.L_4a47bc:                                  ; preds = %block_.L_4a46ae
  store i8 0, i8* %AL.i6276, align 1
  %2653 = add i64 %2086, -28956
  %2654 = add i64 %2086, 7
  %2655 = load i64, i64* %6, align 8
  %2656 = add i64 %2655, -8
  %2657 = inttoptr i64 %2656 to i64*
  store i64 %2654, i64* %2657, align 8
  store i64 %2656, i64* %6, align 8
  store i64 %2653, i64* %3, align 8
  %call2_4a47be = tail call %struct.Memory* @sub_49d6a0.store_coding_state_cs_cm(%struct.State* nonnull %0, i64 %2653, %struct.Memory* %MEMORY.12)
  %2658 = load i64, i64* %RBP.i, align 8
  %2659 = add i64 %2658, -72
  %2660 = load i64, i64* %3, align 8
  store i64 %2659, i64* %RDI.i2141, align 8
  %2661 = add i64 %2658, -12
  %2662 = add i64 %2660, 7
  store i64 %2662, i64* %3, align 8
  %2663 = inttoptr i64 %2661 to i32*
  %2664 = load i32, i32* %2663, align 4
  %2665 = zext i32 %2664 to i64
  store i64 %2665, i64* %RSI.i1889, align 8
  %2666 = add i64 %2658, -36
  %2667 = add i64 %2660, 10
  store i64 %2667, i64* %3, align 8
  %2668 = inttoptr i64 %2666 to i32*
  %2669 = load i32, i32* %2668, align 4
  %2670 = zext i32 %2669 to i64
  store i64 %2670, i64* %RDX.i1805, align 8
  %2671 = add i64 %2658, -24
  %2672 = add i64 %2660, 15
  store i64 %2672, i64* %3, align 8
  %2673 = inttoptr i64 %2671 to i64*
  %2674 = load i64, i64* %2673, align 8
  store i64 %2674, i64* %54, align 1
  store double 0.000000e+00, double* %1228, align 1
  %2675 = add i64 %2658, -520
  %2676 = add i64 %2660, 23
  store i64 %2676, i64* %3, align 8
  %2677 = inttoptr i64 %2675 to i64*
  %2678 = load i64, i64* %2677, align 8
  store i64 %2678, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %2679 = add i64 %2658, -552
  %2680 = add i64 %2660, 29
  store i64 %2680, i64* %3, align 8
  %2681 = inttoptr i64 %2679 to i32*
  %2682 = load i32, i32* %2681, align 4
  %2683 = zext i32 %2682 to i64
  store i64 %2683, i64* %RCX.i1692, align 8
  %2684 = add i64 %2660, 23341
  %2685 = add i64 %2660, 34
  %2686 = load i64, i64* %6, align 8
  %2687 = add i64 %2686, -8
  %2688 = inttoptr i64 %2687 to i64*
  store i64 %2685, i64* %2688, align 8
  store i64 %2687, i64* %6, align 8
  store i64 %2684, i64* %3, align 8
  %call2_4a47e0 = tail call %struct.Memory* @sub_4aa2f0.RDCost_for_8x8IntraBlocks(%struct.State* nonnull %0, i64 %2684, %struct.Memory* %MEMORY.12)
  %2689 = load i64, i64* %RBP.i, align 8
  %2690 = add i64 %2689, -472
  %2691 = load i64, i64* %3, align 8
  %2692 = add i64 %2691, 8
  store i64 %2692, i64* %3, align 8
  %2693 = load i64, i64* %54, align 1
  %2694 = inttoptr i64 %2690 to i64*
  store i64 %2693, i64* %2694, align 8
  %2695 = load i64, i64* %RBP.i, align 8
  %2696 = add i64 %2695, -520
  %2697 = load i64, i64* %3, align 8
  %2698 = add i64 %2697, 8
  store i64 %2698, i64* %3, align 8
  %2699 = inttoptr i64 %2696 to i64*
  %2700 = load i64, i64* %2699, align 8
  store i64 %2700, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %2701 = add i64 %2697, 12
  store i64 %2701, i64* %3, align 8
  %.cast = bitcast i64 %2700 to double
  %2702 = load double, double* %53, align 1
  %2703 = fcmp uno double %.cast, %2702
  br i1 %2703, label %2704, label %2714

; <label>:2704:                                   ; preds = %block_.L_4a47bc
  %2705 = fadd double %.cast, %2702
  %2706 = bitcast double %2705 to i64
  %2707 = and i64 %2706, 9221120237041090560
  %2708 = icmp eq i64 %2707, 9218868437227405312
  %2709 = and i64 %2706, 2251799813685247
  %2710 = icmp ne i64 %2709, 0
  %2711 = and i1 %2708, %2710
  br i1 %2711, label %2712, label %2720

; <label>:2712:                                   ; preds = %2704
  %2713 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %2701, %struct.Memory* %MEMORY.12)
  %.pre659 = load i64, i64* %3, align 8
  br label %routine_ucomisd__xmm0___xmm1.exit6901

; <label>:2714:                                   ; preds = %block_.L_4a47bc
  %2715 = fcmp ogt double %.cast, %2702
  br i1 %2715, label %2720, label %2716

; <label>:2716:                                   ; preds = %2714
  %2717 = fcmp olt double %.cast, %2702
  br i1 %2717, label %2720, label %2718

; <label>:2718:                                   ; preds = %2716
  %2719 = fcmp oeq double %.cast, %2702
  br i1 %2719, label %2720, label %2724

; <label>:2720:                                   ; preds = %2718, %2716, %2714, %2704
  %2721 = phi i8 [ 0, %2714 ], [ 0, %2716 ], [ 1, %2718 ], [ 1, %2704 ]
  %2722 = phi i8 [ 0, %2714 ], [ 0, %2716 ], [ 0, %2718 ], [ 1, %2704 ]
  %2723 = phi i8 [ 0, %2714 ], [ 1, %2716 ], [ 0, %2718 ], [ 1, %2704 ]
  store i8 %2721, i8* %21, align 1
  store i8 %2722, i8* %19, align 1
  store i8 %2723, i8* %18, align 1
  br label %2724

; <label>:2724:                                   ; preds = %2720, %2718
  store i8 0, i8* %23, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %20, align 1
  br label %routine_ucomisd__xmm0___xmm1.exit6901

routine_ucomisd__xmm0___xmm1.exit6901:            ; preds = %2724, %2712
  %2725 = phi i64 [ %.pre659, %2712 ], [ %2701, %2724 ]
  %2726 = phi %struct.Memory* [ %2713, %2712 ], [ %MEMORY.12, %2724 ]
  %2727 = add i64 %2725, 362
  %2728 = add i64 %2725, 6
  %2729 = load i8, i8* %18, align 1
  %2730 = load i8, i8* %21, align 1
  %2731 = or i8 %2730, %2729
  %2732 = icmp ne i8 %2731, 0
  %2733 = select i1 %2732, i64 %2727, i64 %2728
  store i64 %2733, i64* %3, align 8
  br i1 %2732, label %block_.L_4a4963, label %block_4a47ff

block_4a47ff:                                     ; preds = %routine_ucomisd__xmm0___xmm1.exit6901
  %2734 = load i64, i64* %RBP.i, align 8
  %2735 = add i64 %2734, -48
  %2736 = add i64 %2733, 7
  store i64 %2736, i64* %3, align 8
  %2737 = inttoptr i64 %2735 to i32*
  store i32 0, i32* %2737, align 4
  %.pre660 = load i64, i64* %3, align 8
  br label %block_.L_4a4806

block_.L_4a4806:                                  ; preds = %block_.L_4a48a8, %block_4a47ff
  %2738 = phi i64 [ %3004, %block_.L_4a48a8 ], [ %.pre660, %block_4a47ff ]
  %2739 = load i64, i64* %RBP.i, align 8
  %2740 = add i64 %2739, -48
  %2741 = add i64 %2738, 4
  store i64 %2741, i64* %3, align 8
  %2742 = inttoptr i64 %2740 to i32*
  %2743 = load i32, i32* %2742, align 4
  %2744 = add i32 %2743, -2
  %2745 = icmp ult i32 %2743, 2
  %2746 = zext i1 %2745 to i8
  store i8 %2746, i8* %18, align 1
  %2747 = and i32 %2744, 255
  %2748 = tail call i32 @llvm.ctpop.i32(i32 %2747)
  %2749 = trunc i32 %2748 to i8
  %2750 = and i8 %2749, 1
  %2751 = xor i8 %2750, 1
  store i8 %2751, i8* %19, align 1
  %2752 = xor i32 %2744, %2743
  %2753 = lshr i32 %2752, 4
  %2754 = trunc i32 %2753 to i8
  %2755 = and i8 %2754, 1
  store i8 %2755, i8* %20, align 1
  %2756 = icmp eq i32 %2744, 0
  %2757 = zext i1 %2756 to i8
  store i8 %2757, i8* %21, align 1
  %2758 = lshr i32 %2744, 31
  %2759 = trunc i32 %2758 to i8
  store i8 %2759, i8* %22, align 1
  %2760 = lshr i32 %2743, 31
  %2761 = xor i32 %2758, %2760
  %2762 = add nuw nsw i32 %2761, %2760
  %2763 = icmp eq i32 %2762, 2
  %2764 = zext i1 %2763 to i8
  store i8 %2764, i8* %23, align 1
  %2765 = icmp ne i8 %2759, 0
  %2766 = xor i1 %2765, %2763
  %.v865 = select i1 %2766, i64 10, i64 181
  %2767 = add i64 %2738, %.v865
  store i64 %2767, i64* %3, align 8
  br i1 %2766, label %block_4a4810, label %block_.L_4a48bb

block_4a4810:                                     ; preds = %block_.L_4a4806
  %2768 = add i64 %2739, -44
  %2769 = add i64 %2767, 7
  store i64 %2769, i64* %3, align 8
  %2770 = inttoptr i64 %2768 to i32*
  store i32 0, i32* %2770, align 4
  %.pre663 = load i64, i64* %3, align 8
  br label %block_.L_4a4817

block_.L_4a4817:                                  ; preds = %block_.L_4a4895, %block_4a4810
  %2771 = phi i64 [ %2974, %block_.L_4a4895 ], [ %.pre663, %block_4a4810 ]
  %2772 = load i64, i64* %RBP.i, align 8
  %2773 = add i64 %2772, -44
  %2774 = add i64 %2771, 4
  store i64 %2774, i64* %3, align 8
  %2775 = inttoptr i64 %2773 to i32*
  %2776 = load i32, i32* %2775, align 4
  %2777 = add i32 %2776, -65
  %2778 = icmp ult i32 %2776, 65
  %2779 = zext i1 %2778 to i8
  store i8 %2779, i8* %18, align 1
  %2780 = and i32 %2777, 255
  %2781 = tail call i32 @llvm.ctpop.i32(i32 %2780)
  %2782 = trunc i32 %2781 to i8
  %2783 = and i8 %2782, 1
  %2784 = xor i8 %2783, 1
  store i8 %2784, i8* %19, align 1
  %2785 = xor i32 %2777, %2776
  %2786 = lshr i32 %2785, 4
  %2787 = trunc i32 %2786 to i8
  %2788 = and i8 %2787, 1
  store i8 %2788, i8* %20, align 1
  %2789 = icmp eq i32 %2777, 0
  %2790 = zext i1 %2789 to i8
  store i8 %2790, i8* %21, align 1
  %2791 = lshr i32 %2777, 31
  %2792 = trunc i32 %2791 to i8
  store i8 %2792, i8* %22, align 1
  %2793 = lshr i32 %2776, 31
  %2794 = xor i32 %2791, %2793
  %2795 = add nuw nsw i32 %2794, %2793
  %2796 = icmp eq i32 %2795, 2
  %2797 = zext i1 %2796 to i8
  store i8 %2797, i8* %23, align 1
  %2798 = icmp ne i8 %2792, 0
  %2799 = xor i1 %2798, %2796
  %.v789 = select i1 %2799, i64 10, i64 145
  %2800 = add i64 %2771, %.v789
  store i64 %2800, i64* %3, align 8
  br i1 %2799, label %block_4a4821, label %block_.L_4a48a8

block_4a4821:                                     ; preds = %block_.L_4a4817
  %2801 = add i64 %2772, -52
  %2802 = add i64 %2800, 7
  store i64 %2802, i64* %3, align 8
  %2803 = inttoptr i64 %2801 to i32*
  store i32 0, i32* %2803, align 4
  %.pre664 = load i64, i64* %3, align 8
  br label %block_.L_4a4828

block_.L_4a4828:                                  ; preds = %block_4a4832, %block_4a4821
  %2804 = phi i64 [ %2944, %block_4a4832 ], [ %.pre664, %block_4a4821 ]
  %2805 = load i64, i64* %RBP.i, align 8
  %2806 = add i64 %2805, -52
  %2807 = add i64 %2804, 4
  store i64 %2807, i64* %3, align 8
  %2808 = inttoptr i64 %2806 to i32*
  %2809 = load i32, i32* %2808, align 4
  %2810 = add i32 %2809, -4
  %2811 = icmp ult i32 %2809, 4
  %2812 = zext i1 %2811 to i8
  store i8 %2812, i8* %18, align 1
  %2813 = and i32 %2810, 255
  %2814 = tail call i32 @llvm.ctpop.i32(i32 %2813)
  %2815 = trunc i32 %2814 to i8
  %2816 = and i8 %2815, 1
  %2817 = xor i8 %2816, 1
  store i8 %2817, i8* %19, align 1
  %2818 = xor i32 %2810, %2809
  %2819 = lshr i32 %2818, 4
  %2820 = trunc i32 %2819 to i8
  %2821 = and i8 %2820, 1
  store i8 %2821, i8* %20, align 1
  %2822 = icmp eq i32 %2810, 0
  %2823 = zext i1 %2822 to i8
  store i8 %2823, i8* %21, align 1
  %2824 = lshr i32 %2810, 31
  %2825 = trunc i32 %2824 to i8
  store i8 %2825, i8* %22, align 1
  %2826 = lshr i32 %2809, 31
  %2827 = xor i32 %2824, %2826
  %2828 = add nuw nsw i32 %2827, %2826
  %2829 = icmp eq i32 %2828, 2
  %2830 = zext i1 %2829 to i8
  store i8 %2830, i8* %23, align 1
  %2831 = icmp ne i8 %2825, 0
  %2832 = xor i1 %2831, %2829
  %.v790 = select i1 %2832, i64 10, i64 109
  %2833 = add i64 %2804, %.v790
  store i64 %2833, i64* %3, align 8
  br i1 %2832, label %block_4a4832, label %block_.L_4a4895

block_4a4832:                                     ; preds = %block_.L_4a4828
  %2834 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %2834, i64* %RAX.i1763, align 8
  %2835 = add i64 %2834, 14136
  %2836 = add i64 %2833, 15
  store i64 %2836, i64* %3, align 8
  %2837 = inttoptr i64 %2835 to i64*
  %2838 = load i64, i64* %2837, align 8
  store i64 %2838, i64* %RAX.i1763, align 8
  %2839 = add i64 %2805, -12
  %2840 = add i64 %2833, 19
  store i64 %2840, i64* %3, align 8
  %2841 = inttoptr i64 %2839 to i32*
  %2842 = load i32, i32* %2841, align 4
  %2843 = sext i32 %2842 to i64
  store i64 %2843, i64* %RCX.i1692, align 8
  %2844 = shl nsw i64 %2843, 3
  %2845 = add i64 %2844, %2838
  %2846 = add i64 %2833, 23
  store i64 %2846, i64* %3, align 8
  %2847 = inttoptr i64 %2845 to i64*
  %2848 = load i64, i64* %2847, align 8
  store i64 %2848, i64* %RAX.i1763, align 8
  %2849 = add i64 %2833, 27
  store i64 %2849, i64* %3, align 8
  %2850 = load i32, i32* %2808, align 4
  %2851 = sext i32 %2850 to i64
  store i64 %2851, i64* %RCX.i1692, align 8
  %2852 = shl nsw i64 %2851, 3
  %2853 = add i64 %2852, %2848
  %2854 = add i64 %2833, 31
  store i64 %2854, i64* %3, align 8
  %2855 = inttoptr i64 %2853 to i64*
  %2856 = load i64, i64* %2855, align 8
  store i64 %2856, i64* %RAX.i1763, align 8
  %2857 = add i64 %2805, -48
  %2858 = add i64 %2833, 35
  store i64 %2858, i64* %3, align 8
  %2859 = inttoptr i64 %2857 to i32*
  %2860 = load i32, i32* %2859, align 4
  %2861 = sext i32 %2860 to i64
  store i64 %2861, i64* %RCX.i1692, align 8
  %2862 = shl nsw i64 %2861, 3
  %2863 = add i64 %2862, %2856
  %2864 = add i64 %2833, 39
  store i64 %2864, i64* %3, align 8
  %2865 = inttoptr i64 %2863 to i64*
  %2866 = load i64, i64* %2865, align 8
  store i64 %2866, i64* %RAX.i1763, align 8
  %2867 = add i64 %2805, -44
  %2868 = add i64 %2833, 43
  store i64 %2868, i64* %3, align 8
  %2869 = inttoptr i64 %2867 to i32*
  %2870 = load i32, i32* %2869, align 4
  %2871 = sext i32 %2870 to i64
  store i64 %2871, i64* %RCX.i1692, align 8
  %2872 = shl nsw i64 %2871, 2
  %2873 = add i64 %2872, %2866
  %2874 = add i64 %2833, 46
  store i64 %2874, i64* %3, align 8
  %2875 = inttoptr i64 %2873 to i32*
  %2876 = load i32, i32* %2875, align 4
  %2877 = zext i32 %2876 to i64
  store i64 %2877, i64* %RDX.i1805, align 8
  %2878 = load i64, i64* bitcast (%G_0x6cc5f8_type* @G_0x6cc5f8 to i64*), align 8
  store i64 %2878, i64* %RAX.i1763, align 8
  %2879 = add i64 %2833, 58
  store i64 %2879, i64* %3, align 8
  %2880 = load i32, i32* %2841, align 4
  %2881 = sext i32 %2880 to i64
  store i64 %2881, i64* %RCX.i1692, align 8
  %2882 = shl nsw i64 %2881, 3
  %2883 = add i64 %2882, %2878
  %2884 = add i64 %2833, 62
  store i64 %2884, i64* %3, align 8
  %2885 = inttoptr i64 %2883 to i64*
  %2886 = load i64, i64* %2885, align 8
  store i64 %2886, i64* %RAX.i1763, align 8
  %2887 = add i64 %2833, 66
  store i64 %2887, i64* %3, align 8
  %2888 = load i32, i32* %2808, align 4
  %2889 = sext i32 %2888 to i64
  store i64 %2889, i64* %RCX.i1692, align 8
  %2890 = shl nsw i64 %2889, 3
  %2891 = add i64 %2890, %2886
  %2892 = add i64 %2833, 70
  store i64 %2892, i64* %3, align 8
  %2893 = inttoptr i64 %2891 to i64*
  %2894 = load i64, i64* %2893, align 8
  store i64 %2894, i64* %RAX.i1763, align 8
  %2895 = add i64 %2833, 74
  store i64 %2895, i64* %3, align 8
  %2896 = load i32, i32* %2859, align 4
  %2897 = sext i32 %2896 to i64
  store i64 %2897, i64* %RCX.i1692, align 8
  %2898 = shl nsw i64 %2897, 3
  %2899 = add i64 %2898, %2894
  %2900 = add i64 %2833, 78
  store i64 %2900, i64* %3, align 8
  %2901 = inttoptr i64 %2899 to i64*
  %2902 = load i64, i64* %2901, align 8
  store i64 %2902, i64* %RAX.i1763, align 8
  %2903 = load i64, i64* %RBP.i, align 8
  %2904 = add i64 %2903, -44
  %2905 = add i64 %2833, 82
  store i64 %2905, i64* %3, align 8
  %2906 = inttoptr i64 %2904 to i32*
  %2907 = load i32, i32* %2906, align 4
  %2908 = sext i32 %2907 to i64
  store i64 %2908, i64* %RCX.i1692, align 8
  %2909 = shl nsw i64 %2908, 2
  %2910 = add i64 %2909, %2902
  %2911 = add i64 %2833, 85
  store i64 %2911, i64* %3, align 8
  %2912 = inttoptr i64 %2910 to i32*
  store i32 %2876, i32* %2912, align 4
  %2913 = load i64, i64* %RBP.i, align 8
  %2914 = add i64 %2913, -52
  %2915 = load i64, i64* %3, align 8
  %2916 = add i64 %2915, 3
  store i64 %2916, i64* %3, align 8
  %2917 = inttoptr i64 %2914 to i32*
  %2918 = load i32, i32* %2917, align 4
  %2919 = add i32 %2918, 1
  %2920 = zext i32 %2919 to i64
  store i64 %2920, i64* %RAX.i1763, align 8
  %2921 = icmp eq i32 %2918, -1
  %2922 = icmp eq i32 %2919, 0
  %2923 = or i1 %2921, %2922
  %2924 = zext i1 %2923 to i8
  store i8 %2924, i8* %18, align 1
  %2925 = and i32 %2919, 255
  %2926 = tail call i32 @llvm.ctpop.i32(i32 %2925)
  %2927 = trunc i32 %2926 to i8
  %2928 = and i8 %2927, 1
  %2929 = xor i8 %2928, 1
  store i8 %2929, i8* %19, align 1
  %2930 = xor i32 %2919, %2918
  %2931 = lshr i32 %2930, 4
  %2932 = trunc i32 %2931 to i8
  %2933 = and i8 %2932, 1
  store i8 %2933, i8* %20, align 1
  %2934 = zext i1 %2922 to i8
  store i8 %2934, i8* %21, align 1
  %2935 = lshr i32 %2919, 31
  %2936 = trunc i32 %2935 to i8
  store i8 %2936, i8* %22, align 1
  %2937 = lshr i32 %2918, 31
  %2938 = xor i32 %2935, %2937
  %2939 = add nuw nsw i32 %2938, %2935
  %2940 = icmp eq i32 %2939, 2
  %2941 = zext i1 %2940 to i8
  store i8 %2941, i8* %23, align 1
  %2942 = add i64 %2915, 9
  store i64 %2942, i64* %3, align 8
  store i32 %2919, i32* %2917, align 4
  %2943 = load i64, i64* %3, align 8
  %2944 = add i64 %2943, -104
  store i64 %2944, i64* %3, align 8
  br label %block_.L_4a4828

block_.L_4a4895:                                  ; preds = %block_.L_4a4828
  %2945 = add i64 %2805, -44
  %2946 = add i64 %2833, 8
  store i64 %2946, i64* %3, align 8
  %2947 = inttoptr i64 %2945 to i32*
  %2948 = load i32, i32* %2947, align 4
  %2949 = add i32 %2948, 1
  %2950 = zext i32 %2949 to i64
  store i64 %2950, i64* %RAX.i1763, align 8
  %2951 = icmp eq i32 %2948, -1
  %2952 = icmp eq i32 %2949, 0
  %2953 = or i1 %2951, %2952
  %2954 = zext i1 %2953 to i8
  store i8 %2954, i8* %18, align 1
  %2955 = and i32 %2949, 255
  %2956 = tail call i32 @llvm.ctpop.i32(i32 %2955)
  %2957 = trunc i32 %2956 to i8
  %2958 = and i8 %2957, 1
  %2959 = xor i8 %2958, 1
  store i8 %2959, i8* %19, align 1
  %2960 = xor i32 %2949, %2948
  %2961 = lshr i32 %2960, 4
  %2962 = trunc i32 %2961 to i8
  %2963 = and i8 %2962, 1
  store i8 %2963, i8* %20, align 1
  %2964 = zext i1 %2952 to i8
  store i8 %2964, i8* %21, align 1
  %2965 = lshr i32 %2949, 31
  %2966 = trunc i32 %2965 to i8
  store i8 %2966, i8* %22, align 1
  %2967 = lshr i32 %2948, 31
  %2968 = xor i32 %2965, %2967
  %2969 = add nuw nsw i32 %2968, %2965
  %2970 = icmp eq i32 %2969, 2
  %2971 = zext i1 %2970 to i8
  store i8 %2971, i8* %23, align 1
  %2972 = add i64 %2833, 14
  store i64 %2972, i64* %3, align 8
  store i32 %2949, i32* %2947, align 4
  %2973 = load i64, i64* %3, align 8
  %2974 = add i64 %2973, -140
  store i64 %2974, i64* %3, align 8
  br label %block_.L_4a4817

block_.L_4a48a8:                                  ; preds = %block_.L_4a4817
  %2975 = add i64 %2772, -48
  %2976 = add i64 %2800, 8
  store i64 %2976, i64* %3, align 8
  %2977 = inttoptr i64 %2975 to i32*
  %2978 = load i32, i32* %2977, align 4
  %2979 = add i32 %2978, 1
  %2980 = zext i32 %2979 to i64
  store i64 %2980, i64* %RAX.i1763, align 8
  %2981 = icmp eq i32 %2978, -1
  %2982 = icmp eq i32 %2979, 0
  %2983 = or i1 %2981, %2982
  %2984 = zext i1 %2983 to i8
  store i8 %2984, i8* %18, align 1
  %2985 = and i32 %2979, 255
  %2986 = tail call i32 @llvm.ctpop.i32(i32 %2985)
  %2987 = trunc i32 %2986 to i8
  %2988 = and i8 %2987, 1
  %2989 = xor i8 %2988, 1
  store i8 %2989, i8* %19, align 1
  %2990 = xor i32 %2979, %2978
  %2991 = lshr i32 %2990, 4
  %2992 = trunc i32 %2991 to i8
  %2993 = and i8 %2992, 1
  store i8 %2993, i8* %20, align 1
  %2994 = zext i1 %2982 to i8
  store i8 %2994, i8* %21, align 1
  %2995 = lshr i32 %2979, 31
  %2996 = trunc i32 %2995 to i8
  store i8 %2996, i8* %22, align 1
  %2997 = lshr i32 %2978, 31
  %2998 = xor i32 %2995, %2997
  %2999 = add nuw nsw i32 %2998, %2995
  %3000 = icmp eq i32 %2999, 2
  %3001 = zext i1 %3000 to i8
  store i8 %3001, i8* %23, align 1
  %3002 = add i64 %2800, 14
  store i64 %3002, i64* %3, align 8
  store i32 %2979, i32* %2977, align 4
  %3003 = load i64, i64* %3, align 8
  %3004 = add i64 %3003, -176
  store i64 %3004, i64* %3, align 8
  br label %block_.L_4a4806

block_.L_4a48bb:                                  ; preds = %block_.L_4a4806
  %3005 = add i64 %2739, -60
  %3006 = add i64 %2767, 7
  store i64 %3006, i64* %3, align 8
  %3007 = inttoptr i64 %3005 to i32*
  store i32 0, i32* %3007, align 4
  %.pre661 = load i64, i64* %3, align 8
  br label %block_.L_4a48c2

block_.L_4a48c2:                                  ; preds = %block_.L_4a4934, %block_.L_4a48bb
  %3008 = phi i64 [ %3265, %block_.L_4a4934 ], [ %.pre661, %block_.L_4a48bb ]
  %3009 = load i64, i64* %RBP.i, align 8
  %3010 = add i64 %3009, -60
  %3011 = add i64 %3008, 4
  store i64 %3011, i64* %3, align 8
  %3012 = inttoptr i64 %3010 to i32*
  %3013 = load i32, i32* %3012, align 4
  %3014 = add i32 %3013, -8
  %3015 = icmp ult i32 %3013, 8
  %3016 = zext i1 %3015 to i8
  store i8 %3016, i8* %18, align 1
  %3017 = and i32 %3014, 255
  %3018 = tail call i32 @llvm.ctpop.i32(i32 %3017)
  %3019 = trunc i32 %3018 to i8
  %3020 = and i8 %3019, 1
  %3021 = xor i8 %3020, 1
  store i8 %3021, i8* %19, align 1
  %3022 = xor i32 %3014, %3013
  %3023 = lshr i32 %3022, 4
  %3024 = trunc i32 %3023 to i8
  %3025 = and i8 %3024, 1
  store i8 %3025, i8* %20, align 1
  %3026 = icmp eq i32 %3014, 0
  %3027 = zext i1 %3026 to i8
  store i8 %3027, i8* %21, align 1
  %3028 = lshr i32 %3014, 31
  %3029 = trunc i32 %3028 to i8
  store i8 %3029, i8* %22, align 1
  %3030 = lshr i32 %3013, 31
  %3031 = xor i32 %3028, %3030
  %3032 = add nuw nsw i32 %3031, %3030
  %3033 = icmp eq i32 %3032, 2
  %3034 = zext i1 %3033 to i8
  store i8 %3034, i8* %23, align 1
  %3035 = icmp ne i8 %3029, 0
  %3036 = xor i1 %3035, %3033
  %.v866 = select i1 %3036, i64 10, i64 133
  %3037 = add i64 %3008, %.v866
  store i64 %3037, i64* %3, align 8
  br i1 %3036, label %block_4a48cc, label %block_.L_4a4947

block_4a48cc:                                     ; preds = %block_.L_4a48c2
  %3038 = add i64 %3009, -56
  %3039 = add i64 %3037, 7
  store i64 %3039, i64* %3, align 8
  %3040 = inttoptr i64 %3038 to i32*
  store i32 0, i32* %3040, align 4
  %.pre662 = load i64, i64* %3, align 8
  br label %block_.L_4a48d3

block_.L_4a48d3:                                  ; preds = %block_4a48dd, %block_4a48cc
  %3041 = phi i64 [ %3235, %block_4a48dd ], [ %.pre662, %block_4a48cc ]
  %3042 = load i64, i64* %RBP.i, align 8
  %3043 = add i64 %3042, -56
  %3044 = add i64 %3041, 4
  store i64 %3044, i64* %3, align 8
  %3045 = inttoptr i64 %3043 to i32*
  %3046 = load i32, i32* %3045, align 4
  %3047 = add i32 %3046, -8
  %3048 = icmp ult i32 %3046, 8
  %3049 = zext i1 %3048 to i8
  store i8 %3049, i8* %18, align 1
  %3050 = and i32 %3047, 255
  %3051 = tail call i32 @llvm.ctpop.i32(i32 %3050)
  %3052 = trunc i32 %3051 to i8
  %3053 = and i8 %3052, 1
  %3054 = xor i8 %3053, 1
  store i8 %3054, i8* %19, align 1
  %3055 = xor i32 %3047, %3046
  %3056 = lshr i32 %3055, 4
  %3057 = trunc i32 %3056 to i8
  %3058 = and i8 %3057, 1
  store i8 %3058, i8* %20, align 1
  %3059 = icmp eq i32 %3047, 0
  %3060 = zext i1 %3059 to i8
  store i8 %3060, i8* %21, align 1
  %3061 = lshr i32 %3047, 31
  %3062 = trunc i32 %3061 to i8
  store i8 %3062, i8* %22, align 1
  %3063 = lshr i32 %3046, 31
  %3064 = xor i32 %3061, %3063
  %3065 = add nuw nsw i32 %3064, %3063
  %3066 = icmp eq i32 %3065, 2
  %3067 = zext i1 %3066 to i8
  store i8 %3067, i8* %23, align 1
  %3068 = icmp ne i8 %3062, 0
  %3069 = xor i1 %3068, %3066
  %.v788 = select i1 %3069, i64 10, i64 97
  %3070 = add i64 %3041, %.v788
  store i64 %3070, i64* %3, align 8
  br i1 %3069, label %block_4a48dd, label %block_.L_4a4934

block_4a48dd:                                     ; preds = %block_.L_4a48d3
  %3071 = add i64 %3042, -464
  store i64 %3071, i64* %RAX.i1763, align 8
  %3072 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %3072, i64* %RCX.i1692, align 8
  %3073 = add i64 %3072, 6424
  %3074 = add i64 %3070, 22
  store i64 %3074, i64* %3, align 8
  %3075 = inttoptr i64 %3073 to i64*
  %3076 = load i64, i64* %3075, align 8
  store i64 %3076, i64* %RCX.i1692, align 8
  %3077 = add i64 %3042, -496
  %3078 = add i64 %3070, 28
  store i64 %3078, i64* %3, align 8
  %3079 = inttoptr i64 %3077 to i32*
  %3080 = load i32, i32* %3079, align 4
  %3081 = zext i32 %3080 to i64
  store i64 %3081, i64* %RDX.i1805, align 8
  %3082 = add i64 %3042, -60
  %3083 = add i64 %3070, 31
  store i64 %3083, i64* %3, align 8
  %3084 = inttoptr i64 %3082 to i32*
  %3085 = load i32, i32* %3084, align 4
  %3086 = add i32 %3085, %3080
  %3087 = zext i32 %3086 to i64
  store i64 %3087, i64* %RDX.i1805, align 8
  %3088 = icmp ult i32 %3086, %3080
  %3089 = icmp ult i32 %3086, %3085
  %3090 = or i1 %3088, %3089
  %3091 = zext i1 %3090 to i8
  store i8 %3091, i8* %18, align 1
  %3092 = and i32 %3086, 255
  %3093 = tail call i32 @llvm.ctpop.i32(i32 %3092)
  %3094 = trunc i32 %3093 to i8
  %3095 = and i8 %3094, 1
  %3096 = xor i8 %3095, 1
  store i8 %3096, i8* %19, align 1
  %3097 = xor i32 %3085, %3080
  %3098 = xor i32 %3097, %3086
  %3099 = lshr i32 %3098, 4
  %3100 = trunc i32 %3099 to i8
  %3101 = and i8 %3100, 1
  store i8 %3101, i8* %20, align 1
  %3102 = icmp eq i32 %3086, 0
  %3103 = zext i1 %3102 to i8
  store i8 %3103, i8* %21, align 1
  %3104 = lshr i32 %3086, 31
  %3105 = trunc i32 %3104 to i8
  store i8 %3105, i8* %22, align 1
  %3106 = lshr i32 %3080, 31
  %3107 = lshr i32 %3085, 31
  %3108 = xor i32 %3104, %3106
  %3109 = xor i32 %3104, %3107
  %3110 = add nuw nsw i32 %3108, %3109
  %3111 = icmp eq i32 %3110, 2
  %3112 = zext i1 %3111 to i8
  store i8 %3112, i8* %23, align 1
  %3113 = sext i32 %3086 to i64
  store i64 %3113, i64* %RSI.i1889, align 8
  %3114 = shl nsw i64 %3113, 3
  %3115 = add i64 %3076, %3114
  %3116 = add i64 %3070, 38
  store i64 %3116, i64* %3, align 8
  %3117 = inttoptr i64 %3115 to i64*
  %3118 = load i64, i64* %3117, align 8
  store i64 %3118, i64* %RCX.i1692, align 8
  %3119 = add i64 %3042, -492
  %3120 = add i64 %3070, 44
  store i64 %3120, i64* %3, align 8
  %3121 = inttoptr i64 %3119 to i32*
  %3122 = load i32, i32* %3121, align 4
  %3123 = zext i32 %3122 to i64
  store i64 %3123, i64* %RDX.i1805, align 8
  %3124 = add i64 %3070, 47
  store i64 %3124, i64* %3, align 8
  %3125 = load i32, i32* %3045, align 4
  %3126 = add i32 %3125, %3122
  %3127 = zext i32 %3126 to i64
  store i64 %3127, i64* %RDX.i1805, align 8
  %3128 = icmp ult i32 %3126, %3122
  %3129 = icmp ult i32 %3126, %3125
  %3130 = or i1 %3128, %3129
  %3131 = zext i1 %3130 to i8
  store i8 %3131, i8* %18, align 1
  %3132 = and i32 %3126, 255
  %3133 = tail call i32 @llvm.ctpop.i32(i32 %3132)
  %3134 = trunc i32 %3133 to i8
  %3135 = and i8 %3134, 1
  %3136 = xor i8 %3135, 1
  store i8 %3136, i8* %19, align 1
  %3137 = xor i32 %3125, %3122
  %3138 = xor i32 %3137, %3126
  %3139 = lshr i32 %3138, 4
  %3140 = trunc i32 %3139 to i8
  %3141 = and i8 %3140, 1
  store i8 %3141, i8* %20, align 1
  %3142 = icmp eq i32 %3126, 0
  %3143 = zext i1 %3142 to i8
  store i8 %3143, i8* %21, align 1
  %3144 = lshr i32 %3126, 31
  %3145 = trunc i32 %3144 to i8
  store i8 %3145, i8* %22, align 1
  %3146 = lshr i32 %3122, 31
  %3147 = lshr i32 %3125, 31
  %3148 = xor i32 %3144, %3146
  %3149 = xor i32 %3144, %3147
  %3150 = add nuw nsw i32 %3148, %3149
  %3151 = icmp eq i32 %3150, 2
  %3152 = zext i1 %3151 to i8
  store i8 %3152, i8* %23, align 1
  %3153 = sext i32 %3126 to i64
  store i64 %3153, i64* %RSI.i1889, align 8
  %3154 = shl nsw i64 %3153, 1
  %3155 = add i64 %3118, %3154
  %3156 = add i64 %3070, 54
  store i64 %3156, i64* %3, align 8
  %3157 = inttoptr i64 %3155 to i16*
  %3158 = load i16, i16* %3157, align 2
  store i16 %3158, i16* %DI.i3531, align 2
  %3159 = load i64, i64* %RBP.i, align 8
  %3160 = add i64 %3159, -60
  %3161 = add i64 %3070, 58
  store i64 %3161, i64* %3, align 8
  %3162 = inttoptr i64 %3160 to i32*
  %3163 = load i32, i32* %3162, align 4
  %3164 = sext i32 %3163 to i64
  %3165 = shl nsw i64 %3164, 4
  store i64 %3165, i64* %RCX.i1692, align 8
  %3166 = load i64, i64* %RAX.i1763, align 8
  %3167 = add i64 %3165, %3166
  store i64 %3167, i64* %RAX.i1763, align 8
  %3168 = icmp ult i64 %3167, %3166
  %3169 = icmp ult i64 %3167, %3165
  %3170 = or i1 %3168, %3169
  %3171 = zext i1 %3170 to i8
  store i8 %3171, i8* %18, align 1
  %3172 = trunc i64 %3167 to i32
  %3173 = and i32 %3172, 255
  %3174 = tail call i32 @llvm.ctpop.i32(i32 %3173)
  %3175 = trunc i32 %3174 to i8
  %3176 = and i8 %3175, 1
  %3177 = xor i8 %3176, 1
  store i8 %3177, i8* %19, align 1
  %3178 = xor i64 %3165, %3166
  %3179 = xor i64 %3178, %3167
  %3180 = lshr i64 %3179, 4
  %3181 = trunc i64 %3180 to i8
  %3182 = and i8 %3181, 1
  store i8 %3182, i8* %20, align 1
  %3183 = icmp eq i64 %3167, 0
  %3184 = zext i1 %3183 to i8
  store i8 %3184, i8* %21, align 1
  %3185 = lshr i64 %3167, 63
  %3186 = trunc i64 %3185 to i8
  store i8 %3186, i8* %22, align 1
  %3187 = lshr i64 %3166, 63
  %3188 = lshr i64 %3164, 59
  %3189 = and i64 %3188, 1
  %3190 = xor i64 %3185, %3187
  %3191 = xor i64 %3185, %3189
  %3192 = add nuw nsw i64 %3190, %3191
  %3193 = icmp eq i64 %3192, 2
  %3194 = zext i1 %3193 to i8
  store i8 %3194, i8* %23, align 1
  %3195 = add i64 %3159, -56
  %3196 = add i64 %3070, 69
  store i64 %3196, i64* %3, align 8
  %3197 = inttoptr i64 %3195 to i32*
  %3198 = load i32, i32* %3197, align 4
  %3199 = sext i32 %3198 to i64
  store i64 %3199, i64* %RCX.i1692, align 8
  %3200 = shl nsw i64 %3199, 1
  %3201 = add i64 %3200, %3167
  %3202 = add i64 %3070, 73
  store i64 %3202, i64* %3, align 8
  %3203 = inttoptr i64 %3201 to i16*
  store i16 %3158, i16* %3203, align 2
  %3204 = load i64, i64* %RBP.i, align 8
  %3205 = add i64 %3204, -56
  %3206 = load i64, i64* %3, align 8
  %3207 = add i64 %3206, 3
  store i64 %3207, i64* %3, align 8
  %3208 = inttoptr i64 %3205 to i32*
  %3209 = load i32, i32* %3208, align 4
  %3210 = add i32 %3209, 1
  %3211 = zext i32 %3210 to i64
  store i64 %3211, i64* %RAX.i1763, align 8
  %3212 = icmp eq i32 %3209, -1
  %3213 = icmp eq i32 %3210, 0
  %3214 = or i1 %3212, %3213
  %3215 = zext i1 %3214 to i8
  store i8 %3215, i8* %18, align 1
  %3216 = and i32 %3210, 255
  %3217 = tail call i32 @llvm.ctpop.i32(i32 %3216)
  %3218 = trunc i32 %3217 to i8
  %3219 = and i8 %3218, 1
  %3220 = xor i8 %3219, 1
  store i8 %3220, i8* %19, align 1
  %3221 = xor i32 %3210, %3209
  %3222 = lshr i32 %3221, 4
  %3223 = trunc i32 %3222 to i8
  %3224 = and i8 %3223, 1
  store i8 %3224, i8* %20, align 1
  %3225 = zext i1 %3213 to i8
  store i8 %3225, i8* %21, align 1
  %3226 = lshr i32 %3210, 31
  %3227 = trunc i32 %3226 to i8
  store i8 %3227, i8* %22, align 1
  %3228 = lshr i32 %3209, 31
  %3229 = xor i32 %3226, %3228
  %3230 = add nuw nsw i32 %3229, %3226
  %3231 = icmp eq i32 %3230, 2
  %3232 = zext i1 %3231 to i8
  store i8 %3232, i8* %23, align 1
  %3233 = add i64 %3206, 9
  store i64 %3233, i64* %3, align 8
  store i32 %3210, i32* %3208, align 4
  %3234 = load i64, i64* %3, align 8
  %3235 = add i64 %3234, -92
  store i64 %3235, i64* %3, align 8
  br label %block_.L_4a48d3

block_.L_4a4934:                                  ; preds = %block_.L_4a48d3
  %3236 = add i64 %3042, -60
  %3237 = add i64 %3070, 8
  store i64 %3237, i64* %3, align 8
  %3238 = inttoptr i64 %3236 to i32*
  %3239 = load i32, i32* %3238, align 4
  %3240 = add i32 %3239, 1
  %3241 = zext i32 %3240 to i64
  store i64 %3241, i64* %RAX.i1763, align 8
  %3242 = icmp eq i32 %3239, -1
  %3243 = icmp eq i32 %3240, 0
  %3244 = or i1 %3242, %3243
  %3245 = zext i1 %3244 to i8
  store i8 %3245, i8* %18, align 1
  %3246 = and i32 %3240, 255
  %3247 = tail call i32 @llvm.ctpop.i32(i32 %3246)
  %3248 = trunc i32 %3247 to i8
  %3249 = and i8 %3248, 1
  %3250 = xor i8 %3249, 1
  store i8 %3250, i8* %19, align 1
  %3251 = xor i32 %3240, %3239
  %3252 = lshr i32 %3251, 4
  %3253 = trunc i32 %3252 to i8
  %3254 = and i8 %3253, 1
  store i8 %3254, i8* %20, align 1
  %3255 = zext i1 %3243 to i8
  store i8 %3255, i8* %21, align 1
  %3256 = lshr i32 %3240, 31
  %3257 = trunc i32 %3256 to i8
  store i8 %3257, i8* %22, align 1
  %3258 = lshr i32 %3239, 31
  %3259 = xor i32 %3256, %3258
  %3260 = add nuw nsw i32 %3259, %3256
  %3261 = icmp eq i32 %3260, 2
  %3262 = zext i1 %3261 to i8
  store i8 %3262, i8* %23, align 1
  %3263 = add i64 %3070, 14
  store i64 %3263, i64* %3, align 8
  store i32 %3240, i32* %3238, align 4
  %3264 = load i64, i64* %3, align 8
  %3265 = add i64 %3264, -128
  store i64 %3265, i64* %3, align 8
  br label %block_.L_4a48c2

block_.L_4a4947:                                  ; preds = %block_.L_4a48c2
  %3266 = add i64 %3009, -72
  %3267 = add i64 %3037, 3
  store i64 %3267, i64* %3, align 8
  %3268 = inttoptr i64 %3266 to i32*
  %3269 = load i32, i32* %3268, align 4
  %3270 = zext i32 %3269 to i64
  store i64 %3270, i64* %RAX.i1763, align 8
  %3271 = add i64 %3009, -76
  %3272 = add i64 %3037, 6
  store i64 %3272, i64* %3, align 8
  %3273 = inttoptr i64 %3271 to i32*
  store i32 %3269, i32* %3273, align 4
  %3274 = load i64, i64* %RBP.i, align 8
  %3275 = add i64 %3274, -472
  %3276 = load i64, i64* %3, align 8
  %3277 = add i64 %3276, 8
  store i64 %3277, i64* %3, align 8
  %3278 = inttoptr i64 %3275 to i64*
  %3279 = load i64, i64* %3278, align 8
  store i64 %3279, i64* %54, align 1
  store double 0.000000e+00, double* %1228, align 1
  %3280 = add i64 %3274, -520
  %3281 = add i64 %3276, 16
  store i64 %3281, i64* %3, align 8
  %3282 = inttoptr i64 %3280 to i64*
  store i64 %3279, i64* %3282, align 8
  %3283 = load i64, i64* %RBP.i, align 8
  %3284 = add i64 %3283, -36
  %3285 = load i64, i64* %3, align 8
  %3286 = add i64 %3285, 3
  store i64 %3286, i64* %3, align 8
  %3287 = inttoptr i64 %3284 to i32*
  %3288 = load i32, i32* %3287, align 4
  %3289 = zext i32 %3288 to i64
  store i64 %3289, i64* %RAX.i1763, align 8
  %3290 = add i64 %3283, -40
  %3291 = add i64 %3285, 6
  store i64 %3291, i64* %3, align 8
  %3292 = inttoptr i64 %3290 to i32*
  store i32 %3288, i32* %3292, align 4
  %.pre665 = load i64, i64* %3, align 8
  br label %block_.L_4a4963

block_.L_4a4963:                                  ; preds = %block_.L_4a4947, %routine_ucomisd__xmm0___xmm1.exit6901
  %3293 = phi i64 [ %.pre665, %block_.L_4a4947 ], [ %2727, %routine_ucomisd__xmm0___xmm1.exit6901 ]
  store i8 0, i8* %AL.i6276, align 1
  %3294 = add i64 %3293, -29347
  %3295 = add i64 %3293, 7
  %3296 = load i64, i64* %6, align 8
  %3297 = add i64 %3296, -8
  %3298 = inttoptr i64 %3297 to i64*
  store i64 %3295, i64* %3298, align 8
  store i64 %3297, i64* %6, align 8
  store i64 %3294, i64* %3, align 8
  %call2_4a4965 = tail call %struct.Memory* @sub_49d6c0.reset_coding_state_cs_cm(%struct.State* nonnull %0, i64 %3294, %struct.Memory* %2726)
  %3299 = load i64, i64* %3, align 8
  %3300 = add i64 %3299, 5528
  br label %block_.L_4a5f02

block_.L_4a4976:                                  ; preds = %block_.L_4a4976.preheader, %block_.L_4a4bb4
  %3301 = phi i64 [ %4558, %block_.L_4a4bb4 ], [ %.pre658, %block_.L_4a4976.preheader ]
  %3302 = load i64, i64* %RBP.i, align 8
  %3303 = add i64 %3302, -48
  %3304 = add i64 %3301, 4
  store i64 %3304, i64* %3, align 8
  %3305 = inttoptr i64 %3303 to i32*
  %3306 = load i32, i32* %3305, align 4
  %3307 = add i32 %3306, -8
  %3308 = icmp ult i32 %3306, 8
  %3309 = zext i1 %3308 to i8
  store i8 %3309, i8* %18, align 1
  %3310 = and i32 %3307, 255
  %3311 = tail call i32 @llvm.ctpop.i32(i32 %3310)
  %3312 = trunc i32 %3311 to i8
  %3313 = and i8 %3312, 1
  %3314 = xor i8 %3313, 1
  store i8 %3314, i8* %19, align 1
  %3315 = xor i32 %3307, %3306
  %3316 = lshr i32 %3315, 4
  %3317 = trunc i32 %3316 to i8
  %3318 = and i8 %3317, 1
  store i8 %3318, i8* %20, align 1
  %3319 = icmp eq i32 %3307, 0
  %3320 = zext i1 %3319 to i8
  store i8 %3320, i8* %21, align 1
  %3321 = lshr i32 %3307, 31
  %3322 = trunc i32 %3321 to i8
  store i8 %3322, i8* %22, align 1
  %3323 = lshr i32 %3306, 31
  %3324 = xor i32 %3321, %3323
  %3325 = add nuw nsw i32 %3324, %3323
  %3326 = icmp eq i32 %3325, 2
  %3327 = zext i1 %3326 to i8
  store i8 %3327, i8* %23, align 1
  %3328 = icmp ne i8 %3322, 0
  %3329 = xor i1 %3328, %3326
  %.v845 = select i1 %3329, i64 10, i64 593
  %3330 = add i64 %3301, %.v845
  store i64 %3330, i64* %3, align 8
  br i1 %3329, label %block_4a4980, label %block_.L_4a4bc7

block_4a4980:                                     ; preds = %block_.L_4a4976
  %3331 = add i64 %3302, -44
  %3332 = add i64 %3330, 7
  store i64 %3332, i64* %3, align 8
  %3333 = inttoptr i64 %3331 to i32*
  store i32 0, i32* %3333, align 4
  %.pre757 = load i64, i64* %3, align 8
  br label %block_.L_4a4987

block_.L_4a4987:                                  ; preds = %block_4a4991, %block_4a4980
  %3334 = phi i64 [ %4528, %block_4a4991 ], [ %.pre757, %block_4a4980 ]
  %3335 = load i64, i64* %RBP.i, align 8
  %3336 = add i64 %3335, -44
  %3337 = add i64 %3334, 4
  store i64 %3337, i64* %3, align 8
  %3338 = inttoptr i64 %3336 to i32*
  %3339 = load i32, i32* %3338, align 4
  %3340 = add i32 %3339, -8
  %3341 = icmp ult i32 %3339, 8
  %3342 = zext i1 %3341 to i8
  store i8 %3342, i8* %18, align 1
  %3343 = and i32 %3340, 255
  %3344 = tail call i32 @llvm.ctpop.i32(i32 %3343)
  %3345 = trunc i32 %3344 to i8
  %3346 = and i8 %3345, 1
  %3347 = xor i8 %3346, 1
  store i8 %3347, i8* %19, align 1
  %3348 = xor i32 %3340, %3339
  %3349 = lshr i32 %3348, 4
  %3350 = trunc i32 %3349 to i8
  %3351 = and i8 %3350, 1
  store i8 %3351, i8* %20, align 1
  %3352 = icmp eq i32 %3340, 0
  %3353 = zext i1 %3352 to i8
  store i8 %3353, i8* %21, align 1
  %3354 = lshr i32 %3340, 31
  %3355 = trunc i32 %3354 to i8
  store i8 %3355, i8* %22, align 1
  %3356 = lshr i32 %3339, 31
  %3357 = xor i32 %3354, %3356
  %3358 = add nuw nsw i32 %3357, %3356
  %3359 = icmp eq i32 %3358, 2
  %3360 = zext i1 %3359 to i8
  store i8 %3360, i8* %23, align 1
  %3361 = icmp ne i8 %3355, 0
  %3362 = xor i1 %3361, %3359
  %.v808 = select i1 %3362, i64 10, i64 557
  %3363 = add i64 %3334, %.v808
  store i64 %3363, i64* %3, align 8
  br i1 %3362, label %block_4a4991, label %block_.L_4a4bb4

block_4a4991:                                     ; preds = %block_.L_4a4987
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX.i1763, align 8
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RCX.i1692, align 8
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RDX.i1805, align 8
  %3364 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %3364, i64* %RSI.i1889, align 8
  %3365 = add i64 %3363, 41
  store i64 %3365, i64* %3, align 8
  %3366 = inttoptr i64 %3364 to i64*
  %3367 = load i64, i64* %3366, align 8
  store i64 %3367, i64* %RSI.i1889, align 8
  %3368 = add i64 %3335, -504
  %3369 = add i64 %3363, 47
  store i64 %3369, i64* %3, align 8
  %3370 = inttoptr i64 %3368 to i32*
  %3371 = load i32, i32* %3370, align 4
  %3372 = zext i32 %3371 to i64
  store i64 %3372, i64* %RDI.i2141, align 8
  %3373 = add i64 %3335, -48
  %3374 = add i64 %3363, 50
  store i64 %3374, i64* %3, align 8
  %3375 = inttoptr i64 %3373 to i32*
  %3376 = load i32, i32* %3375, align 4
  %3377 = add i32 %3376, %3371
  %3378 = zext i32 %3377 to i64
  store i64 %3378, i64* %RDI.i2141, align 8
  %3379 = icmp ult i32 %3377, %3371
  %3380 = icmp ult i32 %3377, %3376
  %3381 = or i1 %3379, %3380
  %3382 = zext i1 %3381 to i8
  store i8 %3382, i8* %18, align 1
  %3383 = and i32 %3377, 255
  %3384 = tail call i32 @llvm.ctpop.i32(i32 %3383)
  %3385 = trunc i32 %3384 to i8
  %3386 = and i8 %3385, 1
  %3387 = xor i8 %3386, 1
  store i8 %3387, i8* %19, align 1
  %3388 = xor i32 %3376, %3371
  %3389 = xor i32 %3388, %3377
  %3390 = lshr i32 %3389, 4
  %3391 = trunc i32 %3390 to i8
  %3392 = and i8 %3391, 1
  store i8 %3392, i8* %20, align 1
  %3393 = icmp eq i32 %3377, 0
  %3394 = zext i1 %3393 to i8
  store i8 %3394, i8* %21, align 1
  %3395 = lshr i32 %3377, 31
  %3396 = trunc i32 %3395 to i8
  store i8 %3396, i8* %22, align 1
  %3397 = lshr i32 %3371, 31
  %3398 = lshr i32 %3376, 31
  %3399 = xor i32 %3395, %3397
  %3400 = xor i32 %3395, %3398
  %3401 = add nuw nsw i32 %3399, %3400
  %3402 = icmp eq i32 %3401, 2
  %3403 = zext i1 %3402 to i8
  store i8 %3403, i8* %23, align 1
  %3404 = sext i32 %3377 to i64
  store i64 %3404, i64* %26, align 8
  %3405 = shl nsw i64 %3404, 3
  %3406 = add i64 %3367, %3405
  %3407 = add i64 %3363, 57
  store i64 %3407, i64* %3, align 8
  %3408 = inttoptr i64 %3406 to i64*
  %3409 = load i64, i64* %3408, align 8
  store i64 %3409, i64* %RSI.i1889, align 8
  %3410 = add i64 %3335, -500
  %3411 = add i64 %3363, 63
  store i64 %3411, i64* %3, align 8
  %3412 = inttoptr i64 %3410 to i32*
  %3413 = load i32, i32* %3412, align 4
  %3414 = zext i32 %3413 to i64
  store i64 %3414, i64* %RDI.i2141, align 8
  %3415 = add i64 %3363, 66
  store i64 %3415, i64* %3, align 8
  %3416 = load i32, i32* %3338, align 4
  %3417 = add i32 %3416, %3413
  %3418 = zext i32 %3417 to i64
  store i64 %3418, i64* %RDI.i2141, align 8
  %3419 = icmp ult i32 %3417, %3413
  %3420 = icmp ult i32 %3417, %3416
  %3421 = or i1 %3419, %3420
  %3422 = zext i1 %3421 to i8
  store i8 %3422, i8* %18, align 1
  %3423 = and i32 %3417, 255
  %3424 = tail call i32 @llvm.ctpop.i32(i32 %3423)
  %3425 = trunc i32 %3424 to i8
  %3426 = and i8 %3425, 1
  %3427 = xor i8 %3426, 1
  store i8 %3427, i8* %19, align 1
  %3428 = xor i32 %3416, %3413
  %3429 = xor i32 %3428, %3417
  %3430 = lshr i32 %3429, 4
  %3431 = trunc i32 %3430 to i8
  %3432 = and i8 %3431, 1
  store i8 %3432, i8* %20, align 1
  %3433 = icmp eq i32 %3417, 0
  %3434 = zext i1 %3433 to i8
  store i8 %3434, i8* %21, align 1
  %3435 = lshr i32 %3417, 31
  %3436 = trunc i32 %3435 to i8
  store i8 %3436, i8* %22, align 1
  %3437 = lshr i32 %3413, 31
  %3438 = lshr i32 %3416, 31
  %3439 = xor i32 %3435, %3437
  %3440 = xor i32 %3435, %3438
  %3441 = add nuw nsw i32 %3439, %3440
  %3442 = icmp eq i32 %3441, 2
  %3443 = zext i1 %3442 to i8
  store i8 %3443, i8* %23, align 1
  %3444 = sext i32 %3417 to i64
  store i64 %3444, i64* %26, align 8
  %3445 = shl nsw i64 %3444, 1
  %3446 = add i64 %3409, %3445
  %3447 = add i64 %3363, 74
  store i64 %3447, i64* %3, align 8
  %3448 = inttoptr i64 %3446 to i16*
  %3449 = load i16, i16* %3448, align 2
  %3450 = zext i16 %3449 to i64
  store i64 %3450, i64* %RDI.i2141, align 8
  %3451 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %3452 = add i64 %3451, 8504
  store i64 %3452, i64* %RSI.i1889, align 8
  %3453 = icmp ugt i64 %3451, -8505
  %3454 = zext i1 %3453 to i8
  store i8 %3454, i8* %18, align 1
  %3455 = trunc i64 %3452 to i32
  %3456 = and i32 %3455, 255
  %3457 = tail call i32 @llvm.ctpop.i32(i32 %3456)
  %3458 = trunc i32 %3457 to i8
  %3459 = and i8 %3458, 1
  %3460 = xor i8 %3459, 1
  store i8 %3460, i8* %19, align 1
  %3461 = xor i64 %3451, 16
  %3462 = xor i64 %3461, %3452
  %3463 = lshr i64 %3462, 4
  %3464 = trunc i64 %3463 to i8
  %3465 = and i8 %3464, 1
  store i8 %3465, i8* %20, align 1
  %3466 = icmp eq i64 %3452, 0
  %3467 = zext i1 %3466 to i8
  store i8 %3467, i8* %21, align 1
  %3468 = lshr i64 %3452, 63
  %3469 = trunc i64 %3468 to i8
  store i8 %3469, i8* %22, align 1
  %3470 = lshr i64 %3451, 63
  %3471 = xor i64 %3468, %3470
  %3472 = add nuw nsw i64 %3471, %3468
  %3473 = icmp eq i64 %3472, 2
  %3474 = zext i1 %3473 to i8
  store i8 %3474, i8* %23, align 1
  %3475 = load i64, i64* %RBP.i, align 8
  %3476 = add i64 %3475, -632
  %3477 = add i64 %3363, 96
  store i64 %3477, i64* %3, align 8
  %3478 = inttoptr i64 %3476 to i32*
  %3479 = load i32, i32* %3478, align 4
  %3480 = sext i32 %3479 to i64
  %3481 = shl nsw i64 %3480, 9
  store i64 %3481, i64* %26, align 8
  %3482 = add i64 %3481, %3452
  store i64 %3482, i64* %RSI.i1889, align 8
  %3483 = icmp ult i64 %3482, %3452
  %3484 = icmp ult i64 %3482, %3481
  %3485 = or i1 %3483, %3484
  %3486 = zext i1 %3485 to i8
  store i8 %3486, i8* %18, align 1
  %3487 = trunc i64 %3482 to i32
  %3488 = and i32 %3487, 255
  %3489 = tail call i32 @llvm.ctpop.i32(i32 %3488)
  %3490 = trunc i32 %3489 to i8
  %3491 = and i8 %3490, 1
  %3492 = xor i8 %3491, 1
  store i8 %3492, i8* %19, align 1
  %3493 = xor i64 %3452, %3482
  %3494 = lshr i64 %3493, 4
  %3495 = trunc i64 %3494 to i8
  %3496 = and i8 %3495, 1
  store i8 %3496, i8* %20, align 1
  %3497 = icmp eq i64 %3482, 0
  %3498 = zext i1 %3497 to i8
  store i8 %3498, i8* %21, align 1
  %3499 = lshr i64 %3482, 63
  %3500 = trunc i64 %3499 to i8
  store i8 %3500, i8* %22, align 1
  %3501 = lshr i64 %3480, 54
  %3502 = and i64 %3501, 1
  %3503 = xor i64 %3499, %3468
  %3504 = xor i64 %3499, %3502
  %3505 = add nuw nsw i64 %3503, %3504
  %3506 = icmp eq i64 %3505, 2
  %3507 = zext i1 %3506 to i8
  store i8 %3507, i8* %23, align 1
  %3508 = add i64 %3475, -484
  %3509 = add i64 %3363, 110
  store i64 %3509, i64* %3, align 8
  %3510 = inttoptr i64 %3508 to i32*
  %3511 = load i32, i32* %3510, align 4
  %3512 = zext i32 %3511 to i64
  store i64 %3512, i64* %R9.i, align 8
  %3513 = add i64 %3475, -44
  %3514 = add i64 %3363, 114
  store i64 %3514, i64* %3, align 8
  %3515 = inttoptr i64 %3513 to i32*
  %3516 = load i32, i32* %3515, align 4
  %3517 = add i32 %3516, %3511
  %3518 = zext i32 %3517 to i64
  store i64 %3518, i64* %R9.i, align 8
  %3519 = sext i32 %3517 to i64
  %3520 = shl nsw i64 %3519, 5
  store i64 %3520, i64* %26, align 8
  %3521 = load i64, i64* %RSI.i1889, align 8
  %3522 = add i64 %3520, %3521
  store i64 %3522, i64* %RSI.i1889, align 8
  %3523 = icmp ult i64 %3522, %3521
  %3524 = icmp ult i64 %3522, %3520
  %3525 = or i1 %3523, %3524
  %3526 = zext i1 %3525 to i8
  store i8 %3526, i8* %18, align 1
  %3527 = trunc i64 %3522 to i32
  %3528 = and i32 %3527, 255
  %3529 = tail call i32 @llvm.ctpop.i32(i32 %3528)
  %3530 = trunc i32 %3529 to i8
  %3531 = and i8 %3530, 1
  %3532 = xor i8 %3531, 1
  store i8 %3532, i8* %19, align 1
  %3533 = xor i64 %3521, %3522
  %3534 = lshr i64 %3533, 4
  %3535 = trunc i64 %3534 to i8
  %3536 = and i8 %3535, 1
  store i8 %3536, i8* %20, align 1
  %3537 = icmp eq i64 %3522, 0
  %3538 = zext i1 %3537 to i8
  store i8 %3538, i8* %21, align 1
  %3539 = lshr i64 %3522, 63
  %3540 = trunc i64 %3539 to i8
  store i8 %3540, i8* %22, align 1
  %3541 = lshr i64 %3521, 63
  %3542 = lshr i64 %3519, 58
  %3543 = and i64 %3542, 1
  %3544 = xor i64 %3539, %3541
  %3545 = xor i64 %3539, %3543
  %3546 = add nuw nsw i64 %3544, %3545
  %3547 = icmp eq i64 %3546, 2
  %3548 = zext i1 %3547 to i8
  store i8 %3548, i8* %23, align 1
  %3549 = load i64, i64* %RBP.i, align 8
  %3550 = add i64 %3549, -488
  %3551 = add i64 %3363, 131
  store i64 %3551, i64* %3, align 8
  %3552 = inttoptr i64 %3550 to i32*
  %3553 = load i32, i32* %3552, align 4
  %3554 = zext i32 %3553 to i64
  store i64 %3554, i64* %R9.i, align 8
  %3555 = add i64 %3549, -48
  %3556 = add i64 %3363, 135
  store i64 %3556, i64* %3, align 8
  %3557 = inttoptr i64 %3555 to i32*
  %3558 = load i32, i32* %3557, align 4
  %3559 = add i32 %3558, %3553
  %3560 = zext i32 %3559 to i64
  store i64 %3560, i64* %R9.i, align 8
  %3561 = icmp ult i32 %3559, %3553
  %3562 = icmp ult i32 %3559, %3558
  %3563 = or i1 %3561, %3562
  %3564 = zext i1 %3563 to i8
  store i8 %3564, i8* %18, align 1
  %3565 = and i32 %3559, 255
  %3566 = tail call i32 @llvm.ctpop.i32(i32 %3565)
  %3567 = trunc i32 %3566 to i8
  %3568 = and i8 %3567, 1
  %3569 = xor i8 %3568, 1
  store i8 %3569, i8* %19, align 1
  %3570 = xor i32 %3558, %3553
  %3571 = xor i32 %3570, %3559
  %3572 = lshr i32 %3571, 4
  %3573 = trunc i32 %3572 to i8
  %3574 = and i8 %3573, 1
  store i8 %3574, i8* %20, align 1
  %3575 = icmp eq i32 %3559, 0
  %3576 = zext i1 %3575 to i8
  store i8 %3576, i8* %21, align 1
  %3577 = lshr i32 %3559, 31
  %3578 = trunc i32 %3577 to i8
  store i8 %3578, i8* %22, align 1
  %3579 = lshr i32 %3553, 31
  %3580 = lshr i32 %3558, 31
  %3581 = xor i32 %3577, %3579
  %3582 = xor i32 %3577, %3580
  %3583 = add nuw nsw i32 %3581, %3582
  %3584 = icmp eq i32 %3583, 2
  %3585 = zext i1 %3584 to i8
  store i8 %3585, i8* %23, align 1
  %3586 = sext i32 %3559 to i64
  store i64 %3586, i64* %26, align 8
  %3587 = shl nsw i64 %3586, 1
  %3588 = add i64 %3522, %3587
  %3589 = add i64 %3363, 143
  store i64 %3589, i64* %3, align 8
  %3590 = inttoptr i64 %3588 to i16*
  %3591 = load i16, i16* %3590, align 2
  %3592 = zext i16 %3591 to i64
  store i64 %3592, i64* %R9.i, align 8
  %3593 = load i64, i64* %RDI.i2141, align 8
  %3594 = zext i16 %3591 to i32
  %3595 = zext i16 %3591 to i64
  %3596 = trunc i64 %3593 to i32
  %3597 = sub i32 %3596, %3594
  %3598 = zext i32 %3597 to i64
  store i64 %3598, i64* %RDI.i2141, align 8
  %3599 = icmp ult i32 %3596, %3594
  %3600 = zext i1 %3599 to i8
  store i8 %3600, i8* %18, align 1
  %3601 = and i32 %3597, 255
  %3602 = tail call i32 @llvm.ctpop.i32(i32 %3601)
  %3603 = trunc i32 %3602 to i8
  %3604 = and i8 %3603, 1
  %3605 = xor i8 %3604, 1
  store i8 %3605, i8* %19, align 1
  %3606 = xor i64 %3595, %3593
  %3607 = trunc i64 %3606 to i32
  %3608 = xor i32 %3607, %3597
  %3609 = lshr i32 %3608, 4
  %3610 = trunc i32 %3609 to i8
  %3611 = and i8 %3610, 1
  store i8 %3611, i8* %20, align 1
  %3612 = icmp eq i32 %3597, 0
  %3613 = zext i1 %3612 to i8
  store i8 %3613, i8* %21, align 1
  %3614 = lshr i32 %3597, 31
  %3615 = trunc i32 %3614 to i8
  store i8 %3615, i8* %22, align 1
  %3616 = lshr i32 %3596, 31
  %3617 = xor i32 %3614, %3616
  %3618 = add nuw nsw i32 %3617, %3616
  %3619 = icmp eq i32 %3618, 2
  %3620 = zext i1 %3619 to i8
  store i8 %3620, i8* %23, align 1
  %3621 = add i64 %3549, -612
  %3622 = add i64 %3363, 152
  store i64 %3622, i64* %3, align 8
  %3623 = inttoptr i64 %3621 to i32*
  store i32 %3597, i32* %3623, align 4
  %3624 = load i64, i64* %3, align 8
  %3625 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %3625, i64* %RSI.i1889, align 8
  %3626 = load i64, i64* %RBP.i, align 8
  %3627 = add i64 %3626, -504
  %3628 = add i64 %3624, 14
  store i64 %3628, i64* %3, align 8
  %3629 = inttoptr i64 %3627 to i32*
  %3630 = load i32, i32* %3629, align 4
  %3631 = zext i32 %3630 to i64
  store i64 %3631, i64* %RDI.i2141, align 8
  %3632 = add i64 %3626, -48
  %3633 = add i64 %3624, 17
  store i64 %3633, i64* %3, align 8
  %3634 = inttoptr i64 %3632 to i32*
  %3635 = load i32, i32* %3634, align 4
  %3636 = add i32 %3635, %3630
  %3637 = zext i32 %3636 to i64
  store i64 %3637, i64* %RDI.i2141, align 8
  %3638 = icmp ult i32 %3636, %3630
  %3639 = icmp ult i32 %3636, %3635
  %3640 = or i1 %3638, %3639
  %3641 = zext i1 %3640 to i8
  store i8 %3641, i8* %18, align 1
  %3642 = and i32 %3636, 255
  %3643 = tail call i32 @llvm.ctpop.i32(i32 %3642)
  %3644 = trunc i32 %3643 to i8
  %3645 = and i8 %3644, 1
  %3646 = xor i8 %3645, 1
  store i8 %3646, i8* %19, align 1
  %3647 = xor i32 %3635, %3630
  %3648 = xor i32 %3647, %3636
  %3649 = lshr i32 %3648, 4
  %3650 = trunc i32 %3649 to i8
  %3651 = and i8 %3650, 1
  store i8 %3651, i8* %20, align 1
  %3652 = icmp eq i32 %3636, 0
  %3653 = zext i1 %3652 to i8
  store i8 %3653, i8* %21, align 1
  %3654 = lshr i32 %3636, 31
  %3655 = trunc i32 %3654 to i8
  store i8 %3655, i8* %22, align 1
  %3656 = lshr i32 %3630, 31
  %3657 = lshr i32 %3635, 31
  %3658 = xor i32 %3654, %3656
  %3659 = xor i32 %3654, %3657
  %3660 = add nuw nsw i32 %3658, %3659
  %3661 = icmp eq i32 %3660, 2
  %3662 = zext i1 %3661 to i8
  store i8 %3662, i8* %23, align 1
  %3663 = sext i32 %3636 to i64
  store i64 %3663, i64* %26, align 8
  %3664 = shl nsw i64 %3663, 3
  %3665 = add i64 %3625, %3664
  %3666 = add i64 %3624, 24
  store i64 %3666, i64* %3, align 8
  %3667 = inttoptr i64 %3665 to i64*
  %3668 = load i64, i64* %3667, align 8
  store i64 %3668, i64* %RSI.i1889, align 8
  %3669 = add i64 %3626, -500
  %3670 = add i64 %3624, 30
  store i64 %3670, i64* %3, align 8
  %3671 = inttoptr i64 %3669 to i32*
  %3672 = load i32, i32* %3671, align 4
  %3673 = zext i32 %3672 to i64
  store i64 %3673, i64* %RDI.i2141, align 8
  %3674 = add i64 %3626, -44
  %3675 = add i64 %3624, 33
  store i64 %3675, i64* %3, align 8
  %3676 = inttoptr i64 %3674 to i32*
  %3677 = load i32, i32* %3676, align 4
  %3678 = add i32 %3677, %3672
  %3679 = zext i32 %3678 to i64
  store i64 %3679, i64* %RDI.i2141, align 8
  %3680 = icmp ult i32 %3678, %3672
  %3681 = icmp ult i32 %3678, %3677
  %3682 = or i1 %3680, %3681
  %3683 = zext i1 %3682 to i8
  store i8 %3683, i8* %18, align 1
  %3684 = and i32 %3678, 255
  %3685 = tail call i32 @llvm.ctpop.i32(i32 %3684)
  %3686 = trunc i32 %3685 to i8
  %3687 = and i8 %3686, 1
  %3688 = xor i8 %3687, 1
  store i8 %3688, i8* %19, align 1
  %3689 = xor i32 %3677, %3672
  %3690 = xor i32 %3689, %3678
  %3691 = lshr i32 %3690, 4
  %3692 = trunc i32 %3691 to i8
  %3693 = and i8 %3692, 1
  store i8 %3693, i8* %20, align 1
  %3694 = icmp eq i32 %3678, 0
  %3695 = zext i1 %3694 to i8
  store i8 %3695, i8* %21, align 1
  %3696 = lshr i32 %3678, 31
  %3697 = trunc i32 %3696 to i8
  store i8 %3697, i8* %22, align 1
  %3698 = lshr i32 %3672, 31
  %3699 = lshr i32 %3677, 31
  %3700 = xor i32 %3696, %3698
  %3701 = xor i32 %3696, %3699
  %3702 = add nuw nsw i32 %3700, %3701
  %3703 = icmp eq i32 %3702, 2
  %3704 = zext i1 %3703 to i8
  store i8 %3704, i8* %23, align 1
  %3705 = sext i32 %3678 to i64
  store i64 %3705, i64* %26, align 8
  %3706 = shl nsw i64 %3705, 1
  %3707 = add i64 %3668, %3706
  %3708 = add i64 %3624, 41
  store i64 %3708, i64* %3, align 8
  %3709 = inttoptr i64 %3707 to i16*
  %3710 = load i16, i16* %3709, align 2
  %3711 = zext i16 %3710 to i64
  store i64 %3711, i64* %RDI.i2141, align 8
  %3712 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %3713 = add i64 %3712, 7352
  store i64 %3713, i64* %RSI.i1889, align 8
  %3714 = icmp ugt i64 %3712, -7353
  %3715 = zext i1 %3714 to i8
  store i8 %3715, i8* %18, align 1
  %3716 = trunc i64 %3713 to i32
  %3717 = and i32 %3716, 255
  %3718 = tail call i32 @llvm.ctpop.i32(i32 %3717)
  %3719 = trunc i32 %3718 to i8
  %3720 = and i8 %3719, 1
  %3721 = xor i8 %3720, 1
  store i8 %3721, i8* %19, align 1
  %3722 = xor i64 %3712, 16
  %3723 = xor i64 %3722, %3713
  %3724 = lshr i64 %3723, 4
  %3725 = trunc i64 %3724 to i8
  %3726 = and i8 %3725, 1
  store i8 %3726, i8* %20, align 1
  %3727 = icmp eq i64 %3713, 0
  %3728 = zext i1 %3727 to i8
  store i8 %3728, i8* %21, align 1
  %3729 = lshr i64 %3713, 63
  %3730 = trunc i64 %3729 to i8
  store i8 %3730, i8* %22, align 1
  %3731 = lshr i64 %3712, 63
  %3732 = xor i64 %3729, %3731
  %3733 = add nuw nsw i64 %3732, %3729
  %3734 = icmp eq i64 %3733, 2
  %3735 = zext i1 %3734 to i8
  store i8 %3735, i8* %23, align 1
  %3736 = load i64, i64* %RBP.i, align 8
  %3737 = add i64 %3736, -36
  %3738 = add i64 %3624, 60
  store i64 %3738, i64* %3, align 8
  %3739 = inttoptr i64 %3737 to i32*
  %3740 = load i32, i32* %3739, align 4
  %3741 = sext i32 %3740 to i64
  %3742 = shl nsw i64 %3741, 7
  store i64 %3742, i64* %26, align 8
  %3743 = add i64 %3742, %3713
  store i64 %3743, i64* %RSI.i1889, align 8
  %3744 = icmp ult i64 %3743, %3713
  %3745 = icmp ult i64 %3743, %3742
  %3746 = or i1 %3744, %3745
  %3747 = zext i1 %3746 to i8
  store i8 %3747, i8* %18, align 1
  %3748 = trunc i64 %3743 to i32
  %3749 = and i32 %3748, 255
  %3750 = tail call i32 @llvm.ctpop.i32(i32 %3749)
  %3751 = trunc i32 %3750 to i8
  %3752 = and i8 %3751, 1
  %3753 = xor i8 %3752, 1
  store i8 %3753, i8* %19, align 1
  %3754 = xor i64 %3713, %3743
  %3755 = lshr i64 %3754, 4
  %3756 = trunc i64 %3755 to i8
  %3757 = and i8 %3756, 1
  store i8 %3757, i8* %20, align 1
  %3758 = icmp eq i64 %3743, 0
  %3759 = zext i1 %3758 to i8
  store i8 %3759, i8* %21, align 1
  %3760 = lshr i64 %3743, 63
  %3761 = trunc i64 %3760 to i8
  store i8 %3761, i8* %22, align 1
  %3762 = lshr i64 %3741, 56
  %3763 = and i64 %3762, 1
  %3764 = xor i64 %3760, %3729
  %3765 = xor i64 %3760, %3763
  %3766 = add nuw nsw i64 %3764, %3765
  %3767 = icmp eq i64 %3766, 2
  %3768 = zext i1 %3767 to i8
  store i8 %3768, i8* %23, align 1
  %3769 = add i64 %3736, -48
  %3770 = add i64 %3624, 71
  store i64 %3770, i64* %3, align 8
  %3771 = inttoptr i64 %3769 to i32*
  %3772 = load i32, i32* %3771, align 4
  %3773 = sext i32 %3772 to i64
  %3774 = shl nsw i64 %3773, 4
  store i64 %3774, i64* %26, align 8
  %3775 = add i64 %3774, %3743
  store i64 %3775, i64* %RSI.i1889, align 8
  %3776 = icmp ult i64 %3775, %3743
  %3777 = icmp ult i64 %3775, %3774
  %3778 = or i1 %3776, %3777
  %3779 = zext i1 %3778 to i8
  store i8 %3779, i8* %18, align 1
  %3780 = trunc i64 %3775 to i32
  %3781 = and i32 %3780, 255
  %3782 = tail call i32 @llvm.ctpop.i32(i32 %3781)
  %3783 = trunc i32 %3782 to i8
  %3784 = and i8 %3783, 1
  %3785 = xor i8 %3784, 1
  store i8 %3785, i8* %19, align 1
  %3786 = xor i64 %3774, %3743
  %3787 = xor i64 %3786, %3775
  %3788 = lshr i64 %3787, 4
  %3789 = trunc i64 %3788 to i8
  %3790 = and i8 %3789, 1
  store i8 %3790, i8* %20, align 1
  %3791 = icmp eq i64 %3775, 0
  %3792 = zext i1 %3791 to i8
  store i8 %3792, i8* %21, align 1
  %3793 = lshr i64 %3775, 63
  %3794 = trunc i64 %3793 to i8
  store i8 %3794, i8* %22, align 1
  %3795 = lshr i64 %3773, 59
  %3796 = and i64 %3795, 1
  %3797 = xor i64 %3793, %3760
  %3798 = xor i64 %3793, %3796
  %3799 = add nuw nsw i64 %3797, %3798
  %3800 = icmp eq i64 %3799, 2
  %3801 = zext i1 %3800 to i8
  store i8 %3801, i8* %23, align 1
  %3802 = load i64, i64* %RBP.i, align 8
  %3803 = add i64 %3802, -44
  %3804 = add i64 %3624, 82
  store i64 %3804, i64* %3, align 8
  %3805 = inttoptr i64 %3803 to i32*
  %3806 = load i32, i32* %3805, align 4
  %3807 = sext i32 %3806 to i64
  store i64 %3807, i64* %26, align 8
  %3808 = shl nsw i64 %3807, 1
  %3809 = add i64 %3808, %3775
  %3810 = add i64 %3624, 87
  store i64 %3810, i64* %3, align 8
  %3811 = inttoptr i64 %3809 to i16*
  %3812 = load i16, i16* %3811, align 2
  %3813 = zext i16 %3812 to i64
  store i64 %3813, i64* %R9.i, align 8
  %3814 = load i64, i64* %RDI.i2141, align 8
  %3815 = zext i16 %3812 to i32
  %3816 = zext i16 %3812 to i64
  %3817 = trunc i64 %3814 to i32
  %3818 = sub i32 %3817, %3815
  %3819 = zext i32 %3818 to i64
  store i64 %3819, i64* %RDI.i2141, align 8
  %3820 = icmp ult i32 %3817, %3815
  %3821 = zext i1 %3820 to i8
  store i8 %3821, i8* %18, align 1
  %3822 = and i32 %3818, 255
  %3823 = tail call i32 @llvm.ctpop.i32(i32 %3822)
  %3824 = trunc i32 %3823 to i8
  %3825 = and i8 %3824, 1
  %3826 = xor i8 %3825, 1
  store i8 %3826, i8* %19, align 1
  %3827 = xor i64 %3816, %3814
  %3828 = trunc i64 %3827 to i32
  %3829 = xor i32 %3828, %3818
  %3830 = lshr i32 %3829, 4
  %3831 = trunc i32 %3830 to i8
  %3832 = and i8 %3831, 1
  store i8 %3832, i8* %20, align 1
  %3833 = icmp eq i32 %3818, 0
  %3834 = zext i1 %3833 to i8
  store i8 %3834, i8* %21, align 1
  %3835 = lshr i32 %3818, 31
  %3836 = trunc i32 %3835 to i8
  store i8 %3836, i8* %22, align 1
  %3837 = lshr i32 %3817, 31
  %3838 = xor i32 %3835, %3837
  %3839 = add nuw nsw i32 %3838, %3837
  %3840 = icmp eq i32 %3839, 2
  %3841 = zext i1 %3840 to i8
  store i8 %3841, i8* %23, align 1
  %3842 = add i64 %3802, -608
  %3843 = add i64 %3624, 96
  store i64 %3843, i64* %3, align 8
  %3844 = inttoptr i64 %3842 to i32*
  store i32 %3818, i32* %3844, align 4
  %3845 = load i64, i64* %3, align 8
  %3846 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %3846, i64* %RSI.i1889, align 8
  %3847 = add i64 %3846, 8
  %3848 = add i64 %3845, 12
  store i64 %3848, i64* %3, align 8
  %3849 = inttoptr i64 %3847 to i64*
  %3850 = load i64, i64* %3849, align 8
  store i64 %3850, i64* %RSI.i1889, align 8
  %3851 = load i64, i64* %RBP.i, align 8
  %3852 = add i64 %3851, -504
  %3853 = add i64 %3845, 18
  store i64 %3853, i64* %3, align 8
  %3854 = inttoptr i64 %3852 to i32*
  %3855 = load i32, i32* %3854, align 4
  %3856 = zext i32 %3855 to i64
  store i64 %3856, i64* %RDI.i2141, align 8
  %3857 = add i64 %3851, -48
  %3858 = add i64 %3845, 21
  store i64 %3858, i64* %3, align 8
  %3859 = inttoptr i64 %3857 to i32*
  %3860 = load i32, i32* %3859, align 4
  %3861 = add i32 %3860, %3855
  %3862 = zext i32 %3861 to i64
  store i64 %3862, i64* %RDI.i2141, align 8
  %3863 = icmp ult i32 %3861, %3855
  %3864 = icmp ult i32 %3861, %3860
  %3865 = or i1 %3863, %3864
  %3866 = zext i1 %3865 to i8
  store i8 %3866, i8* %18, align 1
  %3867 = and i32 %3861, 255
  %3868 = tail call i32 @llvm.ctpop.i32(i32 %3867)
  %3869 = trunc i32 %3868 to i8
  %3870 = and i8 %3869, 1
  %3871 = xor i8 %3870, 1
  store i8 %3871, i8* %19, align 1
  %3872 = xor i32 %3860, %3855
  %3873 = xor i32 %3872, %3861
  %3874 = lshr i32 %3873, 4
  %3875 = trunc i32 %3874 to i8
  %3876 = and i8 %3875, 1
  store i8 %3876, i8* %20, align 1
  %3877 = icmp eq i32 %3861, 0
  %3878 = zext i1 %3877 to i8
  store i8 %3878, i8* %21, align 1
  %3879 = lshr i32 %3861, 31
  %3880 = trunc i32 %3879 to i8
  store i8 %3880, i8* %22, align 1
  %3881 = lshr i32 %3855, 31
  %3882 = lshr i32 %3860, 31
  %3883 = xor i32 %3879, %3881
  %3884 = xor i32 %3879, %3882
  %3885 = add nuw nsw i32 %3883, %3884
  %3886 = icmp eq i32 %3885, 2
  %3887 = zext i1 %3886 to i8
  store i8 %3887, i8* %23, align 1
  %3888 = sext i32 %3861 to i64
  store i64 %3888, i64* %26, align 8
  %3889 = shl nsw i64 %3888, 3
  %3890 = add i64 %3850, %3889
  %3891 = add i64 %3845, 28
  store i64 %3891, i64* %3, align 8
  %3892 = inttoptr i64 %3890 to i64*
  %3893 = load i64, i64* %3892, align 8
  store i64 %3893, i64* %RSI.i1889, align 8
  %3894 = add i64 %3851, -500
  %3895 = add i64 %3845, 34
  store i64 %3895, i64* %3, align 8
  %3896 = inttoptr i64 %3894 to i32*
  %3897 = load i32, i32* %3896, align 4
  %3898 = zext i32 %3897 to i64
  store i64 %3898, i64* %RDI.i2141, align 8
  %3899 = add i64 %3851, -44
  %3900 = add i64 %3845, 37
  store i64 %3900, i64* %3, align 8
  %3901 = inttoptr i64 %3899 to i32*
  %3902 = load i32, i32* %3901, align 4
  %3903 = add i32 %3902, %3897
  %3904 = zext i32 %3903 to i64
  store i64 %3904, i64* %RDI.i2141, align 8
  %3905 = icmp ult i32 %3903, %3897
  %3906 = icmp ult i32 %3903, %3902
  %3907 = or i1 %3905, %3906
  %3908 = zext i1 %3907 to i8
  store i8 %3908, i8* %18, align 1
  %3909 = and i32 %3903, 255
  %3910 = tail call i32 @llvm.ctpop.i32(i32 %3909)
  %3911 = trunc i32 %3910 to i8
  %3912 = and i8 %3911, 1
  %3913 = xor i8 %3912, 1
  store i8 %3913, i8* %19, align 1
  %3914 = xor i32 %3902, %3897
  %3915 = xor i32 %3914, %3903
  %3916 = lshr i32 %3915, 4
  %3917 = trunc i32 %3916 to i8
  %3918 = and i8 %3917, 1
  store i8 %3918, i8* %20, align 1
  %3919 = icmp eq i32 %3903, 0
  %3920 = zext i1 %3919 to i8
  store i8 %3920, i8* %21, align 1
  %3921 = lshr i32 %3903, 31
  %3922 = trunc i32 %3921 to i8
  store i8 %3922, i8* %22, align 1
  %3923 = lshr i32 %3897, 31
  %3924 = lshr i32 %3902, 31
  %3925 = xor i32 %3921, %3923
  %3926 = xor i32 %3921, %3924
  %3927 = add nuw nsw i32 %3925, %3926
  %3928 = icmp eq i32 %3927, 2
  %3929 = zext i1 %3928 to i8
  store i8 %3929, i8* %23, align 1
  %3930 = sext i32 %3903 to i64
  store i64 %3930, i64* %26, align 8
  %3931 = shl nsw i64 %3930, 1
  %3932 = add i64 %3893, %3931
  %3933 = add i64 %3845, 45
  store i64 %3933, i64* %3, align 8
  %3934 = inttoptr i64 %3932 to i16*
  %3935 = load i16, i16* %3934, align 2
  %3936 = zext i16 %3935 to i64
  store i64 %3936, i64* %RDI.i2141, align 8
  %3937 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %3938 = add i64 %3937, 8504
  %3939 = lshr i64 %3938, 63
  %3940 = add i64 %3937, 10552
  store i64 %3940, i64* %RSI.i1889, align 8
  %3941 = icmp ugt i64 %3938, -2049
  %3942 = zext i1 %3941 to i8
  store i8 %3942, i8* %18, align 1
  %3943 = trunc i64 %3940 to i32
  %3944 = and i32 %3943, 255
  %3945 = tail call i32 @llvm.ctpop.i32(i32 %3944)
  %3946 = trunc i32 %3945 to i8
  %3947 = and i8 %3946, 1
  %3948 = xor i8 %3947, 1
  store i8 %3948, i8* %19, align 1
  %3949 = xor i64 %3940, %3938
  %3950 = lshr i64 %3949, 4
  %3951 = trunc i64 %3950 to i8
  %3952 = and i8 %3951, 1
  store i8 %3952, i8* %20, align 1
  %3953 = icmp eq i64 %3940, 0
  %3954 = zext i1 %3953 to i8
  store i8 %3954, i8* %21, align 1
  %3955 = lshr i64 %3940, 63
  %3956 = trunc i64 %3955 to i8
  store i8 %3956, i8* %22, align 1
  %3957 = xor i64 %3955, %3939
  %3958 = add nuw nsw i64 %3957, %3955
  %3959 = icmp eq i64 %3958, 2
  %3960 = zext i1 %3959 to i8
  store i8 %3960, i8* %23, align 1
  %3961 = load i64, i64* %RBP.i, align 8
  %3962 = add i64 %3961, -632
  %3963 = add i64 %3845, 74
  store i64 %3963, i64* %3, align 8
  %3964 = inttoptr i64 %3962 to i32*
  %3965 = load i32, i32* %3964, align 4
  %3966 = sext i32 %3965 to i64
  %3967 = shl nsw i64 %3966, 9
  store i64 %3967, i64* %26, align 8
  %3968 = add i64 %3967, %3940
  store i64 %3968, i64* %RSI.i1889, align 8
  %3969 = icmp ult i64 %3968, %3940
  %3970 = icmp ult i64 %3968, %3967
  %3971 = or i1 %3969, %3970
  %3972 = zext i1 %3971 to i8
  store i8 %3972, i8* %18, align 1
  %3973 = trunc i64 %3968 to i32
  %3974 = and i32 %3973, 255
  %3975 = tail call i32 @llvm.ctpop.i32(i32 %3974)
  %3976 = trunc i32 %3975 to i8
  %3977 = and i8 %3976, 1
  %3978 = xor i8 %3977, 1
  store i8 %3978, i8* %19, align 1
  %3979 = xor i64 %3940, %3968
  %3980 = lshr i64 %3979, 4
  %3981 = trunc i64 %3980 to i8
  %3982 = and i8 %3981, 1
  store i8 %3982, i8* %20, align 1
  %3983 = icmp eq i64 %3968, 0
  %3984 = zext i1 %3983 to i8
  store i8 %3984, i8* %21, align 1
  %3985 = lshr i64 %3968, 63
  %3986 = trunc i64 %3985 to i8
  store i8 %3986, i8* %22, align 1
  %3987 = lshr i64 %3966, 54
  %3988 = and i64 %3987, 1
  %3989 = xor i64 %3985, %3955
  %3990 = xor i64 %3985, %3988
  %3991 = add nuw nsw i64 %3989, %3990
  %3992 = icmp eq i64 %3991, 2
  %3993 = zext i1 %3992 to i8
  store i8 %3993, i8* %23, align 1
  %3994 = add i64 %3961, -484
  %3995 = add i64 %3845, 88
  store i64 %3995, i64* %3, align 8
  %3996 = inttoptr i64 %3994 to i32*
  %3997 = load i32, i32* %3996, align 4
  %3998 = zext i32 %3997 to i64
  store i64 %3998, i64* %R9.i, align 8
  %3999 = add i64 %3961, -44
  %4000 = add i64 %3845, 92
  store i64 %4000, i64* %3, align 8
  %4001 = inttoptr i64 %3999 to i32*
  %4002 = load i32, i32* %4001, align 4
  %4003 = add i32 %4002, %3997
  %4004 = zext i32 %4003 to i64
  store i64 %4004, i64* %R9.i, align 8
  %4005 = sext i32 %4003 to i64
  %4006 = shl nsw i64 %4005, 5
  store i64 %4006, i64* %26, align 8
  %4007 = load i64, i64* %RSI.i1889, align 8
  %4008 = add i64 %4006, %4007
  store i64 %4008, i64* %RSI.i1889, align 8
  %4009 = icmp ult i64 %4008, %4007
  %4010 = icmp ult i64 %4008, %4006
  %4011 = or i1 %4009, %4010
  %4012 = zext i1 %4011 to i8
  store i8 %4012, i8* %18, align 1
  %4013 = trunc i64 %4008 to i32
  %4014 = and i32 %4013, 255
  %4015 = tail call i32 @llvm.ctpop.i32(i32 %4014)
  %4016 = trunc i32 %4015 to i8
  %4017 = and i8 %4016, 1
  %4018 = xor i8 %4017, 1
  store i8 %4018, i8* %19, align 1
  %4019 = xor i64 %4007, %4008
  %4020 = lshr i64 %4019, 4
  %4021 = trunc i64 %4020 to i8
  %4022 = and i8 %4021, 1
  store i8 %4022, i8* %20, align 1
  %4023 = icmp eq i64 %4008, 0
  %4024 = zext i1 %4023 to i8
  store i8 %4024, i8* %21, align 1
  %4025 = lshr i64 %4008, 63
  %4026 = trunc i64 %4025 to i8
  store i8 %4026, i8* %22, align 1
  %4027 = lshr i64 %4007, 63
  %4028 = lshr i64 %4005, 58
  %4029 = and i64 %4028, 1
  %4030 = xor i64 %4025, %4027
  %4031 = xor i64 %4025, %4029
  %4032 = add nuw nsw i64 %4030, %4031
  %4033 = icmp eq i64 %4032, 2
  %4034 = zext i1 %4033 to i8
  store i8 %4034, i8* %23, align 1
  %4035 = load i64, i64* %RBP.i, align 8
  %4036 = add i64 %4035, -488
  %4037 = add i64 %3845, 109
  store i64 %4037, i64* %3, align 8
  %4038 = inttoptr i64 %4036 to i32*
  %4039 = load i32, i32* %4038, align 4
  %4040 = zext i32 %4039 to i64
  store i64 %4040, i64* %R9.i, align 8
  %4041 = add i64 %4035, -48
  %4042 = add i64 %3845, 113
  store i64 %4042, i64* %3, align 8
  %4043 = inttoptr i64 %4041 to i32*
  %4044 = load i32, i32* %4043, align 4
  %4045 = add i32 %4044, %4039
  %4046 = zext i32 %4045 to i64
  store i64 %4046, i64* %R9.i, align 8
  %4047 = icmp ult i32 %4045, %4039
  %4048 = icmp ult i32 %4045, %4044
  %4049 = or i1 %4047, %4048
  %4050 = zext i1 %4049 to i8
  store i8 %4050, i8* %18, align 1
  %4051 = and i32 %4045, 255
  %4052 = tail call i32 @llvm.ctpop.i32(i32 %4051)
  %4053 = trunc i32 %4052 to i8
  %4054 = and i8 %4053, 1
  %4055 = xor i8 %4054, 1
  store i8 %4055, i8* %19, align 1
  %4056 = xor i32 %4044, %4039
  %4057 = xor i32 %4056, %4045
  %4058 = lshr i32 %4057, 4
  %4059 = trunc i32 %4058 to i8
  %4060 = and i8 %4059, 1
  store i8 %4060, i8* %20, align 1
  %4061 = icmp eq i32 %4045, 0
  %4062 = zext i1 %4061 to i8
  store i8 %4062, i8* %21, align 1
  %4063 = lshr i32 %4045, 31
  %4064 = trunc i32 %4063 to i8
  store i8 %4064, i8* %22, align 1
  %4065 = lshr i32 %4039, 31
  %4066 = lshr i32 %4044, 31
  %4067 = xor i32 %4063, %4065
  %4068 = xor i32 %4063, %4066
  %4069 = add nuw nsw i32 %4067, %4068
  %4070 = icmp eq i32 %4069, 2
  %4071 = zext i1 %4070 to i8
  store i8 %4071, i8* %23, align 1
  %4072 = sext i32 %4045 to i64
  store i64 %4072, i64* %26, align 8
  %4073 = shl nsw i64 %4072, 1
  %4074 = add i64 %4008, %4073
  %4075 = add i64 %3845, 121
  store i64 %4075, i64* %3, align 8
  %4076 = inttoptr i64 %4074 to i16*
  %4077 = load i16, i16* %4076, align 2
  %4078 = zext i16 %4077 to i64
  store i64 %4078, i64* %R9.i, align 8
  %4079 = load i64, i64* %RDI.i2141, align 8
  %4080 = zext i16 %4077 to i32
  %4081 = zext i16 %4077 to i64
  %4082 = trunc i64 %4079 to i32
  %4083 = sub i32 %4082, %4080
  %4084 = zext i32 %4083 to i64
  store i64 %4084, i64* %RDI.i2141, align 8
  %4085 = icmp ult i32 %4082, %4080
  %4086 = zext i1 %4085 to i8
  store i8 %4086, i8* %18, align 1
  %4087 = and i32 %4083, 255
  %4088 = tail call i32 @llvm.ctpop.i32(i32 %4087)
  %4089 = trunc i32 %4088 to i8
  %4090 = and i8 %4089, 1
  %4091 = xor i8 %4090, 1
  store i8 %4091, i8* %19, align 1
  %4092 = xor i64 %4081, %4079
  %4093 = trunc i64 %4092 to i32
  %4094 = xor i32 %4093, %4083
  %4095 = lshr i32 %4094, 4
  %4096 = trunc i32 %4095 to i8
  %4097 = and i8 %4096, 1
  store i8 %4097, i8* %20, align 1
  %4098 = icmp eq i32 %4083, 0
  %4099 = zext i1 %4098 to i8
  store i8 %4099, i8* %21, align 1
  %4100 = lshr i32 %4083, 31
  %4101 = trunc i32 %4100 to i8
  store i8 %4101, i8* %22, align 1
  %4102 = lshr i32 %4082, 31
  %4103 = xor i32 %4100, %4102
  %4104 = add nuw nsw i32 %4103, %4102
  %4105 = icmp eq i32 %4104, 2
  %4106 = zext i1 %4105 to i8
  store i8 %4106, i8* %23, align 1
  %4107 = add i64 %4035, -604
  %4108 = add i64 %3845, 130
  store i64 %4108, i64* %3, align 8
  %4109 = inttoptr i64 %4107 to i32*
  store i32 %4083, i32* %4109, align 4
  %4110 = load i64, i64* %RBP.i, align 8
  %4111 = add i64 %4110, -604
  %4112 = load i64, i64* %3, align 8
  %4113 = add i64 %4112, 6
  store i64 %4113, i64* %3, align 8
  %4114 = inttoptr i64 %4111 to i32*
  %4115 = load i32, i32* %4114, align 4
  %4116 = zext i32 %4115 to i64
  store i64 %4116, i64* %RDI.i2141, align 8
  %4117 = add i64 %4110, -612
  %4118 = add i64 %4112, 12
  store i64 %4118, i64* %3, align 8
  %4119 = inttoptr i64 %4117 to i32*
  %4120 = load i32, i32* %4119, align 4
  %4121 = sub i32 %4115, %4120
  %4122 = zext i32 %4121 to i64
  store i64 %4122, i64* %RDI.i2141, align 8
  %4123 = icmp ult i32 %4115, %4120
  %4124 = zext i1 %4123 to i8
  store i8 %4124, i8* %18, align 1
  %4125 = and i32 %4121, 255
  %4126 = tail call i32 @llvm.ctpop.i32(i32 %4125)
  %4127 = trunc i32 %4126 to i8
  %4128 = and i8 %4127, 1
  %4129 = xor i8 %4128, 1
  store i8 %4129, i8* %19, align 1
  %4130 = xor i32 %4120, %4115
  %4131 = xor i32 %4130, %4121
  %4132 = lshr i32 %4131, 4
  %4133 = trunc i32 %4132 to i8
  %4134 = and i8 %4133, 1
  store i8 %4134, i8* %20, align 1
  %4135 = icmp eq i32 %4121, 0
  %4136 = zext i1 %4135 to i8
  store i8 %4136, i8* %21, align 1
  %4137 = lshr i32 %4121, 31
  %4138 = trunc i32 %4137 to i8
  store i8 %4138, i8* %22, align 1
  %4139 = lshr i32 %4115, 31
  %4140 = lshr i32 %4120, 31
  %4141 = xor i32 %4140, %4139
  %4142 = xor i32 %4137, %4139
  %4143 = add nuw nsw i32 %4142, %4141
  %4144 = icmp eq i32 %4143, 2
  %4145 = zext i1 %4144 to i8
  store i8 %4145, i8* %23, align 1
  %4146 = add i64 %4110, -44
  %4147 = add i64 %4112, 16
  store i64 %4147, i64* %3, align 8
  %4148 = inttoptr i64 %4146 to i32*
  %4149 = load i32, i32* %4148, align 4
  %4150 = sext i32 %4149 to i64
  %4151 = shl nsw i64 %4150, 6
  store i64 %4151, i64* %RSI.i1889, align 8
  %4152 = load i64, i64* %RDX.i1805, align 8
  %4153 = add i64 %4151, %4152
  store i64 %4153, i64* %26, align 8
  %4154 = icmp ult i64 %4153, %4152
  %4155 = icmp ult i64 %4153, %4151
  %4156 = or i1 %4154, %4155
  %4157 = zext i1 %4156 to i8
  store i8 %4157, i8* %18, align 1
  %4158 = trunc i64 %4153 to i32
  %4159 = and i32 %4158, 255
  %4160 = tail call i32 @llvm.ctpop.i32(i32 %4159)
  %4161 = trunc i32 %4160 to i8
  %4162 = and i8 %4161, 1
  %4163 = xor i8 %4162, 1
  store i8 %4163, i8* %19, align 1
  %4164 = xor i64 %4152, %4153
  %4165 = lshr i64 %4164, 4
  %4166 = trunc i64 %4165 to i8
  %4167 = and i8 %4166, 1
  store i8 %4167, i8* %20, align 1
  %4168 = icmp eq i64 %4153, 0
  %4169 = zext i1 %4168 to i8
  store i8 %4169, i8* %21, align 1
  %4170 = lshr i64 %4153, 63
  %4171 = trunc i64 %4170 to i8
  store i8 %4171, i8* %22, align 1
  %4172 = lshr i64 %4152, 63
  %4173 = lshr i64 %4150, 57
  %4174 = and i64 %4173, 1
  %4175 = xor i64 %4170, %4172
  %4176 = xor i64 %4170, %4174
  %4177 = add nuw nsw i64 %4175, %4176
  %4178 = icmp eq i64 %4177, 2
  %4179 = zext i1 %4178 to i8
  store i8 %4179, i8* %23, align 1
  %4180 = load i64, i64* %RBP.i, align 8
  %4181 = add i64 %4180, -48
  %4182 = add i64 %4112, 30
  store i64 %4182, i64* %3, align 8
  %4183 = inttoptr i64 %4181 to i32*
  %4184 = load i32, i32* %4183, align 4
  %4185 = sext i32 %4184 to i64
  store i64 %4185, i64* %RSI.i1889, align 8
  %4186 = shl nsw i64 %4185, 2
  %4187 = add i64 %4186, %4153
  %4188 = load i32, i32* %EDI.i1845, align 4
  %4189 = add i64 %4112, 34
  store i64 %4189, i64* %3, align 8
  %4190 = inttoptr i64 %4187 to i32*
  store i32 %4188, i32* %4190, align 4
  %4191 = load i64, i64* %RBP.i, align 8
  %4192 = add i64 %4191, -612
  %4193 = load i64, i64* %3, align 8
  %4194 = add i64 %4193, 6
  store i64 %4194, i64* %3, align 8
  %4195 = inttoptr i64 %4192 to i32*
  %4196 = load i32, i32* %4195, align 4
  %4197 = zext i32 %4196 to i64
  store i64 %4197, i64* %RDI.i2141, align 8
  %4198 = add i64 %4191, -44
  %4199 = add i64 %4193, 10
  store i64 %4199, i64* %3, align 8
  %4200 = inttoptr i64 %4198 to i32*
  %4201 = load i32, i32* %4200, align 4
  %4202 = sext i32 %4201 to i64
  %4203 = shl nsw i64 %4202, 6
  store i64 %4203, i64* %RSI.i1889, align 8
  %4204 = load i64, i64* %RDX.i1805, align 8
  %4205 = add i64 %4203, %4204
  store i64 %4205, i64* %RDX.i1805, align 8
  %4206 = icmp ult i64 %4205, %4204
  %4207 = icmp ult i64 %4205, %4203
  %4208 = or i1 %4206, %4207
  %4209 = zext i1 %4208 to i8
  store i8 %4209, i8* %18, align 1
  %4210 = trunc i64 %4205 to i32
  %4211 = and i32 %4210, 255
  %4212 = tail call i32 @llvm.ctpop.i32(i32 %4211)
  %4213 = trunc i32 %4212 to i8
  %4214 = and i8 %4213, 1
  %4215 = xor i8 %4214, 1
  store i8 %4215, i8* %19, align 1
  %4216 = xor i64 %4204, %4205
  %4217 = lshr i64 %4216, 4
  %4218 = trunc i64 %4217 to i8
  %4219 = and i8 %4218, 1
  store i8 %4219, i8* %20, align 1
  %4220 = icmp eq i64 %4205, 0
  %4221 = zext i1 %4220 to i8
  store i8 %4221, i8* %21, align 1
  %4222 = lshr i64 %4205, 63
  %4223 = trunc i64 %4222 to i8
  store i8 %4223, i8* %22, align 1
  %4224 = lshr i64 %4204, 63
  %4225 = lshr i64 %4202, 57
  %4226 = and i64 %4225, 1
  %4227 = xor i64 %4222, %4224
  %4228 = xor i64 %4222, %4226
  %4229 = add nuw nsw i64 %4227, %4228
  %4230 = icmp eq i64 %4229, 2
  %4231 = zext i1 %4230 to i8
  store i8 %4231, i8* %23, align 1
  %4232 = add i64 %4191, -48
  %4233 = add i64 %4193, 21
  store i64 %4233, i64* %3, align 8
  %4234 = inttoptr i64 %4232 to i32*
  %4235 = load i32, i32* %4234, align 4
  %4236 = sext i32 %4235 to i64
  store i64 %4236, i64* %RSI.i1889, align 8
  %4237 = shl nsw i64 %4236, 2
  %4238 = add i64 %4237, %4205
  %4239 = add i64 %4193, 25
  store i64 %4239, i64* %3, align 8
  %4240 = inttoptr i64 %4238 to i32*
  %4241 = load i32, i32* %4240, align 4
  %4242 = zext i32 %4241 to i64
  %4243 = shl nuw i64 %4242, 32
  %4244 = ashr i64 %4243, 33
  %4245 = and i64 %4244, 4294967295
  store i64 %4245, i64* %R9.i, align 8
  %4246 = load i64, i64* %RDI.i2141, align 8
  %4247 = trunc i64 %4244 to i32
  %4248 = trunc i64 %4246 to i32
  %4249 = add i32 %4247, %4248
  %4250 = zext i32 %4249 to i64
  store i64 %4250, i64* %RDI.i2141, align 8
  %4251 = icmp ult i32 %4249, %4248
  %4252 = icmp ult i32 %4249, %4247
  %4253 = or i1 %4251, %4252
  %4254 = zext i1 %4253 to i8
  store i8 %4254, i8* %18, align 1
  %4255 = and i32 %4249, 255
  %4256 = tail call i32 @llvm.ctpop.i32(i32 %4255)
  %4257 = trunc i32 %4256 to i8
  %4258 = and i8 %4257, 1
  %4259 = xor i8 %4258, 1
  store i8 %4259, i8* %19, align 1
  %4260 = xor i64 %4244, %4246
  %4261 = trunc i64 %4260 to i32
  %4262 = xor i32 %4261, %4249
  %4263 = lshr i32 %4262, 4
  %4264 = trunc i32 %4263 to i8
  %4265 = and i8 %4264, 1
  store i8 %4265, i8* %20, align 1
  %4266 = icmp eq i32 %4249, 0
  %4267 = zext i1 %4266 to i8
  store i8 %4267, i8* %21, align 1
  %4268 = lshr i32 %4249, 31
  %4269 = trunc i32 %4268 to i8
  store i8 %4269, i8* %22, align 1
  %4270 = lshr i32 %4248, 31
  %4271 = lshr i64 %4244, 31
  %4272 = trunc i64 %4271 to i32
  %4273 = and i32 %4272, 1
  %4274 = xor i32 %4268, %4270
  %4275 = xor i32 %4268, %4273
  %4276 = add nuw nsw i32 %4274, %4275
  %4277 = icmp eq i32 %4276, 2
  %4278 = zext i1 %4277 to i8
  store i8 %4278, i8* %23, align 1
  %4279 = load i64, i64* %RBP.i, align 8
  %4280 = add i64 %4279, -624
  %4281 = add i64 %4193, 37
  store i64 %4281, i64* %3, align 8
  %4282 = inttoptr i64 %4280 to i32*
  store i32 %4249, i32* %4282, align 4
  %4283 = load i64, i64* %RBP.i, align 8
  %4284 = add i64 %4283, -608
  %4285 = load i64, i64* %3, align 8
  %4286 = add i64 %4285, 6
  store i64 %4286, i64* %3, align 8
  %4287 = inttoptr i64 %4284 to i32*
  %4288 = load i32, i32* %4287, align 4
  %4289 = zext i32 %4288 to i64
  store i64 %4289, i64* %RDI.i2141, align 8
  %4290 = add i64 %4283, -624
  %4291 = add i64 %4285, 12
  store i64 %4291, i64* %3, align 8
  %4292 = inttoptr i64 %4290 to i32*
  %4293 = load i32, i32* %4292, align 4
  %4294 = sub i32 %4288, %4293
  %4295 = zext i32 %4294 to i64
  store i64 %4295, i64* %RDI.i2141, align 8
  %4296 = icmp ult i32 %4288, %4293
  %4297 = zext i1 %4296 to i8
  store i8 %4297, i8* %18, align 1
  %4298 = and i32 %4294, 255
  %4299 = tail call i32 @llvm.ctpop.i32(i32 %4298)
  %4300 = trunc i32 %4299 to i8
  %4301 = and i8 %4300, 1
  %4302 = xor i8 %4301, 1
  store i8 %4302, i8* %19, align 1
  %4303 = xor i32 %4293, %4288
  %4304 = xor i32 %4303, %4294
  %4305 = lshr i32 %4304, 4
  %4306 = trunc i32 %4305 to i8
  %4307 = and i8 %4306, 1
  store i8 %4307, i8* %20, align 1
  %4308 = icmp eq i32 %4294, 0
  %4309 = zext i1 %4308 to i8
  store i8 %4309, i8* %21, align 1
  %4310 = lshr i32 %4294, 31
  %4311 = trunc i32 %4310 to i8
  store i8 %4311, i8* %22, align 1
  %4312 = lshr i32 %4288, 31
  %4313 = lshr i32 %4293, 31
  %4314 = xor i32 %4313, %4312
  %4315 = xor i32 %4310, %4312
  %4316 = add nuw nsw i32 %4315, %4314
  %4317 = icmp eq i32 %4316, 2
  %4318 = zext i1 %4317 to i8
  store i8 %4318, i8* %23, align 1
  %4319 = add i64 %4283, -44
  %4320 = add i64 %4285, 16
  store i64 %4320, i64* %3, align 8
  %4321 = inttoptr i64 %4319 to i32*
  %4322 = load i32, i32* %4321, align 4
  %4323 = sext i32 %4322 to i64
  %4324 = shl nsw i64 %4323, 6
  store i64 %4324, i64* %RDX.i1805, align 8
  %4325 = load i64, i64* %RCX.i1692, align 8
  %4326 = add i64 %4324, %4325
  store i64 %4326, i64* %RSI.i1889, align 8
  %4327 = icmp ult i64 %4326, %4325
  %4328 = icmp ult i64 %4326, %4324
  %4329 = or i1 %4327, %4328
  %4330 = zext i1 %4329 to i8
  store i8 %4330, i8* %18, align 1
  %4331 = trunc i64 %4326 to i32
  %4332 = and i32 %4331, 255
  %4333 = tail call i32 @llvm.ctpop.i32(i32 %4332)
  %4334 = trunc i32 %4333 to i8
  %4335 = and i8 %4334, 1
  %4336 = xor i8 %4335, 1
  store i8 %4336, i8* %19, align 1
  %4337 = xor i64 %4325, %4326
  %4338 = lshr i64 %4337, 4
  %4339 = trunc i64 %4338 to i8
  %4340 = and i8 %4339, 1
  store i8 %4340, i8* %20, align 1
  %4341 = icmp eq i64 %4326, 0
  %4342 = zext i1 %4341 to i8
  store i8 %4342, i8* %21, align 1
  %4343 = lshr i64 %4326, 63
  %4344 = trunc i64 %4343 to i8
  store i8 %4344, i8* %22, align 1
  %4345 = lshr i64 %4325, 63
  %4346 = lshr i64 %4323, 57
  %4347 = and i64 %4346, 1
  %4348 = xor i64 %4343, %4345
  %4349 = xor i64 %4343, %4347
  %4350 = add nuw nsw i64 %4348, %4349
  %4351 = icmp eq i64 %4350, 2
  %4352 = zext i1 %4351 to i8
  store i8 %4352, i8* %23, align 1
  %4353 = load i64, i64* %RBP.i, align 8
  %4354 = add i64 %4353, -48
  %4355 = add i64 %4285, 30
  store i64 %4355, i64* %3, align 8
  %4356 = inttoptr i64 %4354 to i32*
  %4357 = load i32, i32* %4356, align 4
  %4358 = sext i32 %4357 to i64
  store i64 %4358, i64* %RDX.i1805, align 8
  %4359 = shl nsw i64 %4358, 2
  %4360 = add i64 %4359, %4326
  %4361 = load i32, i32* %EDI.i1845, align 4
  %4362 = add i64 %4285, 33
  store i64 %4362, i64* %3, align 8
  %4363 = inttoptr i64 %4360 to i32*
  store i32 %4361, i32* %4363, align 4
  %4364 = load i64, i64* %RBP.i, align 8
  %4365 = add i64 %4364, -624
  %4366 = load i64, i64* %3, align 8
  %4367 = add i64 %4366, 6
  store i64 %4367, i64* %3, align 8
  %4368 = inttoptr i64 %4365 to i32*
  %4369 = load i32, i32* %4368, align 4
  %4370 = zext i32 %4369 to i64
  store i64 %4370, i64* %RDI.i2141, align 8
  %4371 = add i64 %4364, -44
  %4372 = add i64 %4366, 10
  store i64 %4372, i64* %3, align 8
  %4373 = inttoptr i64 %4371 to i32*
  %4374 = load i32, i32* %4373, align 4
  %4375 = sext i32 %4374 to i64
  %4376 = shl nsw i64 %4375, 6
  store i64 %4376, i64* %RDX.i1805, align 8
  %4377 = load i64, i64* %RCX.i1692, align 8
  %4378 = add i64 %4376, %4377
  store i64 %4378, i64* %RCX.i1692, align 8
  %4379 = icmp ult i64 %4378, %4377
  %4380 = icmp ult i64 %4378, %4376
  %4381 = or i1 %4379, %4380
  %4382 = zext i1 %4381 to i8
  store i8 %4382, i8* %18, align 1
  %4383 = trunc i64 %4378 to i32
  %4384 = and i32 %4383, 255
  %4385 = tail call i32 @llvm.ctpop.i32(i32 %4384)
  %4386 = trunc i32 %4385 to i8
  %4387 = and i8 %4386, 1
  %4388 = xor i8 %4387, 1
  store i8 %4388, i8* %19, align 1
  %4389 = xor i64 %4377, %4378
  %4390 = lshr i64 %4389, 4
  %4391 = trunc i64 %4390 to i8
  %4392 = and i8 %4391, 1
  store i8 %4392, i8* %20, align 1
  %4393 = icmp eq i64 %4378, 0
  %4394 = zext i1 %4393 to i8
  store i8 %4394, i8* %21, align 1
  %4395 = lshr i64 %4378, 63
  %4396 = trunc i64 %4395 to i8
  store i8 %4396, i8* %22, align 1
  %4397 = lshr i64 %4377, 63
  %4398 = lshr i64 %4375, 57
  %4399 = and i64 %4398, 1
  %4400 = xor i64 %4395, %4397
  %4401 = xor i64 %4395, %4399
  %4402 = add nuw nsw i64 %4400, %4401
  %4403 = icmp eq i64 %4402, 2
  %4404 = zext i1 %4403 to i8
  store i8 %4404, i8* %23, align 1
  %4405 = add i64 %4364, -48
  %4406 = add i64 %4366, 21
  store i64 %4406, i64* %3, align 8
  %4407 = inttoptr i64 %4405 to i32*
  %4408 = load i32, i32* %4407, align 4
  %4409 = sext i32 %4408 to i64
  store i64 %4409, i64* %RDX.i1805, align 8
  %4410 = shl nsw i64 %4409, 2
  %4411 = add i64 %4410, %4378
  %4412 = add i64 %4366, 25
  store i64 %4412, i64* %3, align 8
  %4413 = inttoptr i64 %4411 to i32*
  %4414 = load i32, i32* %4413, align 4
  %4415 = zext i32 %4414 to i64
  %4416 = shl nuw i64 %4415, 32
  %4417 = ashr i64 %4416, 33
  %4418 = and i64 %4417, 4294967295
  store i64 %4418, i64* %R9.i, align 8
  %4419 = load i64, i64* %RDI.i2141, align 8
  %4420 = trunc i64 %4417 to i32
  %4421 = trunc i64 %4419 to i32
  %4422 = add i32 %4420, %4421
  %4423 = zext i32 %4422 to i64
  store i64 %4423, i64* %RDI.i2141, align 8
  %4424 = icmp ult i32 %4422, %4421
  %4425 = icmp ult i32 %4422, %4420
  %4426 = or i1 %4424, %4425
  %4427 = zext i1 %4426 to i8
  store i8 %4427, i8* %18, align 1
  %4428 = and i32 %4422, 255
  %4429 = tail call i32 @llvm.ctpop.i32(i32 %4428)
  %4430 = trunc i32 %4429 to i8
  %4431 = and i8 %4430, 1
  %4432 = xor i8 %4431, 1
  store i8 %4432, i8* %19, align 1
  %4433 = xor i64 %4417, %4419
  %4434 = trunc i64 %4433 to i32
  %4435 = xor i32 %4434, %4422
  %4436 = lshr i32 %4435, 4
  %4437 = trunc i32 %4436 to i8
  %4438 = and i8 %4437, 1
  store i8 %4438, i8* %20, align 1
  %4439 = icmp eq i32 %4422, 0
  %4440 = zext i1 %4439 to i8
  store i8 %4440, i8* %21, align 1
  %4441 = lshr i32 %4422, 31
  %4442 = trunc i32 %4441 to i8
  store i8 %4442, i8* %22, align 1
  %4443 = lshr i32 %4421, 31
  %4444 = lshr i64 %4417, 31
  %4445 = trunc i64 %4444 to i32
  %4446 = and i32 %4445, 1
  %4447 = xor i32 %4441, %4443
  %4448 = xor i32 %4441, %4446
  %4449 = add nuw nsw i32 %4447, %4448
  %4450 = icmp eq i32 %4449, 2
  %4451 = zext i1 %4450 to i8
  store i8 %4451, i8* %23, align 1
  %4452 = load i64, i64* %RBP.i, align 8
  %4453 = add i64 %4452, -44
  %4454 = add i64 %4366, 35
  store i64 %4454, i64* %3, align 8
  %4455 = inttoptr i64 %4453 to i32*
  %4456 = load i32, i32* %4455, align 4
  %4457 = sext i32 %4456 to i64
  %4458 = shl nsw i64 %4457, 6
  store i64 %4458, i64* %RCX.i1692, align 8
  %4459 = load i64, i64* %RAX.i1763, align 8
  %4460 = add i64 %4458, %4459
  store i64 %4460, i64* %RAX.i1763, align 8
  %4461 = icmp ult i64 %4460, %4459
  %4462 = icmp ult i64 %4460, %4458
  %4463 = or i1 %4461, %4462
  %4464 = zext i1 %4463 to i8
  store i8 %4464, i8* %18, align 1
  %4465 = trunc i64 %4460 to i32
  %4466 = and i32 %4465, 255
  %4467 = tail call i32 @llvm.ctpop.i32(i32 %4466)
  %4468 = trunc i32 %4467 to i8
  %4469 = and i8 %4468, 1
  %4470 = xor i8 %4469, 1
  store i8 %4470, i8* %19, align 1
  %4471 = xor i64 %4459, %4460
  %4472 = lshr i64 %4471, 4
  %4473 = trunc i64 %4472 to i8
  %4474 = and i8 %4473, 1
  store i8 %4474, i8* %20, align 1
  %4475 = icmp eq i64 %4460, 0
  %4476 = zext i1 %4475 to i8
  store i8 %4476, i8* %21, align 1
  %4477 = lshr i64 %4460, 63
  %4478 = trunc i64 %4477 to i8
  store i8 %4478, i8* %22, align 1
  %4479 = lshr i64 %4459, 63
  %4480 = lshr i64 %4457, 57
  %4481 = and i64 %4480, 1
  %4482 = xor i64 %4477, %4479
  %4483 = xor i64 %4477, %4481
  %4484 = add nuw nsw i64 %4482, %4483
  %4485 = icmp eq i64 %4484, 2
  %4486 = zext i1 %4485 to i8
  store i8 %4486, i8* %23, align 1
  %4487 = add i64 %4452, -48
  %4488 = add i64 %4366, 46
  store i64 %4488, i64* %3, align 8
  %4489 = inttoptr i64 %4487 to i32*
  %4490 = load i32, i32* %4489, align 4
  %4491 = sext i32 %4490 to i64
  store i64 %4491, i64* %RCX.i1692, align 8
  %4492 = shl nsw i64 %4491, 2
  %4493 = add i64 %4492, %4460
  %4494 = load i32, i32* %EDI.i1845, align 4
  %4495 = add i64 %4366, 49
  store i64 %4495, i64* %3, align 8
  %4496 = inttoptr i64 %4493 to i32*
  store i32 %4494, i32* %4496, align 4
  %4497 = load i64, i64* %RBP.i, align 8
  %4498 = add i64 %4497, -44
  %4499 = load i64, i64* %3, align 8
  %4500 = add i64 %4499, 3
  store i64 %4500, i64* %3, align 8
  %4501 = inttoptr i64 %4498 to i32*
  %4502 = load i32, i32* %4501, align 4
  %4503 = add i32 %4502, 1
  %4504 = zext i32 %4503 to i64
  store i64 %4504, i64* %RAX.i1763, align 8
  %4505 = icmp eq i32 %4502, -1
  %4506 = icmp eq i32 %4503, 0
  %4507 = or i1 %4505, %4506
  %4508 = zext i1 %4507 to i8
  store i8 %4508, i8* %18, align 1
  %4509 = and i32 %4503, 255
  %4510 = tail call i32 @llvm.ctpop.i32(i32 %4509)
  %4511 = trunc i32 %4510 to i8
  %4512 = and i8 %4511, 1
  %4513 = xor i8 %4512, 1
  store i8 %4513, i8* %19, align 1
  %4514 = xor i32 %4503, %4502
  %4515 = lshr i32 %4514, 4
  %4516 = trunc i32 %4515 to i8
  %4517 = and i8 %4516, 1
  store i8 %4517, i8* %20, align 1
  %4518 = zext i1 %4506 to i8
  store i8 %4518, i8* %21, align 1
  %4519 = lshr i32 %4503, 31
  %4520 = trunc i32 %4519 to i8
  store i8 %4520, i8* %22, align 1
  %4521 = lshr i32 %4502, 31
  %4522 = xor i32 %4519, %4521
  %4523 = add nuw nsw i32 %4522, %4519
  %4524 = icmp eq i32 %4523, 2
  %4525 = zext i1 %4524 to i8
  store i8 %4525, i8* %23, align 1
  %4526 = add i64 %4499, 9
  store i64 %4526, i64* %3, align 8
  store i32 %4503, i32* %4501, align 4
  %4527 = load i64, i64* %3, align 8
  %4528 = add i64 %4527, -552
  store i64 %4528, i64* %3, align 8
  br label %block_.L_4a4987

block_.L_4a4bb4:                                  ; preds = %block_.L_4a4987
  %4529 = add i64 %3335, -48
  %4530 = add i64 %3363, 8
  store i64 %4530, i64* %3, align 8
  %4531 = inttoptr i64 %4529 to i32*
  %4532 = load i32, i32* %4531, align 4
  %4533 = add i32 %4532, 1
  %4534 = zext i32 %4533 to i64
  store i64 %4534, i64* %RAX.i1763, align 8
  %4535 = icmp eq i32 %4532, -1
  %4536 = icmp eq i32 %4533, 0
  %4537 = or i1 %4535, %4536
  %4538 = zext i1 %4537 to i8
  store i8 %4538, i8* %18, align 1
  %4539 = and i32 %4533, 255
  %4540 = tail call i32 @llvm.ctpop.i32(i32 %4539)
  %4541 = trunc i32 %4540 to i8
  %4542 = and i8 %4541, 1
  %4543 = xor i8 %4542, 1
  store i8 %4543, i8* %19, align 1
  %4544 = xor i32 %4533, %4532
  %4545 = lshr i32 %4544, 4
  %4546 = trunc i32 %4545 to i8
  %4547 = and i8 %4546, 1
  store i8 %4547, i8* %20, align 1
  %4548 = zext i1 %4536 to i8
  store i8 %4548, i8* %21, align 1
  %4549 = lshr i32 %4533, 31
  %4550 = trunc i32 %4549 to i8
  store i8 %4550, i8* %22, align 1
  %4551 = lshr i32 %4532, 31
  %4552 = xor i32 %4549, %4551
  %4553 = add nuw nsw i32 %4552, %4549
  %4554 = icmp eq i32 %4553, 2
  %4555 = zext i1 %4554 to i8
  store i8 %4555, i8* %23, align 1
  %4556 = add i64 %3363, 14
  store i64 %4556, i64* %3, align 8
  store i32 %4533, i32* %4531, align 4
  %4557 = load i64, i64* %3, align 8
  %4558 = add i64 %4557, -588
  store i64 %4558, i64* %3, align 8
  br label %block_.L_4a4976

block_.L_4a4bc7:                                  ; preds = %block_.L_4a4976
  %4559 = add i64 %3330, 7
  store i64 %4559, i64* %3, align 8
  store i32 0, i32* %3305, align 4
  %.pre668 = load i64, i64* %3, align 8
  br label %block_.L_4a4bce

block_.L_4a4bce:                                  ; preds = %block_.L_4a4c33, %block_.L_4a4bc7
  %4560 = phi i64 [ %4792, %block_.L_4a4c33 ], [ %.pre668, %block_.L_4a4bc7 ]
  %4561 = load i64, i64* %RBP.i, align 8
  %4562 = add i64 %4561, -48
  %4563 = add i64 %4560, 4
  store i64 %4563, i64* %3, align 8
  %4564 = inttoptr i64 %4562 to i32*
  %4565 = load i32, i32* %4564, align 4
  %4566 = add i32 %4565, -8
  %4567 = icmp ult i32 %4565, 8
  %4568 = zext i1 %4567 to i8
  store i8 %4568, i8* %18, align 1
  %4569 = and i32 %4566, 255
  %4570 = tail call i32 @llvm.ctpop.i32(i32 %4569)
  %4571 = trunc i32 %4570 to i8
  %4572 = and i8 %4571, 1
  %4573 = xor i8 %4572, 1
  store i8 %4573, i8* %19, align 1
  %4574 = xor i32 %4566, %4565
  %4575 = lshr i32 %4574, 4
  %4576 = trunc i32 %4575 to i8
  %4577 = and i8 %4576, 1
  store i8 %4577, i8* %20, align 1
  %4578 = icmp eq i32 %4566, 0
  %4579 = zext i1 %4578 to i8
  store i8 %4579, i8* %21, align 1
  %4580 = lshr i32 %4566, 31
  %4581 = trunc i32 %4580 to i8
  store i8 %4581, i8* %22, align 1
  %4582 = lshr i32 %4565, 31
  %4583 = xor i32 %4580, %4582
  %4584 = add nuw nsw i32 %4583, %4582
  %4585 = icmp eq i32 %4584, 2
  %4586 = zext i1 %4585 to i8
  store i8 %4586, i8* %23, align 1
  %4587 = icmp ne i8 %4581, 0
  %4588 = xor i1 %4587, %4585
  %.v846 = select i1 %4588, i64 10, i64 120
  %4589 = add i64 %4560, %.v846
  store i64 %4589, i64* %3, align 8
  br i1 %4588, label %block_4a4bd8, label %block_.L_4a4c46

block_4a4bd8:                                     ; preds = %block_.L_4a4bce
  %4590 = add i64 %4561, -44
  %4591 = add i64 %4589, 7
  store i64 %4591, i64* %3, align 8
  %4592 = inttoptr i64 %4590 to i32*
  store i32 0, i32* %4592, align 4
  %.pre756 = load i64, i64* %3, align 8
  br label %block_.L_4a4bdf

block_.L_4a4bdf:                                  ; preds = %block_4a4be9, %block_4a4bd8
  %4593 = phi i64 [ %4762, %block_4a4be9 ], [ %.pre756, %block_4a4bd8 ]
  %4594 = load i64, i64* %RBP.i, align 8
  %4595 = add i64 %4594, -44
  %4596 = add i64 %4593, 4
  store i64 %4596, i64* %3, align 8
  %4597 = inttoptr i64 %4595 to i32*
  %4598 = load i32, i32* %4597, align 4
  %4599 = add i32 %4598, -8
  %4600 = icmp ult i32 %4598, 8
  %4601 = zext i1 %4600 to i8
  store i8 %4601, i8* %18, align 1
  %4602 = and i32 %4599, 255
  %4603 = tail call i32 @llvm.ctpop.i32(i32 %4602)
  %4604 = trunc i32 %4603 to i8
  %4605 = and i8 %4604, 1
  %4606 = xor i8 %4605, 1
  store i8 %4606, i8* %19, align 1
  %4607 = xor i32 %4599, %4598
  %4608 = lshr i32 %4607, 4
  %4609 = trunc i32 %4608 to i8
  %4610 = and i8 %4609, 1
  store i8 %4610, i8* %20, align 1
  %4611 = icmp eq i32 %4599, 0
  %4612 = zext i1 %4611 to i8
  store i8 %4612, i8* %21, align 1
  %4613 = lshr i32 %4599, 31
  %4614 = trunc i32 %4613 to i8
  store i8 %4614, i8* %22, align 1
  %4615 = lshr i32 %4598, 31
  %4616 = xor i32 %4613, %4615
  %4617 = add nuw nsw i32 %4616, %4615
  %4618 = icmp eq i32 %4617, 2
  %4619 = zext i1 %4618 to i8
  store i8 %4619, i8* %23, align 1
  %4620 = icmp ne i8 %4614, 0
  %4621 = xor i1 %4620, %4618
  %.v807 = select i1 %4621, i64 10, i64 84
  %4622 = add i64 %4593, %.v807
  store i64 %4622, i64* %3, align 8
  br i1 %4621, label %block_4a4be9, label %block_.L_4a4c33

block_4a4be9:                                     ; preds = %block_.L_4a4bdf
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX.i1763, align 8
  %4623 = add i64 %4622, 14
  store i64 %4623, i64* %3, align 8
  %4624 = load i32, i32* %4597, align 4
  %4625 = sext i32 %4624 to i64
  %4626 = shl nsw i64 %4625, 6
  store i64 %4626, i64* %RCX.i1692, align 8
  %4627 = add i64 %4626, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  store i64 %4627, i64* %RAX.i1763, align 8
  %4628 = icmp ult i64 %4627, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  %4629 = icmp ult i64 %4627, %4626
  %4630 = or i1 %4628, %4629
  %4631 = zext i1 %4630 to i8
  store i8 %4631, i8* %18, align 1
  %4632 = trunc i64 %4627 to i32
  %4633 = and i32 %4632, 248
  %4634 = tail call i32 @llvm.ctpop.i32(i32 %4633)
  %4635 = trunc i32 %4634 to i8
  %4636 = and i8 %4635, 1
  %4637 = xor i8 %4636, 1
  store i8 %4637, i8* %19, align 1
  %4638 = xor i64 %4627, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  %4639 = lshr i64 %4638, 4
  %4640 = trunc i64 %4639 to i8
  %4641 = and i8 %4640, 1
  store i8 %4641, i8* %20, align 1
  %4642 = icmp eq i64 %4627, 0
  %4643 = zext i1 %4642 to i8
  store i8 %4643, i8* %21, align 1
  %4644 = lshr i64 %4627, 63
  %4645 = trunc i64 %4644 to i8
  store i8 %4645, i8* %22, align 1
  %4646 = lshr i64 %4625, 57
  %4647 = and i64 %4646, 1
  %4648 = xor i64 %4644, lshr (i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64 63)
  %4649 = xor i64 %4644, %4647
  %4650 = add nuw nsw i64 %4648, %4649
  %4651 = icmp eq i64 %4650, 2
  %4652 = zext i1 %4651 to i8
  store i8 %4652, i8* %23, align 1
  %4653 = add i64 %4594, -48
  %4654 = add i64 %4622, 25
  store i64 %4654, i64* %3, align 8
  %4655 = inttoptr i64 %4653 to i32*
  %4656 = load i32, i32* %4655, align 4
  %4657 = sext i32 %4656 to i64
  store i64 %4657, i64* %RCX.i1692, align 8
  %4658 = shl nsw i64 %4657, 2
  %4659 = add i64 %4658, %4627
  %4660 = add i64 %4622, 28
  store i64 %4660, i64* %3, align 8
  %4661 = inttoptr i64 %4659 to i32*
  %4662 = load i32, i32* %4661, align 4
  %4663 = zext i32 %4662 to i64
  store i64 %4663, i64* %RDX.i1805, align 8
  %4664 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4665 = add i64 %4664, 13112
  store i64 %4665, i64* %RAX.i1763, align 8
  %4666 = icmp ugt i64 %4664, -13113
  %4667 = zext i1 %4666 to i8
  store i8 %4667, i8* %18, align 1
  %4668 = trunc i64 %4665 to i32
  %4669 = and i32 %4668, 255
  %4670 = tail call i32 @llvm.ctpop.i32(i32 %4669)
  %4671 = trunc i32 %4670 to i8
  %4672 = and i8 %4671, 1
  %4673 = xor i8 %4672, 1
  store i8 %4673, i8* %19, align 1
  %4674 = xor i64 %4664, 16
  %4675 = xor i64 %4674, %4665
  %4676 = lshr i64 %4675, 4
  %4677 = trunc i64 %4676 to i8
  %4678 = and i8 %4677, 1
  store i8 %4678, i8* %20, align 1
  %4679 = icmp eq i64 %4665, 0
  %4680 = zext i1 %4679 to i8
  store i8 %4680, i8* %21, align 1
  %4681 = lshr i64 %4665, 63
  %4682 = trunc i64 %4681 to i8
  store i8 %4682, i8* %22, align 1
  %4683 = lshr i64 %4664, 63
  %4684 = xor i64 %4681, %4683
  %4685 = add nuw nsw i64 %4684, %4681
  %4686 = icmp eq i64 %4685, 2
  %4687 = zext i1 %4686 to i8
  store i8 %4687, i8* %23, align 1
  %4688 = load i64, i64* %RBP.i, align 8
  %4689 = add i64 %4688, -44
  %4690 = add i64 %4622, 46
  store i64 %4690, i64* %3, align 8
  %4691 = inttoptr i64 %4689 to i32*
  %4692 = load i32, i32* %4691, align 4
  %4693 = sext i32 %4692 to i64
  %4694 = shl nsw i64 %4693, 6
  store i64 %4694, i64* %RCX.i1692, align 8
  %4695 = add i64 %4694, %4665
  store i64 %4695, i64* %RAX.i1763, align 8
  %4696 = icmp ult i64 %4695, %4665
  %4697 = icmp ult i64 %4695, %4694
  %4698 = or i1 %4696, %4697
  %4699 = zext i1 %4698 to i8
  store i8 %4699, i8* %18, align 1
  %4700 = trunc i64 %4695 to i32
  %4701 = and i32 %4700, 255
  %4702 = tail call i32 @llvm.ctpop.i32(i32 %4701)
  %4703 = trunc i32 %4702 to i8
  %4704 = and i8 %4703, 1
  %4705 = xor i8 %4704, 1
  store i8 %4705, i8* %19, align 1
  %4706 = xor i64 %4665, %4695
  %4707 = lshr i64 %4706, 4
  %4708 = trunc i64 %4707 to i8
  %4709 = and i8 %4708, 1
  store i8 %4709, i8* %20, align 1
  %4710 = icmp eq i64 %4695, 0
  %4711 = zext i1 %4710 to i8
  store i8 %4711, i8* %21, align 1
  %4712 = lshr i64 %4695, 63
  %4713 = trunc i64 %4712 to i8
  store i8 %4713, i8* %22, align 1
  %4714 = lshr i64 %4693, 57
  %4715 = and i64 %4714, 1
  %4716 = xor i64 %4712, %4681
  %4717 = xor i64 %4712, %4715
  %4718 = add nuw nsw i64 %4716, %4717
  %4719 = icmp eq i64 %4718, 2
  %4720 = zext i1 %4719 to i8
  store i8 %4720, i8* %23, align 1
  %4721 = add i64 %4688, -48
  %4722 = add i64 %4622, 57
  store i64 %4722, i64* %3, align 8
  %4723 = inttoptr i64 %4721 to i32*
  %4724 = load i32, i32* %4723, align 4
  %4725 = sext i32 %4724 to i64
  store i64 %4725, i64* %RCX.i1692, align 8
  %4726 = shl nsw i64 %4725, 2
  %4727 = add i64 %4726, %4695
  %4728 = load i32, i32* %EDX.i2206, align 4
  %4729 = add i64 %4622, 60
  store i64 %4729, i64* %3, align 8
  %4730 = inttoptr i64 %4727 to i32*
  store i32 %4728, i32* %4730, align 4
  %4731 = load i64, i64* %RBP.i, align 8
  %4732 = add i64 %4731, -44
  %4733 = load i64, i64* %3, align 8
  %4734 = add i64 %4733, 3
  store i64 %4734, i64* %3, align 8
  %4735 = inttoptr i64 %4732 to i32*
  %4736 = load i32, i32* %4735, align 4
  %4737 = add i32 %4736, 1
  %4738 = zext i32 %4737 to i64
  store i64 %4738, i64* %RAX.i1763, align 8
  %4739 = icmp eq i32 %4736, -1
  %4740 = icmp eq i32 %4737, 0
  %4741 = or i1 %4739, %4740
  %4742 = zext i1 %4741 to i8
  store i8 %4742, i8* %18, align 1
  %4743 = and i32 %4737, 255
  %4744 = tail call i32 @llvm.ctpop.i32(i32 %4743)
  %4745 = trunc i32 %4744 to i8
  %4746 = and i8 %4745, 1
  %4747 = xor i8 %4746, 1
  store i8 %4747, i8* %19, align 1
  %4748 = xor i32 %4737, %4736
  %4749 = lshr i32 %4748, 4
  %4750 = trunc i32 %4749 to i8
  %4751 = and i8 %4750, 1
  store i8 %4751, i8* %20, align 1
  %4752 = zext i1 %4740 to i8
  store i8 %4752, i8* %21, align 1
  %4753 = lshr i32 %4737, 31
  %4754 = trunc i32 %4753 to i8
  store i8 %4754, i8* %22, align 1
  %4755 = lshr i32 %4736, 31
  %4756 = xor i32 %4753, %4755
  %4757 = add nuw nsw i32 %4756, %4753
  %4758 = icmp eq i32 %4757, 2
  %4759 = zext i1 %4758 to i8
  store i8 %4759, i8* %23, align 1
  %4760 = add i64 %4733, 9
  store i64 %4760, i64* %3, align 8
  store i32 %4737, i32* %4735, align 4
  %4761 = load i64, i64* %3, align 8
  %4762 = add i64 %4761, -79
  store i64 %4762, i64* %3, align 8
  br label %block_.L_4a4bdf

block_.L_4a4c33:                                  ; preds = %block_.L_4a4bdf
  %4763 = add i64 %4594, -48
  %4764 = add i64 %4622, 8
  store i64 %4764, i64* %3, align 8
  %4765 = inttoptr i64 %4763 to i32*
  %4766 = load i32, i32* %4765, align 4
  %4767 = add i32 %4766, 1
  %4768 = zext i32 %4767 to i64
  store i64 %4768, i64* %RAX.i1763, align 8
  %4769 = icmp eq i32 %4766, -1
  %4770 = icmp eq i32 %4767, 0
  %4771 = or i1 %4769, %4770
  %4772 = zext i1 %4771 to i8
  store i8 %4772, i8* %18, align 1
  %4773 = and i32 %4767, 255
  %4774 = tail call i32 @llvm.ctpop.i32(i32 %4773)
  %4775 = trunc i32 %4774 to i8
  %4776 = and i8 %4775, 1
  %4777 = xor i8 %4776, 1
  store i8 %4777, i8* %19, align 1
  %4778 = xor i32 %4767, %4766
  %4779 = lshr i32 %4778, 4
  %4780 = trunc i32 %4779 to i8
  %4781 = and i8 %4780, 1
  store i8 %4781, i8* %20, align 1
  %4782 = zext i1 %4770 to i8
  store i8 %4782, i8* %21, align 1
  %4783 = lshr i32 %4767, 31
  %4784 = trunc i32 %4783 to i8
  store i8 %4784, i8* %22, align 1
  %4785 = lshr i32 %4766, 31
  %4786 = xor i32 %4783, %4785
  %4787 = add nuw nsw i32 %4786, %4783
  %4788 = icmp eq i32 %4787, 2
  %4789 = zext i1 %4788 to i8
  store i8 %4789, i8* %23, align 1
  %4790 = add i64 %4622, 14
  store i64 %4790, i64* %3, align 8
  store i32 %4767, i32* %4765, align 4
  %4791 = load i64, i64* %3, align 8
  %4792 = add i64 %4791, -115
  store i64 %4792, i64* %3, align 8
  br label %block_.L_4a4bce

block_.L_4a4c46:                                  ; preds = %block_.L_4a4bce
  store i8 0, i8* %AL.i6276, align 1
  %4793 = add i64 %4589, -30118
  %4794 = add i64 %4589, 7
  %4795 = load i64, i64* %6, align 8
  %4796 = add i64 %4795, -8
  %4797 = inttoptr i64 %4796 to i64*
  store i64 %4794, i64* %4797, align 8
  store i64 %4796, i64* %6, align 8
  store i64 %4793, i64* %3, align 8
  %call2_4a4c48 = tail call %struct.Memory* @sub_49d6a0.store_coding_state_cs_cm(%struct.State* nonnull %0, i64 %4793, %struct.Memory* %MEMORY.12)
  %4798 = load i64, i64* %RBP.i, align 8
  %4799 = add i64 %4798, -72
  %4800 = load i64, i64* %3, align 8
  store i64 %4799, i64* %RDI.i2141, align 8
  %4801 = add i64 %4798, -12
  %4802 = add i64 %4800, 7
  store i64 %4802, i64* %3, align 8
  %4803 = inttoptr i64 %4801 to i32*
  %4804 = load i32, i32* %4803, align 4
  %4805 = zext i32 %4804 to i64
  store i64 %4805, i64* %RSI.i1889, align 8
  %4806 = add i64 %4798, -36
  %4807 = add i64 %4800, 10
  store i64 %4807, i64* %3, align 8
  %4808 = inttoptr i64 %4806 to i32*
  %4809 = load i32, i32* %4808, align 4
  %4810 = zext i32 %4809 to i64
  store i64 %4810, i64* %RDX.i1805, align 8
  %4811 = add i64 %4798, -24
  %4812 = add i64 %4800, 15
  store i64 %4812, i64* %3, align 8
  %4813 = inttoptr i64 %4811 to i64*
  %4814 = load i64, i64* %4813, align 8
  store i64 %4814, i64* %54, align 1
  store double 0.000000e+00, double* %1228, align 1
  %4815 = add i64 %4798, -520
  %4816 = add i64 %4800, 23
  store i64 %4816, i64* %3, align 8
  %4817 = inttoptr i64 %4815 to i64*
  %4818 = load i64, i64* %4817, align 8
  store i64 %4818, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %4819 = add i64 %4798, -552
  %4820 = add i64 %4800, 29
  store i64 %4820, i64* %3, align 8
  %4821 = inttoptr i64 %4819 to i32*
  %4822 = load i32, i32* %4821, align 4
  %4823 = zext i32 %4822 to i64
  store i64 %4823, i64* %RCX.i1692, align 8
  %4824 = add i64 %4800, 22179
  %4825 = add i64 %4800, 34
  %4826 = load i64, i64* %6, align 8
  %4827 = add i64 %4826, -8
  %4828 = inttoptr i64 %4827 to i64*
  store i64 %4825, i64* %4828, align 8
  store i64 %4827, i64* %6, align 8
  store i64 %4824, i64* %3, align 8
  %call2_4a4c6a = tail call %struct.Memory* @sub_4aa2f0.RDCost_for_8x8IntraBlocks(%struct.State* nonnull %0, i64 %4824, %struct.Memory* %MEMORY.12)
  %4829 = load i64, i64* %3, align 8
  %4830 = load double, double* %53, align 1
  %4831 = tail call double @llvm.trunc.f64(double %4830)
  %4832 = tail call double @llvm.fabs.f64(double %4831)
  %4833 = fcmp ogt double %4832, 0x41DFFFFFFFC00000
  %4834 = fptosi double %4831 to i32
  %4835 = zext i32 %4834 to i64
  %4836 = select i1 %4833, i64 2147483648, i64 %4835
  store i64 %4836, i64* %RCX.i1692, align 8
  %4837 = load i64, i64* %RBP.i, align 8
  %4838 = add i64 %4837, -616
  %4839 = trunc i64 %4836 to i32
  %4840 = add i64 %4829, 10
  store i64 %4840, i64* %3, align 8
  %4841 = inttoptr i64 %4838 to i32*
  store i32 %4839, i32* %4841, align 4
  %4842 = load i64, i64* %3, align 8
  store i8 0, i8* %AL.i6276, align 1
  %4843 = add i64 %4842, -30137
  %4844 = add i64 %4842, 7
  %4845 = load i64, i64* %6, align 8
  %4846 = add i64 %4845, -8
  %4847 = inttoptr i64 %4846 to i64*
  store i64 %4844, i64* %4847, align 8
  store i64 %4846, i64* %6, align 8
  store i64 %4843, i64* %3, align 8
  %call2_4a4c7b = tail call %struct.Memory* @sub_49d6c0.reset_coding_state_cs_cm(%struct.State* nonnull %0, i64 %4843, %struct.Memory* %MEMORY.12)
  %4848 = load i64, i64* %RBP.i, align 8
  %4849 = add i64 %4848, -48
  %4850 = load i64, i64* %3, align 8
  %4851 = add i64 %4850, 7
  store i64 %4851, i64* %3, align 8
  %4852 = inttoptr i64 %4849 to i32*
  store i32 0, i32* %4852, align 4
  %.pre669 = load i64, i64* %3, align 8
  br label %block_.L_4a4c87

block_.L_4a4c87:                                  ; preds = %block_.L_4a4ced, %block_.L_4a4c46
  %4853 = phi i64 [ %5084, %block_.L_4a4ced ], [ %.pre669, %block_.L_4a4c46 ]
  %4854 = load i64, i64* %RBP.i, align 8
  %4855 = add i64 %4854, -48
  %4856 = add i64 %4853, 4
  store i64 %4856, i64* %3, align 8
  %4857 = inttoptr i64 %4855 to i32*
  %4858 = load i32, i32* %4857, align 4
  %4859 = add i32 %4858, -8
  %4860 = icmp ult i32 %4858, 8
  %4861 = zext i1 %4860 to i8
  store i8 %4861, i8* %18, align 1
  %4862 = and i32 %4859, 255
  %4863 = tail call i32 @llvm.ctpop.i32(i32 %4862)
  %4864 = trunc i32 %4863 to i8
  %4865 = and i8 %4864, 1
  %4866 = xor i8 %4865, 1
  store i8 %4866, i8* %19, align 1
  %4867 = xor i32 %4859, %4858
  %4868 = lshr i32 %4867, 4
  %4869 = trunc i32 %4868 to i8
  %4870 = and i8 %4869, 1
  store i8 %4870, i8* %20, align 1
  %4871 = icmp eq i32 %4859, 0
  %4872 = zext i1 %4871 to i8
  store i8 %4872, i8* %21, align 1
  %4873 = lshr i32 %4859, 31
  %4874 = trunc i32 %4873 to i8
  store i8 %4874, i8* %22, align 1
  %4875 = lshr i32 %4858, 31
  %4876 = xor i32 %4873, %4875
  %4877 = add nuw nsw i32 %4876, %4875
  %4878 = icmp eq i32 %4877, 2
  %4879 = zext i1 %4878 to i8
  store i8 %4879, i8* %23, align 1
  %4880 = icmp ne i8 %4874, 0
  %4881 = xor i1 %4880, %4878
  %.v847 = select i1 %4881, i64 10, i64 121
  %4882 = add i64 %4853, %.v847
  store i64 %4882, i64* %3, align 8
  br i1 %4881, label %block_4a4c91, label %block_.L_4a4d00

block_4a4c91:                                     ; preds = %block_.L_4a4c87
  %4883 = add i64 %4854, -44
  %4884 = add i64 %4882, 7
  store i64 %4884, i64* %3, align 8
  %4885 = inttoptr i64 %4883 to i32*
  store i32 0, i32* %4885, align 4
  %.pre755 = load i64, i64* %3, align 8
  br label %block_.L_4a4c98

block_.L_4a4c98:                                  ; preds = %block_4a4ca2, %block_4a4c91
  %4886 = phi i64 [ %5054, %block_4a4ca2 ], [ %.pre755, %block_4a4c91 ]
  %4887 = load i64, i64* %RBP.i, align 8
  %4888 = add i64 %4887, -44
  %4889 = add i64 %4886, 4
  store i64 %4889, i64* %3, align 8
  %4890 = inttoptr i64 %4888 to i32*
  %4891 = load i32, i32* %4890, align 4
  %4892 = add i32 %4891, -8
  %4893 = icmp ult i32 %4891, 8
  %4894 = zext i1 %4893 to i8
  store i8 %4894, i8* %18, align 1
  %4895 = and i32 %4892, 255
  %4896 = tail call i32 @llvm.ctpop.i32(i32 %4895)
  %4897 = trunc i32 %4896 to i8
  %4898 = and i8 %4897, 1
  %4899 = xor i8 %4898, 1
  store i8 %4899, i8* %19, align 1
  %4900 = xor i32 %4892, %4891
  %4901 = lshr i32 %4900, 4
  %4902 = trunc i32 %4901 to i8
  %4903 = and i8 %4902, 1
  store i8 %4903, i8* %20, align 1
  %4904 = icmp eq i32 %4892, 0
  %4905 = zext i1 %4904 to i8
  store i8 %4905, i8* %21, align 1
  %4906 = lshr i32 %4892, 31
  %4907 = trunc i32 %4906 to i8
  store i8 %4907, i8* %22, align 1
  %4908 = lshr i32 %4891, 31
  %4909 = xor i32 %4906, %4908
  %4910 = add nuw nsw i32 %4909, %4908
  %4911 = icmp eq i32 %4910, 2
  %4912 = zext i1 %4911 to i8
  store i8 %4912, i8* %23, align 1
  %4913 = icmp ne i8 %4907, 0
  %4914 = xor i1 %4913, %4911
  %.v806 = select i1 %4914, i64 10, i64 85
  %4915 = add i64 %4886, %.v806
  store i64 %4915, i64* %3, align 8
  br i1 %4914, label %block_4a4ca2, label %block_.L_4a4ced

block_4a4ca2:                                     ; preds = %block_.L_4a4c98
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RAX.i1763, align 8
  %4916 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4917 = add i64 %4916, 13112
  store i64 %4917, i64* %RCX.i1692, align 8
  %4918 = icmp ugt i64 %4916, -13113
  %4919 = zext i1 %4918 to i8
  store i8 %4919, i8* %18, align 1
  %4920 = trunc i64 %4917 to i32
  %4921 = and i32 %4920, 255
  %4922 = tail call i32 @llvm.ctpop.i32(i32 %4921)
  %4923 = trunc i32 %4922 to i8
  %4924 = and i8 %4923, 1
  %4925 = xor i8 %4924, 1
  store i8 %4925, i8* %19, align 1
  %4926 = xor i64 %4916, 16
  %4927 = xor i64 %4926, %4917
  %4928 = lshr i64 %4927, 4
  %4929 = trunc i64 %4928 to i8
  %4930 = and i8 %4929, 1
  store i8 %4930, i8* %20, align 1
  %4931 = icmp eq i64 %4917, 0
  %4932 = zext i1 %4931 to i8
  store i8 %4932, i8* %21, align 1
  %4933 = lshr i64 %4917, 63
  %4934 = trunc i64 %4933 to i8
  store i8 %4934, i8* %22, align 1
  %4935 = lshr i64 %4916, 63
  %4936 = xor i64 %4933, %4935
  %4937 = add nuw nsw i64 %4936, %4933
  %4938 = icmp eq i64 %4937, 2
  %4939 = zext i1 %4938 to i8
  store i8 %4939, i8* %23, align 1
  %4940 = add i64 %4915, 29
  store i64 %4940, i64* %3, align 8
  %4941 = load i32, i32* %4890, align 4
  %4942 = sext i32 %4941 to i64
  %4943 = shl nsw i64 %4942, 6
  store i64 %4943, i64* %RDX.i1805, align 8
  %4944 = add i64 %4943, %4917
  store i64 %4944, i64* %RCX.i1692, align 8
  %4945 = icmp ult i64 %4944, %4917
  %4946 = icmp ult i64 %4944, %4943
  %4947 = or i1 %4945, %4946
  %4948 = zext i1 %4947 to i8
  store i8 %4948, i8* %18, align 1
  %4949 = trunc i64 %4944 to i32
  %4950 = and i32 %4949, 255
  %4951 = tail call i32 @llvm.ctpop.i32(i32 %4950)
  %4952 = trunc i32 %4951 to i8
  %4953 = and i8 %4952, 1
  %4954 = xor i8 %4953, 1
  store i8 %4954, i8* %19, align 1
  %4955 = xor i64 %4917, %4944
  %4956 = lshr i64 %4955, 4
  %4957 = trunc i64 %4956 to i8
  %4958 = and i8 %4957, 1
  store i8 %4958, i8* %20, align 1
  %4959 = icmp eq i64 %4944, 0
  %4960 = zext i1 %4959 to i8
  store i8 %4960, i8* %21, align 1
  %4961 = lshr i64 %4944, 63
  %4962 = trunc i64 %4961 to i8
  store i8 %4962, i8* %22, align 1
  %4963 = lshr i64 %4942, 57
  %4964 = and i64 %4963, 1
  %4965 = xor i64 %4961, %4933
  %4966 = xor i64 %4961, %4964
  %4967 = add nuw nsw i64 %4965, %4966
  %4968 = icmp eq i64 %4967, 2
  %4969 = zext i1 %4968 to i8
  store i8 %4969, i8* %23, align 1
  %4970 = load i64, i64* %RBP.i, align 8
  %4971 = add i64 %4970, -48
  %4972 = add i64 %4915, 40
  store i64 %4972, i64* %3, align 8
  %4973 = inttoptr i64 %4971 to i32*
  %4974 = load i32, i32* %4973, align 4
  %4975 = sext i32 %4974 to i64
  store i64 %4975, i64* %RDX.i1805, align 8
  %4976 = shl nsw i64 %4975, 2
  %4977 = add i64 %4976, %4944
  %4978 = add i64 %4915, 43
  store i64 %4978, i64* %3, align 8
  %4979 = inttoptr i64 %4977 to i32*
  %4980 = load i32, i32* %4979, align 4
  %4981 = zext i32 %4980 to i64
  store i64 %4981, i64* %RSI.i1889, align 8
  %4982 = add i64 %4970, -44
  %4983 = add i64 %4915, 47
  store i64 %4983, i64* %3, align 8
  %4984 = inttoptr i64 %4982 to i32*
  %4985 = load i32, i32* %4984, align 4
  %4986 = sext i32 %4985 to i64
  %4987 = shl nsw i64 %4986, 6
  store i64 %4987, i64* %RCX.i1692, align 8
  %4988 = load i64, i64* %RAX.i1763, align 8
  %4989 = add i64 %4987, %4988
  store i64 %4989, i64* %RAX.i1763, align 8
  %4990 = icmp ult i64 %4989, %4988
  %4991 = icmp ult i64 %4989, %4987
  %4992 = or i1 %4990, %4991
  %4993 = zext i1 %4992 to i8
  store i8 %4993, i8* %18, align 1
  %4994 = trunc i64 %4989 to i32
  %4995 = and i32 %4994, 255
  %4996 = tail call i32 @llvm.ctpop.i32(i32 %4995)
  %4997 = trunc i32 %4996 to i8
  %4998 = and i8 %4997, 1
  %4999 = xor i8 %4998, 1
  store i8 %4999, i8* %19, align 1
  %5000 = xor i64 %4988, %4989
  %5001 = lshr i64 %5000, 4
  %5002 = trunc i64 %5001 to i8
  %5003 = and i8 %5002, 1
  store i8 %5003, i8* %20, align 1
  %5004 = icmp eq i64 %4989, 0
  %5005 = zext i1 %5004 to i8
  store i8 %5005, i8* %21, align 1
  %5006 = lshr i64 %4989, 63
  %5007 = trunc i64 %5006 to i8
  store i8 %5007, i8* %22, align 1
  %5008 = lshr i64 %4988, 63
  %5009 = lshr i64 %4986, 57
  %5010 = and i64 %5009, 1
  %5011 = xor i64 %5006, %5008
  %5012 = xor i64 %5006, %5010
  %5013 = add nuw nsw i64 %5011, %5012
  %5014 = icmp eq i64 %5013, 2
  %5015 = zext i1 %5014 to i8
  store i8 %5015, i8* %23, align 1
  %5016 = add i64 %4915, 58
  store i64 %5016, i64* %3, align 8
  %5017 = load i32, i32* %4973, align 4
  %5018 = sext i32 %5017 to i64
  store i64 %5018, i64* %RCX.i1692, align 8
  %5019 = shl nsw i64 %5018, 2
  %5020 = add i64 %5019, %4989
  %5021 = add i64 %4915, 61
  store i64 %5021, i64* %3, align 8
  %5022 = inttoptr i64 %5020 to i32*
  store i32 %4980, i32* %5022, align 4
  %5023 = load i64, i64* %RBP.i, align 8
  %5024 = add i64 %5023, -44
  %5025 = load i64, i64* %3, align 8
  %5026 = add i64 %5025, 3
  store i64 %5026, i64* %3, align 8
  %5027 = inttoptr i64 %5024 to i32*
  %5028 = load i32, i32* %5027, align 4
  %5029 = add i32 %5028, 1
  %5030 = zext i32 %5029 to i64
  store i64 %5030, i64* %RAX.i1763, align 8
  %5031 = icmp eq i32 %5028, -1
  %5032 = icmp eq i32 %5029, 0
  %5033 = or i1 %5031, %5032
  %5034 = zext i1 %5033 to i8
  store i8 %5034, i8* %18, align 1
  %5035 = and i32 %5029, 255
  %5036 = tail call i32 @llvm.ctpop.i32(i32 %5035)
  %5037 = trunc i32 %5036 to i8
  %5038 = and i8 %5037, 1
  %5039 = xor i8 %5038, 1
  store i8 %5039, i8* %19, align 1
  %5040 = xor i32 %5029, %5028
  %5041 = lshr i32 %5040, 4
  %5042 = trunc i32 %5041 to i8
  %5043 = and i8 %5042, 1
  store i8 %5043, i8* %20, align 1
  %5044 = zext i1 %5032 to i8
  store i8 %5044, i8* %21, align 1
  %5045 = lshr i32 %5029, 31
  %5046 = trunc i32 %5045 to i8
  store i8 %5046, i8* %22, align 1
  %5047 = lshr i32 %5028, 31
  %5048 = xor i32 %5045, %5047
  %5049 = add nuw nsw i32 %5048, %5045
  %5050 = icmp eq i32 %5049, 2
  %5051 = zext i1 %5050 to i8
  store i8 %5051, i8* %23, align 1
  %5052 = add i64 %5025, 9
  store i64 %5052, i64* %3, align 8
  store i32 %5029, i32* %5027, align 4
  %5053 = load i64, i64* %3, align 8
  %5054 = add i64 %5053, -80
  store i64 %5054, i64* %3, align 8
  br label %block_.L_4a4c98

block_.L_4a4ced:                                  ; preds = %block_.L_4a4c98
  %5055 = add i64 %4887, -48
  %5056 = add i64 %4915, 8
  store i64 %5056, i64* %3, align 8
  %5057 = inttoptr i64 %5055 to i32*
  %5058 = load i32, i32* %5057, align 4
  %5059 = add i32 %5058, 1
  %5060 = zext i32 %5059 to i64
  store i64 %5060, i64* %RAX.i1763, align 8
  %5061 = icmp eq i32 %5058, -1
  %5062 = icmp eq i32 %5059, 0
  %5063 = or i1 %5061, %5062
  %5064 = zext i1 %5063 to i8
  store i8 %5064, i8* %18, align 1
  %5065 = and i32 %5059, 255
  %5066 = tail call i32 @llvm.ctpop.i32(i32 %5065)
  %5067 = trunc i32 %5066 to i8
  %5068 = and i8 %5067, 1
  %5069 = xor i8 %5068, 1
  store i8 %5069, i8* %19, align 1
  %5070 = xor i32 %5059, %5058
  %5071 = lshr i32 %5070, 4
  %5072 = trunc i32 %5071 to i8
  %5073 = and i8 %5072, 1
  store i8 %5073, i8* %20, align 1
  %5074 = zext i1 %5062 to i8
  store i8 %5074, i8* %21, align 1
  %5075 = lshr i32 %5059, 31
  %5076 = trunc i32 %5075 to i8
  store i8 %5076, i8* %22, align 1
  %5077 = lshr i32 %5058, 31
  %5078 = xor i32 %5075, %5077
  %5079 = add nuw nsw i32 %5078, %5075
  %5080 = icmp eq i32 %5079, 2
  %5081 = zext i1 %5080 to i8
  store i8 %5081, i8* %23, align 1
  %5082 = add i64 %4915, 14
  store i64 %5082, i64* %3, align 8
  store i32 %5059, i32* %5057, align 4
  %5083 = load i64, i64* %3, align 8
  %5084 = add i64 %5083, -116
  store i64 %5084, i64* %3, align 8
  br label %block_.L_4a4c87

block_.L_4a4d00:                                  ; preds = %block_.L_4a4c87
  store i8 0, i8* %AL.i6276, align 1
  %5085 = add i64 %4882, -30304
  %5086 = add i64 %4882, 7
  %5087 = load i64, i64* %6, align 8
  %5088 = add i64 %5087, -8
  %5089 = inttoptr i64 %5088 to i64*
  store i64 %5086, i64* %5089, align 8
  store i64 %5088, i64* %6, align 8
  store i64 %5085, i64* %3, align 8
  %call2_4a4d02 = tail call %struct.Memory* @sub_49d6a0.store_coding_state_cs_cm(%struct.State* nonnull %0, i64 %5085, %struct.Memory* %MEMORY.12)
  %5090 = load i64, i64* %RBP.i, align 8
  %5091 = add i64 %5090, -628
  %5092 = load i64, i64* %3, align 8
  %5093 = add i64 %5092, 10
  store i64 %5093, i64* %3, align 8
  %5094 = inttoptr i64 %5091 to i32*
  store i32 0, i32* %5094, align 4
  %.pre670 = load i64, i64* %3, align 8
  br label %block_.L_4a4d11

block_.L_4a4d11:                                  ; preds = %block_.L_4a4f9b, %block_.L_4a4d00
  %5095 = phi i64 [ %.pre670, %block_.L_4a4d00 ], [ %6389, %block_.L_4a4f9b ]
  %MEMORY.36 = phi %struct.Memory* [ %MEMORY.12, %block_.L_4a4d00 ], [ %call2_4a4efa, %block_.L_4a4f9b ]
  %5096 = load i64, i64* %RBP.i, align 8
  %5097 = add i64 %5096, -628
  %5098 = add i64 %5095, 7
  store i64 %5098, i64* %3, align 8
  %5099 = inttoptr i64 %5097 to i32*
  %5100 = load i32, i32* %5099, align 4
  %5101 = add i32 %5100, -4
  %5102 = icmp ult i32 %5100, 4
  %5103 = zext i1 %5102 to i8
  store i8 %5103, i8* %18, align 1
  %5104 = and i32 %5101, 255
  %5105 = tail call i32 @llvm.ctpop.i32(i32 %5104)
  %5106 = trunc i32 %5105 to i8
  %5107 = and i8 %5106, 1
  %5108 = xor i8 %5107, 1
  store i8 %5108, i8* %19, align 1
  %5109 = xor i32 %5101, %5100
  %5110 = lshr i32 %5109, 4
  %5111 = trunc i32 %5110 to i8
  %5112 = and i8 %5111, 1
  store i8 %5112, i8* %20, align 1
  %5113 = icmp eq i32 %5101, 0
  %5114 = zext i1 %5113 to i8
  store i8 %5114, i8* %21, align 1
  %5115 = lshr i32 %5101, 31
  %5116 = trunc i32 %5115 to i8
  store i8 %5116, i8* %22, align 1
  %5117 = lshr i32 %5100, 31
  %5118 = xor i32 %5115, %5117
  %5119 = add nuw nsw i32 %5118, %5117
  %5120 = icmp eq i32 %5119, 2
  %5121 = zext i1 %5120 to i8
  store i8 %5121, i8* %23, align 1
  %5122 = icmp ne i8 %5116, 0
  %5123 = xor i1 %5122, %5120
  %.v848 = select i1 %5123, i64 13, i64 675
  %5124 = add i64 %5095, %.v848
  store i64 %5124, i64* %3, align 8
  br i1 %5123, label %block_4a4d1e, label %block_.L_4a4fb4

block_4a4d1e:                                     ; preds = %block_.L_4a4d11
  store i64 2, i64* %RAX.i1763, align 8
  %5125 = add i64 %5124, 11
  store i64 %5125, i64* %3, align 8
  %5126 = load i32, i32* %5099, align 4
  %5127 = zext i32 %5126 to i64
  store i64 %5127, i64* %RCX.i1692, align 8
  %5128 = add i64 %5096, -1220
  %5129 = add i64 %5124, 17
  store i64 %5129, i64* %3, align 8
  %5130 = inttoptr i64 %5128 to i32*
  store i32 2, i32* %5130, align 4
  %5131 = load i32, i32* %ECX.i7699, align 4
  %5132 = zext i32 %5131 to i64
  %5133 = load i64, i64* %3, align 8
  store i64 %5132, i64* %RAX.i1763, align 8
  %5134 = sext i32 %5131 to i64
  %5135 = lshr i64 %5134, 32
  store i64 %5135, i64* %101, align 8
  %5136 = load i64, i64* %RBP.i, align 8
  %5137 = add i64 %5136, -1220
  %5138 = add i64 %5133, 9
  store i64 %5138, i64* %3, align 8
  %5139 = inttoptr i64 %5137 to i32*
  %5140 = load i32, i32* %5139, align 4
  %5141 = zext i32 %5140 to i64
  store i64 %5141, i64* %RCX.i1692, align 8
  %5142 = add i64 %5133, 11
  store i64 %5142, i64* %3, align 8
  %5143 = sext i32 %5140 to i64
  %5144 = shl nuw i64 %5135, 32
  %5145 = or i64 %5144, %5132
  %5146 = sdiv i64 %5145, %5143
  %5147 = shl i64 %5146, 32
  %5148 = ashr exact i64 %5147, 32
  %5149 = icmp eq i64 %5146, %5148
  br i1 %5149, label %5152, label %5150

; <label>:5150:                                   ; preds = %block_4a4d1e
  %5151 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %5142, %struct.Memory* %MEMORY.36)
  %.pre743 = load i64, i64* %RDX.i1805, align 8
  %.pre744 = load i64, i64* %3, align 8
  %.pre745 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit6156

; <label>:5152:                                   ; preds = %block_4a4d1e
  %5153 = srem i64 %5145, %5143
  %5154 = and i64 %5146, 4294967295
  store i64 %5154, i64* %RAX.i1763, align 8
  %5155 = and i64 %5153, 4294967295
  store i64 %5155, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__ecx.exit6156

routine_idivl__ecx.exit6156:                      ; preds = %5152, %5150
  %5156 = phi i64 [ %.pre745, %5150 ], [ %5136, %5152 ]
  %5157 = phi i64 [ %.pre744, %5150 ], [ %5142, %5152 ]
  %5158 = phi i64 [ %.pre743, %5150 ], [ %5155, %5152 ]
  %5159 = phi %struct.Memory* [ %5151, %5150 ], [ %MEMORY.36, %5152 ]
  %.tr153 = trunc i64 %5158 to i32
  %5160 = shl i32 %.tr153, 2
  %5161 = zext i32 %5160 to i64
  store i64 %5161, i64* %RDX.i1805, align 8
  %5162 = lshr i64 %5158, 30
  %5163 = trunc i64 %5162 to i8
  %5164 = and i8 %5163, 1
  store i8 %5164, i8* %18, align 1
  %5165 = and i32 %5160, 252
  %5166 = tail call i32 @llvm.ctpop.i32(i32 %5165)
  %5167 = trunc i32 %5166 to i8
  %5168 = and i8 %5167, 1
  %5169 = xor i8 %5168, 1
  store i8 %5169, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %5170 = icmp eq i32 %5160, 0
  %5171 = zext i1 %5170 to i8
  store i8 %5171, i8* %21, align 1
  %5172 = lshr i32 %.tr153, 29
  %5173 = trunc i32 %5172 to i8
  %5174 = and i8 %5173, 1
  store i8 %5174, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %5175 = add i64 %5156, -476
  %5176 = add i64 %5157, 9
  store i64 %5176, i64* %3, align 8
  %5177 = inttoptr i64 %5175 to i32*
  store i32 %5160, i32* %5177, align 4
  %5178 = load i64, i64* %RBP.i, align 8
  %5179 = add i64 %5178, -628
  %5180 = load i64, i64* %3, align 8
  %5181 = add i64 %5180, 6
  store i64 %5181, i64* %3, align 8
  %5182 = inttoptr i64 %5179 to i32*
  %5183 = load i32, i32* %5182, align 4
  %5184 = zext i32 %5183 to i64
  store i64 %5184, i64* %RAX.i1763, align 8
  %5185 = sext i32 %5183 to i64
  %5186 = lshr i64 %5185, 32
  store i64 %5186, i64* %101, align 8
  %5187 = load i32, i32* %ECX.i7699, align 4
  %5188 = add i64 %5180, 11
  store i64 %5188, i64* %3, align 8
  %5189 = sext i32 %5187 to i64
  %5190 = shl nuw i64 %5186, 32
  %5191 = or i64 %5190, %5184
  %5192 = sdiv i64 %5191, %5189
  %5193 = shl i64 %5192, 32
  %5194 = ashr exact i64 %5193, 32
  %5195 = icmp eq i64 %5192, %5194
  br i1 %5195, label %5198, label %5196

; <label>:5196:                                   ; preds = %routine_idivl__ecx.exit6156
  %5197 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %5188, %struct.Memory* %5159)
  %.pre746 = load i64, i64* %RAX.i1763, align 8
  %.pre747 = load i64, i64* %3, align 8
  %.pre748 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit6138

; <label>:5198:                                   ; preds = %routine_idivl__ecx.exit6156
  %5199 = srem i64 %5191, %5189
  %5200 = and i64 %5192, 4294967295
  store i64 %5200, i64* %RAX.i1763, align 8
  %5201 = and i64 %5199, 4294967295
  store i64 %5201, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__ecx.exit6138

routine_idivl__ecx.exit6138:                      ; preds = %5198, %5196
  %5202 = phi i64 [ %.pre748, %5196 ], [ %5178, %5198 ]
  %5203 = phi i64 [ %.pre747, %5196 ], [ %5188, %5198 ]
  %5204 = phi i64 [ %.pre746, %5196 ], [ %5200, %5198 ]
  %5205 = phi %struct.Memory* [ %5197, %5196 ], [ %5159, %5198 ]
  %.tr156 = trunc i64 %5204 to i32
  %5206 = shl i32 %.tr156, 2
  %5207 = zext i32 %5206 to i64
  store i64 %5207, i64* %RAX.i1763, align 8
  %5208 = lshr i64 %5204, 30
  %5209 = trunc i64 %5208 to i8
  %5210 = and i8 %5209, 1
  store i8 %5210, i8* %18, align 1
  %5211 = and i32 %5206, 252
  %5212 = tail call i32 @llvm.ctpop.i32(i32 %5211)
  %5213 = trunc i32 %5212 to i8
  %5214 = and i8 %5213, 1
  %5215 = xor i8 %5214, 1
  store i8 %5215, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %5216 = icmp eq i32 %5206, 0
  %5217 = zext i1 %5216 to i8
  store i8 %5217, i8* %21, align 1
  %5218 = lshr i32 %.tr156, 29
  %5219 = trunc i32 %5218 to i8
  %5220 = and i8 %5219, 1
  store i8 %5220, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %5221 = add i64 %5202, -480
  %5222 = add i64 %5203, 9
  store i64 %5222, i64* %3, align 8
  %5223 = inttoptr i64 %5221 to i32*
  store i32 %5206, i32* %5223, align 4
  %5224 = load i64, i64* %RBP.i, align 8
  %5225 = add i64 %5224, -48
  %5226 = load i64, i64* %3, align 8
  %5227 = add i64 %5226, 7
  store i64 %5227, i64* %3, align 8
  %5228 = inttoptr i64 %5225 to i32*
  store i32 0, i32* %5228, align 4
  %.pre749 = load i64, i64* %3, align 8
  br label %block_.L_4a4d5e

block_.L_4a4d5e:                                  ; preds = %block_.L_4a4dd3, %routine_idivl__ecx.exit6138
  %5229 = phi i64 [ %5501, %block_.L_4a4dd3 ], [ %.pre749, %routine_idivl__ecx.exit6138 ]
  %5230 = load i64, i64* %RBP.i, align 8
  %5231 = add i64 %5230, -48
  %5232 = add i64 %5229, 4
  store i64 %5232, i64* %3, align 8
  %5233 = inttoptr i64 %5231 to i32*
  %5234 = load i32, i32* %5233, align 4
  %5235 = add i32 %5234, -4
  %5236 = icmp ult i32 %5234, 4
  %5237 = zext i1 %5236 to i8
  store i8 %5237, i8* %18, align 1
  %5238 = and i32 %5235, 255
  %5239 = tail call i32 @llvm.ctpop.i32(i32 %5238)
  %5240 = trunc i32 %5239 to i8
  %5241 = and i8 %5240, 1
  %5242 = xor i8 %5241, 1
  store i8 %5242, i8* %19, align 1
  %5243 = xor i32 %5235, %5234
  %5244 = lshr i32 %5243, 4
  %5245 = trunc i32 %5244 to i8
  %5246 = and i8 %5245, 1
  store i8 %5246, i8* %20, align 1
  %5247 = icmp eq i32 %5235, 0
  %5248 = zext i1 %5247 to i8
  store i8 %5248, i8* %21, align 1
  %5249 = lshr i32 %5235, 31
  %5250 = trunc i32 %5249 to i8
  store i8 %5250, i8* %22, align 1
  %5251 = lshr i32 %5234, 31
  %5252 = xor i32 %5249, %5251
  %5253 = add nuw nsw i32 %5252, %5251
  %5254 = icmp eq i32 %5253, 2
  %5255 = zext i1 %5254 to i8
  store i8 %5255, i8* %23, align 1
  %5256 = icmp ne i8 %5250, 0
  %5257 = xor i1 %5256, %5254
  %.v862 = select i1 %5257, i64 10, i64 136
  %5258 = add i64 %5229, %.v862
  store i64 %5258, i64* %3, align 8
  br i1 %5257, label %block_4a4d68, label %block_.L_4a4de6

block_4a4d68:                                     ; preds = %block_.L_4a4d5e
  %5259 = add i64 %5230, -44
  %5260 = add i64 %5258, 7
  store i64 %5260, i64* %3, align 8
  %5261 = inttoptr i64 %5259 to i32*
  store i32 0, i32* %5261, align 4
  %.pre754 = load i64, i64* %3, align 8
  br label %block_.L_4a4d6f

block_.L_4a4d6f:                                  ; preds = %block_4a4d79, %block_4a4d68
  %5262 = phi i64 [ %5471, %block_4a4d79 ], [ %.pre754, %block_4a4d68 ]
  %5263 = load i64, i64* %RBP.i, align 8
  %5264 = add i64 %5263, -44
  %5265 = add i64 %5262, 4
  store i64 %5265, i64* %3, align 8
  %5266 = inttoptr i64 %5264 to i32*
  %5267 = load i32, i32* %5266, align 4
  %5268 = add i32 %5267, -4
  %5269 = icmp ult i32 %5267, 4
  %5270 = zext i1 %5269 to i8
  store i8 %5270, i8* %18, align 1
  %5271 = and i32 %5268, 255
  %5272 = tail call i32 @llvm.ctpop.i32(i32 %5271)
  %5273 = trunc i32 %5272 to i8
  %5274 = and i8 %5273, 1
  %5275 = xor i8 %5274, 1
  store i8 %5275, i8* %19, align 1
  %5276 = xor i32 %5268, %5267
  %5277 = lshr i32 %5276, 4
  %5278 = trunc i32 %5277 to i8
  %5279 = and i8 %5278, 1
  store i8 %5279, i8* %20, align 1
  %5280 = icmp eq i32 %5268, 0
  %5281 = zext i1 %5280 to i8
  store i8 %5281, i8* %21, align 1
  %5282 = lshr i32 %5268, 31
  %5283 = trunc i32 %5282 to i8
  store i8 %5283, i8* %22, align 1
  %5284 = lshr i32 %5267, 31
  %5285 = xor i32 %5282, %5284
  %5286 = add nuw nsw i32 %5285, %5284
  %5287 = icmp eq i32 %5286, 2
  %5288 = zext i1 %5287 to i8
  store i8 %5288, i8* %23, align 1
  %5289 = icmp ne i8 %5283, 0
  %5290 = xor i1 %5289, %5287
  %.v805 = select i1 %5290, i64 10, i64 100
  %5291 = add i64 %5262, %.v805
  store i64 %5291, i64* %3, align 8
  br i1 %5290, label %block_4a4d79, label %block_.L_4a4dd3

block_4a4d79:                                     ; preds = %block_.L_4a4d6f
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RAX.i1763, align 8
  %5292 = add i64 %5291, 13
  store i64 %5292, i64* %3, align 8
  %5293 = load i32, i32* %5266, align 4
  %5294 = zext i32 %5293 to i64
  store i64 %5294, i64* %RCX.i1692, align 8
  %5295 = add i64 %5263, -476
  %5296 = add i64 %5291, 19
  store i64 %5296, i64* %3, align 8
  %5297 = inttoptr i64 %5295 to i32*
  %5298 = load i32, i32* %5297, align 4
  %5299 = add i32 %5298, %5293
  %5300 = zext i32 %5299 to i64
  store i64 %5300, i64* %RCX.i1692, align 8
  %5301 = sext i32 %5299 to i64
  %5302 = shl nsw i64 %5301, 6
  store i64 %5302, i64* %RDX.i1805, align 8
  %5303 = add i64 %5302, ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64)
  store i64 %5303, i64* %RAX.i1763, align 8
  %5304 = icmp ult i64 %5303, ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64)
  %5305 = icmp ult i64 %5303, %5302
  %5306 = or i1 %5304, %5305
  %5307 = zext i1 %5306 to i8
  store i8 %5307, i8* %18, align 1
  %5308 = trunc i64 %5303 to i32
  %5309 = and i32 %5308, 248
  %5310 = tail call i32 @llvm.ctpop.i32(i32 %5309)
  %5311 = trunc i32 %5310 to i8
  %5312 = and i8 %5311, 1
  %5313 = xor i8 %5312, 1
  store i8 %5313, i8* %19, align 1
  %5314 = xor i64 %5303, ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64)
  %5315 = lshr i64 %5314, 4
  %5316 = trunc i64 %5315 to i8
  %5317 = and i8 %5316, 1
  store i8 %5317, i8* %20, align 1
  %5318 = icmp eq i64 %5303, 0
  %5319 = zext i1 %5318 to i8
  store i8 %5319, i8* %21, align 1
  %5320 = lshr i64 %5303, 63
  %5321 = trunc i64 %5320 to i8
  store i8 %5321, i8* %22, align 1
  %5322 = lshr i64 %5301, 57
  %5323 = and i64 %5322, 1
  %5324 = xor i64 %5320, lshr (i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64 63)
  %5325 = xor i64 %5320, %5323
  %5326 = add nuw nsw i64 %5324, %5325
  %5327 = icmp eq i64 %5326, 2
  %5328 = zext i1 %5327 to i8
  store i8 %5328, i8* %23, align 1
  %5329 = load i64, i64* %RBP.i, align 8
  %5330 = add i64 %5329, -48
  %5331 = add i64 %5291, 32
  store i64 %5331, i64* %3, align 8
  %5332 = inttoptr i64 %5330 to i32*
  %5333 = load i32, i32* %5332, align 4
  %5334 = zext i32 %5333 to i64
  store i64 %5334, i64* %RCX.i1692, align 8
  %5335 = add i64 %5329, -480
  %5336 = add i64 %5291, 38
  store i64 %5336, i64* %3, align 8
  %5337 = inttoptr i64 %5335 to i32*
  %5338 = load i32, i32* %5337, align 4
  %5339 = add i32 %5338, %5333
  %5340 = zext i32 %5339 to i64
  store i64 %5340, i64* %RCX.i1692, align 8
  %5341 = icmp ult i32 %5339, %5333
  %5342 = icmp ult i32 %5339, %5338
  %5343 = or i1 %5341, %5342
  %5344 = zext i1 %5343 to i8
  store i8 %5344, i8* %18, align 1
  %5345 = and i32 %5339, 255
  %5346 = tail call i32 @llvm.ctpop.i32(i32 %5345)
  %5347 = trunc i32 %5346 to i8
  %5348 = and i8 %5347, 1
  %5349 = xor i8 %5348, 1
  store i8 %5349, i8* %19, align 1
  %5350 = xor i32 %5338, %5333
  %5351 = xor i32 %5350, %5339
  %5352 = lshr i32 %5351, 4
  %5353 = trunc i32 %5352 to i8
  %5354 = and i8 %5353, 1
  store i8 %5354, i8* %20, align 1
  %5355 = icmp eq i32 %5339, 0
  %5356 = zext i1 %5355 to i8
  store i8 %5356, i8* %21, align 1
  %5357 = lshr i32 %5339, 31
  %5358 = trunc i32 %5357 to i8
  store i8 %5358, i8* %22, align 1
  %5359 = lshr i32 %5333, 31
  %5360 = lshr i32 %5338, 31
  %5361 = xor i32 %5357, %5359
  %5362 = xor i32 %5357, %5360
  %5363 = add nuw nsw i32 %5361, %5362
  %5364 = icmp eq i32 %5363, 2
  %5365 = zext i1 %5364 to i8
  store i8 %5365, i8* %23, align 1
  %5366 = sext i32 %5339 to i64
  store i64 %5366, i64* %RDX.i1805, align 8
  %5367 = shl nsw i64 %5366, 2
  %5368 = add i64 %5303, %5367
  %5369 = add i64 %5291, 44
  store i64 %5369, i64* %3, align 8
  %5370 = inttoptr i64 %5368 to i32*
  %5371 = load i32, i32* %5370, align 4
  %5372 = zext i32 %5371 to i64
  store i64 %5372, i64* %RCX.i1692, align 8
  %5373 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %5374 = add i64 %5373, 13112
  store i64 %5374, i64* %RAX.i1763, align 8
  %5375 = icmp ugt i64 %5373, -13113
  %5376 = zext i1 %5375 to i8
  store i8 %5376, i8* %18, align 1
  %5377 = trunc i64 %5374 to i32
  %5378 = and i32 %5377, 255
  %5379 = tail call i32 @llvm.ctpop.i32(i32 %5378)
  %5380 = trunc i32 %5379 to i8
  %5381 = and i8 %5380, 1
  %5382 = xor i8 %5381, 1
  store i8 %5382, i8* %19, align 1
  %5383 = xor i64 %5373, 16
  %5384 = xor i64 %5383, %5374
  %5385 = lshr i64 %5384, 4
  %5386 = trunc i64 %5385 to i8
  %5387 = and i8 %5386, 1
  store i8 %5387, i8* %20, align 1
  %5388 = icmp eq i64 %5374, 0
  %5389 = zext i1 %5388 to i8
  store i8 %5389, i8* %21, align 1
  %5390 = lshr i64 %5374, 63
  %5391 = trunc i64 %5390 to i8
  store i8 %5391, i8* %22, align 1
  %5392 = lshr i64 %5373, 63
  %5393 = xor i64 %5390, %5392
  %5394 = add nuw nsw i64 %5393, %5390
  %5395 = icmp eq i64 %5394, 2
  %5396 = zext i1 %5395 to i8
  store i8 %5396, i8* %23, align 1
  %5397 = add i64 %5329, -44
  %5398 = add i64 %5291, 62
  store i64 %5398, i64* %3, align 8
  %5399 = inttoptr i64 %5397 to i32*
  %5400 = load i32, i32* %5399, align 4
  %5401 = sext i32 %5400 to i64
  %5402 = shl nsw i64 %5401, 6
  store i64 %5402, i64* %RDX.i1805, align 8
  %5403 = add i64 %5402, %5374
  store i64 %5403, i64* %RAX.i1763, align 8
  %5404 = icmp ult i64 %5403, %5374
  %5405 = icmp ult i64 %5403, %5402
  %5406 = or i1 %5404, %5405
  %5407 = zext i1 %5406 to i8
  store i8 %5407, i8* %18, align 1
  %5408 = trunc i64 %5403 to i32
  %5409 = and i32 %5408, 255
  %5410 = tail call i32 @llvm.ctpop.i32(i32 %5409)
  %5411 = trunc i32 %5410 to i8
  %5412 = and i8 %5411, 1
  %5413 = xor i8 %5412, 1
  store i8 %5413, i8* %19, align 1
  %5414 = xor i64 %5374, %5403
  %5415 = lshr i64 %5414, 4
  %5416 = trunc i64 %5415 to i8
  %5417 = and i8 %5416, 1
  store i8 %5417, i8* %20, align 1
  %5418 = icmp eq i64 %5403, 0
  %5419 = zext i1 %5418 to i8
  store i8 %5419, i8* %21, align 1
  %5420 = lshr i64 %5403, 63
  %5421 = trunc i64 %5420 to i8
  store i8 %5421, i8* %22, align 1
  %5422 = lshr i64 %5401, 57
  %5423 = and i64 %5422, 1
  %5424 = xor i64 %5420, %5390
  %5425 = xor i64 %5420, %5423
  %5426 = add nuw nsw i64 %5424, %5425
  %5427 = icmp eq i64 %5426, 2
  %5428 = zext i1 %5427 to i8
  store i8 %5428, i8* %23, align 1
  %5429 = load i64, i64* %RBP.i, align 8
  %5430 = add i64 %5429, -48
  %5431 = add i64 %5291, 73
  store i64 %5431, i64* %3, align 8
  %5432 = inttoptr i64 %5430 to i32*
  %5433 = load i32, i32* %5432, align 4
  %5434 = sext i32 %5433 to i64
  store i64 %5434, i64* %RDX.i1805, align 8
  %5435 = shl nsw i64 %5434, 2
  %5436 = add i64 %5435, %5403
  %5437 = load i32, i32* %ECX.i7699, align 4
  %5438 = add i64 %5291, 76
  store i64 %5438, i64* %3, align 8
  %5439 = inttoptr i64 %5436 to i32*
  store i32 %5437, i32* %5439, align 4
  %5440 = load i64, i64* %RBP.i, align 8
  %5441 = add i64 %5440, -44
  %5442 = load i64, i64* %3, align 8
  %5443 = add i64 %5442, 3
  store i64 %5443, i64* %3, align 8
  %5444 = inttoptr i64 %5441 to i32*
  %5445 = load i32, i32* %5444, align 4
  %5446 = add i32 %5445, 1
  %5447 = zext i32 %5446 to i64
  store i64 %5447, i64* %RAX.i1763, align 8
  %5448 = icmp eq i32 %5445, -1
  %5449 = icmp eq i32 %5446, 0
  %5450 = or i1 %5448, %5449
  %5451 = zext i1 %5450 to i8
  store i8 %5451, i8* %18, align 1
  %5452 = and i32 %5446, 255
  %5453 = tail call i32 @llvm.ctpop.i32(i32 %5452)
  %5454 = trunc i32 %5453 to i8
  %5455 = and i8 %5454, 1
  %5456 = xor i8 %5455, 1
  store i8 %5456, i8* %19, align 1
  %5457 = xor i32 %5446, %5445
  %5458 = lshr i32 %5457, 4
  %5459 = trunc i32 %5458 to i8
  %5460 = and i8 %5459, 1
  store i8 %5460, i8* %20, align 1
  %5461 = zext i1 %5449 to i8
  store i8 %5461, i8* %21, align 1
  %5462 = lshr i32 %5446, 31
  %5463 = trunc i32 %5462 to i8
  store i8 %5463, i8* %22, align 1
  %5464 = lshr i32 %5445, 31
  %5465 = xor i32 %5462, %5464
  %5466 = add nuw nsw i32 %5465, %5462
  %5467 = icmp eq i32 %5466, 2
  %5468 = zext i1 %5467 to i8
  store i8 %5468, i8* %23, align 1
  %5469 = add i64 %5442, 9
  store i64 %5469, i64* %3, align 8
  store i32 %5446, i32* %5444, align 4
  %5470 = load i64, i64* %3, align 8
  %5471 = add i64 %5470, -95
  store i64 %5471, i64* %3, align 8
  br label %block_.L_4a4d6f

block_.L_4a4dd3:                                  ; preds = %block_.L_4a4d6f
  %5472 = add i64 %5263, -48
  %5473 = add i64 %5291, 8
  store i64 %5473, i64* %3, align 8
  %5474 = inttoptr i64 %5472 to i32*
  %5475 = load i32, i32* %5474, align 4
  %5476 = add i32 %5475, 1
  %5477 = zext i32 %5476 to i64
  store i64 %5477, i64* %RAX.i1763, align 8
  %5478 = icmp eq i32 %5475, -1
  %5479 = icmp eq i32 %5476, 0
  %5480 = or i1 %5478, %5479
  %5481 = zext i1 %5480 to i8
  store i8 %5481, i8* %18, align 1
  %5482 = and i32 %5476, 255
  %5483 = tail call i32 @llvm.ctpop.i32(i32 %5482)
  %5484 = trunc i32 %5483 to i8
  %5485 = and i8 %5484, 1
  %5486 = xor i8 %5485, 1
  store i8 %5486, i8* %19, align 1
  %5487 = xor i32 %5476, %5475
  %5488 = lshr i32 %5487, 4
  %5489 = trunc i32 %5488 to i8
  %5490 = and i8 %5489, 1
  store i8 %5490, i8* %20, align 1
  %5491 = zext i1 %5479 to i8
  store i8 %5491, i8* %21, align 1
  %5492 = lshr i32 %5476, 31
  %5493 = trunc i32 %5492 to i8
  store i8 %5493, i8* %22, align 1
  %5494 = lshr i32 %5475, 31
  %5495 = xor i32 %5492, %5494
  %5496 = add nuw nsw i32 %5495, %5492
  %5497 = icmp eq i32 %5496, 2
  %5498 = zext i1 %5497 to i8
  store i8 %5498, i8* %23, align 1
  %5499 = add i64 %5291, 14
  store i64 %5499, i64* %3, align 8
  store i32 %5476, i32* %5474, align 4
  %5500 = load i64, i64* %3, align 8
  %5501 = add i64 %5500, -131
  store i64 %5501, i64* %3, align 8
  br label %block_.L_4a4d5e

block_.L_4a4de6:                                  ; preds = %block_.L_4a4d5e
  store i64 0, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %5502 = add i64 %5230, -12
  %5503 = add i64 %5258, 5
  store i64 %5503, i64* %3, align 8
  %5504 = inttoptr i64 %5502 to i32*
  %5505 = load i32, i32* %5504, align 4
  %5506 = add i32 %5505, 4
  %5507 = zext i32 %5506 to i64
  store i64 %5507, i64* %RAX.i1763, align 8
  %5508 = icmp ugt i32 %5505, -5
  %5509 = zext i1 %5508 to i8
  store i8 %5509, i8* %18, align 1
  %5510 = and i32 %5506, 255
  %5511 = tail call i32 @llvm.ctpop.i32(i32 %5510)
  %5512 = trunc i32 %5511 to i8
  %5513 = and i8 %5512, 1
  %5514 = xor i8 %5513, 1
  store i8 %5514, i8* %19, align 1
  %5515 = xor i32 %5506, %5505
  %5516 = lshr i32 %5515, 4
  %5517 = trunc i32 %5516 to i8
  %5518 = and i8 %5517, 1
  store i8 %5518, i8* %20, align 1
  %5519 = icmp eq i32 %5506, 0
  %5520 = zext i1 %5519 to i8
  store i8 %5520, i8* %21, align 1
  %5521 = lshr i32 %5506, 31
  %5522 = trunc i32 %5521 to i8
  store i8 %5522, i8* %22, align 1
  %5523 = lshr i32 %5505, 31
  %5524 = xor i32 %5521, %5523
  %5525 = add nuw nsw i32 %5524, %5521
  %5526 = icmp eq i32 %5525, 2
  %5527 = zext i1 %5526 to i8
  store i8 %5527, i8* %23, align 1
  %5528 = add i64 %5230, -628
  %5529 = add i64 %5258, 14
  store i64 %5529, i64* %3, align 8
  %5530 = inttoptr i64 %5528 to i32*
  %5531 = load i32, i32* %5530, align 4
  %5532 = zext i32 %5531 to i64
  store i64 %5532, i64* %RSI.i1889, align 8
  store i64 %5507, i64* %RDI.i2141, align 8
  %5533 = add i64 %5258, -137414
  %5534 = add i64 %5258, 21
  %5535 = load i64, i64* %6, align 8
  %5536 = add i64 %5535, -8
  %5537 = inttoptr i64 %5536 to i64*
  store i64 %5534, i64* %5537, align 8
  store i64 %5536, i64* %6, align 8
  store i64 %5533, i64* %3, align 8
  %call2_4a4df6 = tail call %struct.Memory* @sub_483520.RDCost_for_4x4Blocks_Chroma(%struct.State* nonnull %0, i64 %5533, %struct.Memory* %5205)
  %5538 = load i64, i64* %RAX.i1763, align 8
  %5539 = load i64, i64* %RBP.i, align 8
  %5540 = add i64 %5539, -616
  %5541 = load i64, i64* %3, align 8
  %5542 = add i64 %5541, 6
  store i64 %5542, i64* %3, align 8
  %5543 = trunc i64 %5538 to i32
  %5544 = inttoptr i64 %5540 to i32*
  %5545 = load i32, i32* %5544, align 4
  %5546 = add i32 %5545, %5543
  %5547 = zext i32 %5546 to i64
  store i64 %5547, i64* %RAX.i1763, align 8
  %5548 = icmp ult i32 %5546, %5543
  %5549 = icmp ult i32 %5546, %5545
  %5550 = or i1 %5548, %5549
  %5551 = zext i1 %5550 to i8
  store i8 %5551, i8* %18, align 1
  %5552 = and i32 %5546, 255
  %5553 = tail call i32 @llvm.ctpop.i32(i32 %5552)
  %5554 = trunc i32 %5553 to i8
  %5555 = and i8 %5554, 1
  %5556 = xor i8 %5555, 1
  store i8 %5556, i8* %19, align 1
  %5557 = xor i32 %5545, %5543
  %5558 = xor i32 %5557, %5546
  %5559 = lshr i32 %5558, 4
  %5560 = trunc i32 %5559 to i8
  %5561 = and i8 %5560, 1
  store i8 %5561, i8* %20, align 1
  %5562 = icmp eq i32 %5546, 0
  %5563 = zext i1 %5562 to i8
  store i8 %5563, i8* %21, align 1
  %5564 = lshr i32 %5546, 31
  %5565 = trunc i32 %5564 to i8
  store i8 %5565, i8* %22, align 1
  %5566 = lshr i32 %5543, 31
  %5567 = lshr i32 %5545, 31
  %5568 = xor i32 %5564, %5566
  %5569 = xor i32 %5564, %5567
  %5570 = add nuw nsw i32 %5568, %5569
  %5571 = icmp eq i32 %5570, 2
  %5572 = zext i1 %5571 to i8
  store i8 %5572, i8* %23, align 1
  %5573 = add i64 %5541, 12
  store i64 %5573, i64* %3, align 8
  store i32 %5546, i32* %5544, align 4
  %5574 = load i64, i64* %RBP.i, align 8
  %5575 = add i64 %5574, -48
  %5576 = load i64, i64* %3, align 8
  %5577 = add i64 %5576, 7
  store i64 %5577, i64* %3, align 8
  %5578 = inttoptr i64 %5575 to i32*
  store i32 0, i32* %5578, align 4
  %.pre750 = load i64, i64* %3, align 8
  br label %block_.L_4a4e0e

block_.L_4a4e0e:                                  ; preds = %block_.L_4a4ed4, %block_.L_4a4de6
  %5579 = phi i64 [ %6007, %block_.L_4a4ed4 ], [ %.pre750, %block_.L_4a4de6 ]
  %5580 = load i64, i64* %RBP.i, align 8
  %5581 = add i64 %5580, -48
  %5582 = add i64 %5579, 4
  store i64 %5582, i64* %3, align 8
  %5583 = inttoptr i64 %5581 to i32*
  %5584 = load i32, i32* %5583, align 4
  %5585 = add i32 %5584, -4
  %5586 = icmp ult i32 %5584, 4
  %5587 = zext i1 %5586 to i8
  store i8 %5587, i8* %18, align 1
  %5588 = and i32 %5585, 255
  %5589 = tail call i32 @llvm.ctpop.i32(i32 %5588)
  %5590 = trunc i32 %5589 to i8
  %5591 = and i8 %5590, 1
  %5592 = xor i8 %5591, 1
  store i8 %5592, i8* %19, align 1
  %5593 = xor i32 %5585, %5584
  %5594 = lshr i32 %5593, 4
  %5595 = trunc i32 %5594 to i8
  %5596 = and i8 %5595, 1
  store i8 %5596, i8* %20, align 1
  %5597 = icmp eq i32 %5585, 0
  %5598 = zext i1 %5597 to i8
  store i8 %5598, i8* %21, align 1
  %5599 = lshr i32 %5585, 31
  %5600 = trunc i32 %5599 to i8
  store i8 %5600, i8* %22, align 1
  %5601 = lshr i32 %5584, 31
  %5602 = xor i32 %5599, %5601
  %5603 = add nuw nsw i32 %5602, %5601
  %5604 = icmp eq i32 %5603, 2
  %5605 = zext i1 %5604 to i8
  store i8 %5605, i8* %23, align 1
  %5606 = icmp ne i8 %5600, 0
  %5607 = xor i1 %5606, %5604
  %.v863 = select i1 %5607, i64 10, i64 217
  %5608 = add i64 %5579, %.v863
  store i64 %5608, i64* %3, align 8
  br i1 %5607, label %block_4a4e18, label %block_.L_4a4ee7

block_4a4e18:                                     ; preds = %block_.L_4a4e0e
  %5609 = add i64 %5580, -44
  %5610 = add i64 %5608, 7
  store i64 %5610, i64* %3, align 8
  %5611 = inttoptr i64 %5609 to i32*
  store i32 0, i32* %5611, align 4
  %.pre753 = load i64, i64* %3, align 8
  br label %block_.L_4a4e1f

block_.L_4a4e1f:                                  ; preds = %block_4a4e29, %block_4a4e18
  %5612 = phi i64 [ %5977, %block_4a4e29 ], [ %.pre753, %block_4a4e18 ]
  %5613 = load i64, i64* %RBP.i, align 8
  %5614 = add i64 %5613, -44
  %5615 = add i64 %5612, 4
  store i64 %5615, i64* %3, align 8
  %5616 = inttoptr i64 %5614 to i32*
  %5617 = load i32, i32* %5616, align 4
  %5618 = add i32 %5617, -4
  %5619 = icmp ult i32 %5617, 4
  %5620 = zext i1 %5619 to i8
  store i8 %5620, i8* %18, align 1
  %5621 = and i32 %5618, 255
  %5622 = tail call i32 @llvm.ctpop.i32(i32 %5621)
  %5623 = trunc i32 %5622 to i8
  %5624 = and i8 %5623, 1
  %5625 = xor i8 %5624, 1
  store i8 %5625, i8* %19, align 1
  %5626 = xor i32 %5618, %5617
  %5627 = lshr i32 %5626, 4
  %5628 = trunc i32 %5627 to i8
  %5629 = and i8 %5628, 1
  store i8 %5629, i8* %20, align 1
  %5630 = icmp eq i32 %5618, 0
  %5631 = zext i1 %5630 to i8
  store i8 %5631, i8* %21, align 1
  %5632 = lshr i32 %5618, 31
  %5633 = trunc i32 %5632 to i8
  store i8 %5633, i8* %22, align 1
  %5634 = lshr i32 %5617, 31
  %5635 = xor i32 %5632, %5634
  %5636 = add nuw nsw i32 %5635, %5634
  %5637 = icmp eq i32 %5636, 2
  %5638 = zext i1 %5637 to i8
  store i8 %5638, i8* %23, align 1
  %5639 = icmp ne i8 %5633, 0
  %5640 = xor i1 %5639, %5637
  %.v804 = select i1 %5640, i64 10, i64 181
  %5641 = add i64 %5612, %.v804
  store i64 %5641, i64* %3, align 8
  br i1 %5640, label %block_4a4e29, label %block_.L_4a4ed4

block_4a4e29:                                     ; preds = %block_.L_4a4e1f
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RAX.i1763, align 8
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX.i1692, align 8
  %5642 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %5643 = add i64 %5642, 13112
  store i64 %5643, i64* %RDX.i1805, align 8
  %5644 = icmp ugt i64 %5642, -13113
  %5645 = zext i1 %5644 to i8
  store i8 %5645, i8* %18, align 1
  %5646 = trunc i64 %5643 to i32
  %5647 = and i32 %5646, 255
  %5648 = tail call i32 @llvm.ctpop.i32(i32 %5647)
  %5649 = trunc i32 %5648 to i8
  %5650 = and i8 %5649, 1
  %5651 = xor i8 %5650, 1
  store i8 %5651, i8* %19, align 1
  %5652 = xor i64 %5642, 16
  %5653 = xor i64 %5652, %5643
  %5654 = lshr i64 %5653, 4
  %5655 = trunc i64 %5654 to i8
  %5656 = and i8 %5655, 1
  store i8 %5656, i8* %20, align 1
  %5657 = icmp eq i64 %5643, 0
  %5658 = zext i1 %5657 to i8
  store i8 %5658, i8* %21, align 1
  %5659 = lshr i64 %5643, 63
  %5660 = trunc i64 %5659 to i8
  store i8 %5660, i8* %22, align 1
  %5661 = lshr i64 %5642, 63
  %5662 = xor i64 %5659, %5661
  %5663 = add nuw nsw i64 %5662, %5659
  %5664 = icmp eq i64 %5663, 2
  %5665 = zext i1 %5664 to i8
  store i8 %5665, i8* %23, align 1
  %5666 = add i64 %5641, 39
  store i64 %5666, i64* %3, align 8
  %5667 = load i32, i32* %5616, align 4
  %5668 = sext i32 %5667 to i64
  %5669 = shl nsw i64 %5668, 6
  store i64 %5669, i64* %RSI.i1889, align 8
  %5670 = add i64 %5669, %5643
  store i64 %5670, i64* %RDX.i1805, align 8
  %5671 = icmp ult i64 %5670, %5643
  %5672 = icmp ult i64 %5670, %5669
  %5673 = or i1 %5671, %5672
  %5674 = zext i1 %5673 to i8
  store i8 %5674, i8* %18, align 1
  %5675 = trunc i64 %5670 to i32
  %5676 = and i32 %5675, 255
  %5677 = tail call i32 @llvm.ctpop.i32(i32 %5676)
  %5678 = trunc i32 %5677 to i8
  %5679 = and i8 %5678, 1
  %5680 = xor i8 %5679, 1
  store i8 %5680, i8* %19, align 1
  %5681 = xor i64 %5643, %5670
  %5682 = lshr i64 %5681, 4
  %5683 = trunc i64 %5682 to i8
  %5684 = and i8 %5683, 1
  store i8 %5684, i8* %20, align 1
  %5685 = icmp eq i64 %5670, 0
  %5686 = zext i1 %5685 to i8
  store i8 %5686, i8* %21, align 1
  %5687 = lshr i64 %5670, 63
  %5688 = trunc i64 %5687 to i8
  store i8 %5688, i8* %22, align 1
  %5689 = lshr i64 %5668, 57
  %5690 = and i64 %5689, 1
  %5691 = xor i64 %5687, %5659
  %5692 = xor i64 %5687, %5690
  %5693 = add nuw nsw i64 %5691, %5692
  %5694 = icmp eq i64 %5693, 2
  %5695 = zext i1 %5694 to i8
  store i8 %5695, i8* %23, align 1
  %5696 = load i64, i64* %RBP.i, align 8
  %5697 = add i64 %5696, -48
  %5698 = add i64 %5641, 50
  store i64 %5698, i64* %3, align 8
  %5699 = inttoptr i64 %5697 to i32*
  %5700 = load i32, i32* %5699, align 4
  %5701 = sext i32 %5700 to i64
  store i64 %5701, i64* %RSI.i1889, align 8
  %5702 = shl nsw i64 %5701, 2
  %5703 = add i64 %5702, %5670
  %5704 = add i64 %5641, 53
  store i64 %5704, i64* %3, align 8
  %5705 = inttoptr i64 %5703 to i32*
  %5706 = load i32, i32* %5705, align 4
  %5707 = zext i32 %5706 to i64
  store i64 %5707, i64* %RDI.i2141, align 8
  %5708 = add i64 %5696, -44
  %5709 = add i64 %5641, 57
  store i64 %5709, i64* %3, align 8
  %5710 = inttoptr i64 %5708 to i32*
  %5711 = load i32, i32* %5710, align 4
  %5712 = zext i32 %5711 to i64
  store i64 %5712, i64* %26, align 8
  %5713 = add i64 %5696, -476
  %5714 = add i64 %5641, 64
  store i64 %5714, i64* %3, align 8
  %5715 = inttoptr i64 %5713 to i32*
  %5716 = load i32, i32* %5715, align 4
  %5717 = add i32 %5716, %5711
  %5718 = zext i32 %5717 to i64
  store i64 %5718, i64* %26, align 8
  %5719 = sext i32 %5717 to i64
  %5720 = shl nsw i64 %5719, 6
  store i64 %5720, i64* %RDX.i1805, align 8
  %5721 = load i64, i64* %RCX.i1692, align 8
  %5722 = add i64 %5720, %5721
  store i64 %5722, i64* %RCX.i1692, align 8
  %5723 = icmp ult i64 %5722, %5721
  %5724 = icmp ult i64 %5722, %5720
  %5725 = or i1 %5723, %5724
  %5726 = zext i1 %5725 to i8
  store i8 %5726, i8* %18, align 1
  %5727 = trunc i64 %5722 to i32
  %5728 = and i32 %5727, 255
  %5729 = tail call i32 @llvm.ctpop.i32(i32 %5728)
  %5730 = trunc i32 %5729 to i8
  %5731 = and i8 %5730, 1
  %5732 = xor i8 %5731, 1
  store i8 %5732, i8* %19, align 1
  %5733 = xor i64 %5721, %5722
  %5734 = lshr i64 %5733, 4
  %5735 = trunc i64 %5734 to i8
  %5736 = and i8 %5735, 1
  store i8 %5736, i8* %20, align 1
  %5737 = icmp eq i64 %5722, 0
  %5738 = zext i1 %5737 to i8
  store i8 %5738, i8* %21, align 1
  %5739 = lshr i64 %5722, 63
  %5740 = trunc i64 %5739 to i8
  store i8 %5740, i8* %22, align 1
  %5741 = lshr i64 %5721, 63
  %5742 = lshr i64 %5719, 57
  %5743 = and i64 %5742, 1
  %5744 = xor i64 %5739, %5741
  %5745 = xor i64 %5739, %5743
  %5746 = add nuw nsw i64 %5744, %5745
  %5747 = icmp eq i64 %5746, 2
  %5748 = zext i1 %5747 to i8
  store i8 %5748, i8* %23, align 1
  %5749 = load i64, i64* %RBP.i, align 8
  %5750 = add i64 %5749, -48
  %5751 = add i64 %5641, 78
  store i64 %5751, i64* %3, align 8
  %5752 = inttoptr i64 %5750 to i32*
  %5753 = load i32, i32* %5752, align 4
  %5754 = zext i32 %5753 to i64
  store i64 %5754, i64* %26, align 8
  %5755 = add i64 %5749, -480
  %5756 = add i64 %5641, 85
  store i64 %5756, i64* %3, align 8
  %5757 = inttoptr i64 %5755 to i32*
  %5758 = load i32, i32* %5757, align 4
  %5759 = add i32 %5758, %5753
  %5760 = zext i32 %5759 to i64
  store i64 %5760, i64* %26, align 8
  %5761 = icmp ult i32 %5759, %5753
  %5762 = icmp ult i32 %5759, %5758
  %5763 = or i1 %5761, %5762
  %5764 = zext i1 %5763 to i8
  store i8 %5764, i8* %18, align 1
  %5765 = and i32 %5759, 255
  %5766 = tail call i32 @llvm.ctpop.i32(i32 %5765)
  %5767 = trunc i32 %5766 to i8
  %5768 = and i8 %5767, 1
  %5769 = xor i8 %5768, 1
  store i8 %5769, i8* %19, align 1
  %5770 = xor i32 %5758, %5753
  %5771 = xor i32 %5770, %5759
  %5772 = lshr i32 %5771, 4
  %5773 = trunc i32 %5772 to i8
  %5774 = and i8 %5773, 1
  store i8 %5774, i8* %20, align 1
  %5775 = icmp eq i32 %5759, 0
  %5776 = zext i1 %5775 to i8
  store i8 %5776, i8* %21, align 1
  %5777 = lshr i32 %5759, 31
  %5778 = trunc i32 %5777 to i8
  store i8 %5778, i8* %22, align 1
  %5779 = lshr i32 %5753, 31
  %5780 = lshr i32 %5758, 31
  %5781 = xor i32 %5777, %5779
  %5782 = xor i32 %5777, %5780
  %5783 = add nuw nsw i32 %5781, %5782
  %5784 = icmp eq i32 %5783, 2
  %5785 = zext i1 %5784 to i8
  store i8 %5785, i8* %23, align 1
  %5786 = sext i32 %5759 to i64
  store i64 %5786, i64* %RDX.i1805, align 8
  %5787 = shl nsw i64 %5786, 2
  %5788 = add i64 %5722, %5787
  %5789 = load i32, i32* %EDI.i1845, align 4
  %5790 = add i64 %5641, 91
  store i64 %5790, i64* %3, align 8
  %5791 = inttoptr i64 %5788 to i32*
  store i32 %5789, i32* %5791, align 4
  %5792 = load i64, i64* %RBP.i, align 8
  %5793 = add i64 %5792, -44
  %5794 = load i64, i64* %3, align 8
  %5795 = add i64 %5794, 3
  store i64 %5795, i64* %3, align 8
  %5796 = inttoptr i64 %5793 to i32*
  %5797 = load i32, i32* %5796, align 4
  %5798 = zext i32 %5797 to i64
  store i64 %5798, i64* %RDI.i2141, align 8
  %5799 = add i64 %5792, -476
  %5800 = add i64 %5794, 9
  store i64 %5800, i64* %3, align 8
  %5801 = inttoptr i64 %5799 to i32*
  %5802 = load i32, i32* %5801, align 4
  %5803 = add i32 %5802, %5797
  %5804 = zext i32 %5803 to i64
  store i64 %5804, i64* %RDI.i2141, align 8
  %5805 = sext i32 %5803 to i64
  %5806 = shl nsw i64 %5805, 6
  store i64 %5806, i64* %RCX.i1692, align 8
  %5807 = load i64, i64* %RAX.i1763, align 8
  %5808 = add i64 %5806, %5807
  store i64 %5808, i64* %RAX.i1763, align 8
  %5809 = icmp ult i64 %5808, %5807
  %5810 = icmp ult i64 %5808, %5806
  %5811 = or i1 %5809, %5810
  %5812 = zext i1 %5811 to i8
  store i8 %5812, i8* %18, align 1
  %5813 = trunc i64 %5808 to i32
  %5814 = and i32 %5813, 255
  %5815 = tail call i32 @llvm.ctpop.i32(i32 %5814)
  %5816 = trunc i32 %5815 to i8
  %5817 = and i8 %5816, 1
  %5818 = xor i8 %5817, 1
  store i8 %5818, i8* %19, align 1
  %5819 = xor i64 %5807, %5808
  %5820 = lshr i64 %5819, 4
  %5821 = trunc i64 %5820 to i8
  %5822 = and i8 %5821, 1
  store i8 %5822, i8* %20, align 1
  %5823 = icmp eq i64 %5808, 0
  %5824 = zext i1 %5823 to i8
  store i8 %5824, i8* %21, align 1
  %5825 = lshr i64 %5808, 63
  %5826 = trunc i64 %5825 to i8
  store i8 %5826, i8* %22, align 1
  %5827 = lshr i64 %5807, 63
  %5828 = lshr i64 %5805, 57
  %5829 = and i64 %5828, 1
  %5830 = xor i64 %5825, %5827
  %5831 = xor i64 %5825, %5829
  %5832 = add nuw nsw i64 %5830, %5831
  %5833 = icmp eq i64 %5832, 2
  %5834 = zext i1 %5833 to i8
  store i8 %5834, i8* %23, align 1
  %5835 = load i64, i64* %RBP.i, align 8
  %5836 = add i64 %5835, -48
  %5837 = add i64 %5794, 22
  store i64 %5837, i64* %3, align 8
  %5838 = inttoptr i64 %5836 to i32*
  %5839 = load i32, i32* %5838, align 4
  %5840 = zext i32 %5839 to i64
  store i64 %5840, i64* %RDI.i2141, align 8
  %5841 = add i64 %5835, -480
  %5842 = add i64 %5794, 28
  store i64 %5842, i64* %3, align 8
  %5843 = inttoptr i64 %5841 to i32*
  %5844 = load i32, i32* %5843, align 4
  %5845 = add i32 %5844, %5839
  %5846 = zext i32 %5845 to i64
  store i64 %5846, i64* %RDI.i2141, align 8
  %5847 = icmp ult i32 %5845, %5839
  %5848 = icmp ult i32 %5845, %5844
  %5849 = or i1 %5847, %5848
  %5850 = zext i1 %5849 to i8
  store i8 %5850, i8* %18, align 1
  %5851 = and i32 %5845, 255
  %5852 = tail call i32 @llvm.ctpop.i32(i32 %5851)
  %5853 = trunc i32 %5852 to i8
  %5854 = and i8 %5853, 1
  %5855 = xor i8 %5854, 1
  store i8 %5855, i8* %19, align 1
  %5856 = xor i32 %5844, %5839
  %5857 = xor i32 %5856, %5845
  %5858 = lshr i32 %5857, 4
  %5859 = trunc i32 %5858 to i8
  %5860 = and i8 %5859, 1
  store i8 %5860, i8* %20, align 1
  %5861 = icmp eq i32 %5845, 0
  %5862 = zext i1 %5861 to i8
  store i8 %5862, i8* %21, align 1
  %5863 = lshr i32 %5845, 31
  %5864 = trunc i32 %5863 to i8
  store i8 %5864, i8* %22, align 1
  %5865 = lshr i32 %5839, 31
  %5866 = lshr i32 %5844, 31
  %5867 = xor i32 %5863, %5865
  %5868 = xor i32 %5863, %5866
  %5869 = add nuw nsw i32 %5867, %5868
  %5870 = icmp eq i32 %5869, 2
  %5871 = zext i1 %5870 to i8
  store i8 %5871, i8* %23, align 1
  %5872 = sext i32 %5845 to i64
  store i64 %5872, i64* %RCX.i1692, align 8
  %5873 = shl nsw i64 %5872, 2
  %5874 = add i64 %5808, %5873
  %5875 = add i64 %5794, 34
  store i64 %5875, i64* %3, align 8
  %5876 = inttoptr i64 %5874 to i32*
  %5877 = load i32, i32* %5876, align 4
  %5878 = zext i32 %5877 to i64
  store i64 %5878, i64* %RDI.i2141, align 8
  %5879 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %5880 = add i64 %5879, 13112
  store i64 %5880, i64* %RAX.i1763, align 8
  %5881 = icmp ugt i64 %5879, -13113
  %5882 = zext i1 %5881 to i8
  store i8 %5882, i8* %18, align 1
  %5883 = trunc i64 %5880 to i32
  %5884 = and i32 %5883, 255
  %5885 = tail call i32 @llvm.ctpop.i32(i32 %5884)
  %5886 = trunc i32 %5885 to i8
  %5887 = and i8 %5886, 1
  %5888 = xor i8 %5887, 1
  store i8 %5888, i8* %19, align 1
  %5889 = xor i64 %5879, 16
  %5890 = xor i64 %5889, %5880
  %5891 = lshr i64 %5890, 4
  %5892 = trunc i64 %5891 to i8
  %5893 = and i8 %5892, 1
  store i8 %5893, i8* %20, align 1
  %5894 = icmp eq i64 %5880, 0
  %5895 = zext i1 %5894 to i8
  store i8 %5895, i8* %21, align 1
  %5896 = lshr i64 %5880, 63
  %5897 = trunc i64 %5896 to i8
  store i8 %5897, i8* %22, align 1
  %5898 = lshr i64 %5879, 63
  %5899 = xor i64 %5896, %5898
  %5900 = add nuw nsw i64 %5899, %5896
  %5901 = icmp eq i64 %5900, 2
  %5902 = zext i1 %5901 to i8
  store i8 %5902, i8* %23, align 1
  %5903 = add i64 %5835, -44
  %5904 = add i64 %5794, 52
  store i64 %5904, i64* %3, align 8
  %5905 = inttoptr i64 %5903 to i32*
  %5906 = load i32, i32* %5905, align 4
  %5907 = sext i32 %5906 to i64
  %5908 = shl nsw i64 %5907, 6
  store i64 %5908, i64* %RCX.i1692, align 8
  %5909 = add i64 %5908, %5880
  store i64 %5909, i64* %RAX.i1763, align 8
  %5910 = icmp ult i64 %5909, %5880
  %5911 = icmp ult i64 %5909, %5908
  %5912 = or i1 %5910, %5911
  %5913 = zext i1 %5912 to i8
  store i8 %5913, i8* %18, align 1
  %5914 = trunc i64 %5909 to i32
  %5915 = and i32 %5914, 255
  %5916 = tail call i32 @llvm.ctpop.i32(i32 %5915)
  %5917 = trunc i32 %5916 to i8
  %5918 = and i8 %5917, 1
  %5919 = xor i8 %5918, 1
  store i8 %5919, i8* %19, align 1
  %5920 = xor i64 %5880, %5909
  %5921 = lshr i64 %5920, 4
  %5922 = trunc i64 %5921 to i8
  %5923 = and i8 %5922, 1
  store i8 %5923, i8* %20, align 1
  %5924 = icmp eq i64 %5909, 0
  %5925 = zext i1 %5924 to i8
  store i8 %5925, i8* %21, align 1
  %5926 = lshr i64 %5909, 63
  %5927 = trunc i64 %5926 to i8
  store i8 %5927, i8* %22, align 1
  %5928 = lshr i64 %5907, 57
  %5929 = and i64 %5928, 1
  %5930 = xor i64 %5926, %5896
  %5931 = xor i64 %5926, %5929
  %5932 = add nuw nsw i64 %5930, %5931
  %5933 = icmp eq i64 %5932, 2
  %5934 = zext i1 %5933 to i8
  store i8 %5934, i8* %23, align 1
  %5935 = load i64, i64* %RBP.i, align 8
  %5936 = add i64 %5935, -48
  %5937 = add i64 %5794, 63
  store i64 %5937, i64* %3, align 8
  %5938 = inttoptr i64 %5936 to i32*
  %5939 = load i32, i32* %5938, align 4
  %5940 = sext i32 %5939 to i64
  store i64 %5940, i64* %RCX.i1692, align 8
  %5941 = shl nsw i64 %5940, 2
  %5942 = add i64 %5941, %5909
  %5943 = load i32, i32* %EDI.i1845, align 4
  %5944 = add i64 %5794, 66
  store i64 %5944, i64* %3, align 8
  %5945 = inttoptr i64 %5942 to i32*
  store i32 %5943, i32* %5945, align 4
  %5946 = load i64, i64* %RBP.i, align 8
  %5947 = add i64 %5946, -44
  %5948 = load i64, i64* %3, align 8
  %5949 = add i64 %5948, 3
  store i64 %5949, i64* %3, align 8
  %5950 = inttoptr i64 %5947 to i32*
  %5951 = load i32, i32* %5950, align 4
  %5952 = add i32 %5951, 1
  %5953 = zext i32 %5952 to i64
  store i64 %5953, i64* %RAX.i1763, align 8
  %5954 = icmp eq i32 %5951, -1
  %5955 = icmp eq i32 %5952, 0
  %5956 = or i1 %5954, %5955
  %5957 = zext i1 %5956 to i8
  store i8 %5957, i8* %18, align 1
  %5958 = and i32 %5952, 255
  %5959 = tail call i32 @llvm.ctpop.i32(i32 %5958)
  %5960 = trunc i32 %5959 to i8
  %5961 = and i8 %5960, 1
  %5962 = xor i8 %5961, 1
  store i8 %5962, i8* %19, align 1
  %5963 = xor i32 %5952, %5951
  %5964 = lshr i32 %5963, 4
  %5965 = trunc i32 %5964 to i8
  %5966 = and i8 %5965, 1
  store i8 %5966, i8* %20, align 1
  %5967 = zext i1 %5955 to i8
  store i8 %5967, i8* %21, align 1
  %5968 = lshr i32 %5952, 31
  %5969 = trunc i32 %5968 to i8
  store i8 %5969, i8* %22, align 1
  %5970 = lshr i32 %5951, 31
  %5971 = xor i32 %5968, %5970
  %5972 = add nuw nsw i32 %5971, %5968
  %5973 = icmp eq i32 %5972, 2
  %5974 = zext i1 %5973 to i8
  store i8 %5974, i8* %23, align 1
  %5975 = add i64 %5948, 9
  store i64 %5975, i64* %3, align 8
  store i32 %5952, i32* %5950, align 4
  %5976 = load i64, i64* %3, align 8
  %5977 = add i64 %5976, -176
  store i64 %5977, i64* %3, align 8
  br label %block_.L_4a4e1f

block_.L_4a4ed4:                                  ; preds = %block_.L_4a4e1f
  %5978 = add i64 %5613, -48
  %5979 = add i64 %5641, 8
  store i64 %5979, i64* %3, align 8
  %5980 = inttoptr i64 %5978 to i32*
  %5981 = load i32, i32* %5980, align 4
  %5982 = add i32 %5981, 1
  %5983 = zext i32 %5982 to i64
  store i64 %5983, i64* %RAX.i1763, align 8
  %5984 = icmp eq i32 %5981, -1
  %5985 = icmp eq i32 %5982, 0
  %5986 = or i1 %5984, %5985
  %5987 = zext i1 %5986 to i8
  store i8 %5987, i8* %18, align 1
  %5988 = and i32 %5982, 255
  %5989 = tail call i32 @llvm.ctpop.i32(i32 %5988)
  %5990 = trunc i32 %5989 to i8
  %5991 = and i8 %5990, 1
  %5992 = xor i8 %5991, 1
  store i8 %5992, i8* %19, align 1
  %5993 = xor i32 %5982, %5981
  %5994 = lshr i32 %5993, 4
  %5995 = trunc i32 %5994 to i8
  %5996 = and i8 %5995, 1
  store i8 %5996, i8* %20, align 1
  %5997 = zext i1 %5985 to i8
  store i8 %5997, i8* %21, align 1
  %5998 = lshr i32 %5982, 31
  %5999 = trunc i32 %5998 to i8
  store i8 %5999, i8* %22, align 1
  %6000 = lshr i32 %5981, 31
  %6001 = xor i32 %5998, %6000
  %6002 = add nuw nsw i32 %6001, %5998
  %6003 = icmp eq i32 %6002, 2
  %6004 = zext i1 %6003 to i8
  store i8 %6004, i8* %23, align 1
  %6005 = add i64 %5641, 14
  store i64 %6005, i64* %3, align 8
  store i32 %5982, i32* %5980, align 4
  %6006 = load i64, i64* %3, align 8
  %6007 = add i64 %6006, -212
  store i64 %6007, i64* %3, align 8
  br label %block_.L_4a4e0e

block_.L_4a4ee7:                                  ; preds = %block_.L_4a4e0e
  store i64 1, i64* %RDX.i1805, align 8
  %6008 = add i64 %5580, -12
  %6009 = add i64 %5608, 8
  store i64 %6009, i64* %3, align 8
  %6010 = inttoptr i64 %6008 to i32*
  %6011 = load i32, i32* %6010, align 4
  %6012 = add i32 %6011, 8
  %6013 = zext i32 %6012 to i64
  store i64 %6013, i64* %RAX.i1763, align 8
  %6014 = icmp ugt i32 %6011, -9
  %6015 = zext i1 %6014 to i8
  store i8 %6015, i8* %18, align 1
  %6016 = and i32 %6012, 255
  %6017 = tail call i32 @llvm.ctpop.i32(i32 %6016)
  %6018 = trunc i32 %6017 to i8
  %6019 = and i8 %6018, 1
  %6020 = xor i8 %6019, 1
  store i8 %6020, i8* %19, align 1
  %6021 = xor i32 %6012, %6011
  %6022 = lshr i32 %6021, 4
  %6023 = trunc i32 %6022 to i8
  %6024 = and i8 %6023, 1
  store i8 %6024, i8* %20, align 1
  %6025 = icmp eq i32 %6012, 0
  %6026 = zext i1 %6025 to i8
  store i8 %6026, i8* %21, align 1
  %6027 = lshr i32 %6012, 31
  %6028 = trunc i32 %6027 to i8
  store i8 %6028, i8* %22, align 1
  %6029 = lshr i32 %6011, 31
  %6030 = xor i32 %6027, %6029
  %6031 = add nuw nsw i32 %6030, %6027
  %6032 = icmp eq i32 %6031, 2
  %6033 = zext i1 %6032 to i8
  store i8 %6033, i8* %23, align 1
  %6034 = add i64 %5580, -628
  %6035 = add i64 %5608, 17
  store i64 %6035, i64* %3, align 8
  %6036 = inttoptr i64 %6034 to i32*
  %6037 = load i32, i32* %6036, align 4
  %6038 = zext i32 %6037 to i64
  store i64 %6038, i64* %RSI.i1889, align 8
  store i64 %6013, i64* %RDI.i2141, align 8
  %6039 = add i64 %5608, -137671
  %6040 = add i64 %5608, 24
  %6041 = load i64, i64* %6, align 8
  %6042 = add i64 %6041, -8
  %6043 = inttoptr i64 %6042 to i64*
  store i64 %6040, i64* %6043, align 8
  store i64 %6042, i64* %6, align 8
  store i64 %6039, i64* %3, align 8
  %call2_4a4efa = tail call %struct.Memory* @sub_483520.RDCost_for_4x4Blocks_Chroma(%struct.State* nonnull %0, i64 %6039, %struct.Memory* %call2_4a4df6)
  %6044 = load i64, i64* %RAX.i1763, align 8
  %6045 = load i64, i64* %RBP.i, align 8
  %6046 = add i64 %6045, -616
  %6047 = load i64, i64* %3, align 8
  %6048 = add i64 %6047, 6
  store i64 %6048, i64* %3, align 8
  %6049 = trunc i64 %6044 to i32
  %6050 = inttoptr i64 %6046 to i32*
  %6051 = load i32, i32* %6050, align 4
  %6052 = add i32 %6051, %6049
  %6053 = zext i32 %6052 to i64
  store i64 %6053, i64* %RAX.i1763, align 8
  %6054 = icmp ult i32 %6052, %6049
  %6055 = icmp ult i32 %6052, %6051
  %6056 = or i1 %6054, %6055
  %6057 = zext i1 %6056 to i8
  store i8 %6057, i8* %18, align 1
  %6058 = and i32 %6052, 255
  %6059 = tail call i32 @llvm.ctpop.i32(i32 %6058)
  %6060 = trunc i32 %6059 to i8
  %6061 = and i8 %6060, 1
  %6062 = xor i8 %6061, 1
  store i8 %6062, i8* %19, align 1
  %6063 = xor i32 %6051, %6049
  %6064 = xor i32 %6063, %6052
  %6065 = lshr i32 %6064, 4
  %6066 = trunc i32 %6065 to i8
  %6067 = and i8 %6066, 1
  store i8 %6067, i8* %20, align 1
  %6068 = icmp eq i32 %6052, 0
  %6069 = zext i1 %6068 to i8
  store i8 %6069, i8* %21, align 1
  %6070 = lshr i32 %6052, 31
  %6071 = trunc i32 %6070 to i8
  store i8 %6071, i8* %22, align 1
  %6072 = lshr i32 %6049, 31
  %6073 = lshr i32 %6051, 31
  %6074 = xor i32 %6070, %6072
  %6075 = xor i32 %6070, %6073
  %6076 = add nuw nsw i32 %6074, %6075
  %6077 = icmp eq i32 %6076, 2
  %6078 = zext i1 %6077 to i8
  store i8 %6078, i8* %23, align 1
  %6079 = add i64 %6047, 12
  store i64 %6079, i64* %3, align 8
  store i32 %6052, i32* %6050, align 4
  %6080 = load i64, i64* %RBP.i, align 8
  %6081 = add i64 %6080, -48
  %6082 = load i64, i64* %3, align 8
  %6083 = add i64 %6082, 7
  store i64 %6083, i64* %3, align 8
  %6084 = inttoptr i64 %6081 to i32*
  store i32 0, i32* %6084, align 4
  %.pre751 = load i64, i64* %3, align 8
  br label %block_.L_4a4f12

block_.L_4a4f12:                                  ; preds = %block_.L_4a4f88, %block_.L_4a4ee7
  %6085 = phi i64 [ %6359, %block_.L_4a4f88 ], [ %.pre751, %block_.L_4a4ee7 ]
  %6086 = load i64, i64* %RBP.i, align 8
  %6087 = add i64 %6086, -48
  %6088 = add i64 %6085, 4
  store i64 %6088, i64* %3, align 8
  %6089 = inttoptr i64 %6087 to i32*
  %6090 = load i32, i32* %6089, align 4
  %6091 = add i32 %6090, -4
  %6092 = icmp ult i32 %6090, 4
  %6093 = zext i1 %6092 to i8
  store i8 %6093, i8* %18, align 1
  %6094 = and i32 %6091, 255
  %6095 = tail call i32 @llvm.ctpop.i32(i32 %6094)
  %6096 = trunc i32 %6095 to i8
  %6097 = and i8 %6096, 1
  %6098 = xor i8 %6097, 1
  store i8 %6098, i8* %19, align 1
  %6099 = xor i32 %6091, %6090
  %6100 = lshr i32 %6099, 4
  %6101 = trunc i32 %6100 to i8
  %6102 = and i8 %6101, 1
  store i8 %6102, i8* %20, align 1
  %6103 = icmp eq i32 %6091, 0
  %6104 = zext i1 %6103 to i8
  store i8 %6104, i8* %21, align 1
  %6105 = lshr i32 %6091, 31
  %6106 = trunc i32 %6105 to i8
  store i8 %6106, i8* %22, align 1
  %6107 = lshr i32 %6090, 31
  %6108 = xor i32 %6105, %6107
  %6109 = add nuw nsw i32 %6108, %6107
  %6110 = icmp eq i32 %6109, 2
  %6111 = zext i1 %6110 to i8
  store i8 %6111, i8* %23, align 1
  %6112 = icmp ne i8 %6106, 0
  %6113 = xor i1 %6112, %6110
  %.v802 = select i1 %6113, i64 10, i64 137
  %6114 = add i64 %6085, %.v802
  store i64 %6114, i64* %3, align 8
  br i1 %6113, label %block_4a4f1c, label %block_.L_4a4f9b

block_4a4f1c:                                     ; preds = %block_.L_4a4f12
  %6115 = add i64 %6086, -44
  %6116 = add i64 %6114, 7
  store i64 %6116, i64* %3, align 8
  %6117 = inttoptr i64 %6115 to i32*
  store i32 0, i32* %6117, align 4
  %.pre752 = load i64, i64* %3, align 8
  br label %block_.L_4a4f23

block_.L_4a4f23:                                  ; preds = %block_4a4f2d, %block_4a4f1c
  %6118 = phi i64 [ %6329, %block_4a4f2d ], [ %.pre752, %block_4a4f1c ]
  %6119 = load i64, i64* %RBP.i, align 8
  %6120 = add i64 %6119, -44
  %6121 = add i64 %6118, 4
  store i64 %6121, i64* %3, align 8
  %6122 = inttoptr i64 %6120 to i32*
  %6123 = load i32, i32* %6122, align 4
  %6124 = add i32 %6123, -4
  %6125 = icmp ult i32 %6123, 4
  %6126 = zext i1 %6125 to i8
  store i8 %6126, i8* %18, align 1
  %6127 = and i32 %6124, 255
  %6128 = tail call i32 @llvm.ctpop.i32(i32 %6127)
  %6129 = trunc i32 %6128 to i8
  %6130 = and i8 %6129, 1
  %6131 = xor i8 %6130, 1
  store i8 %6131, i8* %19, align 1
  %6132 = xor i32 %6124, %6123
  %6133 = lshr i32 %6132, 4
  %6134 = trunc i32 %6133 to i8
  %6135 = and i8 %6134, 1
  store i8 %6135, i8* %20, align 1
  %6136 = icmp eq i32 %6124, 0
  %6137 = zext i1 %6136 to i8
  store i8 %6137, i8* %21, align 1
  %6138 = lshr i32 %6124, 31
  %6139 = trunc i32 %6138 to i8
  store i8 %6139, i8* %22, align 1
  %6140 = lshr i32 %6123, 31
  %6141 = xor i32 %6138, %6140
  %6142 = add nuw nsw i32 %6141, %6140
  %6143 = icmp eq i32 %6142, 2
  %6144 = zext i1 %6143 to i8
  store i8 %6144, i8* %23, align 1
  %6145 = icmp ne i8 %6139, 0
  %6146 = xor i1 %6145, %6143
  %.v803 = select i1 %6146, i64 10, i64 101
  %6147 = add i64 %6118, %.v803
  store i64 %6147, i64* %3, align 8
  br i1 %6146, label %block_4a4f2d, label %block_.L_4a4f88

block_4a4f2d:                                     ; preds = %block_.L_4a4f23
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RAX.i1763, align 8
  %6148 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %6149 = add i64 %6148, 13112
  store i64 %6149, i64* %RCX.i1692, align 8
  %6150 = icmp ugt i64 %6148, -13113
  %6151 = zext i1 %6150 to i8
  store i8 %6151, i8* %18, align 1
  %6152 = trunc i64 %6149 to i32
  %6153 = and i32 %6152, 255
  %6154 = tail call i32 @llvm.ctpop.i32(i32 %6153)
  %6155 = trunc i32 %6154 to i8
  %6156 = and i8 %6155, 1
  %6157 = xor i8 %6156, 1
  store i8 %6157, i8* %19, align 1
  %6158 = xor i64 %6148, 16
  %6159 = xor i64 %6158, %6149
  %6160 = lshr i64 %6159, 4
  %6161 = trunc i64 %6160 to i8
  %6162 = and i8 %6161, 1
  store i8 %6162, i8* %20, align 1
  %6163 = icmp eq i64 %6149, 0
  %6164 = zext i1 %6163 to i8
  store i8 %6164, i8* %21, align 1
  %6165 = lshr i64 %6149, 63
  %6166 = trunc i64 %6165 to i8
  store i8 %6166, i8* %22, align 1
  %6167 = lshr i64 %6148, 63
  %6168 = xor i64 %6165, %6167
  %6169 = add nuw nsw i64 %6168, %6165
  %6170 = icmp eq i64 %6169, 2
  %6171 = zext i1 %6170 to i8
  store i8 %6171, i8* %23, align 1
  %6172 = add i64 %6147, 29
  store i64 %6172, i64* %3, align 8
  %6173 = load i32, i32* %6122, align 4
  %6174 = sext i32 %6173 to i64
  %6175 = shl nsw i64 %6174, 6
  store i64 %6175, i64* %RDX.i1805, align 8
  %6176 = add i64 %6175, %6149
  store i64 %6176, i64* %RCX.i1692, align 8
  %6177 = icmp ult i64 %6176, %6149
  %6178 = icmp ult i64 %6176, %6175
  %6179 = or i1 %6177, %6178
  %6180 = zext i1 %6179 to i8
  store i8 %6180, i8* %18, align 1
  %6181 = trunc i64 %6176 to i32
  %6182 = and i32 %6181, 255
  %6183 = tail call i32 @llvm.ctpop.i32(i32 %6182)
  %6184 = trunc i32 %6183 to i8
  %6185 = and i8 %6184, 1
  %6186 = xor i8 %6185, 1
  store i8 %6186, i8* %19, align 1
  %6187 = xor i64 %6149, %6176
  %6188 = lshr i64 %6187, 4
  %6189 = trunc i64 %6188 to i8
  %6190 = and i8 %6189, 1
  store i8 %6190, i8* %20, align 1
  %6191 = icmp eq i64 %6176, 0
  %6192 = zext i1 %6191 to i8
  store i8 %6192, i8* %21, align 1
  %6193 = lshr i64 %6176, 63
  %6194 = trunc i64 %6193 to i8
  store i8 %6194, i8* %22, align 1
  %6195 = lshr i64 %6174, 57
  %6196 = and i64 %6195, 1
  %6197 = xor i64 %6193, %6165
  %6198 = xor i64 %6193, %6196
  %6199 = add nuw nsw i64 %6197, %6198
  %6200 = icmp eq i64 %6199, 2
  %6201 = zext i1 %6200 to i8
  store i8 %6201, i8* %23, align 1
  %6202 = load i64, i64* %RBP.i, align 8
  %6203 = add i64 %6202, -48
  %6204 = add i64 %6147, 40
  store i64 %6204, i64* %3, align 8
  %6205 = inttoptr i64 %6203 to i32*
  %6206 = load i32, i32* %6205, align 4
  %6207 = sext i32 %6206 to i64
  store i64 %6207, i64* %RDX.i1805, align 8
  %6208 = shl nsw i64 %6207, 2
  %6209 = add i64 %6208, %6176
  %6210 = add i64 %6147, 43
  store i64 %6210, i64* %3, align 8
  %6211 = inttoptr i64 %6209 to i32*
  %6212 = load i32, i32* %6211, align 4
  %6213 = zext i32 %6212 to i64
  store i64 %6213, i64* %RSI.i1889, align 8
  %6214 = add i64 %6202, -44
  %6215 = add i64 %6147, 46
  store i64 %6215, i64* %3, align 8
  %6216 = inttoptr i64 %6214 to i32*
  %6217 = load i32, i32* %6216, align 4
  %6218 = zext i32 %6217 to i64
  store i64 %6218, i64* %RDI.i2141, align 8
  %6219 = add i64 %6202, -476
  %6220 = add i64 %6147, 52
  store i64 %6220, i64* %3, align 8
  %6221 = inttoptr i64 %6219 to i32*
  %6222 = load i32, i32* %6221, align 4
  %6223 = add i32 %6222, %6217
  %6224 = zext i32 %6223 to i64
  store i64 %6224, i64* %RDI.i2141, align 8
  %6225 = sext i32 %6223 to i64
  %6226 = shl nsw i64 %6225, 6
  store i64 %6226, i64* %RCX.i1692, align 8
  %6227 = load i64, i64* %RAX.i1763, align 8
  %6228 = add i64 %6226, %6227
  store i64 %6228, i64* %RAX.i1763, align 8
  %6229 = icmp ult i64 %6228, %6227
  %6230 = icmp ult i64 %6228, %6226
  %6231 = or i1 %6229, %6230
  %6232 = zext i1 %6231 to i8
  store i8 %6232, i8* %18, align 1
  %6233 = trunc i64 %6228 to i32
  %6234 = and i32 %6233, 255
  %6235 = tail call i32 @llvm.ctpop.i32(i32 %6234)
  %6236 = trunc i32 %6235 to i8
  %6237 = and i8 %6236, 1
  %6238 = xor i8 %6237, 1
  store i8 %6238, i8* %19, align 1
  %6239 = xor i64 %6227, %6228
  %6240 = lshr i64 %6239, 4
  %6241 = trunc i64 %6240 to i8
  %6242 = and i8 %6241, 1
  store i8 %6242, i8* %20, align 1
  %6243 = icmp eq i64 %6228, 0
  %6244 = zext i1 %6243 to i8
  store i8 %6244, i8* %21, align 1
  %6245 = lshr i64 %6228, 63
  %6246 = trunc i64 %6245 to i8
  store i8 %6246, i8* %22, align 1
  %6247 = lshr i64 %6227, 63
  %6248 = lshr i64 %6225, 57
  %6249 = and i64 %6248, 1
  %6250 = xor i64 %6245, %6247
  %6251 = xor i64 %6245, %6249
  %6252 = add nuw nsw i64 %6250, %6251
  %6253 = icmp eq i64 %6252, 2
  %6254 = zext i1 %6253 to i8
  store i8 %6254, i8* %23, align 1
  %6255 = load i64, i64* %RBP.i, align 8
  %6256 = add i64 %6255, -48
  %6257 = add i64 %6147, 65
  store i64 %6257, i64* %3, align 8
  %6258 = inttoptr i64 %6256 to i32*
  %6259 = load i32, i32* %6258, align 4
  %6260 = zext i32 %6259 to i64
  store i64 %6260, i64* %RDI.i2141, align 8
  %6261 = add i64 %6255, -480
  %6262 = add i64 %6147, 71
  store i64 %6262, i64* %3, align 8
  %6263 = inttoptr i64 %6261 to i32*
  %6264 = load i32, i32* %6263, align 4
  %6265 = add i32 %6264, %6259
  %6266 = zext i32 %6265 to i64
  store i64 %6266, i64* %RDI.i2141, align 8
  %6267 = icmp ult i32 %6265, %6259
  %6268 = icmp ult i32 %6265, %6264
  %6269 = or i1 %6267, %6268
  %6270 = zext i1 %6269 to i8
  store i8 %6270, i8* %18, align 1
  %6271 = and i32 %6265, 255
  %6272 = tail call i32 @llvm.ctpop.i32(i32 %6271)
  %6273 = trunc i32 %6272 to i8
  %6274 = and i8 %6273, 1
  %6275 = xor i8 %6274, 1
  store i8 %6275, i8* %19, align 1
  %6276 = xor i32 %6264, %6259
  %6277 = xor i32 %6276, %6265
  %6278 = lshr i32 %6277, 4
  %6279 = trunc i32 %6278 to i8
  %6280 = and i8 %6279, 1
  store i8 %6280, i8* %20, align 1
  %6281 = icmp eq i32 %6265, 0
  %6282 = zext i1 %6281 to i8
  store i8 %6282, i8* %21, align 1
  %6283 = lshr i32 %6265, 31
  %6284 = trunc i32 %6283 to i8
  store i8 %6284, i8* %22, align 1
  %6285 = lshr i32 %6259, 31
  %6286 = lshr i32 %6264, 31
  %6287 = xor i32 %6283, %6285
  %6288 = xor i32 %6283, %6286
  %6289 = add nuw nsw i32 %6287, %6288
  %6290 = icmp eq i32 %6289, 2
  %6291 = zext i1 %6290 to i8
  store i8 %6291, i8* %23, align 1
  %6292 = sext i32 %6265 to i64
  store i64 %6292, i64* %RCX.i1692, align 8
  %6293 = shl nsw i64 %6292, 2
  %6294 = add i64 %6228, %6293
  %6295 = load i32, i32* %ESI.i7670, align 4
  %6296 = add i64 %6147, 77
  store i64 %6296, i64* %3, align 8
  %6297 = inttoptr i64 %6294 to i32*
  store i32 %6295, i32* %6297, align 4
  %6298 = load i64, i64* %RBP.i, align 8
  %6299 = add i64 %6298, -44
  %6300 = load i64, i64* %3, align 8
  %6301 = add i64 %6300, 3
  store i64 %6301, i64* %3, align 8
  %6302 = inttoptr i64 %6299 to i32*
  %6303 = load i32, i32* %6302, align 4
  %6304 = add i32 %6303, 1
  %6305 = zext i32 %6304 to i64
  store i64 %6305, i64* %RAX.i1763, align 8
  %6306 = icmp eq i32 %6303, -1
  %6307 = icmp eq i32 %6304, 0
  %6308 = or i1 %6306, %6307
  %6309 = zext i1 %6308 to i8
  store i8 %6309, i8* %18, align 1
  %6310 = and i32 %6304, 255
  %6311 = tail call i32 @llvm.ctpop.i32(i32 %6310)
  %6312 = trunc i32 %6311 to i8
  %6313 = and i8 %6312, 1
  %6314 = xor i8 %6313, 1
  store i8 %6314, i8* %19, align 1
  %6315 = xor i32 %6304, %6303
  %6316 = lshr i32 %6315, 4
  %6317 = trunc i32 %6316 to i8
  %6318 = and i8 %6317, 1
  store i8 %6318, i8* %20, align 1
  %6319 = zext i1 %6307 to i8
  store i8 %6319, i8* %21, align 1
  %6320 = lshr i32 %6304, 31
  %6321 = trunc i32 %6320 to i8
  store i8 %6321, i8* %22, align 1
  %6322 = lshr i32 %6303, 31
  %6323 = xor i32 %6320, %6322
  %6324 = add nuw nsw i32 %6323, %6320
  %6325 = icmp eq i32 %6324, 2
  %6326 = zext i1 %6325 to i8
  store i8 %6326, i8* %23, align 1
  %6327 = add i64 %6300, 9
  store i64 %6327, i64* %3, align 8
  store i32 %6304, i32* %6302, align 4
  %6328 = load i64, i64* %3, align 8
  %6329 = add i64 %6328, -96
  store i64 %6329, i64* %3, align 8
  br label %block_.L_4a4f23

block_.L_4a4f88:                                  ; preds = %block_.L_4a4f23
  %6330 = add i64 %6119, -48
  %6331 = add i64 %6147, 8
  store i64 %6331, i64* %3, align 8
  %6332 = inttoptr i64 %6330 to i32*
  %6333 = load i32, i32* %6332, align 4
  %6334 = add i32 %6333, 1
  %6335 = zext i32 %6334 to i64
  store i64 %6335, i64* %RAX.i1763, align 8
  %6336 = icmp eq i32 %6333, -1
  %6337 = icmp eq i32 %6334, 0
  %6338 = or i1 %6336, %6337
  %6339 = zext i1 %6338 to i8
  store i8 %6339, i8* %18, align 1
  %6340 = and i32 %6334, 255
  %6341 = tail call i32 @llvm.ctpop.i32(i32 %6340)
  %6342 = trunc i32 %6341 to i8
  %6343 = and i8 %6342, 1
  %6344 = xor i8 %6343, 1
  store i8 %6344, i8* %19, align 1
  %6345 = xor i32 %6334, %6333
  %6346 = lshr i32 %6345, 4
  %6347 = trunc i32 %6346 to i8
  %6348 = and i8 %6347, 1
  store i8 %6348, i8* %20, align 1
  %6349 = zext i1 %6337 to i8
  store i8 %6349, i8* %21, align 1
  %6350 = lshr i32 %6334, 31
  %6351 = trunc i32 %6350 to i8
  store i8 %6351, i8* %22, align 1
  %6352 = lshr i32 %6333, 31
  %6353 = xor i32 %6350, %6352
  %6354 = add nuw nsw i32 %6353, %6350
  %6355 = icmp eq i32 %6354, 2
  %6356 = zext i1 %6355 to i8
  store i8 %6356, i8* %23, align 1
  %6357 = add i64 %6147, 14
  store i64 %6357, i64* %3, align 8
  store i32 %6334, i32* %6332, align 4
  %6358 = load i64, i64* %3, align 8
  %6359 = add i64 %6358, -132
  store i64 %6359, i64* %3, align 8
  br label %block_.L_4a4f12

block_.L_4a4f9b:                                  ; preds = %block_.L_4a4f12
  %6360 = add i64 %6086, -628
  %6361 = add i64 %6114, 11
  store i64 %6361, i64* %3, align 8
  %6362 = inttoptr i64 %6360 to i32*
  %6363 = load i32, i32* %6362, align 4
  %6364 = add i32 %6363, 1
  %6365 = zext i32 %6364 to i64
  store i64 %6365, i64* %RAX.i1763, align 8
  %6366 = icmp eq i32 %6363, -1
  %6367 = icmp eq i32 %6364, 0
  %6368 = or i1 %6366, %6367
  %6369 = zext i1 %6368 to i8
  store i8 %6369, i8* %18, align 1
  %6370 = and i32 %6364, 255
  %6371 = tail call i32 @llvm.ctpop.i32(i32 %6370)
  %6372 = trunc i32 %6371 to i8
  %6373 = and i8 %6372, 1
  %6374 = xor i8 %6373, 1
  store i8 %6374, i8* %19, align 1
  %6375 = xor i32 %6364, %6363
  %6376 = lshr i32 %6375, 4
  %6377 = trunc i32 %6376 to i8
  %6378 = and i8 %6377, 1
  store i8 %6378, i8* %20, align 1
  %6379 = zext i1 %6367 to i8
  store i8 %6379, i8* %21, align 1
  %6380 = lshr i32 %6364, 31
  %6381 = trunc i32 %6380 to i8
  store i8 %6381, i8* %22, align 1
  %6382 = lshr i32 %6363, 31
  %6383 = xor i32 %6380, %6382
  %6384 = add nuw nsw i32 %6383, %6380
  %6385 = icmp eq i32 %6384, 2
  %6386 = zext i1 %6385 to i8
  store i8 %6386, i8* %23, align 1
  %6387 = add i64 %6114, 20
  store i64 %6387, i64* %3, align 8
  store i32 %6364, i32* %6362, align 4
  %6388 = load i64, i64* %3, align 8
  %6389 = add i64 %6388, -670
  store i64 %6389, i64* %3, align 8
  br label %block_.L_4a4d11

block_.L_4a4fb4:                                  ; preds = %block_.L_4a4d11
  store i8 0, i8* %AL.i6276, align 1
  %6390 = add i64 %5124, -30964
  %6391 = add i64 %5124, 7
  %6392 = load i64, i64* %6, align 8
  %6393 = add i64 %6392, -8
  %6394 = inttoptr i64 %6393 to i64*
  store i64 %6391, i64* %6394, align 8
  store i64 %6393, i64* %6, align 8
  store i64 %6390, i64* %3, align 8
  %call2_4a4fb6 = tail call %struct.Memory* @sub_49d6c0.reset_coding_state_cs_cm(%struct.State* nonnull %0, i64 %6390, %struct.Memory* %MEMORY.36)
  %6395 = load i64, i64* %RBP.i, align 8
  %6396 = add i64 %6395, -48
  %6397 = load i64, i64* %3, align 8
  %6398 = add i64 %6397, 7
  store i64 %6398, i64* %3, align 8
  %6399 = inttoptr i64 %6396 to i32*
  store i32 0, i32* %6399, align 4
  %.pre671 = load i64, i64* %3, align 8
  br label %block_.L_4a4fc2

block_.L_4a4fc2:                                  ; preds = %block_.L_4a5637, %block_.L_4a4fb4
  %6400 = phi i64 [ %9476, %block_.L_4a5637 ], [ %.pre671, %block_.L_4a4fb4 ]
  %6401 = load i64, i64* %RBP.i, align 8
  %6402 = add i64 %6401, -48
  %6403 = add i64 %6400, 4
  store i64 %6403, i64* %3, align 8
  %6404 = inttoptr i64 %6402 to i32*
  %6405 = load i32, i32* %6404, align 4
  %6406 = add i32 %6405, -8
  %6407 = icmp ult i32 %6405, 8
  %6408 = zext i1 %6407 to i8
  store i8 %6408, i8* %18, align 1
  %6409 = and i32 %6406, 255
  %6410 = tail call i32 @llvm.ctpop.i32(i32 %6409)
  %6411 = trunc i32 %6410 to i8
  %6412 = and i8 %6411, 1
  %6413 = xor i8 %6412, 1
  store i8 %6413, i8* %19, align 1
  %6414 = xor i32 %6406, %6405
  %6415 = lshr i32 %6414, 4
  %6416 = trunc i32 %6415 to i8
  %6417 = and i8 %6416, 1
  store i8 %6417, i8* %20, align 1
  %6418 = icmp eq i32 %6406, 0
  %6419 = zext i1 %6418 to i8
  store i8 %6419, i8* %21, align 1
  %6420 = lshr i32 %6406, 31
  %6421 = trunc i32 %6420 to i8
  store i8 %6421, i8* %22, align 1
  %6422 = lshr i32 %6405, 31
  %6423 = xor i32 %6420, %6422
  %6424 = add nuw nsw i32 %6423, %6422
  %6425 = icmp eq i32 %6424, 2
  %6426 = zext i1 %6425 to i8
  store i8 %6426, i8* %23, align 1
  %6427 = icmp ne i8 %6421, 0
  %6428 = xor i1 %6427, %6425
  %.v849 = select i1 %6428, i64 10, i64 1672
  %6429 = add i64 %6400, %.v849
  store i64 %6429, i64* %3, align 8
  br i1 %6428, label %block_4a4fcc, label %block_.L_4a564a

block_4a4fcc:                                     ; preds = %block_.L_4a4fc2
  %6430 = add i64 %6401, -44
  %6431 = add i64 %6429, 7
  store i64 %6431, i64* %3, align 8
  %6432 = inttoptr i64 %6430 to i32*
  store i32 0, i32* %6432, align 4
  %.pre733 = load i64, i64* %3, align 8
  br label %block_.L_4a4fd3

block_.L_4a4fd3:                                  ; preds = %block_.L_4a55ed, %block_4a4fcc
  %6433 = phi i64 [ %9446, %block_.L_4a55ed ], [ %.pre733, %block_4a4fcc ]
  %6434 = load i64, i64* %RBP.i, align 8
  %6435 = add i64 %6434, -44
  %6436 = add i64 %6433, 4
  store i64 %6436, i64* %3, align 8
  %6437 = inttoptr i64 %6435 to i32*
  %6438 = load i32, i32* %6437, align 4
  %6439 = add i32 %6438, -8
  %6440 = icmp ult i32 %6438, 8
  %6441 = zext i1 %6440 to i8
  store i8 %6441, i8* %18, align 1
  %6442 = and i32 %6439, 255
  %6443 = tail call i32 @llvm.ctpop.i32(i32 %6442)
  %6444 = trunc i32 %6443 to i8
  %6445 = and i8 %6444, 1
  %6446 = xor i8 %6445, 1
  store i8 %6446, i8* %19, align 1
  %6447 = xor i32 %6439, %6438
  %6448 = lshr i32 %6447, 4
  %6449 = trunc i32 %6448 to i8
  %6450 = and i8 %6449, 1
  store i8 %6450, i8* %20, align 1
  %6451 = icmp eq i32 %6439, 0
  %6452 = zext i1 %6451 to i8
  store i8 %6452, i8* %21, align 1
  %6453 = lshr i32 %6439, 31
  %6454 = trunc i32 %6453 to i8
  store i8 %6454, i8* %22, align 1
  %6455 = lshr i32 %6438, 31
  %6456 = xor i32 %6453, %6455
  %6457 = add nuw nsw i32 %6456, %6455
  %6458 = icmp eq i32 %6457, 2
  %6459 = zext i1 %6458 to i8
  store i8 %6459, i8* %23, align 1
  %6460 = icmp ne i8 %6454, 0
  %6461 = xor i1 %6460, %6458
  %.v801 = select i1 %6461, i64 10, i64 1636
  %6462 = add i64 %6433, %.v801
  store i64 %6462, i64* %3, align 8
  br i1 %6461, label %block_4a4fdd, label %block_.L_4a5637

block_4a4fdd:                                     ; preds = %block_.L_4a4fd3
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX.i1692, align 8
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RDX.i1805, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RSI.i1889, align 8
  %6463 = add i64 %6462, 36
  store i64 %6463, i64* %3, align 8
  %6464 = load i32, i32* %6437, align 4
  %6465 = sext i32 %6464 to i64
  %6466 = shl nsw i64 %6465, 6
  store i64 %6466, i64* %RDI.i2141, align 8
  %6467 = add i64 %6466, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  store i64 %6467, i64* %RSI.i1889, align 8
  %6468 = icmp ult i64 %6467, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  %6469 = icmp ult i64 %6467, %6466
  %6470 = or i1 %6468, %6469
  %6471 = zext i1 %6470 to i8
  store i8 %6471, i8* %18, align 1
  %6472 = trunc i64 %6467 to i32
  %6473 = and i32 %6472, 248
  %6474 = tail call i32 @llvm.ctpop.i32(i32 %6473)
  %6475 = trunc i32 %6474 to i8
  %6476 = and i8 %6475, 1
  %6477 = xor i8 %6476, 1
  store i8 %6477, i8* %19, align 1
  %6478 = xor i64 %6467, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  %6479 = lshr i64 %6478, 4
  %6480 = trunc i64 %6479 to i8
  %6481 = and i8 %6480, 1
  store i8 %6481, i8* %20, align 1
  %6482 = icmp eq i64 %6467, 0
  %6483 = zext i1 %6482 to i8
  store i8 %6483, i8* %21, align 1
  %6484 = lshr i64 %6467, 63
  %6485 = trunc i64 %6484 to i8
  store i8 %6485, i8* %22, align 1
  %6486 = lshr i64 %6465, 57
  %6487 = and i64 %6486, 1
  %6488 = xor i64 %6484, lshr (i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64 63)
  %6489 = xor i64 %6484, %6487
  %6490 = add nuw nsw i64 %6488, %6489
  %6491 = icmp eq i64 %6490, 2
  %6492 = zext i1 %6491 to i8
  store i8 %6492, i8* %23, align 1
  %6493 = add i64 %6434, -48
  %6494 = add i64 %6462, 47
  store i64 %6494, i64* %3, align 8
  %6495 = inttoptr i64 %6493 to i32*
  %6496 = load i32, i32* %6495, align 4
  %6497 = sext i32 %6496 to i64
  store i64 %6497, i64* %RDI.i2141, align 8
  %6498 = shl nsw i64 %6497, 2
  %6499 = add i64 %6498, %6467
  %6500 = add i64 %6462, 51
  store i64 %6500, i64* %3, align 8
  %6501 = inttoptr i64 %6499 to i32*
  %6502 = load i32, i32* %6501, align 4
  %6503 = zext i32 %6502 to i64
  store i64 %6503, i64* %26, align 8
  %6504 = load i64, i64* %RBP.i, align 8
  %6505 = add i64 %6504, -44
  %6506 = add i64 %6462, 55
  store i64 %6506, i64* %3, align 8
  %6507 = inttoptr i64 %6505 to i32*
  %6508 = load i32, i32* %6507, align 4
  %6509 = sext i32 %6508 to i64
  %6510 = shl nsw i64 %6509, 6
  store i64 %6510, i64* %RSI.i1889, align 8
  %6511 = load i64, i64* %RDX.i1805, align 8
  %6512 = add i64 %6510, %6511
  store i64 %6512, i64* %RDI.i2141, align 8
  %6513 = icmp ult i64 %6512, %6511
  %6514 = icmp ult i64 %6512, %6510
  %6515 = or i1 %6513, %6514
  %6516 = zext i1 %6515 to i8
  store i8 %6516, i8* %18, align 1
  %6517 = trunc i64 %6512 to i32
  %6518 = and i32 %6517, 255
  %6519 = tail call i32 @llvm.ctpop.i32(i32 %6518)
  %6520 = trunc i32 %6519 to i8
  %6521 = and i8 %6520, 1
  %6522 = xor i8 %6521, 1
  store i8 %6522, i8* %19, align 1
  %6523 = xor i64 %6511, %6512
  %6524 = lshr i64 %6523, 4
  %6525 = trunc i64 %6524 to i8
  %6526 = and i8 %6525, 1
  store i8 %6526, i8* %20, align 1
  %6527 = icmp eq i64 %6512, 0
  %6528 = zext i1 %6527 to i8
  store i8 %6528, i8* %21, align 1
  %6529 = lshr i64 %6512, 63
  %6530 = trunc i64 %6529 to i8
  store i8 %6530, i8* %22, align 1
  %6531 = lshr i64 %6511, 63
  %6532 = lshr i64 %6509, 57
  %6533 = and i64 %6532, 1
  %6534 = xor i64 %6529, %6531
  %6535 = xor i64 %6529, %6533
  %6536 = add nuw nsw i64 %6534, %6535
  %6537 = icmp eq i64 %6536, 2
  %6538 = zext i1 %6537 to i8
  store i8 %6538, i8* %23, align 1
  %6539 = add i64 %6504, -48
  %6540 = add i64 %6462, 69
  store i64 %6540, i64* %3, align 8
  %6541 = inttoptr i64 %6539 to i32*
  %6542 = load i32, i32* %6541, align 4
  %6543 = sext i32 %6542 to i64
  store i64 %6543, i64* %RSI.i1889, align 8
  %6544 = shl nsw i64 %6543, 2
  %6545 = add i64 %6544, %6512
  %6546 = add i64 %6462, 73
  store i64 %6546, i64* %3, align 8
  %6547 = inttoptr i64 %6545 to i32*
  %6548 = load i32, i32* %6547, align 4
  %6549 = zext i32 %6548 to i64
  %6550 = shl nuw i64 %6549, 32
  %6551 = ashr i64 %6550, 33
  %6552 = and i64 %6551, 4294967295
  store i64 %6552, i64* %R9.i, align 8
  %6553 = load i32, i32* %R8D.i1718, align 4
  %6554 = trunc i64 %6551 to i32
  %6555 = sub i32 %6553, %6554
  %6556 = zext i32 %6555 to i64
  store i64 %6556, i64* %26, align 8
  %6557 = icmp ult i32 %6553, %6554
  %6558 = zext i1 %6557 to i8
  store i8 %6558, i8* %18, align 1
  %6559 = and i32 %6555, 255
  %6560 = tail call i32 @llvm.ctpop.i32(i32 %6559)
  %6561 = trunc i32 %6560 to i8
  %6562 = and i8 %6561, 1
  %6563 = xor i8 %6562, 1
  store i8 %6563, i8* %19, align 1
  %6564 = xor i32 %6554, %6553
  %6565 = xor i32 %6564, %6555
  %6566 = lshr i32 %6565, 4
  %6567 = trunc i32 %6566 to i8
  %6568 = and i8 %6567, 1
  store i8 %6568, i8* %20, align 1
  %6569 = icmp eq i32 %6555, 0
  %6570 = zext i1 %6569 to i8
  store i8 %6570, i8* %21, align 1
  %6571 = lshr i32 %6555, 31
  %6572 = trunc i32 %6571 to i8
  store i8 %6572, i8* %22, align 1
  %6573 = lshr i32 %6553, 31
  %6574 = lshr i64 %6551, 31
  %6575 = trunc i64 %6574 to i32
  %6576 = and i32 %6575, 1
  %6577 = xor i32 %6576, %6573
  %6578 = xor i32 %6571, %6573
  %6579 = add nuw nsw i32 %6578, %6577
  %6580 = icmp eq i32 %6579, 2
  %6581 = zext i1 %6580 to i8
  store i8 %6581, i8* %23, align 1
  %6582 = load i64, i64* %RBP.i, align 8
  %6583 = add i64 %6582, -624
  %6584 = add i64 %6462, 86
  store i64 %6584, i64* %3, align 8
  %6585 = inttoptr i64 %6583 to i32*
  store i32 %6555, i32* %6585, align 4
  %6586 = load i64, i64* %RBP.i, align 8
  %6587 = add i64 %6586, -44
  %6588 = load i64, i64* %3, align 8
  %6589 = add i64 %6588, 4
  store i64 %6589, i64* %3, align 8
  %6590 = inttoptr i64 %6587 to i32*
  %6591 = load i32, i32* %6590, align 4
  %6592 = sext i32 %6591 to i64
  %6593 = shl nsw i64 %6592, 6
  store i64 %6593, i64* %RSI.i1889, align 8
  %6594 = load i64, i64* %RDX.i1805, align 8
  %6595 = add i64 %6593, %6594
  store i64 %6595, i64* %RDX.i1805, align 8
  %6596 = icmp ult i64 %6595, %6594
  %6597 = icmp ult i64 %6595, %6593
  %6598 = or i1 %6596, %6597
  %6599 = zext i1 %6598 to i8
  store i8 %6599, i8* %18, align 1
  %6600 = trunc i64 %6595 to i32
  %6601 = and i32 %6600, 255
  %6602 = tail call i32 @llvm.ctpop.i32(i32 %6601)
  %6603 = trunc i32 %6602 to i8
  %6604 = and i8 %6603, 1
  %6605 = xor i8 %6604, 1
  store i8 %6605, i8* %19, align 1
  %6606 = xor i64 %6594, %6595
  %6607 = lshr i64 %6606, 4
  %6608 = trunc i64 %6607 to i8
  %6609 = and i8 %6608, 1
  store i8 %6609, i8* %20, align 1
  %6610 = icmp eq i64 %6595, 0
  %6611 = zext i1 %6610 to i8
  store i8 %6611, i8* %21, align 1
  %6612 = lshr i64 %6595, 63
  %6613 = trunc i64 %6612 to i8
  store i8 %6613, i8* %22, align 1
  %6614 = lshr i64 %6594, 63
  %6615 = lshr i64 %6592, 57
  %6616 = and i64 %6615, 1
  %6617 = xor i64 %6612, %6614
  %6618 = xor i64 %6612, %6616
  %6619 = add nuw nsw i64 %6617, %6618
  %6620 = icmp eq i64 %6619, 2
  %6621 = zext i1 %6620 to i8
  store i8 %6621, i8* %23, align 1
  %6622 = add i64 %6586, -48
  %6623 = add i64 %6588, 15
  store i64 %6623, i64* %3, align 8
  %6624 = inttoptr i64 %6622 to i32*
  %6625 = load i32, i32* %6624, align 4
  %6626 = sext i32 %6625 to i64
  store i64 %6626, i64* %RSI.i1889, align 8
  %6627 = shl nsw i64 %6626, 2
  %6628 = add i64 %6627, %6595
  %6629 = add i64 %6588, 19
  store i64 %6629, i64* %3, align 8
  %6630 = inttoptr i64 %6628 to i32*
  %6631 = load i32, i32* %6630, align 4
  %6632 = zext i32 %6631 to i64
  store i64 %6632, i64* %26, align 8
  %6633 = add i64 %6586, -624
  %6634 = add i64 %6588, 26
  store i64 %6634, i64* %3, align 8
  %6635 = inttoptr i64 %6633 to i32*
  %6636 = load i32, i32* %6635, align 4
  %6637 = add i32 %6636, %6631
  %6638 = zext i32 %6637 to i64
  store i64 %6638, i64* %26, align 8
  %6639 = icmp ult i32 %6637, %6631
  %6640 = icmp ult i32 %6637, %6636
  %6641 = or i1 %6639, %6640
  %6642 = zext i1 %6641 to i8
  store i8 %6642, i8* %18, align 1
  %6643 = and i32 %6637, 255
  %6644 = tail call i32 @llvm.ctpop.i32(i32 %6643)
  %6645 = trunc i32 %6644 to i8
  %6646 = and i8 %6645, 1
  %6647 = xor i8 %6646, 1
  store i8 %6647, i8* %19, align 1
  %6648 = xor i32 %6636, %6631
  %6649 = xor i32 %6648, %6637
  %6650 = lshr i32 %6649, 4
  %6651 = trunc i32 %6650 to i8
  %6652 = and i8 %6651, 1
  store i8 %6652, i8* %20, align 1
  %6653 = icmp eq i32 %6637, 0
  %6654 = zext i1 %6653 to i8
  store i8 %6654, i8* %21, align 1
  %6655 = lshr i32 %6637, 31
  %6656 = trunc i32 %6655 to i8
  store i8 %6656, i8* %22, align 1
  %6657 = lshr i32 %6631, 31
  %6658 = lshr i32 %6636, 31
  %6659 = xor i32 %6655, %6657
  %6660 = xor i32 %6655, %6658
  %6661 = add nuw nsw i32 %6659, %6660
  %6662 = icmp eq i32 %6661, 2
  %6663 = zext i1 %6662 to i8
  store i8 %6663, i8* %23, align 1
  %6664 = load i64, i64* %RBP.i, align 8
  %6665 = add i64 %6664, -608
  %6666 = add i64 %6588, 33
  store i64 %6666, i64* %3, align 8
  %6667 = inttoptr i64 %6665 to i32*
  store i32 %6637, i32* %6667, align 4
  %6668 = load i64, i64* %RBP.i, align 8
  %6669 = add i64 %6668, -624
  %6670 = load i64, i64* %3, align 8
  %6671 = add i64 %6670, 7
  store i64 %6671, i64* %3, align 8
  %6672 = inttoptr i64 %6669 to i32*
  %6673 = load i32, i32* %6672, align 4
  %6674 = zext i32 %6673 to i64
  store i64 %6674, i64* %26, align 8
  %6675 = add i64 %6668, -44
  %6676 = add i64 %6670, 11
  store i64 %6676, i64* %3, align 8
  %6677 = inttoptr i64 %6675 to i32*
  %6678 = load i32, i32* %6677, align 4
  %6679 = sext i32 %6678 to i64
  %6680 = shl nsw i64 %6679, 6
  store i64 %6680, i64* %RDX.i1805, align 8
  %6681 = load i64, i64* %RCX.i1692, align 8
  %6682 = add i64 %6680, %6681
  store i64 %6682, i64* %RSI.i1889, align 8
  %6683 = icmp ult i64 %6682, %6681
  %6684 = icmp ult i64 %6682, %6680
  %6685 = or i1 %6683, %6684
  %6686 = zext i1 %6685 to i8
  store i8 %6686, i8* %18, align 1
  %6687 = trunc i64 %6682 to i32
  %6688 = and i32 %6687, 255
  %6689 = tail call i32 @llvm.ctpop.i32(i32 %6688)
  %6690 = trunc i32 %6689 to i8
  %6691 = and i8 %6690, 1
  %6692 = xor i8 %6691, 1
  store i8 %6692, i8* %19, align 1
  %6693 = xor i64 %6681, %6682
  %6694 = lshr i64 %6693, 4
  %6695 = trunc i64 %6694 to i8
  %6696 = and i8 %6695, 1
  store i8 %6696, i8* %20, align 1
  %6697 = icmp eq i64 %6682, 0
  %6698 = zext i1 %6697 to i8
  store i8 %6698, i8* %21, align 1
  %6699 = lshr i64 %6682, 63
  %6700 = trunc i64 %6699 to i8
  store i8 %6700, i8* %22, align 1
  %6701 = lshr i64 %6681, 63
  %6702 = lshr i64 %6679, 57
  %6703 = and i64 %6702, 1
  %6704 = xor i64 %6699, %6701
  %6705 = xor i64 %6699, %6703
  %6706 = add nuw nsw i64 %6704, %6705
  %6707 = icmp eq i64 %6706, 2
  %6708 = zext i1 %6707 to i8
  store i8 %6708, i8* %23, align 1
  %6709 = add i64 %6668, -48
  %6710 = add i64 %6670, 25
  store i64 %6710, i64* %3, align 8
  %6711 = inttoptr i64 %6709 to i32*
  %6712 = load i32, i32* %6711, align 4
  %6713 = sext i32 %6712 to i64
  store i64 %6713, i64* %RDX.i1805, align 8
  %6714 = shl nsw i64 %6713, 2
  %6715 = add i64 %6714, %6682
  %6716 = add i64 %6670, 29
  store i64 %6716, i64* %3, align 8
  %6717 = inttoptr i64 %6715 to i32*
  %6718 = load i32, i32* %6717, align 4
  %6719 = zext i32 %6718 to i64
  %6720 = shl nuw i64 %6719, 32
  %6721 = ashr i64 %6720, 33
  %6722 = and i64 %6721, 4294967295
  store i64 %6722, i64* %R9.i, align 8
  %6723 = load i32, i32* %R8D.i1718, align 4
  %6724 = trunc i64 %6721 to i32
  %6725 = sub i32 %6723, %6724
  %6726 = zext i32 %6725 to i64
  store i64 %6726, i64* %26, align 8
  %6727 = icmp ult i32 %6723, %6724
  %6728 = zext i1 %6727 to i8
  store i8 %6728, i8* %18, align 1
  %6729 = and i32 %6725, 255
  %6730 = tail call i32 @llvm.ctpop.i32(i32 %6729)
  %6731 = trunc i32 %6730 to i8
  %6732 = and i8 %6731, 1
  %6733 = xor i8 %6732, 1
  store i8 %6733, i8* %19, align 1
  %6734 = xor i32 %6724, %6723
  %6735 = xor i32 %6734, %6725
  %6736 = lshr i32 %6735, 4
  %6737 = trunc i32 %6736 to i8
  %6738 = and i8 %6737, 1
  store i8 %6738, i8* %20, align 1
  %6739 = icmp eq i32 %6725, 0
  %6740 = zext i1 %6739 to i8
  store i8 %6740, i8* %21, align 1
  %6741 = lshr i32 %6725, 31
  %6742 = trunc i32 %6741 to i8
  store i8 %6742, i8* %22, align 1
  %6743 = lshr i32 %6723, 31
  %6744 = lshr i64 %6721, 31
  %6745 = trunc i64 %6744 to i32
  %6746 = and i32 %6745, 1
  %6747 = xor i32 %6746, %6743
  %6748 = xor i32 %6741, %6743
  %6749 = add nuw nsw i32 %6748, %6747
  %6750 = icmp eq i32 %6749, 2
  %6751 = zext i1 %6750 to i8
  store i8 %6751, i8* %23, align 1
  %6752 = load i64, i64* %RBP.i, align 8
  %6753 = add i64 %6752, -612
  %6754 = add i64 %6670, 42
  store i64 %6754, i64* %3, align 8
  %6755 = inttoptr i64 %6753 to i32*
  store i32 %6725, i32* %6755, align 4
  %6756 = load i64, i64* %RBP.i, align 8
  %6757 = add i64 %6756, -612
  %6758 = load i64, i64* %3, align 8
  %6759 = add i64 %6758, 7
  store i64 %6759, i64* %3, align 8
  %6760 = inttoptr i64 %6757 to i32*
  %6761 = load i32, i32* %6760, align 4
  %6762 = zext i32 %6761 to i64
  store i64 %6762, i64* %26, align 8
  %6763 = add i64 %6756, -44
  %6764 = add i64 %6758, 11
  store i64 %6764, i64* %3, align 8
  %6765 = inttoptr i64 %6763 to i32*
  %6766 = load i32, i32* %6765, align 4
  %6767 = sext i32 %6766 to i64
  %6768 = shl nsw i64 %6767, 6
  store i64 %6768, i64* %RDX.i1805, align 8
  %6769 = load i64, i64* %RCX.i1692, align 8
  %6770 = add i64 %6768, %6769
  store i64 %6770, i64* %RCX.i1692, align 8
  %6771 = icmp ult i64 %6770, %6769
  %6772 = icmp ult i64 %6770, %6768
  %6773 = or i1 %6771, %6772
  %6774 = zext i1 %6773 to i8
  store i8 %6774, i8* %18, align 1
  %6775 = trunc i64 %6770 to i32
  %6776 = and i32 %6775, 255
  %6777 = tail call i32 @llvm.ctpop.i32(i32 %6776)
  %6778 = trunc i32 %6777 to i8
  %6779 = and i8 %6778, 1
  %6780 = xor i8 %6779, 1
  store i8 %6780, i8* %19, align 1
  %6781 = xor i64 %6769, %6770
  %6782 = lshr i64 %6781, 4
  %6783 = trunc i64 %6782 to i8
  %6784 = and i8 %6783, 1
  store i8 %6784, i8* %20, align 1
  %6785 = icmp eq i64 %6770, 0
  %6786 = zext i1 %6785 to i8
  store i8 %6786, i8* %21, align 1
  %6787 = lshr i64 %6770, 63
  %6788 = trunc i64 %6787 to i8
  store i8 %6788, i8* %22, align 1
  %6789 = lshr i64 %6769, 63
  %6790 = lshr i64 %6767, 57
  %6791 = and i64 %6790, 1
  %6792 = xor i64 %6787, %6789
  %6793 = xor i64 %6787, %6791
  %6794 = add nuw nsw i64 %6792, %6793
  %6795 = icmp eq i64 %6794, 2
  %6796 = zext i1 %6795 to i8
  store i8 %6796, i8* %23, align 1
  %6797 = add i64 %6756, -48
  %6798 = add i64 %6758, 22
  store i64 %6798, i64* %3, align 8
  %6799 = inttoptr i64 %6797 to i32*
  %6800 = load i32, i32* %6799, align 4
  %6801 = sext i32 %6800 to i64
  store i64 %6801, i64* %RDX.i1805, align 8
  %6802 = shl nsw i64 %6801, 2
  %6803 = add i64 %6770, %6802
  %6804 = add i64 %6758, 26
  store i64 %6804, i64* %3, align 8
  %6805 = inttoptr i64 %6803 to i32*
  %6806 = load i32, i32* %6805, align 4
  %6807 = add i32 %6806, %6761
  %6808 = zext i32 %6807 to i64
  store i64 %6808, i64* %26, align 8
  %6809 = icmp ult i32 %6807, %6761
  %6810 = icmp ult i32 %6807, %6806
  %6811 = or i1 %6809, %6810
  %6812 = zext i1 %6811 to i8
  store i8 %6812, i8* %18, align 1
  %6813 = and i32 %6807, 255
  %6814 = tail call i32 @llvm.ctpop.i32(i32 %6813)
  %6815 = trunc i32 %6814 to i8
  %6816 = and i8 %6815, 1
  %6817 = xor i8 %6816, 1
  store i8 %6817, i8* %19, align 1
  %6818 = xor i32 %6806, %6761
  %6819 = xor i32 %6818, %6807
  %6820 = lshr i32 %6819, 4
  %6821 = trunc i32 %6820 to i8
  %6822 = and i8 %6821, 1
  store i8 %6822, i8* %20, align 1
  %6823 = icmp eq i32 %6807, 0
  %6824 = zext i1 %6823 to i8
  store i8 %6824, i8* %21, align 1
  %6825 = lshr i32 %6807, 31
  %6826 = trunc i32 %6825 to i8
  store i8 %6826, i8* %22, align 1
  %6827 = lshr i32 %6761, 31
  %6828 = lshr i32 %6806, 31
  %6829 = xor i32 %6825, %6827
  %6830 = xor i32 %6825, %6828
  %6831 = add nuw nsw i32 %6829, %6830
  %6832 = icmp eq i32 %6831, 2
  %6833 = zext i1 %6832 to i8
  store i8 %6833, i8* %23, align 1
  %6834 = load i64, i64* %RBP.i, align 8
  %6835 = add i64 %6834, -604
  %6836 = add i64 %6758, 33
  store i64 %6836, i64* %3, align 8
  %6837 = inttoptr i64 %6835 to i32*
  store i32 %6807, i32* %6837, align 4
  %6838 = load i64, i64* %3, align 8
  %6839 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6839, i64* %RCX.i1692, align 8
  %6840 = add i64 %6839, 72688
  %6841 = add i64 %6838, 15
  store i64 %6841, i64* %3, align 8
  %6842 = inttoptr i64 %6840 to i32*
  %6843 = load i32, i32* %6842, align 4
  %6844 = zext i32 %6843 to i64
  store i64 %6844, i64* %26, align 8
  %6845 = load i64, i64* %RBP.i, align 8
  %6846 = add i64 %6845, -612
  %6847 = add i64 %6838, 22
  store i64 %6847, i64* %3, align 8
  %6848 = inttoptr i64 %6846 to i32*
  %6849 = load i32, i32* %6848, align 4
  %6850 = zext i32 %6849 to i64
  store i64 %6850, i64* %R9.i, align 8
  %6851 = add i64 %6839, 8504
  store i64 %6851, i64* %RCX.i1692, align 8
  %6852 = icmp ugt i64 %6839, -8505
  %6853 = zext i1 %6852 to i8
  store i8 %6853, i8* %18, align 1
  %6854 = trunc i64 %6851 to i32
  %6855 = and i32 %6854, 255
  %6856 = tail call i32 @llvm.ctpop.i32(i32 %6855)
  %6857 = trunc i32 %6856 to i8
  %6858 = and i8 %6857, 1
  %6859 = xor i8 %6858, 1
  store i8 %6859, i8* %19, align 1
  %6860 = xor i64 %6839, 16
  %6861 = xor i64 %6860, %6851
  %6862 = lshr i64 %6861, 4
  %6863 = trunc i64 %6862 to i8
  %6864 = and i8 %6863, 1
  store i8 %6864, i8* %20, align 1
  %6865 = icmp eq i64 %6851, 0
  %6866 = zext i1 %6865 to i8
  store i8 %6866, i8* %21, align 1
  %6867 = lshr i64 %6851, 63
  %6868 = trunc i64 %6867 to i8
  store i8 %6868, i8* %22, align 1
  %6869 = lshr i64 %6839, 63
  %6870 = xor i64 %6867, %6869
  %6871 = add nuw nsw i64 %6870, %6867
  %6872 = icmp eq i64 %6871, 2
  %6873 = zext i1 %6872 to i8
  store i8 %6873, i8* %23, align 1
  %6874 = add i64 %6845, -632
  %6875 = add i64 %6838, 44
  store i64 %6875, i64* %3, align 8
  %6876 = inttoptr i64 %6874 to i32*
  %6877 = load i32, i32* %6876, align 4
  %6878 = sext i32 %6877 to i64
  %6879 = shl nsw i64 %6878, 9
  store i64 %6879, i64* %RDX.i1805, align 8
  %6880 = add i64 %6879, %6851
  store i64 %6880, i64* %RCX.i1692, align 8
  %6881 = icmp ult i64 %6880, %6851
  %6882 = icmp ult i64 %6880, %6879
  %6883 = or i1 %6881, %6882
  %6884 = zext i1 %6883 to i8
  store i8 %6884, i8* %18, align 1
  %6885 = trunc i64 %6880 to i32
  %6886 = and i32 %6885, 255
  %6887 = tail call i32 @llvm.ctpop.i32(i32 %6886)
  %6888 = trunc i32 %6887 to i8
  %6889 = and i8 %6888, 1
  %6890 = xor i8 %6889, 1
  store i8 %6890, i8* %19, align 1
  %6891 = xor i64 %6851, %6880
  %6892 = lshr i64 %6891, 4
  %6893 = trunc i64 %6892 to i8
  %6894 = and i8 %6893, 1
  store i8 %6894, i8* %20, align 1
  %6895 = icmp eq i64 %6880, 0
  %6896 = zext i1 %6895 to i8
  store i8 %6896, i8* %21, align 1
  %6897 = lshr i64 %6880, 63
  %6898 = trunc i64 %6897 to i8
  store i8 %6898, i8* %22, align 1
  %6899 = lshr i64 %6878, 54
  %6900 = and i64 %6899, 1
  %6901 = xor i64 %6897, %6867
  %6902 = xor i64 %6897, %6900
  %6903 = add nuw nsw i64 %6901, %6902
  %6904 = icmp eq i64 %6903, 2
  %6905 = zext i1 %6904 to i8
  store i8 %6905, i8* %23, align 1
  %6906 = load i64, i64* %RBP.i, align 8
  %6907 = add i64 %6906, -484
  %6908 = add i64 %6838, 58
  store i64 %6908, i64* %3, align 8
  %6909 = inttoptr i64 %6907 to i32*
  %6910 = load i32, i32* %6909, align 4
  %6911 = zext i32 %6910 to i64
  store i64 %6911, i64* %372, align 8
  %6912 = add i64 %6906, -44
  %6913 = add i64 %6838, 62
  store i64 %6913, i64* %3, align 8
  %6914 = inttoptr i64 %6912 to i32*
  %6915 = load i32, i32* %6914, align 4
  %6916 = add i32 %6915, %6910
  %6917 = zext i32 %6916 to i64
  store i64 %6917, i64* %372, align 8
  %6918 = sext i32 %6916 to i64
  %6919 = shl nsw i64 %6918, 5
  store i64 %6919, i64* %RDX.i1805, align 8
  %6920 = load i64, i64* %RCX.i1692, align 8
  %6921 = add i64 %6919, %6920
  store i64 %6921, i64* %RCX.i1692, align 8
  %6922 = icmp ult i64 %6921, %6920
  %6923 = icmp ult i64 %6921, %6919
  %6924 = or i1 %6922, %6923
  %6925 = zext i1 %6924 to i8
  store i8 %6925, i8* %18, align 1
  %6926 = trunc i64 %6921 to i32
  %6927 = and i32 %6926, 255
  %6928 = tail call i32 @llvm.ctpop.i32(i32 %6927)
  %6929 = trunc i32 %6928 to i8
  %6930 = and i8 %6929, 1
  %6931 = xor i8 %6930, 1
  store i8 %6931, i8* %19, align 1
  %6932 = xor i64 %6920, %6921
  %6933 = lshr i64 %6932, 4
  %6934 = trunc i64 %6933 to i8
  %6935 = and i8 %6934, 1
  store i8 %6935, i8* %20, align 1
  %6936 = icmp eq i64 %6921, 0
  %6937 = zext i1 %6936 to i8
  store i8 %6937, i8* %21, align 1
  %6938 = lshr i64 %6921, 63
  %6939 = trunc i64 %6938 to i8
  store i8 %6939, i8* %22, align 1
  %6940 = lshr i64 %6920, 63
  %6941 = lshr i64 %6918, 58
  %6942 = and i64 %6941, 1
  %6943 = xor i64 %6938, %6940
  %6944 = xor i64 %6938, %6942
  %6945 = add nuw nsw i64 %6943, %6944
  %6946 = icmp eq i64 %6945, 2
  %6947 = zext i1 %6946 to i8
  store i8 %6947, i8* %23, align 1
  %6948 = load i64, i64* %RBP.i, align 8
  %6949 = add i64 %6948, -488
  %6950 = add i64 %6838, 79
  store i64 %6950, i64* %3, align 8
  %6951 = inttoptr i64 %6949 to i32*
  %6952 = load i32, i32* %6951, align 4
  %6953 = zext i32 %6952 to i64
  store i64 %6953, i64* %372, align 8
  %6954 = add i64 %6948, -48
  %6955 = add i64 %6838, 83
  store i64 %6955, i64* %3, align 8
  %6956 = inttoptr i64 %6954 to i32*
  %6957 = load i32, i32* %6956, align 4
  %6958 = add i32 %6957, %6952
  %6959 = zext i32 %6958 to i64
  store i64 %6959, i64* %372, align 8
  %6960 = icmp ult i32 %6958, %6952
  %6961 = icmp ult i32 %6958, %6957
  %6962 = or i1 %6960, %6961
  %6963 = zext i1 %6962 to i8
  store i8 %6963, i8* %18, align 1
  %6964 = and i32 %6958, 255
  %6965 = tail call i32 @llvm.ctpop.i32(i32 %6964)
  %6966 = trunc i32 %6965 to i8
  %6967 = and i8 %6966, 1
  %6968 = xor i8 %6967, 1
  store i8 %6968, i8* %19, align 1
  %6969 = xor i32 %6957, %6952
  %6970 = xor i32 %6969, %6958
  %6971 = lshr i32 %6970, 4
  %6972 = trunc i32 %6971 to i8
  %6973 = and i8 %6972, 1
  store i8 %6973, i8* %20, align 1
  %6974 = icmp eq i32 %6958, 0
  %6975 = zext i1 %6974 to i8
  store i8 %6975, i8* %21, align 1
  %6976 = lshr i32 %6958, 31
  %6977 = trunc i32 %6976 to i8
  store i8 %6977, i8* %22, align 1
  %6978 = lshr i32 %6952, 31
  %6979 = lshr i32 %6957, 31
  %6980 = xor i32 %6976, %6978
  %6981 = xor i32 %6976, %6979
  %6982 = add nuw nsw i32 %6980, %6981
  %6983 = icmp eq i32 %6982, 2
  %6984 = zext i1 %6983 to i8
  store i8 %6984, i8* %23, align 1
  %6985 = sext i32 %6958 to i64
  store i64 %6985, i64* %RDX.i1805, align 8
  %6986 = shl nsw i64 %6985, 1
  %6987 = add i64 %6921, %6986
  %6988 = add i64 %6838, 91
  store i64 %6988, i64* %3, align 8
  %6989 = inttoptr i64 %6987 to i16*
  %6990 = load i16, i16* %6989, align 2
  %6991 = zext i16 %6990 to i64
  store i64 %6991, i64* %372, align 8
  %6992 = load i32, i32* %R9D.i6640, align 4
  %6993 = zext i16 %6990 to i32
  %6994 = add i32 %6993, %6992
  %6995 = zext i32 %6994 to i64
  store i64 %6995, i64* %R9.i, align 8
  %6996 = lshr i32 %6994, 31
  %6997 = load i32, i32* %EAX.i2159, align 4
  %6998 = sub i32 %6997, %6994
  %6999 = icmp ult i32 %6997, %6994
  %7000 = zext i1 %6999 to i8
  store i8 %7000, i8* %18, align 1
  %7001 = and i32 %6998, 255
  %7002 = tail call i32 @llvm.ctpop.i32(i32 %7001)
  %7003 = trunc i32 %7002 to i8
  %7004 = and i8 %7003, 1
  %7005 = xor i8 %7004, 1
  store i8 %7005, i8* %19, align 1
  %7006 = xor i32 %6994, %6997
  %7007 = xor i32 %7006, %6998
  %7008 = lshr i32 %7007, 4
  %7009 = trunc i32 %7008 to i8
  %7010 = and i8 %7009, 1
  store i8 %7010, i8* %20, align 1
  %7011 = icmp eq i32 %6998, 0
  %7012 = zext i1 %7011 to i8
  store i8 %7012, i8* %21, align 1
  %7013 = lshr i32 %6998, 31
  %7014 = trunc i32 %7013 to i8
  store i8 %7014, i8* %22, align 1
  %7015 = lshr i32 %6997, 31
  %7016 = xor i32 %6996, %7015
  %7017 = xor i32 %7013, %7015
  %7018 = add nuw nsw i32 %7017, %7016
  %7019 = icmp eq i32 %7018, 2
  %7020 = zext i1 %7019 to i8
  store i8 %7020, i8* %23, align 1
  %7021 = load i64, i64* %RBP.i, align 8
  %7022 = add i64 %7021, -1224
  %7023 = load i32, i32* %R8D.i1718, align 4
  %7024 = add i64 %6838, 104
  store i64 %7024, i64* %3, align 8
  %7025 = inttoptr i64 %7022 to i32*
  store i32 %7023, i32* %7025, align 4
  %7026 = load i64, i64* %3, align 8
  %7027 = load i8, i8* %21, align 1
  %7028 = icmp ne i8 %7027, 0
  %7029 = load i8, i8* %22, align 1
  %7030 = icmp ne i8 %7029, 0
  %7031 = load i8, i8* %23, align 1
  %7032 = icmp ne i8 %7031, 0
  %7033 = xor i1 %7030, %7032
  %7034 = or i1 %7028, %7033
  %.v1014 = select i1 %7034, i64 19, i64 6
  %7035 = add i64 %7026, %.v1014
  store i64 %7035, i64* %3, align 8
  br i1 %7034, label %block_.L_4a511c, label %block_4a510f

block_4a510f:                                     ; preds = %block_4a4fdd
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %7036 = load i64, i64* %RBP.i, align 8
  %7037 = add i64 %7036, -1228
  %7038 = add i64 %7035, 8
  store i64 %7038, i64* %3, align 8
  %7039 = inttoptr i64 %7037 to i32*
  store i32 0, i32* %7039, align 4
  %7040 = load i64, i64* %3, align 8
  %7041 = add i64 %7040, 83
  store i64 %7041, i64* %3, align 8
  br label %block_.L_4a516a

block_.L_4a511c:                                  ; preds = %block_4a4fdd
  %7042 = load i64, i64* %RBP.i, align 8
  %7043 = add i64 %7042, -612
  %7044 = add i64 %7035, 6
  store i64 %7044, i64* %3, align 8
  %7045 = inttoptr i64 %7043 to i32*
  %7046 = load i32, i32* %7045, align 4
  %7047 = zext i32 %7046 to i64
  store i64 %7047, i64* %RAX.i1763, align 8
  %7048 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %7049 = add i64 %7048, 8504
  store i64 %7049, i64* %RCX.i1692, align 8
  %7050 = icmp ugt i64 %7048, -8505
  %7051 = zext i1 %7050 to i8
  store i8 %7051, i8* %18, align 1
  %7052 = trunc i64 %7049 to i32
  %7053 = and i32 %7052, 255
  %7054 = tail call i32 @llvm.ctpop.i32(i32 %7053)
  %7055 = trunc i32 %7054 to i8
  %7056 = and i8 %7055, 1
  %7057 = xor i8 %7056, 1
  store i8 %7057, i8* %19, align 1
  %7058 = xor i64 %7048, 16
  %7059 = xor i64 %7058, %7049
  %7060 = lshr i64 %7059, 4
  %7061 = trunc i64 %7060 to i8
  %7062 = and i8 %7061, 1
  store i8 %7062, i8* %20, align 1
  %7063 = icmp eq i64 %7049, 0
  %7064 = zext i1 %7063 to i8
  store i8 %7064, i8* %21, align 1
  %7065 = lshr i64 %7049, 63
  %7066 = trunc i64 %7065 to i8
  store i8 %7066, i8* %22, align 1
  %7067 = lshr i64 %7048, 63
  %7068 = xor i64 %7065, %7067
  %7069 = add nuw nsw i64 %7068, %7065
  %7070 = icmp eq i64 %7069, 2
  %7071 = zext i1 %7070 to i8
  store i8 %7071, i8* %23, align 1
  %7072 = add i64 %7042, -632
  %7073 = add i64 %7035, 28
  store i64 %7073, i64* %3, align 8
  %7074 = inttoptr i64 %7072 to i32*
  %7075 = load i32, i32* %7074, align 4
  %7076 = sext i32 %7075 to i64
  %7077 = shl nsw i64 %7076, 9
  store i64 %7077, i64* %RDX.i1805, align 8
  %7078 = add i64 %7077, %7049
  store i64 %7078, i64* %RCX.i1692, align 8
  %7079 = icmp ult i64 %7078, %7049
  %7080 = icmp ult i64 %7078, %7077
  %7081 = or i1 %7079, %7080
  %7082 = zext i1 %7081 to i8
  store i8 %7082, i8* %18, align 1
  %7083 = trunc i64 %7078 to i32
  %7084 = and i32 %7083, 255
  %7085 = tail call i32 @llvm.ctpop.i32(i32 %7084)
  %7086 = trunc i32 %7085 to i8
  %7087 = and i8 %7086, 1
  %7088 = xor i8 %7087, 1
  store i8 %7088, i8* %19, align 1
  %7089 = xor i64 %7049, %7078
  %7090 = lshr i64 %7089, 4
  %7091 = trunc i64 %7090 to i8
  %7092 = and i8 %7091, 1
  store i8 %7092, i8* %20, align 1
  %7093 = icmp eq i64 %7078, 0
  %7094 = zext i1 %7093 to i8
  store i8 %7094, i8* %21, align 1
  %7095 = lshr i64 %7078, 63
  %7096 = trunc i64 %7095 to i8
  store i8 %7096, i8* %22, align 1
  %7097 = lshr i64 %7076, 54
  %7098 = and i64 %7097, 1
  %7099 = xor i64 %7095, %7065
  %7100 = xor i64 %7095, %7098
  %7101 = add nuw nsw i64 %7099, %7100
  %7102 = icmp eq i64 %7101, 2
  %7103 = zext i1 %7102 to i8
  store i8 %7103, i8* %23, align 1
  %7104 = load i64, i64* %RBP.i, align 8
  %7105 = add i64 %7104, -484
  %7106 = add i64 %7035, 41
  store i64 %7106, i64* %3, align 8
  %7107 = inttoptr i64 %7105 to i32*
  %7108 = load i32, i32* %7107, align 4
  %7109 = zext i32 %7108 to i64
  store i64 %7109, i64* %RSI.i1889, align 8
  %7110 = add i64 %7104, -44
  %7111 = add i64 %7035, 44
  store i64 %7111, i64* %3, align 8
  %7112 = inttoptr i64 %7110 to i32*
  %7113 = load i32, i32* %7112, align 4
  %7114 = add i32 %7113, %7108
  %7115 = zext i32 %7114 to i64
  store i64 %7115, i64* %RSI.i1889, align 8
  %7116 = sext i32 %7114 to i64
  %7117 = shl nsw i64 %7116, 5
  store i64 %7117, i64* %RDX.i1805, align 8
  %7118 = load i64, i64* %RCX.i1692, align 8
  %7119 = add i64 %7117, %7118
  store i64 %7119, i64* %RCX.i1692, align 8
  %7120 = icmp ult i64 %7119, %7118
  %7121 = icmp ult i64 %7119, %7117
  %7122 = or i1 %7120, %7121
  %7123 = zext i1 %7122 to i8
  store i8 %7123, i8* %18, align 1
  %7124 = trunc i64 %7119 to i32
  %7125 = and i32 %7124, 255
  %7126 = tail call i32 @llvm.ctpop.i32(i32 %7125)
  %7127 = trunc i32 %7126 to i8
  %7128 = and i8 %7127, 1
  %7129 = xor i8 %7128, 1
  store i8 %7129, i8* %19, align 1
  %7130 = xor i64 %7118, %7119
  %7131 = lshr i64 %7130, 4
  %7132 = trunc i64 %7131 to i8
  %7133 = and i8 %7132, 1
  store i8 %7133, i8* %20, align 1
  %7134 = icmp eq i64 %7119, 0
  %7135 = zext i1 %7134 to i8
  store i8 %7135, i8* %21, align 1
  %7136 = lshr i64 %7119, 63
  %7137 = trunc i64 %7136 to i8
  store i8 %7137, i8* %22, align 1
  %7138 = lshr i64 %7118, 63
  %7139 = lshr i64 %7116, 58
  %7140 = and i64 %7139, 1
  %7141 = xor i64 %7136, %7138
  %7142 = xor i64 %7136, %7140
  %7143 = add nuw nsw i64 %7141, %7142
  %7144 = icmp eq i64 %7143, 2
  %7145 = zext i1 %7144 to i8
  store i8 %7145, i8* %23, align 1
  %7146 = load i64, i64* %RBP.i, align 8
  %7147 = add i64 %7146, -488
  %7148 = add i64 %7035, 60
  store i64 %7148, i64* %3, align 8
  %7149 = inttoptr i64 %7147 to i32*
  %7150 = load i32, i32* %7149, align 4
  %7151 = zext i32 %7150 to i64
  store i64 %7151, i64* %RSI.i1889, align 8
  %7152 = add i64 %7146, -48
  %7153 = add i64 %7035, 63
  store i64 %7153, i64* %3, align 8
  %7154 = inttoptr i64 %7152 to i32*
  %7155 = load i32, i32* %7154, align 4
  %7156 = add i32 %7155, %7150
  %7157 = zext i32 %7156 to i64
  store i64 %7157, i64* %RSI.i1889, align 8
  %7158 = icmp ult i32 %7156, %7150
  %7159 = icmp ult i32 %7156, %7155
  %7160 = or i1 %7158, %7159
  %7161 = zext i1 %7160 to i8
  store i8 %7161, i8* %18, align 1
  %7162 = and i32 %7156, 255
  %7163 = tail call i32 @llvm.ctpop.i32(i32 %7162)
  %7164 = trunc i32 %7163 to i8
  %7165 = and i8 %7164, 1
  %7166 = xor i8 %7165, 1
  store i8 %7166, i8* %19, align 1
  %7167 = xor i32 %7155, %7150
  %7168 = xor i32 %7167, %7156
  %7169 = lshr i32 %7168, 4
  %7170 = trunc i32 %7169 to i8
  %7171 = and i8 %7170, 1
  store i8 %7171, i8* %20, align 1
  %7172 = icmp eq i32 %7156, 0
  %7173 = zext i1 %7172 to i8
  store i8 %7173, i8* %21, align 1
  %7174 = lshr i32 %7156, 31
  %7175 = trunc i32 %7174 to i8
  store i8 %7175, i8* %22, align 1
  %7176 = lshr i32 %7150, 31
  %7177 = lshr i32 %7155, 31
  %7178 = xor i32 %7174, %7176
  %7179 = xor i32 %7174, %7177
  %7180 = add nuw nsw i32 %7178, %7179
  %7181 = icmp eq i32 %7180, 2
  %7182 = zext i1 %7181 to i8
  store i8 %7182, i8* %23, align 1
  %7183 = sext i32 %7156 to i64
  store i64 %7183, i64* %RDX.i1805, align 8
  %7184 = shl nsw i64 %7183, 1
  %7185 = add i64 %7119, %7184
  %7186 = add i64 %7035, 70
  store i64 %7186, i64* %3, align 8
  %7187 = inttoptr i64 %7185 to i16*
  %7188 = load i16, i16* %7187, align 2
  %7189 = zext i16 %7188 to i64
  store i64 %7189, i64* %RSI.i1889, align 8
  %7190 = load i64, i64* %RAX.i1763, align 8
  %7191 = zext i16 %7188 to i32
  %7192 = zext i16 %7188 to i64
  %7193 = trunc i64 %7190 to i32
  %7194 = add i32 %7191, %7193
  %7195 = zext i32 %7194 to i64
  store i64 %7195, i64* %RAX.i1763, align 8
  %7196 = icmp ult i32 %7194, %7193
  %7197 = icmp ult i32 %7194, %7191
  %7198 = or i1 %7196, %7197
  %7199 = zext i1 %7198 to i8
  store i8 %7199, i8* %18, align 1
  %7200 = and i32 %7194, 255
  %7201 = tail call i32 @llvm.ctpop.i32(i32 %7200)
  %7202 = trunc i32 %7201 to i8
  %7203 = and i8 %7202, 1
  %7204 = xor i8 %7203, 1
  store i8 %7204, i8* %19, align 1
  %7205 = xor i64 %7192, %7190
  %7206 = trunc i64 %7205 to i32
  %7207 = xor i32 %7206, %7194
  %7208 = lshr i32 %7207, 4
  %7209 = trunc i32 %7208 to i8
  %7210 = and i8 %7209, 1
  store i8 %7210, i8* %20, align 1
  %7211 = icmp eq i32 %7194, 0
  %7212 = zext i1 %7211 to i8
  store i8 %7212, i8* %21, align 1
  %7213 = lshr i32 %7194, 31
  %7214 = trunc i32 %7213 to i8
  store i8 %7214, i8* %22, align 1
  %7215 = lshr i32 %7193, 31
  %7216 = xor i32 %7213, %7215
  %7217 = add nuw nsw i32 %7216, %7213
  %7218 = icmp eq i32 %7217, 2
  %7219 = zext i1 %7218 to i8
  store i8 %7219, i8* %23, align 1
  %7220 = add i64 %7146, -1228
  %7221 = add i64 %7035, 78
  store i64 %7221, i64* %3, align 8
  %7222 = inttoptr i64 %7220 to i32*
  store i32 %7194, i32* %7222, align 4
  %.pre734 = load i64, i64* %3, align 8
  br label %block_.L_4a516a

block_.L_4a516a:                                  ; preds = %block_.L_4a511c, %block_4a510f
  %7223 = phi i64 [ %.pre734, %block_.L_4a511c ], [ %7041, %block_4a510f ]
  %7224 = load i64, i64* %RBP.i, align 8
  %7225 = add i64 %7224, -1228
  %7226 = add i64 %7223, 6
  store i64 %7226, i64* %3, align 8
  %7227 = inttoptr i64 %7225 to i32*
  %7228 = load i32, i32* %7227, align 4
  %7229 = zext i32 %7228 to i64
  store i64 %7229, i64* %RAX.i1763, align 8
  %7230 = add i64 %7224, -1224
  %7231 = add i64 %7223, 12
  store i64 %7231, i64* %3, align 8
  %7232 = inttoptr i64 %7230 to i32*
  %7233 = load i32, i32* %7232, align 4
  %7234 = zext i32 %7233 to i64
  store i64 %7234, i64* %RCX.i1692, align 8
  %7235 = sub i32 %7233, %7228
  %7236 = icmp ult i32 %7233, %7228
  %7237 = zext i1 %7236 to i8
  store i8 %7237, i8* %18, align 1
  %7238 = and i32 %7235, 255
  %7239 = tail call i32 @llvm.ctpop.i32(i32 %7238)
  %7240 = trunc i32 %7239 to i8
  %7241 = and i8 %7240, 1
  %7242 = xor i8 %7241, 1
  store i8 %7242, i8* %19, align 1
  %7243 = xor i32 %7228, %7233
  %7244 = xor i32 %7243, %7235
  %7245 = lshr i32 %7244, 4
  %7246 = trunc i32 %7245 to i8
  %7247 = and i8 %7246, 1
  store i8 %7247, i8* %20, align 1
  %7248 = icmp eq i32 %7235, 0
  %7249 = zext i1 %7248 to i8
  store i8 %7249, i8* %21, align 1
  %7250 = lshr i32 %7235, 31
  %7251 = trunc i32 %7250 to i8
  store i8 %7251, i8* %22, align 1
  %7252 = lshr i32 %7233, 31
  %7253 = lshr i32 %7228, 31
  %7254 = xor i32 %7253, %7252
  %7255 = xor i32 %7250, %7252
  %7256 = add nuw nsw i32 %7255, %7254
  %7257 = icmp eq i32 %7256, 2
  %7258 = zext i1 %7257 to i8
  store i8 %7258, i8* %23, align 1
  %7259 = icmp ne i8 %7251, 0
  %7260 = xor i1 %7259, %7257
  %.v856 = select i1 %7260, i64 20, i64 45
  %7261 = add i64 %7223, %.v856
  store i64 %7261, i64* %3, align 8
  br i1 %7260, label %block_4a517e, label %block_.L_4a5197

block_4a517e:                                     ; preds = %block_.L_4a516a
  %7262 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7262, i64* %RAX.i1763, align 8
  %7263 = add i64 %7262, 72688
  %7264 = add i64 %7261, 14
  store i64 %7264, i64* %3, align 8
  %7265 = inttoptr i64 %7263 to i32*
  %7266 = load i32, i32* %7265, align 4
  %7267 = zext i32 %7266 to i64
  store i64 %7267, i64* %RCX.i1692, align 8
  %7268 = add i64 %7224, -1232
  %7269 = add i64 %7261, 20
  store i64 %7269, i64* %3, align 8
  %7270 = inttoptr i64 %7268 to i32*
  store i32 %7266, i32* %7270, align 4
  %7271 = load i64, i64* %3, align 8
  %7272 = add i64 %7271, 190
  store i64 %7272, i64* %3, align 8
  br label %block_.L_4a5250

block_.L_4a5197:                                  ; preds = %block_.L_4a516a
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %7273 = add i64 %7224, -612
  %7274 = add i64 %7261, 8
  store i64 %7274, i64* %3, align 8
  %7275 = inttoptr i64 %7273 to i32*
  %7276 = load i32, i32* %7275, align 4
  %7277 = zext i32 %7276 to i64
  store i64 %7277, i64* %RCX.i1692, align 8
  %7278 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %7279 = add i64 %7278, 8504
  store i64 %7279, i64* %RDX.i1805, align 8
  %7280 = icmp ugt i64 %7278, -8505
  %7281 = zext i1 %7280 to i8
  store i8 %7281, i8* %18, align 1
  %7282 = trunc i64 %7279 to i32
  %7283 = and i32 %7282, 255
  %7284 = tail call i32 @llvm.ctpop.i32(i32 %7283)
  %7285 = trunc i32 %7284 to i8
  %7286 = and i8 %7285, 1
  %7287 = xor i8 %7286, 1
  store i8 %7287, i8* %19, align 1
  %7288 = xor i64 %7278, 16
  %7289 = xor i64 %7288, %7279
  %7290 = lshr i64 %7289, 4
  %7291 = trunc i64 %7290 to i8
  %7292 = and i8 %7291, 1
  store i8 %7292, i8* %20, align 1
  %7293 = icmp eq i64 %7279, 0
  %7294 = zext i1 %7293 to i8
  store i8 %7294, i8* %21, align 1
  %7295 = lshr i64 %7279, 63
  %7296 = trunc i64 %7295 to i8
  store i8 %7296, i8* %22, align 1
  %7297 = lshr i64 %7278, 63
  %7298 = xor i64 %7295, %7297
  %7299 = add nuw nsw i64 %7298, %7295
  %7300 = icmp eq i64 %7299, 2
  %7301 = zext i1 %7300 to i8
  store i8 %7301, i8* %23, align 1
  %7302 = add i64 %7224, -632
  %7303 = add i64 %7261, 30
  store i64 %7303, i64* %3, align 8
  %7304 = inttoptr i64 %7302 to i32*
  %7305 = load i32, i32* %7304, align 4
  %7306 = sext i32 %7305 to i64
  %7307 = shl nsw i64 %7306, 9
  store i64 %7307, i64* %RSI.i1889, align 8
  %7308 = add i64 %7307, %7279
  store i64 %7308, i64* %RDX.i1805, align 8
  %7309 = icmp ult i64 %7308, %7279
  %7310 = icmp ult i64 %7308, %7307
  %7311 = or i1 %7309, %7310
  %7312 = zext i1 %7311 to i8
  store i8 %7312, i8* %18, align 1
  %7313 = trunc i64 %7308 to i32
  %7314 = and i32 %7313, 255
  %7315 = tail call i32 @llvm.ctpop.i32(i32 %7314)
  %7316 = trunc i32 %7315 to i8
  %7317 = and i8 %7316, 1
  %7318 = xor i8 %7317, 1
  store i8 %7318, i8* %19, align 1
  %7319 = xor i64 %7279, %7308
  %7320 = lshr i64 %7319, 4
  %7321 = trunc i64 %7320 to i8
  %7322 = and i8 %7321, 1
  store i8 %7322, i8* %20, align 1
  %7323 = icmp eq i64 %7308, 0
  %7324 = zext i1 %7323 to i8
  store i8 %7324, i8* %21, align 1
  %7325 = lshr i64 %7308, 63
  %7326 = trunc i64 %7325 to i8
  store i8 %7326, i8* %22, align 1
  %7327 = lshr i64 %7306, 54
  %7328 = and i64 %7327, 1
  %7329 = xor i64 %7325, %7295
  %7330 = xor i64 %7325, %7328
  %7331 = add nuw nsw i64 %7329, %7330
  %7332 = icmp eq i64 %7331, 2
  %7333 = zext i1 %7332 to i8
  store i8 %7333, i8* %23, align 1
  %7334 = load i64, i64* %RBP.i, align 8
  %7335 = add i64 %7334, -484
  %7336 = add i64 %7261, 43
  store i64 %7336, i64* %3, align 8
  %7337 = inttoptr i64 %7335 to i32*
  %7338 = load i32, i32* %7337, align 4
  %7339 = zext i32 %7338 to i64
  store i64 %7339, i64* %RDI.i2141, align 8
  %7340 = add i64 %7334, -44
  %7341 = add i64 %7261, 46
  store i64 %7341, i64* %3, align 8
  %7342 = inttoptr i64 %7340 to i32*
  %7343 = load i32, i32* %7342, align 4
  %7344 = add i32 %7343, %7338
  %7345 = zext i32 %7344 to i64
  store i64 %7345, i64* %RDI.i2141, align 8
  %7346 = sext i32 %7344 to i64
  %7347 = shl nsw i64 %7346, 5
  store i64 %7347, i64* %RSI.i1889, align 8
  %7348 = load i64, i64* %RDX.i1805, align 8
  %7349 = add i64 %7347, %7348
  store i64 %7349, i64* %RDX.i1805, align 8
  %7350 = icmp ult i64 %7349, %7348
  %7351 = icmp ult i64 %7349, %7347
  %7352 = or i1 %7350, %7351
  %7353 = zext i1 %7352 to i8
  store i8 %7353, i8* %18, align 1
  %7354 = trunc i64 %7349 to i32
  %7355 = and i32 %7354, 255
  %7356 = tail call i32 @llvm.ctpop.i32(i32 %7355)
  %7357 = trunc i32 %7356 to i8
  %7358 = and i8 %7357, 1
  %7359 = xor i8 %7358, 1
  store i8 %7359, i8* %19, align 1
  %7360 = xor i64 %7348, %7349
  %7361 = lshr i64 %7360, 4
  %7362 = trunc i64 %7361 to i8
  %7363 = and i8 %7362, 1
  store i8 %7363, i8* %20, align 1
  %7364 = icmp eq i64 %7349, 0
  %7365 = zext i1 %7364 to i8
  store i8 %7365, i8* %21, align 1
  %7366 = lshr i64 %7349, 63
  %7367 = trunc i64 %7366 to i8
  store i8 %7367, i8* %22, align 1
  %7368 = lshr i64 %7348, 63
  %7369 = lshr i64 %7346, 58
  %7370 = and i64 %7369, 1
  %7371 = xor i64 %7366, %7368
  %7372 = xor i64 %7366, %7370
  %7373 = add nuw nsw i64 %7371, %7372
  %7374 = icmp eq i64 %7373, 2
  %7375 = zext i1 %7374 to i8
  store i8 %7375, i8* %23, align 1
  %7376 = load i64, i64* %RBP.i, align 8
  %7377 = add i64 %7376, -488
  %7378 = add i64 %7261, 62
  store i64 %7378, i64* %3, align 8
  %7379 = inttoptr i64 %7377 to i32*
  %7380 = load i32, i32* %7379, align 4
  %7381 = zext i32 %7380 to i64
  store i64 %7381, i64* %RDI.i2141, align 8
  %7382 = add i64 %7376, -48
  %7383 = add i64 %7261, 65
  store i64 %7383, i64* %3, align 8
  %7384 = inttoptr i64 %7382 to i32*
  %7385 = load i32, i32* %7384, align 4
  %7386 = add i32 %7385, %7380
  %7387 = zext i32 %7386 to i64
  store i64 %7387, i64* %RDI.i2141, align 8
  %7388 = icmp ult i32 %7386, %7380
  %7389 = icmp ult i32 %7386, %7385
  %7390 = or i1 %7388, %7389
  %7391 = zext i1 %7390 to i8
  store i8 %7391, i8* %18, align 1
  %7392 = and i32 %7386, 255
  %7393 = tail call i32 @llvm.ctpop.i32(i32 %7392)
  %7394 = trunc i32 %7393 to i8
  %7395 = and i8 %7394, 1
  %7396 = xor i8 %7395, 1
  store i8 %7396, i8* %19, align 1
  %7397 = xor i32 %7385, %7380
  %7398 = xor i32 %7397, %7386
  %7399 = lshr i32 %7398, 4
  %7400 = trunc i32 %7399 to i8
  %7401 = and i8 %7400, 1
  store i8 %7401, i8* %20, align 1
  %7402 = icmp eq i32 %7386, 0
  %7403 = zext i1 %7402 to i8
  store i8 %7403, i8* %21, align 1
  %7404 = lshr i32 %7386, 31
  %7405 = trunc i32 %7404 to i8
  store i8 %7405, i8* %22, align 1
  %7406 = lshr i32 %7380, 31
  %7407 = lshr i32 %7385, 31
  %7408 = xor i32 %7404, %7406
  %7409 = xor i32 %7404, %7407
  %7410 = add nuw nsw i32 %7408, %7409
  %7411 = icmp eq i32 %7410, 2
  %7412 = zext i1 %7411 to i8
  store i8 %7412, i8* %23, align 1
  %7413 = sext i32 %7386 to i64
  store i64 %7413, i64* %RSI.i1889, align 8
  %7414 = shl nsw i64 %7413, 1
  %7415 = add i64 %7349, %7414
  %7416 = add i64 %7261, 72
  store i64 %7416, i64* %3, align 8
  %7417 = inttoptr i64 %7415 to i16*
  %7418 = load i16, i16* %7417, align 2
  %7419 = zext i16 %7418 to i64
  store i64 %7419, i64* %RDI.i2141, align 8
  %7420 = load i64, i64* %RCX.i1692, align 8
  %7421 = zext i16 %7418 to i32
  %7422 = trunc i64 %7420 to i32
  %7423 = add i32 %7421, %7422
  %7424 = zext i32 %7423 to i64
  store i64 %7424, i64* %RCX.i1692, align 8
  %7425 = lshr i32 %7423, 31
  %7426 = load i32, i32* %EAX.i2159, align 4
  %7427 = sub i32 %7426, %7423
  %7428 = icmp ult i32 %7426, %7423
  %7429 = zext i1 %7428 to i8
  store i8 %7429, i8* %18, align 1
  %7430 = and i32 %7427, 255
  %7431 = tail call i32 @llvm.ctpop.i32(i32 %7430)
  %7432 = trunc i32 %7431 to i8
  %7433 = and i8 %7432, 1
  %7434 = xor i8 %7433, 1
  store i8 %7434, i8* %19, align 1
  %7435 = xor i32 %7423, %7426
  %7436 = xor i32 %7435, %7427
  %7437 = lshr i32 %7436, 4
  %7438 = trunc i32 %7437 to i8
  %7439 = and i8 %7438, 1
  store i8 %7439, i8* %20, align 1
  %7440 = icmp eq i32 %7427, 0
  %7441 = zext i1 %7440 to i8
  store i8 %7441, i8* %21, align 1
  %7442 = lshr i32 %7427, 31
  %7443 = trunc i32 %7442 to i8
  store i8 %7443, i8* %22, align 1
  %7444 = lshr i32 %7426, 31
  %7445 = xor i32 %7425, %7444
  %7446 = xor i32 %7442, %7444
  %7447 = add nuw nsw i32 %7446, %7445
  %7448 = icmp eq i32 %7447, 2
  %7449 = zext i1 %7448 to i8
  store i8 %7449, i8* %23, align 1
  %7450 = icmp ne i8 %7443, 0
  %7451 = xor i1 %7450, %7448
  %7452 = or i1 %7440, %7451
  %.v857 = select i1 %7452, i64 95, i64 82
  %7453 = add i64 %7261, %.v857
  store i64 %7453, i64* %3, align 8
  br i1 %7452, label %block_.L_4a51f6, label %block_4a51e9

block_4a51e9:                                     ; preds = %block_.L_4a5197
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %7454 = load i64, i64* %RBP.i, align 8
  %7455 = add i64 %7454, -1236
  %7456 = add i64 %7453, 8
  store i64 %7456, i64* %3, align 8
  %7457 = inttoptr i64 %7455 to i32*
  store i32 0, i32* %7457, align 4
  %7458 = load i64, i64* %3, align 8
  %7459 = add i64 %7458, 83
  store i64 %7459, i64* %3, align 8
  br label %block_.L_4a5244

block_.L_4a51f6:                                  ; preds = %block_.L_4a5197
  %7460 = load i64, i64* %RBP.i, align 8
  %7461 = add i64 %7460, -612
  %7462 = add i64 %7453, 6
  store i64 %7462, i64* %3, align 8
  %7463 = inttoptr i64 %7461 to i32*
  %7464 = load i32, i32* %7463, align 4
  %7465 = zext i32 %7464 to i64
  store i64 %7465, i64* %RAX.i1763, align 8
  %7466 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %7467 = add i64 %7466, 8504
  store i64 %7467, i64* %RCX.i1692, align 8
  %7468 = icmp ugt i64 %7466, -8505
  %7469 = zext i1 %7468 to i8
  store i8 %7469, i8* %18, align 1
  %7470 = trunc i64 %7467 to i32
  %7471 = and i32 %7470, 255
  %7472 = tail call i32 @llvm.ctpop.i32(i32 %7471)
  %7473 = trunc i32 %7472 to i8
  %7474 = and i8 %7473, 1
  %7475 = xor i8 %7474, 1
  store i8 %7475, i8* %19, align 1
  %7476 = xor i64 %7466, 16
  %7477 = xor i64 %7476, %7467
  %7478 = lshr i64 %7477, 4
  %7479 = trunc i64 %7478 to i8
  %7480 = and i8 %7479, 1
  store i8 %7480, i8* %20, align 1
  %7481 = icmp eq i64 %7467, 0
  %7482 = zext i1 %7481 to i8
  store i8 %7482, i8* %21, align 1
  %7483 = lshr i64 %7467, 63
  %7484 = trunc i64 %7483 to i8
  store i8 %7484, i8* %22, align 1
  %7485 = lshr i64 %7466, 63
  %7486 = xor i64 %7483, %7485
  %7487 = add nuw nsw i64 %7486, %7483
  %7488 = icmp eq i64 %7487, 2
  %7489 = zext i1 %7488 to i8
  store i8 %7489, i8* %23, align 1
  %7490 = add i64 %7460, -632
  %7491 = add i64 %7453, 28
  store i64 %7491, i64* %3, align 8
  %7492 = inttoptr i64 %7490 to i32*
  %7493 = load i32, i32* %7492, align 4
  %7494 = sext i32 %7493 to i64
  %7495 = shl nsw i64 %7494, 9
  store i64 %7495, i64* %RDX.i1805, align 8
  %7496 = add i64 %7495, %7467
  store i64 %7496, i64* %RCX.i1692, align 8
  %7497 = icmp ult i64 %7496, %7467
  %7498 = icmp ult i64 %7496, %7495
  %7499 = or i1 %7497, %7498
  %7500 = zext i1 %7499 to i8
  store i8 %7500, i8* %18, align 1
  %7501 = trunc i64 %7496 to i32
  %7502 = and i32 %7501, 255
  %7503 = tail call i32 @llvm.ctpop.i32(i32 %7502)
  %7504 = trunc i32 %7503 to i8
  %7505 = and i8 %7504, 1
  %7506 = xor i8 %7505, 1
  store i8 %7506, i8* %19, align 1
  %7507 = xor i64 %7467, %7496
  %7508 = lshr i64 %7507, 4
  %7509 = trunc i64 %7508 to i8
  %7510 = and i8 %7509, 1
  store i8 %7510, i8* %20, align 1
  %7511 = icmp eq i64 %7496, 0
  %7512 = zext i1 %7511 to i8
  store i8 %7512, i8* %21, align 1
  %7513 = lshr i64 %7496, 63
  %7514 = trunc i64 %7513 to i8
  store i8 %7514, i8* %22, align 1
  %7515 = lshr i64 %7494, 54
  %7516 = and i64 %7515, 1
  %7517 = xor i64 %7513, %7483
  %7518 = xor i64 %7513, %7516
  %7519 = add nuw nsw i64 %7517, %7518
  %7520 = icmp eq i64 %7519, 2
  %7521 = zext i1 %7520 to i8
  store i8 %7521, i8* %23, align 1
  %7522 = load i64, i64* %RBP.i, align 8
  %7523 = add i64 %7522, -484
  %7524 = add i64 %7453, 41
  store i64 %7524, i64* %3, align 8
  %7525 = inttoptr i64 %7523 to i32*
  %7526 = load i32, i32* %7525, align 4
  %7527 = zext i32 %7526 to i64
  store i64 %7527, i64* %RSI.i1889, align 8
  %7528 = add i64 %7522, -44
  %7529 = add i64 %7453, 44
  store i64 %7529, i64* %3, align 8
  %7530 = inttoptr i64 %7528 to i32*
  %7531 = load i32, i32* %7530, align 4
  %7532 = add i32 %7531, %7526
  %7533 = zext i32 %7532 to i64
  store i64 %7533, i64* %RSI.i1889, align 8
  %7534 = sext i32 %7532 to i64
  %7535 = shl nsw i64 %7534, 5
  store i64 %7535, i64* %RDX.i1805, align 8
  %7536 = load i64, i64* %RCX.i1692, align 8
  %7537 = add i64 %7535, %7536
  store i64 %7537, i64* %RCX.i1692, align 8
  %7538 = icmp ult i64 %7537, %7536
  %7539 = icmp ult i64 %7537, %7535
  %7540 = or i1 %7538, %7539
  %7541 = zext i1 %7540 to i8
  store i8 %7541, i8* %18, align 1
  %7542 = trunc i64 %7537 to i32
  %7543 = and i32 %7542, 255
  %7544 = tail call i32 @llvm.ctpop.i32(i32 %7543)
  %7545 = trunc i32 %7544 to i8
  %7546 = and i8 %7545, 1
  %7547 = xor i8 %7546, 1
  store i8 %7547, i8* %19, align 1
  %7548 = xor i64 %7536, %7537
  %7549 = lshr i64 %7548, 4
  %7550 = trunc i64 %7549 to i8
  %7551 = and i8 %7550, 1
  store i8 %7551, i8* %20, align 1
  %7552 = icmp eq i64 %7537, 0
  %7553 = zext i1 %7552 to i8
  store i8 %7553, i8* %21, align 1
  %7554 = lshr i64 %7537, 63
  %7555 = trunc i64 %7554 to i8
  store i8 %7555, i8* %22, align 1
  %7556 = lshr i64 %7536, 63
  %7557 = lshr i64 %7534, 58
  %7558 = and i64 %7557, 1
  %7559 = xor i64 %7554, %7556
  %7560 = xor i64 %7554, %7558
  %7561 = add nuw nsw i64 %7559, %7560
  %7562 = icmp eq i64 %7561, 2
  %7563 = zext i1 %7562 to i8
  store i8 %7563, i8* %23, align 1
  %7564 = load i64, i64* %RBP.i, align 8
  %7565 = add i64 %7564, -488
  %7566 = add i64 %7453, 60
  store i64 %7566, i64* %3, align 8
  %7567 = inttoptr i64 %7565 to i32*
  %7568 = load i32, i32* %7567, align 4
  %7569 = zext i32 %7568 to i64
  store i64 %7569, i64* %RSI.i1889, align 8
  %7570 = add i64 %7564, -48
  %7571 = add i64 %7453, 63
  store i64 %7571, i64* %3, align 8
  %7572 = inttoptr i64 %7570 to i32*
  %7573 = load i32, i32* %7572, align 4
  %7574 = add i32 %7573, %7568
  %7575 = zext i32 %7574 to i64
  store i64 %7575, i64* %RSI.i1889, align 8
  %7576 = icmp ult i32 %7574, %7568
  %7577 = icmp ult i32 %7574, %7573
  %7578 = or i1 %7576, %7577
  %7579 = zext i1 %7578 to i8
  store i8 %7579, i8* %18, align 1
  %7580 = and i32 %7574, 255
  %7581 = tail call i32 @llvm.ctpop.i32(i32 %7580)
  %7582 = trunc i32 %7581 to i8
  %7583 = and i8 %7582, 1
  %7584 = xor i8 %7583, 1
  store i8 %7584, i8* %19, align 1
  %7585 = xor i32 %7573, %7568
  %7586 = xor i32 %7585, %7574
  %7587 = lshr i32 %7586, 4
  %7588 = trunc i32 %7587 to i8
  %7589 = and i8 %7588, 1
  store i8 %7589, i8* %20, align 1
  %7590 = icmp eq i32 %7574, 0
  %7591 = zext i1 %7590 to i8
  store i8 %7591, i8* %21, align 1
  %7592 = lshr i32 %7574, 31
  %7593 = trunc i32 %7592 to i8
  store i8 %7593, i8* %22, align 1
  %7594 = lshr i32 %7568, 31
  %7595 = lshr i32 %7573, 31
  %7596 = xor i32 %7592, %7594
  %7597 = xor i32 %7592, %7595
  %7598 = add nuw nsw i32 %7596, %7597
  %7599 = icmp eq i32 %7598, 2
  %7600 = zext i1 %7599 to i8
  store i8 %7600, i8* %23, align 1
  %7601 = sext i32 %7574 to i64
  store i64 %7601, i64* %RDX.i1805, align 8
  %7602 = shl nsw i64 %7601, 1
  %7603 = add i64 %7537, %7602
  %7604 = add i64 %7453, 70
  store i64 %7604, i64* %3, align 8
  %7605 = inttoptr i64 %7603 to i16*
  %7606 = load i16, i16* %7605, align 2
  %7607 = zext i16 %7606 to i64
  store i64 %7607, i64* %RSI.i1889, align 8
  %7608 = load i64, i64* %RAX.i1763, align 8
  %7609 = zext i16 %7606 to i32
  %7610 = zext i16 %7606 to i64
  %7611 = trunc i64 %7608 to i32
  %7612 = add i32 %7609, %7611
  %7613 = zext i32 %7612 to i64
  store i64 %7613, i64* %RAX.i1763, align 8
  %7614 = icmp ult i32 %7612, %7611
  %7615 = icmp ult i32 %7612, %7609
  %7616 = or i1 %7614, %7615
  %7617 = zext i1 %7616 to i8
  store i8 %7617, i8* %18, align 1
  %7618 = and i32 %7612, 255
  %7619 = tail call i32 @llvm.ctpop.i32(i32 %7618)
  %7620 = trunc i32 %7619 to i8
  %7621 = and i8 %7620, 1
  %7622 = xor i8 %7621, 1
  store i8 %7622, i8* %19, align 1
  %7623 = xor i64 %7610, %7608
  %7624 = trunc i64 %7623 to i32
  %7625 = xor i32 %7624, %7612
  %7626 = lshr i32 %7625, 4
  %7627 = trunc i32 %7626 to i8
  %7628 = and i8 %7627, 1
  store i8 %7628, i8* %20, align 1
  %7629 = icmp eq i32 %7612, 0
  %7630 = zext i1 %7629 to i8
  store i8 %7630, i8* %21, align 1
  %7631 = lshr i32 %7612, 31
  %7632 = trunc i32 %7631 to i8
  store i8 %7632, i8* %22, align 1
  %7633 = lshr i32 %7611, 31
  %7634 = xor i32 %7631, %7633
  %7635 = add nuw nsw i32 %7634, %7631
  %7636 = icmp eq i32 %7635, 2
  %7637 = zext i1 %7636 to i8
  store i8 %7637, i8* %23, align 1
  %7638 = add i64 %7564, -1236
  %7639 = add i64 %7453, 78
  store i64 %7639, i64* %3, align 8
  %7640 = inttoptr i64 %7638 to i32*
  store i32 %7612, i32* %7640, align 4
  %.pre735 = load i64, i64* %3, align 8
  br label %block_.L_4a5244

block_.L_4a5244:                                  ; preds = %block_.L_4a51f6, %block_4a51e9
  %7641 = phi i64 [ %.pre735, %block_.L_4a51f6 ], [ %7459, %block_4a51e9 ]
  %7642 = load i64, i64* %RBP.i, align 8
  %7643 = add i64 %7642, -1236
  %7644 = add i64 %7641, 6
  store i64 %7644, i64* %3, align 8
  %7645 = inttoptr i64 %7643 to i32*
  %7646 = load i32, i32* %7645, align 4
  %7647 = zext i32 %7646 to i64
  store i64 %7647, i64* %RAX.i1763, align 8
  %7648 = add i64 %7642, -1232
  %7649 = add i64 %7641, 12
  store i64 %7649, i64* %3, align 8
  %7650 = inttoptr i64 %7648 to i32*
  store i32 %7646, i32* %7650, align 4
  %.pre736 = load i64, i64* %3, align 8
  br label %block_.L_4a5250

block_.L_4a5250:                                  ; preds = %block_.L_4a5244, %block_4a517e
  %7651 = phi i64 [ %.pre736, %block_.L_4a5244 ], [ %7272, %block_4a517e ]
  %7652 = load i64, i64* %RBP.i, align 8
  %7653 = add i64 %7652, -1232
  %7654 = add i64 %7651, 6
  store i64 %7654, i64* %3, align 8
  %7655 = inttoptr i64 %7653 to i32*
  %7656 = load i32, i32* %7655, align 4
  %7657 = zext i32 %7656 to i64
  store i64 %7657, i64* %RAX.i1763, align 8
  store i64 0, i64* %RCX.i1692, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %7658 = trunc i32 %7656 to i16
  store i16 %7658, i16* %DX.i5417, align 2
  %7659 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %7659, i64* %RSI.i1889, align 8
  %7660 = add i64 %7659, 6464
  %7661 = add i64 %7651, 26
  store i64 %7661, i64* %3, align 8
  %7662 = inttoptr i64 %7660 to i64*
  %7663 = load i64, i64* %7662, align 8
  store i64 %7663, i64* %RSI.i1889, align 8
  %7664 = add i64 %7651, 29
  store i64 %7664, i64* %3, align 8
  %7665 = inttoptr i64 %7663 to i64*
  %7666 = load i64, i64* %7665, align 8
  store i64 %7666, i64* %RSI.i1889, align 8
  %7667 = add i64 %7652, -496
  %7668 = add i64 %7651, 35
  store i64 %7668, i64* %3, align 8
  %7669 = inttoptr i64 %7667 to i32*
  %7670 = load i32, i32* %7669, align 4
  %7671 = zext i32 %7670 to i64
  store i64 %7671, i64* %RAX.i1763, align 8
  %7672 = add i64 %7652, -48
  %7673 = add i64 %7651, 38
  store i64 %7673, i64* %3, align 8
  %7674 = inttoptr i64 %7672 to i32*
  %7675 = load i32, i32* %7674, align 4
  %7676 = add i32 %7675, %7670
  %7677 = zext i32 %7676 to i64
  store i64 %7677, i64* %RAX.i1763, align 8
  %7678 = icmp ult i32 %7676, %7670
  %7679 = icmp ult i32 %7676, %7675
  %7680 = or i1 %7678, %7679
  %7681 = zext i1 %7680 to i8
  store i8 %7681, i8* %18, align 1
  %7682 = and i32 %7676, 255
  %7683 = tail call i32 @llvm.ctpop.i32(i32 %7682)
  %7684 = trunc i32 %7683 to i8
  %7685 = and i8 %7684, 1
  %7686 = xor i8 %7685, 1
  store i8 %7686, i8* %19, align 1
  %7687 = xor i32 %7675, %7670
  %7688 = xor i32 %7687, %7676
  %7689 = lshr i32 %7688, 4
  %7690 = trunc i32 %7689 to i8
  %7691 = and i8 %7690, 1
  store i8 %7691, i8* %20, align 1
  %7692 = icmp eq i32 %7676, 0
  %7693 = zext i1 %7692 to i8
  store i8 %7693, i8* %21, align 1
  %7694 = lshr i32 %7676, 31
  %7695 = trunc i32 %7694 to i8
  store i8 %7695, i8* %22, align 1
  %7696 = lshr i32 %7670, 31
  %7697 = lshr i32 %7675, 31
  %7698 = xor i32 %7694, %7696
  %7699 = xor i32 %7694, %7697
  %7700 = add nuw nsw i32 %7698, %7699
  %7701 = icmp eq i32 %7700, 2
  %7702 = zext i1 %7701 to i8
  store i8 %7702, i8* %23, align 1
  %7703 = sext i32 %7676 to i64
  store i64 %7703, i64* %RDI.i2141, align 8
  %7704 = shl nsw i64 %7703, 3
  %7705 = add i64 %7666, %7704
  %7706 = add i64 %7651, 45
  store i64 %7706, i64* %3, align 8
  %7707 = inttoptr i64 %7705 to i64*
  %7708 = load i64, i64* %7707, align 8
  store i64 %7708, i64* %RSI.i1889, align 8
  %7709 = load i64, i64* %RBP.i, align 8
  %7710 = add i64 %7709, -492
  %7711 = add i64 %7651, 51
  store i64 %7711, i64* %3, align 8
  %7712 = inttoptr i64 %7710 to i32*
  %7713 = load i32, i32* %7712, align 4
  %7714 = zext i32 %7713 to i64
  store i64 %7714, i64* %RAX.i1763, align 8
  %7715 = add i64 %7709, -44
  %7716 = add i64 %7651, 54
  store i64 %7716, i64* %3, align 8
  %7717 = inttoptr i64 %7715 to i32*
  %7718 = load i32, i32* %7717, align 4
  %7719 = add i32 %7718, %7713
  %7720 = zext i32 %7719 to i64
  store i64 %7720, i64* %RAX.i1763, align 8
  %7721 = icmp ult i32 %7719, %7713
  %7722 = icmp ult i32 %7719, %7718
  %7723 = or i1 %7721, %7722
  %7724 = zext i1 %7723 to i8
  store i8 %7724, i8* %18, align 1
  %7725 = and i32 %7719, 255
  %7726 = tail call i32 @llvm.ctpop.i32(i32 %7725)
  %7727 = trunc i32 %7726 to i8
  %7728 = and i8 %7727, 1
  %7729 = xor i8 %7728, 1
  store i8 %7729, i8* %19, align 1
  %7730 = xor i32 %7718, %7713
  %7731 = xor i32 %7730, %7719
  %7732 = lshr i32 %7731, 4
  %7733 = trunc i32 %7732 to i8
  %7734 = and i8 %7733, 1
  store i8 %7734, i8* %20, align 1
  %7735 = icmp eq i32 %7719, 0
  %7736 = zext i1 %7735 to i8
  store i8 %7736, i8* %21, align 1
  %7737 = lshr i32 %7719, 31
  %7738 = trunc i32 %7737 to i8
  store i8 %7738, i8* %22, align 1
  %7739 = lshr i32 %7713, 31
  %7740 = lshr i32 %7718, 31
  %7741 = xor i32 %7737, %7739
  %7742 = xor i32 %7737, %7740
  %7743 = add nuw nsw i32 %7741, %7742
  %7744 = icmp eq i32 %7743, 2
  %7745 = zext i1 %7744 to i8
  store i8 %7745, i8* %23, align 1
  %7746 = sext i32 %7719 to i64
  store i64 %7746, i64* %RDI.i2141, align 8
  %7747 = shl nsw i64 %7746, 1
  %7748 = add i64 %7708, %7747
  %7749 = load i16, i16* %DX.i5417, align 2
  %7750 = add i64 %7651, 61
  store i64 %7750, i64* %3, align 8
  %7751 = inttoptr i64 %7748 to i16*
  store i16 %7749, i16* %7751, align 2
  %7752 = load i64, i64* %3, align 8
  %7753 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7753, i64* %RSI.i1889, align 8
  %7754 = add i64 %7753, 72684
  %7755 = add i64 %7752, 14
  store i64 %7755, i64* %3, align 8
  %7756 = inttoptr i64 %7754 to i32*
  %7757 = load i32, i32* %7756, align 4
  %7758 = zext i32 %7757 to i64
  store i64 %7758, i64* %RAX.i1763, align 8
  %7759 = load i64, i64* %RBP.i, align 8
  %7760 = add i64 %7759, -608
  %7761 = add i64 %7752, 21
  store i64 %7761, i64* %3, align 8
  %7762 = inttoptr i64 %7760 to i32*
  %7763 = load i32, i32* %7762, align 4
  %7764 = zext i32 %7763 to i64
  store i64 %7764, i64* %26, align 8
  %7765 = add i64 %7753, 7352
  store i64 %7765, i64* %RSI.i1889, align 8
  %7766 = icmp ugt i64 %7753, -7353
  %7767 = zext i1 %7766 to i8
  store i8 %7767, i8* %18, align 1
  %7768 = trunc i64 %7765 to i32
  %7769 = and i32 %7768, 255
  %7770 = tail call i32 @llvm.ctpop.i32(i32 %7769)
  %7771 = trunc i32 %7770 to i8
  %7772 = and i8 %7771, 1
  %7773 = xor i8 %7772, 1
  store i8 %7773, i8* %19, align 1
  %7774 = xor i64 %7753, 16
  %7775 = xor i64 %7774, %7765
  %7776 = lshr i64 %7775, 4
  %7777 = trunc i64 %7776 to i8
  %7778 = and i8 %7777, 1
  store i8 %7778, i8* %20, align 1
  %7779 = icmp eq i64 %7765, 0
  %7780 = zext i1 %7779 to i8
  store i8 %7780, i8* %21, align 1
  %7781 = lshr i64 %7765, 63
  %7782 = trunc i64 %7781 to i8
  store i8 %7782, i8* %22, align 1
  %7783 = lshr i64 %7753, 63
  %7784 = xor i64 %7781, %7783
  %7785 = add nuw nsw i64 %7784, %7781
  %7786 = icmp eq i64 %7785, 2
  %7787 = zext i1 %7786 to i8
  store i8 %7787, i8* %23, align 1
  %7788 = add i64 %7759, -36
  %7789 = add i64 %7752, 40
  store i64 %7789, i64* %3, align 8
  %7790 = inttoptr i64 %7788 to i32*
  %7791 = load i32, i32* %7790, align 4
  %7792 = sext i32 %7791 to i64
  %7793 = shl nsw i64 %7792, 7
  store i64 %7793, i64* %RDI.i2141, align 8
  %7794 = add i64 %7793, %7765
  store i64 %7794, i64* %RSI.i1889, align 8
  %7795 = icmp ult i64 %7794, %7765
  %7796 = icmp ult i64 %7794, %7793
  %7797 = or i1 %7795, %7796
  %7798 = zext i1 %7797 to i8
  store i8 %7798, i8* %18, align 1
  %7799 = trunc i64 %7794 to i32
  %7800 = and i32 %7799, 255
  %7801 = tail call i32 @llvm.ctpop.i32(i32 %7800)
  %7802 = trunc i32 %7801 to i8
  %7803 = and i8 %7802, 1
  %7804 = xor i8 %7803, 1
  store i8 %7804, i8* %19, align 1
  %7805 = xor i64 %7765, %7794
  %7806 = lshr i64 %7805, 4
  %7807 = trunc i64 %7806 to i8
  %7808 = and i8 %7807, 1
  store i8 %7808, i8* %20, align 1
  %7809 = icmp eq i64 %7794, 0
  %7810 = zext i1 %7809 to i8
  store i8 %7810, i8* %21, align 1
  %7811 = lshr i64 %7794, 63
  %7812 = trunc i64 %7811 to i8
  store i8 %7812, i8* %22, align 1
  %7813 = lshr i64 %7792, 56
  %7814 = and i64 %7813, 1
  %7815 = xor i64 %7811, %7781
  %7816 = xor i64 %7811, %7814
  %7817 = add nuw nsw i64 %7815, %7816
  %7818 = icmp eq i64 %7817, 2
  %7819 = zext i1 %7818 to i8
  store i8 %7819, i8* %23, align 1
  %7820 = load i64, i64* %RBP.i, align 8
  %7821 = add i64 %7820, -48
  %7822 = add i64 %7752, 51
  store i64 %7822, i64* %3, align 8
  %7823 = inttoptr i64 %7821 to i32*
  %7824 = load i32, i32* %7823, align 4
  %7825 = sext i32 %7824 to i64
  %7826 = shl nsw i64 %7825, 4
  store i64 %7826, i64* %RDI.i2141, align 8
  %7827 = add i64 %7826, %7794
  store i64 %7827, i64* %RSI.i1889, align 8
  %7828 = icmp ult i64 %7827, %7794
  %7829 = icmp ult i64 %7827, %7826
  %7830 = or i1 %7828, %7829
  %7831 = zext i1 %7830 to i8
  store i8 %7831, i8* %18, align 1
  %7832 = trunc i64 %7827 to i32
  %7833 = and i32 %7832, 255
  %7834 = tail call i32 @llvm.ctpop.i32(i32 %7833)
  %7835 = trunc i32 %7834 to i8
  %7836 = and i8 %7835, 1
  %7837 = xor i8 %7836, 1
  store i8 %7837, i8* %19, align 1
  %7838 = xor i64 %7826, %7794
  %7839 = xor i64 %7838, %7827
  %7840 = lshr i64 %7839, 4
  %7841 = trunc i64 %7840 to i8
  %7842 = and i8 %7841, 1
  store i8 %7842, i8* %20, align 1
  %7843 = icmp eq i64 %7827, 0
  %7844 = zext i1 %7843 to i8
  store i8 %7844, i8* %21, align 1
  %7845 = lshr i64 %7827, 63
  %7846 = trunc i64 %7845 to i8
  store i8 %7846, i8* %22, align 1
  %7847 = lshr i64 %7825, 59
  %7848 = and i64 %7847, 1
  %7849 = xor i64 %7845, %7811
  %7850 = xor i64 %7845, %7848
  %7851 = add nuw nsw i64 %7849, %7850
  %7852 = icmp eq i64 %7851, 2
  %7853 = zext i1 %7852 to i8
  store i8 %7853, i8* %23, align 1
  %7854 = add i64 %7820, -44
  %7855 = add i64 %7752, 62
  store i64 %7855, i64* %3, align 8
  %7856 = inttoptr i64 %7854 to i32*
  %7857 = load i32, i32* %7856, align 4
  %7858 = sext i32 %7857 to i64
  store i64 %7858, i64* %RDI.i2141, align 8
  %7859 = shl nsw i64 %7858, 1
  %7860 = add i64 %7859, %7827
  %7861 = add i64 %7752, 67
  store i64 %7861, i64* %3, align 8
  %7862 = inttoptr i64 %7860 to i16*
  %7863 = load i16, i16* %7862, align 2
  %7864 = zext i16 %7863 to i64
  store i64 %7864, i64* %R9.i, align 8
  %7865 = load i32, i32* %R8D.i1718, align 4
  %7866 = zext i16 %7863 to i32
  %7867 = add i32 %7866, %7865
  %7868 = zext i32 %7867 to i64
  store i64 %7868, i64* %26, align 8
  %7869 = lshr i32 %7867, 31
  %7870 = load i32, i32* %ECX.i7699, align 4
  %7871 = sub i32 %7870, %7867
  %7872 = icmp ult i32 %7870, %7867
  %7873 = zext i1 %7872 to i8
  store i8 %7873, i8* %18, align 1
  %7874 = and i32 %7871, 255
  %7875 = tail call i32 @llvm.ctpop.i32(i32 %7874)
  %7876 = trunc i32 %7875 to i8
  %7877 = and i8 %7876, 1
  %7878 = xor i8 %7877, 1
  store i8 %7878, i8* %19, align 1
  %7879 = xor i32 %7867, %7870
  %7880 = xor i32 %7879, %7871
  %7881 = lshr i32 %7880, 4
  %7882 = trunc i32 %7881 to i8
  %7883 = and i8 %7882, 1
  store i8 %7883, i8* %20, align 1
  %7884 = icmp eq i32 %7871, 0
  %7885 = zext i1 %7884 to i8
  store i8 %7885, i8* %21, align 1
  %7886 = lshr i32 %7871, 31
  %7887 = trunc i32 %7886 to i8
  store i8 %7887, i8* %22, align 1
  %7888 = lshr i32 %7870, 31
  %7889 = xor i32 %7869, %7888
  %7890 = xor i32 %7886, %7888
  %7891 = add nuw nsw i32 %7890, %7889
  %7892 = icmp eq i32 %7891, 2
  %7893 = zext i1 %7892 to i8
  store i8 %7893, i8* %23, align 1
  %7894 = load i64, i64* %RBP.i, align 8
  %7895 = add i64 %7894, -1240
  %7896 = load i32, i32* %EAX.i2159, align 4
  %7897 = add i64 %7752, 79
  store i64 %7897, i64* %3, align 8
  %7898 = inttoptr i64 %7895 to i32*
  store i32 %7896, i32* %7898, align 4
  %7899 = load i64, i64* %3, align 8
  %7900 = load i8, i8* %21, align 1
  %7901 = icmp ne i8 %7900, 0
  %7902 = load i8, i8* %22, align 1
  %7903 = icmp ne i8 %7902, 0
  %7904 = load i8, i8* %23, align 1
  %7905 = icmp ne i8 %7904, 0
  %7906 = xor i1 %7903, %7905
  %7907 = or i1 %7901, %7906
  %.v1015 = select i1 %7907, i64 19, i64 6
  %7908 = add i64 %7899, %.v1015
  store i64 %7908, i64* %3, align 8
  br i1 %7907, label %block_.L_4a52ef, label %block_4a52e2

block_4a52e2:                                     ; preds = %block_.L_4a5250
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %7909 = load i64, i64* %RBP.i, align 8
  %7910 = add i64 %7909, -1244
  %7911 = add i64 %7908, 8
  store i64 %7911, i64* %3, align 8
  %7912 = inttoptr i64 %7910 to i32*
  store i32 0, i32* %7912, align 4
  %7913 = load i64, i64* %3, align 8
  %7914 = add i64 %7913, 64
  store i64 %7914, i64* %3, align 8
  br label %block_.L_4a532a

block_.L_4a52ef:                                  ; preds = %block_.L_4a5250
  %7915 = load i64, i64* %RBP.i, align 8
  %7916 = add i64 %7915, -608
  %7917 = add i64 %7908, 6
  store i64 %7917, i64* %3, align 8
  %7918 = inttoptr i64 %7916 to i32*
  %7919 = load i32, i32* %7918, align 4
  %7920 = zext i32 %7919 to i64
  store i64 %7920, i64* %RAX.i1763, align 8
  %7921 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %7922 = add i64 %7921, 7352
  store i64 %7922, i64* %RCX.i1692, align 8
  %7923 = icmp ugt i64 %7921, -7353
  %7924 = zext i1 %7923 to i8
  store i8 %7924, i8* %18, align 1
  %7925 = trunc i64 %7922 to i32
  %7926 = and i32 %7925, 255
  %7927 = tail call i32 @llvm.ctpop.i32(i32 %7926)
  %7928 = trunc i32 %7927 to i8
  %7929 = and i8 %7928, 1
  %7930 = xor i8 %7929, 1
  store i8 %7930, i8* %19, align 1
  %7931 = xor i64 %7921, 16
  %7932 = xor i64 %7931, %7922
  %7933 = lshr i64 %7932, 4
  %7934 = trunc i64 %7933 to i8
  %7935 = and i8 %7934, 1
  store i8 %7935, i8* %20, align 1
  %7936 = icmp eq i64 %7922, 0
  %7937 = zext i1 %7936 to i8
  store i8 %7937, i8* %21, align 1
  %7938 = lshr i64 %7922, 63
  %7939 = trunc i64 %7938 to i8
  store i8 %7939, i8* %22, align 1
  %7940 = lshr i64 %7921, 63
  %7941 = xor i64 %7938, %7940
  %7942 = add nuw nsw i64 %7941, %7938
  %7943 = icmp eq i64 %7942, 2
  %7944 = zext i1 %7943 to i8
  store i8 %7944, i8* %23, align 1
  %7945 = add i64 %7915, -36
  %7946 = add i64 %7908, 25
  store i64 %7946, i64* %3, align 8
  %7947 = inttoptr i64 %7945 to i32*
  %7948 = load i32, i32* %7947, align 4
  %7949 = sext i32 %7948 to i64
  %7950 = shl nsw i64 %7949, 7
  store i64 %7950, i64* %RDX.i1805, align 8
  %7951 = add i64 %7950, %7922
  store i64 %7951, i64* %RCX.i1692, align 8
  %7952 = icmp ult i64 %7951, %7922
  %7953 = icmp ult i64 %7951, %7950
  %7954 = or i1 %7952, %7953
  %7955 = zext i1 %7954 to i8
  store i8 %7955, i8* %18, align 1
  %7956 = trunc i64 %7951 to i32
  %7957 = and i32 %7956, 255
  %7958 = tail call i32 @llvm.ctpop.i32(i32 %7957)
  %7959 = trunc i32 %7958 to i8
  %7960 = and i8 %7959, 1
  %7961 = xor i8 %7960, 1
  store i8 %7961, i8* %19, align 1
  %7962 = xor i64 %7922, %7951
  %7963 = lshr i64 %7962, 4
  %7964 = trunc i64 %7963 to i8
  %7965 = and i8 %7964, 1
  store i8 %7965, i8* %20, align 1
  %7966 = icmp eq i64 %7951, 0
  %7967 = zext i1 %7966 to i8
  store i8 %7967, i8* %21, align 1
  %7968 = lshr i64 %7951, 63
  %7969 = trunc i64 %7968 to i8
  store i8 %7969, i8* %22, align 1
  %7970 = lshr i64 %7949, 56
  %7971 = and i64 %7970, 1
  %7972 = xor i64 %7968, %7938
  %7973 = xor i64 %7968, %7971
  %7974 = add nuw nsw i64 %7972, %7973
  %7975 = icmp eq i64 %7974, 2
  %7976 = zext i1 %7975 to i8
  store i8 %7976, i8* %23, align 1
  %7977 = load i64, i64* %RBP.i, align 8
  %7978 = add i64 %7977, -48
  %7979 = add i64 %7908, 36
  store i64 %7979, i64* %3, align 8
  %7980 = inttoptr i64 %7978 to i32*
  %7981 = load i32, i32* %7980, align 4
  %7982 = sext i32 %7981 to i64
  %7983 = shl nsw i64 %7982, 4
  store i64 %7983, i64* %RDX.i1805, align 8
  %7984 = add i64 %7983, %7951
  store i64 %7984, i64* %RCX.i1692, align 8
  %7985 = icmp ult i64 %7984, %7951
  %7986 = icmp ult i64 %7984, %7983
  %7987 = or i1 %7985, %7986
  %7988 = zext i1 %7987 to i8
  store i8 %7988, i8* %18, align 1
  %7989 = trunc i64 %7984 to i32
  %7990 = and i32 %7989, 255
  %7991 = tail call i32 @llvm.ctpop.i32(i32 %7990)
  %7992 = trunc i32 %7991 to i8
  %7993 = and i8 %7992, 1
  %7994 = xor i8 %7993, 1
  store i8 %7994, i8* %19, align 1
  %7995 = xor i64 %7983, %7951
  %7996 = xor i64 %7995, %7984
  %7997 = lshr i64 %7996, 4
  %7998 = trunc i64 %7997 to i8
  %7999 = and i8 %7998, 1
  store i8 %7999, i8* %20, align 1
  %8000 = icmp eq i64 %7984, 0
  %8001 = zext i1 %8000 to i8
  store i8 %8001, i8* %21, align 1
  %8002 = lshr i64 %7984, 63
  %8003 = trunc i64 %8002 to i8
  store i8 %8003, i8* %22, align 1
  %8004 = lshr i64 %7982, 59
  %8005 = and i64 %8004, 1
  %8006 = xor i64 %8002, %7968
  %8007 = xor i64 %8002, %8005
  %8008 = add nuw nsw i64 %8006, %8007
  %8009 = icmp eq i64 %8008, 2
  %8010 = zext i1 %8009 to i8
  store i8 %8010, i8* %23, align 1
  %8011 = add i64 %7977, -44
  %8012 = add i64 %7908, 47
  store i64 %8012, i64* %3, align 8
  %8013 = inttoptr i64 %8011 to i32*
  %8014 = load i32, i32* %8013, align 4
  %8015 = sext i32 %8014 to i64
  store i64 %8015, i64* %RDX.i1805, align 8
  %8016 = shl nsw i64 %8015, 1
  %8017 = add i64 %8016, %7984
  %8018 = add i64 %7908, 51
  store i64 %8018, i64* %3, align 8
  %8019 = inttoptr i64 %8017 to i16*
  %8020 = load i16, i16* %8019, align 2
  %8021 = zext i16 %8020 to i64
  store i64 %8021, i64* %RSI.i1889, align 8
  %8022 = load i64, i64* %RAX.i1763, align 8
  %8023 = zext i16 %8020 to i32
  %8024 = zext i16 %8020 to i64
  %8025 = trunc i64 %8022 to i32
  %8026 = add i32 %8023, %8025
  %8027 = zext i32 %8026 to i64
  store i64 %8027, i64* %RAX.i1763, align 8
  %8028 = icmp ult i32 %8026, %8025
  %8029 = icmp ult i32 %8026, %8023
  %8030 = or i1 %8028, %8029
  %8031 = zext i1 %8030 to i8
  store i8 %8031, i8* %18, align 1
  %8032 = and i32 %8026, 255
  %8033 = tail call i32 @llvm.ctpop.i32(i32 %8032)
  %8034 = trunc i32 %8033 to i8
  %8035 = and i8 %8034, 1
  %8036 = xor i8 %8035, 1
  store i8 %8036, i8* %19, align 1
  %8037 = xor i64 %8024, %8022
  %8038 = trunc i64 %8037 to i32
  %8039 = xor i32 %8038, %8026
  %8040 = lshr i32 %8039, 4
  %8041 = trunc i32 %8040 to i8
  %8042 = and i8 %8041, 1
  store i8 %8042, i8* %20, align 1
  %8043 = icmp eq i32 %8026, 0
  %8044 = zext i1 %8043 to i8
  store i8 %8044, i8* %21, align 1
  %8045 = lshr i32 %8026, 31
  %8046 = trunc i32 %8045 to i8
  store i8 %8046, i8* %22, align 1
  %8047 = lshr i32 %8025, 31
  %8048 = xor i32 %8045, %8047
  %8049 = add nuw nsw i32 %8048, %8045
  %8050 = icmp eq i32 %8049, 2
  %8051 = zext i1 %8050 to i8
  store i8 %8051, i8* %23, align 1
  %8052 = load i64, i64* %RBP.i, align 8
  %8053 = add i64 %8052, -1244
  %8054 = add i64 %7908, 59
  store i64 %8054, i64* %3, align 8
  %8055 = inttoptr i64 %8053 to i32*
  store i32 %8026, i32* %8055, align 4
  %.pre737 = load i64, i64* %3, align 8
  br label %block_.L_4a532a

block_.L_4a532a:                                  ; preds = %block_.L_4a52ef, %block_4a52e2
  %8056 = phi i64 [ %.pre737, %block_.L_4a52ef ], [ %7914, %block_4a52e2 ]
  %8057 = load i64, i64* %RBP.i, align 8
  %8058 = add i64 %8057, -1244
  %8059 = add i64 %8056, 6
  store i64 %8059, i64* %3, align 8
  %8060 = inttoptr i64 %8058 to i32*
  %8061 = load i32, i32* %8060, align 4
  %8062 = zext i32 %8061 to i64
  store i64 %8062, i64* %RAX.i1763, align 8
  %8063 = add i64 %8057, -1240
  %8064 = add i64 %8056, 12
  store i64 %8064, i64* %3, align 8
  %8065 = inttoptr i64 %8063 to i32*
  %8066 = load i32, i32* %8065, align 4
  %8067 = zext i32 %8066 to i64
  store i64 %8067, i64* %RCX.i1692, align 8
  %8068 = sub i32 %8066, %8061
  %8069 = icmp ult i32 %8066, %8061
  %8070 = zext i1 %8069 to i8
  store i8 %8070, i8* %18, align 1
  %8071 = and i32 %8068, 255
  %8072 = tail call i32 @llvm.ctpop.i32(i32 %8071)
  %8073 = trunc i32 %8072 to i8
  %8074 = and i8 %8073, 1
  %8075 = xor i8 %8074, 1
  store i8 %8075, i8* %19, align 1
  %8076 = xor i32 %8061, %8066
  %8077 = xor i32 %8076, %8068
  %8078 = lshr i32 %8077, 4
  %8079 = trunc i32 %8078 to i8
  %8080 = and i8 %8079, 1
  store i8 %8080, i8* %20, align 1
  %8081 = icmp eq i32 %8068, 0
  %8082 = zext i1 %8081 to i8
  store i8 %8082, i8* %21, align 1
  %8083 = lshr i32 %8068, 31
  %8084 = trunc i32 %8083 to i8
  store i8 %8084, i8* %22, align 1
  %8085 = lshr i32 %8066, 31
  %8086 = lshr i32 %8061, 31
  %8087 = xor i32 %8086, %8085
  %8088 = xor i32 %8083, %8085
  %8089 = add nuw nsw i32 %8088, %8087
  %8090 = icmp eq i32 %8089, 2
  %8091 = zext i1 %8090 to i8
  store i8 %8091, i8* %23, align 1
  %8092 = icmp ne i8 %8084, 0
  %8093 = xor i1 %8092, %8090
  %.v858 = select i1 %8093, i64 20, i64 45
  %8094 = add i64 %8056, %.v858
  store i64 %8094, i64* %3, align 8
  br i1 %8093, label %block_4a533e, label %block_.L_4a5357

block_4a533e:                                     ; preds = %block_.L_4a532a
  %8095 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8095, i64* %RAX.i1763, align 8
  %8096 = add i64 %8095, 72684
  %8097 = add i64 %8094, 14
  store i64 %8097, i64* %3, align 8
  %8098 = inttoptr i64 %8096 to i32*
  %8099 = load i32, i32* %8098, align 4
  %8100 = zext i32 %8099 to i64
  store i64 %8100, i64* %RCX.i1692, align 8
  %8101 = add i64 %8057, -1248
  %8102 = add i64 %8094, 20
  store i64 %8102, i64* %3, align 8
  %8103 = inttoptr i64 %8101 to i32*
  store i32 %8099, i32* %8103, align 4
  %8104 = load i64, i64* %3, align 8
  %8105 = add i64 %8104, 152
  store i64 %8105, i64* %3, align 8
  br label %block_.L_4a53ea

block_.L_4a5357:                                  ; preds = %block_.L_4a532a
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %8106 = add i64 %8057, -608
  %8107 = add i64 %8094, 8
  store i64 %8107, i64* %3, align 8
  %8108 = inttoptr i64 %8106 to i32*
  %8109 = load i32, i32* %8108, align 4
  %8110 = zext i32 %8109 to i64
  store i64 %8110, i64* %RCX.i1692, align 8
  %8111 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %8112 = add i64 %8111, 7352
  store i64 %8112, i64* %RDX.i1805, align 8
  %8113 = icmp ugt i64 %8111, -7353
  %8114 = zext i1 %8113 to i8
  store i8 %8114, i8* %18, align 1
  %8115 = trunc i64 %8112 to i32
  %8116 = and i32 %8115, 255
  %8117 = tail call i32 @llvm.ctpop.i32(i32 %8116)
  %8118 = trunc i32 %8117 to i8
  %8119 = and i8 %8118, 1
  %8120 = xor i8 %8119, 1
  store i8 %8120, i8* %19, align 1
  %8121 = xor i64 %8111, 16
  %8122 = xor i64 %8121, %8112
  %8123 = lshr i64 %8122, 4
  %8124 = trunc i64 %8123 to i8
  %8125 = and i8 %8124, 1
  store i8 %8125, i8* %20, align 1
  %8126 = icmp eq i64 %8112, 0
  %8127 = zext i1 %8126 to i8
  store i8 %8127, i8* %21, align 1
  %8128 = lshr i64 %8112, 63
  %8129 = trunc i64 %8128 to i8
  store i8 %8129, i8* %22, align 1
  %8130 = lshr i64 %8111, 63
  %8131 = xor i64 %8128, %8130
  %8132 = add nuw nsw i64 %8131, %8128
  %8133 = icmp eq i64 %8132, 2
  %8134 = zext i1 %8133 to i8
  store i8 %8134, i8* %23, align 1
  %8135 = add i64 %8057, -36
  %8136 = add i64 %8094, 27
  store i64 %8136, i64* %3, align 8
  %8137 = inttoptr i64 %8135 to i32*
  %8138 = load i32, i32* %8137, align 4
  %8139 = sext i32 %8138 to i64
  %8140 = shl nsw i64 %8139, 7
  store i64 %8140, i64* %RSI.i1889, align 8
  %8141 = add i64 %8140, %8112
  store i64 %8141, i64* %RDX.i1805, align 8
  %8142 = icmp ult i64 %8141, %8112
  %8143 = icmp ult i64 %8141, %8140
  %8144 = or i1 %8142, %8143
  %8145 = zext i1 %8144 to i8
  store i8 %8145, i8* %18, align 1
  %8146 = trunc i64 %8141 to i32
  %8147 = and i32 %8146, 255
  %8148 = tail call i32 @llvm.ctpop.i32(i32 %8147)
  %8149 = trunc i32 %8148 to i8
  %8150 = and i8 %8149, 1
  %8151 = xor i8 %8150, 1
  store i8 %8151, i8* %19, align 1
  %8152 = xor i64 %8112, %8141
  %8153 = lshr i64 %8152, 4
  %8154 = trunc i64 %8153 to i8
  %8155 = and i8 %8154, 1
  store i8 %8155, i8* %20, align 1
  %8156 = icmp eq i64 %8141, 0
  %8157 = zext i1 %8156 to i8
  store i8 %8157, i8* %21, align 1
  %8158 = lshr i64 %8141, 63
  %8159 = trunc i64 %8158 to i8
  store i8 %8159, i8* %22, align 1
  %8160 = lshr i64 %8139, 56
  %8161 = and i64 %8160, 1
  %8162 = xor i64 %8158, %8128
  %8163 = xor i64 %8158, %8161
  %8164 = add nuw nsw i64 %8162, %8163
  %8165 = icmp eq i64 %8164, 2
  %8166 = zext i1 %8165 to i8
  store i8 %8166, i8* %23, align 1
  %8167 = load i64, i64* %RBP.i, align 8
  %8168 = add i64 %8167, -48
  %8169 = add i64 %8094, 38
  store i64 %8169, i64* %3, align 8
  %8170 = inttoptr i64 %8168 to i32*
  %8171 = load i32, i32* %8170, align 4
  %8172 = sext i32 %8171 to i64
  %8173 = shl nsw i64 %8172, 4
  store i64 %8173, i64* %RSI.i1889, align 8
  %8174 = add i64 %8173, %8141
  store i64 %8174, i64* %RDX.i1805, align 8
  %8175 = icmp ult i64 %8174, %8141
  %8176 = icmp ult i64 %8174, %8173
  %8177 = or i1 %8175, %8176
  %8178 = zext i1 %8177 to i8
  store i8 %8178, i8* %18, align 1
  %8179 = trunc i64 %8174 to i32
  %8180 = and i32 %8179, 255
  %8181 = tail call i32 @llvm.ctpop.i32(i32 %8180)
  %8182 = trunc i32 %8181 to i8
  %8183 = and i8 %8182, 1
  %8184 = xor i8 %8183, 1
  store i8 %8184, i8* %19, align 1
  %8185 = xor i64 %8173, %8141
  %8186 = xor i64 %8185, %8174
  %8187 = lshr i64 %8186, 4
  %8188 = trunc i64 %8187 to i8
  %8189 = and i8 %8188, 1
  store i8 %8189, i8* %20, align 1
  %8190 = icmp eq i64 %8174, 0
  %8191 = zext i1 %8190 to i8
  store i8 %8191, i8* %21, align 1
  %8192 = lshr i64 %8174, 63
  %8193 = trunc i64 %8192 to i8
  store i8 %8193, i8* %22, align 1
  %8194 = lshr i64 %8172, 59
  %8195 = and i64 %8194, 1
  %8196 = xor i64 %8192, %8158
  %8197 = xor i64 %8192, %8195
  %8198 = add nuw nsw i64 %8196, %8197
  %8199 = icmp eq i64 %8198, 2
  %8200 = zext i1 %8199 to i8
  store i8 %8200, i8* %23, align 1
  %8201 = add i64 %8167, -44
  %8202 = add i64 %8094, 49
  store i64 %8202, i64* %3, align 8
  %8203 = inttoptr i64 %8201 to i32*
  %8204 = load i32, i32* %8203, align 4
  %8205 = sext i32 %8204 to i64
  store i64 %8205, i64* %RSI.i1889, align 8
  %8206 = shl nsw i64 %8205, 1
  %8207 = add i64 %8206, %8174
  %8208 = add i64 %8094, 53
  store i64 %8208, i64* %3, align 8
  %8209 = inttoptr i64 %8207 to i16*
  %8210 = load i16, i16* %8209, align 2
  %8211 = zext i16 %8210 to i64
  store i64 %8211, i64* %RDI.i2141, align 8
  %8212 = load i64, i64* %RCX.i1692, align 8
  %8213 = zext i16 %8210 to i32
  %8214 = trunc i64 %8212 to i32
  %8215 = add i32 %8213, %8214
  %8216 = zext i32 %8215 to i64
  store i64 %8216, i64* %RCX.i1692, align 8
  %8217 = lshr i32 %8215, 31
  %8218 = load i32, i32* %EAX.i2159, align 4
  %8219 = sub i32 %8218, %8215
  %8220 = icmp ult i32 %8218, %8215
  %8221 = zext i1 %8220 to i8
  store i8 %8221, i8* %18, align 1
  %8222 = and i32 %8219, 255
  %8223 = tail call i32 @llvm.ctpop.i32(i32 %8222)
  %8224 = trunc i32 %8223 to i8
  %8225 = and i8 %8224, 1
  %8226 = xor i8 %8225, 1
  store i8 %8226, i8* %19, align 1
  %8227 = xor i32 %8215, %8218
  %8228 = xor i32 %8227, %8219
  %8229 = lshr i32 %8228, 4
  %8230 = trunc i32 %8229 to i8
  %8231 = and i8 %8230, 1
  store i8 %8231, i8* %20, align 1
  %8232 = icmp eq i32 %8219, 0
  %8233 = zext i1 %8232 to i8
  store i8 %8233, i8* %21, align 1
  %8234 = lshr i32 %8219, 31
  %8235 = trunc i32 %8234 to i8
  store i8 %8235, i8* %22, align 1
  %8236 = lshr i32 %8218, 31
  %8237 = xor i32 %8217, %8236
  %8238 = xor i32 %8234, %8236
  %8239 = add nuw nsw i32 %8238, %8237
  %8240 = icmp eq i32 %8239, 2
  %8241 = zext i1 %8240 to i8
  store i8 %8241, i8* %23, align 1
  %8242 = icmp ne i8 %8235, 0
  %8243 = xor i1 %8242, %8240
  %8244 = or i1 %8232, %8243
  %.v859 = select i1 %8244, i64 76, i64 63
  %8245 = add i64 %8094, %.v859
  store i64 %8245, i64* %3, align 8
  br i1 %8244, label %block_.L_4a53a3, label %block_4a5396

block_4a5396:                                     ; preds = %block_.L_4a5357
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %8246 = load i64, i64* %RBP.i, align 8
  %8247 = add i64 %8246, -1252
  %8248 = add i64 %8245, 8
  store i64 %8248, i64* %3, align 8
  %8249 = inttoptr i64 %8247 to i32*
  store i32 0, i32* %8249, align 4
  %8250 = load i64, i64* %3, align 8
  %8251 = add i64 %8250, 64
  store i64 %8251, i64* %3, align 8
  br label %block_.L_4a53de

block_.L_4a53a3:                                  ; preds = %block_.L_4a5357
  %8252 = load i64, i64* %RBP.i, align 8
  %8253 = add i64 %8252, -608
  %8254 = add i64 %8245, 6
  store i64 %8254, i64* %3, align 8
  %8255 = inttoptr i64 %8253 to i32*
  %8256 = load i32, i32* %8255, align 4
  %8257 = zext i32 %8256 to i64
  store i64 %8257, i64* %RAX.i1763, align 8
  %8258 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %8259 = add i64 %8258, 7352
  store i64 %8259, i64* %RCX.i1692, align 8
  %8260 = icmp ugt i64 %8258, -7353
  %8261 = zext i1 %8260 to i8
  store i8 %8261, i8* %18, align 1
  %8262 = trunc i64 %8259 to i32
  %8263 = and i32 %8262, 255
  %8264 = tail call i32 @llvm.ctpop.i32(i32 %8263)
  %8265 = trunc i32 %8264 to i8
  %8266 = and i8 %8265, 1
  %8267 = xor i8 %8266, 1
  store i8 %8267, i8* %19, align 1
  %8268 = xor i64 %8258, 16
  %8269 = xor i64 %8268, %8259
  %8270 = lshr i64 %8269, 4
  %8271 = trunc i64 %8270 to i8
  %8272 = and i8 %8271, 1
  store i8 %8272, i8* %20, align 1
  %8273 = icmp eq i64 %8259, 0
  %8274 = zext i1 %8273 to i8
  store i8 %8274, i8* %21, align 1
  %8275 = lshr i64 %8259, 63
  %8276 = trunc i64 %8275 to i8
  store i8 %8276, i8* %22, align 1
  %8277 = lshr i64 %8258, 63
  %8278 = xor i64 %8275, %8277
  %8279 = add nuw nsw i64 %8278, %8275
  %8280 = icmp eq i64 %8279, 2
  %8281 = zext i1 %8280 to i8
  store i8 %8281, i8* %23, align 1
  %8282 = add i64 %8252, -36
  %8283 = add i64 %8245, 25
  store i64 %8283, i64* %3, align 8
  %8284 = inttoptr i64 %8282 to i32*
  %8285 = load i32, i32* %8284, align 4
  %8286 = sext i32 %8285 to i64
  %8287 = shl nsw i64 %8286, 7
  store i64 %8287, i64* %RDX.i1805, align 8
  %8288 = add i64 %8287, %8259
  store i64 %8288, i64* %RCX.i1692, align 8
  %8289 = icmp ult i64 %8288, %8259
  %8290 = icmp ult i64 %8288, %8287
  %8291 = or i1 %8289, %8290
  %8292 = zext i1 %8291 to i8
  store i8 %8292, i8* %18, align 1
  %8293 = trunc i64 %8288 to i32
  %8294 = and i32 %8293, 255
  %8295 = tail call i32 @llvm.ctpop.i32(i32 %8294)
  %8296 = trunc i32 %8295 to i8
  %8297 = and i8 %8296, 1
  %8298 = xor i8 %8297, 1
  store i8 %8298, i8* %19, align 1
  %8299 = xor i64 %8259, %8288
  %8300 = lshr i64 %8299, 4
  %8301 = trunc i64 %8300 to i8
  %8302 = and i8 %8301, 1
  store i8 %8302, i8* %20, align 1
  %8303 = icmp eq i64 %8288, 0
  %8304 = zext i1 %8303 to i8
  store i8 %8304, i8* %21, align 1
  %8305 = lshr i64 %8288, 63
  %8306 = trunc i64 %8305 to i8
  store i8 %8306, i8* %22, align 1
  %8307 = lshr i64 %8286, 56
  %8308 = and i64 %8307, 1
  %8309 = xor i64 %8305, %8275
  %8310 = xor i64 %8305, %8308
  %8311 = add nuw nsw i64 %8309, %8310
  %8312 = icmp eq i64 %8311, 2
  %8313 = zext i1 %8312 to i8
  store i8 %8313, i8* %23, align 1
  %8314 = load i64, i64* %RBP.i, align 8
  %8315 = add i64 %8314, -48
  %8316 = add i64 %8245, 36
  store i64 %8316, i64* %3, align 8
  %8317 = inttoptr i64 %8315 to i32*
  %8318 = load i32, i32* %8317, align 4
  %8319 = sext i32 %8318 to i64
  %8320 = shl nsw i64 %8319, 4
  store i64 %8320, i64* %RDX.i1805, align 8
  %8321 = add i64 %8320, %8288
  store i64 %8321, i64* %RCX.i1692, align 8
  %8322 = icmp ult i64 %8321, %8288
  %8323 = icmp ult i64 %8321, %8320
  %8324 = or i1 %8322, %8323
  %8325 = zext i1 %8324 to i8
  store i8 %8325, i8* %18, align 1
  %8326 = trunc i64 %8321 to i32
  %8327 = and i32 %8326, 255
  %8328 = tail call i32 @llvm.ctpop.i32(i32 %8327)
  %8329 = trunc i32 %8328 to i8
  %8330 = and i8 %8329, 1
  %8331 = xor i8 %8330, 1
  store i8 %8331, i8* %19, align 1
  %8332 = xor i64 %8320, %8288
  %8333 = xor i64 %8332, %8321
  %8334 = lshr i64 %8333, 4
  %8335 = trunc i64 %8334 to i8
  %8336 = and i8 %8335, 1
  store i8 %8336, i8* %20, align 1
  %8337 = icmp eq i64 %8321, 0
  %8338 = zext i1 %8337 to i8
  store i8 %8338, i8* %21, align 1
  %8339 = lshr i64 %8321, 63
  %8340 = trunc i64 %8339 to i8
  store i8 %8340, i8* %22, align 1
  %8341 = lshr i64 %8319, 59
  %8342 = and i64 %8341, 1
  %8343 = xor i64 %8339, %8305
  %8344 = xor i64 %8339, %8342
  %8345 = add nuw nsw i64 %8343, %8344
  %8346 = icmp eq i64 %8345, 2
  %8347 = zext i1 %8346 to i8
  store i8 %8347, i8* %23, align 1
  %8348 = add i64 %8314, -44
  %8349 = add i64 %8245, 47
  store i64 %8349, i64* %3, align 8
  %8350 = inttoptr i64 %8348 to i32*
  %8351 = load i32, i32* %8350, align 4
  %8352 = sext i32 %8351 to i64
  store i64 %8352, i64* %RDX.i1805, align 8
  %8353 = shl nsw i64 %8352, 1
  %8354 = add i64 %8353, %8321
  %8355 = add i64 %8245, 51
  store i64 %8355, i64* %3, align 8
  %8356 = inttoptr i64 %8354 to i16*
  %8357 = load i16, i16* %8356, align 2
  %8358 = zext i16 %8357 to i64
  store i64 %8358, i64* %RSI.i1889, align 8
  %8359 = load i64, i64* %RAX.i1763, align 8
  %8360 = zext i16 %8357 to i32
  %8361 = zext i16 %8357 to i64
  %8362 = trunc i64 %8359 to i32
  %8363 = add i32 %8360, %8362
  %8364 = zext i32 %8363 to i64
  store i64 %8364, i64* %RAX.i1763, align 8
  %8365 = icmp ult i32 %8363, %8362
  %8366 = icmp ult i32 %8363, %8360
  %8367 = or i1 %8365, %8366
  %8368 = zext i1 %8367 to i8
  store i8 %8368, i8* %18, align 1
  %8369 = and i32 %8363, 255
  %8370 = tail call i32 @llvm.ctpop.i32(i32 %8369)
  %8371 = trunc i32 %8370 to i8
  %8372 = and i8 %8371, 1
  %8373 = xor i8 %8372, 1
  store i8 %8373, i8* %19, align 1
  %8374 = xor i64 %8361, %8359
  %8375 = trunc i64 %8374 to i32
  %8376 = xor i32 %8375, %8363
  %8377 = lshr i32 %8376, 4
  %8378 = trunc i32 %8377 to i8
  %8379 = and i8 %8378, 1
  store i8 %8379, i8* %20, align 1
  %8380 = icmp eq i32 %8363, 0
  %8381 = zext i1 %8380 to i8
  store i8 %8381, i8* %21, align 1
  %8382 = lshr i32 %8363, 31
  %8383 = trunc i32 %8382 to i8
  store i8 %8383, i8* %22, align 1
  %8384 = lshr i32 %8362, 31
  %8385 = xor i32 %8382, %8384
  %8386 = add nuw nsw i32 %8385, %8382
  %8387 = icmp eq i32 %8386, 2
  %8388 = zext i1 %8387 to i8
  store i8 %8388, i8* %23, align 1
  %8389 = load i64, i64* %RBP.i, align 8
  %8390 = add i64 %8389, -1252
  %8391 = add i64 %8245, 59
  store i64 %8391, i64* %3, align 8
  %8392 = inttoptr i64 %8390 to i32*
  store i32 %8363, i32* %8392, align 4
  %.pre738 = load i64, i64* %3, align 8
  br label %block_.L_4a53de

block_.L_4a53de:                                  ; preds = %block_.L_4a53a3, %block_4a5396
  %8393 = phi i64 [ %.pre738, %block_.L_4a53a3 ], [ %8251, %block_4a5396 ]
  %8394 = load i64, i64* %RBP.i, align 8
  %8395 = add i64 %8394, -1252
  %8396 = add i64 %8393, 6
  store i64 %8396, i64* %3, align 8
  %8397 = inttoptr i64 %8395 to i32*
  %8398 = load i32, i32* %8397, align 4
  %8399 = zext i32 %8398 to i64
  store i64 %8399, i64* %RAX.i1763, align 8
  %8400 = add i64 %8394, -1248
  %8401 = add i64 %8393, 12
  store i64 %8401, i64* %3, align 8
  %8402 = inttoptr i64 %8400 to i32*
  store i32 %8398, i32* %8402, align 4
  %.pre739 = load i64, i64* %3, align 8
  br label %block_.L_4a53ea

block_.L_4a53ea:                                  ; preds = %block_.L_4a53de, %block_4a533e
  %8403 = phi i64 [ %.pre739, %block_.L_4a53de ], [ %8105, %block_4a533e ]
  %8404 = load i64, i64* %RBP.i, align 8
  %8405 = add i64 %8404, -1248
  %8406 = add i64 %8403, 6
  store i64 %8406, i64* %3, align 8
  %8407 = inttoptr i64 %8405 to i32*
  %8408 = load i32, i32* %8407, align 4
  %8409 = zext i32 %8408 to i64
  store i64 %8409, i64* %RAX.i1763, align 8
  store i64 0, i64* %RCX.i1692, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %8410 = trunc i32 %8408 to i16
  store i16 %8410, i16* %DX.i5417, align 2
  %8411 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %8411, i64* %RSI.i1889, align 8
  %8412 = add i64 %8411, 6424
  %8413 = add i64 %8403, 26
  store i64 %8413, i64* %3, align 8
  %8414 = inttoptr i64 %8412 to i64*
  %8415 = load i64, i64* %8414, align 8
  store i64 %8415, i64* %RSI.i1889, align 8
  %8416 = add i64 %8404, -496
  %8417 = add i64 %8403, 32
  store i64 %8417, i64* %3, align 8
  %8418 = inttoptr i64 %8416 to i32*
  %8419 = load i32, i32* %8418, align 4
  %8420 = zext i32 %8419 to i64
  store i64 %8420, i64* %RAX.i1763, align 8
  %8421 = add i64 %8404, -48
  %8422 = add i64 %8403, 35
  store i64 %8422, i64* %3, align 8
  %8423 = inttoptr i64 %8421 to i32*
  %8424 = load i32, i32* %8423, align 4
  %8425 = add i32 %8424, %8419
  %8426 = zext i32 %8425 to i64
  store i64 %8426, i64* %RAX.i1763, align 8
  %8427 = icmp ult i32 %8425, %8419
  %8428 = icmp ult i32 %8425, %8424
  %8429 = or i1 %8427, %8428
  %8430 = zext i1 %8429 to i8
  store i8 %8430, i8* %18, align 1
  %8431 = and i32 %8425, 255
  %8432 = tail call i32 @llvm.ctpop.i32(i32 %8431)
  %8433 = trunc i32 %8432 to i8
  %8434 = and i8 %8433, 1
  %8435 = xor i8 %8434, 1
  store i8 %8435, i8* %19, align 1
  %8436 = xor i32 %8424, %8419
  %8437 = xor i32 %8436, %8425
  %8438 = lshr i32 %8437, 4
  %8439 = trunc i32 %8438 to i8
  %8440 = and i8 %8439, 1
  store i8 %8440, i8* %20, align 1
  %8441 = icmp eq i32 %8425, 0
  %8442 = zext i1 %8441 to i8
  store i8 %8442, i8* %21, align 1
  %8443 = lshr i32 %8425, 31
  %8444 = trunc i32 %8443 to i8
  store i8 %8444, i8* %22, align 1
  %8445 = lshr i32 %8419, 31
  %8446 = lshr i32 %8424, 31
  %8447 = xor i32 %8443, %8445
  %8448 = xor i32 %8443, %8446
  %8449 = add nuw nsw i32 %8447, %8448
  %8450 = icmp eq i32 %8449, 2
  %8451 = zext i1 %8450 to i8
  store i8 %8451, i8* %23, align 1
  %8452 = sext i32 %8425 to i64
  store i64 %8452, i64* %RDI.i2141, align 8
  %8453 = shl nsw i64 %8452, 3
  %8454 = add i64 %8415, %8453
  %8455 = add i64 %8403, 42
  store i64 %8455, i64* %3, align 8
  %8456 = inttoptr i64 %8454 to i64*
  %8457 = load i64, i64* %8456, align 8
  store i64 %8457, i64* %RSI.i1889, align 8
  %8458 = load i64, i64* %RBP.i, align 8
  %8459 = add i64 %8458, -492
  %8460 = add i64 %8403, 48
  store i64 %8460, i64* %3, align 8
  %8461 = inttoptr i64 %8459 to i32*
  %8462 = load i32, i32* %8461, align 4
  %8463 = zext i32 %8462 to i64
  store i64 %8463, i64* %RAX.i1763, align 8
  %8464 = add i64 %8458, -44
  %8465 = add i64 %8403, 51
  store i64 %8465, i64* %3, align 8
  %8466 = inttoptr i64 %8464 to i32*
  %8467 = load i32, i32* %8466, align 4
  %8468 = add i32 %8467, %8462
  %8469 = zext i32 %8468 to i64
  store i64 %8469, i64* %RAX.i1763, align 8
  %8470 = icmp ult i32 %8468, %8462
  %8471 = icmp ult i32 %8468, %8467
  %8472 = or i1 %8470, %8471
  %8473 = zext i1 %8472 to i8
  store i8 %8473, i8* %18, align 1
  %8474 = and i32 %8468, 255
  %8475 = tail call i32 @llvm.ctpop.i32(i32 %8474)
  %8476 = trunc i32 %8475 to i8
  %8477 = and i8 %8476, 1
  %8478 = xor i8 %8477, 1
  store i8 %8478, i8* %19, align 1
  %8479 = xor i32 %8467, %8462
  %8480 = xor i32 %8479, %8468
  %8481 = lshr i32 %8480, 4
  %8482 = trunc i32 %8481 to i8
  %8483 = and i8 %8482, 1
  store i8 %8483, i8* %20, align 1
  %8484 = icmp eq i32 %8468, 0
  %8485 = zext i1 %8484 to i8
  store i8 %8485, i8* %21, align 1
  %8486 = lshr i32 %8468, 31
  %8487 = trunc i32 %8486 to i8
  store i8 %8487, i8* %22, align 1
  %8488 = lshr i32 %8462, 31
  %8489 = lshr i32 %8467, 31
  %8490 = xor i32 %8486, %8488
  %8491 = xor i32 %8486, %8489
  %8492 = add nuw nsw i32 %8490, %8491
  %8493 = icmp eq i32 %8492, 2
  %8494 = zext i1 %8493 to i8
  store i8 %8494, i8* %23, align 1
  %8495 = sext i32 %8468 to i64
  store i64 %8495, i64* %RDI.i2141, align 8
  %8496 = shl nsw i64 %8495, 1
  %8497 = add i64 %8457, %8496
  %8498 = load i16, i16* %DX.i5417, align 2
  %8499 = add i64 %8403, 58
  store i64 %8499, i64* %3, align 8
  %8500 = inttoptr i64 %8497 to i16*
  store i16 %8498, i16* %8500, align 2
  %8501 = load i64, i64* %3, align 8
  %8502 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8502, i64* %RSI.i1889, align 8
  %8503 = add i64 %8502, 72688
  %8504 = add i64 %8501, 14
  store i64 %8504, i64* %3, align 8
  %8505 = inttoptr i64 %8503 to i32*
  %8506 = load i32, i32* %8505, align 4
  %8507 = zext i32 %8506 to i64
  store i64 %8507, i64* %RAX.i1763, align 8
  %8508 = load i64, i64* %RBP.i, align 8
  %8509 = add i64 %8508, -604
  %8510 = add i64 %8501, 21
  store i64 %8510, i64* %3, align 8
  %8511 = inttoptr i64 %8509 to i32*
  %8512 = load i32, i32* %8511, align 4
  %8513 = zext i32 %8512 to i64
  store i64 %8513, i64* %26, align 8
  %8514 = add i64 %8502, 8504
  %8515 = lshr i64 %8514, 63
  %8516 = add i64 %8502, 10552
  store i64 %8516, i64* %RSI.i1889, align 8
  %8517 = icmp ugt i64 %8514, -2049
  %8518 = zext i1 %8517 to i8
  store i8 %8518, i8* %18, align 1
  %8519 = trunc i64 %8516 to i32
  %8520 = and i32 %8519, 255
  %8521 = tail call i32 @llvm.ctpop.i32(i32 %8520)
  %8522 = trunc i32 %8521 to i8
  %8523 = and i8 %8522, 1
  %8524 = xor i8 %8523, 1
  store i8 %8524, i8* %19, align 1
  %8525 = xor i64 %8516, %8514
  %8526 = lshr i64 %8525, 4
  %8527 = trunc i64 %8526 to i8
  %8528 = and i8 %8527, 1
  store i8 %8528, i8* %20, align 1
  %8529 = icmp eq i64 %8516, 0
  %8530 = zext i1 %8529 to i8
  store i8 %8530, i8* %21, align 1
  %8531 = lshr i64 %8516, 63
  %8532 = trunc i64 %8531 to i8
  store i8 %8532, i8* %22, align 1
  %8533 = xor i64 %8531, %8515
  %8534 = add nuw nsw i64 %8533, %8531
  %8535 = icmp eq i64 %8534, 2
  %8536 = zext i1 %8535 to i8
  store i8 %8536, i8* %23, align 1
  %8537 = add i64 %8508, -632
  %8538 = add i64 %8501, 50
  store i64 %8538, i64* %3, align 8
  %8539 = inttoptr i64 %8537 to i32*
  %8540 = load i32, i32* %8539, align 4
  %8541 = sext i32 %8540 to i64
  %8542 = shl nsw i64 %8541, 9
  store i64 %8542, i64* %RDI.i2141, align 8
  %8543 = add i64 %8542, %8516
  store i64 %8543, i64* %RSI.i1889, align 8
  %8544 = icmp ult i64 %8543, %8516
  %8545 = icmp ult i64 %8543, %8542
  %8546 = or i1 %8544, %8545
  %8547 = zext i1 %8546 to i8
  store i8 %8547, i8* %18, align 1
  %8548 = trunc i64 %8543 to i32
  %8549 = and i32 %8548, 255
  %8550 = tail call i32 @llvm.ctpop.i32(i32 %8549)
  %8551 = trunc i32 %8550 to i8
  %8552 = and i8 %8551, 1
  %8553 = xor i8 %8552, 1
  store i8 %8553, i8* %19, align 1
  %8554 = xor i64 %8516, %8543
  %8555 = lshr i64 %8554, 4
  %8556 = trunc i64 %8555 to i8
  %8557 = and i8 %8556, 1
  store i8 %8557, i8* %20, align 1
  %8558 = icmp eq i64 %8543, 0
  %8559 = zext i1 %8558 to i8
  store i8 %8559, i8* %21, align 1
  %8560 = lshr i64 %8543, 63
  %8561 = trunc i64 %8560 to i8
  store i8 %8561, i8* %22, align 1
  %8562 = lshr i64 %8541, 54
  %8563 = and i64 %8562, 1
  %8564 = xor i64 %8560, %8531
  %8565 = xor i64 %8560, %8563
  %8566 = add nuw nsw i64 %8564, %8565
  %8567 = icmp eq i64 %8566, 2
  %8568 = zext i1 %8567 to i8
  store i8 %8568, i8* %23, align 1
  %8569 = load i64, i64* %RBP.i, align 8
  %8570 = add i64 %8569, -484
  %8571 = add i64 %8501, 64
  store i64 %8571, i64* %3, align 8
  %8572 = inttoptr i64 %8570 to i32*
  %8573 = load i32, i32* %8572, align 4
  %8574 = zext i32 %8573 to i64
  store i64 %8574, i64* %R9.i, align 8
  %8575 = add i64 %8569, -44
  %8576 = add i64 %8501, 68
  store i64 %8576, i64* %3, align 8
  %8577 = inttoptr i64 %8575 to i32*
  %8578 = load i32, i32* %8577, align 4
  %8579 = add i32 %8578, %8573
  %8580 = zext i32 %8579 to i64
  store i64 %8580, i64* %R9.i, align 8
  %8581 = sext i32 %8579 to i64
  %8582 = shl nsw i64 %8581, 5
  store i64 %8582, i64* %RDI.i2141, align 8
  %8583 = load i64, i64* %RSI.i1889, align 8
  %8584 = add i64 %8582, %8583
  store i64 %8584, i64* %RSI.i1889, align 8
  %8585 = icmp ult i64 %8584, %8583
  %8586 = icmp ult i64 %8584, %8582
  %8587 = or i1 %8585, %8586
  %8588 = zext i1 %8587 to i8
  store i8 %8588, i8* %18, align 1
  %8589 = trunc i64 %8584 to i32
  %8590 = and i32 %8589, 255
  %8591 = tail call i32 @llvm.ctpop.i32(i32 %8590)
  %8592 = trunc i32 %8591 to i8
  %8593 = and i8 %8592, 1
  %8594 = xor i8 %8593, 1
  store i8 %8594, i8* %19, align 1
  %8595 = xor i64 %8583, %8584
  %8596 = lshr i64 %8595, 4
  %8597 = trunc i64 %8596 to i8
  %8598 = and i8 %8597, 1
  store i8 %8598, i8* %20, align 1
  %8599 = icmp eq i64 %8584, 0
  %8600 = zext i1 %8599 to i8
  store i8 %8600, i8* %21, align 1
  %8601 = lshr i64 %8584, 63
  %8602 = trunc i64 %8601 to i8
  store i8 %8602, i8* %22, align 1
  %8603 = lshr i64 %8583, 63
  %8604 = lshr i64 %8581, 58
  %8605 = and i64 %8604, 1
  %8606 = xor i64 %8601, %8603
  %8607 = xor i64 %8601, %8605
  %8608 = add nuw nsw i64 %8606, %8607
  %8609 = icmp eq i64 %8608, 2
  %8610 = zext i1 %8609 to i8
  store i8 %8610, i8* %23, align 1
  %8611 = load i64, i64* %RBP.i, align 8
  %8612 = add i64 %8611, -488
  %8613 = add i64 %8501, 85
  store i64 %8613, i64* %3, align 8
  %8614 = inttoptr i64 %8612 to i32*
  %8615 = load i32, i32* %8614, align 4
  %8616 = zext i32 %8615 to i64
  store i64 %8616, i64* %R9.i, align 8
  %8617 = add i64 %8611, -48
  %8618 = add i64 %8501, 89
  store i64 %8618, i64* %3, align 8
  %8619 = inttoptr i64 %8617 to i32*
  %8620 = load i32, i32* %8619, align 4
  %8621 = add i32 %8620, %8615
  %8622 = zext i32 %8621 to i64
  store i64 %8622, i64* %R9.i, align 8
  %8623 = icmp ult i32 %8621, %8615
  %8624 = icmp ult i32 %8621, %8620
  %8625 = or i1 %8623, %8624
  %8626 = zext i1 %8625 to i8
  store i8 %8626, i8* %18, align 1
  %8627 = and i32 %8621, 255
  %8628 = tail call i32 @llvm.ctpop.i32(i32 %8627)
  %8629 = trunc i32 %8628 to i8
  %8630 = and i8 %8629, 1
  %8631 = xor i8 %8630, 1
  store i8 %8631, i8* %19, align 1
  %8632 = xor i32 %8620, %8615
  %8633 = xor i32 %8632, %8621
  %8634 = lshr i32 %8633, 4
  %8635 = trunc i32 %8634 to i8
  %8636 = and i8 %8635, 1
  store i8 %8636, i8* %20, align 1
  %8637 = icmp eq i32 %8621, 0
  %8638 = zext i1 %8637 to i8
  store i8 %8638, i8* %21, align 1
  %8639 = lshr i32 %8621, 31
  %8640 = trunc i32 %8639 to i8
  store i8 %8640, i8* %22, align 1
  %8641 = lshr i32 %8615, 31
  %8642 = lshr i32 %8620, 31
  %8643 = xor i32 %8639, %8641
  %8644 = xor i32 %8639, %8642
  %8645 = add nuw nsw i32 %8643, %8644
  %8646 = icmp eq i32 %8645, 2
  %8647 = zext i1 %8646 to i8
  store i8 %8647, i8* %23, align 1
  %8648 = sext i32 %8621 to i64
  store i64 %8648, i64* %RDI.i2141, align 8
  %8649 = shl nsw i64 %8648, 1
  %8650 = add i64 %8584, %8649
  %8651 = add i64 %8501, 97
  store i64 %8651, i64* %3, align 8
  %8652 = inttoptr i64 %8650 to i16*
  %8653 = load i16, i16* %8652, align 2
  %8654 = zext i16 %8653 to i64
  store i64 %8654, i64* %R9.i, align 8
  %8655 = load i32, i32* %R8D.i1718, align 4
  %8656 = zext i16 %8653 to i32
  %8657 = add i32 %8656, %8655
  %8658 = zext i32 %8657 to i64
  store i64 %8658, i64* %26, align 8
  %8659 = lshr i32 %8657, 31
  %8660 = load i32, i32* %ECX.i7699, align 4
  %8661 = sub i32 %8660, %8657
  %8662 = icmp ult i32 %8660, %8657
  %8663 = zext i1 %8662 to i8
  store i8 %8663, i8* %18, align 1
  %8664 = and i32 %8661, 255
  %8665 = tail call i32 @llvm.ctpop.i32(i32 %8664)
  %8666 = trunc i32 %8665 to i8
  %8667 = and i8 %8666, 1
  %8668 = xor i8 %8667, 1
  store i8 %8668, i8* %19, align 1
  %8669 = xor i32 %8657, %8660
  %8670 = xor i32 %8669, %8661
  %8671 = lshr i32 %8670, 4
  %8672 = trunc i32 %8671 to i8
  %8673 = and i8 %8672, 1
  store i8 %8673, i8* %20, align 1
  %8674 = icmp eq i32 %8661, 0
  %8675 = zext i1 %8674 to i8
  store i8 %8675, i8* %21, align 1
  %8676 = lshr i32 %8661, 31
  %8677 = trunc i32 %8676 to i8
  store i8 %8677, i8* %22, align 1
  %8678 = lshr i32 %8660, 31
  %8679 = xor i32 %8659, %8678
  %8680 = xor i32 %8676, %8678
  %8681 = add nuw nsw i32 %8680, %8679
  %8682 = icmp eq i32 %8681, 2
  %8683 = zext i1 %8682 to i8
  store i8 %8683, i8* %23, align 1
  %8684 = load i64, i64* %RBP.i, align 8
  %8685 = add i64 %8684, -1256
  %8686 = load i32, i32* %EAX.i2159, align 4
  %8687 = add i64 %8501, 109
  store i64 %8687, i64* %3, align 8
  %8688 = inttoptr i64 %8685 to i32*
  store i32 %8686, i32* %8688, align 4
  %8689 = load i64, i64* %3, align 8
  %8690 = load i8, i8* %21, align 1
  %8691 = icmp ne i8 %8690, 0
  %8692 = load i8, i8* %22, align 1
  %8693 = icmp ne i8 %8692, 0
  %8694 = load i8, i8* %23, align 1
  %8695 = icmp ne i8 %8694, 0
  %8696 = xor i1 %8693, %8695
  %8697 = or i1 %8691, %8696
  %.v1016 = select i1 %8697, i64 19, i64 6
  %8698 = add i64 %8689, %.v1016
  store i64 %8698, i64* %3, align 8
  br i1 %8697, label %block_.L_4a54a4, label %block_4a5497

block_4a5497:                                     ; preds = %block_.L_4a53ea
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %8699 = load i64, i64* %RBP.i, align 8
  %8700 = add i64 %8699, -1260
  %8701 = add i64 %8698, 8
  store i64 %8701, i64* %3, align 8
  %8702 = inttoptr i64 %8700 to i32*
  store i32 0, i32* %8702, align 4
  %8703 = load i64, i64* %3, align 8
  %8704 = add i64 %8703, 90
  store i64 %8704, i64* %3, align 8
  br label %block_.L_4a54f9

block_.L_4a54a4:                                  ; preds = %block_.L_4a53ea
  %8705 = load i64, i64* %RBP.i, align 8
  %8706 = add i64 %8705, -604
  %8707 = add i64 %8698, 6
  store i64 %8707, i64* %3, align 8
  %8708 = inttoptr i64 %8706 to i32*
  %8709 = load i32, i32* %8708, align 4
  %8710 = zext i32 %8709 to i64
  store i64 %8710, i64* %RAX.i1763, align 8
  %8711 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %8712 = add i64 %8711, 8504
  %8713 = lshr i64 %8712, 63
  %8714 = add i64 %8711, 10552
  store i64 %8714, i64* %RCX.i1692, align 8
  %8715 = icmp ugt i64 %8712, -2049
  %8716 = zext i1 %8715 to i8
  store i8 %8716, i8* %18, align 1
  %8717 = trunc i64 %8714 to i32
  %8718 = and i32 %8717, 255
  %8719 = tail call i32 @llvm.ctpop.i32(i32 %8718)
  %8720 = trunc i32 %8719 to i8
  %8721 = and i8 %8720, 1
  %8722 = xor i8 %8721, 1
  store i8 %8722, i8* %19, align 1
  %8723 = xor i64 %8714, %8712
  %8724 = lshr i64 %8723, 4
  %8725 = trunc i64 %8724 to i8
  %8726 = and i8 %8725, 1
  store i8 %8726, i8* %20, align 1
  %8727 = icmp eq i64 %8714, 0
  %8728 = zext i1 %8727 to i8
  store i8 %8728, i8* %21, align 1
  %8729 = lshr i64 %8714, 63
  %8730 = trunc i64 %8729 to i8
  store i8 %8730, i8* %22, align 1
  %8731 = xor i64 %8729, %8713
  %8732 = add nuw nsw i64 %8731, %8729
  %8733 = icmp eq i64 %8732, 2
  %8734 = zext i1 %8733 to i8
  store i8 %8734, i8* %23, align 1
  %8735 = add i64 %8705, -632
  %8736 = add i64 %8698, 35
  store i64 %8736, i64* %3, align 8
  %8737 = inttoptr i64 %8735 to i32*
  %8738 = load i32, i32* %8737, align 4
  %8739 = sext i32 %8738 to i64
  %8740 = shl nsw i64 %8739, 9
  store i64 %8740, i64* %RDX.i1805, align 8
  %8741 = add i64 %8740, %8714
  store i64 %8741, i64* %RCX.i1692, align 8
  %8742 = icmp ult i64 %8741, %8714
  %8743 = icmp ult i64 %8741, %8740
  %8744 = or i1 %8742, %8743
  %8745 = zext i1 %8744 to i8
  store i8 %8745, i8* %18, align 1
  %8746 = trunc i64 %8741 to i32
  %8747 = and i32 %8746, 255
  %8748 = tail call i32 @llvm.ctpop.i32(i32 %8747)
  %8749 = trunc i32 %8748 to i8
  %8750 = and i8 %8749, 1
  %8751 = xor i8 %8750, 1
  store i8 %8751, i8* %19, align 1
  %8752 = xor i64 %8714, %8741
  %8753 = lshr i64 %8752, 4
  %8754 = trunc i64 %8753 to i8
  %8755 = and i8 %8754, 1
  store i8 %8755, i8* %20, align 1
  %8756 = icmp eq i64 %8741, 0
  %8757 = zext i1 %8756 to i8
  store i8 %8757, i8* %21, align 1
  %8758 = lshr i64 %8741, 63
  %8759 = trunc i64 %8758 to i8
  store i8 %8759, i8* %22, align 1
  %8760 = lshr i64 %8739, 54
  %8761 = and i64 %8760, 1
  %8762 = xor i64 %8758, %8729
  %8763 = xor i64 %8758, %8761
  %8764 = add nuw nsw i64 %8762, %8763
  %8765 = icmp eq i64 %8764, 2
  %8766 = zext i1 %8765 to i8
  store i8 %8766, i8* %23, align 1
  %8767 = load i64, i64* %RBP.i, align 8
  %8768 = add i64 %8767, -484
  %8769 = add i64 %8698, 48
  store i64 %8769, i64* %3, align 8
  %8770 = inttoptr i64 %8768 to i32*
  %8771 = load i32, i32* %8770, align 4
  %8772 = zext i32 %8771 to i64
  store i64 %8772, i64* %RSI.i1889, align 8
  %8773 = add i64 %8767, -44
  %8774 = add i64 %8698, 51
  store i64 %8774, i64* %3, align 8
  %8775 = inttoptr i64 %8773 to i32*
  %8776 = load i32, i32* %8775, align 4
  %8777 = add i32 %8776, %8771
  %8778 = zext i32 %8777 to i64
  store i64 %8778, i64* %RSI.i1889, align 8
  %8779 = sext i32 %8777 to i64
  %8780 = shl nsw i64 %8779, 5
  store i64 %8780, i64* %RDX.i1805, align 8
  %8781 = load i64, i64* %RCX.i1692, align 8
  %8782 = add i64 %8780, %8781
  store i64 %8782, i64* %RCX.i1692, align 8
  %8783 = icmp ult i64 %8782, %8781
  %8784 = icmp ult i64 %8782, %8780
  %8785 = or i1 %8783, %8784
  %8786 = zext i1 %8785 to i8
  store i8 %8786, i8* %18, align 1
  %8787 = trunc i64 %8782 to i32
  %8788 = and i32 %8787, 255
  %8789 = tail call i32 @llvm.ctpop.i32(i32 %8788)
  %8790 = trunc i32 %8789 to i8
  %8791 = and i8 %8790, 1
  %8792 = xor i8 %8791, 1
  store i8 %8792, i8* %19, align 1
  %8793 = xor i64 %8781, %8782
  %8794 = lshr i64 %8793, 4
  %8795 = trunc i64 %8794 to i8
  %8796 = and i8 %8795, 1
  store i8 %8796, i8* %20, align 1
  %8797 = icmp eq i64 %8782, 0
  %8798 = zext i1 %8797 to i8
  store i8 %8798, i8* %21, align 1
  %8799 = lshr i64 %8782, 63
  %8800 = trunc i64 %8799 to i8
  store i8 %8800, i8* %22, align 1
  %8801 = lshr i64 %8781, 63
  %8802 = lshr i64 %8779, 58
  %8803 = and i64 %8802, 1
  %8804 = xor i64 %8799, %8801
  %8805 = xor i64 %8799, %8803
  %8806 = add nuw nsw i64 %8804, %8805
  %8807 = icmp eq i64 %8806, 2
  %8808 = zext i1 %8807 to i8
  store i8 %8808, i8* %23, align 1
  %8809 = load i64, i64* %RBP.i, align 8
  %8810 = add i64 %8809, -488
  %8811 = add i64 %8698, 67
  store i64 %8811, i64* %3, align 8
  %8812 = inttoptr i64 %8810 to i32*
  %8813 = load i32, i32* %8812, align 4
  %8814 = zext i32 %8813 to i64
  store i64 %8814, i64* %RSI.i1889, align 8
  %8815 = add i64 %8809, -48
  %8816 = add i64 %8698, 70
  store i64 %8816, i64* %3, align 8
  %8817 = inttoptr i64 %8815 to i32*
  %8818 = load i32, i32* %8817, align 4
  %8819 = add i32 %8818, %8813
  %8820 = zext i32 %8819 to i64
  store i64 %8820, i64* %RSI.i1889, align 8
  %8821 = icmp ult i32 %8819, %8813
  %8822 = icmp ult i32 %8819, %8818
  %8823 = or i1 %8821, %8822
  %8824 = zext i1 %8823 to i8
  store i8 %8824, i8* %18, align 1
  %8825 = and i32 %8819, 255
  %8826 = tail call i32 @llvm.ctpop.i32(i32 %8825)
  %8827 = trunc i32 %8826 to i8
  %8828 = and i8 %8827, 1
  %8829 = xor i8 %8828, 1
  store i8 %8829, i8* %19, align 1
  %8830 = xor i32 %8818, %8813
  %8831 = xor i32 %8830, %8819
  %8832 = lshr i32 %8831, 4
  %8833 = trunc i32 %8832 to i8
  %8834 = and i8 %8833, 1
  store i8 %8834, i8* %20, align 1
  %8835 = icmp eq i32 %8819, 0
  %8836 = zext i1 %8835 to i8
  store i8 %8836, i8* %21, align 1
  %8837 = lshr i32 %8819, 31
  %8838 = trunc i32 %8837 to i8
  store i8 %8838, i8* %22, align 1
  %8839 = lshr i32 %8813, 31
  %8840 = lshr i32 %8818, 31
  %8841 = xor i32 %8837, %8839
  %8842 = xor i32 %8837, %8840
  %8843 = add nuw nsw i32 %8841, %8842
  %8844 = icmp eq i32 %8843, 2
  %8845 = zext i1 %8844 to i8
  store i8 %8845, i8* %23, align 1
  %8846 = sext i32 %8819 to i64
  store i64 %8846, i64* %RDX.i1805, align 8
  %8847 = shl nsw i64 %8846, 1
  %8848 = add i64 %8782, %8847
  %8849 = add i64 %8698, 77
  store i64 %8849, i64* %3, align 8
  %8850 = inttoptr i64 %8848 to i16*
  %8851 = load i16, i16* %8850, align 2
  %8852 = zext i16 %8851 to i64
  store i64 %8852, i64* %RSI.i1889, align 8
  %8853 = load i64, i64* %RAX.i1763, align 8
  %8854 = zext i16 %8851 to i32
  %8855 = zext i16 %8851 to i64
  %8856 = trunc i64 %8853 to i32
  %8857 = add i32 %8854, %8856
  %8858 = zext i32 %8857 to i64
  store i64 %8858, i64* %RAX.i1763, align 8
  %8859 = icmp ult i32 %8857, %8856
  %8860 = icmp ult i32 %8857, %8854
  %8861 = or i1 %8859, %8860
  %8862 = zext i1 %8861 to i8
  store i8 %8862, i8* %18, align 1
  %8863 = and i32 %8857, 255
  %8864 = tail call i32 @llvm.ctpop.i32(i32 %8863)
  %8865 = trunc i32 %8864 to i8
  %8866 = and i8 %8865, 1
  %8867 = xor i8 %8866, 1
  store i8 %8867, i8* %19, align 1
  %8868 = xor i64 %8855, %8853
  %8869 = trunc i64 %8868 to i32
  %8870 = xor i32 %8869, %8857
  %8871 = lshr i32 %8870, 4
  %8872 = trunc i32 %8871 to i8
  %8873 = and i8 %8872, 1
  store i8 %8873, i8* %20, align 1
  %8874 = icmp eq i32 %8857, 0
  %8875 = zext i1 %8874 to i8
  store i8 %8875, i8* %21, align 1
  %8876 = lshr i32 %8857, 31
  %8877 = trunc i32 %8876 to i8
  store i8 %8877, i8* %22, align 1
  %8878 = lshr i32 %8856, 31
  %8879 = xor i32 %8876, %8878
  %8880 = add nuw nsw i32 %8879, %8876
  %8881 = icmp eq i32 %8880, 2
  %8882 = zext i1 %8881 to i8
  store i8 %8882, i8* %23, align 1
  %8883 = add i64 %8809, -1260
  %8884 = add i64 %8698, 85
  store i64 %8884, i64* %3, align 8
  %8885 = inttoptr i64 %8883 to i32*
  store i32 %8857, i32* %8885, align 4
  %.pre740 = load i64, i64* %3, align 8
  br label %block_.L_4a54f9

block_.L_4a54f9:                                  ; preds = %block_.L_4a54a4, %block_4a5497
  %8886 = phi i64 [ %.pre740, %block_.L_4a54a4 ], [ %8704, %block_4a5497 ]
  %8887 = load i64, i64* %RBP.i, align 8
  %8888 = add i64 %8887, -1260
  %8889 = add i64 %8886, 6
  store i64 %8889, i64* %3, align 8
  %8890 = inttoptr i64 %8888 to i32*
  %8891 = load i32, i32* %8890, align 4
  %8892 = zext i32 %8891 to i64
  store i64 %8892, i64* %RAX.i1763, align 8
  %8893 = add i64 %8887, -1256
  %8894 = add i64 %8886, 12
  store i64 %8894, i64* %3, align 8
  %8895 = inttoptr i64 %8893 to i32*
  %8896 = load i32, i32* %8895, align 4
  %8897 = zext i32 %8896 to i64
  store i64 %8897, i64* %RCX.i1692, align 8
  %8898 = sub i32 %8896, %8891
  %8899 = icmp ult i32 %8896, %8891
  %8900 = zext i1 %8899 to i8
  store i8 %8900, i8* %18, align 1
  %8901 = and i32 %8898, 255
  %8902 = tail call i32 @llvm.ctpop.i32(i32 %8901)
  %8903 = trunc i32 %8902 to i8
  %8904 = and i8 %8903, 1
  %8905 = xor i8 %8904, 1
  store i8 %8905, i8* %19, align 1
  %8906 = xor i32 %8891, %8896
  %8907 = xor i32 %8906, %8898
  %8908 = lshr i32 %8907, 4
  %8909 = trunc i32 %8908 to i8
  %8910 = and i8 %8909, 1
  store i8 %8910, i8* %20, align 1
  %8911 = icmp eq i32 %8898, 0
  %8912 = zext i1 %8911 to i8
  store i8 %8912, i8* %21, align 1
  %8913 = lshr i32 %8898, 31
  %8914 = trunc i32 %8913 to i8
  store i8 %8914, i8* %22, align 1
  %8915 = lshr i32 %8896, 31
  %8916 = lshr i32 %8891, 31
  %8917 = xor i32 %8916, %8915
  %8918 = xor i32 %8913, %8915
  %8919 = add nuw nsw i32 %8918, %8917
  %8920 = icmp eq i32 %8919, 2
  %8921 = zext i1 %8920 to i8
  store i8 %8921, i8* %23, align 1
  %8922 = icmp ne i8 %8914, 0
  %8923 = xor i1 %8922, %8920
  %.v860 = select i1 %8923, i64 20, i64 45
  %8924 = add i64 %8886, %.v860
  store i64 %8924, i64* %3, align 8
  br i1 %8923, label %block_4a550d, label %block_.L_4a5526

block_4a550d:                                     ; preds = %block_.L_4a54f9
  %8925 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8925, i64* %RAX.i1763, align 8
  %8926 = add i64 %8925, 72688
  %8927 = add i64 %8924, 14
  store i64 %8927, i64* %3, align 8
  %8928 = inttoptr i64 %8926 to i32*
  %8929 = load i32, i32* %8928, align 4
  %8930 = zext i32 %8929 to i64
  store i64 %8930, i64* %RCX.i1692, align 8
  %8931 = add i64 %8887, -1264
  %8932 = add i64 %8924, 20
  store i64 %8932, i64* %3, align 8
  %8933 = inttoptr i64 %8931 to i32*
  store i32 %8929, i32* %8933, align 4
  %8934 = load i64, i64* %3, align 8
  %8935 = add i64 %8934, 204
  store i64 %8935, i64* %3, align 8
  br label %block_.L_4a55ed

block_.L_4a5526:                                  ; preds = %block_.L_4a54f9
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %8936 = add i64 %8887, -604
  %8937 = add i64 %8924, 8
  store i64 %8937, i64* %3, align 8
  %8938 = inttoptr i64 %8936 to i32*
  %8939 = load i32, i32* %8938, align 4
  %8940 = zext i32 %8939 to i64
  store i64 %8940, i64* %RCX.i1692, align 8
  %8941 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %8942 = add i64 %8941, 8504
  %8943 = lshr i64 %8942, 63
  %8944 = add i64 %8941, 10552
  store i64 %8944, i64* %RDX.i1805, align 8
  %8945 = icmp ugt i64 %8942, -2049
  %8946 = zext i1 %8945 to i8
  store i8 %8946, i8* %18, align 1
  %8947 = trunc i64 %8944 to i32
  %8948 = and i32 %8947, 255
  %8949 = tail call i32 @llvm.ctpop.i32(i32 %8948)
  %8950 = trunc i32 %8949 to i8
  %8951 = and i8 %8950, 1
  %8952 = xor i8 %8951, 1
  store i8 %8952, i8* %19, align 1
  %8953 = xor i64 %8944, %8942
  %8954 = lshr i64 %8953, 4
  %8955 = trunc i64 %8954 to i8
  %8956 = and i8 %8955, 1
  store i8 %8956, i8* %20, align 1
  %8957 = icmp eq i64 %8944, 0
  %8958 = zext i1 %8957 to i8
  store i8 %8958, i8* %21, align 1
  %8959 = lshr i64 %8944, 63
  %8960 = trunc i64 %8959 to i8
  store i8 %8960, i8* %22, align 1
  %8961 = xor i64 %8959, %8943
  %8962 = add nuw nsw i64 %8961, %8959
  %8963 = icmp eq i64 %8962, 2
  %8964 = zext i1 %8963 to i8
  store i8 %8964, i8* %23, align 1
  %8965 = add i64 %8887, -632
  %8966 = add i64 %8924, 37
  store i64 %8966, i64* %3, align 8
  %8967 = inttoptr i64 %8965 to i32*
  %8968 = load i32, i32* %8967, align 4
  %8969 = sext i32 %8968 to i64
  %8970 = shl nsw i64 %8969, 9
  store i64 %8970, i64* %RSI.i1889, align 8
  %8971 = add i64 %8970, %8944
  store i64 %8971, i64* %RDX.i1805, align 8
  %8972 = icmp ult i64 %8971, %8944
  %8973 = icmp ult i64 %8971, %8970
  %8974 = or i1 %8972, %8973
  %8975 = zext i1 %8974 to i8
  store i8 %8975, i8* %18, align 1
  %8976 = trunc i64 %8971 to i32
  %8977 = and i32 %8976, 255
  %8978 = tail call i32 @llvm.ctpop.i32(i32 %8977)
  %8979 = trunc i32 %8978 to i8
  %8980 = and i8 %8979, 1
  %8981 = xor i8 %8980, 1
  store i8 %8981, i8* %19, align 1
  %8982 = xor i64 %8944, %8971
  %8983 = lshr i64 %8982, 4
  %8984 = trunc i64 %8983 to i8
  %8985 = and i8 %8984, 1
  store i8 %8985, i8* %20, align 1
  %8986 = icmp eq i64 %8971, 0
  %8987 = zext i1 %8986 to i8
  store i8 %8987, i8* %21, align 1
  %8988 = lshr i64 %8971, 63
  %8989 = trunc i64 %8988 to i8
  store i8 %8989, i8* %22, align 1
  %8990 = lshr i64 %8969, 54
  %8991 = and i64 %8990, 1
  %8992 = xor i64 %8988, %8959
  %8993 = xor i64 %8988, %8991
  %8994 = add nuw nsw i64 %8992, %8993
  %8995 = icmp eq i64 %8994, 2
  %8996 = zext i1 %8995 to i8
  store i8 %8996, i8* %23, align 1
  %8997 = load i64, i64* %RBP.i, align 8
  %8998 = add i64 %8997, -484
  %8999 = add i64 %8924, 50
  store i64 %8999, i64* %3, align 8
  %9000 = inttoptr i64 %8998 to i32*
  %9001 = load i32, i32* %9000, align 4
  %9002 = zext i32 %9001 to i64
  store i64 %9002, i64* %RDI.i2141, align 8
  %9003 = add i64 %8997, -44
  %9004 = add i64 %8924, 53
  store i64 %9004, i64* %3, align 8
  %9005 = inttoptr i64 %9003 to i32*
  %9006 = load i32, i32* %9005, align 4
  %9007 = add i32 %9006, %9001
  %9008 = zext i32 %9007 to i64
  store i64 %9008, i64* %RDI.i2141, align 8
  %9009 = sext i32 %9007 to i64
  %9010 = shl nsw i64 %9009, 5
  store i64 %9010, i64* %RSI.i1889, align 8
  %9011 = load i64, i64* %RDX.i1805, align 8
  %9012 = add i64 %9010, %9011
  store i64 %9012, i64* %RDX.i1805, align 8
  %9013 = icmp ult i64 %9012, %9011
  %9014 = icmp ult i64 %9012, %9010
  %9015 = or i1 %9013, %9014
  %9016 = zext i1 %9015 to i8
  store i8 %9016, i8* %18, align 1
  %9017 = trunc i64 %9012 to i32
  %9018 = and i32 %9017, 255
  %9019 = tail call i32 @llvm.ctpop.i32(i32 %9018)
  %9020 = trunc i32 %9019 to i8
  %9021 = and i8 %9020, 1
  %9022 = xor i8 %9021, 1
  store i8 %9022, i8* %19, align 1
  %9023 = xor i64 %9011, %9012
  %9024 = lshr i64 %9023, 4
  %9025 = trunc i64 %9024 to i8
  %9026 = and i8 %9025, 1
  store i8 %9026, i8* %20, align 1
  %9027 = icmp eq i64 %9012, 0
  %9028 = zext i1 %9027 to i8
  store i8 %9028, i8* %21, align 1
  %9029 = lshr i64 %9012, 63
  %9030 = trunc i64 %9029 to i8
  store i8 %9030, i8* %22, align 1
  %9031 = lshr i64 %9011, 63
  %9032 = lshr i64 %9009, 58
  %9033 = and i64 %9032, 1
  %9034 = xor i64 %9029, %9031
  %9035 = xor i64 %9029, %9033
  %9036 = add nuw nsw i64 %9034, %9035
  %9037 = icmp eq i64 %9036, 2
  %9038 = zext i1 %9037 to i8
  store i8 %9038, i8* %23, align 1
  %9039 = load i64, i64* %RBP.i, align 8
  %9040 = add i64 %9039, -488
  %9041 = add i64 %8924, 69
  store i64 %9041, i64* %3, align 8
  %9042 = inttoptr i64 %9040 to i32*
  %9043 = load i32, i32* %9042, align 4
  %9044 = zext i32 %9043 to i64
  store i64 %9044, i64* %RDI.i2141, align 8
  %9045 = add i64 %9039, -48
  %9046 = add i64 %8924, 72
  store i64 %9046, i64* %3, align 8
  %9047 = inttoptr i64 %9045 to i32*
  %9048 = load i32, i32* %9047, align 4
  %9049 = add i32 %9048, %9043
  %9050 = zext i32 %9049 to i64
  store i64 %9050, i64* %RDI.i2141, align 8
  %9051 = icmp ult i32 %9049, %9043
  %9052 = icmp ult i32 %9049, %9048
  %9053 = or i1 %9051, %9052
  %9054 = zext i1 %9053 to i8
  store i8 %9054, i8* %18, align 1
  %9055 = and i32 %9049, 255
  %9056 = tail call i32 @llvm.ctpop.i32(i32 %9055)
  %9057 = trunc i32 %9056 to i8
  %9058 = and i8 %9057, 1
  %9059 = xor i8 %9058, 1
  store i8 %9059, i8* %19, align 1
  %9060 = xor i32 %9048, %9043
  %9061 = xor i32 %9060, %9049
  %9062 = lshr i32 %9061, 4
  %9063 = trunc i32 %9062 to i8
  %9064 = and i8 %9063, 1
  store i8 %9064, i8* %20, align 1
  %9065 = icmp eq i32 %9049, 0
  %9066 = zext i1 %9065 to i8
  store i8 %9066, i8* %21, align 1
  %9067 = lshr i32 %9049, 31
  %9068 = trunc i32 %9067 to i8
  store i8 %9068, i8* %22, align 1
  %9069 = lshr i32 %9043, 31
  %9070 = lshr i32 %9048, 31
  %9071 = xor i32 %9067, %9069
  %9072 = xor i32 %9067, %9070
  %9073 = add nuw nsw i32 %9071, %9072
  %9074 = icmp eq i32 %9073, 2
  %9075 = zext i1 %9074 to i8
  store i8 %9075, i8* %23, align 1
  %9076 = sext i32 %9049 to i64
  store i64 %9076, i64* %RSI.i1889, align 8
  %9077 = shl nsw i64 %9076, 1
  %9078 = add i64 %9012, %9077
  %9079 = add i64 %8924, 79
  store i64 %9079, i64* %3, align 8
  %9080 = inttoptr i64 %9078 to i16*
  %9081 = load i16, i16* %9080, align 2
  %9082 = zext i16 %9081 to i64
  store i64 %9082, i64* %RDI.i2141, align 8
  %9083 = load i64, i64* %RCX.i1692, align 8
  %9084 = zext i16 %9081 to i32
  %9085 = trunc i64 %9083 to i32
  %9086 = add i32 %9084, %9085
  %9087 = zext i32 %9086 to i64
  store i64 %9087, i64* %RCX.i1692, align 8
  %9088 = lshr i32 %9086, 31
  %9089 = load i32, i32* %EAX.i2159, align 4
  %9090 = sub i32 %9089, %9086
  %9091 = icmp ult i32 %9089, %9086
  %9092 = zext i1 %9091 to i8
  store i8 %9092, i8* %18, align 1
  %9093 = and i32 %9090, 255
  %9094 = tail call i32 @llvm.ctpop.i32(i32 %9093)
  %9095 = trunc i32 %9094 to i8
  %9096 = and i8 %9095, 1
  %9097 = xor i8 %9096, 1
  store i8 %9097, i8* %19, align 1
  %9098 = xor i32 %9086, %9089
  %9099 = xor i32 %9098, %9090
  %9100 = lshr i32 %9099, 4
  %9101 = trunc i32 %9100 to i8
  %9102 = and i8 %9101, 1
  store i8 %9102, i8* %20, align 1
  %9103 = icmp eq i32 %9090, 0
  %9104 = zext i1 %9103 to i8
  store i8 %9104, i8* %21, align 1
  %9105 = lshr i32 %9090, 31
  %9106 = trunc i32 %9105 to i8
  store i8 %9106, i8* %22, align 1
  %9107 = lshr i32 %9089, 31
  %9108 = xor i32 %9088, %9107
  %9109 = xor i32 %9105, %9107
  %9110 = add nuw nsw i32 %9109, %9108
  %9111 = icmp eq i32 %9110, 2
  %9112 = zext i1 %9111 to i8
  store i8 %9112, i8* %23, align 1
  %9113 = icmp ne i8 %9106, 0
  %9114 = xor i1 %9113, %9111
  %9115 = or i1 %9103, %9114
  %.v861 = select i1 %9115, i64 102, i64 89
  %9116 = add i64 %8924, %.v861
  store i64 %9116, i64* %3, align 8
  br i1 %9115, label %block_.L_4a558c, label %block_4a557f

block_4a557f:                                     ; preds = %block_.L_4a5526
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %9117 = load i64, i64* %RBP.i, align 8
  %9118 = add i64 %9117, -1268
  %9119 = add i64 %9116, 8
  store i64 %9119, i64* %3, align 8
  %9120 = inttoptr i64 %9118 to i32*
  store i32 0, i32* %9120, align 4
  %9121 = load i64, i64* %3, align 8
  %9122 = add i64 %9121, 90
  store i64 %9122, i64* %3, align 8
  br label %block_.L_4a55e1

block_.L_4a558c:                                  ; preds = %block_.L_4a5526
  %9123 = load i64, i64* %RBP.i, align 8
  %9124 = add i64 %9123, -604
  %9125 = add i64 %9116, 6
  store i64 %9125, i64* %3, align 8
  %9126 = inttoptr i64 %9124 to i32*
  %9127 = load i32, i32* %9126, align 4
  %9128 = zext i32 %9127 to i64
  store i64 %9128, i64* %RAX.i1763, align 8
  %9129 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %9130 = add i64 %9129, 8504
  %9131 = lshr i64 %9130, 63
  %9132 = add i64 %9129, 10552
  store i64 %9132, i64* %RCX.i1692, align 8
  %9133 = icmp ugt i64 %9130, -2049
  %9134 = zext i1 %9133 to i8
  store i8 %9134, i8* %18, align 1
  %9135 = trunc i64 %9132 to i32
  %9136 = and i32 %9135, 255
  %9137 = tail call i32 @llvm.ctpop.i32(i32 %9136)
  %9138 = trunc i32 %9137 to i8
  %9139 = and i8 %9138, 1
  %9140 = xor i8 %9139, 1
  store i8 %9140, i8* %19, align 1
  %9141 = xor i64 %9132, %9130
  %9142 = lshr i64 %9141, 4
  %9143 = trunc i64 %9142 to i8
  %9144 = and i8 %9143, 1
  store i8 %9144, i8* %20, align 1
  %9145 = icmp eq i64 %9132, 0
  %9146 = zext i1 %9145 to i8
  store i8 %9146, i8* %21, align 1
  %9147 = lshr i64 %9132, 63
  %9148 = trunc i64 %9147 to i8
  store i8 %9148, i8* %22, align 1
  %9149 = xor i64 %9147, %9131
  %9150 = add nuw nsw i64 %9149, %9147
  %9151 = icmp eq i64 %9150, 2
  %9152 = zext i1 %9151 to i8
  store i8 %9152, i8* %23, align 1
  %9153 = add i64 %9123, -632
  %9154 = add i64 %9116, 35
  store i64 %9154, i64* %3, align 8
  %9155 = inttoptr i64 %9153 to i32*
  %9156 = load i32, i32* %9155, align 4
  %9157 = sext i32 %9156 to i64
  %9158 = shl nsw i64 %9157, 9
  store i64 %9158, i64* %RDX.i1805, align 8
  %9159 = add i64 %9158, %9132
  store i64 %9159, i64* %RCX.i1692, align 8
  %9160 = icmp ult i64 %9159, %9132
  %9161 = icmp ult i64 %9159, %9158
  %9162 = or i1 %9160, %9161
  %9163 = zext i1 %9162 to i8
  store i8 %9163, i8* %18, align 1
  %9164 = trunc i64 %9159 to i32
  %9165 = and i32 %9164, 255
  %9166 = tail call i32 @llvm.ctpop.i32(i32 %9165)
  %9167 = trunc i32 %9166 to i8
  %9168 = and i8 %9167, 1
  %9169 = xor i8 %9168, 1
  store i8 %9169, i8* %19, align 1
  %9170 = xor i64 %9132, %9159
  %9171 = lshr i64 %9170, 4
  %9172 = trunc i64 %9171 to i8
  %9173 = and i8 %9172, 1
  store i8 %9173, i8* %20, align 1
  %9174 = icmp eq i64 %9159, 0
  %9175 = zext i1 %9174 to i8
  store i8 %9175, i8* %21, align 1
  %9176 = lshr i64 %9159, 63
  %9177 = trunc i64 %9176 to i8
  store i8 %9177, i8* %22, align 1
  %9178 = lshr i64 %9157, 54
  %9179 = and i64 %9178, 1
  %9180 = xor i64 %9176, %9147
  %9181 = xor i64 %9176, %9179
  %9182 = add nuw nsw i64 %9180, %9181
  %9183 = icmp eq i64 %9182, 2
  %9184 = zext i1 %9183 to i8
  store i8 %9184, i8* %23, align 1
  %9185 = load i64, i64* %RBP.i, align 8
  %9186 = add i64 %9185, -484
  %9187 = add i64 %9116, 48
  store i64 %9187, i64* %3, align 8
  %9188 = inttoptr i64 %9186 to i32*
  %9189 = load i32, i32* %9188, align 4
  %9190 = zext i32 %9189 to i64
  store i64 %9190, i64* %RSI.i1889, align 8
  %9191 = add i64 %9185, -44
  %9192 = add i64 %9116, 51
  store i64 %9192, i64* %3, align 8
  %9193 = inttoptr i64 %9191 to i32*
  %9194 = load i32, i32* %9193, align 4
  %9195 = add i32 %9194, %9189
  %9196 = zext i32 %9195 to i64
  store i64 %9196, i64* %RSI.i1889, align 8
  %9197 = sext i32 %9195 to i64
  %9198 = shl nsw i64 %9197, 5
  store i64 %9198, i64* %RDX.i1805, align 8
  %9199 = load i64, i64* %RCX.i1692, align 8
  %9200 = add i64 %9198, %9199
  store i64 %9200, i64* %RCX.i1692, align 8
  %9201 = icmp ult i64 %9200, %9199
  %9202 = icmp ult i64 %9200, %9198
  %9203 = or i1 %9201, %9202
  %9204 = zext i1 %9203 to i8
  store i8 %9204, i8* %18, align 1
  %9205 = trunc i64 %9200 to i32
  %9206 = and i32 %9205, 255
  %9207 = tail call i32 @llvm.ctpop.i32(i32 %9206)
  %9208 = trunc i32 %9207 to i8
  %9209 = and i8 %9208, 1
  %9210 = xor i8 %9209, 1
  store i8 %9210, i8* %19, align 1
  %9211 = xor i64 %9199, %9200
  %9212 = lshr i64 %9211, 4
  %9213 = trunc i64 %9212 to i8
  %9214 = and i8 %9213, 1
  store i8 %9214, i8* %20, align 1
  %9215 = icmp eq i64 %9200, 0
  %9216 = zext i1 %9215 to i8
  store i8 %9216, i8* %21, align 1
  %9217 = lshr i64 %9200, 63
  %9218 = trunc i64 %9217 to i8
  store i8 %9218, i8* %22, align 1
  %9219 = lshr i64 %9199, 63
  %9220 = lshr i64 %9197, 58
  %9221 = and i64 %9220, 1
  %9222 = xor i64 %9217, %9219
  %9223 = xor i64 %9217, %9221
  %9224 = add nuw nsw i64 %9222, %9223
  %9225 = icmp eq i64 %9224, 2
  %9226 = zext i1 %9225 to i8
  store i8 %9226, i8* %23, align 1
  %9227 = load i64, i64* %RBP.i, align 8
  %9228 = add i64 %9227, -488
  %9229 = add i64 %9116, 67
  store i64 %9229, i64* %3, align 8
  %9230 = inttoptr i64 %9228 to i32*
  %9231 = load i32, i32* %9230, align 4
  %9232 = zext i32 %9231 to i64
  store i64 %9232, i64* %RSI.i1889, align 8
  %9233 = add i64 %9227, -48
  %9234 = add i64 %9116, 70
  store i64 %9234, i64* %3, align 8
  %9235 = inttoptr i64 %9233 to i32*
  %9236 = load i32, i32* %9235, align 4
  %9237 = add i32 %9236, %9231
  %9238 = zext i32 %9237 to i64
  store i64 %9238, i64* %RSI.i1889, align 8
  %9239 = icmp ult i32 %9237, %9231
  %9240 = icmp ult i32 %9237, %9236
  %9241 = or i1 %9239, %9240
  %9242 = zext i1 %9241 to i8
  store i8 %9242, i8* %18, align 1
  %9243 = and i32 %9237, 255
  %9244 = tail call i32 @llvm.ctpop.i32(i32 %9243)
  %9245 = trunc i32 %9244 to i8
  %9246 = and i8 %9245, 1
  %9247 = xor i8 %9246, 1
  store i8 %9247, i8* %19, align 1
  %9248 = xor i32 %9236, %9231
  %9249 = xor i32 %9248, %9237
  %9250 = lshr i32 %9249, 4
  %9251 = trunc i32 %9250 to i8
  %9252 = and i8 %9251, 1
  store i8 %9252, i8* %20, align 1
  %9253 = icmp eq i32 %9237, 0
  %9254 = zext i1 %9253 to i8
  store i8 %9254, i8* %21, align 1
  %9255 = lshr i32 %9237, 31
  %9256 = trunc i32 %9255 to i8
  store i8 %9256, i8* %22, align 1
  %9257 = lshr i32 %9231, 31
  %9258 = lshr i32 %9236, 31
  %9259 = xor i32 %9255, %9257
  %9260 = xor i32 %9255, %9258
  %9261 = add nuw nsw i32 %9259, %9260
  %9262 = icmp eq i32 %9261, 2
  %9263 = zext i1 %9262 to i8
  store i8 %9263, i8* %23, align 1
  %9264 = sext i32 %9237 to i64
  store i64 %9264, i64* %RDX.i1805, align 8
  %9265 = shl nsw i64 %9264, 1
  %9266 = add i64 %9200, %9265
  %9267 = add i64 %9116, 77
  store i64 %9267, i64* %3, align 8
  %9268 = inttoptr i64 %9266 to i16*
  %9269 = load i16, i16* %9268, align 2
  %9270 = zext i16 %9269 to i64
  store i64 %9270, i64* %RSI.i1889, align 8
  %9271 = load i64, i64* %RAX.i1763, align 8
  %9272 = zext i16 %9269 to i32
  %9273 = zext i16 %9269 to i64
  %9274 = trunc i64 %9271 to i32
  %9275 = add i32 %9272, %9274
  %9276 = zext i32 %9275 to i64
  store i64 %9276, i64* %RAX.i1763, align 8
  %9277 = icmp ult i32 %9275, %9274
  %9278 = icmp ult i32 %9275, %9272
  %9279 = or i1 %9277, %9278
  %9280 = zext i1 %9279 to i8
  store i8 %9280, i8* %18, align 1
  %9281 = and i32 %9275, 255
  %9282 = tail call i32 @llvm.ctpop.i32(i32 %9281)
  %9283 = trunc i32 %9282 to i8
  %9284 = and i8 %9283, 1
  %9285 = xor i8 %9284, 1
  store i8 %9285, i8* %19, align 1
  %9286 = xor i64 %9273, %9271
  %9287 = trunc i64 %9286 to i32
  %9288 = xor i32 %9287, %9275
  %9289 = lshr i32 %9288, 4
  %9290 = trunc i32 %9289 to i8
  %9291 = and i8 %9290, 1
  store i8 %9291, i8* %20, align 1
  %9292 = icmp eq i32 %9275, 0
  %9293 = zext i1 %9292 to i8
  store i8 %9293, i8* %21, align 1
  %9294 = lshr i32 %9275, 31
  %9295 = trunc i32 %9294 to i8
  store i8 %9295, i8* %22, align 1
  %9296 = lshr i32 %9274, 31
  %9297 = xor i32 %9294, %9296
  %9298 = add nuw nsw i32 %9297, %9294
  %9299 = icmp eq i32 %9298, 2
  %9300 = zext i1 %9299 to i8
  store i8 %9300, i8* %23, align 1
  %9301 = add i64 %9227, -1268
  %9302 = add i64 %9116, 85
  store i64 %9302, i64* %3, align 8
  %9303 = inttoptr i64 %9301 to i32*
  store i32 %9275, i32* %9303, align 4
  %.pre741 = load i64, i64* %3, align 8
  br label %block_.L_4a55e1

block_.L_4a55e1:                                  ; preds = %block_.L_4a558c, %block_4a557f
  %9304 = phi i64 [ %.pre741, %block_.L_4a558c ], [ %9122, %block_4a557f ]
  %9305 = load i64, i64* %RBP.i, align 8
  %9306 = add i64 %9305, -1268
  %9307 = add i64 %9304, 6
  store i64 %9307, i64* %3, align 8
  %9308 = inttoptr i64 %9306 to i32*
  %9309 = load i32, i32* %9308, align 4
  %9310 = zext i32 %9309 to i64
  store i64 %9310, i64* %RAX.i1763, align 8
  %9311 = add i64 %9305, -1264
  %9312 = add i64 %9304, 12
  store i64 %9312, i64* %3, align 8
  %9313 = inttoptr i64 %9311 to i32*
  store i32 %9309, i32* %9313, align 4
  %.pre742 = load i64, i64* %3, align 8
  br label %block_.L_4a55ed

block_.L_4a55ed:                                  ; preds = %block_.L_4a55e1, %block_4a550d
  %9314 = phi i64 [ %.pre742, %block_.L_4a55e1 ], [ %8935, %block_4a550d ]
  %9315 = load i64, i64* %RBP.i, align 8
  %9316 = add i64 %9315, -1264
  %9317 = add i64 %9314, 6
  store i64 %9317, i64* %3, align 8
  %9318 = inttoptr i64 %9316 to i32*
  %9319 = load i32, i32* %9318, align 4
  %9320 = zext i32 %9319 to i64
  store i64 %9320, i64* %RAX.i1763, align 8
  %9321 = trunc i32 %9319 to i16
  store i16 %9321, i16* %CX.i4894, align 2
  %9322 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9322, i64* %RDX.i1805, align 8
  %9323 = add i64 %9322, 6464
  %9324 = add i64 %9314, 24
  store i64 %9324, i64* %3, align 8
  %9325 = inttoptr i64 %9323 to i64*
  %9326 = load i64, i64* %9325, align 8
  store i64 %9326, i64* %RDX.i1805, align 8
  %9327 = add i64 %9326, 8
  %9328 = add i64 %9314, 28
  store i64 %9328, i64* %3, align 8
  %9329 = inttoptr i64 %9327 to i64*
  %9330 = load i64, i64* %9329, align 8
  store i64 %9330, i64* %RDX.i1805, align 8
  %9331 = add i64 %9315, -496
  %9332 = add i64 %9314, 34
  store i64 %9332, i64* %3, align 8
  %9333 = inttoptr i64 %9331 to i32*
  %9334 = load i32, i32* %9333, align 4
  %9335 = zext i32 %9334 to i64
  store i64 %9335, i64* %RAX.i1763, align 8
  %9336 = add i64 %9315, -48
  %9337 = add i64 %9314, 37
  store i64 %9337, i64* %3, align 8
  %9338 = inttoptr i64 %9336 to i32*
  %9339 = load i32, i32* %9338, align 4
  %9340 = add i32 %9339, %9334
  %9341 = zext i32 %9340 to i64
  store i64 %9341, i64* %RAX.i1763, align 8
  %9342 = icmp ult i32 %9340, %9334
  %9343 = icmp ult i32 %9340, %9339
  %9344 = or i1 %9342, %9343
  %9345 = zext i1 %9344 to i8
  store i8 %9345, i8* %18, align 1
  %9346 = and i32 %9340, 255
  %9347 = tail call i32 @llvm.ctpop.i32(i32 %9346)
  %9348 = trunc i32 %9347 to i8
  %9349 = and i8 %9348, 1
  %9350 = xor i8 %9349, 1
  store i8 %9350, i8* %19, align 1
  %9351 = xor i32 %9339, %9334
  %9352 = xor i32 %9351, %9340
  %9353 = lshr i32 %9352, 4
  %9354 = trunc i32 %9353 to i8
  %9355 = and i8 %9354, 1
  store i8 %9355, i8* %20, align 1
  %9356 = icmp eq i32 %9340, 0
  %9357 = zext i1 %9356 to i8
  store i8 %9357, i8* %21, align 1
  %9358 = lshr i32 %9340, 31
  %9359 = trunc i32 %9358 to i8
  store i8 %9359, i8* %22, align 1
  %9360 = lshr i32 %9334, 31
  %9361 = lshr i32 %9339, 31
  %9362 = xor i32 %9358, %9360
  %9363 = xor i32 %9358, %9361
  %9364 = add nuw nsw i32 %9362, %9363
  %9365 = icmp eq i32 %9364, 2
  %9366 = zext i1 %9365 to i8
  store i8 %9366, i8* %23, align 1
  %9367 = sext i32 %9340 to i64
  store i64 %9367, i64* %RSI.i1889, align 8
  %9368 = shl nsw i64 %9367, 3
  %9369 = add i64 %9330, %9368
  %9370 = add i64 %9314, 44
  store i64 %9370, i64* %3, align 8
  %9371 = inttoptr i64 %9369 to i64*
  %9372 = load i64, i64* %9371, align 8
  store i64 %9372, i64* %RDX.i1805, align 8
  %9373 = add i64 %9315, -492
  %9374 = add i64 %9314, 50
  store i64 %9374, i64* %3, align 8
  %9375 = inttoptr i64 %9373 to i32*
  %9376 = load i32, i32* %9375, align 4
  %9377 = zext i32 %9376 to i64
  store i64 %9377, i64* %RAX.i1763, align 8
  %9378 = add i64 %9315, -44
  %9379 = add i64 %9314, 53
  store i64 %9379, i64* %3, align 8
  %9380 = inttoptr i64 %9378 to i32*
  %9381 = load i32, i32* %9380, align 4
  %9382 = add i32 %9381, %9376
  %9383 = zext i32 %9382 to i64
  store i64 %9383, i64* %RAX.i1763, align 8
  %9384 = icmp ult i32 %9382, %9376
  %9385 = icmp ult i32 %9382, %9381
  %9386 = or i1 %9384, %9385
  %9387 = zext i1 %9386 to i8
  store i8 %9387, i8* %18, align 1
  %9388 = and i32 %9382, 255
  %9389 = tail call i32 @llvm.ctpop.i32(i32 %9388)
  %9390 = trunc i32 %9389 to i8
  %9391 = and i8 %9390, 1
  %9392 = xor i8 %9391, 1
  store i8 %9392, i8* %19, align 1
  %9393 = xor i32 %9381, %9376
  %9394 = xor i32 %9393, %9382
  %9395 = lshr i32 %9394, 4
  %9396 = trunc i32 %9395 to i8
  %9397 = and i8 %9396, 1
  store i8 %9397, i8* %20, align 1
  %9398 = icmp eq i32 %9382, 0
  %9399 = zext i1 %9398 to i8
  store i8 %9399, i8* %21, align 1
  %9400 = lshr i32 %9382, 31
  %9401 = trunc i32 %9400 to i8
  store i8 %9401, i8* %22, align 1
  %9402 = lshr i32 %9376, 31
  %9403 = lshr i32 %9381, 31
  %9404 = xor i32 %9400, %9402
  %9405 = xor i32 %9400, %9403
  %9406 = add nuw nsw i32 %9404, %9405
  %9407 = icmp eq i32 %9406, 2
  %9408 = zext i1 %9407 to i8
  store i8 %9408, i8* %23, align 1
  %9409 = sext i32 %9382 to i64
  store i64 %9409, i64* %RSI.i1889, align 8
  %9410 = shl nsw i64 %9409, 1
  %9411 = add i64 %9372, %9410
  %9412 = load i16, i16* %CX.i4894, align 2
  %9413 = add i64 %9314, 60
  store i64 %9413, i64* %3, align 8
  %9414 = inttoptr i64 %9411 to i16*
  store i16 %9412, i16* %9414, align 2
  %9415 = load i64, i64* %RBP.i, align 8
  %9416 = add i64 %9415, -44
  %9417 = load i64, i64* %3, align 8
  %9418 = add i64 %9417, 3
  store i64 %9418, i64* %3, align 8
  %9419 = inttoptr i64 %9416 to i32*
  %9420 = load i32, i32* %9419, align 4
  %9421 = add i32 %9420, 1
  %9422 = zext i32 %9421 to i64
  store i64 %9422, i64* %RAX.i1763, align 8
  %9423 = icmp eq i32 %9420, -1
  %9424 = icmp eq i32 %9421, 0
  %9425 = or i1 %9423, %9424
  %9426 = zext i1 %9425 to i8
  store i8 %9426, i8* %18, align 1
  %9427 = and i32 %9421, 255
  %9428 = tail call i32 @llvm.ctpop.i32(i32 %9427)
  %9429 = trunc i32 %9428 to i8
  %9430 = and i8 %9429, 1
  %9431 = xor i8 %9430, 1
  store i8 %9431, i8* %19, align 1
  %9432 = xor i32 %9421, %9420
  %9433 = lshr i32 %9432, 4
  %9434 = trunc i32 %9433 to i8
  %9435 = and i8 %9434, 1
  store i8 %9435, i8* %20, align 1
  %9436 = zext i1 %9424 to i8
  store i8 %9436, i8* %21, align 1
  %9437 = lshr i32 %9421, 31
  %9438 = trunc i32 %9437 to i8
  store i8 %9438, i8* %22, align 1
  %9439 = lshr i32 %9420, 31
  %9440 = xor i32 %9437, %9439
  %9441 = add nuw nsw i32 %9440, %9437
  %9442 = icmp eq i32 %9441, 2
  %9443 = zext i1 %9442 to i8
  store i8 %9443, i8* %23, align 1
  %9444 = add i64 %9417, 9
  store i64 %9444, i64* %3, align 8
  store i32 %9421, i32* %9419, align 4
  %9445 = load i64, i64* %3, align 8
  %9446 = add i64 %9445, -1631
  store i64 %9446, i64* %3, align 8
  br label %block_.L_4a4fd3

block_.L_4a5637:                                  ; preds = %block_.L_4a4fd3
  %9447 = add i64 %6434, -48
  %9448 = add i64 %6462, 8
  store i64 %9448, i64* %3, align 8
  %9449 = inttoptr i64 %9447 to i32*
  %9450 = load i32, i32* %9449, align 4
  %9451 = add i32 %9450, 1
  %9452 = zext i32 %9451 to i64
  store i64 %9452, i64* %RAX.i1763, align 8
  %9453 = icmp eq i32 %9450, -1
  %9454 = icmp eq i32 %9451, 0
  %9455 = or i1 %9453, %9454
  %9456 = zext i1 %9455 to i8
  store i8 %9456, i8* %18, align 1
  %9457 = and i32 %9451, 255
  %9458 = tail call i32 @llvm.ctpop.i32(i32 %9457)
  %9459 = trunc i32 %9458 to i8
  %9460 = and i8 %9459, 1
  %9461 = xor i8 %9460, 1
  store i8 %9461, i8* %19, align 1
  %9462 = xor i32 %9451, %9450
  %9463 = lshr i32 %9462, 4
  %9464 = trunc i32 %9463 to i8
  %9465 = and i8 %9464, 1
  store i8 %9465, i8* %20, align 1
  %9466 = zext i1 %9454 to i8
  store i8 %9466, i8* %21, align 1
  %9467 = lshr i32 %9451, 31
  %9468 = trunc i32 %9467 to i8
  store i8 %9468, i8* %22, align 1
  %9469 = lshr i32 %9450, 31
  %9470 = xor i32 %9467, %9469
  %9471 = add nuw nsw i32 %9470, %9467
  %9472 = icmp eq i32 %9471, 2
  %9473 = zext i1 %9472 to i8
  store i8 %9473, i8* %23, align 1
  %9474 = add i64 %6462, 14
  store i64 %9474, i64* %3, align 8
  store i32 %9451, i32* %9449, align 4
  %9475 = load i64, i64* %3, align 8
  %9476 = add i64 %9475, -1667
  store i64 %9476, i64* %3, align 8
  br label %block_.L_4a4fc2

block_.L_4a564a:                                  ; preds = %block_.L_4a4fc2
  %9477 = add i64 %6401, -620
  %9478 = add i64 %6429, 10
  store i64 %9478, i64* %3, align 8
  %9479 = inttoptr i64 %9477 to i32*
  store i32 0, i32* %9479, align 4
  %9480 = load i64, i64* %RBP.i, align 8
  %9481 = add i64 %9480, -60
  %9482 = load i64, i64* %3, align 8
  %9483 = add i64 %9482, 7
  store i64 %9483, i64* %3, align 8
  %9484 = inttoptr i64 %9481 to i32*
  store i32 0, i32* %9484, align 4
  %.pre672 = load i64, i64* %3, align 8
  br label %block_.L_4a565b

block_.L_4a565b:                                  ; preds = %block_.L_4a588f, %block_.L_4a564a
  %9485 = phi i64 [ %10545, %block_.L_4a588f ], [ %.pre672, %block_.L_4a564a ]
  %9486 = load i64, i64* %RBP.i, align 8
  %9487 = add i64 %9486, -60
  %9488 = add i64 %9485, 4
  store i64 %9488, i64* %3, align 8
  %9489 = inttoptr i64 %9487 to i32*
  %9490 = load i32, i32* %9489, align 4
  %9491 = add i32 %9490, -8
  %9492 = icmp ult i32 %9490, 8
  %9493 = zext i1 %9492 to i8
  store i8 %9493, i8* %18, align 1
  %9494 = and i32 %9491, 255
  %9495 = tail call i32 @llvm.ctpop.i32(i32 %9494)
  %9496 = trunc i32 %9495 to i8
  %9497 = and i8 %9496, 1
  %9498 = xor i8 %9497, 1
  store i8 %9498, i8* %19, align 1
  %9499 = xor i32 %9491, %9490
  %9500 = lshr i32 %9499, 4
  %9501 = trunc i32 %9500 to i8
  %9502 = and i8 %9501, 1
  store i8 %9502, i8* %20, align 1
  %9503 = icmp eq i32 %9491, 0
  %9504 = zext i1 %9503 to i8
  store i8 %9504, i8* %21, align 1
  %9505 = lshr i32 %9491, 31
  %9506 = trunc i32 %9505 to i8
  store i8 %9506, i8* %22, align 1
  %9507 = lshr i32 %9490, 31
  %9508 = xor i32 %9505, %9507
  %9509 = add nuw nsw i32 %9508, %9507
  %9510 = icmp eq i32 %9509, 2
  %9511 = zext i1 %9510 to i8
  store i8 %9511, i8* %23, align 1
  %9512 = icmp ne i8 %9506, 0
  %9513 = xor i1 %9512, %9510
  %.v850 = select i1 %9513, i64 10, i64 583
  %9514 = add i64 %9485, %.v850
  store i64 %9514, i64* %3, align 8
  br i1 %9513, label %block_4a5665, label %block_.L_4a58a2

block_4a5665:                                     ; preds = %block_.L_4a565b
  %9515 = add i64 %9486, -492
  %9516 = add i64 %9514, 6
  store i64 %9516, i64* %3, align 8
  %9517 = inttoptr i64 %9515 to i32*
  %9518 = load i32, i32* %9517, align 4
  %9519 = zext i32 %9518 to i64
  store i64 %9519, i64* %RAX.i1763, align 8
  %9520 = add i64 %9486, -56
  %9521 = add i64 %9514, 9
  store i64 %9521, i64* %3, align 8
  %9522 = inttoptr i64 %9520 to i32*
  store i32 %9518, i32* %9522, align 4
  %.pre732 = load i64, i64* %3, align 8
  br label %block_.L_4a566e

block_.L_4a566e:                                  ; preds = %block_4a5682, %block_4a5665
  %9523 = phi i64 [ %10515, %block_4a5682 ], [ %.pre732, %block_4a5665 ]
  %9524 = load i64, i64* %RBP.i, align 8
  %9525 = add i64 %9524, -56
  %9526 = add i64 %9523, 3
  store i64 %9526, i64* %3, align 8
  %9527 = inttoptr i64 %9525 to i32*
  %9528 = load i32, i32* %9527, align 4
  %9529 = zext i32 %9528 to i64
  store i64 %9529, i64* %RAX.i1763, align 8
  %9530 = add i64 %9524, -492
  %9531 = add i64 %9523, 9
  store i64 %9531, i64* %3, align 8
  %9532 = inttoptr i64 %9530 to i32*
  %9533 = load i32, i32* %9532, align 4
  %9534 = add i32 %9533, 8
  %9535 = zext i32 %9534 to i64
  store i64 %9535, i64* %RCX.i1692, align 8
  %9536 = lshr i32 %9534, 31
  %9537 = sub i32 %9528, %9534
  %9538 = icmp ult i32 %9528, %9534
  %9539 = zext i1 %9538 to i8
  store i8 %9539, i8* %18, align 1
  %9540 = and i32 %9537, 255
  %9541 = tail call i32 @llvm.ctpop.i32(i32 %9540)
  %9542 = trunc i32 %9541 to i8
  %9543 = and i8 %9542, 1
  %9544 = xor i8 %9543, 1
  store i8 %9544, i8* %19, align 1
  %9545 = xor i32 %9534, %9528
  %9546 = xor i32 %9545, %9537
  %9547 = lshr i32 %9546, 4
  %9548 = trunc i32 %9547 to i8
  %9549 = and i8 %9548, 1
  store i8 %9549, i8* %20, align 1
  %9550 = icmp eq i32 %9537, 0
  %9551 = zext i1 %9550 to i8
  store i8 %9551, i8* %21, align 1
  %9552 = lshr i32 %9537, 31
  %9553 = trunc i32 %9552 to i8
  store i8 %9553, i8* %22, align 1
  %9554 = lshr i32 %9528, 31
  %9555 = xor i32 %9536, %9554
  %9556 = xor i32 %9552, %9554
  %9557 = add nuw nsw i32 %9556, %9555
  %9558 = icmp eq i32 %9557, 2
  %9559 = zext i1 %9558 to i8
  store i8 %9559, i8* %23, align 1
  %9560 = icmp ne i8 %9553, 0
  %9561 = xor i1 %9560, %9558
  %.v800 = select i1 %9561, i64 20, i64 545
  %9562 = add i64 %9523, %.v800
  store i64 %9562, i64* %3, align 8
  br i1 %9561, label %block_4a5682, label %block_.L_4a588f

block_4a5682:                                     ; preds = %block_.L_4a566e
  %9563 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %9563, i64* %RAX.i1763, align 8
  %9564 = add i64 %9524, -496
  %9565 = add i64 %9562, 14
  store i64 %9565, i64* %3, align 8
  %9566 = inttoptr i64 %9564 to i32*
  %9567 = load i32, i32* %9566, align 4
  %9568 = zext i32 %9567 to i64
  store i64 %9568, i64* %RCX.i1692, align 8
  %9569 = add i64 %9524, -60
  %9570 = add i64 %9562, 17
  store i64 %9570, i64* %3, align 8
  %9571 = inttoptr i64 %9569 to i32*
  %9572 = load i32, i32* %9571, align 4
  %9573 = add i32 %9572, %9567
  %9574 = zext i32 %9573 to i64
  store i64 %9574, i64* %RCX.i1692, align 8
  %9575 = icmp ult i32 %9573, %9567
  %9576 = icmp ult i32 %9573, %9572
  %9577 = or i1 %9575, %9576
  %9578 = zext i1 %9577 to i8
  store i8 %9578, i8* %18, align 1
  %9579 = and i32 %9573, 255
  %9580 = tail call i32 @llvm.ctpop.i32(i32 %9579)
  %9581 = trunc i32 %9580 to i8
  %9582 = and i8 %9581, 1
  %9583 = xor i8 %9582, 1
  store i8 %9583, i8* %19, align 1
  %9584 = xor i32 %9572, %9567
  %9585 = xor i32 %9584, %9573
  %9586 = lshr i32 %9585, 4
  %9587 = trunc i32 %9586 to i8
  %9588 = and i8 %9587, 1
  store i8 %9588, i8* %20, align 1
  %9589 = icmp eq i32 %9573, 0
  %9590 = zext i1 %9589 to i8
  store i8 %9590, i8* %21, align 1
  %9591 = lshr i32 %9573, 31
  %9592 = trunc i32 %9591 to i8
  store i8 %9592, i8* %22, align 1
  %9593 = lshr i32 %9567, 31
  %9594 = lshr i32 %9572, 31
  %9595 = xor i32 %9591, %9593
  %9596 = xor i32 %9591, %9594
  %9597 = add nuw nsw i32 %9595, %9596
  %9598 = icmp eq i32 %9597, 2
  %9599 = zext i1 %9598 to i8
  store i8 %9599, i8* %23, align 1
  %9600 = sext i32 %9573 to i64
  store i64 %9600, i64* %RDX.i1805, align 8
  %9601 = shl nsw i64 %9600, 3
  %9602 = add i64 %9563, %9601
  %9603 = add i64 %9562, 24
  store i64 %9603, i64* %3, align 8
  %9604 = inttoptr i64 %9602 to i64*
  %9605 = load i64, i64* %9604, align 8
  store i64 %9605, i64* %RAX.i1763, align 8
  %9606 = add i64 %9562, 28
  store i64 %9606, i64* %3, align 8
  %9607 = load i32, i32* %9527, align 4
  %9608 = sext i32 %9607 to i64
  store i64 %9608, i64* %RDX.i1805, align 8
  %9609 = shl nsw i64 %9608, 1
  %9610 = add i64 %9609, %9605
  %9611 = add i64 %9562, 32
  store i64 %9611, i64* %3, align 8
  %9612 = inttoptr i64 %9610 to i16*
  %9613 = load i16, i16* %9612, align 2
  %9614 = zext i16 %9613 to i64
  store i64 %9614, i64* %RCX.i1692, align 8
  %9615 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9615, i64* %RAX.i1763, align 8
  %9616 = add i64 %9615, 6424
  %9617 = add i64 %9562, 47
  store i64 %9617, i64* %3, align 8
  %9618 = inttoptr i64 %9616 to i64*
  %9619 = load i64, i64* %9618, align 8
  store i64 %9619, i64* %RAX.i1763, align 8
  %9620 = add i64 %9562, 53
  store i64 %9620, i64* %3, align 8
  %9621 = load i32, i32* %9566, align 4
  %9622 = zext i32 %9621 to i64
  store i64 %9622, i64* %RSI.i1889, align 8
  %9623 = add i64 %9562, 56
  store i64 %9623, i64* %3, align 8
  %9624 = load i32, i32* %9571, align 4
  %9625 = add i32 %9624, %9621
  %9626 = zext i32 %9625 to i64
  store i64 %9626, i64* %RSI.i1889, align 8
  %9627 = icmp ult i32 %9625, %9621
  %9628 = icmp ult i32 %9625, %9624
  %9629 = or i1 %9627, %9628
  %9630 = zext i1 %9629 to i8
  store i8 %9630, i8* %18, align 1
  %9631 = and i32 %9625, 255
  %9632 = tail call i32 @llvm.ctpop.i32(i32 %9631)
  %9633 = trunc i32 %9632 to i8
  %9634 = and i8 %9633, 1
  %9635 = xor i8 %9634, 1
  store i8 %9635, i8* %19, align 1
  %9636 = xor i32 %9624, %9621
  %9637 = xor i32 %9636, %9625
  %9638 = lshr i32 %9637, 4
  %9639 = trunc i32 %9638 to i8
  %9640 = and i8 %9639, 1
  store i8 %9640, i8* %20, align 1
  %9641 = icmp eq i32 %9625, 0
  %9642 = zext i1 %9641 to i8
  store i8 %9642, i8* %21, align 1
  %9643 = lshr i32 %9625, 31
  %9644 = trunc i32 %9643 to i8
  store i8 %9644, i8* %22, align 1
  %9645 = lshr i32 %9621, 31
  %9646 = lshr i32 %9624, 31
  %9647 = xor i32 %9643, %9645
  %9648 = xor i32 %9643, %9646
  %9649 = add nuw nsw i32 %9647, %9648
  %9650 = icmp eq i32 %9649, 2
  %9651 = zext i1 %9650 to i8
  store i8 %9651, i8* %23, align 1
  %9652 = sext i32 %9625 to i64
  store i64 %9652, i64* %RDX.i1805, align 8
  %9653 = shl nsw i64 %9652, 3
  %9654 = add i64 %9619, %9653
  %9655 = add i64 %9562, 63
  store i64 %9655, i64* %3, align 8
  %9656 = inttoptr i64 %9654 to i64*
  %9657 = load i64, i64* %9656, align 8
  store i64 %9657, i64* %RAX.i1763, align 8
  %9658 = load i64, i64* %RBP.i, align 8
  %9659 = add i64 %9658, -56
  %9660 = add i64 %9562, 67
  store i64 %9660, i64* %3, align 8
  %9661 = inttoptr i64 %9659 to i32*
  %9662 = load i32, i32* %9661, align 4
  %9663 = sext i32 %9662 to i64
  store i64 %9663, i64* %RDX.i1805, align 8
  %9664 = shl nsw i64 %9663, 1
  %9665 = add i64 %9664, %9657
  %9666 = add i64 %9562, 71
  store i64 %9666, i64* %3, align 8
  %9667 = inttoptr i64 %9665 to i16*
  %9668 = load i16, i16* %9667, align 2
  %9669 = zext i16 %9668 to i64
  store i64 %9669, i64* %RSI.i1889, align 8
  %9670 = zext i16 %9668 to i32
  %9671 = zext i16 %9613 to i32
  %9672 = sub nsw i32 %9671, %9670
  %9673 = zext i32 %9672 to i64
  store i64 %9673, i64* %RCX.i1692, align 8
  %9674 = icmp ult i16 %9613, %9668
  %9675 = zext i1 %9674 to i8
  store i8 %9675, i8* %18, align 1
  %9676 = and i32 %9672, 255
  %9677 = tail call i32 @llvm.ctpop.i32(i32 %9676)
  %9678 = trunc i32 %9677 to i8
  %9679 = and i8 %9678, 1
  %9680 = xor i8 %9679, 1
  store i8 %9680, i8* %19, align 1
  %9681 = xor i16 %9668, %9613
  %9682 = zext i16 %9681 to i32
  %9683 = xor i32 %9682, %9672
  %9684 = lshr i32 %9683, 4
  %9685 = trunc i32 %9684 to i8
  %9686 = and i8 %9685, 1
  store i8 %9686, i8* %20, align 1
  %9687 = icmp eq i32 %9672, 0
  %9688 = zext i1 %9687 to i8
  store i8 %9688, i8* %21, align 1
  %9689 = lshr i32 %9672, 31
  %9690 = trunc i32 %9689 to i8
  store i8 %9690, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %9691 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %9691, i64* %RAX.i1763, align 8
  %9692 = add i64 %9658, -496
  %9693 = add i64 %9562, 87
  store i64 %9693, i64* %3, align 8
  %9694 = inttoptr i64 %9692 to i32*
  %9695 = load i32, i32* %9694, align 4
  %9696 = zext i32 %9695 to i64
  store i64 %9696, i64* %RSI.i1889, align 8
  %9697 = add i64 %9658, -60
  %9698 = add i64 %9562, 90
  store i64 %9698, i64* %3, align 8
  %9699 = inttoptr i64 %9697 to i32*
  %9700 = load i32, i32* %9699, align 4
  %9701 = add i32 %9700, %9695
  %9702 = zext i32 %9701 to i64
  store i64 %9702, i64* %RSI.i1889, align 8
  %9703 = icmp ult i32 %9701, %9695
  %9704 = icmp ult i32 %9701, %9700
  %9705 = or i1 %9703, %9704
  %9706 = zext i1 %9705 to i8
  store i8 %9706, i8* %18, align 1
  %9707 = and i32 %9701, 255
  %9708 = tail call i32 @llvm.ctpop.i32(i32 %9707)
  %9709 = trunc i32 %9708 to i8
  %9710 = and i8 %9709, 1
  %9711 = xor i8 %9710, 1
  store i8 %9711, i8* %19, align 1
  %9712 = xor i32 %9700, %9695
  %9713 = xor i32 %9712, %9701
  %9714 = lshr i32 %9713, 4
  %9715 = trunc i32 %9714 to i8
  %9716 = and i8 %9715, 1
  store i8 %9716, i8* %20, align 1
  %9717 = icmp eq i32 %9701, 0
  %9718 = zext i1 %9717 to i8
  store i8 %9718, i8* %21, align 1
  %9719 = lshr i32 %9701, 31
  %9720 = trunc i32 %9719 to i8
  store i8 %9720, i8* %22, align 1
  %9721 = lshr i32 %9695, 31
  %9722 = lshr i32 %9700, 31
  %9723 = xor i32 %9719, %9721
  %9724 = xor i32 %9719, %9722
  %9725 = add nuw nsw i32 %9723, %9724
  %9726 = icmp eq i32 %9725, 2
  %9727 = zext i1 %9726 to i8
  store i8 %9727, i8* %23, align 1
  %9728 = sext i32 %9701 to i64
  store i64 %9728, i64* %RDX.i1805, align 8
  %9729 = shl nsw i64 %9728, 3
  %9730 = add i64 %9691, %9729
  %9731 = add i64 %9562, 97
  store i64 %9731, i64* %3, align 8
  %9732 = inttoptr i64 %9730 to i64*
  %9733 = load i64, i64* %9732, align 8
  store i64 %9733, i64* %RAX.i1763, align 8
  %9734 = load i64, i64* %RBP.i, align 8
  %9735 = add i64 %9734, -56
  %9736 = add i64 %9562, 101
  store i64 %9736, i64* %3, align 8
  %9737 = inttoptr i64 %9735 to i32*
  %9738 = load i32, i32* %9737, align 4
  %9739 = sext i32 %9738 to i64
  store i64 %9739, i64* %RDX.i1805, align 8
  %9740 = shl nsw i64 %9739, 1
  %9741 = add i64 %9740, %9733
  %9742 = add i64 %9562, 105
  store i64 %9742, i64* %3, align 8
  %9743 = inttoptr i64 %9741 to i16*
  %9744 = load i16, i16* %9743, align 2
  %9745 = zext i16 %9744 to i64
  store i64 %9745, i64* %RSI.i1889, align 8
  %9746 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9746, i64* %RAX.i1763, align 8
  %9747 = add i64 %9746, 6424
  %9748 = add i64 %9562, 120
  store i64 %9748, i64* %3, align 8
  %9749 = inttoptr i64 %9747 to i64*
  %9750 = load i64, i64* %9749, align 8
  store i64 %9750, i64* %RAX.i1763, align 8
  %9751 = add i64 %9734, -496
  %9752 = add i64 %9562, 126
  store i64 %9752, i64* %3, align 8
  %9753 = inttoptr i64 %9751 to i32*
  %9754 = load i32, i32* %9753, align 4
  %9755 = zext i32 %9754 to i64
  store i64 %9755, i64* %RDI.i2141, align 8
  %9756 = add i64 %9734, -60
  %9757 = add i64 %9562, 129
  store i64 %9757, i64* %3, align 8
  %9758 = inttoptr i64 %9756 to i32*
  %9759 = load i32, i32* %9758, align 4
  %9760 = add i32 %9759, %9754
  %9761 = zext i32 %9760 to i64
  store i64 %9761, i64* %RDI.i2141, align 8
  %9762 = icmp ult i32 %9760, %9754
  %9763 = icmp ult i32 %9760, %9759
  %9764 = or i1 %9762, %9763
  %9765 = zext i1 %9764 to i8
  store i8 %9765, i8* %18, align 1
  %9766 = and i32 %9760, 255
  %9767 = tail call i32 @llvm.ctpop.i32(i32 %9766)
  %9768 = trunc i32 %9767 to i8
  %9769 = and i8 %9768, 1
  %9770 = xor i8 %9769, 1
  store i8 %9770, i8* %19, align 1
  %9771 = xor i32 %9759, %9754
  %9772 = xor i32 %9771, %9760
  %9773 = lshr i32 %9772, 4
  %9774 = trunc i32 %9773 to i8
  %9775 = and i8 %9774, 1
  store i8 %9775, i8* %20, align 1
  %9776 = icmp eq i32 %9760, 0
  %9777 = zext i1 %9776 to i8
  store i8 %9777, i8* %21, align 1
  %9778 = lshr i32 %9760, 31
  %9779 = trunc i32 %9778 to i8
  store i8 %9779, i8* %22, align 1
  %9780 = lshr i32 %9754, 31
  %9781 = lshr i32 %9759, 31
  %9782 = xor i32 %9778, %9780
  %9783 = xor i32 %9778, %9781
  %9784 = add nuw nsw i32 %9782, %9783
  %9785 = icmp eq i32 %9784, 2
  %9786 = zext i1 %9785 to i8
  store i8 %9786, i8* %23, align 1
  %9787 = sext i32 %9760 to i64
  store i64 %9787, i64* %RDX.i1805, align 8
  %9788 = shl nsw i64 %9787, 3
  %9789 = add i64 %9750, %9788
  %9790 = add i64 %9562, 136
  store i64 %9790, i64* %3, align 8
  %9791 = inttoptr i64 %9789 to i64*
  %9792 = load i64, i64* %9791, align 8
  store i64 %9792, i64* %RAX.i1763, align 8
  %9793 = add i64 %9562, 140
  store i64 %9793, i64* %3, align 8
  %9794 = load i32, i32* %9737, align 4
  %9795 = sext i32 %9794 to i64
  store i64 %9795, i64* %RDX.i1805, align 8
  %9796 = shl nsw i64 %9795, 1
  %9797 = add i64 %9796, %9792
  %9798 = add i64 %9562, 144
  store i64 %9798, i64* %3, align 8
  %9799 = inttoptr i64 %9797 to i16*
  %9800 = load i16, i16* %9799, align 2
  %9801 = zext i16 %9800 to i64
  store i64 %9801, i64* %RDI.i2141, align 8
  %9802 = zext i16 %9800 to i32
  %9803 = zext i16 %9744 to i32
  %9804 = sub nsw i32 %9803, %9802
  %9805 = zext i32 %9804 to i64
  store i64 %9805, i64* %RSI.i1889, align 8
  %9806 = load i64, i64* %RCX.i1692, align 8
  %9807 = shl i64 %9806, 32
  %9808 = ashr exact i64 %9807, 32
  %9809 = sext i32 %9804 to i64
  %9810 = mul nsw i64 %9809, %9808
  %9811 = trunc i64 %9810 to i32
  %9812 = and i64 %9810, 4294967295
  store i64 %9812, i64* %RCX.i1692, align 8
  %9813 = shl i64 %9810, 32
  %9814 = ashr exact i64 %9813, 32
  %9815 = icmp ne i64 %9814, %9810
  %9816 = zext i1 %9815 to i8
  store i8 %9816, i8* %18, align 1
  %9817 = and i32 %9811, 255
  %9818 = tail call i32 @llvm.ctpop.i32(i32 %9817)
  %9819 = trunc i32 %9818 to i8
  %9820 = and i8 %9819, 1
  %9821 = xor i8 %9820, 1
  store i8 %9821, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  %9822 = lshr i32 %9811, 31
  %9823 = trunc i32 %9822 to i8
  store i8 %9823, i8* %22, align 1
  store i8 %9816, i8* %23, align 1
  %9824 = load i64, i64* %RBP.i, align 8
  %9825 = add i64 %9824, -620
  %9826 = add i64 %9562, 155
  store i64 %9826, i64* %3, align 8
  %9827 = trunc i64 %9810 to i32
  %9828 = inttoptr i64 %9825 to i32*
  %9829 = load i32, i32* %9828, align 4
  %9830 = add i32 %9829, %9827
  %9831 = zext i32 %9830 to i64
  store i64 %9831, i64* %RCX.i1692, align 8
  %9832 = icmp ult i32 %9830, %9827
  %9833 = icmp ult i32 %9830, %9829
  %9834 = or i1 %9832, %9833
  %9835 = zext i1 %9834 to i8
  store i8 %9835, i8* %18, align 1
  %9836 = and i32 %9830, 255
  %9837 = tail call i32 @llvm.ctpop.i32(i32 %9836)
  %9838 = trunc i32 %9837 to i8
  %9839 = and i8 %9838, 1
  %9840 = xor i8 %9839, 1
  store i8 %9840, i8* %19, align 1
  %9841 = xor i32 %9829, %9827
  %9842 = xor i32 %9841, %9830
  %9843 = lshr i32 %9842, 4
  %9844 = trunc i32 %9843 to i8
  %9845 = and i8 %9844, 1
  store i8 %9845, i8* %20, align 1
  %9846 = icmp eq i32 %9830, 0
  %9847 = zext i1 %9846 to i8
  store i8 %9847, i8* %21, align 1
  %9848 = lshr i32 %9830, 31
  %9849 = trunc i32 %9848 to i8
  store i8 %9849, i8* %22, align 1
  %9850 = lshr i32 %9827, 31
  %9851 = lshr i32 %9829, 31
  %9852 = xor i32 %9848, %9850
  %9853 = xor i32 %9848, %9851
  %9854 = add nuw nsw i32 %9852, %9853
  %9855 = icmp eq i32 %9854, 2
  %9856 = zext i1 %9855 to i8
  store i8 %9856, i8* %23, align 1
  %9857 = add i64 %9562, 161
  store i64 %9857, i64* %3, align 8
  store i32 %9830, i32* %9828, align 4
  %9858 = load i64, i64* %3, align 8
  %9859 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %9859, i64* %RAX.i1763, align 8
  %9860 = add i64 %9858, 11
  store i64 %9860, i64* %3, align 8
  %9861 = inttoptr i64 %9859 to i64*
  %9862 = load i64, i64* %9861, align 8
  store i64 %9862, i64* %RAX.i1763, align 8
  %9863 = load i64, i64* %RBP.i, align 8
  %9864 = add i64 %9863, -496
  %9865 = add i64 %9858, 17
  store i64 %9865, i64* %3, align 8
  %9866 = inttoptr i64 %9864 to i32*
  %9867 = load i32, i32* %9866, align 4
  %9868 = zext i32 %9867 to i64
  store i64 %9868, i64* %RCX.i1692, align 8
  %9869 = add i64 %9863, -60
  %9870 = add i64 %9858, 20
  store i64 %9870, i64* %3, align 8
  %9871 = inttoptr i64 %9869 to i32*
  %9872 = load i32, i32* %9871, align 4
  %9873 = add i32 %9872, %9867
  %9874 = zext i32 %9873 to i64
  store i64 %9874, i64* %RCX.i1692, align 8
  %9875 = icmp ult i32 %9873, %9867
  %9876 = icmp ult i32 %9873, %9872
  %9877 = or i1 %9875, %9876
  %9878 = zext i1 %9877 to i8
  store i8 %9878, i8* %18, align 1
  %9879 = and i32 %9873, 255
  %9880 = tail call i32 @llvm.ctpop.i32(i32 %9879)
  %9881 = trunc i32 %9880 to i8
  %9882 = and i8 %9881, 1
  %9883 = xor i8 %9882, 1
  store i8 %9883, i8* %19, align 1
  %9884 = xor i32 %9872, %9867
  %9885 = xor i32 %9884, %9873
  %9886 = lshr i32 %9885, 4
  %9887 = trunc i32 %9886 to i8
  %9888 = and i8 %9887, 1
  store i8 %9888, i8* %20, align 1
  %9889 = icmp eq i32 %9873, 0
  %9890 = zext i1 %9889 to i8
  store i8 %9890, i8* %21, align 1
  %9891 = lshr i32 %9873, 31
  %9892 = trunc i32 %9891 to i8
  store i8 %9892, i8* %22, align 1
  %9893 = lshr i32 %9867, 31
  %9894 = lshr i32 %9872, 31
  %9895 = xor i32 %9891, %9893
  %9896 = xor i32 %9891, %9894
  %9897 = add nuw nsw i32 %9895, %9896
  %9898 = icmp eq i32 %9897, 2
  %9899 = zext i1 %9898 to i8
  store i8 %9899, i8* %23, align 1
  %9900 = sext i32 %9873 to i64
  store i64 %9900, i64* %RDX.i1805, align 8
  %9901 = shl nsw i64 %9900, 3
  %9902 = add i64 %9862, %9901
  %9903 = add i64 %9858, 27
  store i64 %9903, i64* %3, align 8
  %9904 = inttoptr i64 %9902 to i64*
  %9905 = load i64, i64* %9904, align 8
  store i64 %9905, i64* %RAX.i1763, align 8
  %9906 = add i64 %9863, -56
  %9907 = add i64 %9858, 31
  store i64 %9907, i64* %3, align 8
  %9908 = inttoptr i64 %9906 to i32*
  %9909 = load i32, i32* %9908, align 4
  %9910 = sext i32 %9909 to i64
  store i64 %9910, i64* %RDX.i1805, align 8
  %9911 = shl nsw i64 %9910, 1
  %9912 = add i64 %9911, %9905
  %9913 = add i64 %9858, 35
  store i64 %9913, i64* %3, align 8
  %9914 = inttoptr i64 %9912 to i16*
  %9915 = load i16, i16* %9914, align 2
  %9916 = zext i16 %9915 to i64
  store i64 %9916, i64* %RCX.i1692, align 8
  %9917 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9917, i64* %RAX.i1763, align 8
  %9918 = add i64 %9917, 6464
  %9919 = add i64 %9858, 50
  store i64 %9919, i64* %3, align 8
  %9920 = inttoptr i64 %9918 to i64*
  %9921 = load i64, i64* %9920, align 8
  store i64 %9921, i64* %RAX.i1763, align 8
  %9922 = add i64 %9858, 53
  store i64 %9922, i64* %3, align 8
  %9923 = inttoptr i64 %9921 to i64*
  %9924 = load i64, i64* %9923, align 8
  store i64 %9924, i64* %RAX.i1763, align 8
  %9925 = add i64 %9858, 59
  store i64 %9925, i64* %3, align 8
  %9926 = load i32, i32* %9866, align 4
  %9927 = zext i32 %9926 to i64
  store i64 %9927, i64* %RSI.i1889, align 8
  %9928 = add i64 %9858, 62
  store i64 %9928, i64* %3, align 8
  %9929 = load i32, i32* %9871, align 4
  %9930 = add i32 %9929, %9926
  %9931 = zext i32 %9930 to i64
  store i64 %9931, i64* %RSI.i1889, align 8
  %9932 = icmp ult i32 %9930, %9926
  %9933 = icmp ult i32 %9930, %9929
  %9934 = or i1 %9932, %9933
  %9935 = zext i1 %9934 to i8
  store i8 %9935, i8* %18, align 1
  %9936 = and i32 %9930, 255
  %9937 = tail call i32 @llvm.ctpop.i32(i32 %9936)
  %9938 = trunc i32 %9937 to i8
  %9939 = and i8 %9938, 1
  %9940 = xor i8 %9939, 1
  store i8 %9940, i8* %19, align 1
  %9941 = xor i32 %9929, %9926
  %9942 = xor i32 %9941, %9930
  %9943 = lshr i32 %9942, 4
  %9944 = trunc i32 %9943 to i8
  %9945 = and i8 %9944, 1
  store i8 %9945, i8* %20, align 1
  %9946 = icmp eq i32 %9930, 0
  %9947 = zext i1 %9946 to i8
  store i8 %9947, i8* %21, align 1
  %9948 = lshr i32 %9930, 31
  %9949 = trunc i32 %9948 to i8
  store i8 %9949, i8* %22, align 1
  %9950 = lshr i32 %9926, 31
  %9951 = lshr i32 %9929, 31
  %9952 = xor i32 %9948, %9950
  %9953 = xor i32 %9948, %9951
  %9954 = add nuw nsw i32 %9952, %9953
  %9955 = icmp eq i32 %9954, 2
  %9956 = zext i1 %9955 to i8
  store i8 %9956, i8* %23, align 1
  %9957 = sext i32 %9930 to i64
  store i64 %9957, i64* %RDX.i1805, align 8
  %9958 = shl nsw i64 %9957, 3
  %9959 = add i64 %9924, %9958
  %9960 = add i64 %9858, 69
  store i64 %9960, i64* %3, align 8
  %9961 = inttoptr i64 %9959 to i64*
  %9962 = load i64, i64* %9961, align 8
  store i64 %9962, i64* %RAX.i1763, align 8
  %9963 = load i64, i64* %RBP.i, align 8
  %9964 = add i64 %9963, -56
  %9965 = add i64 %9858, 73
  store i64 %9965, i64* %3, align 8
  %9966 = inttoptr i64 %9964 to i32*
  %9967 = load i32, i32* %9966, align 4
  %9968 = sext i32 %9967 to i64
  store i64 %9968, i64* %RDX.i1805, align 8
  %9969 = shl nsw i64 %9968, 1
  %9970 = add i64 %9969, %9962
  %9971 = add i64 %9858, 77
  store i64 %9971, i64* %3, align 8
  %9972 = inttoptr i64 %9970 to i16*
  %9973 = load i16, i16* %9972, align 2
  %9974 = zext i16 %9973 to i64
  store i64 %9974, i64* %RSI.i1889, align 8
  %9975 = zext i16 %9973 to i32
  %9976 = zext i16 %9915 to i32
  %9977 = sub nsw i32 %9976, %9975
  %9978 = zext i32 %9977 to i64
  store i64 %9978, i64* %RCX.i1692, align 8
  %9979 = icmp ult i16 %9915, %9973
  %9980 = zext i1 %9979 to i8
  store i8 %9980, i8* %18, align 1
  %9981 = and i32 %9977, 255
  %9982 = tail call i32 @llvm.ctpop.i32(i32 %9981)
  %9983 = trunc i32 %9982 to i8
  %9984 = and i8 %9983, 1
  %9985 = xor i8 %9984, 1
  store i8 %9985, i8* %19, align 1
  %9986 = xor i16 %9973, %9915
  %9987 = zext i16 %9986 to i32
  %9988 = xor i32 %9987, %9977
  %9989 = lshr i32 %9988, 4
  %9990 = trunc i32 %9989 to i8
  %9991 = and i8 %9990, 1
  store i8 %9991, i8* %20, align 1
  %9992 = icmp eq i32 %9977, 0
  %9993 = zext i1 %9992 to i8
  store i8 %9993, i8* %21, align 1
  %9994 = lshr i32 %9977, 31
  %9995 = trunc i32 %9994 to i8
  store i8 %9995, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %9996 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %9996, i64* %RAX.i1763, align 8
  %9997 = add i64 %9858, 90
  store i64 %9997, i64* %3, align 8
  %9998 = inttoptr i64 %9996 to i64*
  %9999 = load i64, i64* %9998, align 8
  store i64 %9999, i64* %RAX.i1763, align 8
  %10000 = add i64 %9963, -496
  %10001 = add i64 %9858, 96
  store i64 %10001, i64* %3, align 8
  %10002 = inttoptr i64 %10000 to i32*
  %10003 = load i32, i32* %10002, align 4
  %10004 = zext i32 %10003 to i64
  store i64 %10004, i64* %RSI.i1889, align 8
  %10005 = add i64 %9963, -60
  %10006 = add i64 %9858, 99
  store i64 %10006, i64* %3, align 8
  %10007 = inttoptr i64 %10005 to i32*
  %10008 = load i32, i32* %10007, align 4
  %10009 = add i32 %10008, %10003
  %10010 = zext i32 %10009 to i64
  store i64 %10010, i64* %RSI.i1889, align 8
  %10011 = icmp ult i32 %10009, %10003
  %10012 = icmp ult i32 %10009, %10008
  %10013 = or i1 %10011, %10012
  %10014 = zext i1 %10013 to i8
  store i8 %10014, i8* %18, align 1
  %10015 = and i32 %10009, 255
  %10016 = tail call i32 @llvm.ctpop.i32(i32 %10015)
  %10017 = trunc i32 %10016 to i8
  %10018 = and i8 %10017, 1
  %10019 = xor i8 %10018, 1
  store i8 %10019, i8* %19, align 1
  %10020 = xor i32 %10008, %10003
  %10021 = xor i32 %10020, %10009
  %10022 = lshr i32 %10021, 4
  %10023 = trunc i32 %10022 to i8
  %10024 = and i8 %10023, 1
  store i8 %10024, i8* %20, align 1
  %10025 = icmp eq i32 %10009, 0
  %10026 = zext i1 %10025 to i8
  store i8 %10026, i8* %21, align 1
  %10027 = lshr i32 %10009, 31
  %10028 = trunc i32 %10027 to i8
  store i8 %10028, i8* %22, align 1
  %10029 = lshr i32 %10003, 31
  %10030 = lshr i32 %10008, 31
  %10031 = xor i32 %10027, %10029
  %10032 = xor i32 %10027, %10030
  %10033 = add nuw nsw i32 %10031, %10032
  %10034 = icmp eq i32 %10033, 2
  %10035 = zext i1 %10034 to i8
  store i8 %10035, i8* %23, align 1
  %10036 = sext i32 %10009 to i64
  store i64 %10036, i64* %RDX.i1805, align 8
  %10037 = shl nsw i64 %10036, 3
  %10038 = add i64 %9999, %10037
  %10039 = add i64 %9858, 106
  store i64 %10039, i64* %3, align 8
  %10040 = inttoptr i64 %10038 to i64*
  %10041 = load i64, i64* %10040, align 8
  store i64 %10041, i64* %RAX.i1763, align 8
  %10042 = load i64, i64* %RBP.i, align 8
  %10043 = add i64 %10042, -56
  %10044 = add i64 %9858, 110
  store i64 %10044, i64* %3, align 8
  %10045 = inttoptr i64 %10043 to i32*
  %10046 = load i32, i32* %10045, align 4
  %10047 = sext i32 %10046 to i64
  store i64 %10047, i64* %RDX.i1805, align 8
  %10048 = shl nsw i64 %10047, 1
  %10049 = add i64 %10048, %10041
  %10050 = add i64 %9858, 114
  store i64 %10050, i64* %3, align 8
  %10051 = inttoptr i64 %10049 to i16*
  %10052 = load i16, i16* %10051, align 2
  %10053 = zext i16 %10052 to i64
  store i64 %10053, i64* %RSI.i1889, align 8
  %10054 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %10054, i64* %RAX.i1763, align 8
  %10055 = add i64 %10054, 6464
  %10056 = add i64 %9858, 129
  store i64 %10056, i64* %3, align 8
  %10057 = inttoptr i64 %10055 to i64*
  %10058 = load i64, i64* %10057, align 8
  store i64 %10058, i64* %RAX.i1763, align 8
  %10059 = add i64 %9858, 132
  store i64 %10059, i64* %3, align 8
  %10060 = inttoptr i64 %10058 to i64*
  %10061 = load i64, i64* %10060, align 8
  store i64 %10061, i64* %RAX.i1763, align 8
  %10062 = add i64 %10042, -496
  %10063 = add i64 %9858, 138
  store i64 %10063, i64* %3, align 8
  %10064 = inttoptr i64 %10062 to i32*
  %10065 = load i32, i32* %10064, align 4
  %10066 = zext i32 %10065 to i64
  store i64 %10066, i64* %RDI.i2141, align 8
  %10067 = add i64 %10042, -60
  %10068 = add i64 %9858, 141
  store i64 %10068, i64* %3, align 8
  %10069 = inttoptr i64 %10067 to i32*
  %10070 = load i32, i32* %10069, align 4
  %10071 = add i32 %10070, %10065
  %10072 = zext i32 %10071 to i64
  store i64 %10072, i64* %RDI.i2141, align 8
  %10073 = icmp ult i32 %10071, %10065
  %10074 = icmp ult i32 %10071, %10070
  %10075 = or i1 %10073, %10074
  %10076 = zext i1 %10075 to i8
  store i8 %10076, i8* %18, align 1
  %10077 = and i32 %10071, 255
  %10078 = tail call i32 @llvm.ctpop.i32(i32 %10077)
  %10079 = trunc i32 %10078 to i8
  %10080 = and i8 %10079, 1
  %10081 = xor i8 %10080, 1
  store i8 %10081, i8* %19, align 1
  %10082 = xor i32 %10070, %10065
  %10083 = xor i32 %10082, %10071
  %10084 = lshr i32 %10083, 4
  %10085 = trunc i32 %10084 to i8
  %10086 = and i8 %10085, 1
  store i8 %10086, i8* %20, align 1
  %10087 = icmp eq i32 %10071, 0
  %10088 = zext i1 %10087 to i8
  store i8 %10088, i8* %21, align 1
  %10089 = lshr i32 %10071, 31
  %10090 = trunc i32 %10089 to i8
  store i8 %10090, i8* %22, align 1
  %10091 = lshr i32 %10065, 31
  %10092 = lshr i32 %10070, 31
  %10093 = xor i32 %10089, %10091
  %10094 = xor i32 %10089, %10092
  %10095 = add nuw nsw i32 %10093, %10094
  %10096 = icmp eq i32 %10095, 2
  %10097 = zext i1 %10096 to i8
  store i8 %10097, i8* %23, align 1
  %10098 = sext i32 %10071 to i64
  store i64 %10098, i64* %RDX.i1805, align 8
  %10099 = shl nsw i64 %10098, 3
  %10100 = add i64 %10061, %10099
  %10101 = add i64 %9858, 148
  store i64 %10101, i64* %3, align 8
  %10102 = inttoptr i64 %10100 to i64*
  %10103 = load i64, i64* %10102, align 8
  store i64 %10103, i64* %RAX.i1763, align 8
  %10104 = add i64 %9858, 152
  store i64 %10104, i64* %3, align 8
  %10105 = load i32, i32* %10045, align 4
  %10106 = sext i32 %10105 to i64
  store i64 %10106, i64* %RDX.i1805, align 8
  %10107 = shl nsw i64 %10106, 1
  %10108 = add i64 %10107, %10103
  %10109 = add i64 %9858, 156
  store i64 %10109, i64* %3, align 8
  %10110 = inttoptr i64 %10108 to i16*
  %10111 = load i16, i16* %10110, align 2
  %10112 = zext i16 %10111 to i64
  store i64 %10112, i64* %RDI.i2141, align 8
  %10113 = zext i16 %10111 to i32
  %10114 = zext i16 %10052 to i32
  %10115 = sub nsw i32 %10114, %10113
  %10116 = zext i32 %10115 to i64
  store i64 %10116, i64* %RSI.i1889, align 8
  %10117 = load i64, i64* %RCX.i1692, align 8
  %10118 = shl i64 %10117, 32
  %10119 = ashr exact i64 %10118, 32
  %10120 = sext i32 %10115 to i64
  %10121 = mul nsw i64 %10120, %10119
  %10122 = trunc i64 %10121 to i32
  %10123 = and i64 %10121, 4294967295
  store i64 %10123, i64* %RCX.i1692, align 8
  %10124 = shl i64 %10121, 32
  %10125 = ashr exact i64 %10124, 32
  %10126 = icmp ne i64 %10125, %10121
  %10127 = zext i1 %10126 to i8
  store i8 %10127, i8* %18, align 1
  %10128 = and i32 %10122, 255
  %10129 = tail call i32 @llvm.ctpop.i32(i32 %10128)
  %10130 = trunc i32 %10129 to i8
  %10131 = and i8 %10130, 1
  %10132 = xor i8 %10131, 1
  store i8 %10132, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  %10133 = lshr i32 %10122, 31
  %10134 = trunc i32 %10133 to i8
  store i8 %10134, i8* %22, align 1
  store i8 %10127, i8* %23, align 1
  %10135 = load i64, i64* %RBP.i, align 8
  %10136 = add i64 %10135, -620
  %10137 = add i64 %9858, 167
  store i64 %10137, i64* %3, align 8
  %10138 = trunc i64 %10121 to i32
  %10139 = inttoptr i64 %10136 to i32*
  %10140 = load i32, i32* %10139, align 4
  %10141 = add i32 %10140, %10138
  %10142 = zext i32 %10141 to i64
  store i64 %10142, i64* %RCX.i1692, align 8
  %10143 = icmp ult i32 %10141, %10138
  %10144 = icmp ult i32 %10141, %10140
  %10145 = or i1 %10143, %10144
  %10146 = zext i1 %10145 to i8
  store i8 %10146, i8* %18, align 1
  %10147 = and i32 %10141, 255
  %10148 = tail call i32 @llvm.ctpop.i32(i32 %10147)
  %10149 = trunc i32 %10148 to i8
  %10150 = and i8 %10149, 1
  %10151 = xor i8 %10150, 1
  store i8 %10151, i8* %19, align 1
  %10152 = xor i32 %10140, %10138
  %10153 = xor i32 %10152, %10141
  %10154 = lshr i32 %10153, 4
  %10155 = trunc i32 %10154 to i8
  %10156 = and i8 %10155, 1
  store i8 %10156, i8* %20, align 1
  %10157 = icmp eq i32 %10141, 0
  %10158 = zext i1 %10157 to i8
  store i8 %10158, i8* %21, align 1
  %10159 = lshr i32 %10141, 31
  %10160 = trunc i32 %10159 to i8
  store i8 %10160, i8* %22, align 1
  %10161 = lshr i32 %10138, 31
  %10162 = lshr i32 %10140, 31
  %10163 = xor i32 %10159, %10161
  %10164 = xor i32 %10159, %10162
  %10165 = add nuw nsw i32 %10163, %10164
  %10166 = icmp eq i32 %10165, 2
  %10167 = zext i1 %10166 to i8
  store i8 %10167, i8* %23, align 1
  %10168 = add i64 %9858, 173
  store i64 %10168, i64* %3, align 8
  store i32 %10141, i32* %10139, align 4
  %10169 = load i64, i64* %3, align 8
  %10170 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %10170, i64* %RAX.i1763, align 8
  %10171 = add i64 %10170, 8
  %10172 = add i64 %10169, 12
  store i64 %10172, i64* %3, align 8
  %10173 = inttoptr i64 %10171 to i64*
  %10174 = load i64, i64* %10173, align 8
  store i64 %10174, i64* %RAX.i1763, align 8
  %10175 = load i64, i64* %RBP.i, align 8
  %10176 = add i64 %10175, -496
  %10177 = add i64 %10169, 18
  store i64 %10177, i64* %3, align 8
  %10178 = inttoptr i64 %10176 to i32*
  %10179 = load i32, i32* %10178, align 4
  %10180 = zext i32 %10179 to i64
  store i64 %10180, i64* %RCX.i1692, align 8
  %10181 = add i64 %10175, -60
  %10182 = add i64 %10169, 21
  store i64 %10182, i64* %3, align 8
  %10183 = inttoptr i64 %10181 to i32*
  %10184 = load i32, i32* %10183, align 4
  %10185 = add i32 %10184, %10179
  %10186 = zext i32 %10185 to i64
  store i64 %10186, i64* %RCX.i1692, align 8
  %10187 = icmp ult i32 %10185, %10179
  %10188 = icmp ult i32 %10185, %10184
  %10189 = or i1 %10187, %10188
  %10190 = zext i1 %10189 to i8
  store i8 %10190, i8* %18, align 1
  %10191 = and i32 %10185, 255
  %10192 = tail call i32 @llvm.ctpop.i32(i32 %10191)
  %10193 = trunc i32 %10192 to i8
  %10194 = and i8 %10193, 1
  %10195 = xor i8 %10194, 1
  store i8 %10195, i8* %19, align 1
  %10196 = xor i32 %10184, %10179
  %10197 = xor i32 %10196, %10185
  %10198 = lshr i32 %10197, 4
  %10199 = trunc i32 %10198 to i8
  %10200 = and i8 %10199, 1
  store i8 %10200, i8* %20, align 1
  %10201 = icmp eq i32 %10185, 0
  %10202 = zext i1 %10201 to i8
  store i8 %10202, i8* %21, align 1
  %10203 = lshr i32 %10185, 31
  %10204 = trunc i32 %10203 to i8
  store i8 %10204, i8* %22, align 1
  %10205 = lshr i32 %10179, 31
  %10206 = lshr i32 %10184, 31
  %10207 = xor i32 %10203, %10205
  %10208 = xor i32 %10203, %10206
  %10209 = add nuw nsw i32 %10207, %10208
  %10210 = icmp eq i32 %10209, 2
  %10211 = zext i1 %10210 to i8
  store i8 %10211, i8* %23, align 1
  %10212 = sext i32 %10185 to i64
  store i64 %10212, i64* %RDX.i1805, align 8
  %10213 = shl nsw i64 %10212, 3
  %10214 = add i64 %10174, %10213
  %10215 = add i64 %10169, 28
  store i64 %10215, i64* %3, align 8
  %10216 = inttoptr i64 %10214 to i64*
  %10217 = load i64, i64* %10216, align 8
  store i64 %10217, i64* %RAX.i1763, align 8
  %10218 = add i64 %10175, -56
  %10219 = add i64 %10169, 32
  store i64 %10219, i64* %3, align 8
  %10220 = inttoptr i64 %10218 to i32*
  %10221 = load i32, i32* %10220, align 4
  %10222 = sext i32 %10221 to i64
  store i64 %10222, i64* %RDX.i1805, align 8
  %10223 = shl nsw i64 %10222, 1
  %10224 = add i64 %10223, %10217
  %10225 = add i64 %10169, 36
  store i64 %10225, i64* %3, align 8
  %10226 = inttoptr i64 %10224 to i16*
  %10227 = load i16, i16* %10226, align 2
  %10228 = zext i16 %10227 to i64
  store i64 %10228, i64* %RCX.i1692, align 8
  %10229 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %10229, i64* %RAX.i1763, align 8
  %10230 = add i64 %10229, 6464
  %10231 = add i64 %10169, 51
  store i64 %10231, i64* %3, align 8
  %10232 = inttoptr i64 %10230 to i64*
  %10233 = load i64, i64* %10232, align 8
  store i64 %10233, i64* %RAX.i1763, align 8
  %10234 = add i64 %10233, 8
  %10235 = add i64 %10169, 55
  store i64 %10235, i64* %3, align 8
  %10236 = inttoptr i64 %10234 to i64*
  %10237 = load i64, i64* %10236, align 8
  store i64 %10237, i64* %RAX.i1763, align 8
  %10238 = add i64 %10169, 61
  store i64 %10238, i64* %3, align 8
  %10239 = load i32, i32* %10178, align 4
  %10240 = zext i32 %10239 to i64
  store i64 %10240, i64* %RSI.i1889, align 8
  %10241 = add i64 %10169, 64
  store i64 %10241, i64* %3, align 8
  %10242 = load i32, i32* %10183, align 4
  %10243 = add i32 %10242, %10239
  %10244 = zext i32 %10243 to i64
  store i64 %10244, i64* %RSI.i1889, align 8
  %10245 = icmp ult i32 %10243, %10239
  %10246 = icmp ult i32 %10243, %10242
  %10247 = or i1 %10245, %10246
  %10248 = zext i1 %10247 to i8
  store i8 %10248, i8* %18, align 1
  %10249 = and i32 %10243, 255
  %10250 = tail call i32 @llvm.ctpop.i32(i32 %10249)
  %10251 = trunc i32 %10250 to i8
  %10252 = and i8 %10251, 1
  %10253 = xor i8 %10252, 1
  store i8 %10253, i8* %19, align 1
  %10254 = xor i32 %10242, %10239
  %10255 = xor i32 %10254, %10243
  %10256 = lshr i32 %10255, 4
  %10257 = trunc i32 %10256 to i8
  %10258 = and i8 %10257, 1
  store i8 %10258, i8* %20, align 1
  %10259 = icmp eq i32 %10243, 0
  %10260 = zext i1 %10259 to i8
  store i8 %10260, i8* %21, align 1
  %10261 = lshr i32 %10243, 31
  %10262 = trunc i32 %10261 to i8
  store i8 %10262, i8* %22, align 1
  %10263 = lshr i32 %10239, 31
  %10264 = lshr i32 %10242, 31
  %10265 = xor i32 %10261, %10263
  %10266 = xor i32 %10261, %10264
  %10267 = add nuw nsw i32 %10265, %10266
  %10268 = icmp eq i32 %10267, 2
  %10269 = zext i1 %10268 to i8
  store i8 %10269, i8* %23, align 1
  %10270 = sext i32 %10243 to i64
  store i64 %10270, i64* %RDX.i1805, align 8
  %10271 = shl nsw i64 %10270, 3
  %10272 = add i64 %10237, %10271
  %10273 = add i64 %10169, 71
  store i64 %10273, i64* %3, align 8
  %10274 = inttoptr i64 %10272 to i64*
  %10275 = load i64, i64* %10274, align 8
  store i64 %10275, i64* %RAX.i1763, align 8
  %10276 = load i64, i64* %RBP.i, align 8
  %10277 = add i64 %10276, -56
  %10278 = add i64 %10169, 75
  store i64 %10278, i64* %3, align 8
  %10279 = inttoptr i64 %10277 to i32*
  %10280 = load i32, i32* %10279, align 4
  %10281 = sext i32 %10280 to i64
  store i64 %10281, i64* %RDX.i1805, align 8
  %10282 = shl nsw i64 %10281, 1
  %10283 = add i64 %10282, %10275
  %10284 = add i64 %10169, 79
  store i64 %10284, i64* %3, align 8
  %10285 = inttoptr i64 %10283 to i16*
  %10286 = load i16, i16* %10285, align 2
  %10287 = zext i16 %10286 to i64
  store i64 %10287, i64* %RSI.i1889, align 8
  %10288 = zext i16 %10286 to i32
  %10289 = zext i16 %10227 to i32
  %10290 = sub nsw i32 %10289, %10288
  %10291 = zext i32 %10290 to i64
  store i64 %10291, i64* %RCX.i1692, align 8
  %10292 = icmp ult i16 %10227, %10286
  %10293 = zext i1 %10292 to i8
  store i8 %10293, i8* %18, align 1
  %10294 = and i32 %10290, 255
  %10295 = tail call i32 @llvm.ctpop.i32(i32 %10294)
  %10296 = trunc i32 %10295 to i8
  %10297 = and i8 %10296, 1
  %10298 = xor i8 %10297, 1
  store i8 %10298, i8* %19, align 1
  %10299 = xor i16 %10286, %10227
  %10300 = zext i16 %10299 to i32
  %10301 = xor i32 %10300, %10290
  %10302 = lshr i32 %10301, 4
  %10303 = trunc i32 %10302 to i8
  %10304 = and i8 %10303, 1
  store i8 %10304, i8* %20, align 1
  %10305 = icmp eq i32 %10290, 0
  %10306 = zext i1 %10305 to i8
  store i8 %10306, i8* %21, align 1
  %10307 = lshr i32 %10290, 31
  %10308 = trunc i32 %10307 to i8
  store i8 %10308, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %10309 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %10309, i64* %RAX.i1763, align 8
  %10310 = add i64 %10309, 8
  %10311 = add i64 %10169, 93
  store i64 %10311, i64* %3, align 8
  %10312 = inttoptr i64 %10310 to i64*
  %10313 = load i64, i64* %10312, align 8
  store i64 %10313, i64* %RAX.i1763, align 8
  %10314 = add i64 %10276, -496
  %10315 = add i64 %10169, 99
  store i64 %10315, i64* %3, align 8
  %10316 = inttoptr i64 %10314 to i32*
  %10317 = load i32, i32* %10316, align 4
  %10318 = zext i32 %10317 to i64
  store i64 %10318, i64* %RSI.i1889, align 8
  %10319 = add i64 %10276, -60
  %10320 = add i64 %10169, 102
  store i64 %10320, i64* %3, align 8
  %10321 = inttoptr i64 %10319 to i32*
  %10322 = load i32, i32* %10321, align 4
  %10323 = add i32 %10322, %10317
  %10324 = zext i32 %10323 to i64
  store i64 %10324, i64* %RSI.i1889, align 8
  %10325 = icmp ult i32 %10323, %10317
  %10326 = icmp ult i32 %10323, %10322
  %10327 = or i1 %10325, %10326
  %10328 = zext i1 %10327 to i8
  store i8 %10328, i8* %18, align 1
  %10329 = and i32 %10323, 255
  %10330 = tail call i32 @llvm.ctpop.i32(i32 %10329)
  %10331 = trunc i32 %10330 to i8
  %10332 = and i8 %10331, 1
  %10333 = xor i8 %10332, 1
  store i8 %10333, i8* %19, align 1
  %10334 = xor i32 %10322, %10317
  %10335 = xor i32 %10334, %10323
  %10336 = lshr i32 %10335, 4
  %10337 = trunc i32 %10336 to i8
  %10338 = and i8 %10337, 1
  store i8 %10338, i8* %20, align 1
  %10339 = icmp eq i32 %10323, 0
  %10340 = zext i1 %10339 to i8
  store i8 %10340, i8* %21, align 1
  %10341 = lshr i32 %10323, 31
  %10342 = trunc i32 %10341 to i8
  store i8 %10342, i8* %22, align 1
  %10343 = lshr i32 %10317, 31
  %10344 = lshr i32 %10322, 31
  %10345 = xor i32 %10341, %10343
  %10346 = xor i32 %10341, %10344
  %10347 = add nuw nsw i32 %10345, %10346
  %10348 = icmp eq i32 %10347, 2
  %10349 = zext i1 %10348 to i8
  store i8 %10349, i8* %23, align 1
  %10350 = sext i32 %10323 to i64
  store i64 %10350, i64* %RDX.i1805, align 8
  %10351 = shl nsw i64 %10350, 3
  %10352 = add i64 %10313, %10351
  %10353 = add i64 %10169, 109
  store i64 %10353, i64* %3, align 8
  %10354 = inttoptr i64 %10352 to i64*
  %10355 = load i64, i64* %10354, align 8
  store i64 %10355, i64* %RAX.i1763, align 8
  %10356 = load i64, i64* %RBP.i, align 8
  %10357 = add i64 %10356, -56
  %10358 = add i64 %10169, 113
  store i64 %10358, i64* %3, align 8
  %10359 = inttoptr i64 %10357 to i32*
  %10360 = load i32, i32* %10359, align 4
  %10361 = sext i32 %10360 to i64
  store i64 %10361, i64* %RDX.i1805, align 8
  %10362 = shl nsw i64 %10361, 1
  %10363 = add i64 %10362, %10355
  %10364 = add i64 %10169, 117
  store i64 %10364, i64* %3, align 8
  %10365 = inttoptr i64 %10363 to i16*
  %10366 = load i16, i16* %10365, align 2
  %10367 = zext i16 %10366 to i64
  store i64 %10367, i64* %RSI.i1889, align 8
  %10368 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %10368, i64* %RAX.i1763, align 8
  %10369 = add i64 %10368, 6464
  %10370 = add i64 %10169, 132
  store i64 %10370, i64* %3, align 8
  %10371 = inttoptr i64 %10369 to i64*
  %10372 = load i64, i64* %10371, align 8
  store i64 %10372, i64* %RAX.i1763, align 8
  %10373 = add i64 %10372, 8
  %10374 = add i64 %10169, 136
  store i64 %10374, i64* %3, align 8
  %10375 = inttoptr i64 %10373 to i64*
  %10376 = load i64, i64* %10375, align 8
  store i64 %10376, i64* %RAX.i1763, align 8
  %10377 = add i64 %10356, -496
  %10378 = add i64 %10169, 142
  store i64 %10378, i64* %3, align 8
  %10379 = inttoptr i64 %10377 to i32*
  %10380 = load i32, i32* %10379, align 4
  %10381 = zext i32 %10380 to i64
  store i64 %10381, i64* %RDI.i2141, align 8
  %10382 = add i64 %10356, -60
  %10383 = add i64 %10169, 145
  store i64 %10383, i64* %3, align 8
  %10384 = inttoptr i64 %10382 to i32*
  %10385 = load i32, i32* %10384, align 4
  %10386 = add i32 %10385, %10380
  %10387 = zext i32 %10386 to i64
  store i64 %10387, i64* %RDI.i2141, align 8
  %10388 = icmp ult i32 %10386, %10380
  %10389 = icmp ult i32 %10386, %10385
  %10390 = or i1 %10388, %10389
  %10391 = zext i1 %10390 to i8
  store i8 %10391, i8* %18, align 1
  %10392 = and i32 %10386, 255
  %10393 = tail call i32 @llvm.ctpop.i32(i32 %10392)
  %10394 = trunc i32 %10393 to i8
  %10395 = and i8 %10394, 1
  %10396 = xor i8 %10395, 1
  store i8 %10396, i8* %19, align 1
  %10397 = xor i32 %10385, %10380
  %10398 = xor i32 %10397, %10386
  %10399 = lshr i32 %10398, 4
  %10400 = trunc i32 %10399 to i8
  %10401 = and i8 %10400, 1
  store i8 %10401, i8* %20, align 1
  %10402 = icmp eq i32 %10386, 0
  %10403 = zext i1 %10402 to i8
  store i8 %10403, i8* %21, align 1
  %10404 = lshr i32 %10386, 31
  %10405 = trunc i32 %10404 to i8
  store i8 %10405, i8* %22, align 1
  %10406 = lshr i32 %10380, 31
  %10407 = lshr i32 %10385, 31
  %10408 = xor i32 %10404, %10406
  %10409 = xor i32 %10404, %10407
  %10410 = add nuw nsw i32 %10408, %10409
  %10411 = icmp eq i32 %10410, 2
  %10412 = zext i1 %10411 to i8
  store i8 %10412, i8* %23, align 1
  %10413 = sext i32 %10386 to i64
  store i64 %10413, i64* %RDX.i1805, align 8
  %10414 = shl nsw i64 %10413, 3
  %10415 = add i64 %10376, %10414
  %10416 = add i64 %10169, 152
  store i64 %10416, i64* %3, align 8
  %10417 = inttoptr i64 %10415 to i64*
  %10418 = load i64, i64* %10417, align 8
  store i64 %10418, i64* %RAX.i1763, align 8
  %10419 = add i64 %10169, 156
  store i64 %10419, i64* %3, align 8
  %10420 = load i32, i32* %10359, align 4
  %10421 = sext i32 %10420 to i64
  store i64 %10421, i64* %RDX.i1805, align 8
  %10422 = shl nsw i64 %10421, 1
  %10423 = add i64 %10422, %10418
  %10424 = add i64 %10169, 160
  store i64 %10424, i64* %3, align 8
  %10425 = inttoptr i64 %10423 to i16*
  %10426 = load i16, i16* %10425, align 2
  %10427 = zext i16 %10426 to i64
  store i64 %10427, i64* %RDI.i2141, align 8
  %10428 = zext i16 %10426 to i32
  %10429 = zext i16 %10366 to i32
  %10430 = sub nsw i32 %10429, %10428
  %10431 = zext i32 %10430 to i64
  store i64 %10431, i64* %RSI.i1889, align 8
  %10432 = load i64, i64* %RCX.i1692, align 8
  %10433 = shl i64 %10432, 32
  %10434 = ashr exact i64 %10433, 32
  %10435 = sext i32 %10430 to i64
  %10436 = mul nsw i64 %10435, %10434
  %10437 = trunc i64 %10436 to i32
  %10438 = and i64 %10436, 4294967295
  store i64 %10438, i64* %RCX.i1692, align 8
  %10439 = shl i64 %10436, 32
  %10440 = ashr exact i64 %10439, 32
  %10441 = icmp ne i64 %10440, %10436
  %10442 = zext i1 %10441 to i8
  store i8 %10442, i8* %18, align 1
  %10443 = and i32 %10437, 255
  %10444 = tail call i32 @llvm.ctpop.i32(i32 %10443)
  %10445 = trunc i32 %10444 to i8
  %10446 = and i8 %10445, 1
  %10447 = xor i8 %10446, 1
  store i8 %10447, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  %10448 = lshr i32 %10437, 31
  %10449 = trunc i32 %10448 to i8
  store i8 %10449, i8* %22, align 1
  store i8 %10442, i8* %23, align 1
  %10450 = load i64, i64* %RBP.i, align 8
  %10451 = add i64 %10450, -620
  %10452 = add i64 %10169, 171
  store i64 %10452, i64* %3, align 8
  %10453 = trunc i64 %10436 to i32
  %10454 = inttoptr i64 %10451 to i32*
  %10455 = load i32, i32* %10454, align 4
  %10456 = add i32 %10455, %10453
  %10457 = zext i32 %10456 to i64
  store i64 %10457, i64* %RCX.i1692, align 8
  %10458 = icmp ult i32 %10456, %10453
  %10459 = icmp ult i32 %10456, %10455
  %10460 = or i1 %10458, %10459
  %10461 = zext i1 %10460 to i8
  store i8 %10461, i8* %18, align 1
  %10462 = and i32 %10456, 255
  %10463 = tail call i32 @llvm.ctpop.i32(i32 %10462)
  %10464 = trunc i32 %10463 to i8
  %10465 = and i8 %10464, 1
  %10466 = xor i8 %10465, 1
  store i8 %10466, i8* %19, align 1
  %10467 = xor i32 %10455, %10453
  %10468 = xor i32 %10467, %10456
  %10469 = lshr i32 %10468, 4
  %10470 = trunc i32 %10469 to i8
  %10471 = and i8 %10470, 1
  store i8 %10471, i8* %20, align 1
  %10472 = icmp eq i32 %10456, 0
  %10473 = zext i1 %10472 to i8
  store i8 %10473, i8* %21, align 1
  %10474 = lshr i32 %10456, 31
  %10475 = trunc i32 %10474 to i8
  store i8 %10475, i8* %22, align 1
  %10476 = lshr i32 %10453, 31
  %10477 = lshr i32 %10455, 31
  %10478 = xor i32 %10474, %10476
  %10479 = xor i32 %10474, %10477
  %10480 = add nuw nsw i32 %10478, %10479
  %10481 = icmp eq i32 %10480, 2
  %10482 = zext i1 %10481 to i8
  store i8 %10482, i8* %23, align 1
  %10483 = add i64 %10169, 177
  store i64 %10483, i64* %3, align 8
  store i32 %10456, i32* %10454, align 4
  %10484 = load i64, i64* %RBP.i, align 8
  %10485 = add i64 %10484, -56
  %10486 = load i64, i64* %3, align 8
  %10487 = add i64 %10486, 3
  store i64 %10487, i64* %3, align 8
  %10488 = inttoptr i64 %10485 to i32*
  %10489 = load i32, i32* %10488, align 4
  %10490 = add i32 %10489, 1
  %10491 = zext i32 %10490 to i64
  store i64 %10491, i64* %RAX.i1763, align 8
  %10492 = icmp eq i32 %10489, -1
  %10493 = icmp eq i32 %10490, 0
  %10494 = or i1 %10492, %10493
  %10495 = zext i1 %10494 to i8
  store i8 %10495, i8* %18, align 1
  %10496 = and i32 %10490, 255
  %10497 = tail call i32 @llvm.ctpop.i32(i32 %10496)
  %10498 = trunc i32 %10497 to i8
  %10499 = and i8 %10498, 1
  %10500 = xor i8 %10499, 1
  store i8 %10500, i8* %19, align 1
  %10501 = xor i32 %10490, %10489
  %10502 = lshr i32 %10501, 4
  %10503 = trunc i32 %10502 to i8
  %10504 = and i8 %10503, 1
  store i8 %10504, i8* %20, align 1
  %10505 = zext i1 %10493 to i8
  store i8 %10505, i8* %21, align 1
  %10506 = lshr i32 %10490, 31
  %10507 = trunc i32 %10506 to i8
  store i8 %10507, i8* %22, align 1
  %10508 = lshr i32 %10489, 31
  %10509 = xor i32 %10506, %10508
  %10510 = add nuw nsw i32 %10509, %10506
  %10511 = icmp eq i32 %10510, 2
  %10512 = zext i1 %10511 to i8
  store i8 %10512, i8* %23, align 1
  %10513 = add i64 %10486, 9
  store i64 %10513, i64* %3, align 8
  store i32 %10490, i32* %10488, align 4
  %10514 = load i64, i64* %3, align 8
  %10515 = add i64 %10514, -540
  store i64 %10515, i64* %3, align 8
  br label %block_.L_4a566e

block_.L_4a588f:                                  ; preds = %block_.L_4a566e
  %10516 = add i64 %9524, -60
  %10517 = add i64 %9562, 8
  store i64 %10517, i64* %3, align 8
  %10518 = inttoptr i64 %10516 to i32*
  %10519 = load i32, i32* %10518, align 4
  %10520 = add i32 %10519, 1
  %10521 = zext i32 %10520 to i64
  store i64 %10521, i64* %RAX.i1763, align 8
  %10522 = icmp eq i32 %10519, -1
  %10523 = icmp eq i32 %10520, 0
  %10524 = or i1 %10522, %10523
  %10525 = zext i1 %10524 to i8
  store i8 %10525, i8* %18, align 1
  %10526 = and i32 %10520, 255
  %10527 = tail call i32 @llvm.ctpop.i32(i32 %10526)
  %10528 = trunc i32 %10527 to i8
  %10529 = and i8 %10528, 1
  %10530 = xor i8 %10529, 1
  store i8 %10530, i8* %19, align 1
  %10531 = xor i32 %10520, %10519
  %10532 = lshr i32 %10531, 4
  %10533 = trunc i32 %10532 to i8
  %10534 = and i8 %10533, 1
  store i8 %10534, i8* %20, align 1
  %10535 = zext i1 %10523 to i8
  store i8 %10535, i8* %21, align 1
  %10536 = lshr i32 %10520, 31
  %10537 = trunc i32 %10536 to i8
  store i8 %10537, i8* %22, align 1
  %10538 = lshr i32 %10519, 31
  %10539 = xor i32 %10536, %10538
  %10540 = add nuw nsw i32 %10539, %10536
  %10541 = icmp eq i32 %10540, 2
  %10542 = zext i1 %10541 to i8
  store i8 %10542, i8* %23, align 1
  %10543 = add i64 %9562, 14
  store i64 %10543, i64* %3, align 8
  store i32 %10520, i32* %10518, align 4
  %10544 = load i64, i64* %3, align 8
  %10545 = add i64 %10544, -578
  store i64 %10545, i64* %3, align 8
  br label %block_.L_4a565b

block_.L_4a58a2:                                  ; preds = %block_.L_4a565b
  %10546 = add i64 %9486, -620
  %10547 = add i64 %9514, 8
  store i64 %10547, i64* %3, align 8
  %10548 = inttoptr i64 %10546 to i32*
  %10549 = load i32, i32* %10548, align 4
  %10550 = sitofp i32 %10549 to double
  store double %10550, double* %53, align 1
  %10551 = add i64 %9486, -24
  %10552 = add i64 %9514, 13
  store i64 %10552, i64* %3, align 8
  %10553 = inttoptr i64 %10551 to i64*
  %10554 = load i64, i64* %10553, align 8
  store i64 %10554, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %10555 = add i64 %9486, -616
  %10556 = add i64 %9514, 21
  store i64 %10556, i64* %3, align 8
  %10557 = inttoptr i64 %10555 to i32*
  %10558 = load i32, i32* %10557, align 4
  %10559 = sitofp i32 %10558 to double
  store double %10559, double* %1229, align 1
  %10560 = bitcast i64 %10554 to double
  %10561 = fmul double %10559, %10560
  store double %10561, double* %36, align 1
  store i64 0, i64* %38, align 1
  %10562 = fadd double %10561, %10550
  store double %10562, double* %53, align 1
  %10563 = add i64 %9486, -472
  %10564 = add i64 %9514, 37
  store i64 %10564, i64* %3, align 8
  %10565 = inttoptr i64 %10563 to double*
  store double %10562, double* %10565, align 8
  %10566 = load i64, i64* %RBP.i, align 8
  %10567 = add i64 %10566, -472
  %10568 = load i64, i64* %3, align 8
  %10569 = add i64 %10568, 8
  store i64 %10569, i64* %3, align 8
  %10570 = inttoptr i64 %10567 to i64*
  %10571 = load i64, i64* %10570, align 8
  store i64 %10571, i64* %54, align 1
  store double 0.000000e+00, double* %1228, align 1
  %10572 = add i64 %10566, -520
  %10573 = add i64 %10568, 16
  store i64 %10573, i64* %3, align 8
  %10574 = inttoptr i64 %10572 to i64*
  %10575 = load i64, i64* %10574, align 8
  store i64 %10575, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %10576 = add i64 %10568, 20
  store i64 %10576, i64* %3, align 8
  %.cast196 = bitcast i64 %10575 to double
  %10577 = bitcast i64 %10571 to double
  %10578 = fcmp uno double %.cast196, %10577
  br i1 %10578, label %10579, label %10589

; <label>:10579:                                  ; preds = %block_.L_4a58a2
  %10580 = fadd double %.cast196, %10577
  %10581 = bitcast double %10580 to i64
  %10582 = and i64 %10581, 9221120237041090560
  %10583 = icmp eq i64 %10582, 9218868437227405312
  %10584 = and i64 %10581, 2251799813685247
  %10585 = icmp ne i64 %10584, 0
  %10586 = and i1 %10583, %10585
  br i1 %10586, label %10587, label %10595

; <label>:10587:                                  ; preds = %10579
  %10588 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %10576, %struct.Memory* %call2_4a4fb6)
  %.pre673 = load i64, i64* %3, align 8
  br label %routine_ucomisd__xmm0___xmm1.exit

; <label>:10589:                                  ; preds = %block_.L_4a58a2
  %10590 = fcmp ogt double %.cast196, %10577
  br i1 %10590, label %10595, label %10591

; <label>:10591:                                  ; preds = %10589
  %10592 = fcmp olt double %.cast196, %10577
  br i1 %10592, label %10595, label %10593

; <label>:10593:                                  ; preds = %10591
  %10594 = fcmp oeq double %.cast196, %10577
  br i1 %10594, label %10595, label %10599

; <label>:10595:                                  ; preds = %10593, %10591, %10589, %10579
  %10596 = phi i8 [ 0, %10589 ], [ 0, %10591 ], [ 1, %10593 ], [ 1, %10579 ]
  %10597 = phi i8 [ 0, %10589 ], [ 0, %10591 ], [ 0, %10593 ], [ 1, %10579 ]
  %10598 = phi i8 [ 0, %10589 ], [ 1, %10591 ], [ 0, %10593 ], [ 1, %10579 ]
  store i8 %10596, i8* %21, align 1
  store i8 %10597, i8* %19, align 1
  store i8 %10598, i8* %18, align 1
  br label %10599

; <label>:10599:                                  ; preds = %10595, %10593
  store i8 0, i8* %23, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %20, align 1
  br label %routine_ucomisd__xmm0___xmm1.exit

routine_ucomisd__xmm0___xmm1.exit:                ; preds = %10599, %10587
  %10600 = phi i64 [ %.pre673, %10587 ], [ %10576, %10599 ]
  %10601 = phi %struct.Memory* [ %10588, %10587 ], [ %call2_4a4fb6, %10599 ]
  %10602 = add i64 %10600, 1570
  %10603 = add i64 %10600, 6
  %10604 = load i8, i8* %18, align 1
  %10605 = load i8, i8* %21, align 1
  %10606 = or i8 %10605, %10604
  %10607 = icmp ne i8 %10606, 0
  %10608 = select i1 %10607, i64 %10602, i64 %10603
  store i64 %10608, i64* %3, align 8
  br i1 %10607, label %block_.L_4a5efd, label %block_4a58e1

block_4a58e1:                                     ; preds = %routine_ucomisd__xmm0___xmm1.exit
  %10609 = load i64, i64* %RBP.i, align 8
  %10610 = add i64 %10609, -48
  %10611 = add i64 %10608, 7
  store i64 %10611, i64* %3, align 8
  %10612 = inttoptr i64 %10610 to i32*
  store i32 0, i32* %10612, align 4
  %.pre674 = load i64, i64* %3, align 8
  br label %block_.L_4a58e8

block_.L_4a58e8:                                  ; preds = %block_.L_4a598a, %block_4a58e1
  %10613 = phi i64 [ %10879, %block_.L_4a598a ], [ %.pre674, %block_4a58e1 ]
  %10614 = load i64, i64* %RBP.i, align 8
  %10615 = add i64 %10614, -48
  %10616 = add i64 %10613, 4
  store i64 %10616, i64* %3, align 8
  %10617 = inttoptr i64 %10615 to i32*
  %10618 = load i32, i32* %10617, align 4
  %10619 = add i32 %10618, -2
  %10620 = icmp ult i32 %10618, 2
  %10621 = zext i1 %10620 to i8
  store i8 %10621, i8* %18, align 1
  %10622 = and i32 %10619, 255
  %10623 = tail call i32 @llvm.ctpop.i32(i32 %10622)
  %10624 = trunc i32 %10623 to i8
  %10625 = and i8 %10624, 1
  %10626 = xor i8 %10625, 1
  store i8 %10626, i8* %19, align 1
  %10627 = xor i32 %10619, %10618
  %10628 = lshr i32 %10627, 4
  %10629 = trunc i32 %10628 to i8
  %10630 = and i8 %10629, 1
  store i8 %10630, i8* %20, align 1
  %10631 = icmp eq i32 %10619, 0
  %10632 = zext i1 %10631 to i8
  store i8 %10632, i8* %21, align 1
  %10633 = lshr i32 %10619, 31
  %10634 = trunc i32 %10633 to i8
  store i8 %10634, i8* %22, align 1
  %10635 = lshr i32 %10618, 31
  %10636 = xor i32 %10633, %10635
  %10637 = add nuw nsw i32 %10636, %10635
  %10638 = icmp eq i32 %10637, 2
  %10639 = zext i1 %10638 to i8
  store i8 %10639, i8* %23, align 1
  %10640 = icmp ne i8 %10634, 0
  %10641 = xor i1 %10640, %10638
  %.v851 = select i1 %10641, i64 10, i64 181
  %10642 = add i64 %10613, %.v851
  store i64 %10642, i64* %3, align 8
  br i1 %10641, label %block_4a58f2, label %block_.L_4a599d

block_4a58f2:                                     ; preds = %block_.L_4a58e8
  %10643 = add i64 %10614, -44
  %10644 = add i64 %10642, 7
  store i64 %10644, i64* %3, align 8
  %10645 = inttoptr i64 %10643 to i32*
  store i32 0, i32* %10645, align 4
  %.pre728 = load i64, i64* %3, align 8
  br label %block_.L_4a58f9

block_.L_4a58f9:                                  ; preds = %block_.L_4a5977, %block_4a58f2
  %10646 = phi i64 [ %10849, %block_.L_4a5977 ], [ %.pre728, %block_4a58f2 ]
  %10647 = load i64, i64* %RBP.i, align 8
  %10648 = add i64 %10647, -44
  %10649 = add i64 %10646, 4
  store i64 %10649, i64* %3, align 8
  %10650 = inttoptr i64 %10648 to i32*
  %10651 = load i32, i32* %10650, align 4
  %10652 = add i32 %10651, -65
  %10653 = icmp ult i32 %10651, 65
  %10654 = zext i1 %10653 to i8
  store i8 %10654, i8* %18, align 1
  %10655 = and i32 %10652, 255
  %10656 = tail call i32 @llvm.ctpop.i32(i32 %10655)
  %10657 = trunc i32 %10656 to i8
  %10658 = and i8 %10657, 1
  %10659 = xor i8 %10658, 1
  store i8 %10659, i8* %19, align 1
  %10660 = xor i32 %10652, %10651
  %10661 = lshr i32 %10660, 4
  %10662 = trunc i32 %10661 to i8
  %10663 = and i8 %10662, 1
  store i8 %10663, i8* %20, align 1
  %10664 = icmp eq i32 %10652, 0
  %10665 = zext i1 %10664 to i8
  store i8 %10665, i8* %21, align 1
  %10666 = lshr i32 %10652, 31
  %10667 = trunc i32 %10666 to i8
  store i8 %10667, i8* %22, align 1
  %10668 = lshr i32 %10651, 31
  %10669 = xor i32 %10666, %10668
  %10670 = add nuw nsw i32 %10669, %10668
  %10671 = icmp eq i32 %10670, 2
  %10672 = zext i1 %10671 to i8
  store i8 %10672, i8* %23, align 1
  %10673 = icmp ne i8 %10667, 0
  %10674 = xor i1 %10673, %10671
  %.v798 = select i1 %10674, i64 10, i64 145
  %10675 = add i64 %10646, %.v798
  store i64 %10675, i64* %3, align 8
  br i1 %10674, label %block_4a5903, label %block_.L_4a598a

block_4a5903:                                     ; preds = %block_.L_4a58f9
  %10676 = add i64 %10647, -52
  %10677 = add i64 %10675, 7
  store i64 %10677, i64* %3, align 8
  %10678 = inttoptr i64 %10676 to i32*
  store i32 0, i32* %10678, align 4
  %.pre729 = load i64, i64* %3, align 8
  br label %block_.L_4a590a

block_.L_4a590a:                                  ; preds = %block_4a5914, %block_4a5903
  %10679 = phi i64 [ %10819, %block_4a5914 ], [ %.pre729, %block_4a5903 ]
  %10680 = load i64, i64* %RBP.i, align 8
  %10681 = add i64 %10680, -52
  %10682 = add i64 %10679, 4
  store i64 %10682, i64* %3, align 8
  %10683 = inttoptr i64 %10681 to i32*
  %10684 = load i32, i32* %10683, align 4
  %10685 = add i32 %10684, -4
  %10686 = icmp ult i32 %10684, 4
  %10687 = zext i1 %10686 to i8
  store i8 %10687, i8* %18, align 1
  %10688 = and i32 %10685, 255
  %10689 = tail call i32 @llvm.ctpop.i32(i32 %10688)
  %10690 = trunc i32 %10689 to i8
  %10691 = and i8 %10690, 1
  %10692 = xor i8 %10691, 1
  store i8 %10692, i8* %19, align 1
  %10693 = xor i32 %10685, %10684
  %10694 = lshr i32 %10693, 4
  %10695 = trunc i32 %10694 to i8
  %10696 = and i8 %10695, 1
  store i8 %10696, i8* %20, align 1
  %10697 = icmp eq i32 %10685, 0
  %10698 = zext i1 %10697 to i8
  store i8 %10698, i8* %21, align 1
  %10699 = lshr i32 %10685, 31
  %10700 = trunc i32 %10699 to i8
  store i8 %10700, i8* %22, align 1
  %10701 = lshr i32 %10684, 31
  %10702 = xor i32 %10699, %10701
  %10703 = add nuw nsw i32 %10702, %10701
  %10704 = icmp eq i32 %10703, 2
  %10705 = zext i1 %10704 to i8
  store i8 %10705, i8* %23, align 1
  %10706 = icmp ne i8 %10700, 0
  %10707 = xor i1 %10706, %10704
  %.v799 = select i1 %10707, i64 10, i64 109
  %10708 = add i64 %10679, %.v799
  store i64 %10708, i64* %3, align 8
  br i1 %10707, label %block_4a5914, label %block_.L_4a5977

block_4a5914:                                     ; preds = %block_.L_4a590a
  %10709 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10709, i64* %RAX.i1763, align 8
  %10710 = add i64 %10709, 14136
  %10711 = add i64 %10708, 15
  store i64 %10711, i64* %3, align 8
  %10712 = inttoptr i64 %10710 to i64*
  %10713 = load i64, i64* %10712, align 8
  store i64 %10713, i64* %RAX.i1763, align 8
  %10714 = add i64 %10680, -12
  %10715 = add i64 %10708, 19
  store i64 %10715, i64* %3, align 8
  %10716 = inttoptr i64 %10714 to i32*
  %10717 = load i32, i32* %10716, align 4
  %10718 = sext i32 %10717 to i64
  store i64 %10718, i64* %RCX.i1692, align 8
  %10719 = shl nsw i64 %10718, 3
  %10720 = add i64 %10719, %10713
  %10721 = add i64 %10708, 23
  store i64 %10721, i64* %3, align 8
  %10722 = inttoptr i64 %10720 to i64*
  %10723 = load i64, i64* %10722, align 8
  store i64 %10723, i64* %RAX.i1763, align 8
  %10724 = add i64 %10708, 27
  store i64 %10724, i64* %3, align 8
  %10725 = load i32, i32* %10683, align 4
  %10726 = sext i32 %10725 to i64
  store i64 %10726, i64* %RCX.i1692, align 8
  %10727 = shl nsw i64 %10726, 3
  %10728 = add i64 %10727, %10723
  %10729 = add i64 %10708, 31
  store i64 %10729, i64* %3, align 8
  %10730 = inttoptr i64 %10728 to i64*
  %10731 = load i64, i64* %10730, align 8
  store i64 %10731, i64* %RAX.i1763, align 8
  %10732 = add i64 %10680, -48
  %10733 = add i64 %10708, 35
  store i64 %10733, i64* %3, align 8
  %10734 = inttoptr i64 %10732 to i32*
  %10735 = load i32, i32* %10734, align 4
  %10736 = sext i32 %10735 to i64
  store i64 %10736, i64* %RCX.i1692, align 8
  %10737 = shl nsw i64 %10736, 3
  %10738 = add i64 %10737, %10731
  %10739 = add i64 %10708, 39
  store i64 %10739, i64* %3, align 8
  %10740 = inttoptr i64 %10738 to i64*
  %10741 = load i64, i64* %10740, align 8
  store i64 %10741, i64* %RAX.i1763, align 8
  %10742 = add i64 %10680, -44
  %10743 = add i64 %10708, 43
  store i64 %10743, i64* %3, align 8
  %10744 = inttoptr i64 %10742 to i32*
  %10745 = load i32, i32* %10744, align 4
  %10746 = sext i32 %10745 to i64
  store i64 %10746, i64* %RCX.i1692, align 8
  %10747 = shl nsw i64 %10746, 2
  %10748 = add i64 %10747, %10741
  %10749 = add i64 %10708, 46
  store i64 %10749, i64* %3, align 8
  %10750 = inttoptr i64 %10748 to i32*
  %10751 = load i32, i32* %10750, align 4
  %10752 = zext i32 %10751 to i64
  store i64 %10752, i64* %RDX.i1805, align 8
  %10753 = load i64, i64* bitcast (%G_0x6cc5f8_type* @G_0x6cc5f8 to i64*), align 8
  store i64 %10753, i64* %RAX.i1763, align 8
  %10754 = add i64 %10708, 58
  store i64 %10754, i64* %3, align 8
  %10755 = load i32, i32* %10716, align 4
  %10756 = sext i32 %10755 to i64
  store i64 %10756, i64* %RCX.i1692, align 8
  %10757 = shl nsw i64 %10756, 3
  %10758 = add i64 %10757, %10753
  %10759 = add i64 %10708, 62
  store i64 %10759, i64* %3, align 8
  %10760 = inttoptr i64 %10758 to i64*
  %10761 = load i64, i64* %10760, align 8
  store i64 %10761, i64* %RAX.i1763, align 8
  %10762 = add i64 %10708, 66
  store i64 %10762, i64* %3, align 8
  %10763 = load i32, i32* %10683, align 4
  %10764 = sext i32 %10763 to i64
  store i64 %10764, i64* %RCX.i1692, align 8
  %10765 = shl nsw i64 %10764, 3
  %10766 = add i64 %10765, %10761
  %10767 = add i64 %10708, 70
  store i64 %10767, i64* %3, align 8
  %10768 = inttoptr i64 %10766 to i64*
  %10769 = load i64, i64* %10768, align 8
  store i64 %10769, i64* %RAX.i1763, align 8
  %10770 = add i64 %10708, 74
  store i64 %10770, i64* %3, align 8
  %10771 = load i32, i32* %10734, align 4
  %10772 = sext i32 %10771 to i64
  store i64 %10772, i64* %RCX.i1692, align 8
  %10773 = shl nsw i64 %10772, 3
  %10774 = add i64 %10773, %10769
  %10775 = add i64 %10708, 78
  store i64 %10775, i64* %3, align 8
  %10776 = inttoptr i64 %10774 to i64*
  %10777 = load i64, i64* %10776, align 8
  store i64 %10777, i64* %RAX.i1763, align 8
  %10778 = load i64, i64* %RBP.i, align 8
  %10779 = add i64 %10778, -44
  %10780 = add i64 %10708, 82
  store i64 %10780, i64* %3, align 8
  %10781 = inttoptr i64 %10779 to i32*
  %10782 = load i32, i32* %10781, align 4
  %10783 = sext i32 %10782 to i64
  store i64 %10783, i64* %RCX.i1692, align 8
  %10784 = shl nsw i64 %10783, 2
  %10785 = add i64 %10784, %10777
  %10786 = add i64 %10708, 85
  store i64 %10786, i64* %3, align 8
  %10787 = inttoptr i64 %10785 to i32*
  store i32 %10751, i32* %10787, align 4
  %10788 = load i64, i64* %RBP.i, align 8
  %10789 = add i64 %10788, -52
  %10790 = load i64, i64* %3, align 8
  %10791 = add i64 %10790, 3
  store i64 %10791, i64* %3, align 8
  %10792 = inttoptr i64 %10789 to i32*
  %10793 = load i32, i32* %10792, align 4
  %10794 = add i32 %10793, 1
  %10795 = zext i32 %10794 to i64
  store i64 %10795, i64* %RAX.i1763, align 8
  %10796 = icmp eq i32 %10793, -1
  %10797 = icmp eq i32 %10794, 0
  %10798 = or i1 %10796, %10797
  %10799 = zext i1 %10798 to i8
  store i8 %10799, i8* %18, align 1
  %10800 = and i32 %10794, 255
  %10801 = tail call i32 @llvm.ctpop.i32(i32 %10800)
  %10802 = trunc i32 %10801 to i8
  %10803 = and i8 %10802, 1
  %10804 = xor i8 %10803, 1
  store i8 %10804, i8* %19, align 1
  %10805 = xor i32 %10794, %10793
  %10806 = lshr i32 %10805, 4
  %10807 = trunc i32 %10806 to i8
  %10808 = and i8 %10807, 1
  store i8 %10808, i8* %20, align 1
  %10809 = zext i1 %10797 to i8
  store i8 %10809, i8* %21, align 1
  %10810 = lshr i32 %10794, 31
  %10811 = trunc i32 %10810 to i8
  store i8 %10811, i8* %22, align 1
  %10812 = lshr i32 %10793, 31
  %10813 = xor i32 %10810, %10812
  %10814 = add nuw nsw i32 %10813, %10810
  %10815 = icmp eq i32 %10814, 2
  %10816 = zext i1 %10815 to i8
  store i8 %10816, i8* %23, align 1
  %10817 = add i64 %10790, 9
  store i64 %10817, i64* %3, align 8
  store i32 %10794, i32* %10792, align 4
  %10818 = load i64, i64* %3, align 8
  %10819 = add i64 %10818, -104
  store i64 %10819, i64* %3, align 8
  br label %block_.L_4a590a

block_.L_4a5977:                                  ; preds = %block_.L_4a590a
  %10820 = add i64 %10680, -44
  %10821 = add i64 %10708, 8
  store i64 %10821, i64* %3, align 8
  %10822 = inttoptr i64 %10820 to i32*
  %10823 = load i32, i32* %10822, align 4
  %10824 = add i32 %10823, 1
  %10825 = zext i32 %10824 to i64
  store i64 %10825, i64* %RAX.i1763, align 8
  %10826 = icmp eq i32 %10823, -1
  %10827 = icmp eq i32 %10824, 0
  %10828 = or i1 %10826, %10827
  %10829 = zext i1 %10828 to i8
  store i8 %10829, i8* %18, align 1
  %10830 = and i32 %10824, 255
  %10831 = tail call i32 @llvm.ctpop.i32(i32 %10830)
  %10832 = trunc i32 %10831 to i8
  %10833 = and i8 %10832, 1
  %10834 = xor i8 %10833, 1
  store i8 %10834, i8* %19, align 1
  %10835 = xor i32 %10824, %10823
  %10836 = lshr i32 %10835, 4
  %10837 = trunc i32 %10836 to i8
  %10838 = and i8 %10837, 1
  store i8 %10838, i8* %20, align 1
  %10839 = zext i1 %10827 to i8
  store i8 %10839, i8* %21, align 1
  %10840 = lshr i32 %10824, 31
  %10841 = trunc i32 %10840 to i8
  store i8 %10841, i8* %22, align 1
  %10842 = lshr i32 %10823, 31
  %10843 = xor i32 %10840, %10842
  %10844 = add nuw nsw i32 %10843, %10840
  %10845 = icmp eq i32 %10844, 2
  %10846 = zext i1 %10845 to i8
  store i8 %10846, i8* %23, align 1
  %10847 = add i64 %10708, 14
  store i64 %10847, i64* %3, align 8
  store i32 %10824, i32* %10822, align 4
  %10848 = load i64, i64* %3, align 8
  %10849 = add i64 %10848, -140
  store i64 %10849, i64* %3, align 8
  br label %block_.L_4a58f9

block_.L_4a598a:                                  ; preds = %block_.L_4a58f9
  %10850 = add i64 %10647, -48
  %10851 = add i64 %10675, 8
  store i64 %10851, i64* %3, align 8
  %10852 = inttoptr i64 %10850 to i32*
  %10853 = load i32, i32* %10852, align 4
  %10854 = add i32 %10853, 1
  %10855 = zext i32 %10854 to i64
  store i64 %10855, i64* %RAX.i1763, align 8
  %10856 = icmp eq i32 %10853, -1
  %10857 = icmp eq i32 %10854, 0
  %10858 = or i1 %10856, %10857
  %10859 = zext i1 %10858 to i8
  store i8 %10859, i8* %18, align 1
  %10860 = and i32 %10854, 255
  %10861 = tail call i32 @llvm.ctpop.i32(i32 %10860)
  %10862 = trunc i32 %10861 to i8
  %10863 = and i8 %10862, 1
  %10864 = xor i8 %10863, 1
  store i8 %10864, i8* %19, align 1
  %10865 = xor i32 %10854, %10853
  %10866 = lshr i32 %10865, 4
  %10867 = trunc i32 %10866 to i8
  %10868 = and i8 %10867, 1
  store i8 %10868, i8* %20, align 1
  %10869 = zext i1 %10857 to i8
  store i8 %10869, i8* %21, align 1
  %10870 = lshr i32 %10854, 31
  %10871 = trunc i32 %10870 to i8
  store i8 %10871, i8* %22, align 1
  %10872 = lshr i32 %10853, 31
  %10873 = xor i32 %10870, %10872
  %10874 = add nuw nsw i32 %10873, %10870
  %10875 = icmp eq i32 %10874, 2
  %10876 = zext i1 %10875 to i8
  store i8 %10876, i8* %23, align 1
  %10877 = add i64 %10675, 14
  store i64 %10877, i64* %3, align 8
  store i32 %10854, i32* %10852, align 4
  %10878 = load i64, i64* %3, align 8
  %10879 = add i64 %10878, -176
  store i64 %10879, i64* %3, align 8
  br label %block_.L_4a58e8

block_.L_4a599d:                                  ; preds = %block_.L_4a58e8
  %10880 = add i64 %10614, -628
  %10881 = add i64 %10642, 10
  store i64 %10881, i64* %3, align 8
  %10882 = inttoptr i64 %10880 to i32*
  store i32 0, i32* %10882, align 4
  %.pre675 = load i64, i64* %3, align 8
  br label %block_.L_4a59a7

block_.L_4a59a7:                                  ; preds = %block_.L_4a5e3c, %block_.L_4a599d
  %10883 = phi i64 [ %.pre675, %block_.L_4a599d ], [ %13165, %block_.L_4a5e3c ]
  %MEMORY.59 = phi %struct.Memory* [ %10601, %block_.L_4a599d ], [ %MEMORY.64, %block_.L_4a5e3c ]
  %10884 = load i64, i64* %RBP.i, align 8
  %10885 = add i64 %10884, -628
  %10886 = add i64 %10883, 7
  store i64 %10886, i64* %3, align 8
  %10887 = inttoptr i64 %10885 to i32*
  %10888 = load i32, i32* %10887, align 4
  %10889 = add i32 %10888, -4
  %10890 = icmp ult i32 %10888, 4
  %10891 = zext i1 %10890 to i8
  store i8 %10891, i8* %18, align 1
  %10892 = and i32 %10889, 255
  %10893 = tail call i32 @llvm.ctpop.i32(i32 %10892)
  %10894 = trunc i32 %10893 to i8
  %10895 = and i8 %10894, 1
  %10896 = xor i8 %10895, 1
  store i8 %10896, i8* %19, align 1
  %10897 = xor i32 %10889, %10888
  %10898 = lshr i32 %10897, 4
  %10899 = trunc i32 %10898 to i8
  %10900 = and i8 %10899, 1
  store i8 %10900, i8* %20, align 1
  %10901 = icmp eq i32 %10889, 0
  %10902 = zext i1 %10901 to i8
  store i8 %10902, i8* %21, align 1
  %10903 = lshr i32 %10889, 31
  %10904 = trunc i32 %10903 to i8
  store i8 %10904, i8* %22, align 1
  %10905 = lshr i32 %10888, 31
  %10906 = xor i32 %10903, %10905
  %10907 = add nuw nsw i32 %10906, %10905
  %10908 = icmp eq i32 %10907, 2
  %10909 = zext i1 %10908 to i8
  store i8 %10909, i8* %23, align 1
  %10910 = icmp ne i8 %10904, 0
  %10911 = xor i1 %10910, %10908
  %.v852 = select i1 %10911, i64 13, i64 1198
  %10912 = add i64 %10883, %.v852
  store i64 %10912, i64* %3, align 8
  br i1 %10911, label %block_4a59b4, label %block_.L_4a5e55

block_4a59b4:                                     ; preds = %block_.L_4a59a7
  store i64 2, i64* %RAX.i1763, align 8
  %10913 = add i64 %10912, 11
  store i64 %10913, i64* %3, align 8
  %10914 = load i32, i32* %10887, align 4
  %10915 = zext i32 %10914 to i64
  store i64 %10915, i64* %RCX.i1692, align 8
  %10916 = add i64 %10884, -1272
  %10917 = add i64 %10912, 17
  store i64 %10917, i64* %3, align 8
  %10918 = inttoptr i64 %10916 to i32*
  store i32 2, i32* %10918, align 4
  %10919 = load i32, i32* %ECX.i7699, align 4
  %10920 = zext i32 %10919 to i64
  %10921 = load i64, i64* %3, align 8
  store i64 %10920, i64* %RAX.i1763, align 8
  %10922 = sext i32 %10919 to i64
  %10923 = lshr i64 %10922, 32
  store i64 %10923, i64* %101, align 8
  %10924 = load i64, i64* %RBP.i, align 8
  %10925 = add i64 %10924, -1272
  %10926 = add i64 %10921, 9
  store i64 %10926, i64* %3, align 8
  %10927 = inttoptr i64 %10925 to i32*
  %10928 = load i32, i32* %10927, align 4
  %10929 = zext i32 %10928 to i64
  store i64 %10929, i64* %RCX.i1692, align 8
  %10930 = add i64 %10921, 11
  store i64 %10930, i64* %3, align 8
  %10931 = sext i32 %10928 to i64
  %10932 = shl nuw i64 %10923, 32
  %10933 = or i64 %10932, %10920
  %10934 = sdiv i64 %10933, %10931
  %10935 = shl i64 %10934, 32
  %10936 = ashr exact i64 %10935, 32
  %10937 = icmp eq i64 %10934, %10936
  br i1 %10937, label %10940, label %10938

; <label>:10938:                                  ; preds = %block_4a59b4
  %10939 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %10930, %struct.Memory* %MEMORY.59)
  %.pre678 = load i64, i64* %RDX.i1805, align 8
  %.pre679 = load i64, i64* %3, align 8
  %.pre680 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit4317

; <label>:10940:                                  ; preds = %block_4a59b4
  %10941 = srem i64 %10933, %10931
  %10942 = and i64 %10934, 4294967295
  store i64 %10942, i64* %RAX.i1763, align 8
  %10943 = and i64 %10941, 4294967295
  store i64 %10943, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__ecx.exit4317

routine_idivl__ecx.exit4317:                      ; preds = %10940, %10938
  %10944 = phi i64 [ %.pre680, %10938 ], [ %10924, %10940 ]
  %10945 = phi i64 [ %.pre679, %10938 ], [ %10930, %10940 ]
  %10946 = phi i64 [ %.pre678, %10938 ], [ %10943, %10940 ]
  %10947 = phi %struct.Memory* [ %10939, %10938 ], [ %MEMORY.59, %10940 ]
  %.tr197 = trunc i64 %10946 to i32
  %10948 = shl i32 %.tr197, 2
  %10949 = zext i32 %10948 to i64
  store i64 %10949, i64* %RDX.i1805, align 8
  %10950 = lshr i64 %10946, 30
  %10951 = trunc i64 %10950 to i8
  %10952 = and i8 %10951, 1
  store i8 %10952, i8* %18, align 1
  %10953 = and i32 %10948, 252
  %10954 = tail call i32 @llvm.ctpop.i32(i32 %10953)
  %10955 = trunc i32 %10954 to i8
  %10956 = and i8 %10955, 1
  %10957 = xor i8 %10956, 1
  store i8 %10957, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %10958 = icmp eq i32 %10948, 0
  %10959 = zext i1 %10958 to i8
  store i8 %10959, i8* %21, align 1
  %10960 = lshr i32 %.tr197, 29
  %10961 = trunc i32 %10960 to i8
  %10962 = and i8 %10961, 1
  store i8 %10962, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %10963 = add i64 %10944, -476
  %10964 = add i64 %10945, 9
  store i64 %10964, i64* %3, align 8
  %10965 = inttoptr i64 %10963 to i32*
  store i32 %10948, i32* %10965, align 4
  %10966 = load i64, i64* %RBP.i, align 8
  %10967 = add i64 %10966, -628
  %10968 = load i64, i64* %3, align 8
  %10969 = add i64 %10968, 6
  store i64 %10969, i64* %3, align 8
  %10970 = inttoptr i64 %10967 to i32*
  %10971 = load i32, i32* %10970, align 4
  %10972 = zext i32 %10971 to i64
  store i64 %10972, i64* %RAX.i1763, align 8
  %10973 = sext i32 %10971 to i64
  %10974 = lshr i64 %10973, 32
  store i64 %10974, i64* %101, align 8
  %10975 = load i32, i32* %ECX.i7699, align 4
  %10976 = add i64 %10968, 11
  store i64 %10976, i64* %3, align 8
  %10977 = sext i32 %10975 to i64
  %10978 = shl nuw i64 %10974, 32
  %10979 = or i64 %10978, %10972
  %10980 = sdiv i64 %10979, %10977
  %10981 = shl i64 %10980, 32
  %10982 = ashr exact i64 %10981, 32
  %10983 = icmp eq i64 %10980, %10982
  br i1 %10983, label %10986, label %10984

; <label>:10984:                                  ; preds = %routine_idivl__ecx.exit4317
  %10985 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %10976, %struct.Memory* %10947)
  %.pre681 = load i64, i64* %RAX.i1763, align 8
  %.pre682 = load i64, i64* %3, align 8
  %.pre683 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit4301

; <label>:10986:                                  ; preds = %routine_idivl__ecx.exit4317
  %10987 = srem i64 %10979, %10977
  %10988 = and i64 %10980, 4294967295
  store i64 %10988, i64* %RAX.i1763, align 8
  %10989 = and i64 %10987, 4294967295
  store i64 %10989, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__ecx.exit4301

routine_idivl__ecx.exit4301:                      ; preds = %10986, %10984
  %10990 = phi i64 [ %.pre683, %10984 ], [ %10966, %10986 ]
  %10991 = phi i64 [ %.pre682, %10984 ], [ %10976, %10986 ]
  %10992 = phi i64 [ %.pre681, %10984 ], [ %10988, %10986 ]
  %10993 = phi %struct.Memory* [ %10985, %10984 ], [ %10947, %10986 ]
  %.tr200 = trunc i64 %10992 to i32
  %10994 = shl i32 %.tr200, 2
  %10995 = zext i32 %10994 to i64
  store i64 %10995, i64* %RAX.i1763, align 8
  %10996 = lshr i64 %10992, 30
  %10997 = trunc i64 %10996 to i8
  %10998 = and i8 %10997, 1
  store i8 %10998, i8* %18, align 1
  %10999 = and i32 %10994, 252
  %11000 = tail call i32 @llvm.ctpop.i32(i32 %10999)
  %11001 = trunc i32 %11000 to i8
  %11002 = and i8 %11001, 1
  %11003 = xor i8 %11002, 1
  store i8 %11003, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %11004 = icmp eq i32 %10994, 0
  %11005 = zext i1 %11004 to i8
  store i8 %11005, i8* %21, align 1
  %11006 = lshr i32 %.tr200, 29
  %11007 = trunc i32 %11006 to i8
  %11008 = and i8 %11007, 1
  store i8 %11008, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %11009 = add i64 %10990, -480
  %11010 = add i64 %10991, 9
  store i64 %11010, i64* %3, align 8
  %11011 = inttoptr i64 %11009 to i32*
  store i32 %10994, i32* %11011, align 4
  %11012 = load i64, i64* %RBP.i, align 8
  %11013 = add i64 %11012, -48
  %11014 = load i64, i64* %3, align 8
  %11015 = add i64 %11014, 7
  store i64 %11015, i64* %3, align 8
  %11016 = inttoptr i64 %11013 to i32*
  store i32 0, i32* %11016, align 4
  %.pre684 = load i64, i64* %3, align 8
  br label %block_.L_4a59f4

block_.L_4a59f4:                                  ; preds = %block_.L_4a5a80, %routine_idivl__ecx.exit4301
  %11017 = phi i64 [ %11286, %block_.L_4a5a80 ], [ %.pre684, %routine_idivl__ecx.exit4301 ]
  %11018 = load i64, i64* %RBP.i, align 8
  %11019 = add i64 %11018, -48
  %11020 = add i64 %11017, 4
  store i64 %11020, i64* %3, align 8
  %11021 = inttoptr i64 %11019 to i32*
  %11022 = load i32, i32* %11021, align 4
  %11023 = add i32 %11022, -2
  %11024 = icmp ult i32 %11022, 2
  %11025 = zext i1 %11024 to i8
  store i8 %11025, i8* %18, align 1
  %11026 = and i32 %11023, 255
  %11027 = tail call i32 @llvm.ctpop.i32(i32 %11026)
  %11028 = trunc i32 %11027 to i8
  %11029 = and i8 %11028, 1
  %11030 = xor i8 %11029, 1
  store i8 %11030, i8* %19, align 1
  %11031 = xor i32 %11023, %11022
  %11032 = lshr i32 %11031, 4
  %11033 = trunc i32 %11032 to i8
  %11034 = and i8 %11033, 1
  store i8 %11034, i8* %20, align 1
  %11035 = icmp eq i32 %11023, 0
  %11036 = zext i1 %11035 to i8
  store i8 %11036, i8* %21, align 1
  %11037 = lshr i32 %11023, 31
  %11038 = trunc i32 %11037 to i8
  store i8 %11038, i8* %22, align 1
  %11039 = lshr i32 %11022, 31
  %11040 = xor i32 %11037, %11039
  %11041 = add nuw nsw i32 %11040, %11039
  %11042 = icmp eq i32 %11041, 2
  %11043 = zext i1 %11042 to i8
  store i8 %11043, i8* %23, align 1
  %11044 = icmp ne i8 %11038, 0
  %11045 = xor i1 %11044, %11042
  %.v854 = select i1 %11045, i64 10, i64 159
  %11046 = add i64 %11017, %.v854
  store i64 %11046, i64* %3, align 8
  br i1 %11045, label %block_4a59fe, label %block_.L_4a5a93

block_4a59fe:                                     ; preds = %block_.L_4a59f4
  %11047 = add i64 %11018, -44
  %11048 = add i64 %11046, 7
  store i64 %11048, i64* %3, align 8
  %11049 = inttoptr i64 %11047 to i32*
  store i32 0, i32* %11049, align 4
  %.pre727 = load i64, i64* %3, align 8
  br label %block_.L_4a5a05

block_.L_4a5a05:                                  ; preds = %block_4a5a0f, %block_4a59fe
  %11050 = phi i64 [ %11256, %block_4a5a0f ], [ %.pre727, %block_4a59fe ]
  %11051 = load i64, i64* %RBP.i, align 8
  %11052 = add i64 %11051, -44
  %11053 = add i64 %11050, 4
  store i64 %11053, i64* %3, align 8
  %11054 = inttoptr i64 %11052 to i32*
  %11055 = load i32, i32* %11054, align 4
  %11056 = add i32 %11055, -18
  %11057 = icmp ult i32 %11055, 18
  %11058 = zext i1 %11057 to i8
  store i8 %11058, i8* %18, align 1
  %11059 = and i32 %11056, 255
  %11060 = tail call i32 @llvm.ctpop.i32(i32 %11059)
  %11061 = trunc i32 %11060 to i8
  %11062 = and i8 %11061, 1
  %11063 = xor i8 %11062, 1
  store i8 %11063, i8* %19, align 1
  %11064 = xor i32 %11055, 16
  %11065 = xor i32 %11064, %11056
  %11066 = lshr i32 %11065, 4
  %11067 = trunc i32 %11066 to i8
  %11068 = and i8 %11067, 1
  store i8 %11068, i8* %20, align 1
  %11069 = icmp eq i32 %11056, 0
  %11070 = zext i1 %11069 to i8
  store i8 %11070, i8* %21, align 1
  %11071 = lshr i32 %11056, 31
  %11072 = trunc i32 %11071 to i8
  store i8 %11072, i8* %22, align 1
  %11073 = lshr i32 %11055, 31
  %11074 = xor i32 %11071, %11073
  %11075 = add nuw nsw i32 %11074, %11073
  %11076 = icmp eq i32 %11075, 2
  %11077 = zext i1 %11076 to i8
  store i8 %11077, i8* %23, align 1
  %11078 = icmp ne i8 %11072, 0
  %11079 = xor i1 %11078, %11076
  %.v797 = select i1 %11079, i64 10, i64 123
  %11080 = add i64 %11050, %.v797
  store i64 %11080, i64* %3, align 8
  br i1 %11079, label %block_4a5a0f, label %block_.L_4a5a80

block_4a5a0f:                                     ; preds = %block_.L_4a5a05
  store i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64* %RAX.i1763, align 8
  %11081 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %11081, i64* %RCX.i1692, align 8
  %11082 = add i64 %11081, 14136
  %11083 = add i64 %11080, 25
  store i64 %11083, i64* %3, align 8
  %11084 = inttoptr i64 %11082 to i64*
  %11085 = load i64, i64* %11084, align 8
  store i64 %11085, i64* %RCX.i1692, align 8
  %11086 = add i64 %11051, -12
  %11087 = add i64 %11080, 28
  store i64 %11087, i64* %3, align 8
  %11088 = inttoptr i64 %11086 to i32*
  %11089 = load i32, i32* %11088, align 4
  %11090 = add i32 %11089, 4
  %11091 = zext i32 %11090 to i64
  store i64 %11091, i64* %RDX.i1805, align 8
  %11092 = icmp ugt i32 %11089, -5
  %11093 = zext i1 %11092 to i8
  store i8 %11093, i8* %18, align 1
  %11094 = and i32 %11090, 255
  %11095 = tail call i32 @llvm.ctpop.i32(i32 %11094)
  %11096 = trunc i32 %11095 to i8
  %11097 = and i8 %11096, 1
  %11098 = xor i8 %11097, 1
  store i8 %11098, i8* %19, align 1
  %11099 = xor i32 %11090, %11089
  %11100 = lshr i32 %11099, 4
  %11101 = trunc i32 %11100 to i8
  %11102 = and i8 %11101, 1
  store i8 %11102, i8* %20, align 1
  %11103 = icmp eq i32 %11090, 0
  %11104 = zext i1 %11103 to i8
  store i8 %11104, i8* %21, align 1
  %11105 = lshr i32 %11090, 31
  %11106 = trunc i32 %11105 to i8
  store i8 %11106, i8* %22, align 1
  %11107 = lshr i32 %11089, 31
  %11108 = xor i32 %11105, %11107
  %11109 = add nuw nsw i32 %11108, %11105
  %11110 = icmp eq i32 %11109, 2
  %11111 = zext i1 %11110 to i8
  store i8 %11111, i8* %23, align 1
  %11112 = sext i32 %11090 to i64
  store i64 %11112, i64* %RSI.i1889, align 8
  %11113 = shl nsw i64 %11112, 3
  %11114 = add i64 %11085, %11113
  %11115 = add i64 %11080, 38
  store i64 %11115, i64* %3, align 8
  %11116 = inttoptr i64 %11114 to i64*
  %11117 = load i64, i64* %11116, align 8
  store i64 %11117, i64* %RCX.i1692, align 8
  %11118 = add i64 %11051, -628
  %11119 = add i64 %11080, 45
  store i64 %11119, i64* %3, align 8
  %11120 = inttoptr i64 %11118 to i32*
  %11121 = load i32, i32* %11120, align 4
  %11122 = sext i32 %11121 to i64
  store i64 %11122, i64* %RSI.i1889, align 8
  %11123 = shl nsw i64 %11122, 3
  %11124 = add i64 %11123, %11117
  %11125 = add i64 %11080, 49
  store i64 %11125, i64* %3, align 8
  %11126 = inttoptr i64 %11124 to i64*
  %11127 = load i64, i64* %11126, align 8
  store i64 %11127, i64* %RCX.i1692, align 8
  %11128 = add i64 %11051, -48
  %11129 = add i64 %11080, 53
  store i64 %11129, i64* %3, align 8
  %11130 = inttoptr i64 %11128 to i32*
  %11131 = load i32, i32* %11130, align 4
  %11132 = sext i32 %11131 to i64
  store i64 %11132, i64* %RSI.i1889, align 8
  %11133 = shl nsw i64 %11132, 3
  %11134 = add i64 %11133, %11127
  %11135 = add i64 %11080, 57
  store i64 %11135, i64* %3, align 8
  %11136 = inttoptr i64 %11134 to i64*
  %11137 = load i64, i64* %11136, align 8
  store i64 %11137, i64* %RCX.i1692, align 8
  %11138 = add i64 %11080, 61
  store i64 %11138, i64* %3, align 8
  %11139 = load i32, i32* %11054, align 4
  %11140 = sext i32 %11139 to i64
  store i64 %11140, i64* %RSI.i1889, align 8
  %11141 = shl nsw i64 %11140, 2
  %11142 = add i64 %11141, %11137
  %11143 = add i64 %11080, 64
  store i64 %11143, i64* %3, align 8
  %11144 = inttoptr i64 %11142 to i32*
  %11145 = load i32, i32* %11144, align 4
  %11146 = zext i32 %11145 to i64
  store i64 %11146, i64* %RDX.i1805, align 8
  %11147 = load i64, i64* %RBP.i, align 8
  %11148 = add i64 %11147, -628
  %11149 = add i64 %11080, 71
  store i64 %11149, i64* %3, align 8
  %11150 = inttoptr i64 %11148 to i32*
  %11151 = load i32, i32* %11150, align 4
  %11152 = sext i32 %11151 to i64
  %11153 = mul nsw i64 %11152, 144
  store i64 %11153, i64* %RCX.i1692, align 8
  %11154 = lshr i64 %11153, 63
  %11155 = load i64, i64* %RAX.i1763, align 8
  %11156 = add i64 %11153, %11155
  store i64 %11156, i64* %RAX.i1763, align 8
  %11157 = icmp ult i64 %11156, %11155
  %11158 = icmp ult i64 %11156, %11153
  %11159 = or i1 %11157, %11158
  %11160 = zext i1 %11159 to i8
  store i8 %11160, i8* %18, align 1
  %11161 = trunc i64 %11156 to i32
  %11162 = and i32 %11161, 255
  %11163 = tail call i32 @llvm.ctpop.i32(i32 %11162)
  %11164 = trunc i32 %11163 to i8
  %11165 = and i8 %11164, 1
  %11166 = xor i8 %11165, 1
  store i8 %11166, i8* %19, align 1
  %11167 = xor i64 %11153, %11155
  %11168 = xor i64 %11167, %11156
  %11169 = lshr i64 %11168, 4
  %11170 = trunc i64 %11169 to i8
  %11171 = and i8 %11170, 1
  store i8 %11171, i8* %20, align 1
  %11172 = icmp eq i64 %11156, 0
  %11173 = zext i1 %11172 to i8
  store i8 %11173, i8* %21, align 1
  %11174 = lshr i64 %11156, 63
  %11175 = trunc i64 %11174 to i8
  store i8 %11175, i8* %22, align 1
  %11176 = lshr i64 %11155, 63
  %11177 = xor i64 %11174, %11176
  %11178 = xor i64 %11174, %11154
  %11179 = add nuw nsw i64 %11177, %11178
  %11180 = icmp eq i64 %11179, 2
  %11181 = zext i1 %11180 to i8
  store i8 %11181, i8* %23, align 1
  %11182 = add i64 %11147, -48
  %11183 = add i64 %11080, 85
  store i64 %11183, i64* %3, align 8
  %11184 = inttoptr i64 %11182 to i32*
  %11185 = load i32, i32* %11184, align 4
  %11186 = sext i32 %11185 to i64
  %11187 = mul nsw i64 %11186, 72
  store i64 %11187, i64* %RCX.i1692, align 8
  %11188 = lshr i64 %11187, 63
  %11189 = add i64 %11187, %11156
  store i64 %11189, i64* %RAX.i1763, align 8
  %11190 = icmp ult i64 %11189, %11156
  %11191 = icmp ult i64 %11189, %11187
  %11192 = or i1 %11190, %11191
  %11193 = zext i1 %11192 to i8
  store i8 %11193, i8* %18, align 1
  %11194 = trunc i64 %11189 to i32
  %11195 = and i32 %11194, 255
  %11196 = tail call i32 @llvm.ctpop.i32(i32 %11195)
  %11197 = trunc i32 %11196 to i8
  %11198 = and i8 %11197, 1
  %11199 = xor i8 %11198, 1
  store i8 %11199, i8* %19, align 1
  %11200 = xor i64 %11187, %11156
  %11201 = xor i64 %11200, %11189
  %11202 = lshr i64 %11201, 4
  %11203 = trunc i64 %11202 to i8
  %11204 = and i8 %11203, 1
  store i8 %11204, i8* %20, align 1
  %11205 = icmp eq i64 %11189, 0
  %11206 = zext i1 %11205 to i8
  store i8 %11206, i8* %21, align 1
  %11207 = lshr i64 %11189, 63
  %11208 = trunc i64 %11207 to i8
  store i8 %11208, i8* %22, align 1
  %11209 = xor i64 %11207, %11174
  %11210 = xor i64 %11207, %11188
  %11211 = add nuw nsw i64 %11209, %11210
  %11212 = icmp eq i64 %11211, 2
  %11213 = zext i1 %11212 to i8
  store i8 %11213, i8* %23, align 1
  %11214 = load i64, i64* %RBP.i, align 8
  %11215 = add i64 %11214, -44
  %11216 = add i64 %11080, 96
  store i64 %11216, i64* %3, align 8
  %11217 = inttoptr i64 %11215 to i32*
  %11218 = load i32, i32* %11217, align 4
  %11219 = sext i32 %11218 to i64
  store i64 %11219, i64* %RCX.i1692, align 8
  %11220 = shl nsw i64 %11219, 2
  %11221 = add i64 %11220, %11189
  %11222 = load i32, i32* %EDX.i2206, align 4
  %11223 = add i64 %11080, 99
  store i64 %11223, i64* %3, align 8
  %11224 = inttoptr i64 %11221 to i32*
  store i32 %11222, i32* %11224, align 4
  %11225 = load i64, i64* %RBP.i, align 8
  %11226 = add i64 %11225, -44
  %11227 = load i64, i64* %3, align 8
  %11228 = add i64 %11227, 3
  store i64 %11228, i64* %3, align 8
  %11229 = inttoptr i64 %11226 to i32*
  %11230 = load i32, i32* %11229, align 4
  %11231 = add i32 %11230, 1
  %11232 = zext i32 %11231 to i64
  store i64 %11232, i64* %RAX.i1763, align 8
  %11233 = icmp eq i32 %11230, -1
  %11234 = icmp eq i32 %11231, 0
  %11235 = or i1 %11233, %11234
  %11236 = zext i1 %11235 to i8
  store i8 %11236, i8* %18, align 1
  %11237 = and i32 %11231, 255
  %11238 = tail call i32 @llvm.ctpop.i32(i32 %11237)
  %11239 = trunc i32 %11238 to i8
  %11240 = and i8 %11239, 1
  %11241 = xor i8 %11240, 1
  store i8 %11241, i8* %19, align 1
  %11242 = xor i32 %11231, %11230
  %11243 = lshr i32 %11242, 4
  %11244 = trunc i32 %11243 to i8
  %11245 = and i8 %11244, 1
  store i8 %11245, i8* %20, align 1
  %11246 = zext i1 %11234 to i8
  store i8 %11246, i8* %21, align 1
  %11247 = lshr i32 %11231, 31
  %11248 = trunc i32 %11247 to i8
  store i8 %11248, i8* %22, align 1
  %11249 = lshr i32 %11230, 31
  %11250 = xor i32 %11247, %11249
  %11251 = add nuw nsw i32 %11250, %11247
  %11252 = icmp eq i32 %11251, 2
  %11253 = zext i1 %11252 to i8
  store i8 %11253, i8* %23, align 1
  %11254 = add i64 %11227, 9
  store i64 %11254, i64* %3, align 8
  store i32 %11231, i32* %11229, align 4
  %11255 = load i64, i64* %3, align 8
  %11256 = add i64 %11255, -118
  store i64 %11256, i64* %3, align 8
  br label %block_.L_4a5a05

block_.L_4a5a80:                                  ; preds = %block_.L_4a5a05
  %11257 = add i64 %11051, -48
  %11258 = add i64 %11080, 8
  store i64 %11258, i64* %3, align 8
  %11259 = inttoptr i64 %11257 to i32*
  %11260 = load i32, i32* %11259, align 4
  %11261 = add i32 %11260, 1
  %11262 = zext i32 %11261 to i64
  store i64 %11262, i64* %RAX.i1763, align 8
  %11263 = icmp eq i32 %11260, -1
  %11264 = icmp eq i32 %11261, 0
  %11265 = or i1 %11263, %11264
  %11266 = zext i1 %11265 to i8
  store i8 %11266, i8* %18, align 1
  %11267 = and i32 %11261, 255
  %11268 = tail call i32 @llvm.ctpop.i32(i32 %11267)
  %11269 = trunc i32 %11268 to i8
  %11270 = and i8 %11269, 1
  %11271 = xor i8 %11270, 1
  store i8 %11271, i8* %19, align 1
  %11272 = xor i32 %11261, %11260
  %11273 = lshr i32 %11272, 4
  %11274 = trunc i32 %11273 to i8
  %11275 = and i8 %11274, 1
  store i8 %11275, i8* %20, align 1
  %11276 = zext i1 %11264 to i8
  store i8 %11276, i8* %21, align 1
  %11277 = lshr i32 %11261, 31
  %11278 = trunc i32 %11277 to i8
  store i8 %11278, i8* %22, align 1
  %11279 = lshr i32 %11260, 31
  %11280 = xor i32 %11277, %11279
  %11281 = add nuw nsw i32 %11280, %11277
  %11282 = icmp eq i32 %11281, 2
  %11283 = zext i1 %11282 to i8
  store i8 %11283, i8* %23, align 1
  %11284 = add i64 %11080, 14
  store i64 %11284, i64* %3, align 8
  store i32 %11261, i32* %11259, align 4
  %11285 = load i64, i64* %3, align 8
  %11286 = add i64 %11285, -154
  store i64 %11286, i64* %3, align 8
  br label %block_.L_4a59f4

block_.L_4a5a93:                                  ; preds = %block_.L_4a59f4
  %11287 = add i64 %11046, 7
  store i64 %11287, i64* %3, align 8
  store i32 0, i32* %11021, align 4
  %.pre685 = load i64, i64* %3, align 8
  br label %block_.L_4a5a9a

block_.L_4a5a9a:                                  ; preds = %block_.L_4a5b2c, %block_.L_4a5a93
  %11288 = phi i64 [ %11559, %block_.L_4a5b2c ], [ %.pre685, %block_.L_4a5a93 ]
  %11289 = load i64, i64* %RBP.i, align 8
  %11290 = add i64 %11289, -48
  %11291 = add i64 %11288, 4
  store i64 %11291, i64* %3, align 8
  %11292 = inttoptr i64 %11290 to i32*
  %11293 = load i32, i32* %11292, align 4
  %11294 = add i32 %11293, -2
  %11295 = icmp ult i32 %11293, 2
  %11296 = zext i1 %11295 to i8
  store i8 %11296, i8* %18, align 1
  %11297 = and i32 %11294, 255
  %11298 = tail call i32 @llvm.ctpop.i32(i32 %11297)
  %11299 = trunc i32 %11298 to i8
  %11300 = and i8 %11299, 1
  %11301 = xor i8 %11300, 1
  store i8 %11301, i8* %19, align 1
  %11302 = xor i32 %11294, %11293
  %11303 = lshr i32 %11302, 4
  %11304 = trunc i32 %11303 to i8
  %11305 = and i8 %11304, 1
  store i8 %11305, i8* %20, align 1
  %11306 = icmp eq i32 %11294, 0
  %11307 = zext i1 %11306 to i8
  store i8 %11307, i8* %21, align 1
  %11308 = lshr i32 %11294, 31
  %11309 = trunc i32 %11308 to i8
  store i8 %11309, i8* %22, align 1
  %11310 = lshr i32 %11293, 31
  %11311 = xor i32 %11308, %11310
  %11312 = add nuw nsw i32 %11311, %11310
  %11313 = icmp eq i32 %11312, 2
  %11314 = zext i1 %11313 to i8
  store i8 %11314, i8* %23, align 1
  %11315 = icmp ne i8 %11309, 0
  %11316 = xor i1 %11315, %11313
  %.v793 = select i1 %11316, i64 10, i64 165
  %11317 = add i64 %11288, %.v793
  %11318 = add i64 %11289, -44
  %11319 = add i64 %11317, 7
  store i64 %11319, i64* %3, align 8
  %11320 = inttoptr i64 %11318 to i32*
  store i32 0, i32* %11320, align 4
  %.pre726 = load i64, i64* %3, align 8
  br i1 %11316, label %block_.L_4a5aab.preheader, label %block_.L_4a5b46.preheader

block_.L_4a5b46.preheader:                        ; preds = %block_.L_4a5a9a
  br label %block_.L_4a5b46

block_.L_4a5aab.preheader:                        ; preds = %block_.L_4a5a9a
  br label %block_.L_4a5aab

block_.L_4a5aab:                                  ; preds = %block_.L_4a5aab.preheader, %block_4a5ab5
  %11321 = phi i64 [ %11529, %block_4a5ab5 ], [ %.pre726, %block_.L_4a5aab.preheader ]
  %11322 = load i64, i64* %RBP.i, align 8
  %11323 = add i64 %11322, -44
  %11324 = add i64 %11321, 4
  store i64 %11324, i64* %3, align 8
  %11325 = inttoptr i64 %11323 to i32*
  %11326 = load i32, i32* %11325, align 4
  %11327 = add i32 %11326, -18
  %11328 = icmp ult i32 %11326, 18
  %11329 = zext i1 %11328 to i8
  store i8 %11329, i8* %18, align 1
  %11330 = and i32 %11327, 255
  %11331 = tail call i32 @llvm.ctpop.i32(i32 %11330)
  %11332 = trunc i32 %11331 to i8
  %11333 = and i8 %11332, 1
  %11334 = xor i8 %11333, 1
  store i8 %11334, i8* %19, align 1
  %11335 = xor i32 %11326, 16
  %11336 = xor i32 %11335, %11327
  %11337 = lshr i32 %11336, 4
  %11338 = trunc i32 %11337 to i8
  %11339 = and i8 %11338, 1
  store i8 %11339, i8* %20, align 1
  %11340 = icmp eq i32 %11327, 0
  %11341 = zext i1 %11340 to i8
  store i8 %11341, i8* %21, align 1
  %11342 = lshr i32 %11327, 31
  %11343 = trunc i32 %11342 to i8
  store i8 %11343, i8* %22, align 1
  %11344 = lshr i32 %11326, 31
  %11345 = xor i32 %11342, %11344
  %11346 = add nuw nsw i32 %11345, %11344
  %11347 = icmp eq i32 %11346, 2
  %11348 = zext i1 %11347 to i8
  store i8 %11348, i8* %23, align 1
  %11349 = icmp ne i8 %11343, 0
  %11350 = xor i1 %11349, %11347
  %.v796 = select i1 %11350, i64 10, i64 129
  %11351 = add i64 %11321, %.v796
  store i64 %11351, i64* %3, align 8
  br i1 %11350, label %block_4a5ab5, label %block_.L_4a5b2c

block_4a5ab5:                                     ; preds = %block_.L_4a5aab
  store i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64* %RAX.i1763, align 8
  store i8 zext (i1 or (i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64)), i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 576)) to i8), i8* %18, align 1
  store i8 %1233, i8* %19, align 1
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576)), i64 4) to i8), i8 1), i8* %20, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 0) to i8), i8* %21, align 1
  store i8 trunc (i64 lshr (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 63) to i8), i8* %22, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 63), i64 lshr (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 63)), i64 lshr (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 63)), i64 2) to i8), i8* %23, align 1
  %11352 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %11352, i64* %RCX.i1692, align 8
  %11353 = add i64 %11352, 14136
  %11354 = add i64 %11351, 31
  store i64 %11354, i64* %3, align 8
  %11355 = inttoptr i64 %11353 to i64*
  %11356 = load i64, i64* %11355, align 8
  store i64 %11356, i64* %RCX.i1692, align 8
  %11357 = add i64 %11322, -12
  %11358 = add i64 %11351, 34
  store i64 %11358, i64* %3, align 8
  %11359 = inttoptr i64 %11357 to i32*
  %11360 = load i32, i32* %11359, align 4
  %11361 = add i32 %11360, 8
  %11362 = zext i32 %11361 to i64
  store i64 %11362, i64* %RDX.i1805, align 8
  %11363 = icmp ugt i32 %11360, -9
  %11364 = zext i1 %11363 to i8
  store i8 %11364, i8* %18, align 1
  %11365 = and i32 %11361, 255
  %11366 = tail call i32 @llvm.ctpop.i32(i32 %11365)
  %11367 = trunc i32 %11366 to i8
  %11368 = and i8 %11367, 1
  %11369 = xor i8 %11368, 1
  store i8 %11369, i8* %19, align 1
  %11370 = xor i32 %11361, %11360
  %11371 = lshr i32 %11370, 4
  %11372 = trunc i32 %11371 to i8
  %11373 = and i8 %11372, 1
  store i8 %11373, i8* %20, align 1
  %11374 = icmp eq i32 %11361, 0
  %11375 = zext i1 %11374 to i8
  store i8 %11375, i8* %21, align 1
  %11376 = lshr i32 %11361, 31
  %11377 = trunc i32 %11376 to i8
  store i8 %11377, i8* %22, align 1
  %11378 = lshr i32 %11360, 31
  %11379 = xor i32 %11376, %11378
  %11380 = add nuw nsw i32 %11379, %11376
  %11381 = icmp eq i32 %11380, 2
  %11382 = zext i1 %11381 to i8
  store i8 %11382, i8* %23, align 1
  %11383 = sext i32 %11361 to i64
  store i64 %11383, i64* %RSI.i1889, align 8
  %11384 = shl nsw i64 %11383, 3
  %11385 = add i64 %11356, %11384
  %11386 = add i64 %11351, 44
  store i64 %11386, i64* %3, align 8
  %11387 = inttoptr i64 %11385 to i64*
  %11388 = load i64, i64* %11387, align 8
  store i64 %11388, i64* %RCX.i1692, align 8
  %11389 = add i64 %11322, -628
  %11390 = add i64 %11351, 51
  store i64 %11390, i64* %3, align 8
  %11391 = inttoptr i64 %11389 to i32*
  %11392 = load i32, i32* %11391, align 4
  %11393 = sext i32 %11392 to i64
  store i64 %11393, i64* %RSI.i1889, align 8
  %11394 = shl nsw i64 %11393, 3
  %11395 = add i64 %11394, %11388
  %11396 = add i64 %11351, 55
  store i64 %11396, i64* %3, align 8
  %11397 = inttoptr i64 %11395 to i64*
  %11398 = load i64, i64* %11397, align 8
  store i64 %11398, i64* %RCX.i1692, align 8
  %11399 = add i64 %11322, -48
  %11400 = add i64 %11351, 59
  store i64 %11400, i64* %3, align 8
  %11401 = inttoptr i64 %11399 to i32*
  %11402 = load i32, i32* %11401, align 4
  %11403 = sext i32 %11402 to i64
  store i64 %11403, i64* %RSI.i1889, align 8
  %11404 = shl nsw i64 %11403, 3
  %11405 = add i64 %11404, %11398
  %11406 = add i64 %11351, 63
  store i64 %11406, i64* %3, align 8
  %11407 = inttoptr i64 %11405 to i64*
  %11408 = load i64, i64* %11407, align 8
  store i64 %11408, i64* %RCX.i1692, align 8
  %11409 = load i64, i64* %RBP.i, align 8
  %11410 = add i64 %11409, -44
  %11411 = add i64 %11351, 67
  store i64 %11411, i64* %3, align 8
  %11412 = inttoptr i64 %11410 to i32*
  %11413 = load i32, i32* %11412, align 4
  %11414 = sext i32 %11413 to i64
  store i64 %11414, i64* %RSI.i1889, align 8
  %11415 = shl nsw i64 %11414, 2
  %11416 = add i64 %11415, %11408
  %11417 = add i64 %11351, 70
  store i64 %11417, i64* %3, align 8
  %11418 = inttoptr i64 %11416 to i32*
  %11419 = load i32, i32* %11418, align 4
  %11420 = zext i32 %11419 to i64
  store i64 %11420, i64* %RDX.i1805, align 8
  %11421 = add i64 %11409, -628
  %11422 = add i64 %11351, 77
  store i64 %11422, i64* %3, align 8
  %11423 = inttoptr i64 %11421 to i32*
  %11424 = load i32, i32* %11423, align 4
  %11425 = sext i32 %11424 to i64
  %11426 = mul nsw i64 %11425, 144
  store i64 %11426, i64* %RCX.i1692, align 8
  %11427 = lshr i64 %11426, 63
  %11428 = load i64, i64* %RAX.i1763, align 8
  %11429 = add i64 %11426, %11428
  store i64 %11429, i64* %RAX.i1763, align 8
  %11430 = icmp ult i64 %11429, %11428
  %11431 = icmp ult i64 %11429, %11426
  %11432 = or i1 %11430, %11431
  %11433 = zext i1 %11432 to i8
  store i8 %11433, i8* %18, align 1
  %11434 = trunc i64 %11429 to i32
  %11435 = and i32 %11434, 255
  %11436 = tail call i32 @llvm.ctpop.i32(i32 %11435)
  %11437 = trunc i32 %11436 to i8
  %11438 = and i8 %11437, 1
  %11439 = xor i8 %11438, 1
  store i8 %11439, i8* %19, align 1
  %11440 = xor i64 %11426, %11428
  %11441 = xor i64 %11440, %11429
  %11442 = lshr i64 %11441, 4
  %11443 = trunc i64 %11442 to i8
  %11444 = and i8 %11443, 1
  store i8 %11444, i8* %20, align 1
  %11445 = icmp eq i64 %11429, 0
  %11446 = zext i1 %11445 to i8
  store i8 %11446, i8* %21, align 1
  %11447 = lshr i64 %11429, 63
  %11448 = trunc i64 %11447 to i8
  store i8 %11448, i8* %22, align 1
  %11449 = lshr i64 %11428, 63
  %11450 = xor i64 %11447, %11449
  %11451 = xor i64 %11447, %11427
  %11452 = add nuw nsw i64 %11450, %11451
  %11453 = icmp eq i64 %11452, 2
  %11454 = zext i1 %11453 to i8
  store i8 %11454, i8* %23, align 1
  %11455 = add i64 %11409, -48
  %11456 = add i64 %11351, 91
  store i64 %11456, i64* %3, align 8
  %11457 = inttoptr i64 %11455 to i32*
  %11458 = load i32, i32* %11457, align 4
  %11459 = sext i32 %11458 to i64
  %11460 = mul nsw i64 %11459, 72
  store i64 %11460, i64* %RCX.i1692, align 8
  %11461 = lshr i64 %11460, 63
  %11462 = add i64 %11460, %11429
  store i64 %11462, i64* %RAX.i1763, align 8
  %11463 = icmp ult i64 %11462, %11429
  %11464 = icmp ult i64 %11462, %11460
  %11465 = or i1 %11463, %11464
  %11466 = zext i1 %11465 to i8
  store i8 %11466, i8* %18, align 1
  %11467 = trunc i64 %11462 to i32
  %11468 = and i32 %11467, 255
  %11469 = tail call i32 @llvm.ctpop.i32(i32 %11468)
  %11470 = trunc i32 %11469 to i8
  %11471 = and i8 %11470, 1
  %11472 = xor i8 %11471, 1
  store i8 %11472, i8* %19, align 1
  %11473 = xor i64 %11460, %11429
  %11474 = xor i64 %11473, %11462
  %11475 = lshr i64 %11474, 4
  %11476 = trunc i64 %11475 to i8
  %11477 = and i8 %11476, 1
  store i8 %11477, i8* %20, align 1
  %11478 = icmp eq i64 %11462, 0
  %11479 = zext i1 %11478 to i8
  store i8 %11479, i8* %21, align 1
  %11480 = lshr i64 %11462, 63
  %11481 = trunc i64 %11480 to i8
  store i8 %11481, i8* %22, align 1
  %11482 = xor i64 %11480, %11447
  %11483 = xor i64 %11480, %11461
  %11484 = add nuw nsw i64 %11482, %11483
  %11485 = icmp eq i64 %11484, 2
  %11486 = zext i1 %11485 to i8
  store i8 %11486, i8* %23, align 1
  %11487 = load i64, i64* %RBP.i, align 8
  %11488 = add i64 %11487, -44
  %11489 = add i64 %11351, 102
  store i64 %11489, i64* %3, align 8
  %11490 = inttoptr i64 %11488 to i32*
  %11491 = load i32, i32* %11490, align 4
  %11492 = sext i32 %11491 to i64
  store i64 %11492, i64* %RCX.i1692, align 8
  %11493 = shl nsw i64 %11492, 2
  %11494 = add i64 %11493, %11462
  %11495 = load i32, i32* %EDX.i2206, align 4
  %11496 = add i64 %11351, 105
  store i64 %11496, i64* %3, align 8
  %11497 = inttoptr i64 %11494 to i32*
  store i32 %11495, i32* %11497, align 4
  %11498 = load i64, i64* %RBP.i, align 8
  %11499 = add i64 %11498, -44
  %11500 = load i64, i64* %3, align 8
  %11501 = add i64 %11500, 3
  store i64 %11501, i64* %3, align 8
  %11502 = inttoptr i64 %11499 to i32*
  %11503 = load i32, i32* %11502, align 4
  %11504 = add i32 %11503, 1
  %11505 = zext i32 %11504 to i64
  store i64 %11505, i64* %RAX.i1763, align 8
  %11506 = icmp eq i32 %11503, -1
  %11507 = icmp eq i32 %11504, 0
  %11508 = or i1 %11506, %11507
  %11509 = zext i1 %11508 to i8
  store i8 %11509, i8* %18, align 1
  %11510 = and i32 %11504, 255
  %11511 = tail call i32 @llvm.ctpop.i32(i32 %11510)
  %11512 = trunc i32 %11511 to i8
  %11513 = and i8 %11512, 1
  %11514 = xor i8 %11513, 1
  store i8 %11514, i8* %19, align 1
  %11515 = xor i32 %11504, %11503
  %11516 = lshr i32 %11515, 4
  %11517 = trunc i32 %11516 to i8
  %11518 = and i8 %11517, 1
  store i8 %11518, i8* %20, align 1
  %11519 = zext i1 %11507 to i8
  store i8 %11519, i8* %21, align 1
  %11520 = lshr i32 %11504, 31
  %11521 = trunc i32 %11520 to i8
  store i8 %11521, i8* %22, align 1
  %11522 = lshr i32 %11503, 31
  %11523 = xor i32 %11520, %11522
  %11524 = add nuw nsw i32 %11523, %11520
  %11525 = icmp eq i32 %11524, 2
  %11526 = zext i1 %11525 to i8
  store i8 %11526, i8* %23, align 1
  %11527 = add i64 %11500, 9
  store i64 %11527, i64* %3, align 8
  store i32 %11504, i32* %11502, align 4
  %11528 = load i64, i64* %3, align 8
  %11529 = add i64 %11528, -124
  store i64 %11529, i64* %3, align 8
  br label %block_.L_4a5aab

block_.L_4a5b2c:                                  ; preds = %block_.L_4a5aab
  %11530 = add i64 %11322, -48
  %11531 = add i64 %11351, 8
  store i64 %11531, i64* %3, align 8
  %11532 = inttoptr i64 %11530 to i32*
  %11533 = load i32, i32* %11532, align 4
  %11534 = add i32 %11533, 1
  %11535 = zext i32 %11534 to i64
  store i64 %11535, i64* %RAX.i1763, align 8
  %11536 = icmp eq i32 %11533, -1
  %11537 = icmp eq i32 %11534, 0
  %11538 = or i1 %11536, %11537
  %11539 = zext i1 %11538 to i8
  store i8 %11539, i8* %18, align 1
  %11540 = and i32 %11534, 255
  %11541 = tail call i32 @llvm.ctpop.i32(i32 %11540)
  %11542 = trunc i32 %11541 to i8
  %11543 = and i8 %11542, 1
  %11544 = xor i8 %11543, 1
  store i8 %11544, i8* %19, align 1
  %11545 = xor i32 %11534, %11533
  %11546 = lshr i32 %11545, 4
  %11547 = trunc i32 %11546 to i8
  %11548 = and i8 %11547, 1
  store i8 %11548, i8* %20, align 1
  %11549 = zext i1 %11537 to i8
  store i8 %11549, i8* %21, align 1
  %11550 = lshr i32 %11534, 31
  %11551 = trunc i32 %11550 to i8
  store i8 %11551, i8* %22, align 1
  %11552 = lshr i32 %11533, 31
  %11553 = xor i32 %11550, %11552
  %11554 = add nuw nsw i32 %11553, %11550
  %11555 = icmp eq i32 %11554, 2
  %11556 = zext i1 %11555 to i8
  store i8 %11556, i8* %23, align 1
  %11557 = add i64 %11351, 14
  store i64 %11557, i64* %3, align 8
  store i32 %11534, i32* %11532, align 4
  %11558 = load i64, i64* %3, align 8
  %11559 = add i64 %11558, -160
  store i64 %11559, i64* %3, align 8
  br label %block_.L_4a5a9a

block_.L_4a5b46:                                  ; preds = %block_.L_4a5b46.preheader, %block_.L_4a5e29
  %11560 = phi i64 [ %13135, %block_.L_4a5e29 ], [ %.pre726, %block_.L_4a5b46.preheader ]
  %MEMORY.64 = phi %struct.Memory* [ %12659, %block_.L_4a5e29 ], [ %10993, %block_.L_4a5b46.preheader ]
  %11561 = load i64, i64* %RBP.i, align 8
  %11562 = add i64 %11561, -44
  %11563 = add i64 %11560, 4
  store i64 %11563, i64* %3, align 8
  %11564 = inttoptr i64 %11562 to i32*
  %11565 = load i32, i32* %11564, align 4
  %11566 = add i32 %11565, -2
  %11567 = icmp ult i32 %11565, 2
  %11568 = zext i1 %11567 to i8
  store i8 %11568, i8* %18, align 1
  %11569 = and i32 %11566, 255
  %11570 = tail call i32 @llvm.ctpop.i32(i32 %11569)
  %11571 = trunc i32 %11570 to i8
  %11572 = and i8 %11571, 1
  %11573 = xor i8 %11572, 1
  store i8 %11573, i8* %19, align 1
  %11574 = xor i32 %11566, %11565
  %11575 = lshr i32 %11574, 4
  %11576 = trunc i32 %11575 to i8
  %11577 = and i8 %11576, 1
  store i8 %11577, i8* %20, align 1
  %11578 = icmp eq i32 %11566, 0
  %11579 = zext i1 %11578 to i8
  store i8 %11579, i8* %21, align 1
  %11580 = lshr i32 %11566, 31
  %11581 = trunc i32 %11580 to i8
  store i8 %11581, i8* %22, align 1
  %11582 = lshr i32 %11565, 31
  %11583 = xor i32 %11580, %11582
  %11584 = add nuw nsw i32 %11583, %11582
  %11585 = icmp eq i32 %11584, 2
  %11586 = zext i1 %11585 to i8
  store i8 %11586, i8* %23, align 1
  %11587 = icmp ne i8 %11581, 0
  %11588 = xor i1 %11587, %11585
  %.v855 = select i1 %11588, i64 10, i64 758
  %11589 = add i64 %11560, %.v855
  %11590 = add i64 %11589, 5
  store i64 %11590, i64* %3, align 8
  br i1 %11588, label %block_4a5b50, label %block_.L_4a5e3c

block_4a5b50:                                     ; preds = %block_.L_4a5b46
  store i64 2, i64* %RAX.i1763, align 8
  store i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64* %RCX.i1692, align 8
  store i64 ptrtoint (%G__0x6cd4f0_type* @G__0x6cd4f0 to i64), i64* %RDX.i1805, align 8
  store i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64* %RSI.i1889, align 8
  store i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64* %RDI.i2141, align 8
  %11591 = add i64 %11589, 49
  store i64 %11591, i64* %3, align 8
  %11592 = load i32, i32* %11564, align 4
  %11593 = sext i32 %11592 to i64
  %11594 = shl nsw i64 %11593, 6
  store i64 %11594, i64* %26, align 8
  %11595 = add i64 %11594, ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64)
  store i64 %11595, i64* %RDI.i2141, align 8
  %11596 = icmp ult i64 %11595, ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64)
  %11597 = icmp ult i64 %11595, %11594
  %11598 = or i1 %11596, %11597
  %11599 = zext i1 %11598 to i8
  store i8 %11599, i8* %18, align 1
  %11600 = trunc i64 %11595 to i32
  %11601 = and i32 %11600, 248
  %11602 = tail call i32 @llvm.ctpop.i32(i32 %11601)
  %11603 = trunc i32 %11602 to i8
  %11604 = and i8 %11603, 1
  %11605 = xor i8 %11604, 1
  store i8 %11605, i8* %19, align 1
  %11606 = xor i64 %11595, ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64)
  %11607 = lshr i64 %11606, 4
  %11608 = trunc i64 %11607 to i8
  %11609 = and i8 %11608, 1
  store i8 %11609, i8* %20, align 1
  %11610 = icmp eq i64 %11595, 0
  %11611 = zext i1 %11610 to i8
  store i8 %11611, i8* %21, align 1
  %11612 = lshr i64 %11595, 63
  %11613 = trunc i64 %11612 to i8
  store i8 %11613, i8* %22, align 1
  %11614 = lshr i64 %11593, 57
  %11615 = and i64 %11614, 1
  %11616 = xor i64 %11612, lshr (i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64 63)
  %11617 = xor i64 %11612, %11615
  %11618 = add nuw nsw i64 %11616, %11617
  %11619 = icmp eq i64 %11618, 2
  %11620 = zext i1 %11619 to i8
  store i8 %11620, i8* %23, align 1
  %11621 = add i64 %11561, -12
  %11622 = add i64 %11589, 60
  store i64 %11622, i64* %3, align 8
  %11623 = inttoptr i64 %11621 to i32*
  %11624 = load i32, i32* %11623, align 4
  %11625 = zext i32 %11624 to i64
  store i64 %11625, i64* %R9.i, align 8
  %11626 = add i64 %11561, -1276
  %11627 = add i64 %11589, 66
  store i64 %11627, i64* %3, align 8
  %11628 = inttoptr i64 %11626 to i32*
  store i32 2, i32* %11628, align 4
  %11629 = load i32, i32* %R9D.i6640, align 4
  %11630 = zext i32 %11629 to i64
  %11631 = load i64, i64* %3, align 8
  store i64 %11630, i64* %RAX.i1763, align 8
  %11632 = load i64, i64* %RBP.i, align 8
  %11633 = add i64 %11632, -1288
  %11634 = load i64, i64* %RDX.i1805, align 8
  %11635 = add i64 %11631, 10
  store i64 %11635, i64* %3, align 8
  %11636 = inttoptr i64 %11633 to i64*
  store i64 %11634, i64* %11636, align 8
  %11637 = load i64, i64* %3, align 8
  %11638 = load i32, i32* %EAX.i2159, align 8
  %11639 = sext i32 %11638 to i64
  %11640 = lshr i64 %11639, 32
  store i64 %11640, i64* %101, align 8
  %11641 = load i64, i64* %RBP.i, align 8
  %11642 = add i64 %11641, -1276
  %11643 = add i64 %11637, 8
  store i64 %11643, i64* %3, align 8
  %11644 = inttoptr i64 %11642 to i32*
  %11645 = load i32, i32* %11644, align 4
  %11646 = zext i32 %11645 to i64
  store i64 %11646, i64* %R9.i, align 8
  %11647 = add i64 %11637, 11
  store i64 %11647, i64* %3, align 8
  %11648 = zext i32 %11638 to i64
  %11649 = sext i32 %11645 to i64
  %11650 = shl nuw i64 %11640, 32
  %11651 = or i64 %11650, %11648
  %11652 = sdiv i64 %11651, %11649
  %11653 = shl i64 %11652, 32
  %11654 = ashr exact i64 %11653, 32
  %11655 = icmp eq i64 %11652, %11654
  br i1 %11655, label %11658, label %11656

; <label>:11656:                                  ; preds = %block_4a5b50
  %11657 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11647, %struct.Memory* %MEMORY.64)
  %.pre687 = load i64, i64* %RDX.i1805, align 8
  %.pre688 = load i64, i64* %3, align 8
  %.pre689 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit4073

; <label>:11658:                                  ; preds = %block_4a5b50
  %11659 = srem i64 %11651, %11649
  %11660 = and i64 %11652, 4294967295
  store i64 %11660, i64* %RAX.i1763, align 8
  %11661 = and i64 %11659, 4294967295
  store i64 %11661, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r9d.exit4073

routine_idivl__r9d.exit4073:                      ; preds = %11658, %11656
  %11662 = phi i64 [ %.pre689, %11656 ], [ %11641, %11658 ]
  %11663 = phi i64 [ %.pre688, %11656 ], [ %11647, %11658 ]
  %11664 = phi i64 [ %.pre687, %11656 ], [ %11661, %11658 ]
  %11665 = phi %struct.Memory* [ %11657, %11656 ], [ %MEMORY.64, %11658 ]
  %11666 = trunc i64 %11664 to i32
  %11667 = shl i32 %11666, 1
  %11668 = icmp slt i32 %11666, 0
  %11669 = icmp slt i32 %11667, 0
  %11670 = xor i1 %11668, %11669
  %11671 = zext i32 %11667 to i64
  store i64 %11671, i64* %RDX.i1805, align 8
  %.lobit204 = lshr i32 %11666, 31
  %11672 = trunc i32 %.lobit204 to i8
  store i8 %11672, i8* %18, align 1
  %11673 = and i32 %11667, 254
  %11674 = tail call i32 @llvm.ctpop.i32(i32 %11673)
  %11675 = trunc i32 %11674 to i8
  %11676 = and i8 %11675, 1
  %11677 = xor i8 %11676, 1
  store i8 %11677, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %11678 = icmp eq i32 %11667, 0
  %11679 = zext i1 %11678 to i8
  store i8 %11679, i8* %21, align 1
  %11680 = lshr i32 %11666, 30
  %11681 = trunc i32 %11680 to i8
  %11682 = and i8 %11681, 1
  store i8 %11682, i8* %22, align 1
  %11683 = zext i1 %11670 to i8
  store i8 %11683, i8* %23, align 1
  %11684 = add i64 %11662, -628
  %11685 = add i64 %11663, 9
  store i64 %11685, i64* %3, align 8
  %11686 = inttoptr i64 %11684 to i32*
  %11687 = load i32, i32* %11686, align 4
  %11688 = zext i32 %11687 to i64
  store i64 %11688, i64* %372, align 8
  store i64 %11688, i64* %RAX.i1763, align 8
  %11689 = add i64 %11662, -1292
  %11690 = add i64 %11663, 18
  store i64 %11690, i64* %3, align 8
  %11691 = inttoptr i64 %11689 to i32*
  store i32 %11667, i32* %11691, align 4
  %11692 = load i64, i64* %3, align 8
  %11693 = load i32, i32* %EAX.i2159, align 8
  %11694 = sext i32 %11693 to i64
  %11695 = lshr i64 %11694, 32
  store i64 %11695, i64* %101, align 8
  %11696 = load i32, i32* %R9D.i6640, align 4
  %11697 = add i64 %11692, 4
  store i64 %11697, i64* %3, align 8
  %11698 = zext i32 %11693 to i64
  %11699 = sext i32 %11696 to i64
  %11700 = shl nuw i64 %11695, 32
  %11701 = or i64 %11700, %11698
  %11702 = sdiv i64 %11701, %11699
  %11703 = shl i64 %11702, 32
  %11704 = ashr exact i64 %11703, 32
  %11705 = icmp eq i64 %11702, %11704
  br i1 %11705, label %11708, label %11706

; <label>:11706:                                  ; preds = %routine_idivl__r9d.exit4073
  %11707 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11697, %struct.Memory* %11665)
  %.pre690 = load i64, i64* %3, align 8
  %.pre691 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__r9d.exit4055

; <label>:11708:                                  ; preds = %routine_idivl__r9d.exit4073
  %11709 = srem i64 %11701, %11699
  %11710 = and i64 %11702, 4294967295
  store i64 %11710, i64* %RAX.i1763, align 8
  %11711 = and i64 %11709, 4294967295
  store i64 %11711, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %11712 = trunc i64 %11709 to i32
  br label %routine_idivl__r9d.exit4055

routine_idivl__r9d.exit4055:                      ; preds = %11708, %11706
  %11713 = phi i32 [ %.pre691, %11706 ], [ %11712, %11708 ]
  %11714 = phi i64 [ %.pre690, %11706 ], [ %11697, %11708 ]
  %11715 = phi %struct.Memory* [ %11707, %11706 ], [ %11665, %11708 ]
  %11716 = load i64, i64* %RBP.i, align 8
  %11717 = add i64 %11716, -1292
  %11718 = add i64 %11714, 7
  store i64 %11718, i64* %3, align 8
  %11719 = inttoptr i64 %11717 to i32*
  %11720 = load i32, i32* %11719, align 4
  %11721 = add i32 %11713, %11720
  %11722 = zext i32 %11721 to i64
  store i64 %11722, i64* %372, align 8
  %11723 = sext i32 %11721 to i64
  %11724 = shl nsw i64 %11723, 4
  store i64 %11724, i64* %26, align 8
  %11725 = load i64, i64* %RDI.i2141, align 8
  %11726 = add i64 %11724, %11725
  store i64 %11726, i64* %RDI.i2141, align 8
  %11727 = icmp ult i64 %11726, %11725
  %11728 = icmp ult i64 %11726, %11724
  %11729 = or i1 %11727, %11728
  %11730 = zext i1 %11729 to i8
  store i8 %11730, i8* %18, align 1
  %11731 = trunc i64 %11726 to i32
  %11732 = and i32 %11731, 255
  %11733 = tail call i32 @llvm.ctpop.i32(i32 %11732)
  %11734 = trunc i32 %11733 to i8
  %11735 = and i8 %11734, 1
  %11736 = xor i8 %11735, 1
  store i8 %11736, i8* %19, align 1
  %11737 = xor i64 %11724, %11725
  %11738 = xor i64 %11737, %11726
  %11739 = lshr i64 %11738, 4
  %11740 = trunc i64 %11739 to i8
  %11741 = and i8 %11740, 1
  store i8 %11741, i8* %20, align 1
  %11742 = icmp eq i64 %11726, 0
  %11743 = zext i1 %11742 to i8
  store i8 %11743, i8* %21, align 1
  %11744 = lshr i64 %11726, 63
  %11745 = trunc i64 %11744 to i8
  store i8 %11745, i8* %22, align 1
  %11746 = lshr i64 %11725, 63
  %11747 = lshr i64 %11723, 59
  %11748 = and i64 %11747, 1
  %11749 = xor i64 %11744, %11746
  %11750 = xor i64 %11744, %11748
  %11751 = add nuw nsw i64 %11749, %11750
  %11752 = icmp eq i64 %11751, 2
  %11753 = zext i1 %11752 to i8
  store i8 %11753, i8* %23, align 1
  %11754 = load i64, i64* %RBP.i, align 8
  %11755 = add i64 %11754, -12
  %11756 = add i64 %11714, 23
  store i64 %11756, i64* %3, align 8
  %11757 = inttoptr i64 %11755 to i32*
  %11758 = load i32, i32* %11757, align 4
  %11759 = zext i32 %11758 to i64
  store i64 %11759, i64* %RAX.i1763, align 8
  %11760 = sext i32 %11758 to i64
  %11761 = lshr i64 %11760, 32
  store i64 %11761, i64* %101, align 8
  %11762 = load i32, i32* %R9D.i6640, align 4
  %11763 = add i64 %11714, 29
  store i64 %11763, i64* %3, align 8
  %11764 = sext i32 %11762 to i64
  %11765 = shl nuw i64 %11761, 32
  %11766 = or i64 %11765, %11759
  %11767 = sdiv i64 %11766, %11764
  %11768 = shl i64 %11767, 32
  %11769 = ashr exact i64 %11768, 32
  %11770 = icmp eq i64 %11767, %11769
  br i1 %11770, label %11773, label %11771

; <label>:11771:                                  ; preds = %routine_idivl__r9d.exit4055
  %11772 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11763, %struct.Memory* %11715)
  %.pre692 = load i64, i64* %RAX.i1763, align 8
  %.pre693 = load i64, i64* %3, align 8
  %.pre694 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit4028

; <label>:11773:                                  ; preds = %routine_idivl__r9d.exit4055
  %11774 = srem i64 %11766, %11764
  %11775 = and i64 %11767, 4294967295
  store i64 %11775, i64* %RAX.i1763, align 8
  %11776 = and i64 %11774, 4294967295
  store i64 %11776, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r9d.exit4028

routine_idivl__r9d.exit4028:                      ; preds = %11773, %11771
  %11777 = phi i64 [ %.pre694, %11771 ], [ %11754, %11773 ]
  %11778 = phi i64 [ %.pre693, %11771 ], [ %11763, %11773 ]
  %11779 = phi i64 [ %.pre692, %11771 ], [ %11775, %11773 ]
  %11780 = phi %struct.Memory* [ %11772, %11771 ], [ %11715, %11773 ]
  %11781 = trunc i64 %11779 to i32
  %11782 = shl i32 %11781, 1
  %11783 = icmp slt i32 %11781, 0
  %11784 = icmp slt i32 %11782, 0
  %11785 = xor i1 %11783, %11784
  %11786 = zext i32 %11782 to i64
  store i64 %11786, i64* %RAX.i1763, align 8
  %.lobit206 = lshr i32 %11781, 31
  %11787 = trunc i32 %.lobit206 to i8
  store i8 %11787, i8* %18, align 1
  %11788 = and i32 %11782, 254
  %11789 = tail call i32 @llvm.ctpop.i32(i32 %11788)
  %11790 = trunc i32 %11789 to i8
  %11791 = and i8 %11790, 1
  %11792 = xor i8 %11791, 1
  store i8 %11792, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %11793 = icmp eq i32 %11782, 0
  %11794 = zext i1 %11793 to i8
  store i8 %11794, i8* %21, align 1
  %11795 = lshr i32 %11781, 30
  %11796 = trunc i32 %11795 to i8
  %11797 = and i8 %11796, 1
  store i8 %11797, i8* %22, align 1
  %11798 = zext i1 %11785 to i8
  store i8 %11798, i8* %23, align 1
  %11799 = add i64 %11777, -628
  %11800 = add i64 %11778, 9
  store i64 %11800, i64* %3, align 8
  %11801 = inttoptr i64 %11799 to i32*
  %11802 = load i32, i32* %11801, align 4
  %11803 = zext i32 %11802 to i64
  store i64 %11803, i64* %372, align 8
  %11804 = add i64 %11777, -1296
  %11805 = add i64 %11778, 15
  store i64 %11805, i64* %3, align 8
  %11806 = inttoptr i64 %11804 to i32*
  store i32 %11782, i32* %11806, align 4
  %11807 = load i32, i32* %R10D.i4319, align 4
  %11808 = zext i32 %11807 to i64
  %11809 = load i64, i64* %3, align 8
  store i64 %11808, i64* %RAX.i1763, align 8
  %11810 = sext i32 %11807 to i64
  %11811 = lshr i64 %11810, 32
  store i64 %11811, i64* %101, align 8
  %11812 = load i32, i32* %R9D.i6640, align 4
  %11813 = add i64 %11809, 7
  store i64 %11813, i64* %3, align 8
  %11814 = sext i32 %11812 to i64
  %11815 = shl nuw i64 %11811, 32
  %11816 = or i64 %11815, %11808
  %11817 = sdiv i64 %11816, %11814
  %11818 = shl i64 %11817, 32
  %11819 = ashr exact i64 %11818, 32
  %11820 = icmp eq i64 %11817, %11819
  br i1 %11820, label %11823, label %11821

; <label>:11821:                                  ; preds = %routine_idivl__r9d.exit4028
  %11822 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11813, %struct.Memory* %11780)
  %.pre695 = load i64, i64* %3, align 8
  %.pre696 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__r9d.exit4010

; <label>:11823:                                  ; preds = %routine_idivl__r9d.exit4028
  %11824 = srem i64 %11816, %11814
  %11825 = and i64 %11817, 4294967295
  store i64 %11825, i64* %RAX.i1763, align 8
  %11826 = and i64 %11824, 4294967295
  store i64 %11826, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %11827 = trunc i64 %11817 to i32
  br label %routine_idivl__r9d.exit4010

routine_idivl__r9d.exit4010:                      ; preds = %11823, %11821
  %11828 = phi i32 [ %.pre696, %11821 ], [ %11827, %11823 ]
  %11829 = phi i64 [ %.pre695, %11821 ], [ %11813, %11823 ]
  %11830 = phi %struct.Memory* [ %11822, %11821 ], [ %11780, %11823 ]
  %11831 = load i64, i64* %RBP.i, align 8
  %11832 = add i64 %11831, -1296
  %11833 = add i64 %11829, 7
  store i64 %11833, i64* %3, align 8
  %11834 = inttoptr i64 %11832 to i32*
  %11835 = load i32, i32* %11834, align 4
  %11836 = add i32 %11828, %11835
  %11837 = zext i32 %11836 to i64
  store i64 %11837, i64* %372, align 8
  %11838 = icmp ult i32 %11836, %11835
  %11839 = icmp ult i32 %11836, %11828
  %11840 = or i1 %11838, %11839
  %11841 = zext i1 %11840 to i8
  store i8 %11841, i8* %18, align 1
  %11842 = and i32 %11836, 255
  %11843 = tail call i32 @llvm.ctpop.i32(i32 %11842)
  %11844 = trunc i32 %11843 to i8
  %11845 = and i8 %11844, 1
  %11846 = xor i8 %11845, 1
  store i8 %11846, i8* %19, align 1
  %11847 = xor i32 %11828, %11835
  %11848 = xor i32 %11847, %11836
  %11849 = lshr i32 %11848, 4
  %11850 = trunc i32 %11849 to i8
  %11851 = and i8 %11850, 1
  store i8 %11851, i8* %20, align 1
  %11852 = icmp eq i32 %11836, 0
  %11853 = zext i1 %11852 to i8
  store i8 %11853, i8* %21, align 1
  %11854 = lshr i32 %11836, 31
  %11855 = trunc i32 %11854 to i8
  store i8 %11855, i8* %22, align 1
  %11856 = lshr i32 %11835, 31
  %11857 = lshr i32 %11828, 31
  %11858 = xor i32 %11854, %11856
  %11859 = xor i32 %11854, %11857
  %11860 = add nuw nsw i32 %11858, %11859
  %11861 = icmp eq i32 %11860, 2
  %11862 = zext i1 %11861 to i8
  store i8 %11862, i8* %23, align 1
  %11863 = sext i32 %11836 to i64
  store i64 %11863, i64* %26, align 8
  %11864 = load i64, i64* %RDI.i2141, align 8
  %11865 = shl nsw i64 %11863, 2
  %11866 = add i64 %11864, %11865
  %11867 = add i64 %11829, 17
  store i64 %11867, i64* %3, align 8
  %11868 = inttoptr i64 %11866 to i32*
  %11869 = load i32, i32* %11868, align 4
  %11870 = zext i32 %11869 to i64
  store i64 %11870, i64* %RAX.i1763, align 8
  %11871 = add i64 %11831, -44
  %11872 = add i64 %11829, 21
  store i64 %11872, i64* %3, align 8
  %11873 = inttoptr i64 %11871 to i32*
  %11874 = load i32, i32* %11873, align 4
  %11875 = sext i32 %11874 to i64
  %11876 = shl nsw i64 %11875, 6
  store i64 %11876, i64* %RDI.i2141, align 8
  %11877 = load i64, i64* %RSI.i1889, align 8
  %11878 = add i64 %11876, %11877
  store i64 %11878, i64* %RSI.i1889, align 8
  %11879 = icmp ult i64 %11878, %11877
  %11880 = icmp ult i64 %11878, %11876
  %11881 = or i1 %11879, %11880
  %11882 = zext i1 %11881 to i8
  store i8 %11882, i8* %18, align 1
  %11883 = trunc i64 %11878 to i32
  %11884 = and i32 %11883, 255
  %11885 = tail call i32 @llvm.ctpop.i32(i32 %11884)
  %11886 = trunc i32 %11885 to i8
  %11887 = and i8 %11886, 1
  %11888 = xor i8 %11887, 1
  store i8 %11888, i8* %19, align 1
  %11889 = xor i64 %11877, %11878
  %11890 = lshr i64 %11889, 4
  %11891 = trunc i64 %11890 to i8
  %11892 = and i8 %11891, 1
  store i8 %11892, i8* %20, align 1
  %11893 = icmp eq i64 %11878, 0
  %11894 = zext i1 %11893 to i8
  store i8 %11894, i8* %21, align 1
  %11895 = lshr i64 %11878, 63
  %11896 = trunc i64 %11895 to i8
  store i8 %11896, i8* %22, align 1
  %11897 = lshr i64 %11877, 63
  %11898 = lshr i64 %11875, 57
  %11899 = and i64 %11898, 1
  %11900 = xor i64 %11895, %11897
  %11901 = xor i64 %11895, %11899
  %11902 = add nuw nsw i64 %11900, %11901
  %11903 = icmp eq i64 %11902, 2
  %11904 = zext i1 %11903 to i8
  store i8 %11904, i8* %23, align 1
  %11905 = load i64, i64* %RBP.i, align 8
  %11906 = add i64 %11905, -12
  %11907 = add i64 %11829, 32
  store i64 %11907, i64* %3, align 8
  %11908 = inttoptr i64 %11906 to i32*
  %11909 = load i32, i32* %11908, align 4
  %11910 = zext i32 %11909 to i64
  store i64 %11910, i64* %372, align 8
  %11911 = add i64 %11905, -1300
  %11912 = add i64 %11829, 38
  store i64 %11912, i64* %3, align 8
  %11913 = inttoptr i64 %11911 to i32*
  store i32 %11869, i32* %11913, align 4
  %11914 = load i32, i32* %R10D.i4319, align 4
  %11915 = zext i32 %11914 to i64
  %11916 = load i64, i64* %3, align 8
  store i64 %11915, i64* %RAX.i1763, align 8
  %11917 = sext i32 %11914 to i64
  %11918 = lshr i64 %11917, 32
  store i64 %11918, i64* %101, align 8
  %11919 = load i32, i32* %R9D.i6640, align 4
  %11920 = add i64 %11916, 7
  store i64 %11920, i64* %3, align 8
  %11921 = sext i32 %11919 to i64
  %11922 = shl nuw i64 %11918, 32
  %11923 = or i64 %11922, %11915
  %11924 = sdiv i64 %11923, %11921
  %11925 = shl i64 %11924, 32
  %11926 = ashr exact i64 %11925, 32
  %11927 = icmp eq i64 %11924, %11926
  br i1 %11927, label %11930, label %11928

; <label>:11928:                                  ; preds = %routine_idivl__r9d.exit4010
  %11929 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11920, %struct.Memory* %11830)
  %.pre697 = load i64, i64* %RDX.i1805, align 8
  %.pre698 = load i64, i64* %3, align 8
  br label %routine_idivl__r9d.exit3974

; <label>:11930:                                  ; preds = %routine_idivl__r9d.exit4010
  %11931 = srem i64 %11923, %11921
  %11932 = and i64 %11924, 4294967295
  store i64 %11932, i64* %RAX.i1763, align 8
  %11933 = and i64 %11931, 4294967295
  store i64 %11933, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r9d.exit3974

routine_idivl__r9d.exit3974:                      ; preds = %11930, %11928
  %11934 = phi i64 [ %.pre698, %11928 ], [ %11920, %11930 ]
  %11935 = phi i64 [ %.pre697, %11928 ], [ %11933, %11930 ]
  %11936 = phi %struct.Memory* [ %11929, %11928 ], [ %11830, %11930 ]
  %11937 = trunc i64 %11935 to i32
  %11938 = shl i32 %11937, 1
  %11939 = icmp slt i32 %11937, 0
  %11940 = icmp slt i32 %11938, 0
  %11941 = xor i1 %11939, %11940
  %11942 = zext i32 %11938 to i64
  store i64 %11942, i64* %RDX.i1805, align 8
  %.lobit208 = lshr i32 %11937, 31
  %11943 = trunc i32 %.lobit208 to i8
  store i8 %11943, i8* %18, align 1
  %11944 = and i32 %11938, 254
  %11945 = tail call i32 @llvm.ctpop.i32(i32 %11944)
  %11946 = trunc i32 %11945 to i8
  %11947 = and i8 %11946, 1
  %11948 = xor i8 %11947, 1
  store i8 %11948, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %11949 = icmp eq i32 %11938, 0
  %11950 = zext i1 %11949 to i8
  store i8 %11950, i8* %21, align 1
  %11951 = lshr i32 %11937, 30
  %11952 = trunc i32 %11951 to i8
  %11953 = and i8 %11952, 1
  store i8 %11953, i8* %22, align 1
  %11954 = zext i1 %11941 to i8
  store i8 %11954, i8* %23, align 1
  %11955 = load i64, i64* %RBP.i, align 8
  %11956 = add i64 %11955, -628
  %11957 = add i64 %11934, 9
  store i64 %11957, i64* %3, align 8
  %11958 = inttoptr i64 %11956 to i32*
  %11959 = load i32, i32* %11958, align 4
  %11960 = zext i32 %11959 to i64
  store i64 %11960, i64* %372, align 8
  store i64 %11960, i64* %RAX.i1763, align 8
  %11961 = add i64 %11955, -1304
  %11962 = add i64 %11934, 18
  store i64 %11962, i64* %3, align 8
  %11963 = inttoptr i64 %11961 to i32*
  store i32 %11938, i32* %11963, align 4
  %11964 = load i64, i64* %3, align 8
  %11965 = load i32, i32* %EAX.i2159, align 8
  %11966 = sext i32 %11965 to i64
  %11967 = lshr i64 %11966, 32
  store i64 %11967, i64* %101, align 8
  %11968 = load i32, i32* %R9D.i6640, align 4
  %11969 = add i64 %11964, 4
  store i64 %11969, i64* %3, align 8
  %11970 = zext i32 %11965 to i64
  %11971 = sext i32 %11968 to i64
  %11972 = shl nuw i64 %11967, 32
  %11973 = or i64 %11972, %11970
  %11974 = sdiv i64 %11973, %11971
  %11975 = shl i64 %11974, 32
  %11976 = ashr exact i64 %11975, 32
  %11977 = icmp eq i64 %11974, %11976
  br i1 %11977, label %11980, label %11978

; <label>:11978:                                  ; preds = %routine_idivl__r9d.exit3974
  %11979 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11969, %struct.Memory* %11936)
  %.pre699 = load i64, i64* %3, align 8
  %.pre700 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__r9d.exit3956

; <label>:11980:                                  ; preds = %routine_idivl__r9d.exit3974
  %11981 = srem i64 %11973, %11971
  %11982 = and i64 %11974, 4294967295
  store i64 %11982, i64* %RAX.i1763, align 8
  %11983 = and i64 %11981, 4294967295
  store i64 %11983, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %11984 = trunc i64 %11981 to i32
  br label %routine_idivl__r9d.exit3956

routine_idivl__r9d.exit3956:                      ; preds = %11980, %11978
  %11985 = phi i32 [ %.pre700, %11978 ], [ %11984, %11980 ]
  %11986 = phi i64 [ %.pre699, %11978 ], [ %11969, %11980 ]
  %11987 = phi %struct.Memory* [ %11979, %11978 ], [ %11936, %11980 ]
  %11988 = load i64, i64* %RBP.i, align 8
  %11989 = add i64 %11988, -1304
  %11990 = add i64 %11986, 7
  store i64 %11990, i64* %3, align 8
  %11991 = inttoptr i64 %11989 to i32*
  %11992 = load i32, i32* %11991, align 4
  %11993 = add i32 %11985, %11992
  %11994 = zext i32 %11993 to i64
  store i64 %11994, i64* %372, align 8
  %11995 = sext i32 %11993 to i64
  %11996 = shl nsw i64 %11995, 4
  store i64 %11996, i64* %RDI.i2141, align 8
  %11997 = load i64, i64* %RSI.i1889, align 8
  %11998 = add i64 %11996, %11997
  store i64 %11998, i64* %RSI.i1889, align 8
  %11999 = icmp ult i64 %11998, %11997
  %12000 = icmp ult i64 %11998, %11996
  %12001 = or i1 %11999, %12000
  %12002 = zext i1 %12001 to i8
  store i8 %12002, i8* %18, align 1
  %12003 = trunc i64 %11998 to i32
  %12004 = and i32 %12003, 255
  %12005 = tail call i32 @llvm.ctpop.i32(i32 %12004)
  %12006 = trunc i32 %12005 to i8
  %12007 = and i8 %12006, 1
  %12008 = xor i8 %12007, 1
  store i8 %12008, i8* %19, align 1
  %12009 = xor i64 %11996, %11997
  %12010 = xor i64 %12009, %11998
  %12011 = lshr i64 %12010, 4
  %12012 = trunc i64 %12011 to i8
  %12013 = and i8 %12012, 1
  store i8 %12013, i8* %20, align 1
  %12014 = icmp eq i64 %11998, 0
  %12015 = zext i1 %12014 to i8
  store i8 %12015, i8* %21, align 1
  %12016 = lshr i64 %11998, 63
  %12017 = trunc i64 %12016 to i8
  store i8 %12017, i8* %22, align 1
  %12018 = lshr i64 %11997, 63
  %12019 = lshr i64 %11995, 59
  %12020 = and i64 %12019, 1
  %12021 = xor i64 %12016, %12018
  %12022 = xor i64 %12016, %12020
  %12023 = add nuw nsw i64 %12021, %12022
  %12024 = icmp eq i64 %12023, 2
  %12025 = zext i1 %12024 to i8
  store i8 %12025, i8* %23, align 1
  %12026 = load i64, i64* %RBP.i, align 8
  %12027 = add i64 %12026, -12
  %12028 = add i64 %11986, 23
  store i64 %12028, i64* %3, align 8
  %12029 = inttoptr i64 %12027 to i32*
  %12030 = load i32, i32* %12029, align 4
  %12031 = zext i32 %12030 to i64
  store i64 %12031, i64* %RAX.i1763, align 8
  %12032 = sext i32 %12030 to i64
  %12033 = lshr i64 %12032, 32
  store i64 %12033, i64* %101, align 8
  %12034 = load i32, i32* %R9D.i6640, align 4
  %12035 = add i64 %11986, 29
  store i64 %12035, i64* %3, align 8
  %12036 = sext i32 %12034 to i64
  %12037 = shl nuw i64 %12033, 32
  %12038 = or i64 %12037, %12031
  %12039 = sdiv i64 %12038, %12036
  %12040 = shl i64 %12039, 32
  %12041 = ashr exact i64 %12040, 32
  %12042 = icmp eq i64 %12039, %12041
  br i1 %12042, label %12045, label %12043

; <label>:12043:                                  ; preds = %routine_idivl__r9d.exit3956
  %12044 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12035, %struct.Memory* %11987)
  %.pre701 = load i64, i64* %RAX.i1763, align 8
  %.pre702 = load i64, i64* %3, align 8
  %.pre703 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3929

; <label>:12045:                                  ; preds = %routine_idivl__r9d.exit3956
  %12046 = srem i64 %12038, %12036
  %12047 = and i64 %12039, 4294967295
  store i64 %12047, i64* %RAX.i1763, align 8
  %12048 = and i64 %12046, 4294967295
  store i64 %12048, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r9d.exit3929

routine_idivl__r9d.exit3929:                      ; preds = %12045, %12043
  %12049 = phi i64 [ %.pre703, %12043 ], [ %12026, %12045 ]
  %12050 = phi i64 [ %.pre702, %12043 ], [ %12035, %12045 ]
  %12051 = phi i64 [ %.pre701, %12043 ], [ %12047, %12045 ]
  %12052 = phi %struct.Memory* [ %12044, %12043 ], [ %11987, %12045 ]
  %12053 = trunc i64 %12051 to i32
  %12054 = shl i32 %12053, 1
  %12055 = icmp slt i32 %12053, 0
  %12056 = icmp slt i32 %12054, 0
  %12057 = xor i1 %12055, %12056
  %12058 = zext i32 %12054 to i64
  store i64 %12058, i64* %RAX.i1763, align 8
  %.lobit210 = lshr i32 %12053, 31
  %12059 = trunc i32 %.lobit210 to i8
  store i8 %12059, i8* %18, align 1
  %12060 = and i32 %12054, 254
  %12061 = tail call i32 @llvm.ctpop.i32(i32 %12060)
  %12062 = trunc i32 %12061 to i8
  %12063 = and i8 %12062, 1
  %12064 = xor i8 %12063, 1
  store i8 %12064, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %12065 = icmp eq i32 %12054, 0
  %12066 = zext i1 %12065 to i8
  store i8 %12066, i8* %21, align 1
  %12067 = lshr i32 %12053, 30
  %12068 = trunc i32 %12067 to i8
  %12069 = and i8 %12068, 1
  store i8 %12069, i8* %22, align 1
  %12070 = zext i1 %12057 to i8
  store i8 %12070, i8* %23, align 1
  %12071 = add i64 %12049, -628
  %12072 = add i64 %12050, 9
  store i64 %12072, i64* %3, align 8
  %12073 = inttoptr i64 %12071 to i32*
  %12074 = load i32, i32* %12073, align 4
  %12075 = zext i32 %12074 to i64
  store i64 %12075, i64* %372, align 8
  %12076 = add i64 %12049, -1308
  %12077 = add i64 %12050, 15
  store i64 %12077, i64* %3, align 8
  %12078 = inttoptr i64 %12076 to i32*
  store i32 %12054, i32* %12078, align 4
  %12079 = load i32, i32* %R10D.i4319, align 4
  %12080 = zext i32 %12079 to i64
  %12081 = load i64, i64* %3, align 8
  store i64 %12080, i64* %RAX.i1763, align 8
  %12082 = sext i32 %12079 to i64
  %12083 = lshr i64 %12082, 32
  store i64 %12083, i64* %101, align 8
  %12084 = load i32, i32* %R9D.i6640, align 4
  %12085 = add i64 %12081, 7
  store i64 %12085, i64* %3, align 8
  %12086 = sext i32 %12084 to i64
  %12087 = shl nuw i64 %12083, 32
  %12088 = or i64 %12087, %12080
  %12089 = sdiv i64 %12088, %12086
  %12090 = shl i64 %12089, 32
  %12091 = ashr exact i64 %12090, 32
  %12092 = icmp eq i64 %12089, %12091
  br i1 %12092, label %12095, label %12093

; <label>:12093:                                  ; preds = %routine_idivl__r9d.exit3929
  %12094 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12085, %struct.Memory* %12052)
  %.pre704 = load i64, i64* %3, align 8
  %.pre705 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__r9d.exit3911

; <label>:12095:                                  ; preds = %routine_idivl__r9d.exit3929
  %12096 = srem i64 %12088, %12086
  %12097 = and i64 %12089, 4294967295
  store i64 %12097, i64* %RAX.i1763, align 8
  %12098 = and i64 %12096, 4294967295
  store i64 %12098, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %12099 = trunc i64 %12089 to i32
  br label %routine_idivl__r9d.exit3911

routine_idivl__r9d.exit3911:                      ; preds = %12095, %12093
  %12100 = phi i32 [ %.pre705, %12093 ], [ %12099, %12095 ]
  %12101 = phi i64 [ %.pre704, %12093 ], [ %12085, %12095 ]
  %12102 = phi %struct.Memory* [ %12094, %12093 ], [ %12052, %12095 ]
  %12103 = load i64, i64* %RBP.i, align 8
  %12104 = add i64 %12103, -1308
  %12105 = add i64 %12101, 7
  store i64 %12105, i64* %3, align 8
  %12106 = inttoptr i64 %12104 to i32*
  %12107 = load i32, i32* %12106, align 4
  %12108 = add i32 %12100, %12107
  %12109 = zext i32 %12108 to i64
  store i64 %12109, i64* %372, align 8
  %12110 = icmp ult i32 %12108, %12107
  %12111 = icmp ult i32 %12108, %12100
  %12112 = or i1 %12110, %12111
  %12113 = zext i1 %12112 to i8
  store i8 %12113, i8* %18, align 1
  %12114 = and i32 %12108, 255
  %12115 = tail call i32 @llvm.ctpop.i32(i32 %12114)
  %12116 = trunc i32 %12115 to i8
  %12117 = and i8 %12116, 1
  %12118 = xor i8 %12117, 1
  store i8 %12118, i8* %19, align 1
  %12119 = xor i32 %12100, %12107
  %12120 = xor i32 %12119, %12108
  %12121 = lshr i32 %12120, 4
  %12122 = trunc i32 %12121 to i8
  %12123 = and i8 %12122, 1
  store i8 %12123, i8* %20, align 1
  %12124 = icmp eq i32 %12108, 0
  %12125 = zext i1 %12124 to i8
  store i8 %12125, i8* %21, align 1
  %12126 = lshr i32 %12108, 31
  %12127 = trunc i32 %12126 to i8
  store i8 %12127, i8* %22, align 1
  %12128 = lshr i32 %12107, 31
  %12129 = lshr i32 %12100, 31
  %12130 = xor i32 %12126, %12128
  %12131 = xor i32 %12126, %12129
  %12132 = add nuw nsw i32 %12130, %12131
  %12133 = icmp eq i32 %12132, 2
  %12134 = zext i1 %12133 to i8
  store i8 %12134, i8* %23, align 1
  %12135 = sext i32 %12108 to i64
  store i64 %12135, i64* %RDI.i2141, align 8
  %12136 = add i64 %12103, -1300
  %12137 = add i64 %12101, 19
  store i64 %12137, i64* %3, align 8
  %12138 = inttoptr i64 %12136 to i32*
  %12139 = load i32, i32* %12138, align 4
  %12140 = zext i32 %12139 to i64
  store i64 %12140, i64* %RAX.i1763, align 8
  %12141 = load i64, i64* %RSI.i1889, align 8
  %12142 = shl nsw i64 %12135, 2
  %12143 = add i64 %12142, %12141
  %12144 = add i64 %12101, 22
  store i64 %12144, i64* %3, align 8
  %12145 = inttoptr i64 %12143 to i32*
  store i32 %12139, i32* %12145, align 4
  %12146 = load i64, i64* %RBP.i, align 8
  %12147 = add i64 %12146, -44
  %12148 = load i64, i64* %3, align 8
  %12149 = add i64 %12148, 4
  store i64 %12149, i64* %3, align 8
  %12150 = inttoptr i64 %12147 to i32*
  %12151 = load i32, i32* %12150, align 4
  %12152 = sext i32 %12151 to i64
  %12153 = shl nsw i64 %12152, 6
  store i64 %12153, i64* %RSI.i1889, align 8
  %.lobit211 = lshr i32 %12151, 31
  %12154 = trunc i32 %.lobit211 to i8
  store i8 %12154, i8* %18, align 1
  %12155 = trunc i64 %12153 to i32
  %12156 = and i32 %12155, 192
  %12157 = tail call i32 @llvm.ctpop.i32(i32 %12156)
  %12158 = trunc i32 %12157 to i8
  %12159 = and i8 %12158, 1
  %12160 = xor i8 %12159, 1
  store i8 %12160, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %12161 = icmp eq i32 %12151, 0
  %12162 = zext i1 %12161 to i8
  store i8 %12162, i8* %21, align 1
  %12163 = lshr i64 %12152, 57
  %12164 = trunc i64 %12163 to i8
  %12165 = and i8 %12164, 1
  store i8 %12165, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %12166 = add i64 %12146, -1288
  %12167 = add i64 %12148, 15
  store i64 %12167, i64* %3, align 8
  %12168 = inttoptr i64 %12166 to i64*
  %12169 = load i64, i64* %12168, align 8
  %12170 = add i64 %12153, %12169
  store i64 %12170, i64* %RDI.i2141, align 8
  %12171 = icmp ult i64 %12170, %12169
  %12172 = icmp ult i64 %12170, %12153
  %12173 = or i1 %12171, %12172
  %12174 = zext i1 %12173 to i8
  store i8 %12174, i8* %18, align 1
  %12175 = trunc i64 %12170 to i32
  %12176 = and i32 %12175, 255
  %12177 = tail call i32 @llvm.ctpop.i32(i32 %12176)
  %12178 = trunc i32 %12177 to i8
  %12179 = and i8 %12178, 1
  %12180 = xor i8 %12179, 1
  store i8 %12180, i8* %19, align 1
  %12181 = xor i64 %12169, %12170
  %12182 = lshr i64 %12181, 4
  %12183 = trunc i64 %12182 to i8
  %12184 = and i8 %12183, 1
  store i8 %12184, i8* %20, align 1
  %12185 = icmp eq i64 %12170, 0
  %12186 = zext i1 %12185 to i8
  store i8 %12186, i8* %21, align 1
  %12187 = lshr i64 %12170, 63
  %12188 = trunc i64 %12187 to i8
  store i8 %12188, i8* %22, align 1
  %12189 = lshr i64 %12169, 63
  %12190 = lshr i64 %12152, 57
  %12191 = and i64 %12190, 1
  %12192 = xor i64 %12187, %12189
  %12193 = xor i64 %12187, %12191
  %12194 = add nuw nsw i64 %12192, %12193
  %12195 = icmp eq i64 %12194, 2
  %12196 = zext i1 %12195 to i8
  store i8 %12196, i8* %23, align 1
  %12197 = add i64 %12146, -12
  %12198 = add i64 %12148, 21
  store i64 %12198, i64* %3, align 8
  %12199 = inttoptr i64 %12197 to i32*
  %12200 = load i32, i32* %12199, align 4
  %12201 = zext i32 %12200 to i64
  store i64 %12201, i64* %RAX.i1763, align 8
  %12202 = sext i32 %12200 to i64
  %12203 = lshr i64 %12202, 32
  store i64 %12203, i64* %101, align 8
  %12204 = load i32, i32* %R9D.i6640, align 4
  %12205 = add i64 %12148, 25
  store i64 %12205, i64* %3, align 8
  %12206 = sext i32 %12204 to i64
  %12207 = shl nuw i64 %12203, 32
  %12208 = or i64 %12207, %12201
  %12209 = sdiv i64 %12208, %12206
  %12210 = shl i64 %12209, 32
  %12211 = ashr exact i64 %12210, 32
  %12212 = icmp eq i64 %12209, %12211
  br i1 %12212, label %12215, label %12213

; <label>:12213:                                  ; preds = %routine_idivl__r9d.exit3911
  %12214 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12205, %struct.Memory* %12102)
  %.pre706 = load i64, i64* %RDX.i1805, align 8
  %.pre707 = load i64, i64* %3, align 8
  %.pre759 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3875

; <label>:12215:                                  ; preds = %routine_idivl__r9d.exit3911
  %12216 = srem i64 %12208, %12206
  %12217 = and i64 %12209, 4294967295
  store i64 %12217, i64* %RAX.i1763, align 8
  %12218 = and i64 %12216, 4294967295
  store i64 %12218, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r9d.exit3875

routine_idivl__r9d.exit3875:                      ; preds = %12215, %12213
  %12219 = phi i64 [ %.pre759, %12213 ], [ %12146, %12215 ]
  %12220 = phi i64 [ %.pre707, %12213 ], [ %12205, %12215 ]
  %12221 = phi i64 [ %.pre706, %12213 ], [ %12218, %12215 ]
  %12222 = phi %struct.Memory* [ %12214, %12213 ], [ %12102, %12215 ]
  %12223 = trunc i64 %12221 to i32
  %12224 = shl i32 %12223, 1
  %12225 = icmp slt i32 %12223, 0
  %12226 = icmp slt i32 %12224, 0
  %12227 = xor i1 %12225, %12226
  %12228 = zext i32 %12224 to i64
  store i64 %12228, i64* %RDX.i1805, align 8
  %.lobit212 = lshr i32 %12223, 31
  %12229 = trunc i32 %.lobit212 to i8
  store i8 %12229, i8* %18, align 1
  %12230 = and i32 %12224, 254
  %12231 = tail call i32 @llvm.ctpop.i32(i32 %12230)
  %12232 = trunc i32 %12231 to i8
  %12233 = and i8 %12232, 1
  %12234 = xor i8 %12233, 1
  store i8 %12234, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %12235 = icmp eq i32 %12224, 0
  %12236 = zext i1 %12235 to i8
  store i8 %12236, i8* %21, align 1
  %12237 = lshr i32 %12223, 30
  %12238 = trunc i32 %12237 to i8
  %12239 = and i8 %12238, 1
  store i8 %12239, i8* %22, align 1
  %12240 = zext i1 %12227 to i8
  store i8 %12240, i8* %23, align 1
  %12241 = add i64 %12219, -628
  %12242 = add i64 %12220, 9
  store i64 %12242, i64* %3, align 8
  %12243 = inttoptr i64 %12241 to i32*
  %12244 = load i32, i32* %12243, align 4
  %12245 = zext i32 %12244 to i64
  store i64 %12245, i64* %372, align 8
  store i64 %12245, i64* %RAX.i1763, align 8
  %12246 = add i64 %12219, -1312
  %12247 = add i64 %12220, 18
  store i64 %12247, i64* %3, align 8
  %12248 = inttoptr i64 %12246 to i32*
  store i32 %12224, i32* %12248, align 4
  %12249 = load i64, i64* %3, align 8
  %12250 = load i32, i32* %EAX.i2159, align 8
  %12251 = sext i32 %12250 to i64
  %12252 = lshr i64 %12251, 32
  store i64 %12252, i64* %101, align 8
  %12253 = load i32, i32* %R9D.i6640, align 4
  %12254 = add i64 %12249, 4
  store i64 %12254, i64* %3, align 8
  %12255 = zext i32 %12250 to i64
  %12256 = sext i32 %12253 to i64
  %12257 = shl nuw i64 %12252, 32
  %12258 = or i64 %12257, %12255
  %12259 = sdiv i64 %12258, %12256
  %12260 = shl i64 %12259, 32
  %12261 = ashr exact i64 %12260, 32
  %12262 = icmp eq i64 %12259, %12261
  br i1 %12262, label %12265, label %12263

; <label>:12263:                                  ; preds = %routine_idivl__r9d.exit3875
  %12264 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12254, %struct.Memory* %12222)
  %.pre708 = load i64, i64* %3, align 8
  %.pre709 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__r9d.exit3857

; <label>:12265:                                  ; preds = %routine_idivl__r9d.exit3875
  %12266 = srem i64 %12258, %12256
  %12267 = and i64 %12259, 4294967295
  store i64 %12267, i64* %RAX.i1763, align 8
  %12268 = and i64 %12266, 4294967295
  store i64 %12268, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %12269 = trunc i64 %12266 to i32
  br label %routine_idivl__r9d.exit3857

routine_idivl__r9d.exit3857:                      ; preds = %12265, %12263
  %12270 = phi i32 [ %.pre709, %12263 ], [ %12269, %12265 ]
  %12271 = phi i64 [ %.pre708, %12263 ], [ %12254, %12265 ]
  %12272 = phi %struct.Memory* [ %12264, %12263 ], [ %12222, %12265 ]
  %12273 = load i64, i64* %RBP.i, align 8
  %12274 = add i64 %12273, -1312
  %12275 = add i64 %12271, 7
  store i64 %12275, i64* %3, align 8
  %12276 = inttoptr i64 %12274 to i32*
  %12277 = load i32, i32* %12276, align 4
  %12278 = add i32 %12270, %12277
  %12279 = zext i32 %12278 to i64
  store i64 %12279, i64* %372, align 8
  %12280 = sext i32 %12278 to i64
  %12281 = shl nsw i64 %12280, 4
  store i64 %12281, i64* %RSI.i1889, align 8
  %12282 = load i64, i64* %RDI.i2141, align 8
  %12283 = add i64 %12281, %12282
  store i64 %12283, i64* %RDI.i2141, align 8
  %12284 = icmp ult i64 %12283, %12282
  %12285 = icmp ult i64 %12283, %12281
  %12286 = or i1 %12284, %12285
  %12287 = zext i1 %12286 to i8
  store i8 %12287, i8* %18, align 1
  %12288 = trunc i64 %12283 to i32
  %12289 = and i32 %12288, 255
  %12290 = tail call i32 @llvm.ctpop.i32(i32 %12289)
  %12291 = trunc i32 %12290 to i8
  %12292 = and i8 %12291, 1
  %12293 = xor i8 %12292, 1
  store i8 %12293, i8* %19, align 1
  %12294 = xor i64 %12281, %12282
  %12295 = xor i64 %12294, %12283
  %12296 = lshr i64 %12295, 4
  %12297 = trunc i64 %12296 to i8
  %12298 = and i8 %12297, 1
  store i8 %12298, i8* %20, align 1
  %12299 = icmp eq i64 %12283, 0
  %12300 = zext i1 %12299 to i8
  store i8 %12300, i8* %21, align 1
  %12301 = lshr i64 %12283, 63
  %12302 = trunc i64 %12301 to i8
  store i8 %12302, i8* %22, align 1
  %12303 = lshr i64 %12282, 63
  %12304 = lshr i64 %12280, 59
  %12305 = and i64 %12304, 1
  %12306 = xor i64 %12301, %12303
  %12307 = xor i64 %12301, %12305
  %12308 = add nuw nsw i64 %12306, %12307
  %12309 = icmp eq i64 %12308, 2
  %12310 = zext i1 %12309 to i8
  store i8 %12310, i8* %23, align 1
  %12311 = load i64, i64* %RBP.i, align 8
  %12312 = add i64 %12311, -12
  %12313 = add i64 %12271, 23
  store i64 %12313, i64* %3, align 8
  %12314 = inttoptr i64 %12312 to i32*
  %12315 = load i32, i32* %12314, align 4
  %12316 = zext i32 %12315 to i64
  store i64 %12316, i64* %RAX.i1763, align 8
  %12317 = sext i32 %12315 to i64
  %12318 = lshr i64 %12317, 32
  store i64 %12318, i64* %101, align 8
  %12319 = load i32, i32* %R9D.i6640, align 4
  %12320 = add i64 %12271, 29
  store i64 %12320, i64* %3, align 8
  %12321 = sext i32 %12319 to i64
  %12322 = shl nuw i64 %12318, 32
  %12323 = or i64 %12322, %12316
  %12324 = sdiv i64 %12323, %12321
  %12325 = shl i64 %12324, 32
  %12326 = ashr exact i64 %12325, 32
  %12327 = icmp eq i64 %12324, %12326
  br i1 %12327, label %12330, label %12328

; <label>:12328:                                  ; preds = %routine_idivl__r9d.exit3857
  %12329 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12320, %struct.Memory* %12272)
  %.pre710 = load i64, i64* %RAX.i1763, align 8
  %.pre711 = load i64, i64* %3, align 8
  %.pre712 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3830

; <label>:12330:                                  ; preds = %routine_idivl__r9d.exit3857
  %12331 = srem i64 %12323, %12321
  %12332 = and i64 %12324, 4294967295
  store i64 %12332, i64* %RAX.i1763, align 8
  %12333 = and i64 %12331, 4294967295
  store i64 %12333, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r9d.exit3830

routine_idivl__r9d.exit3830:                      ; preds = %12330, %12328
  %12334 = phi i64 [ %.pre712, %12328 ], [ %12311, %12330 ]
  %12335 = phi i64 [ %.pre711, %12328 ], [ %12320, %12330 ]
  %12336 = phi i64 [ %.pre710, %12328 ], [ %12332, %12330 ]
  %12337 = phi %struct.Memory* [ %12329, %12328 ], [ %12272, %12330 ]
  %12338 = trunc i64 %12336 to i32
  %12339 = shl i32 %12338, 1
  %12340 = icmp slt i32 %12338, 0
  %12341 = icmp slt i32 %12339, 0
  %12342 = xor i1 %12340, %12341
  %12343 = zext i32 %12339 to i64
  store i64 %12343, i64* %RAX.i1763, align 8
  %.lobit214 = lshr i32 %12338, 31
  %12344 = trunc i32 %.lobit214 to i8
  store i8 %12344, i8* %18, align 1
  %12345 = and i32 %12339, 254
  %12346 = tail call i32 @llvm.ctpop.i32(i32 %12345)
  %12347 = trunc i32 %12346 to i8
  %12348 = and i8 %12347, 1
  %12349 = xor i8 %12348, 1
  store i8 %12349, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %12350 = icmp eq i32 %12339, 0
  %12351 = zext i1 %12350 to i8
  store i8 %12351, i8* %21, align 1
  %12352 = lshr i32 %12338, 30
  %12353 = trunc i32 %12352 to i8
  %12354 = and i8 %12353, 1
  store i8 %12354, i8* %22, align 1
  %12355 = zext i1 %12342 to i8
  store i8 %12355, i8* %23, align 1
  %12356 = add i64 %12334, -628
  %12357 = add i64 %12335, 9
  store i64 %12357, i64* %3, align 8
  %12358 = inttoptr i64 %12356 to i32*
  %12359 = load i32, i32* %12358, align 4
  %12360 = zext i32 %12359 to i64
  store i64 %12360, i64* %372, align 8
  %12361 = add i64 %12334, -1316
  %12362 = add i64 %12335, 15
  store i64 %12362, i64* %3, align 8
  %12363 = inttoptr i64 %12361 to i32*
  store i32 %12339, i32* %12363, align 4
  %12364 = load i32, i32* %R10D.i4319, align 4
  %12365 = zext i32 %12364 to i64
  %12366 = load i64, i64* %3, align 8
  store i64 %12365, i64* %RAX.i1763, align 8
  %12367 = sext i32 %12364 to i64
  %12368 = lshr i64 %12367, 32
  store i64 %12368, i64* %101, align 8
  %12369 = load i32, i32* %R9D.i6640, align 4
  %12370 = add i64 %12366, 7
  store i64 %12370, i64* %3, align 8
  %12371 = sext i32 %12369 to i64
  %12372 = shl nuw i64 %12368, 32
  %12373 = or i64 %12372, %12365
  %12374 = sdiv i64 %12373, %12371
  %12375 = shl i64 %12374, 32
  %12376 = ashr exact i64 %12375, 32
  %12377 = icmp eq i64 %12374, %12376
  br i1 %12377, label %12380, label %12378

; <label>:12378:                                  ; preds = %routine_idivl__r9d.exit3830
  %12379 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12370, %struct.Memory* %12337)
  %.pre713 = load i64, i64* %3, align 8
  %.pre714 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__r9d.exit3812

; <label>:12380:                                  ; preds = %routine_idivl__r9d.exit3830
  %12381 = srem i64 %12373, %12371
  %12382 = and i64 %12374, 4294967295
  store i64 %12382, i64* %RAX.i1763, align 8
  %12383 = and i64 %12381, 4294967295
  store i64 %12383, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %12384 = trunc i64 %12374 to i32
  br label %routine_idivl__r9d.exit3812

routine_idivl__r9d.exit3812:                      ; preds = %12380, %12378
  %12385 = phi i32 [ %.pre714, %12378 ], [ %12384, %12380 ]
  %12386 = phi i64 [ %.pre713, %12378 ], [ %12370, %12380 ]
  %12387 = phi %struct.Memory* [ %12379, %12378 ], [ %12337, %12380 ]
  %12388 = load i64, i64* %RBP.i, align 8
  %12389 = add i64 %12388, -1316
  %12390 = add i64 %12386, 7
  store i64 %12390, i64* %3, align 8
  %12391 = inttoptr i64 %12389 to i32*
  %12392 = load i32, i32* %12391, align 4
  %12393 = add i32 %12385, %12392
  %12394 = zext i32 %12393 to i64
  store i64 %12394, i64* %372, align 8
  %12395 = icmp ult i32 %12393, %12392
  %12396 = icmp ult i32 %12393, %12385
  %12397 = or i1 %12395, %12396
  %12398 = zext i1 %12397 to i8
  store i8 %12398, i8* %18, align 1
  %12399 = and i32 %12393, 255
  %12400 = tail call i32 @llvm.ctpop.i32(i32 %12399)
  %12401 = trunc i32 %12400 to i8
  %12402 = and i8 %12401, 1
  %12403 = xor i8 %12402, 1
  store i8 %12403, i8* %19, align 1
  %12404 = xor i32 %12385, %12392
  %12405 = xor i32 %12404, %12393
  %12406 = lshr i32 %12405, 4
  %12407 = trunc i32 %12406 to i8
  %12408 = and i8 %12407, 1
  store i8 %12408, i8* %20, align 1
  %12409 = icmp eq i32 %12393, 0
  %12410 = zext i1 %12409 to i8
  store i8 %12410, i8* %21, align 1
  %12411 = lshr i32 %12393, 31
  %12412 = trunc i32 %12411 to i8
  store i8 %12412, i8* %22, align 1
  %12413 = lshr i32 %12392, 31
  %12414 = lshr i32 %12385, 31
  %12415 = xor i32 %12411, %12413
  %12416 = xor i32 %12411, %12414
  %12417 = add nuw nsw i32 %12415, %12416
  %12418 = icmp eq i32 %12417, 2
  %12419 = zext i1 %12418 to i8
  store i8 %12419, i8* %23, align 1
  %12420 = sext i32 %12393 to i64
  store i64 %12420, i64* %RSI.i1889, align 8
  %12421 = load i64, i64* %RDI.i2141, align 8
  %12422 = shl nsw i64 %12420, 2
  %12423 = add i64 %12421, %12422
  %12424 = add i64 %12386, 16
  store i64 %12424, i64* %3, align 8
  %12425 = inttoptr i64 %12423 to i32*
  %12426 = load i32, i32* %12425, align 4
  %12427 = zext i32 %12426 to i64
  store i64 %12427, i64* %RAX.i1763, align 8
  %12428 = add i64 %12388, -44
  %12429 = add i64 %12386, 20
  store i64 %12429, i64* %3, align 8
  %12430 = inttoptr i64 %12428 to i32*
  %12431 = load i32, i32* %12430, align 4
  %12432 = sext i32 %12431 to i64
  %12433 = shl nsw i64 %12432, 6
  store i64 %12433, i64* %RSI.i1889, align 8
  %12434 = load i64, i64* %RCX.i1692, align 8
  %12435 = add i64 %12433, %12434
  store i64 %12435, i64* %RCX.i1692, align 8
  %12436 = icmp ult i64 %12435, %12434
  %12437 = icmp ult i64 %12435, %12433
  %12438 = or i1 %12436, %12437
  %12439 = zext i1 %12438 to i8
  store i8 %12439, i8* %18, align 1
  %12440 = trunc i64 %12435 to i32
  %12441 = and i32 %12440, 255
  %12442 = tail call i32 @llvm.ctpop.i32(i32 %12441)
  %12443 = trunc i32 %12442 to i8
  %12444 = and i8 %12443, 1
  %12445 = xor i8 %12444, 1
  store i8 %12445, i8* %19, align 1
  %12446 = xor i64 %12434, %12435
  %12447 = lshr i64 %12446, 4
  %12448 = trunc i64 %12447 to i8
  %12449 = and i8 %12448, 1
  store i8 %12449, i8* %20, align 1
  %12450 = icmp eq i64 %12435, 0
  %12451 = zext i1 %12450 to i8
  store i8 %12451, i8* %21, align 1
  %12452 = lshr i64 %12435, 63
  %12453 = trunc i64 %12452 to i8
  store i8 %12453, i8* %22, align 1
  %12454 = lshr i64 %12434, 63
  %12455 = lshr i64 %12432, 57
  %12456 = and i64 %12455, 1
  %12457 = xor i64 %12452, %12454
  %12458 = xor i64 %12452, %12456
  %12459 = add nuw nsw i64 %12457, %12458
  %12460 = icmp eq i64 %12459, 2
  %12461 = zext i1 %12460 to i8
  store i8 %12461, i8* %23, align 1
  %12462 = load i64, i64* %RBP.i, align 8
  %12463 = add i64 %12462, -12
  %12464 = add i64 %12386, 31
  store i64 %12464, i64* %3, align 8
  %12465 = inttoptr i64 %12463 to i32*
  %12466 = load i32, i32* %12465, align 4
  %12467 = zext i32 %12466 to i64
  store i64 %12467, i64* %372, align 8
  %12468 = add i64 %12462, -1320
  %12469 = add i64 %12386, 37
  store i64 %12469, i64* %3, align 8
  %12470 = inttoptr i64 %12468 to i32*
  store i32 %12426, i32* %12470, align 4
  %12471 = load i32, i32* %R10D.i4319, align 4
  %12472 = zext i32 %12471 to i64
  %12473 = load i64, i64* %3, align 8
  store i64 %12472, i64* %RAX.i1763, align 8
  %12474 = sext i32 %12471 to i64
  %12475 = lshr i64 %12474, 32
  store i64 %12475, i64* %101, align 8
  %12476 = load i32, i32* %R9D.i6640, align 4
  %12477 = add i64 %12473, 7
  store i64 %12477, i64* %3, align 8
  %12478 = sext i32 %12476 to i64
  %12479 = shl nuw i64 %12475, 32
  %12480 = or i64 %12479, %12472
  %12481 = sdiv i64 %12480, %12478
  %12482 = shl i64 %12481, 32
  %12483 = ashr exact i64 %12482, 32
  %12484 = icmp eq i64 %12481, %12483
  br i1 %12484, label %12487, label %12485

; <label>:12485:                                  ; preds = %routine_idivl__r9d.exit3812
  %12486 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12477, %struct.Memory* %12387)
  %.pre715 = load i64, i64* %RDX.i1805, align 8
  %.pre716 = load i64, i64* %3, align 8
  br label %routine_idivl__r9d.exit3776

; <label>:12487:                                  ; preds = %routine_idivl__r9d.exit3812
  %12488 = srem i64 %12480, %12478
  %12489 = and i64 %12481, 4294967295
  store i64 %12489, i64* %RAX.i1763, align 8
  %12490 = and i64 %12488, 4294967295
  store i64 %12490, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r9d.exit3776

routine_idivl__r9d.exit3776:                      ; preds = %12487, %12485
  %12491 = phi i64 [ %.pre716, %12485 ], [ %12477, %12487 ]
  %12492 = phi i64 [ %.pre715, %12485 ], [ %12490, %12487 ]
  %12493 = phi %struct.Memory* [ %12486, %12485 ], [ %12387, %12487 ]
  %12494 = trunc i64 %12492 to i32
  %12495 = shl i32 %12494, 1
  %12496 = icmp slt i32 %12494, 0
  %12497 = icmp slt i32 %12495, 0
  %12498 = xor i1 %12496, %12497
  %12499 = zext i32 %12495 to i64
  store i64 %12499, i64* %RDX.i1805, align 8
  %.lobit216 = lshr i32 %12494, 31
  %12500 = trunc i32 %.lobit216 to i8
  store i8 %12500, i8* %18, align 1
  %12501 = and i32 %12495, 254
  %12502 = tail call i32 @llvm.ctpop.i32(i32 %12501)
  %12503 = trunc i32 %12502 to i8
  %12504 = and i8 %12503, 1
  %12505 = xor i8 %12504, 1
  store i8 %12505, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %12506 = icmp eq i32 %12495, 0
  %12507 = zext i1 %12506 to i8
  store i8 %12507, i8* %21, align 1
  %12508 = lshr i32 %12494, 30
  %12509 = trunc i32 %12508 to i8
  %12510 = and i8 %12509, 1
  store i8 %12510, i8* %22, align 1
  %12511 = zext i1 %12498 to i8
  store i8 %12511, i8* %23, align 1
  %12512 = load i64, i64* %RBP.i, align 8
  %12513 = add i64 %12512, -628
  %12514 = add i64 %12491, 9
  store i64 %12514, i64* %3, align 8
  %12515 = inttoptr i64 %12513 to i32*
  %12516 = load i32, i32* %12515, align 4
  %12517 = zext i32 %12516 to i64
  store i64 %12517, i64* %372, align 8
  store i64 %12517, i64* %RAX.i1763, align 8
  %12518 = add i64 %12512, -1324
  %12519 = add i64 %12491, 18
  store i64 %12519, i64* %3, align 8
  %12520 = inttoptr i64 %12518 to i32*
  store i32 %12495, i32* %12520, align 4
  %12521 = load i64, i64* %3, align 8
  %12522 = load i32, i32* %EAX.i2159, align 8
  %12523 = sext i32 %12522 to i64
  %12524 = lshr i64 %12523, 32
  store i64 %12524, i64* %101, align 8
  %12525 = load i32, i32* %R9D.i6640, align 4
  %12526 = add i64 %12521, 4
  store i64 %12526, i64* %3, align 8
  %12527 = zext i32 %12522 to i64
  %12528 = sext i32 %12525 to i64
  %12529 = shl nuw i64 %12524, 32
  %12530 = or i64 %12529, %12527
  %12531 = sdiv i64 %12530, %12528
  %12532 = shl i64 %12531, 32
  %12533 = ashr exact i64 %12532, 32
  %12534 = icmp eq i64 %12531, %12533
  br i1 %12534, label %12537, label %12535

; <label>:12535:                                  ; preds = %routine_idivl__r9d.exit3776
  %12536 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12526, %struct.Memory* %12493)
  %.pre717 = load i64, i64* %3, align 8
  %.pre718 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__r9d.exit3758

; <label>:12537:                                  ; preds = %routine_idivl__r9d.exit3776
  %12538 = srem i64 %12530, %12528
  %12539 = and i64 %12531, 4294967295
  store i64 %12539, i64* %RAX.i1763, align 8
  %12540 = and i64 %12538, 4294967295
  store i64 %12540, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %12541 = trunc i64 %12538 to i32
  br label %routine_idivl__r9d.exit3758

routine_idivl__r9d.exit3758:                      ; preds = %12537, %12535
  %12542 = phi i32 [ %.pre718, %12535 ], [ %12541, %12537 ]
  %12543 = phi i64 [ %.pre717, %12535 ], [ %12526, %12537 ]
  %12544 = phi %struct.Memory* [ %12536, %12535 ], [ %12493, %12537 ]
  %12545 = load i64, i64* %RBP.i, align 8
  %12546 = add i64 %12545, -1324
  %12547 = add i64 %12543, 7
  store i64 %12547, i64* %3, align 8
  %12548 = inttoptr i64 %12546 to i32*
  %12549 = load i32, i32* %12548, align 4
  %12550 = add i32 %12542, %12549
  %12551 = zext i32 %12550 to i64
  store i64 %12551, i64* %372, align 8
  %12552 = sext i32 %12550 to i64
  %12553 = shl nsw i64 %12552, 4
  store i64 %12553, i64* %RSI.i1889, align 8
  %12554 = load i64, i64* %RCX.i1692, align 8
  %12555 = add i64 %12553, %12554
  store i64 %12555, i64* %RCX.i1692, align 8
  %12556 = icmp ult i64 %12555, %12554
  %12557 = icmp ult i64 %12555, %12553
  %12558 = or i1 %12556, %12557
  %12559 = zext i1 %12558 to i8
  store i8 %12559, i8* %18, align 1
  %12560 = trunc i64 %12555 to i32
  %12561 = and i32 %12560, 255
  %12562 = tail call i32 @llvm.ctpop.i32(i32 %12561)
  %12563 = trunc i32 %12562 to i8
  %12564 = and i8 %12563, 1
  %12565 = xor i8 %12564, 1
  store i8 %12565, i8* %19, align 1
  %12566 = xor i64 %12553, %12554
  %12567 = xor i64 %12566, %12555
  %12568 = lshr i64 %12567, 4
  %12569 = trunc i64 %12568 to i8
  %12570 = and i8 %12569, 1
  store i8 %12570, i8* %20, align 1
  %12571 = icmp eq i64 %12555, 0
  %12572 = zext i1 %12571 to i8
  store i8 %12572, i8* %21, align 1
  %12573 = lshr i64 %12555, 63
  %12574 = trunc i64 %12573 to i8
  store i8 %12574, i8* %22, align 1
  %12575 = lshr i64 %12554, 63
  %12576 = lshr i64 %12552, 59
  %12577 = and i64 %12576, 1
  %12578 = xor i64 %12573, %12575
  %12579 = xor i64 %12573, %12577
  %12580 = add nuw nsw i64 %12578, %12579
  %12581 = icmp eq i64 %12580, 2
  %12582 = zext i1 %12581 to i8
  store i8 %12582, i8* %23, align 1
  %12583 = load i64, i64* %RBP.i, align 8
  %12584 = add i64 %12583, -12
  %12585 = add i64 %12543, 23
  store i64 %12585, i64* %3, align 8
  %12586 = inttoptr i64 %12584 to i32*
  %12587 = load i32, i32* %12586, align 4
  %12588 = zext i32 %12587 to i64
  store i64 %12588, i64* %RAX.i1763, align 8
  %12589 = sext i32 %12587 to i64
  %12590 = lshr i64 %12589, 32
  store i64 %12590, i64* %101, align 8
  %12591 = load i32, i32* %R9D.i6640, align 4
  %12592 = add i64 %12543, 29
  store i64 %12592, i64* %3, align 8
  %12593 = sext i32 %12591 to i64
  %12594 = shl nuw i64 %12590, 32
  %12595 = or i64 %12594, %12588
  %12596 = sdiv i64 %12595, %12593
  %12597 = shl i64 %12596, 32
  %12598 = ashr exact i64 %12597, 32
  %12599 = icmp eq i64 %12596, %12598
  br i1 %12599, label %12602, label %12600

; <label>:12600:                                  ; preds = %routine_idivl__r9d.exit3758
  %12601 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12592, %struct.Memory* %12544)
  %.pre719 = load i64, i64* %RAX.i1763, align 8
  %.pre720 = load i64, i64* %3, align 8
  %.pre721 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3731

; <label>:12602:                                  ; preds = %routine_idivl__r9d.exit3758
  %12603 = srem i64 %12595, %12593
  %12604 = and i64 %12596, 4294967295
  store i64 %12604, i64* %RAX.i1763, align 8
  %12605 = and i64 %12603, 4294967295
  store i64 %12605, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r9d.exit3731

routine_idivl__r9d.exit3731:                      ; preds = %12602, %12600
  %12606 = phi i64 [ %.pre721, %12600 ], [ %12583, %12602 ]
  %12607 = phi i64 [ %.pre720, %12600 ], [ %12592, %12602 ]
  %12608 = phi i64 [ %.pre719, %12600 ], [ %12604, %12602 ]
  %12609 = phi %struct.Memory* [ %12601, %12600 ], [ %12544, %12602 ]
  %12610 = trunc i64 %12608 to i32
  %12611 = shl i32 %12610, 1
  %12612 = icmp slt i32 %12610, 0
  %12613 = icmp slt i32 %12611, 0
  %12614 = xor i1 %12612, %12613
  %12615 = zext i32 %12611 to i64
  store i64 %12615, i64* %RAX.i1763, align 8
  %.lobit218 = lshr i32 %12610, 31
  %12616 = trunc i32 %.lobit218 to i8
  store i8 %12616, i8* %18, align 1
  %12617 = and i32 %12611, 254
  %12618 = tail call i32 @llvm.ctpop.i32(i32 %12617)
  %12619 = trunc i32 %12618 to i8
  %12620 = and i8 %12619, 1
  %12621 = xor i8 %12620, 1
  store i8 %12621, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %12622 = icmp eq i32 %12611, 0
  %12623 = zext i1 %12622 to i8
  store i8 %12623, i8* %21, align 1
  %12624 = lshr i32 %12610, 30
  %12625 = trunc i32 %12624 to i8
  %12626 = and i8 %12625, 1
  store i8 %12626, i8* %22, align 1
  %12627 = zext i1 %12614 to i8
  store i8 %12627, i8* %23, align 1
  %12628 = add i64 %12606, -628
  %12629 = add i64 %12607, 9
  store i64 %12629, i64* %3, align 8
  %12630 = inttoptr i64 %12628 to i32*
  %12631 = load i32, i32* %12630, align 4
  %12632 = zext i32 %12631 to i64
  store i64 %12632, i64* %372, align 8
  %12633 = add i64 %12606, -1328
  %12634 = add i64 %12607, 15
  store i64 %12634, i64* %3, align 8
  %12635 = inttoptr i64 %12633 to i32*
  store i32 %12611, i32* %12635, align 4
  %12636 = load i32, i32* %R10D.i4319, align 4
  %12637 = zext i32 %12636 to i64
  %12638 = load i64, i64* %3, align 8
  store i64 %12637, i64* %RAX.i1763, align 8
  %12639 = sext i32 %12636 to i64
  %12640 = lshr i64 %12639, 32
  store i64 %12640, i64* %101, align 8
  %12641 = load i32, i32* %R9D.i6640, align 4
  %12642 = add i64 %12638, 7
  store i64 %12642, i64* %3, align 8
  %12643 = sext i32 %12641 to i64
  %12644 = shl nuw i64 %12640, 32
  %12645 = or i64 %12644, %12637
  %12646 = sdiv i64 %12645, %12643
  %12647 = shl i64 %12646, 32
  %12648 = ashr exact i64 %12647, 32
  %12649 = icmp eq i64 %12646, %12648
  br i1 %12649, label %12652, label %12650

; <label>:12650:                                  ; preds = %routine_idivl__r9d.exit3731
  %12651 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12642, %struct.Memory* %12609)
  %.pre722 = load i64, i64* %3, align 8
  %.pre723 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__r9d.exit

; <label>:12652:                                  ; preds = %routine_idivl__r9d.exit3731
  %12653 = srem i64 %12645, %12643
  %12654 = and i64 %12646, 4294967295
  store i64 %12654, i64* %RAX.i1763, align 8
  %12655 = and i64 %12653, 4294967295
  store i64 %12655, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %12656 = trunc i64 %12646 to i32
  br label %routine_idivl__r9d.exit

routine_idivl__r9d.exit:                          ; preds = %12652, %12650
  %12657 = phi i32 [ %.pre723, %12650 ], [ %12656, %12652 ]
  %12658 = phi i64 [ %.pre722, %12650 ], [ %12642, %12652 ]
  %12659 = phi %struct.Memory* [ %12651, %12650 ], [ %12609, %12652 ]
  %12660 = load i64, i64* %RBP.i, align 8
  %12661 = add i64 %12660, -1328
  %12662 = add i64 %12658, 7
  store i64 %12662, i64* %3, align 8
  %12663 = inttoptr i64 %12661 to i32*
  %12664 = load i32, i32* %12663, align 4
  %12665 = add i32 %12657, %12664
  %12666 = zext i32 %12665 to i64
  store i64 %12666, i64* %372, align 8
  %12667 = icmp ult i32 %12665, %12664
  %12668 = icmp ult i32 %12665, %12657
  %12669 = or i1 %12667, %12668
  %12670 = zext i1 %12669 to i8
  store i8 %12670, i8* %18, align 1
  %12671 = and i32 %12665, 255
  %12672 = tail call i32 @llvm.ctpop.i32(i32 %12671)
  %12673 = trunc i32 %12672 to i8
  %12674 = and i8 %12673, 1
  %12675 = xor i8 %12674, 1
  store i8 %12675, i8* %19, align 1
  %12676 = xor i32 %12657, %12664
  %12677 = xor i32 %12676, %12665
  %12678 = lshr i32 %12677, 4
  %12679 = trunc i32 %12678 to i8
  %12680 = and i8 %12679, 1
  store i8 %12680, i8* %20, align 1
  %12681 = icmp eq i32 %12665, 0
  %12682 = zext i1 %12681 to i8
  store i8 %12682, i8* %21, align 1
  %12683 = lshr i32 %12665, 31
  %12684 = trunc i32 %12683 to i8
  store i8 %12684, i8* %22, align 1
  %12685 = lshr i32 %12664, 31
  %12686 = lshr i32 %12657, 31
  %12687 = xor i32 %12683, %12685
  %12688 = xor i32 %12683, %12686
  %12689 = add nuw nsw i32 %12687, %12688
  %12690 = icmp eq i32 %12689, 2
  %12691 = zext i1 %12690 to i8
  store i8 %12691, i8* %23, align 1
  %12692 = sext i32 %12665 to i64
  store i64 %12692, i64* %RSI.i1889, align 8
  %12693 = add i64 %12660, -1320
  %12694 = add i64 %12658, 19
  store i64 %12694, i64* %3, align 8
  %12695 = inttoptr i64 %12693 to i32*
  %12696 = load i32, i32* %12695, align 4
  %12697 = zext i32 %12696 to i64
  store i64 %12697, i64* %RAX.i1763, align 8
  %12698 = load i64, i64* %RCX.i1692, align 8
  %12699 = shl nsw i64 %12692, 2
  %12700 = add i64 %12699, %12698
  %12701 = add i64 %12658, 22
  store i64 %12701, i64* %3, align 8
  %12702 = inttoptr i64 %12700 to i32*
  store i32 %12696, i32* %12702, align 4
  %12703 = load i64, i64* %RBP.i, align 8
  %12704 = add i64 %12703, -60
  %12705 = load i64, i64* %3, align 8
  %12706 = add i64 %12705, 7
  store i64 %12706, i64* %3, align 8
  %12707 = inttoptr i64 %12704 to i32*
  store i32 0, i32* %12707, align 4
  %.pre724 = load i64, i64* %3, align 8
  br label %block_.L_4a5d78

block_.L_4a5d78:                                  ; preds = %block_.L_4a5e16, %routine_idivl__r9d.exit
  %12708 = phi i64 [ %13105, %block_.L_4a5e16 ], [ %.pre724, %routine_idivl__r9d.exit ]
  %12709 = load i64, i64* %RBP.i, align 8
  %12710 = add i64 %12709, -60
  %12711 = add i64 %12708, 4
  store i64 %12711, i64* %3, align 8
  %12712 = inttoptr i64 %12710 to i32*
  %12713 = load i32, i32* %12712, align 4
  %12714 = add i32 %12713, -4
  %12715 = icmp ult i32 %12713, 4
  %12716 = zext i1 %12715 to i8
  store i8 %12716, i8* %18, align 1
  %12717 = and i32 %12714, 255
  %12718 = tail call i32 @llvm.ctpop.i32(i32 %12717)
  %12719 = trunc i32 %12718 to i8
  %12720 = and i8 %12719, 1
  %12721 = xor i8 %12720, 1
  store i8 %12721, i8* %19, align 1
  %12722 = xor i32 %12714, %12713
  %12723 = lshr i32 %12722, 4
  %12724 = trunc i32 %12723 to i8
  %12725 = and i8 %12724, 1
  store i8 %12725, i8* %20, align 1
  %12726 = icmp eq i32 %12714, 0
  %12727 = zext i1 %12726 to i8
  store i8 %12727, i8* %21, align 1
  %12728 = lshr i32 %12714, 31
  %12729 = trunc i32 %12728 to i8
  store i8 %12729, i8* %22, align 1
  %12730 = lshr i32 %12713, 31
  %12731 = xor i32 %12728, %12730
  %12732 = add nuw nsw i32 %12731, %12730
  %12733 = icmp eq i32 %12732, 2
  %12734 = zext i1 %12733 to i8
  store i8 %12734, i8* %23, align 1
  %12735 = icmp ne i8 %12729, 0
  %12736 = xor i1 %12735, %12733
  %.v794 = select i1 %12736, i64 10, i64 177
  %12737 = add i64 %12708, %.v794
  store i64 %12737, i64* %3, align 8
  br i1 %12736, label %block_4a5d82, label %block_.L_4a5e29

block_4a5d82:                                     ; preds = %block_.L_4a5d78
  %12738 = add i64 %12709, -56
  %12739 = add i64 %12737, 7
  store i64 %12739, i64* %3, align 8
  %12740 = inttoptr i64 %12738 to i32*
  store i32 0, i32* %12740, align 4
  %.pre725 = load i64, i64* %3, align 8
  br label %block_.L_4a5d89

block_.L_4a5d89:                                  ; preds = %block_4a5d93, %block_4a5d82
  %12741 = phi i64 [ %13075, %block_4a5d93 ], [ %.pre725, %block_4a5d82 ]
  %12742 = load i64, i64* %RBP.i, align 8
  %12743 = add i64 %12742, -56
  %12744 = add i64 %12741, 4
  store i64 %12744, i64* %3, align 8
  %12745 = inttoptr i64 %12743 to i32*
  %12746 = load i32, i32* %12745, align 4
  %12747 = add i32 %12746, -4
  %12748 = icmp ult i32 %12746, 4
  %12749 = zext i1 %12748 to i8
  store i8 %12749, i8* %18, align 1
  %12750 = and i32 %12747, 255
  %12751 = tail call i32 @llvm.ctpop.i32(i32 %12750)
  %12752 = trunc i32 %12751 to i8
  %12753 = and i8 %12752, 1
  %12754 = xor i8 %12753, 1
  store i8 %12754, i8* %19, align 1
  %12755 = xor i32 %12747, %12746
  %12756 = lshr i32 %12755, 4
  %12757 = trunc i32 %12756 to i8
  %12758 = and i8 %12757, 1
  store i8 %12758, i8* %20, align 1
  %12759 = icmp eq i32 %12747, 0
  %12760 = zext i1 %12759 to i8
  store i8 %12760, i8* %21, align 1
  %12761 = lshr i32 %12747, 31
  %12762 = trunc i32 %12761 to i8
  store i8 %12762, i8* %22, align 1
  %12763 = lshr i32 %12746, 31
  %12764 = xor i32 %12761, %12763
  %12765 = add nuw nsw i32 %12764, %12763
  %12766 = icmp eq i32 %12765, 2
  %12767 = zext i1 %12766 to i8
  store i8 %12767, i8* %23, align 1
  %12768 = icmp ne i8 %12762, 0
  %12769 = xor i1 %12768, %12766
  %.v795 = select i1 %12769, i64 10, i64 141
  %12770 = add i64 %12741, %.v795
  store i64 %12770, i64* %3, align 8
  br i1 %12769, label %block_4a5d93, label %block_.L_4a5e16

block_4a5d93:                                     ; preds = %block_.L_4a5d89
  %12771 = add i64 %12742, -1152
  store i64 %12771, i64* %RAX.i1763, align 8
  %12772 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %12772, i64* %RCX.i1692, align 8
  %12773 = add i64 %12772, 6464
  %12774 = add i64 %12770, 22
  store i64 %12774, i64* %3, align 8
  %12775 = inttoptr i64 %12773 to i64*
  %12776 = load i64, i64* %12775, align 8
  store i64 %12776, i64* %RCX.i1692, align 8
  %12777 = add i64 %12742, -44
  %12778 = add i64 %12770, 26
  store i64 %12778, i64* %3, align 8
  %12779 = inttoptr i64 %12777 to i32*
  %12780 = load i32, i32* %12779, align 4
  %12781 = sext i32 %12780 to i64
  store i64 %12781, i64* %RDX.i1805, align 8
  %12782 = shl nsw i64 %12781, 3
  %12783 = add i64 %12782, %12776
  %12784 = add i64 %12770, 30
  store i64 %12784, i64* %3, align 8
  %12785 = inttoptr i64 %12783 to i64*
  %12786 = load i64, i64* %12785, align 8
  store i64 %12786, i64* %RCX.i1692, align 8
  %12787 = add i64 %12742, -496
  %12788 = add i64 %12770, 36
  store i64 %12788, i64* %3, align 8
  %12789 = inttoptr i64 %12787 to i32*
  %12790 = load i32, i32* %12789, align 4
  %12791 = zext i32 %12790 to i64
  store i64 %12791, i64* %RSI.i1889, align 8
  %12792 = add i64 %12742, -60
  %12793 = add i64 %12770, 39
  store i64 %12793, i64* %3, align 8
  %12794 = inttoptr i64 %12792 to i32*
  %12795 = load i32, i32* %12794, align 4
  %12796 = add i32 %12795, %12790
  %12797 = zext i32 %12796 to i64
  store i64 %12797, i64* %RSI.i1889, align 8
  %12798 = icmp ult i32 %12796, %12790
  %12799 = icmp ult i32 %12796, %12795
  %12800 = or i1 %12798, %12799
  %12801 = zext i1 %12800 to i8
  store i8 %12801, i8* %18, align 1
  %12802 = and i32 %12796, 255
  %12803 = tail call i32 @llvm.ctpop.i32(i32 %12802)
  %12804 = trunc i32 %12803 to i8
  %12805 = and i8 %12804, 1
  %12806 = xor i8 %12805, 1
  store i8 %12806, i8* %19, align 1
  %12807 = xor i32 %12795, %12790
  %12808 = xor i32 %12807, %12796
  %12809 = lshr i32 %12808, 4
  %12810 = trunc i32 %12809 to i8
  %12811 = and i8 %12810, 1
  store i8 %12811, i8* %20, align 1
  %12812 = icmp eq i32 %12796, 0
  %12813 = zext i1 %12812 to i8
  store i8 %12813, i8* %21, align 1
  %12814 = lshr i32 %12796, 31
  %12815 = trunc i32 %12814 to i8
  store i8 %12815, i8* %22, align 1
  %12816 = lshr i32 %12790, 31
  %12817 = lshr i32 %12795, 31
  %12818 = xor i32 %12814, %12816
  %12819 = xor i32 %12814, %12817
  %12820 = add nuw nsw i32 %12818, %12819
  %12821 = icmp eq i32 %12820, 2
  %12822 = zext i1 %12821 to i8
  store i8 %12822, i8* %23, align 1
  %12823 = add i64 %12742, -480
  %12824 = add i64 %12770, 45
  store i64 %12824, i64* %3, align 8
  %12825 = inttoptr i64 %12823 to i32*
  %12826 = load i32, i32* %12825, align 4
  %12827 = add i32 %12826, %12796
  %12828 = zext i32 %12827 to i64
  store i64 %12828, i64* %RSI.i1889, align 8
  %12829 = icmp ult i32 %12827, %12796
  %12830 = icmp ult i32 %12827, %12826
  %12831 = or i1 %12829, %12830
  %12832 = zext i1 %12831 to i8
  store i8 %12832, i8* %18, align 1
  %12833 = and i32 %12827, 255
  %12834 = tail call i32 @llvm.ctpop.i32(i32 %12833)
  %12835 = trunc i32 %12834 to i8
  %12836 = and i8 %12835, 1
  %12837 = xor i8 %12836, 1
  store i8 %12837, i8* %19, align 1
  %12838 = xor i32 %12826, %12796
  %12839 = xor i32 %12838, %12827
  %12840 = lshr i32 %12839, 4
  %12841 = trunc i32 %12840 to i8
  %12842 = and i8 %12841, 1
  store i8 %12842, i8* %20, align 1
  %12843 = icmp eq i32 %12827, 0
  %12844 = zext i1 %12843 to i8
  store i8 %12844, i8* %21, align 1
  %12845 = lshr i32 %12827, 31
  %12846 = trunc i32 %12845 to i8
  store i8 %12846, i8* %22, align 1
  %12847 = lshr i32 %12826, 31
  %12848 = xor i32 %12845, %12814
  %12849 = xor i32 %12845, %12847
  %12850 = add nuw nsw i32 %12848, %12849
  %12851 = icmp eq i32 %12850, 2
  %12852 = zext i1 %12851 to i8
  store i8 %12852, i8* %23, align 1
  %12853 = sext i32 %12827 to i64
  store i64 %12853, i64* %RDX.i1805, align 8
  %12854 = shl nsw i64 %12853, 3
  %12855 = add i64 %12786, %12854
  %12856 = add i64 %12770, 52
  store i64 %12856, i64* %3, align 8
  %12857 = inttoptr i64 %12855 to i64*
  %12858 = load i64, i64* %12857, align 8
  store i64 %12858, i64* %RCX.i1692, align 8
  %12859 = load i64, i64* %RBP.i, align 8
  %12860 = add i64 %12859, -492
  %12861 = add i64 %12770, 58
  store i64 %12861, i64* %3, align 8
  %12862 = inttoptr i64 %12860 to i32*
  %12863 = load i32, i32* %12862, align 4
  %12864 = zext i32 %12863 to i64
  store i64 %12864, i64* %RSI.i1889, align 8
  %12865 = add i64 %12859, -56
  %12866 = add i64 %12770, 61
  store i64 %12866, i64* %3, align 8
  %12867 = inttoptr i64 %12865 to i32*
  %12868 = load i32, i32* %12867, align 4
  %12869 = add i32 %12868, %12863
  %12870 = zext i32 %12869 to i64
  store i64 %12870, i64* %RSI.i1889, align 8
  %12871 = icmp ult i32 %12869, %12863
  %12872 = icmp ult i32 %12869, %12868
  %12873 = or i1 %12871, %12872
  %12874 = zext i1 %12873 to i8
  store i8 %12874, i8* %18, align 1
  %12875 = and i32 %12869, 255
  %12876 = tail call i32 @llvm.ctpop.i32(i32 %12875)
  %12877 = trunc i32 %12876 to i8
  %12878 = and i8 %12877, 1
  %12879 = xor i8 %12878, 1
  store i8 %12879, i8* %19, align 1
  %12880 = xor i32 %12868, %12863
  %12881 = xor i32 %12880, %12869
  %12882 = lshr i32 %12881, 4
  %12883 = trunc i32 %12882 to i8
  %12884 = and i8 %12883, 1
  store i8 %12884, i8* %20, align 1
  %12885 = icmp eq i32 %12869, 0
  %12886 = zext i1 %12885 to i8
  store i8 %12886, i8* %21, align 1
  %12887 = lshr i32 %12869, 31
  %12888 = trunc i32 %12887 to i8
  store i8 %12888, i8* %22, align 1
  %12889 = lshr i32 %12863, 31
  %12890 = lshr i32 %12868, 31
  %12891 = xor i32 %12887, %12889
  %12892 = xor i32 %12887, %12890
  %12893 = add nuw nsw i32 %12891, %12892
  %12894 = icmp eq i32 %12893, 2
  %12895 = zext i1 %12894 to i8
  store i8 %12895, i8* %23, align 1
  %12896 = add i64 %12859, -476
  %12897 = add i64 %12770, 67
  store i64 %12897, i64* %3, align 8
  %12898 = inttoptr i64 %12896 to i32*
  %12899 = load i32, i32* %12898, align 4
  %12900 = add i32 %12899, %12869
  %12901 = zext i32 %12900 to i64
  store i64 %12901, i64* %RSI.i1889, align 8
  %12902 = icmp ult i32 %12900, %12869
  %12903 = icmp ult i32 %12900, %12899
  %12904 = or i1 %12902, %12903
  %12905 = zext i1 %12904 to i8
  store i8 %12905, i8* %18, align 1
  %12906 = and i32 %12900, 255
  %12907 = tail call i32 @llvm.ctpop.i32(i32 %12906)
  %12908 = trunc i32 %12907 to i8
  %12909 = and i8 %12908, 1
  %12910 = xor i8 %12909, 1
  store i8 %12910, i8* %19, align 1
  %12911 = xor i32 %12899, %12869
  %12912 = xor i32 %12911, %12900
  %12913 = lshr i32 %12912, 4
  %12914 = trunc i32 %12913 to i8
  %12915 = and i8 %12914, 1
  store i8 %12915, i8* %20, align 1
  %12916 = icmp eq i32 %12900, 0
  %12917 = zext i1 %12916 to i8
  store i8 %12917, i8* %21, align 1
  %12918 = lshr i32 %12900, 31
  %12919 = trunc i32 %12918 to i8
  store i8 %12919, i8* %22, align 1
  %12920 = lshr i32 %12899, 31
  %12921 = xor i32 %12918, %12887
  %12922 = xor i32 %12918, %12920
  %12923 = add nuw nsw i32 %12921, %12922
  %12924 = icmp eq i32 %12923, 2
  %12925 = zext i1 %12924 to i8
  store i8 %12925, i8* %23, align 1
  %12926 = sext i32 %12900 to i64
  store i64 %12926, i64* %RDX.i1805, align 8
  %12927 = shl nsw i64 %12926, 1
  %12928 = add i64 %12858, %12927
  %12929 = add i64 %12770, 74
  store i64 %12929, i64* %3, align 8
  %12930 = inttoptr i64 %12928 to i16*
  %12931 = load i16, i16* %12930, align 2
  %12932 = zext i16 %12931 to i64
  store i64 %12932, i64* %RSI.i1889, align 8
  %12933 = add i64 %12859, -44
  %12934 = add i64 %12770, 78
  store i64 %12934, i64* %3, align 8
  %12935 = inttoptr i64 %12933 to i32*
  %12936 = load i32, i32* %12935, align 4
  %12937 = sext i32 %12936 to i64
  %12938 = shl nsw i64 %12937, 8
  store i64 %12938, i64* %RCX.i1692, align 8
  %12939 = load i64, i64* %RAX.i1763, align 8
  %12940 = add i64 %12938, %12939
  store i64 %12940, i64* %RAX.i1763, align 8
  %12941 = icmp ult i64 %12940, %12939
  %12942 = icmp ult i64 %12940, %12938
  %12943 = or i1 %12941, %12942
  %12944 = zext i1 %12943 to i8
  store i8 %12944, i8* %18, align 1
  %12945 = trunc i64 %12940 to i32
  %12946 = and i32 %12945, 255
  %12947 = tail call i32 @llvm.ctpop.i32(i32 %12946)
  %12948 = trunc i32 %12947 to i8
  %12949 = and i8 %12948, 1
  %12950 = xor i8 %12949, 1
  store i8 %12950, i8* %19, align 1
  %12951 = xor i64 %12939, %12940
  %12952 = lshr i64 %12951, 4
  %12953 = trunc i64 %12952 to i8
  %12954 = and i8 %12953, 1
  store i8 %12954, i8* %20, align 1
  %12955 = icmp eq i64 %12940, 0
  %12956 = zext i1 %12955 to i8
  store i8 %12956, i8* %21, align 1
  %12957 = lshr i64 %12940, 63
  %12958 = trunc i64 %12957 to i8
  store i8 %12958, i8* %22, align 1
  %12959 = lshr i64 %12939, 63
  %12960 = lshr i64 %12937, 55
  %12961 = and i64 %12960, 1
  %12962 = xor i64 %12957, %12959
  %12963 = xor i64 %12957, %12961
  %12964 = add nuw nsw i64 %12962, %12963
  %12965 = icmp eq i64 %12964, 2
  %12966 = zext i1 %12965 to i8
  store i8 %12966, i8* %23, align 1
  %12967 = load i64, i64* %RBP.i, align 8
  %12968 = add i64 %12967, -628
  %12969 = add i64 %12770, 92
  store i64 %12969, i64* %3, align 8
  %12970 = inttoptr i64 %12968 to i32*
  %12971 = load i32, i32* %12970, align 4
  %12972 = sext i32 %12971 to i64
  %12973 = shl nsw i64 %12972, 6
  store i64 %12973, i64* %RCX.i1692, align 8
  %12974 = add i64 %12973, %12940
  store i64 %12974, i64* %RAX.i1763, align 8
  %12975 = icmp ult i64 %12974, %12940
  %12976 = icmp ult i64 %12974, %12973
  %12977 = or i1 %12975, %12976
  %12978 = zext i1 %12977 to i8
  store i8 %12978, i8* %18, align 1
  %12979 = trunc i64 %12974 to i32
  %12980 = and i32 %12979, 255
  %12981 = tail call i32 @llvm.ctpop.i32(i32 %12980)
  %12982 = trunc i32 %12981 to i8
  %12983 = and i8 %12982, 1
  %12984 = xor i8 %12983, 1
  store i8 %12984, i8* %19, align 1
  %12985 = xor i64 %12940, %12974
  %12986 = lshr i64 %12985, 4
  %12987 = trunc i64 %12986 to i8
  %12988 = and i8 %12987, 1
  store i8 %12988, i8* %20, align 1
  %12989 = icmp eq i64 %12974, 0
  %12990 = zext i1 %12989 to i8
  store i8 %12990, i8* %21, align 1
  %12991 = lshr i64 %12974, 63
  %12992 = trunc i64 %12991 to i8
  store i8 %12992, i8* %22, align 1
  %12993 = lshr i64 %12972, 57
  %12994 = and i64 %12993, 1
  %12995 = xor i64 %12991, %12957
  %12996 = xor i64 %12991, %12994
  %12997 = add nuw nsw i64 %12995, %12996
  %12998 = icmp eq i64 %12997, 2
  %12999 = zext i1 %12998 to i8
  store i8 %12999, i8* %23, align 1
  %13000 = add i64 %12967, -60
  %13001 = add i64 %12770, 103
  store i64 %13001, i64* %3, align 8
  %13002 = inttoptr i64 %13000 to i32*
  %13003 = load i32, i32* %13002, align 4
  %13004 = sext i32 %13003 to i64
  %13005 = shl nsw i64 %13004, 4
  store i64 %13005, i64* %RCX.i1692, align 8
  %13006 = add i64 %13005, %12974
  store i64 %13006, i64* %RAX.i1763, align 8
  %13007 = icmp ult i64 %13006, %12974
  %13008 = icmp ult i64 %13006, %13005
  %13009 = or i1 %13007, %13008
  %13010 = zext i1 %13009 to i8
  store i8 %13010, i8* %18, align 1
  %13011 = trunc i64 %13006 to i32
  %13012 = and i32 %13011, 255
  %13013 = tail call i32 @llvm.ctpop.i32(i32 %13012)
  %13014 = trunc i32 %13013 to i8
  %13015 = and i8 %13014, 1
  %13016 = xor i8 %13015, 1
  store i8 %13016, i8* %19, align 1
  %13017 = xor i64 %13005, %12974
  %13018 = xor i64 %13017, %13006
  %13019 = lshr i64 %13018, 4
  %13020 = trunc i64 %13019 to i8
  %13021 = and i8 %13020, 1
  store i8 %13021, i8* %20, align 1
  %13022 = icmp eq i64 %13006, 0
  %13023 = zext i1 %13022 to i8
  store i8 %13023, i8* %21, align 1
  %13024 = lshr i64 %13006, 63
  %13025 = trunc i64 %13024 to i8
  store i8 %13025, i8* %22, align 1
  %13026 = lshr i64 %13004, 59
  %13027 = and i64 %13026, 1
  %13028 = xor i64 %13024, %12991
  %13029 = xor i64 %13024, %13027
  %13030 = add nuw nsw i64 %13028, %13029
  %13031 = icmp eq i64 %13030, 2
  %13032 = zext i1 %13031 to i8
  store i8 %13032, i8* %23, align 1
  %13033 = load i64, i64* %RBP.i, align 8
  %13034 = add i64 %13033, -56
  %13035 = add i64 %12770, 114
  store i64 %13035, i64* %3, align 8
  %13036 = inttoptr i64 %13034 to i32*
  %13037 = load i32, i32* %13036, align 4
  %13038 = sext i32 %13037 to i64
  store i64 %13038, i64* %RCX.i1692, align 8
  %13039 = shl nsw i64 %13038, 2
  %13040 = add i64 %13039, %13006
  %13041 = load i32, i32* %ESI.i7670, align 4
  %13042 = add i64 %12770, 117
  store i64 %13042, i64* %3, align 8
  %13043 = inttoptr i64 %13040 to i32*
  store i32 %13041, i32* %13043, align 4
  %13044 = load i64, i64* %RBP.i, align 8
  %13045 = add i64 %13044, -56
  %13046 = load i64, i64* %3, align 8
  %13047 = add i64 %13046, 3
  store i64 %13047, i64* %3, align 8
  %13048 = inttoptr i64 %13045 to i32*
  %13049 = load i32, i32* %13048, align 4
  %13050 = add i32 %13049, 1
  %13051 = zext i32 %13050 to i64
  store i64 %13051, i64* %RAX.i1763, align 8
  %13052 = icmp eq i32 %13049, -1
  %13053 = icmp eq i32 %13050, 0
  %13054 = or i1 %13052, %13053
  %13055 = zext i1 %13054 to i8
  store i8 %13055, i8* %18, align 1
  %13056 = and i32 %13050, 255
  %13057 = tail call i32 @llvm.ctpop.i32(i32 %13056)
  %13058 = trunc i32 %13057 to i8
  %13059 = and i8 %13058, 1
  %13060 = xor i8 %13059, 1
  store i8 %13060, i8* %19, align 1
  %13061 = xor i32 %13050, %13049
  %13062 = lshr i32 %13061, 4
  %13063 = trunc i32 %13062 to i8
  %13064 = and i8 %13063, 1
  store i8 %13064, i8* %20, align 1
  %13065 = zext i1 %13053 to i8
  store i8 %13065, i8* %21, align 1
  %13066 = lshr i32 %13050, 31
  %13067 = trunc i32 %13066 to i8
  store i8 %13067, i8* %22, align 1
  %13068 = lshr i32 %13049, 31
  %13069 = xor i32 %13066, %13068
  %13070 = add nuw nsw i32 %13069, %13066
  %13071 = icmp eq i32 %13070, 2
  %13072 = zext i1 %13071 to i8
  store i8 %13072, i8* %23, align 1
  %13073 = add i64 %13046, 9
  store i64 %13073, i64* %3, align 8
  store i32 %13050, i32* %13048, align 4
  %13074 = load i64, i64* %3, align 8
  %13075 = add i64 %13074, -136
  store i64 %13075, i64* %3, align 8
  br label %block_.L_4a5d89

block_.L_4a5e16:                                  ; preds = %block_.L_4a5d89
  %13076 = add i64 %12742, -60
  %13077 = add i64 %12770, 8
  store i64 %13077, i64* %3, align 8
  %13078 = inttoptr i64 %13076 to i32*
  %13079 = load i32, i32* %13078, align 4
  %13080 = add i32 %13079, 1
  %13081 = zext i32 %13080 to i64
  store i64 %13081, i64* %RAX.i1763, align 8
  %13082 = icmp eq i32 %13079, -1
  %13083 = icmp eq i32 %13080, 0
  %13084 = or i1 %13082, %13083
  %13085 = zext i1 %13084 to i8
  store i8 %13085, i8* %18, align 1
  %13086 = and i32 %13080, 255
  %13087 = tail call i32 @llvm.ctpop.i32(i32 %13086)
  %13088 = trunc i32 %13087 to i8
  %13089 = and i8 %13088, 1
  %13090 = xor i8 %13089, 1
  store i8 %13090, i8* %19, align 1
  %13091 = xor i32 %13080, %13079
  %13092 = lshr i32 %13091, 4
  %13093 = trunc i32 %13092 to i8
  %13094 = and i8 %13093, 1
  store i8 %13094, i8* %20, align 1
  %13095 = zext i1 %13083 to i8
  store i8 %13095, i8* %21, align 1
  %13096 = lshr i32 %13080, 31
  %13097 = trunc i32 %13096 to i8
  store i8 %13097, i8* %22, align 1
  %13098 = lshr i32 %13079, 31
  %13099 = xor i32 %13096, %13098
  %13100 = add nuw nsw i32 %13099, %13096
  %13101 = icmp eq i32 %13100, 2
  %13102 = zext i1 %13101 to i8
  store i8 %13102, i8* %23, align 1
  %13103 = add i64 %12770, 14
  store i64 %13103, i64* %3, align 8
  store i32 %13080, i32* %13078, align 4
  %13104 = load i64, i64* %3, align 8
  %13105 = add i64 %13104, -172
  store i64 %13105, i64* %3, align 8
  br label %block_.L_4a5d78

block_.L_4a5e29:                                  ; preds = %block_.L_4a5d78
  %13106 = add i64 %12709, -44
  %13107 = add i64 %12737, 8
  store i64 %13107, i64* %3, align 8
  %13108 = inttoptr i64 %13106 to i32*
  %13109 = load i32, i32* %13108, align 4
  %13110 = add i32 %13109, 1
  %13111 = zext i32 %13110 to i64
  store i64 %13111, i64* %RAX.i1763, align 8
  %13112 = icmp eq i32 %13109, -1
  %13113 = icmp eq i32 %13110, 0
  %13114 = or i1 %13112, %13113
  %13115 = zext i1 %13114 to i8
  store i8 %13115, i8* %18, align 1
  %13116 = and i32 %13110, 255
  %13117 = tail call i32 @llvm.ctpop.i32(i32 %13116)
  %13118 = trunc i32 %13117 to i8
  %13119 = and i8 %13118, 1
  %13120 = xor i8 %13119, 1
  store i8 %13120, i8* %19, align 1
  %13121 = xor i32 %13110, %13109
  %13122 = lshr i32 %13121, 4
  %13123 = trunc i32 %13122 to i8
  %13124 = and i8 %13123, 1
  store i8 %13124, i8* %20, align 1
  %13125 = zext i1 %13113 to i8
  store i8 %13125, i8* %21, align 1
  %13126 = lshr i32 %13110, 31
  %13127 = trunc i32 %13126 to i8
  store i8 %13127, i8* %22, align 1
  %13128 = lshr i32 %13109, 31
  %13129 = xor i32 %13126, %13128
  %13130 = add nuw nsw i32 %13129, %13126
  %13131 = icmp eq i32 %13130, 2
  %13132 = zext i1 %13131 to i8
  store i8 %13132, i8* %23, align 1
  %13133 = add i64 %12737, 14
  store i64 %13133, i64* %3, align 8
  store i32 %13110, i32* %13108, align 4
  %13134 = load i64, i64* %3, align 8
  %13135 = add i64 %13134, -753
  store i64 %13135, i64* %3, align 8
  br label %block_.L_4a5b46

block_.L_4a5e3c:                                  ; preds = %block_.L_4a5b46
  %13136 = add i64 %11561, -628
  %13137 = add i64 %11589, 11
  store i64 %13137, i64* %3, align 8
  %13138 = inttoptr i64 %13136 to i32*
  %13139 = load i32, i32* %13138, align 4
  %13140 = add i32 %13139, 1
  %13141 = zext i32 %13140 to i64
  store i64 %13141, i64* %RAX.i1763, align 8
  %13142 = icmp eq i32 %13139, -1
  %13143 = icmp eq i32 %13140, 0
  %13144 = or i1 %13142, %13143
  %13145 = zext i1 %13144 to i8
  store i8 %13145, i8* %18, align 1
  %13146 = and i32 %13140, 255
  %13147 = tail call i32 @llvm.ctpop.i32(i32 %13146)
  %13148 = trunc i32 %13147 to i8
  %13149 = and i8 %13148, 1
  %13150 = xor i8 %13149, 1
  store i8 %13150, i8* %19, align 1
  %13151 = xor i32 %13140, %13139
  %13152 = lshr i32 %13151, 4
  %13153 = trunc i32 %13152 to i8
  %13154 = and i8 %13153, 1
  store i8 %13154, i8* %20, align 1
  %13155 = zext i1 %13143 to i8
  store i8 %13155, i8* %21, align 1
  %13156 = lshr i32 %13140, 31
  %13157 = trunc i32 %13156 to i8
  store i8 %13157, i8* %22, align 1
  %13158 = lshr i32 %13139, 31
  %13159 = xor i32 %13156, %13158
  %13160 = add nuw nsw i32 %13159, %13156
  %13161 = icmp eq i32 %13160, 2
  %13162 = zext i1 %13161 to i8
  store i8 %13162, i8* %23, align 1
  %13163 = add i64 %11589, 20
  store i64 %13163, i64* %3, align 8
  store i32 %13140, i32* %13138, align 4
  %13164 = load i64, i64* %3, align 8
  %13165 = add i64 %13164, -1193
  store i64 %13165, i64* %3, align 8
  br label %block_.L_4a59a7

block_.L_4a5e55:                                  ; preds = %block_.L_4a59a7
  %13166 = add i64 %10884, -60
  %13167 = add i64 %10912, 7
  store i64 %13167, i64* %3, align 8
  %13168 = inttoptr i64 %13166 to i32*
  store i32 0, i32* %13168, align 4
  %.pre676 = load i64, i64* %3, align 8
  br label %block_.L_4a5e5c

block_.L_4a5e5c:                                  ; preds = %block_.L_4a5ece, %block_.L_4a5e55
  %13169 = phi i64 [ %13426, %block_.L_4a5ece ], [ %.pre676, %block_.L_4a5e55 ]
  %13170 = load i64, i64* %RBP.i, align 8
  %13171 = add i64 %13170, -60
  %13172 = add i64 %13169, 4
  store i64 %13172, i64* %3, align 8
  %13173 = inttoptr i64 %13171 to i32*
  %13174 = load i32, i32* %13173, align 4
  %13175 = add i32 %13174, -8
  %13176 = icmp ult i32 %13174, 8
  %13177 = zext i1 %13176 to i8
  store i8 %13177, i8* %18, align 1
  %13178 = and i32 %13175, 255
  %13179 = tail call i32 @llvm.ctpop.i32(i32 %13178)
  %13180 = trunc i32 %13179 to i8
  %13181 = and i8 %13180, 1
  %13182 = xor i8 %13181, 1
  store i8 %13182, i8* %19, align 1
  %13183 = xor i32 %13175, %13174
  %13184 = lshr i32 %13183, 4
  %13185 = trunc i32 %13184 to i8
  %13186 = and i8 %13185, 1
  store i8 %13186, i8* %20, align 1
  %13187 = icmp eq i32 %13175, 0
  %13188 = zext i1 %13187 to i8
  store i8 %13188, i8* %21, align 1
  %13189 = lshr i32 %13175, 31
  %13190 = trunc i32 %13189 to i8
  store i8 %13190, i8* %22, align 1
  %13191 = lshr i32 %13174, 31
  %13192 = xor i32 %13189, %13191
  %13193 = add nuw nsw i32 %13192, %13191
  %13194 = icmp eq i32 %13193, 2
  %13195 = zext i1 %13194 to i8
  store i8 %13195, i8* %23, align 1
  %13196 = icmp ne i8 %13190, 0
  %13197 = xor i1 %13196, %13194
  %.v853 = select i1 %13197, i64 10, i64 133
  %13198 = add i64 %13169, %.v853
  store i64 %13198, i64* %3, align 8
  br i1 %13197, label %block_4a5e66, label %block_.L_4a5ee1

block_4a5e66:                                     ; preds = %block_.L_4a5e5c
  %13199 = add i64 %13170, -56
  %13200 = add i64 %13198, 7
  store i64 %13200, i64* %3, align 8
  %13201 = inttoptr i64 %13199 to i32*
  store i32 0, i32* %13201, align 4
  %.pre677 = load i64, i64* %3, align 8
  br label %block_.L_4a5e6d

block_.L_4a5e6d:                                  ; preds = %block_4a5e77, %block_4a5e66
  %13202 = phi i64 [ %13396, %block_4a5e77 ], [ %.pre677, %block_4a5e66 ]
  %13203 = load i64, i64* %RBP.i, align 8
  %13204 = add i64 %13203, -56
  %13205 = add i64 %13202, 4
  store i64 %13205, i64* %3, align 8
  %13206 = inttoptr i64 %13204 to i32*
  %13207 = load i32, i32* %13206, align 4
  %13208 = add i32 %13207, -8
  %13209 = icmp ult i32 %13207, 8
  %13210 = zext i1 %13209 to i8
  store i8 %13210, i8* %18, align 1
  %13211 = and i32 %13208, 255
  %13212 = tail call i32 @llvm.ctpop.i32(i32 %13211)
  %13213 = trunc i32 %13212 to i8
  %13214 = and i8 %13213, 1
  %13215 = xor i8 %13214, 1
  store i8 %13215, i8* %19, align 1
  %13216 = xor i32 %13208, %13207
  %13217 = lshr i32 %13216, 4
  %13218 = trunc i32 %13217 to i8
  %13219 = and i8 %13218, 1
  store i8 %13219, i8* %20, align 1
  %13220 = icmp eq i32 %13208, 0
  %13221 = zext i1 %13220 to i8
  store i8 %13221, i8* %21, align 1
  %13222 = lshr i32 %13208, 31
  %13223 = trunc i32 %13222 to i8
  store i8 %13223, i8* %22, align 1
  %13224 = lshr i32 %13207, 31
  %13225 = xor i32 %13222, %13224
  %13226 = add nuw nsw i32 %13225, %13224
  %13227 = icmp eq i32 %13226, 2
  %13228 = zext i1 %13227 to i8
  store i8 %13228, i8* %23, align 1
  %13229 = icmp ne i8 %13223, 0
  %13230 = xor i1 %13229, %13227
  %.v792 = select i1 %13230, i64 10, i64 97
  %13231 = add i64 %13202, %.v792
  store i64 %13231, i64* %3, align 8
  br i1 %13230, label %block_4a5e77, label %block_.L_4a5ece

block_4a5e77:                                     ; preds = %block_.L_4a5e6d
  %13232 = add i64 %13203, -464
  store i64 %13232, i64* %RAX.i1763, align 8
  %13233 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %13233, i64* %RCX.i1692, align 8
  %13234 = add i64 %13233, 6424
  %13235 = add i64 %13231, 22
  store i64 %13235, i64* %3, align 8
  %13236 = inttoptr i64 %13234 to i64*
  %13237 = load i64, i64* %13236, align 8
  store i64 %13237, i64* %RCX.i1692, align 8
  %13238 = add i64 %13203, -496
  %13239 = add i64 %13231, 28
  store i64 %13239, i64* %3, align 8
  %13240 = inttoptr i64 %13238 to i32*
  %13241 = load i32, i32* %13240, align 4
  %13242 = zext i32 %13241 to i64
  store i64 %13242, i64* %RDX.i1805, align 8
  %13243 = add i64 %13203, -60
  %13244 = add i64 %13231, 31
  store i64 %13244, i64* %3, align 8
  %13245 = inttoptr i64 %13243 to i32*
  %13246 = load i32, i32* %13245, align 4
  %13247 = add i32 %13246, %13241
  %13248 = zext i32 %13247 to i64
  store i64 %13248, i64* %RDX.i1805, align 8
  %13249 = icmp ult i32 %13247, %13241
  %13250 = icmp ult i32 %13247, %13246
  %13251 = or i1 %13249, %13250
  %13252 = zext i1 %13251 to i8
  store i8 %13252, i8* %18, align 1
  %13253 = and i32 %13247, 255
  %13254 = tail call i32 @llvm.ctpop.i32(i32 %13253)
  %13255 = trunc i32 %13254 to i8
  %13256 = and i8 %13255, 1
  %13257 = xor i8 %13256, 1
  store i8 %13257, i8* %19, align 1
  %13258 = xor i32 %13246, %13241
  %13259 = xor i32 %13258, %13247
  %13260 = lshr i32 %13259, 4
  %13261 = trunc i32 %13260 to i8
  %13262 = and i8 %13261, 1
  store i8 %13262, i8* %20, align 1
  %13263 = icmp eq i32 %13247, 0
  %13264 = zext i1 %13263 to i8
  store i8 %13264, i8* %21, align 1
  %13265 = lshr i32 %13247, 31
  %13266 = trunc i32 %13265 to i8
  store i8 %13266, i8* %22, align 1
  %13267 = lshr i32 %13241, 31
  %13268 = lshr i32 %13246, 31
  %13269 = xor i32 %13265, %13267
  %13270 = xor i32 %13265, %13268
  %13271 = add nuw nsw i32 %13269, %13270
  %13272 = icmp eq i32 %13271, 2
  %13273 = zext i1 %13272 to i8
  store i8 %13273, i8* %23, align 1
  %13274 = sext i32 %13247 to i64
  store i64 %13274, i64* %RSI.i1889, align 8
  %13275 = shl nsw i64 %13274, 3
  %13276 = add i64 %13237, %13275
  %13277 = add i64 %13231, 38
  store i64 %13277, i64* %3, align 8
  %13278 = inttoptr i64 %13276 to i64*
  %13279 = load i64, i64* %13278, align 8
  store i64 %13279, i64* %RCX.i1692, align 8
  %13280 = add i64 %13203, -492
  %13281 = add i64 %13231, 44
  store i64 %13281, i64* %3, align 8
  %13282 = inttoptr i64 %13280 to i32*
  %13283 = load i32, i32* %13282, align 4
  %13284 = zext i32 %13283 to i64
  store i64 %13284, i64* %RDX.i1805, align 8
  %13285 = add i64 %13231, 47
  store i64 %13285, i64* %3, align 8
  %13286 = load i32, i32* %13206, align 4
  %13287 = add i32 %13286, %13283
  %13288 = zext i32 %13287 to i64
  store i64 %13288, i64* %RDX.i1805, align 8
  %13289 = icmp ult i32 %13287, %13283
  %13290 = icmp ult i32 %13287, %13286
  %13291 = or i1 %13289, %13290
  %13292 = zext i1 %13291 to i8
  store i8 %13292, i8* %18, align 1
  %13293 = and i32 %13287, 255
  %13294 = tail call i32 @llvm.ctpop.i32(i32 %13293)
  %13295 = trunc i32 %13294 to i8
  %13296 = and i8 %13295, 1
  %13297 = xor i8 %13296, 1
  store i8 %13297, i8* %19, align 1
  %13298 = xor i32 %13286, %13283
  %13299 = xor i32 %13298, %13287
  %13300 = lshr i32 %13299, 4
  %13301 = trunc i32 %13300 to i8
  %13302 = and i8 %13301, 1
  store i8 %13302, i8* %20, align 1
  %13303 = icmp eq i32 %13287, 0
  %13304 = zext i1 %13303 to i8
  store i8 %13304, i8* %21, align 1
  %13305 = lshr i32 %13287, 31
  %13306 = trunc i32 %13305 to i8
  store i8 %13306, i8* %22, align 1
  %13307 = lshr i32 %13283, 31
  %13308 = lshr i32 %13286, 31
  %13309 = xor i32 %13305, %13307
  %13310 = xor i32 %13305, %13308
  %13311 = add nuw nsw i32 %13309, %13310
  %13312 = icmp eq i32 %13311, 2
  %13313 = zext i1 %13312 to i8
  store i8 %13313, i8* %23, align 1
  %13314 = sext i32 %13287 to i64
  store i64 %13314, i64* %RSI.i1889, align 8
  %13315 = shl nsw i64 %13314, 1
  %13316 = add i64 %13279, %13315
  %13317 = add i64 %13231, 54
  store i64 %13317, i64* %3, align 8
  %13318 = inttoptr i64 %13316 to i16*
  %13319 = load i16, i16* %13318, align 2
  store i16 %13319, i16* %DI.i3531, align 2
  %13320 = load i64, i64* %RBP.i, align 8
  %13321 = add i64 %13320, -60
  %13322 = add i64 %13231, 58
  store i64 %13322, i64* %3, align 8
  %13323 = inttoptr i64 %13321 to i32*
  %13324 = load i32, i32* %13323, align 4
  %13325 = sext i32 %13324 to i64
  %13326 = shl nsw i64 %13325, 4
  store i64 %13326, i64* %RCX.i1692, align 8
  %13327 = load i64, i64* %RAX.i1763, align 8
  %13328 = add i64 %13326, %13327
  store i64 %13328, i64* %RAX.i1763, align 8
  %13329 = icmp ult i64 %13328, %13327
  %13330 = icmp ult i64 %13328, %13326
  %13331 = or i1 %13329, %13330
  %13332 = zext i1 %13331 to i8
  store i8 %13332, i8* %18, align 1
  %13333 = trunc i64 %13328 to i32
  %13334 = and i32 %13333, 255
  %13335 = tail call i32 @llvm.ctpop.i32(i32 %13334)
  %13336 = trunc i32 %13335 to i8
  %13337 = and i8 %13336, 1
  %13338 = xor i8 %13337, 1
  store i8 %13338, i8* %19, align 1
  %13339 = xor i64 %13326, %13327
  %13340 = xor i64 %13339, %13328
  %13341 = lshr i64 %13340, 4
  %13342 = trunc i64 %13341 to i8
  %13343 = and i8 %13342, 1
  store i8 %13343, i8* %20, align 1
  %13344 = icmp eq i64 %13328, 0
  %13345 = zext i1 %13344 to i8
  store i8 %13345, i8* %21, align 1
  %13346 = lshr i64 %13328, 63
  %13347 = trunc i64 %13346 to i8
  store i8 %13347, i8* %22, align 1
  %13348 = lshr i64 %13327, 63
  %13349 = lshr i64 %13325, 59
  %13350 = and i64 %13349, 1
  %13351 = xor i64 %13346, %13348
  %13352 = xor i64 %13346, %13350
  %13353 = add nuw nsw i64 %13351, %13352
  %13354 = icmp eq i64 %13353, 2
  %13355 = zext i1 %13354 to i8
  store i8 %13355, i8* %23, align 1
  %13356 = add i64 %13320, -56
  %13357 = add i64 %13231, 69
  store i64 %13357, i64* %3, align 8
  %13358 = inttoptr i64 %13356 to i32*
  %13359 = load i32, i32* %13358, align 4
  %13360 = sext i32 %13359 to i64
  store i64 %13360, i64* %RCX.i1692, align 8
  %13361 = shl nsw i64 %13360, 1
  %13362 = add i64 %13361, %13328
  %13363 = add i64 %13231, 73
  store i64 %13363, i64* %3, align 8
  %13364 = inttoptr i64 %13362 to i16*
  store i16 %13319, i16* %13364, align 2
  %13365 = load i64, i64* %RBP.i, align 8
  %13366 = add i64 %13365, -56
  %13367 = load i64, i64* %3, align 8
  %13368 = add i64 %13367, 3
  store i64 %13368, i64* %3, align 8
  %13369 = inttoptr i64 %13366 to i32*
  %13370 = load i32, i32* %13369, align 4
  %13371 = add i32 %13370, 1
  %13372 = zext i32 %13371 to i64
  store i64 %13372, i64* %RAX.i1763, align 8
  %13373 = icmp eq i32 %13370, -1
  %13374 = icmp eq i32 %13371, 0
  %13375 = or i1 %13373, %13374
  %13376 = zext i1 %13375 to i8
  store i8 %13376, i8* %18, align 1
  %13377 = and i32 %13371, 255
  %13378 = tail call i32 @llvm.ctpop.i32(i32 %13377)
  %13379 = trunc i32 %13378 to i8
  %13380 = and i8 %13379, 1
  %13381 = xor i8 %13380, 1
  store i8 %13381, i8* %19, align 1
  %13382 = xor i32 %13371, %13370
  %13383 = lshr i32 %13382, 4
  %13384 = trunc i32 %13383 to i8
  %13385 = and i8 %13384, 1
  store i8 %13385, i8* %20, align 1
  %13386 = zext i1 %13374 to i8
  store i8 %13386, i8* %21, align 1
  %13387 = lshr i32 %13371, 31
  %13388 = trunc i32 %13387 to i8
  store i8 %13388, i8* %22, align 1
  %13389 = lshr i32 %13370, 31
  %13390 = xor i32 %13387, %13389
  %13391 = add nuw nsw i32 %13390, %13387
  %13392 = icmp eq i32 %13391, 2
  %13393 = zext i1 %13392 to i8
  store i8 %13393, i8* %23, align 1
  %13394 = add i64 %13367, 9
  store i64 %13394, i64* %3, align 8
  store i32 %13371, i32* %13369, align 4
  %13395 = load i64, i64* %3, align 8
  %13396 = add i64 %13395, -92
  store i64 %13396, i64* %3, align 8
  br label %block_.L_4a5e6d

block_.L_4a5ece:                                  ; preds = %block_.L_4a5e6d
  %13397 = add i64 %13203, -60
  %13398 = add i64 %13231, 8
  store i64 %13398, i64* %3, align 8
  %13399 = inttoptr i64 %13397 to i32*
  %13400 = load i32, i32* %13399, align 4
  %13401 = add i32 %13400, 1
  %13402 = zext i32 %13401 to i64
  store i64 %13402, i64* %RAX.i1763, align 8
  %13403 = icmp eq i32 %13400, -1
  %13404 = icmp eq i32 %13401, 0
  %13405 = or i1 %13403, %13404
  %13406 = zext i1 %13405 to i8
  store i8 %13406, i8* %18, align 1
  %13407 = and i32 %13401, 255
  %13408 = tail call i32 @llvm.ctpop.i32(i32 %13407)
  %13409 = trunc i32 %13408 to i8
  %13410 = and i8 %13409, 1
  %13411 = xor i8 %13410, 1
  store i8 %13411, i8* %19, align 1
  %13412 = xor i32 %13401, %13400
  %13413 = lshr i32 %13412, 4
  %13414 = trunc i32 %13413 to i8
  %13415 = and i8 %13414, 1
  store i8 %13415, i8* %20, align 1
  %13416 = zext i1 %13404 to i8
  store i8 %13416, i8* %21, align 1
  %13417 = lshr i32 %13401, 31
  %13418 = trunc i32 %13417 to i8
  store i8 %13418, i8* %22, align 1
  %13419 = lshr i32 %13400, 31
  %13420 = xor i32 %13417, %13419
  %13421 = add nuw nsw i32 %13420, %13417
  %13422 = icmp eq i32 %13421, 2
  %13423 = zext i1 %13422 to i8
  store i8 %13423, i8* %23, align 1
  %13424 = add i64 %13231, 14
  store i64 %13424, i64* %3, align 8
  store i32 %13401, i32* %13399, align 4
  %13425 = load i64, i64* %3, align 8
  %13426 = add i64 %13425, -128
  store i64 %13426, i64* %3, align 8
  br label %block_.L_4a5e5c

block_.L_4a5ee1:                                  ; preds = %block_.L_4a5e5c
  %13427 = add i64 %13170, -72
  %13428 = add i64 %13198, 3
  store i64 %13428, i64* %3, align 8
  %13429 = inttoptr i64 %13427 to i32*
  %13430 = load i32, i32* %13429, align 4
  %13431 = zext i32 %13430 to i64
  store i64 %13431, i64* %RAX.i1763, align 8
  %13432 = add i64 %13170, -76
  %13433 = add i64 %13198, 6
  store i64 %13433, i64* %3, align 8
  %13434 = inttoptr i64 %13432 to i32*
  store i32 %13430, i32* %13434, align 4
  %13435 = load i64, i64* %RBP.i, align 8
  %13436 = add i64 %13435, -472
  %13437 = load i64, i64* %3, align 8
  %13438 = add i64 %13437, 8
  store i64 %13438, i64* %3, align 8
  %13439 = inttoptr i64 %13436 to i64*
  %13440 = load i64, i64* %13439, align 8
  store i64 %13440, i64* %54, align 1
  store double 0.000000e+00, double* %1228, align 1
  %13441 = add i64 %13435, -520
  %13442 = add i64 %13437, 16
  store i64 %13442, i64* %3, align 8
  %13443 = inttoptr i64 %13441 to i64*
  store i64 %13440, i64* %13443, align 8
  %13444 = load i64, i64* %RBP.i, align 8
  %13445 = add i64 %13444, -36
  %13446 = load i64, i64* %3, align 8
  %13447 = add i64 %13446, 3
  store i64 %13447, i64* %3, align 8
  %13448 = inttoptr i64 %13445 to i32*
  %13449 = load i32, i32* %13448, align 4
  %13450 = zext i32 %13449 to i64
  store i64 %13450, i64* %RAX.i1763, align 8
  %13451 = add i64 %13444, -40
  %13452 = add i64 %13446, 6
  store i64 %13452, i64* %3, align 8
  %13453 = inttoptr i64 %13451 to i32*
  store i32 %13449, i32* %13453, align 4
  %.pre730 = load i64, i64* %3, align 8
  br label %block_.L_4a5efd

block_.L_4a5efd:                                  ; preds = %block_.L_4a5ee1, %routine_ucomisd__xmm0___xmm1.exit
  %13454 = phi i64 [ %10602, %routine_ucomisd__xmm0___xmm1.exit ], [ %.pre730, %block_.L_4a5ee1 ]
  %MEMORY.69 = phi %struct.Memory* [ %10601, %routine_ucomisd__xmm0___xmm1.exit ], [ %MEMORY.59, %block_.L_4a5ee1 ]
  %13455 = add i64 %13454, 5
  store i64 %13455, i64* %3, align 8
  br label %block_.L_4a5f02

block_.L_4a5f02:                                  ; preds = %block_.L_4a5efd, %block_.L_4a4963
  %storemerge137 = phi i64 [ %3300, %block_.L_4a4963 ], [ %13455, %block_.L_4a5efd ]
  %MEMORY.70 = phi %struct.Memory* [ %call2_4a4965, %block_.L_4a4963 ], [ %MEMORY.69, %block_.L_4a5efd ]
  %13456 = add i64 %storemerge137, 5
  store i64 %13456, i64* %3, align 8
  br label %block_.L_4a5f07

block_.L_4a5f07:                                  ; preds = %block_.L_4a5f02, %block_.L_4a468d
  %storemerge129 = phi i64 [ %2038, %block_.L_4a468d ], [ %13456, %block_.L_4a5f02 ]
  %MEMORY.71 = phi %struct.Memory* [ %call2_4a4664, %block_.L_4a468d ], [ %MEMORY.70, %block_.L_4a5f02 ]
  %13457 = add i64 %storemerge129, 5
  store i64 %13457, i64* %3, align 8
  %.pre731 = load i64, i64* %RBP.i, align 8
  br label %block_.L_4a5f0c

block_.L_4a5f0c:                                  ; preds = %block_.L_4a5f07, %block_.L_4a453c
  %13458 = phi i64 [ %.pre731, %block_.L_4a5f07 ], [ %1235, %block_.L_4a453c ]
  %13459 = phi i64 [ %13457, %block_.L_4a5f07 ], [ %1441, %block_.L_4a453c ]
  %MEMORY.72 = phi %struct.Memory* [ %MEMORY.71, %block_.L_4a5f07 ], [ %MEMORY.12, %block_.L_4a453c ]
  %13460 = add i64 %13458, -36
  %13461 = add i64 %13459, 8
  store i64 %13461, i64* %3, align 8
  %13462 = inttoptr i64 %13460 to i32*
  %13463 = load i32, i32* %13462, align 4
  %13464 = add i32 %13463, 1
  %13465 = zext i32 %13464 to i64
  store i64 %13465, i64* %RAX.i1763, align 8
  %13466 = icmp eq i32 %13463, -1
  %13467 = icmp eq i32 %13464, 0
  %13468 = or i1 %13466, %13467
  %13469 = zext i1 %13468 to i8
  store i8 %13469, i8* %18, align 1
  %13470 = and i32 %13464, 255
  %13471 = tail call i32 @llvm.ctpop.i32(i32 %13470)
  %13472 = trunc i32 %13471 to i8
  %13473 = and i8 %13472, 1
  %13474 = xor i8 %13473, 1
  store i8 %13474, i8* %19, align 1
  %13475 = xor i32 %13464, %13463
  %13476 = lshr i32 %13475, 4
  %13477 = trunc i32 %13476 to i8
  %13478 = and i8 %13477, 1
  store i8 %13478, i8* %20, align 1
  %13479 = zext i1 %13467 to i8
  store i8 %13479, i8* %21, align 1
  %13480 = lshr i32 %13464, 31
  %13481 = trunc i32 %13480 to i8
  store i8 %13481, i8* %22, align 1
  %13482 = lshr i32 %13463, 31
  %13483 = xor i32 %13480, %13482
  %13484 = add nuw nsw i32 %13483, %13480
  %13485 = icmp eq i32 %13484, 2
  %13486 = zext i1 %13485 to i8
  store i8 %13486, i8* %23, align 1
  %13487 = add i64 %13459, 14
  store i64 %13487, i64* %3, align 8
  store i32 %13464, i32* %13462, align 4
  %13488 = load i64, i64* %3, align 8
  %13489 = add i64 %13488, -6718
  store i64 %13489, i64* %3, align 8
  br label %block_.L_4a44dc

block_.L_4a5f1f:                                  ; preds = %block_.L_4a44dc
  %13490 = add i64 %1235, -40
  %13491 = add i64 %1263, 3
  store i64 %13491, i64* %3, align 8
  %13492 = inttoptr i64 %13490 to i32*
  %13493 = load i32, i32* %13492, align 4
  %13494 = zext i32 %13493 to i64
  store i64 %13494, i64* %RAX.i1763, align 8
  %13495 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %13495, i64* %RCX.i1692, align 8
  %13496 = add i64 %13495, 112
  %13497 = add i64 %1263, 15
  store i64 %13497, i64* %3, align 8
  %13498 = inttoptr i64 %13496 to i64*
  %13499 = load i64, i64* %13498, align 8
  store i64 %13499, i64* %RCX.i1692, align 8
  %13500 = add i64 %1235, -508
  %13501 = add i64 %1263, 22
  store i64 %13501, i64* %3, align 8
  %13502 = inttoptr i64 %13500 to i32*
  %13503 = load i32, i32* %13502, align 4
  %13504 = sext i32 %13503 to i64
  store i64 %13504, i64* %RDX.i1805, align 8
  %13505 = shl nsw i64 %13504, 3
  %13506 = add i64 %13505, %13499
  %13507 = add i64 %1263, 26
  store i64 %13507, i64* %3, align 8
  %13508 = inttoptr i64 %13506 to i64*
  %13509 = load i64, i64* %13508, align 8
  store i64 %13509, i64* %RCX.i1692, align 8
  %13510 = add i64 %1235, -512
  %13511 = add i64 %1263, 33
  store i64 %13511, i64* %3, align 8
  %13512 = inttoptr i64 %13510 to i32*
  %13513 = load i32, i32* %13512, align 4
  %13514 = sext i32 %13513 to i64
  store i64 %13514, i64* %RDX.i1805, align 8
  %13515 = shl nsw i64 %13514, 2
  %13516 = add i64 %13515, %13509
  %13517 = add i64 %1263, 36
  store i64 %13517, i64* %3, align 8
  %13518 = inttoptr i64 %13516 to i32*
  store i32 %13493, i32* %13518, align 4
  %13519 = load i64, i64* %RBP.i, align 8
  %13520 = add i64 %13519, -552
  %13521 = load i64, i64* %3, align 8
  %13522 = add i64 %13521, 6
  store i64 %13522, i64* %3, align 8
  %13523 = inttoptr i64 %13520 to i32*
  %13524 = load i32, i32* %13523, align 4
  %13525 = zext i32 %13524 to i64
  store i64 %13525, i64* %RAX.i1763, align 8
  %13526 = add i64 %13519, -40
  %13527 = add i64 %13521, 9
  store i64 %13527, i64* %3, align 8
  %13528 = inttoptr i64 %13526 to i32*
  %13529 = load i32, i32* %13528, align 4
  %13530 = sub i32 %13524, %13529
  %13531 = icmp ult i32 %13524, %13529
  %13532 = zext i1 %13531 to i8
  store i8 %13532, i8* %18, align 1
  %13533 = and i32 %13530, 255
  %13534 = tail call i32 @llvm.ctpop.i32(i32 %13533)
  %13535 = trunc i32 %13534 to i8
  %13536 = and i8 %13535, 1
  %13537 = xor i8 %13536, 1
  store i8 %13537, i8* %19, align 1
  %13538 = xor i32 %13529, %13524
  %13539 = xor i32 %13538, %13530
  %13540 = lshr i32 %13539, 4
  %13541 = trunc i32 %13540 to i8
  %13542 = and i8 %13541, 1
  store i8 %13542, i8* %20, align 1
  %13543 = icmp eq i32 %13530, 0
  %13544 = zext i1 %13543 to i8
  store i8 %13544, i8* %21, align 1
  %13545 = lshr i32 %13530, 31
  %13546 = trunc i32 %13545 to i8
  store i8 %13546, i8* %22, align 1
  %13547 = lshr i32 %13524, 31
  %13548 = lshr i32 %13529, 31
  %13549 = xor i32 %13548, %13547
  %13550 = xor i32 %13545, %13547
  %13551 = add nuw nsw i32 %13550, %13549
  %13552 = icmp eq i32 %13551, 2
  %13553 = zext i1 %13552 to i8
  store i8 %13553, i8* %23, align 1
  %.v784 = select i1 %13543, i64 15, i64 31
  %13554 = add i64 %13521, %.v784
  store i64 %13554, i64* %3, align 8
  br i1 %13543, label %block_4a5f52, label %block_.L_4a5f62

block_4a5f52:                                     ; preds = %block_.L_4a5f1f
  store i64 4294967295, i64* %RAX.i1763, align 8
  %13555 = add i64 %13519, -1332
  %13556 = add i64 %13554, 11
  store i64 %13556, i64* %3, align 8
  %13557 = inttoptr i64 %13555 to i32*
  store i32 -1, i32* %13557, align 4
  %13558 = load i64, i64* %3, align 8
  %13559 = add i64 %13558, 58
  store i64 %13559, i64* %3, align 8
  br label %block_.L_4a5f97

block_.L_4a5f62:                                  ; preds = %block_.L_4a5f1f
  %13560 = add i64 %13554, 3
  store i64 %13560, i64* %3, align 8
  %13561 = load i32, i32* %13528, align 4
  %13562 = zext i32 %13561 to i64
  store i64 %13562, i64* %RAX.i1763, align 8
  %13563 = add i64 %13554, 9
  store i64 %13563, i64* %3, align 8
  %13564 = load i32, i32* %13523, align 4
  %13565 = sub i32 %13561, %13564
  %13566 = icmp ult i32 %13561, %13564
  %13567 = zext i1 %13566 to i8
  store i8 %13567, i8* %18, align 1
  %13568 = and i32 %13565, 255
  %13569 = tail call i32 @llvm.ctpop.i32(i32 %13568)
  %13570 = trunc i32 %13569 to i8
  %13571 = and i8 %13570, 1
  %13572 = xor i8 %13571, 1
  store i8 %13572, i8* %19, align 1
  %13573 = xor i32 %13564, %13561
  %13574 = xor i32 %13573, %13565
  %13575 = lshr i32 %13574, 4
  %13576 = trunc i32 %13575 to i8
  %13577 = and i8 %13576, 1
  store i8 %13577, i8* %20, align 1
  %13578 = icmp eq i32 %13565, 0
  %13579 = zext i1 %13578 to i8
  store i8 %13579, i8* %21, align 1
  %13580 = lshr i32 %13565, 31
  %13581 = trunc i32 %13580 to i8
  store i8 %13581, i8* %22, align 1
  %13582 = lshr i32 %13561, 31
  %13583 = lshr i32 %13564, 31
  %13584 = xor i32 %13583, %13582
  %13585 = xor i32 %13580, %13582
  %13586 = add nuw nsw i32 %13585, %13584
  %13587 = icmp eq i32 %13586, 2
  %13588 = zext i1 %13587 to i8
  store i8 %13588, i8* %23, align 1
  %13589 = icmp ne i8 %13581, 0
  %13590 = xor i1 %13589, %13587
  %.v783 = select i1 %13590, i64 15, i64 29
  %13591 = add i64 %13554, %.v783
  %13592 = add i64 %13591, 3
  store i64 %13592, i64* %3, align 8
  %13593 = load i32, i32* %13528, align 4
  %13594 = zext i32 %13593 to i64
  store i64 %13594, i64* %RAX.i1763, align 8
  br i1 %13590, label %block_4a5f71, label %block_.L_4a5f7f

block_4a5f71:                                     ; preds = %block_.L_4a5f62
  %13595 = add i64 %13519, -1336
  %13596 = add i64 %13591, 9
  store i64 %13596, i64* %3, align 8
  %13597 = inttoptr i64 %13595 to i32*
  store i32 %13593, i32* %13597, align 4
  %13598 = load i64, i64* %3, align 8
  %13599 = add i64 %13598, 17
  store i64 %13599, i64* %3, align 8
  br label %block_.L_4a5f8b

block_.L_4a5f7f:                                  ; preds = %block_.L_4a5f62
  %13600 = add i32 %13593, -1
  %13601 = zext i32 %13600 to i64
  store i64 %13601, i64* %RAX.i1763, align 8
  %13602 = icmp eq i32 %13593, 0
  %13603 = zext i1 %13602 to i8
  store i8 %13603, i8* %18, align 1
  %13604 = and i32 %13600, 255
  %13605 = tail call i32 @llvm.ctpop.i32(i32 %13604)
  %13606 = trunc i32 %13605 to i8
  %13607 = and i8 %13606, 1
  %13608 = xor i8 %13607, 1
  store i8 %13608, i8* %19, align 1
  %13609 = xor i32 %13600, %13593
  %13610 = lshr i32 %13609, 4
  %13611 = trunc i32 %13610 to i8
  %13612 = and i8 %13611, 1
  store i8 %13612, i8* %20, align 1
  %13613 = icmp eq i32 %13600, 0
  %13614 = zext i1 %13613 to i8
  store i8 %13614, i8* %21, align 1
  %13615 = lshr i32 %13600, 31
  %13616 = trunc i32 %13615 to i8
  store i8 %13616, i8* %22, align 1
  %13617 = lshr i32 %13593, 31
  %13618 = xor i32 %13615, %13617
  %13619 = add nuw nsw i32 %13618, %13617
  %13620 = icmp eq i32 %13619, 2
  %13621 = zext i1 %13620 to i8
  store i8 %13621, i8* %23, align 1
  %13622 = add i64 %13519, -1336
  %13623 = add i64 %13591, 12
  store i64 %13623, i64* %3, align 8
  %13624 = inttoptr i64 %13622 to i32*
  store i32 %13600, i32* %13624, align 4
  %.pre534 = load i64, i64* %3, align 8
  br label %block_.L_4a5f8b

block_.L_4a5f8b:                                  ; preds = %block_.L_4a5f7f, %block_4a5f71
  %13625 = phi i64 [ %.pre534, %block_.L_4a5f7f ], [ %13599, %block_4a5f71 ]
  %13626 = load i64, i64* %RBP.i, align 8
  %13627 = add i64 %13626, -1336
  %13628 = add i64 %13625, 6
  store i64 %13628, i64* %3, align 8
  %13629 = inttoptr i64 %13627 to i32*
  %13630 = load i32, i32* %13629, align 4
  %13631 = zext i32 %13630 to i64
  store i64 %13631, i64* %RAX.i1763, align 8
  %13632 = add i64 %13626, -1332
  %13633 = add i64 %13625, 12
  store i64 %13633, i64* %3, align 8
  %13634 = inttoptr i64 %13632 to i32*
  store i32 %13630, i32* %13634, align 4
  %.pre535 = load i64, i64* %3, align 8
  br label %block_.L_4a5f97

block_.L_4a5f97:                                  ; preds = %block_.L_4a5f8b, %block_4a5f52
  %13635 = phi i64 [ %.pre535, %block_.L_4a5f8b ], [ %13559, %block_4a5f52 ]
  %13636 = load i64, i64* %RBP.i, align 8
  %13637 = add i64 %13636, -1332
  %13638 = add i64 %13635, 6
  store i64 %13638, i64* %3, align 8
  %13639 = inttoptr i64 %13637 to i32*
  %13640 = load i32, i32* %13639, align 4
  %13641 = zext i32 %13640 to i64
  store i64 %13641, i64* %RAX.i1763, align 8
  %13642 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %13642, i64* %RCX.i1692, align 8
  %13643 = add i64 %13642, 14168
  %13644 = add i64 %13635, 21
  store i64 %13644, i64* %3, align 8
  %13645 = inttoptr i64 %13643 to i64*
  %13646 = load i64, i64* %13645, align 8
  store i64 %13646, i64* %RCX.i1692, align 8
  store i64 %13642, i64* %RDX.i1805, align 8
  %13647 = add i64 %13642, 12
  %13648 = add i64 %13635, 33
  store i64 %13648, i64* %3, align 8
  %13649 = inttoptr i64 %13647 to i32*
  %13650 = load i32, i32* %13649, align 4
  %13651 = sext i32 %13650 to i64
  %13652 = mul nsw i64 %13651, 632
  store i64 %13652, i64* %RDX.i1805, align 8
  %13653 = lshr i64 %13652, 63
  %13654 = add i64 %13652, %13646
  store i64 %13654, i64* %RCX.i1692, align 8
  %13655 = icmp ult i64 %13654, %13646
  %13656 = icmp ult i64 %13654, %13652
  %13657 = or i1 %13655, %13656
  %13658 = zext i1 %13657 to i8
  store i8 %13658, i8* %18, align 1
  %13659 = trunc i64 %13654 to i32
  %13660 = and i32 %13659, 255
  %13661 = tail call i32 @llvm.ctpop.i32(i32 %13660)
  %13662 = trunc i32 %13661 to i8
  %13663 = and i8 %13662, 1
  %13664 = xor i8 %13663, 1
  store i8 %13664, i8* %19, align 1
  %13665 = xor i64 %13652, %13646
  %13666 = xor i64 %13665, %13654
  %13667 = lshr i64 %13666, 4
  %13668 = trunc i64 %13667 to i8
  %13669 = and i8 %13668, 1
  store i8 %13669, i8* %20, align 1
  %13670 = icmp eq i64 %13654, 0
  %13671 = zext i1 %13670 to i8
  store i8 %13671, i8* %21, align 1
  %13672 = lshr i64 %13654, 63
  %13673 = trunc i64 %13672 to i8
  store i8 %13673, i8* %22, align 1
  %13674 = lshr i64 %13646, 63
  %13675 = xor i64 %13672, %13674
  %13676 = xor i64 %13672, %13653
  %13677 = add nuw nsw i64 %13675, %13676
  %13678 = icmp eq i64 %13677, 2
  %13679 = zext i1 %13678 to i8
  store i8 %13679, i8* %23, align 1
  %13680 = add i64 %13636, -12
  %13681 = add i64 %13635, 46
  store i64 %13681, i64* %3, align 8
  %13682 = inttoptr i64 %13680 to i32*
  %13683 = load i32, i32* %13682, align 4
  %13684 = shl i32 %13683, 2
  %13685 = zext i32 %13684 to i64
  store i64 %13685, i64* %RSI.i1889, align 8
  %13686 = lshr i32 %13683, 30
  %13687 = trunc i32 %13686 to i8
  %13688 = and i8 %13687, 1
  store i8 %13688, i8* %18, align 1
  %13689 = and i32 %13684, 252
  %13690 = tail call i32 @llvm.ctpop.i32(i32 %13689)
  %13691 = trunc i32 %13690 to i8
  %13692 = and i8 %13691, 1
  %13693 = xor i8 %13692, 1
  store i8 %13693, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %13694 = icmp eq i32 %13684, 0
  %13695 = zext i1 %13694 to i8
  store i8 %13695, i8* %21, align 1
  %13696 = lshr i32 %13683, 29
  %13697 = trunc i32 %13696 to i8
  %13698 = and i8 %13697, 1
  store i8 %13698, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %13699 = sext i32 %13684 to i64
  store i64 %13699, i64* %RDX.i1805, align 8
  %13700 = shl nsw i64 %13699, 2
  %13701 = add nsw i64 %13700, 396
  %13702 = add i64 %13701, %13654
  %13703 = load i32, i32* %EAX.i2159, align 4
  %13704 = add i64 %13635, 59
  store i64 %13704, i64* %3, align 8
  %13705 = inttoptr i64 %13702 to i32*
  store i32 %13703, i32* %13705, align 4
  %13706 = load i64, i64* %RBP.i, align 8
  %13707 = add i64 %13706, -48
  %13708 = load i64, i64* %3, align 8
  %13709 = add i64 %13708, 7
  store i64 %13709, i64* %3, align 8
  %13710 = inttoptr i64 %13707 to i32*
  store i32 0, i32* %13710, align 4
  %.pre536 = load i64, i64* %3, align 8
  br label %block_.L_4a5fd9

block_.L_4a5fd9:                                  ; preds = %block_.L_4a6099, %block_.L_4a5f97
  %13711 = phi i64 [ %.pre536, %block_.L_4a5f97 ], [ %14104, %block_.L_4a6099 ]
  %MEMORY.75 = phi %struct.Memory* [ %MEMORY.12, %block_.L_4a5f97 ], [ %MEMORY.76, %block_.L_4a6099 ]
  %13712 = load i64, i64* %RBP.i, align 8
  %13713 = add i64 %13712, -48
  %13714 = add i64 %13711, 4
  store i64 %13714, i64* %3, align 8
  %13715 = inttoptr i64 %13713 to i32*
  %13716 = load i32, i32* %13715, align 4
  %13717 = add i32 %13716, -2
  %13718 = icmp ult i32 %13716, 2
  %13719 = zext i1 %13718 to i8
  store i8 %13719, i8* %18, align 1
  %13720 = and i32 %13717, 255
  %13721 = tail call i32 @llvm.ctpop.i32(i32 %13720)
  %13722 = trunc i32 %13721 to i8
  %13723 = and i8 %13722, 1
  %13724 = xor i8 %13723, 1
  store i8 %13724, i8* %19, align 1
  %13725 = xor i32 %13717, %13716
  %13726 = lshr i32 %13725, 4
  %13727 = trunc i32 %13726 to i8
  %13728 = and i8 %13727, 1
  store i8 %13728, i8* %20, align 1
  %13729 = icmp eq i32 %13717, 0
  %13730 = zext i1 %13729 to i8
  store i8 %13730, i8* %21, align 1
  %13731 = lshr i32 %13717, 31
  %13732 = trunc i32 %13731 to i8
  store i8 %13732, i8* %22, align 1
  %13733 = lshr i32 %13716, 31
  %13734 = xor i32 %13731, %13733
  %13735 = add nuw nsw i32 %13734, %13733
  %13736 = icmp eq i32 %13735, 2
  %13737 = zext i1 %13736 to i8
  store i8 %13737, i8* %23, align 1
  %13738 = icmp ne i8 %13732, 0
  %13739 = xor i1 %13738, %13736
  %.v764 = select i1 %13739, i64 10, i64 211
  %13740 = add i64 %13711, %.v764
  store i64 %13740, i64* %3, align 8
  br i1 %13739, label %block_4a5fe3, label %block_.L_4a60ac

block_4a5fe3:                                     ; preds = %block_.L_4a5fd9
  %13741 = add i64 %13712, -44
  %13742 = add i64 %13740, 7
  store i64 %13742, i64* %3, align 8
  %13743 = inttoptr i64 %13741 to i32*
  store i32 0, i32* %13743, align 4
  %.pre648 = load i64, i64* %3, align 8
  br label %block_.L_4a5fea

block_.L_4a5fea:                                  ; preds = %routine_idivl__r8d.exit, %block_4a5fe3
  %13744 = phi i64 [ %.pre648, %block_4a5fe3 ], [ %14074, %routine_idivl__r8d.exit ]
  %MEMORY.76 = phi %struct.Memory* [ %MEMORY.75, %block_4a5fe3 ], [ %13984, %routine_idivl__r8d.exit ]
  %13745 = load i64, i64* %RBP.i, align 8
  %13746 = add i64 %13745, -44
  %13747 = add i64 %13744, 4
  store i64 %13747, i64* %3, align 8
  %13748 = inttoptr i64 %13746 to i32*
  %13749 = load i32, i32* %13748, align 4
  %13750 = add i32 %13749, -2
  %13751 = icmp ult i32 %13749, 2
  %13752 = zext i1 %13751 to i8
  store i8 %13752, i8* %18, align 1
  %13753 = and i32 %13750, 255
  %13754 = tail call i32 @llvm.ctpop.i32(i32 %13753)
  %13755 = trunc i32 %13754 to i8
  %13756 = and i8 %13755, 1
  %13757 = xor i8 %13756, 1
  store i8 %13757, i8* %19, align 1
  %13758 = xor i32 %13750, %13749
  %13759 = lshr i32 %13758, 4
  %13760 = trunc i32 %13759 to i8
  %13761 = and i8 %13760, 1
  store i8 %13761, i8* %20, align 1
  %13762 = icmp eq i32 %13750, 0
  %13763 = zext i1 %13762 to i8
  store i8 %13763, i8* %21, align 1
  %13764 = lshr i32 %13750, 31
  %13765 = trunc i32 %13764 to i8
  store i8 %13765, i8* %22, align 1
  %13766 = lshr i32 %13749, 31
  %13767 = xor i32 %13764, %13766
  %13768 = add nuw nsw i32 %13767, %13766
  %13769 = icmp eq i32 %13768, 2
  %13770 = zext i1 %13769 to i8
  store i8 %13770, i8* %23, align 1
  %13771 = icmp ne i8 %13765, 0
  %13772 = xor i1 %13771, %13769
  %.v837 = select i1 %13772, i64 10, i64 175
  %13773 = add i64 %13744, %.v837
  %13774 = add i64 %13773, 5
  store i64 %13774, i64* %3, align 8
  br i1 %13772, label %block_4a5ff4, label %block_.L_4a6099

block_4a5ff4:                                     ; preds = %block_.L_4a5fea
  store i64 2, i64* %RAX.i1763, align 8
  %13775 = add i64 %13745, -40
  %13776 = add i64 %13773, 8
  store i64 %13776, i64* %3, align 8
  %13777 = inttoptr i64 %13775 to i32*
  %13778 = load i32, i32* %13777, align 4
  %13779 = zext i32 %13778 to i64
  store i64 %13779, i64* %RCX.i1692, align 8
  %13780 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %13780, i64* %RDX.i1805, align 8
  %13781 = add i64 %13780, 112
  %13782 = add i64 %13773, 20
  store i64 %13782, i64* %3, align 8
  %13783 = inttoptr i64 %13781 to i64*
  %13784 = load i64, i64* %13783, align 8
  store i64 %13784, i64* %RDX.i1805, align 8
  %13785 = add i64 %13773, 23
  store i64 %13785, i64* %3, align 8
  %13786 = load i32, i32* %13748, align 4
  %13787 = zext i32 %13786 to i64
  store i64 %13787, i64* %RSI.i1889, align 8
  store i64 %13780, i64* %RDI.i2141, align 8
  %13788 = add i64 %13780, 136
  %13789 = add i64 %13773, 38
  store i64 %13789, i64* %3, align 8
  %13790 = inttoptr i64 %13788 to i32*
  %13791 = load i32, i32* %13790, align 4
  %13792 = shl i32 %13791, 2
  %13793 = zext i32 %13792 to i64
  store i64 %13793, i64* %26, align 8
  %13794 = add i32 %13792, %13786
  %13795 = zext i32 %13794 to i64
  store i64 %13795, i64* %RSI.i1889, align 8
  %13796 = icmp ult i32 %13794, %13786
  %13797 = icmp ult i32 %13794, %13792
  %13798 = or i1 %13796, %13797
  %13799 = zext i1 %13798 to i8
  store i8 %13799, i8* %18, align 1
  %13800 = and i32 %13794, 255
  %13801 = tail call i32 @llvm.ctpop.i32(i32 %13800)
  %13802 = trunc i32 %13801 to i8
  %13803 = and i8 %13802, 1
  %13804 = xor i8 %13803, 1
  store i8 %13804, i8* %19, align 1
  %13805 = xor i32 %13792, %13786
  %13806 = xor i32 %13805, %13794
  %13807 = lshr i32 %13806, 4
  %13808 = trunc i32 %13807 to i8
  %13809 = and i8 %13808, 1
  store i8 %13809, i8* %20, align 1
  %13810 = icmp eq i32 %13794, 0
  %13811 = zext i1 %13810 to i8
  store i8 %13811, i8* %21, align 1
  %13812 = lshr i32 %13794, 31
  %13813 = trunc i32 %13812 to i8
  store i8 %13813, i8* %22, align 1
  %13814 = lshr i32 %13786, 31
  %13815 = lshr i32 %13791, 29
  %13816 = and i32 %13815, 1
  %13817 = xor i32 %13812, %13814
  %13818 = xor i32 %13812, %13816
  %13819 = add nuw nsw i32 %13817, %13818
  %13820 = icmp eq i32 %13819, 2
  %13821 = zext i1 %13820 to i8
  store i8 %13821, i8* %23, align 1
  %13822 = add i64 %13745, -12
  %13823 = add i64 %13773, 49
  store i64 %13823, i64* %3, align 8
  %13824 = inttoptr i64 %13822 to i32*
  %13825 = load i32, i32* %13824, align 4
  %13826 = zext i32 %13825 to i64
  store i64 %13826, i64* %26, align 8
  %13827 = load i64, i64* %RBP.i, align 8
  %13828 = add i64 %13827, -1340
  %13829 = load i32, i32* %EAX.i2159, align 4
  %13830 = add i64 %13773, 55
  store i64 %13830, i64* %3, align 8
  %13831 = inttoptr i64 %13828 to i32*
  store i32 %13829, i32* %13831, align 4
  %13832 = load i32, i32* %R8D.i1718, align 4
  %13833 = zext i32 %13832 to i64
  %13834 = load i64, i64* %3, align 8
  store i64 %13833, i64* %RAX.i1763, align 8
  %13835 = load i64, i64* %RBP.i, align 8
  %13836 = add i64 %13835, -1352
  %13837 = load i64, i64* %RDX.i1805, align 8
  %13838 = add i64 %13834, 10
  store i64 %13838, i64* %3, align 8
  %13839 = inttoptr i64 %13836 to i64*
  store i64 %13837, i64* %13839, align 8
  %13840 = load i64, i64* %3, align 8
  %13841 = load i32, i32* %EAX.i2159, align 8
  %13842 = sext i32 %13841 to i64
  %13843 = lshr i64 %13842, 32
  store i64 %13843, i64* %101, align 8
  %13844 = load i64, i64* %RBP.i, align 8
  %13845 = add i64 %13844, -1340
  %13846 = add i64 %13840, 8
  store i64 %13846, i64* %3, align 8
  %13847 = inttoptr i64 %13845 to i32*
  %13848 = load i32, i32* %13847, align 4
  %13849 = zext i32 %13848 to i64
  store i64 %13849, i64* %26, align 8
  %13850 = add i64 %13840, 11
  store i64 %13850, i64* %3, align 8
  %13851 = zext i32 %13841 to i64
  %13852 = sext i32 %13848 to i64
  %13853 = shl nuw i64 %13843, 32
  %13854 = or i64 %13853, %13851
  %13855 = sdiv i64 %13854, %13852
  %13856 = shl i64 %13855, 32
  %13857 = ashr exact i64 %13856, 32
  %13858 = icmp eq i64 %13855, %13857
  br i1 %13858, label %13861, label %13859

; <label>:13859:                                  ; preds = %block_4a5ff4
  %13860 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %13850, %struct.Memory* %MEMORY.76)
  %.pre649 = load i64, i64* %RDX.i1805, align 8
  %.pre650 = load i64, i64* %3, align 8
  %.pre651 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r8d.exit3327

; <label>:13861:                                  ; preds = %block_4a5ff4
  %13862 = srem i64 %13854, %13852
  %13863 = and i64 %13855, 4294967295
  store i64 %13863, i64* %RAX.i1763, align 8
  %13864 = and i64 %13862, 4294967295
  store i64 %13864, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r8d.exit3327

routine_idivl__r8d.exit3327:                      ; preds = %13861, %13859
  %13865 = phi i64 [ %.pre651, %13859 ], [ %13844, %13861 ]
  %13866 = phi i64 [ %.pre650, %13859 ], [ %13850, %13861 ]
  %13867 = phi i64 [ %.pre649, %13859 ], [ %13864, %13861 ]
  %13868 = phi %struct.Memory* [ %13860, %13859 ], [ %MEMORY.76, %13861 ]
  %13869 = trunc i64 %13867 to i32
  %13870 = shl i32 %13869, 1
  %13871 = zext i32 %13870 to i64
  store i64 %13871, i64* %RDX.i1805, align 8
  %13872 = load i64, i64* %RSI.i1889, align 8
  %13873 = trunc i64 %13872 to i32
  %13874 = add i32 %13870, %13873
  %13875 = zext i32 %13874 to i64
  store i64 %13875, i64* %RSI.i1889, align 8
  %13876 = icmp ult i32 %13874, %13873
  %13877 = icmp ult i32 %13874, %13870
  %13878 = or i1 %13876, %13877
  %13879 = zext i1 %13878 to i8
  store i8 %13879, i8* %18, align 1
  %13880 = and i32 %13874, 255
  %13881 = tail call i32 @llvm.ctpop.i32(i32 %13880)
  %13882 = trunc i32 %13881 to i8
  %13883 = and i8 %13882, 1
  %13884 = xor i8 %13883, 1
  store i8 %13884, i8* %19, align 1
  %13885 = xor i64 %13871, %13872
  %13886 = trunc i64 %13885 to i32
  %13887 = xor i32 %13886, %13874
  %13888 = lshr i32 %13887, 4
  %13889 = trunc i32 %13888 to i8
  %13890 = and i8 %13889, 1
  store i8 %13890, i8* %20, align 1
  %13891 = icmp eq i32 %13874, 0
  %13892 = zext i1 %13891 to i8
  store i8 %13892, i8* %21, align 1
  %13893 = lshr i32 %13874, 31
  %13894 = trunc i32 %13893 to i8
  store i8 %13894, i8* %22, align 1
  %13895 = lshr i32 %13873, 31
  %13896 = lshr i32 %13869, 30
  %13897 = and i32 %13896, 1
  %13898 = xor i32 %13893, %13895
  %13899 = xor i32 %13893, %13897
  %13900 = add nuw nsw i32 %13898, %13899
  %13901 = icmp eq i32 %13900, 2
  %13902 = zext i1 %13901 to i8
  store i8 %13902, i8* %23, align 1
  %13903 = sext i32 %13874 to i64
  store i64 %13903, i64* %RDI.i2141, align 8
  %13904 = add i64 %13865, -1352
  %13905 = add i64 %13866, 14
  store i64 %13905, i64* %3, align 8
  %13906 = inttoptr i64 %13904 to i64*
  %13907 = load i64, i64* %13906, align 8
  store i64 %13907, i64* %R9.i, align 8
  %13908 = shl nsw i64 %13903, 3
  %13909 = add i64 %13908, %13907
  %13910 = add i64 %13866, 18
  store i64 %13910, i64* %3, align 8
  %13911 = inttoptr i64 %13909 to i64*
  %13912 = load i64, i64* %13911, align 8
  store i64 %13912, i64* %RDI.i2141, align 8
  %13913 = add i64 %13865, -48
  %13914 = add i64 %13866, 21
  store i64 %13914, i64* %3, align 8
  %13915 = inttoptr i64 %13913 to i32*
  %13916 = load i32, i32* %13915, align 4
  %13917 = zext i32 %13916 to i64
  store i64 %13917, i64* %RDX.i1805, align 8
  %13918 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %13918, i64* %372, align 8
  %13919 = add i64 %13918, 140
  %13920 = add i64 %13866, 36
  store i64 %13920, i64* %3, align 8
  %13921 = inttoptr i64 %13919 to i32*
  %13922 = load i32, i32* %13921, align 4
  %13923 = shl i32 %13922, 2
  %13924 = zext i32 %13923 to i64
  store i64 %13924, i64* %RSI.i1889, align 8
  %13925 = add i32 %13923, %13916
  %13926 = zext i32 %13925 to i64
  store i64 %13926, i64* %RDX.i1805, align 8
  %13927 = icmp ult i32 %13925, %13916
  %13928 = icmp ult i32 %13925, %13923
  %13929 = or i1 %13927, %13928
  %13930 = zext i1 %13929 to i8
  store i8 %13930, i8* %18, align 1
  %13931 = and i32 %13925, 255
  %13932 = tail call i32 @llvm.ctpop.i32(i32 %13931)
  %13933 = trunc i32 %13932 to i8
  %13934 = and i8 %13933, 1
  %13935 = xor i8 %13934, 1
  store i8 %13935, i8* %19, align 1
  %13936 = xor i32 %13923, %13916
  %13937 = xor i32 %13936, %13925
  %13938 = lshr i32 %13937, 4
  %13939 = trunc i32 %13938 to i8
  %13940 = and i8 %13939, 1
  store i8 %13940, i8* %20, align 1
  %13941 = icmp eq i32 %13925, 0
  %13942 = zext i1 %13941 to i8
  store i8 %13942, i8* %21, align 1
  %13943 = lshr i32 %13925, 31
  %13944 = trunc i32 %13943 to i8
  store i8 %13944, i8* %22, align 1
  %13945 = lshr i32 %13916, 31
  %13946 = lshr i32 %13922, 29
  %13947 = and i32 %13946, 1
  %13948 = xor i32 %13943, %13945
  %13949 = xor i32 %13943, %13947
  %13950 = add nuw nsw i32 %13948, %13949
  %13951 = icmp eq i32 %13950, 2
  %13952 = zext i1 %13951 to i8
  store i8 %13952, i8* %23, align 1
  %13953 = load i64, i64* %RBP.i, align 8
  %13954 = add i64 %13953, -12
  %13955 = add i64 %13866, 44
  store i64 %13955, i64* %3, align 8
  %13956 = inttoptr i64 %13954 to i32*
  %13957 = load i32, i32* %13956, align 4
  %13958 = zext i32 %13957 to i64
  store i64 %13958, i64* %RSI.i1889, align 8
  store i64 %13958, i64* %RAX.i1763, align 8
  %13959 = add i64 %13953, -1356
  %13960 = add i64 %13866, 52
  store i64 %13960, i64* %3, align 8
  %13961 = inttoptr i64 %13959 to i32*
  store i32 %13925, i32* %13961, align 4
  %13962 = load i64, i64* %3, align 8
  %13963 = load i32, i32* %EAX.i2159, align 8
  %13964 = sext i32 %13963 to i64
  %13965 = lshr i64 %13964, 32
  store i64 %13965, i64* %101, align 8
  %13966 = load i32, i32* %R8D.i1718, align 4
  %13967 = add i64 %13962, 4
  store i64 %13967, i64* %3, align 8
  %13968 = zext i32 %13963 to i64
  %13969 = sext i32 %13966 to i64
  %13970 = shl nuw i64 %13965, 32
  %13971 = or i64 %13970, %13968
  %13972 = sdiv i64 %13971, %13969
  %13973 = shl i64 %13972, 32
  %13974 = ashr exact i64 %13973, 32
  %13975 = icmp eq i64 %13972, %13974
  br i1 %13975, label %13978, label %13976

; <label>:13976:                                  ; preds = %routine_idivl__r8d.exit3327
  %13977 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %13967, %struct.Memory* %13868)
  %.pre652 = load i64, i64* %RAX.i1763, align 8
  %.pre653 = load i64, i64* %3, align 8
  br label %routine_idivl__r8d.exit

; <label>:13978:                                  ; preds = %routine_idivl__r8d.exit3327
  %13979 = srem i64 %13971, %13969
  %13980 = and i64 %13972, 4294967295
  store i64 %13980, i64* %RAX.i1763, align 8
  %13981 = and i64 %13979, 4294967295
  store i64 %13981, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__r8d.exit

routine_idivl__r8d.exit:                          ; preds = %13978, %13976
  %13982 = phi i64 [ %.pre653, %13976 ], [ %13967, %13978 ]
  %13983 = phi i64 [ %.pre652, %13976 ], [ %13980, %13978 ]
  %13984 = phi %struct.Memory* [ %13977, %13976 ], [ %13868, %13978 ]
  %13985 = trunc i64 %13983 to i32
  %13986 = shl i32 %13985, 1
  %13987 = icmp slt i32 %13985, 0
  %13988 = icmp slt i32 %13986, 0
  %13989 = xor i1 %13987, %13988
  %13990 = zext i32 %13986 to i64
  store i64 %13990, i64* %RAX.i1763, align 8
  %.lobit227 = lshr i32 %13985, 31
  %13991 = trunc i32 %.lobit227 to i8
  store i8 %13991, i8* %18, align 1
  %13992 = and i32 %13986, 254
  %13993 = tail call i32 @llvm.ctpop.i32(i32 %13992)
  %13994 = trunc i32 %13993 to i8
  %13995 = and i8 %13994, 1
  %13996 = xor i8 %13995, 1
  store i8 %13996, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %13997 = icmp eq i32 %13986, 0
  %13998 = zext i1 %13997 to i8
  store i8 %13998, i8* %21, align 1
  %13999 = lshr i32 %13985, 30
  %14000 = trunc i32 %13999 to i8
  %14001 = and i8 %14000, 1
  store i8 %14001, i8* %22, align 1
  %14002 = zext i1 %13989 to i8
  store i8 %14002, i8* %23, align 1
  %14003 = load i64, i64* %RBP.i, align 8
  %14004 = add i64 %14003, -1356
  %14005 = add i64 %13982, 8
  store i64 %14005, i64* %3, align 8
  %14006 = inttoptr i64 %14004 to i32*
  %14007 = load i32, i32* %14006, align 4
  %14008 = add i32 %13986, %14007
  %14009 = zext i32 %14008 to i64
  store i64 %14009, i64* %RSI.i1889, align 8
  %14010 = icmp ult i32 %14008, %14007
  %14011 = icmp ult i32 %14008, %13986
  %14012 = or i1 %14010, %14011
  %14013 = zext i1 %14012 to i8
  store i8 %14013, i8* %18, align 1
  %14014 = and i32 %14008, 255
  %14015 = tail call i32 @llvm.ctpop.i32(i32 %14014)
  %14016 = trunc i32 %14015 to i8
  %14017 = and i8 %14016, 1
  %14018 = xor i8 %14017, 1
  store i8 %14018, i8* %19, align 1
  %14019 = xor i32 %13986, %14007
  %14020 = xor i32 %14019, %14008
  %14021 = lshr i32 %14020, 4
  %14022 = trunc i32 %14021 to i8
  %14023 = and i8 %14022, 1
  store i8 %14023, i8* %20, align 1
  %14024 = icmp eq i32 %14008, 0
  %14025 = zext i1 %14024 to i8
  store i8 %14025, i8* %21, align 1
  %14026 = lshr i32 %14008, 31
  %14027 = trunc i32 %14026 to i8
  store i8 %14027, i8* %22, align 1
  %14028 = lshr i32 %14007, 31
  %14029 = lshr i32 %13985, 30
  %14030 = and i32 %14029, 1
  %14031 = xor i32 %14026, %14028
  %14032 = xor i32 %14026, %14030
  %14033 = add nuw nsw i32 %14031, %14032
  %14034 = icmp eq i32 %14033, 2
  %14035 = zext i1 %14034 to i8
  store i8 %14035, i8* %23, align 1
  %14036 = sext i32 %14008 to i64
  store i64 %14036, i64* %372, align 8
  %14037 = load i64, i64* %RDI.i2141, align 8
  %14038 = shl nsw i64 %14036, 2
  %14039 = add i64 %14037, %14038
  %14040 = load i32, i32* %ECX.i7699, align 4
  %14041 = add i64 %13982, 17
  store i64 %14041, i64* %3, align 8
  %14042 = inttoptr i64 %14039 to i32*
  store i32 %14040, i32* %14042, align 4
  %14043 = load i64, i64* %RBP.i, align 8
  %14044 = add i64 %14043, -44
  %14045 = load i64, i64* %3, align 8
  %14046 = add i64 %14045, 3
  store i64 %14046, i64* %3, align 8
  %14047 = inttoptr i64 %14044 to i32*
  %14048 = load i32, i32* %14047, align 4
  %14049 = add i32 %14048, 1
  %14050 = zext i32 %14049 to i64
  store i64 %14050, i64* %RAX.i1763, align 8
  %14051 = icmp eq i32 %14048, -1
  %14052 = icmp eq i32 %14049, 0
  %14053 = or i1 %14051, %14052
  %14054 = zext i1 %14053 to i8
  store i8 %14054, i8* %18, align 1
  %14055 = and i32 %14049, 255
  %14056 = tail call i32 @llvm.ctpop.i32(i32 %14055)
  %14057 = trunc i32 %14056 to i8
  %14058 = and i8 %14057, 1
  %14059 = xor i8 %14058, 1
  store i8 %14059, i8* %19, align 1
  %14060 = xor i32 %14049, %14048
  %14061 = lshr i32 %14060, 4
  %14062 = trunc i32 %14061 to i8
  %14063 = and i8 %14062, 1
  store i8 %14063, i8* %20, align 1
  %14064 = zext i1 %14052 to i8
  store i8 %14064, i8* %21, align 1
  %14065 = lshr i32 %14049, 31
  %14066 = trunc i32 %14065 to i8
  store i8 %14066, i8* %22, align 1
  %14067 = lshr i32 %14048, 31
  %14068 = xor i32 %14065, %14067
  %14069 = add nuw nsw i32 %14068, %14065
  %14070 = icmp eq i32 %14069, 2
  %14071 = zext i1 %14070 to i8
  store i8 %14071, i8* %23, align 1
  %14072 = add i64 %14045, 9
  store i64 %14072, i64* %3, align 8
  store i32 %14049, i32* %14047, align 4
  %14073 = load i64, i64* %3, align 8
  %14074 = add i64 %14073, -170
  store i64 %14074, i64* %3, align 8
  br label %block_.L_4a5fea

block_.L_4a6099:                                  ; preds = %block_.L_4a5fea
  %14075 = add i64 %13745, -48
  %14076 = add i64 %13773, 8
  store i64 %14076, i64* %3, align 8
  %14077 = inttoptr i64 %14075 to i32*
  %14078 = load i32, i32* %14077, align 4
  %14079 = add i32 %14078, 1
  %14080 = zext i32 %14079 to i64
  store i64 %14080, i64* %RAX.i1763, align 8
  %14081 = icmp eq i32 %14078, -1
  %14082 = icmp eq i32 %14079, 0
  %14083 = or i1 %14081, %14082
  %14084 = zext i1 %14083 to i8
  store i8 %14084, i8* %18, align 1
  %14085 = and i32 %14079, 255
  %14086 = tail call i32 @llvm.ctpop.i32(i32 %14085)
  %14087 = trunc i32 %14086 to i8
  %14088 = and i8 %14087, 1
  %14089 = xor i8 %14088, 1
  store i8 %14089, i8* %19, align 1
  %14090 = xor i32 %14079, %14078
  %14091 = lshr i32 %14090, 4
  %14092 = trunc i32 %14091 to i8
  %14093 = and i8 %14092, 1
  store i8 %14093, i8* %20, align 1
  %14094 = zext i1 %14082 to i8
  store i8 %14094, i8* %21, align 1
  %14095 = lshr i32 %14079, 31
  %14096 = trunc i32 %14095 to i8
  store i8 %14096, i8* %22, align 1
  %14097 = lshr i32 %14078, 31
  %14098 = xor i32 %14095, %14097
  %14099 = add nuw nsw i32 %14098, %14095
  %14100 = icmp eq i32 %14099, 2
  %14101 = zext i1 %14100 to i8
  store i8 %14101, i8* %23, align 1
  %14102 = add i64 %13773, 14
  store i64 %14102, i64* %3, align 8
  store i32 %14079, i32* %14077, align 4
  %14103 = load i64, i64* %3, align 8
  %14104 = add i64 %14103, -206
  store i64 %14104, i64* %3, align 8
  br label %block_.L_4a5fd9

block_.L_4a60ac:                                  ; preds = %block_.L_4a5fd9
  %14105 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %14105, i64* %RAX.i1763, align 8
  %14106 = add i64 %14105, 2464
  %14107 = add i64 %13740, 15
  store i64 %14107, i64* %3, align 8
  %14108 = inttoptr i64 %14106 to i32*
  %14109 = load i32, i32* %14108, align 4
  store i8 0, i8* %18, align 1
  %14110 = and i32 %14109, 255
  %14111 = tail call i32 @llvm.ctpop.i32(i32 %14110)
  %14112 = trunc i32 %14111 to i8
  %14113 = and i8 %14112, 1
  %14114 = xor i8 %14113, 1
  store i8 %14114, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %14115 = icmp eq i32 %14109, 0
  %14116 = zext i1 %14115 to i8
  store i8 %14116, i8* %21, align 1
  %14117 = lshr i32 %14109, 31
  %14118 = trunc i32 %14117 to i8
  store i8 %14118, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v763 = select i1 %14115, i64 21, i64 4378
  %14119 = add i64 %13740, %.v763
  store i64 %14119, i64* %3, align 8
  br i1 %14115, label %block_4a60c1, label %block_.L_4a71c6

block_4a60c1:                                     ; preds = %block_.L_4a60ac
  %14120 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %14120, i64* %RAX.i1763, align 8
  %14121 = add i64 %14120, 72724
  %14122 = add i64 %14119, 15
  store i64 %14122, i64* %3, align 8
  %14123 = inttoptr i64 %14121 to i32*
  %14124 = load i32, i32* %14123, align 4
  store i8 0, i8* %18, align 1
  %14125 = and i32 %14124, 255
  %14126 = tail call i32 @llvm.ctpop.i32(i32 %14125)
  %14127 = trunc i32 %14126 to i8
  %14128 = and i8 %14127, 1
  %14129 = xor i8 %14128, 1
  store i8 %14129, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %14130 = icmp eq i32 %14124, 0
  %14131 = zext i1 %14130 to i8
  store i8 %14131, i8* %21, align 1
  %14132 = lshr i32 %14124, 31
  %14133 = trunc i32 %14132 to i8
  store i8 %14133, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v762 = select i1 %14130, i64 21, i64 323
  %14134 = add i64 %14119, %.v762
  %14135 = add i64 %14134, 7
  store i64 %14135, i64* %3, align 8
  store i32 0, i32* %13715, align 4
  br i1 %14130, label %block_.L_4a60dd.preheader, label %block_.L_4a620b.preheader

block_.L_4a60dd.preheader:                        ; preds = %block_4a60c1
  %.pre537 = load i64, i64* %3, align 8
  br label %block_.L_4a60dd

block_.L_4a620b.preheader:                        ; preds = %block_4a60c1
  %R8W.i3020 = bitcast %union.anon* %25 to i16*
  %.pre539 = load i64, i64* %3, align 8
  br label %block_.L_4a620b

block_.L_4a60dd:                                  ; preds = %block_.L_4a60dd.preheader, %block_.L_4a61d8
  %14136 = phi i64 [ %.pre537, %block_.L_4a60dd.preheader ], [ %14731, %block_.L_4a61d8 ]
  %14137 = load i64, i64* %RBP.i, align 8
  %14138 = add i64 %14137, -48
  %14139 = add i64 %14136, 4
  store i64 %14139, i64* %3, align 8
  %14140 = inttoptr i64 %14138 to i32*
  %14141 = load i32, i32* %14140, align 4
  %14142 = add i32 %14141, -8
  %14143 = icmp ult i32 %14141, 8
  %14144 = zext i1 %14143 to i8
  store i8 %14144, i8* %18, align 1
  %14145 = and i32 %14142, 255
  %14146 = tail call i32 @llvm.ctpop.i32(i32 %14145)
  %14147 = trunc i32 %14146 to i8
  %14148 = and i8 %14147, 1
  %14149 = xor i8 %14148, 1
  store i8 %14149, i8* %19, align 1
  %14150 = xor i32 %14142, %14141
  %14151 = lshr i32 %14150, 4
  %14152 = trunc i32 %14151 to i8
  %14153 = and i8 %14152, 1
  store i8 %14153, i8* %20, align 1
  %14154 = icmp eq i32 %14142, 0
  %14155 = zext i1 %14154 to i8
  store i8 %14155, i8* %21, align 1
  %14156 = lshr i32 %14142, 31
  %14157 = trunc i32 %14156 to i8
  store i8 %14157, i8* %22, align 1
  %14158 = lshr i32 %14141, 31
  %14159 = xor i32 %14156, %14158
  %14160 = add nuw nsw i32 %14159, %14158
  %14161 = icmp eq i32 %14160, 2
  %14162 = zext i1 %14161 to i8
  store i8 %14162, i8* %23, align 1
  %14163 = icmp ne i8 %14157, 0
  %14164 = xor i1 %14163, %14161
  %.v836 = select i1 %14164, i64 10, i64 270
  %14165 = add i64 %14136, %.v836
  store i64 %14165, i64* %3, align 8
  br i1 %14164, label %block_4a60e7, label %block_.L_4a61eb

block_4a60e7:                                     ; preds = %block_.L_4a60dd
  %14166 = add i64 %14137, -44
  %14167 = add i64 %14165, 7
  store i64 %14167, i64* %3, align 8
  %14168 = inttoptr i64 %14166 to i32*
  store i32 0, i32* %14168, align 4
  %.pre538 = load i64, i64* %3, align 8
  br label %block_.L_4a60ee

block_.L_4a60ee:                                  ; preds = %block_4a60f8, %block_4a60e7
  %14169 = phi i64 [ %14701, %block_4a60f8 ], [ %.pre538, %block_4a60e7 ]
  %14170 = load i64, i64* %RBP.i, align 8
  %14171 = add i64 %14170, -44
  %14172 = add i64 %14169, 4
  store i64 %14172, i64* %3, align 8
  %14173 = inttoptr i64 %14171 to i32*
  %14174 = load i32, i32* %14173, align 4
  %14175 = add i32 %14174, -8
  %14176 = icmp ult i32 %14174, 8
  %14177 = zext i1 %14176 to i8
  store i8 %14177, i8* %18, align 1
  %14178 = and i32 %14175, 255
  %14179 = tail call i32 @llvm.ctpop.i32(i32 %14178)
  %14180 = trunc i32 %14179 to i8
  %14181 = and i8 %14180, 1
  %14182 = xor i8 %14181, 1
  store i8 %14182, i8* %19, align 1
  %14183 = xor i32 %14175, %14174
  %14184 = lshr i32 %14183, 4
  %14185 = trunc i32 %14184 to i8
  %14186 = and i8 %14185, 1
  store i8 %14186, i8* %20, align 1
  %14187 = icmp eq i32 %14175, 0
  %14188 = zext i1 %14187 to i8
  store i8 %14188, i8* %21, align 1
  %14189 = lshr i32 %14175, 31
  %14190 = trunc i32 %14189 to i8
  store i8 %14190, i8* %22, align 1
  %14191 = lshr i32 %14174, 31
  %14192 = xor i32 %14189, %14191
  %14193 = add nuw nsw i32 %14192, %14191
  %14194 = icmp eq i32 %14193, 2
  %14195 = zext i1 %14194 to i8
  store i8 %14195, i8* %23, align 1
  %14196 = icmp ne i8 %14190, 0
  %14197 = xor i1 %14196, %14194
  %.v765 = select i1 %14197, i64 10, i64 234
  %14198 = add i64 %14169, %.v765
  store i64 %14198, i64* %3, align 8
  br i1 %14197, label %block_4a60f8, label %block_.L_4a61d8

block_4a60f8:                                     ; preds = %block_.L_4a60ee
  %14199 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %14200 = add i64 %14199, 7352
  store i64 %14200, i64* %RAX.i1763, align 8
  %14201 = icmp ugt i64 %14199, -7353
  %14202 = zext i1 %14201 to i8
  store i8 %14202, i8* %18, align 1
  %14203 = trunc i64 %14200 to i32
  %14204 = and i32 %14203, 255
  %14205 = tail call i32 @llvm.ctpop.i32(i32 %14204)
  %14206 = trunc i32 %14205 to i8
  %14207 = and i8 %14206, 1
  %14208 = xor i8 %14207, 1
  store i8 %14208, i8* %19, align 1
  %14209 = xor i64 %14199, 16
  %14210 = xor i64 %14209, %14200
  %14211 = lshr i64 %14210, 4
  %14212 = trunc i64 %14211 to i8
  %14213 = and i8 %14212, 1
  store i8 %14213, i8* %20, align 1
  %14214 = icmp eq i64 %14200, 0
  %14215 = zext i1 %14214 to i8
  store i8 %14215, i8* %21, align 1
  %14216 = lshr i64 %14200, 63
  %14217 = trunc i64 %14216 to i8
  store i8 %14217, i8* %22, align 1
  %14218 = lshr i64 %14199, 63
  %14219 = xor i64 %14216, %14218
  %14220 = add nuw nsw i64 %14219, %14216
  %14221 = icmp eq i64 %14220, 2
  %14222 = zext i1 %14221 to i8
  store i8 %14222, i8* %23, align 1
  %14223 = add i64 %14170, -40
  %14224 = add i64 %14198, 18
  store i64 %14224, i64* %3, align 8
  %14225 = inttoptr i64 %14223 to i32*
  %14226 = load i32, i32* %14225, align 4
  %14227 = sext i32 %14226 to i64
  %14228 = shl nsw i64 %14227, 7
  store i64 %14228, i64* %RCX.i1692, align 8
  %14229 = add i64 %14228, %14200
  store i64 %14229, i64* %RAX.i1763, align 8
  %14230 = icmp ult i64 %14229, %14200
  %14231 = icmp ult i64 %14229, %14228
  %14232 = or i1 %14230, %14231
  %14233 = zext i1 %14232 to i8
  store i8 %14233, i8* %18, align 1
  %14234 = trunc i64 %14229 to i32
  %14235 = and i32 %14234, 255
  %14236 = tail call i32 @llvm.ctpop.i32(i32 %14235)
  %14237 = trunc i32 %14236 to i8
  %14238 = and i8 %14237, 1
  %14239 = xor i8 %14238, 1
  store i8 %14239, i8* %19, align 1
  %14240 = xor i64 %14200, %14229
  %14241 = lshr i64 %14240, 4
  %14242 = trunc i64 %14241 to i8
  %14243 = and i8 %14242, 1
  store i8 %14243, i8* %20, align 1
  %14244 = icmp eq i64 %14229, 0
  %14245 = zext i1 %14244 to i8
  store i8 %14245, i8* %21, align 1
  %14246 = lshr i64 %14229, 63
  %14247 = trunc i64 %14246 to i8
  store i8 %14247, i8* %22, align 1
  %14248 = lshr i64 %14227, 56
  %14249 = and i64 %14248, 1
  %14250 = xor i64 %14246, %14216
  %14251 = xor i64 %14246, %14249
  %14252 = add nuw nsw i64 %14250, %14251
  %14253 = icmp eq i64 %14252, 2
  %14254 = zext i1 %14253 to i8
  store i8 %14254, i8* %23, align 1
  %14255 = load i64, i64* %RBP.i, align 8
  %14256 = add i64 %14255, -48
  %14257 = add i64 %14198, 29
  store i64 %14257, i64* %3, align 8
  %14258 = inttoptr i64 %14256 to i32*
  %14259 = load i32, i32* %14258, align 4
  %14260 = sext i32 %14259 to i64
  %14261 = shl nsw i64 %14260, 4
  store i64 %14261, i64* %RCX.i1692, align 8
  %14262 = add i64 %14261, %14229
  store i64 %14262, i64* %RAX.i1763, align 8
  %14263 = icmp ult i64 %14262, %14229
  %14264 = icmp ult i64 %14262, %14261
  %14265 = or i1 %14263, %14264
  %14266 = zext i1 %14265 to i8
  store i8 %14266, i8* %18, align 1
  %14267 = trunc i64 %14262 to i32
  %14268 = and i32 %14267, 255
  %14269 = tail call i32 @llvm.ctpop.i32(i32 %14268)
  %14270 = trunc i32 %14269 to i8
  %14271 = and i8 %14270, 1
  %14272 = xor i8 %14271, 1
  store i8 %14272, i8* %19, align 1
  %14273 = xor i64 %14261, %14229
  %14274 = xor i64 %14273, %14262
  %14275 = lshr i64 %14274, 4
  %14276 = trunc i64 %14275 to i8
  %14277 = and i8 %14276, 1
  store i8 %14277, i8* %20, align 1
  %14278 = icmp eq i64 %14262, 0
  %14279 = zext i1 %14278 to i8
  store i8 %14279, i8* %21, align 1
  %14280 = lshr i64 %14262, 63
  %14281 = trunc i64 %14280 to i8
  store i8 %14281, i8* %22, align 1
  %14282 = lshr i64 %14260, 59
  %14283 = and i64 %14282, 1
  %14284 = xor i64 %14280, %14246
  %14285 = xor i64 %14280, %14283
  %14286 = add nuw nsw i64 %14284, %14285
  %14287 = icmp eq i64 %14286, 2
  %14288 = zext i1 %14287 to i8
  store i8 %14288, i8* %23, align 1
  %14289 = add i64 %14255, -44
  %14290 = add i64 %14198, 40
  store i64 %14290, i64* %3, align 8
  %14291 = inttoptr i64 %14289 to i32*
  %14292 = load i32, i32* %14291, align 4
  %14293 = sext i32 %14292 to i64
  store i64 %14293, i64* %RCX.i1692, align 8
  %14294 = shl nsw i64 %14293, 1
  %14295 = add i64 %14294, %14262
  %14296 = add i64 %14198, 44
  store i64 %14296, i64* %3, align 8
  %14297 = inttoptr i64 %14295 to i16*
  %14298 = load i16, i16* %14297, align 2
  store i16 %14298, i16* %DX.i5417, align 2
  %14299 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %14300 = add i64 %14299, 12600
  store i64 %14300, i64* %RAX.i1763, align 8
  %14301 = icmp ugt i64 %14299, -12601
  %14302 = zext i1 %14301 to i8
  store i8 %14302, i8* %18, align 1
  %14303 = trunc i64 %14300 to i32
  %14304 = and i32 %14303, 255
  %14305 = tail call i32 @llvm.ctpop.i32(i32 %14304)
  %14306 = trunc i32 %14305 to i8
  %14307 = and i8 %14306, 1
  %14308 = xor i8 %14307, 1
  store i8 %14308, i8* %19, align 1
  %14309 = xor i64 %14299, 16
  %14310 = xor i64 %14309, %14300
  %14311 = lshr i64 %14310, 4
  %14312 = trunc i64 %14311 to i8
  %14313 = and i8 %14312, 1
  store i8 %14313, i8* %20, align 1
  %14314 = icmp eq i64 %14300, 0
  %14315 = zext i1 %14314 to i8
  store i8 %14315, i8* %21, align 1
  %14316 = lshr i64 %14300, 63
  %14317 = trunc i64 %14316 to i8
  store i8 %14317, i8* %22, align 1
  %14318 = lshr i64 %14299, 63
  %14319 = xor i64 %14316, %14318
  %14320 = add nuw nsw i64 %14319, %14316
  %14321 = icmp eq i64 %14320, 2
  %14322 = zext i1 %14321 to i8
  store i8 %14322, i8* %23, align 1
  %14323 = load i64, i64* %RBP.i, align 8
  %14324 = add i64 %14323, -484
  %14325 = add i64 %14198, 64
  store i64 %14325, i64* %3, align 8
  %14326 = inttoptr i64 %14324 to i32*
  %14327 = load i32, i32* %14326, align 4
  %14328 = zext i32 %14327 to i64
  store i64 %14328, i64* %RSI.i1889, align 8
  %14329 = add i64 %14323, -44
  %14330 = add i64 %14198, 67
  store i64 %14330, i64* %3, align 8
  %14331 = inttoptr i64 %14329 to i32*
  %14332 = load i32, i32* %14331, align 4
  %14333 = add i32 %14332, %14327
  %14334 = zext i32 %14333 to i64
  store i64 %14334, i64* %RSI.i1889, align 8
  %14335 = sext i32 %14333 to i64
  %14336 = shl nsw i64 %14335, 5
  store i64 %14336, i64* %RCX.i1692, align 8
  %14337 = load i64, i64* %RAX.i1763, align 8
  %14338 = add i64 %14336, %14337
  store i64 %14338, i64* %RAX.i1763, align 8
  %14339 = icmp ult i64 %14338, %14337
  %14340 = icmp ult i64 %14338, %14336
  %14341 = or i1 %14339, %14340
  %14342 = zext i1 %14341 to i8
  store i8 %14342, i8* %18, align 1
  %14343 = trunc i64 %14338 to i32
  %14344 = and i32 %14343, 255
  %14345 = tail call i32 @llvm.ctpop.i32(i32 %14344)
  %14346 = trunc i32 %14345 to i8
  %14347 = and i8 %14346, 1
  %14348 = xor i8 %14347, 1
  store i8 %14348, i8* %19, align 1
  %14349 = xor i64 %14337, %14338
  %14350 = lshr i64 %14349, 4
  %14351 = trunc i64 %14350 to i8
  %14352 = and i8 %14351, 1
  store i8 %14352, i8* %20, align 1
  %14353 = icmp eq i64 %14338, 0
  %14354 = zext i1 %14353 to i8
  store i8 %14354, i8* %21, align 1
  %14355 = lshr i64 %14338, 63
  %14356 = trunc i64 %14355 to i8
  store i8 %14356, i8* %22, align 1
  %14357 = lshr i64 %14337, 63
  %14358 = lshr i64 %14335, 58
  %14359 = and i64 %14358, 1
  %14360 = xor i64 %14355, %14357
  %14361 = xor i64 %14355, %14359
  %14362 = add nuw nsw i64 %14360, %14361
  %14363 = icmp eq i64 %14362, 2
  %14364 = zext i1 %14363 to i8
  store i8 %14364, i8* %23, align 1
  %14365 = load i64, i64* %RBP.i, align 8
  %14366 = add i64 %14365, -488
  %14367 = add i64 %14198, 83
  store i64 %14367, i64* %3, align 8
  %14368 = inttoptr i64 %14366 to i32*
  %14369 = load i32, i32* %14368, align 4
  %14370 = zext i32 %14369 to i64
  store i64 %14370, i64* %RSI.i1889, align 8
  %14371 = add i64 %14365, -48
  %14372 = add i64 %14198, 86
  store i64 %14372, i64* %3, align 8
  %14373 = inttoptr i64 %14371 to i32*
  %14374 = load i32, i32* %14373, align 4
  %14375 = add i32 %14374, %14369
  %14376 = zext i32 %14375 to i64
  store i64 %14376, i64* %RSI.i1889, align 8
  %14377 = icmp ult i32 %14375, %14369
  %14378 = icmp ult i32 %14375, %14374
  %14379 = or i1 %14377, %14378
  %14380 = zext i1 %14379 to i8
  store i8 %14380, i8* %18, align 1
  %14381 = and i32 %14375, 255
  %14382 = tail call i32 @llvm.ctpop.i32(i32 %14381)
  %14383 = trunc i32 %14382 to i8
  %14384 = and i8 %14383, 1
  %14385 = xor i8 %14384, 1
  store i8 %14385, i8* %19, align 1
  %14386 = xor i32 %14374, %14369
  %14387 = xor i32 %14386, %14375
  %14388 = lshr i32 %14387, 4
  %14389 = trunc i32 %14388 to i8
  %14390 = and i8 %14389, 1
  store i8 %14390, i8* %20, align 1
  %14391 = icmp eq i32 %14375, 0
  %14392 = zext i1 %14391 to i8
  store i8 %14392, i8* %21, align 1
  %14393 = lshr i32 %14375, 31
  %14394 = trunc i32 %14393 to i8
  store i8 %14394, i8* %22, align 1
  %14395 = lshr i32 %14369, 31
  %14396 = lshr i32 %14374, 31
  %14397 = xor i32 %14393, %14395
  %14398 = xor i32 %14393, %14396
  %14399 = add nuw nsw i32 %14397, %14398
  %14400 = icmp eq i32 %14399, 2
  %14401 = zext i1 %14400 to i8
  store i8 %14401, i8* %23, align 1
  %14402 = sext i32 %14375 to i64
  store i64 %14402, i64* %RCX.i1692, align 8
  %14403 = shl nsw i64 %14402, 1
  %14404 = add i64 %14338, %14403
  %14405 = load i16, i16* %DX.i5417, align 2
  %14406 = add i64 %14198, 93
  store i64 %14406, i64* %3, align 8
  %14407 = inttoptr i64 %14404 to i16*
  store i16 %14405, i16* %14407, align 2
  %14408 = load i64, i64* %RBP.i, align 8
  %14409 = add i64 %14408, -528
  %14410 = load i64, i64* %3, align 8
  %14411 = add i64 %14410, 7
  store i64 %14411, i64* %3, align 8
  %14412 = inttoptr i64 %14409 to i64*
  %14413 = load i64, i64* %14412, align 8
  store i64 %14413, i64* %RAX.i1763, align 8
  %14414 = add i64 %14408, -504
  %14415 = add i64 %14410, 13
  store i64 %14415, i64* %3, align 8
  %14416 = inttoptr i64 %14414 to i32*
  %14417 = load i32, i32* %14416, align 4
  %14418 = zext i32 %14417 to i64
  store i64 %14418, i64* %RSI.i1889, align 8
  %14419 = add i64 %14408, -48
  %14420 = add i64 %14410, 16
  store i64 %14420, i64* %3, align 8
  %14421 = inttoptr i64 %14419 to i32*
  %14422 = load i32, i32* %14421, align 4
  %14423 = add i32 %14422, %14417
  %14424 = zext i32 %14423 to i64
  store i64 %14424, i64* %RSI.i1889, align 8
  %14425 = icmp ult i32 %14423, %14417
  %14426 = icmp ult i32 %14423, %14422
  %14427 = or i1 %14425, %14426
  %14428 = zext i1 %14427 to i8
  store i8 %14428, i8* %18, align 1
  %14429 = and i32 %14423, 255
  %14430 = tail call i32 @llvm.ctpop.i32(i32 %14429)
  %14431 = trunc i32 %14430 to i8
  %14432 = and i8 %14431, 1
  %14433 = xor i8 %14432, 1
  store i8 %14433, i8* %19, align 1
  %14434 = xor i32 %14422, %14417
  %14435 = xor i32 %14434, %14423
  %14436 = lshr i32 %14435, 4
  %14437 = trunc i32 %14436 to i8
  %14438 = and i8 %14437, 1
  store i8 %14438, i8* %20, align 1
  %14439 = icmp eq i32 %14423, 0
  %14440 = zext i1 %14439 to i8
  store i8 %14440, i8* %21, align 1
  %14441 = lshr i32 %14423, 31
  %14442 = trunc i32 %14441 to i8
  store i8 %14442, i8* %22, align 1
  %14443 = lshr i32 %14417, 31
  %14444 = lshr i32 %14422, 31
  %14445 = xor i32 %14441, %14443
  %14446 = xor i32 %14441, %14444
  %14447 = add nuw nsw i32 %14445, %14446
  %14448 = icmp eq i32 %14447, 2
  %14449 = zext i1 %14448 to i8
  store i8 %14449, i8* %23, align 1
  %14450 = sext i32 %14423 to i64
  store i64 %14450, i64* %RCX.i1692, align 8
  %14451 = shl nsw i64 %14450, 3
  %14452 = add i64 %14413, %14451
  %14453 = add i64 %14410, 23
  store i64 %14453, i64* %3, align 8
  %14454 = inttoptr i64 %14452 to i64*
  %14455 = load i64, i64* %14454, align 8
  store i64 %14455, i64* %RAX.i1763, align 8
  %14456 = add i64 %14408, -500
  %14457 = add i64 %14410, 29
  store i64 %14457, i64* %3, align 8
  %14458 = inttoptr i64 %14456 to i32*
  %14459 = load i32, i32* %14458, align 4
  %14460 = zext i32 %14459 to i64
  store i64 %14460, i64* %RSI.i1889, align 8
  %14461 = add i64 %14408, -44
  %14462 = add i64 %14410, 32
  store i64 %14462, i64* %3, align 8
  %14463 = inttoptr i64 %14461 to i32*
  %14464 = load i32, i32* %14463, align 4
  %14465 = add i32 %14464, %14459
  %14466 = zext i32 %14465 to i64
  store i64 %14466, i64* %RSI.i1889, align 8
  %14467 = icmp ult i32 %14465, %14459
  %14468 = icmp ult i32 %14465, %14464
  %14469 = or i1 %14467, %14468
  %14470 = zext i1 %14469 to i8
  store i8 %14470, i8* %18, align 1
  %14471 = and i32 %14465, 255
  %14472 = tail call i32 @llvm.ctpop.i32(i32 %14471)
  %14473 = trunc i32 %14472 to i8
  %14474 = and i8 %14473, 1
  %14475 = xor i8 %14474, 1
  store i8 %14475, i8* %19, align 1
  %14476 = xor i32 %14464, %14459
  %14477 = xor i32 %14476, %14465
  %14478 = lshr i32 %14477, 4
  %14479 = trunc i32 %14478 to i8
  %14480 = and i8 %14479, 1
  store i8 %14480, i8* %20, align 1
  %14481 = icmp eq i32 %14465, 0
  %14482 = zext i1 %14481 to i8
  store i8 %14482, i8* %21, align 1
  %14483 = lshr i32 %14465, 31
  %14484 = trunc i32 %14483 to i8
  store i8 %14484, i8* %22, align 1
  %14485 = lshr i32 %14459, 31
  %14486 = lshr i32 %14464, 31
  %14487 = xor i32 %14483, %14485
  %14488 = xor i32 %14483, %14486
  %14489 = add nuw nsw i32 %14487, %14488
  %14490 = icmp eq i32 %14489, 2
  %14491 = zext i1 %14490 to i8
  store i8 %14491, i8* %23, align 1
  %14492 = sext i32 %14465 to i64
  store i64 %14492, i64* %RCX.i1692, align 8
  %14493 = shl nsw i64 %14492, 1
  %14494 = add i64 %14455, %14493
  %14495 = add i64 %14410, 39
  store i64 %14495, i64* %3, align 8
  %14496 = inttoptr i64 %14494 to i16*
  %14497 = load i16, i16* %14496, align 2
  %14498 = zext i16 %14497 to i64
  store i64 %14498, i64* %RSI.i1889, align 8
  %14499 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %14500 = add i64 %14499, 7352
  store i64 %14500, i64* %RAX.i1763, align 8
  %14501 = icmp ugt i64 %14499, -7353
  %14502 = zext i1 %14501 to i8
  store i8 %14502, i8* %18, align 1
  %14503 = trunc i64 %14500 to i32
  %14504 = and i32 %14503, 255
  %14505 = tail call i32 @llvm.ctpop.i32(i32 %14504)
  %14506 = trunc i32 %14505 to i8
  %14507 = and i8 %14506, 1
  %14508 = xor i8 %14507, 1
  store i8 %14508, i8* %19, align 1
  %14509 = xor i64 %14499, 16
  %14510 = xor i64 %14509, %14500
  %14511 = lshr i64 %14510, 4
  %14512 = trunc i64 %14511 to i8
  %14513 = and i8 %14512, 1
  store i8 %14513, i8* %20, align 1
  %14514 = icmp eq i64 %14500, 0
  %14515 = zext i1 %14514 to i8
  store i8 %14515, i8* %21, align 1
  %14516 = lshr i64 %14500, 63
  %14517 = trunc i64 %14516 to i8
  store i8 %14517, i8* %22, align 1
  %14518 = lshr i64 %14499, 63
  %14519 = xor i64 %14516, %14518
  %14520 = add nuw nsw i64 %14519, %14516
  %14521 = icmp eq i64 %14520, 2
  %14522 = zext i1 %14521 to i8
  store i8 %14522, i8* %23, align 1
  %14523 = load i64, i64* %RBP.i, align 8
  %14524 = add i64 %14523, -40
  %14525 = add i64 %14410, 57
  store i64 %14525, i64* %3, align 8
  %14526 = inttoptr i64 %14524 to i32*
  %14527 = load i32, i32* %14526, align 4
  %14528 = sext i32 %14527 to i64
  %14529 = shl nsw i64 %14528, 7
  store i64 %14529, i64* %RCX.i1692, align 8
  %14530 = add i64 %14529, %14500
  store i64 %14530, i64* %RAX.i1763, align 8
  %14531 = icmp ult i64 %14530, %14500
  %14532 = icmp ult i64 %14530, %14529
  %14533 = or i1 %14531, %14532
  %14534 = zext i1 %14533 to i8
  store i8 %14534, i8* %18, align 1
  %14535 = trunc i64 %14530 to i32
  %14536 = and i32 %14535, 255
  %14537 = tail call i32 @llvm.ctpop.i32(i32 %14536)
  %14538 = trunc i32 %14537 to i8
  %14539 = and i8 %14538, 1
  %14540 = xor i8 %14539, 1
  store i8 %14540, i8* %19, align 1
  %14541 = xor i64 %14500, %14530
  %14542 = lshr i64 %14541, 4
  %14543 = trunc i64 %14542 to i8
  %14544 = and i8 %14543, 1
  store i8 %14544, i8* %20, align 1
  %14545 = icmp eq i64 %14530, 0
  %14546 = zext i1 %14545 to i8
  store i8 %14546, i8* %21, align 1
  %14547 = lshr i64 %14530, 63
  %14548 = trunc i64 %14547 to i8
  store i8 %14548, i8* %22, align 1
  %14549 = lshr i64 %14528, 56
  %14550 = and i64 %14549, 1
  %14551 = xor i64 %14547, %14516
  %14552 = xor i64 %14547, %14550
  %14553 = add nuw nsw i64 %14551, %14552
  %14554 = icmp eq i64 %14553, 2
  %14555 = zext i1 %14554 to i8
  store i8 %14555, i8* %23, align 1
  %14556 = add i64 %14523, -48
  %14557 = add i64 %14410, 68
  store i64 %14557, i64* %3, align 8
  %14558 = inttoptr i64 %14556 to i32*
  %14559 = load i32, i32* %14558, align 4
  %14560 = sext i32 %14559 to i64
  %14561 = shl nsw i64 %14560, 4
  store i64 %14561, i64* %RCX.i1692, align 8
  %14562 = add i64 %14561, %14530
  store i64 %14562, i64* %RAX.i1763, align 8
  %14563 = icmp ult i64 %14562, %14530
  %14564 = icmp ult i64 %14562, %14561
  %14565 = or i1 %14563, %14564
  %14566 = zext i1 %14565 to i8
  store i8 %14566, i8* %18, align 1
  %14567 = trunc i64 %14562 to i32
  %14568 = and i32 %14567, 255
  %14569 = tail call i32 @llvm.ctpop.i32(i32 %14568)
  %14570 = trunc i32 %14569 to i8
  %14571 = and i8 %14570, 1
  %14572 = xor i8 %14571, 1
  store i8 %14572, i8* %19, align 1
  %14573 = xor i64 %14561, %14530
  %14574 = xor i64 %14573, %14562
  %14575 = lshr i64 %14574, 4
  %14576 = trunc i64 %14575 to i8
  %14577 = and i8 %14576, 1
  store i8 %14577, i8* %20, align 1
  %14578 = icmp eq i64 %14562, 0
  %14579 = zext i1 %14578 to i8
  store i8 %14579, i8* %21, align 1
  %14580 = lshr i64 %14562, 63
  %14581 = trunc i64 %14580 to i8
  store i8 %14581, i8* %22, align 1
  %14582 = lshr i64 %14560, 59
  %14583 = and i64 %14582, 1
  %14584 = xor i64 %14580, %14547
  %14585 = xor i64 %14580, %14583
  %14586 = add nuw nsw i64 %14584, %14585
  %14587 = icmp eq i64 %14586, 2
  %14588 = zext i1 %14587 to i8
  store i8 %14588, i8* %23, align 1
  %14589 = load i64, i64* %RBP.i, align 8
  %14590 = add i64 %14589, -44
  %14591 = add i64 %14410, 79
  store i64 %14591, i64* %3, align 8
  %14592 = inttoptr i64 %14590 to i32*
  %14593 = load i32, i32* %14592, align 4
  %14594 = sext i32 %14593 to i64
  store i64 %14594, i64* %RCX.i1692, align 8
  %14595 = shl nsw i64 %14594, 1
  %14596 = add i64 %14595, %14562
  %14597 = add i64 %14410, 83
  store i64 %14597, i64* %3, align 8
  %14598 = inttoptr i64 %14596 to i16*
  %14599 = load i16, i16* %14598, align 2
  %14600 = zext i16 %14599 to i64
  store i64 %14600, i64* %RDI.i2141, align 8
  %14601 = load i64, i64* %RSI.i1889, align 8
  %14602 = zext i16 %14599 to i64
  %14603 = sub i64 %14601, %14602
  %14604 = and i64 %14603, 4294967295
  store i64 %14604, i64* %RSI.i1889, align 8
  %14605 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %14606 = add i64 %14605, 13112
  store i64 %14606, i64* %RAX.i1763, align 8
  %14607 = icmp ugt i64 %14605, -13113
  %14608 = zext i1 %14607 to i8
  store i8 %14608, i8* %18, align 1
  %14609 = trunc i64 %14606 to i32
  %14610 = and i32 %14609, 255
  %14611 = tail call i32 @llvm.ctpop.i32(i32 %14610)
  %14612 = trunc i32 %14611 to i8
  %14613 = and i8 %14612, 1
  %14614 = xor i8 %14613, 1
  store i8 %14614, i8* %19, align 1
  %14615 = xor i64 %14605, 16
  %14616 = xor i64 %14615, %14606
  %14617 = lshr i64 %14616, 4
  %14618 = trunc i64 %14617 to i8
  %14619 = and i8 %14618, 1
  store i8 %14619, i8* %20, align 1
  %14620 = icmp eq i64 %14606, 0
  %14621 = zext i1 %14620 to i8
  store i8 %14621, i8* %21, align 1
  %14622 = lshr i64 %14606, 63
  %14623 = trunc i64 %14622 to i8
  store i8 %14623, i8* %22, align 1
  %14624 = lshr i64 %14605, 63
  %14625 = xor i64 %14622, %14624
  %14626 = add nuw nsw i64 %14625, %14622
  %14627 = icmp eq i64 %14626, 2
  %14628 = zext i1 %14627 to i8
  store i8 %14628, i8* %23, align 1
  %14629 = add i64 %14410, 103
  store i64 %14629, i64* %3, align 8
  %14630 = load i32, i32* %14592, align 4
  %14631 = sext i32 %14630 to i64
  %14632 = shl nsw i64 %14631, 6
  store i64 %14632, i64* %RCX.i1692, align 8
  %14633 = add i64 %14632, %14606
  store i64 %14633, i64* %RAX.i1763, align 8
  %14634 = icmp ult i64 %14633, %14606
  %14635 = icmp ult i64 %14633, %14632
  %14636 = or i1 %14634, %14635
  %14637 = zext i1 %14636 to i8
  store i8 %14637, i8* %18, align 1
  %14638 = trunc i64 %14633 to i32
  %14639 = and i32 %14638, 255
  %14640 = tail call i32 @llvm.ctpop.i32(i32 %14639)
  %14641 = trunc i32 %14640 to i8
  %14642 = and i8 %14641, 1
  %14643 = xor i8 %14642, 1
  store i8 %14643, i8* %19, align 1
  %14644 = xor i64 %14606, %14633
  %14645 = lshr i64 %14644, 4
  %14646 = trunc i64 %14645 to i8
  %14647 = and i8 %14646, 1
  store i8 %14647, i8* %20, align 1
  %14648 = icmp eq i64 %14633, 0
  %14649 = zext i1 %14648 to i8
  store i8 %14649, i8* %21, align 1
  %14650 = lshr i64 %14633, 63
  %14651 = trunc i64 %14650 to i8
  store i8 %14651, i8* %22, align 1
  %14652 = lshr i64 %14631, 57
  %14653 = and i64 %14652, 1
  %14654 = xor i64 %14650, %14622
  %14655 = xor i64 %14650, %14653
  %14656 = add nuw nsw i64 %14654, %14655
  %14657 = icmp eq i64 %14656, 2
  %14658 = zext i1 %14657 to i8
  store i8 %14658, i8* %23, align 1
  %14659 = load i64, i64* %RBP.i, align 8
  %14660 = add i64 %14659, -48
  %14661 = add i64 %14410, 114
  store i64 %14661, i64* %3, align 8
  %14662 = inttoptr i64 %14660 to i32*
  %14663 = load i32, i32* %14662, align 4
  %14664 = sext i32 %14663 to i64
  store i64 %14664, i64* %RCX.i1692, align 8
  %14665 = shl nsw i64 %14664, 2
  %14666 = add i64 %14665, %14633
  %14667 = load i32, i32* %ESI.i7670, align 4
  %14668 = add i64 %14410, 117
  store i64 %14668, i64* %3, align 8
  %14669 = inttoptr i64 %14666 to i32*
  store i32 %14667, i32* %14669, align 4
  %14670 = load i64, i64* %RBP.i, align 8
  %14671 = add i64 %14670, -44
  %14672 = load i64, i64* %3, align 8
  %14673 = add i64 %14672, 3
  store i64 %14673, i64* %3, align 8
  %14674 = inttoptr i64 %14671 to i32*
  %14675 = load i32, i32* %14674, align 4
  %14676 = add i32 %14675, 1
  %14677 = zext i32 %14676 to i64
  store i64 %14677, i64* %RAX.i1763, align 8
  %14678 = icmp eq i32 %14675, -1
  %14679 = icmp eq i32 %14676, 0
  %14680 = or i1 %14678, %14679
  %14681 = zext i1 %14680 to i8
  store i8 %14681, i8* %18, align 1
  %14682 = and i32 %14676, 255
  %14683 = tail call i32 @llvm.ctpop.i32(i32 %14682)
  %14684 = trunc i32 %14683 to i8
  %14685 = and i8 %14684, 1
  %14686 = xor i8 %14685, 1
  store i8 %14686, i8* %19, align 1
  %14687 = xor i32 %14676, %14675
  %14688 = lshr i32 %14687, 4
  %14689 = trunc i32 %14688 to i8
  %14690 = and i8 %14689, 1
  store i8 %14690, i8* %20, align 1
  %14691 = zext i1 %14679 to i8
  store i8 %14691, i8* %21, align 1
  %14692 = lshr i32 %14676, 31
  %14693 = trunc i32 %14692 to i8
  store i8 %14693, i8* %22, align 1
  %14694 = lshr i32 %14675, 31
  %14695 = xor i32 %14692, %14694
  %14696 = add nuw nsw i32 %14695, %14692
  %14697 = icmp eq i32 %14696, 2
  %14698 = zext i1 %14697 to i8
  store i8 %14698, i8* %23, align 1
  %14699 = add i64 %14672, 9
  store i64 %14699, i64* %3, align 8
  store i32 %14676, i32* %14674, align 4
  %14700 = load i64, i64* %3, align 8
  %14701 = add i64 %14700, -229
  store i64 %14701, i64* %3, align 8
  br label %block_.L_4a60ee

block_.L_4a61d8:                                  ; preds = %block_.L_4a60ee
  %14702 = add i64 %14170, -48
  %14703 = add i64 %14198, 8
  store i64 %14703, i64* %3, align 8
  %14704 = inttoptr i64 %14702 to i32*
  %14705 = load i32, i32* %14704, align 4
  %14706 = add i32 %14705, 1
  %14707 = zext i32 %14706 to i64
  store i64 %14707, i64* %RAX.i1763, align 8
  %14708 = icmp eq i32 %14705, -1
  %14709 = icmp eq i32 %14706, 0
  %14710 = or i1 %14708, %14709
  %14711 = zext i1 %14710 to i8
  store i8 %14711, i8* %18, align 1
  %14712 = and i32 %14706, 255
  %14713 = tail call i32 @llvm.ctpop.i32(i32 %14712)
  %14714 = trunc i32 %14713 to i8
  %14715 = and i8 %14714, 1
  %14716 = xor i8 %14715, 1
  store i8 %14716, i8* %19, align 1
  %14717 = xor i32 %14706, %14705
  %14718 = lshr i32 %14717, 4
  %14719 = trunc i32 %14718 to i8
  %14720 = and i8 %14719, 1
  store i8 %14720, i8* %20, align 1
  %14721 = zext i1 %14709 to i8
  store i8 %14721, i8* %21, align 1
  %14722 = lshr i32 %14706, 31
  %14723 = trunc i32 %14722 to i8
  store i8 %14723, i8* %22, align 1
  %14724 = lshr i32 %14705, 31
  %14725 = xor i32 %14722, %14724
  %14726 = add nuw nsw i32 %14725, %14722
  %14727 = icmp eq i32 %14726, 2
  %14728 = zext i1 %14727 to i8
  store i8 %14728, i8* %23, align 1
  %14729 = add i64 %14198, 14
  store i64 %14729, i64* %3, align 8
  store i32 %14706, i32* %14704, align 4
  %14730 = load i64, i64* %3, align 8
  %14731 = add i64 %14730, -265
  store i64 %14731, i64* %3, align 8
  br label %block_.L_4a60dd

block_.L_4a61eb:                                  ; preds = %block_.L_4a60dd
  %14732 = add i64 %14137, -68
  store i64 %14732, i64* %RSI.i1889, align 8
  store i64 1, i64* %RDX.i1805, align 8
  %14733 = add i64 %14137, -12
  %14734 = add i64 %14165, 12
  store i64 %14734, i64* %3, align 8
  %14735 = inttoptr i64 %14733 to i32*
  %14736 = load i32, i32* %14735, align 4
  %14737 = zext i32 %14736 to i64
  store i64 %14737, i64* %RDI.i2141, align 8
  %14738 = add i64 %14165, 17749
  %14739 = add i64 %14165, 17
  %14740 = load i64, i64* %6, align 8
  %14741 = add i64 %14740, -8
  %14742 = inttoptr i64 %14741 to i64*
  store i64 %14739, i64* %14742, align 8
  store i64 %14741, i64* %6, align 8
  store i64 %14738, i64* %3, align 8
  %call2_4a61f7 = tail call %struct.Memory* @sub_4aa740.dct_luma8x8(%struct.State* nonnull %0, i64 %14738, %struct.Memory* %MEMORY.75)
  %14743 = load i64, i64* %RBP.i, align 8
  %14744 = add i64 %14743, -76
  %14745 = load i32, i32* %EAX.i2159, align 4
  %14746 = load i64, i64* %3, align 8
  %14747 = add i64 %14746, 3
  store i64 %14747, i64* %3, align 8
  %14748 = inttoptr i64 %14744 to i32*
  store i32 %14745, i32* %14748, align 4
  %14749 = load i64, i64* %3, align 8
  %14750 = add i64 %14749, 4034
  %.pre644.pre = load i64, i64* %RBP.i, align 8
  br label %block_.L_4a71c1

block_.L_4a620b:                                  ; preds = %block_.L_4a620b.preheader, %block_.L_4a64c6
  %14751 = phi i64 [ %.pre539, %block_.L_4a620b.preheader ], [ %16208, %block_.L_4a64c6 ]
  %14752 = load i64, i64* %RBP.i, align 8
  %14753 = add i64 %14752, -48
  %14754 = add i64 %14751, 4
  store i64 %14754, i64* %3, align 8
  %14755 = inttoptr i64 %14753 to i32*
  %14756 = load i32, i32* %14755, align 4
  %14757 = add i32 %14756, -8
  %14758 = icmp ult i32 %14756, 8
  %14759 = zext i1 %14758 to i8
  store i8 %14759, i8* %18, align 1
  %14760 = and i32 %14757, 255
  %14761 = tail call i32 @llvm.ctpop.i32(i32 %14760)
  %14762 = trunc i32 %14761 to i8
  %14763 = and i8 %14762, 1
  %14764 = xor i8 %14763, 1
  store i8 %14764, i8* %19, align 1
  %14765 = xor i32 %14757, %14756
  %14766 = lshr i32 %14765, 4
  %14767 = trunc i32 %14766 to i8
  %14768 = and i8 %14767, 1
  store i8 %14768, i8* %20, align 1
  %14769 = icmp eq i32 %14757, 0
  %14770 = zext i1 %14769 to i8
  store i8 %14770, i8* %21, align 1
  %14771 = lshr i32 %14757, 31
  %14772 = trunc i32 %14771 to i8
  store i8 %14772, i8* %22, align 1
  %14773 = lshr i32 %14756, 31
  %14774 = xor i32 %14771, %14773
  %14775 = add nuw nsw i32 %14774, %14773
  %14776 = icmp eq i32 %14775, 2
  %14777 = zext i1 %14776 to i8
  store i8 %14777, i8* %23, align 1
  %14778 = icmp ne i8 %14772, 0
  %14779 = xor i1 %14778, %14776
  %.v823 = select i1 %14779, i64 10, i64 718
  %14780 = add i64 %14751, %.v823
  store i64 %14780, i64* %3, align 8
  br i1 %14779, label %block_4a6215, label %block_.L_4a64d9

block_4a6215:                                     ; preds = %block_.L_4a620b
  %14781 = add i64 %14752, -44
  %14782 = add i64 %14780, 7
  store i64 %14782, i64* %3, align 8
  %14783 = inttoptr i64 %14781 to i32*
  store i32 0, i32* %14783, align 4
  %.pre626 = load i64, i64* %3, align 8
  br label %block_.L_4a621c

block_.L_4a621c:                                  ; preds = %block_4a6226, %block_4a6215
  %14784 = phi i64 [ %16178, %block_4a6226 ], [ %.pre626, %block_4a6215 ]
  %14785 = load i64, i64* %RBP.i, align 8
  %14786 = add i64 %14785, -44
  %14787 = add i64 %14784, 4
  store i64 %14787, i64* %3, align 8
  %14788 = inttoptr i64 %14786 to i32*
  %14789 = load i32, i32* %14788, align 4
  %14790 = add i32 %14789, -8
  %14791 = icmp ult i32 %14789, 8
  %14792 = zext i1 %14791 to i8
  store i8 %14792, i8* %18, align 1
  %14793 = and i32 %14790, 255
  %14794 = tail call i32 @llvm.ctpop.i32(i32 %14793)
  %14795 = trunc i32 %14794 to i8
  %14796 = and i8 %14795, 1
  %14797 = xor i8 %14796, 1
  store i8 %14797, i8* %19, align 1
  %14798 = xor i32 %14790, %14789
  %14799 = lshr i32 %14798, 4
  %14800 = trunc i32 %14799 to i8
  %14801 = and i8 %14800, 1
  store i8 %14801, i8* %20, align 1
  %14802 = icmp eq i32 %14790, 0
  %14803 = zext i1 %14802 to i8
  store i8 %14803, i8* %21, align 1
  %14804 = lshr i32 %14790, 31
  %14805 = trunc i32 %14804 to i8
  store i8 %14805, i8* %22, align 1
  %14806 = lshr i32 %14789, 31
  %14807 = xor i32 %14804, %14806
  %14808 = add nuw nsw i32 %14807, %14806
  %14809 = icmp eq i32 %14808, 2
  %14810 = zext i1 %14809 to i8
  store i8 %14810, i8* %23, align 1
  %14811 = icmp ne i8 %14805, 0
  %14812 = xor i1 %14811, %14809
  %.v773 = select i1 %14812, i64 10, i64 682
  %14813 = add i64 %14784, %.v773
  store i64 %14813, i64* %3, align 8
  br i1 %14812, label %block_4a6226, label %block_.L_4a64c6

block_4a6226:                                     ; preds = %block_.L_4a621c
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX.i1763, align 8
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RCX.i1692, align 8
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RDX.i1805, align 8
  %14814 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %14815 = add i64 %14814, 7352
  store i64 %14815, i64* %RSI.i1889, align 8
  %14816 = icmp ugt i64 %14814, -7353
  %14817 = zext i1 %14816 to i8
  store i8 %14817, i8* %18, align 1
  %14818 = trunc i64 %14815 to i32
  %14819 = and i32 %14818, 255
  %14820 = tail call i32 @llvm.ctpop.i32(i32 %14819)
  %14821 = trunc i32 %14820 to i8
  %14822 = and i8 %14821, 1
  %14823 = xor i8 %14822, 1
  store i8 %14823, i8* %19, align 1
  %14824 = xor i64 %14814, 16
  %14825 = xor i64 %14824, %14815
  %14826 = lshr i64 %14825, 4
  %14827 = trunc i64 %14826 to i8
  %14828 = and i8 %14827, 1
  store i8 %14828, i8* %20, align 1
  %14829 = icmp eq i64 %14815, 0
  %14830 = zext i1 %14829 to i8
  store i8 %14830, i8* %21, align 1
  %14831 = lshr i64 %14815, 63
  %14832 = trunc i64 %14831 to i8
  store i8 %14832, i8* %22, align 1
  %14833 = lshr i64 %14814, 63
  %14834 = xor i64 %14831, %14833
  %14835 = add nuw nsw i64 %14834, %14831
  %14836 = icmp eq i64 %14835, 2
  %14837 = zext i1 %14836 to i8
  store i8 %14837, i8* %23, align 1
  %14838 = add i64 %14785, -40
  %14839 = add i64 %14813, 49
  store i64 %14839, i64* %3, align 8
  %14840 = inttoptr i64 %14838 to i32*
  %14841 = load i32, i32* %14840, align 4
  %14842 = sext i32 %14841 to i64
  %14843 = shl nsw i64 %14842, 7
  store i64 %14843, i64* %RDI.i2141, align 8
  %14844 = add i64 %14843, %14815
  store i64 %14844, i64* %RSI.i1889, align 8
  %14845 = icmp ult i64 %14844, %14815
  %14846 = icmp ult i64 %14844, %14843
  %14847 = or i1 %14845, %14846
  %14848 = zext i1 %14847 to i8
  store i8 %14848, i8* %18, align 1
  %14849 = trunc i64 %14844 to i32
  %14850 = and i32 %14849, 255
  %14851 = tail call i32 @llvm.ctpop.i32(i32 %14850)
  %14852 = trunc i32 %14851 to i8
  %14853 = and i8 %14852, 1
  %14854 = xor i8 %14853, 1
  store i8 %14854, i8* %19, align 1
  %14855 = xor i64 %14815, %14844
  %14856 = lshr i64 %14855, 4
  %14857 = trunc i64 %14856 to i8
  %14858 = and i8 %14857, 1
  store i8 %14858, i8* %20, align 1
  %14859 = icmp eq i64 %14844, 0
  %14860 = zext i1 %14859 to i8
  store i8 %14860, i8* %21, align 1
  %14861 = lshr i64 %14844, 63
  %14862 = trunc i64 %14861 to i8
  store i8 %14862, i8* %22, align 1
  %14863 = lshr i64 %14842, 56
  %14864 = and i64 %14863, 1
  %14865 = xor i64 %14861, %14831
  %14866 = xor i64 %14861, %14864
  %14867 = add nuw nsw i64 %14865, %14866
  %14868 = icmp eq i64 %14867, 2
  %14869 = zext i1 %14868 to i8
  store i8 %14869, i8* %23, align 1
  %14870 = load i64, i64* %RBP.i, align 8
  %14871 = add i64 %14870, -48
  %14872 = add i64 %14813, 60
  store i64 %14872, i64* %3, align 8
  %14873 = inttoptr i64 %14871 to i32*
  %14874 = load i32, i32* %14873, align 4
  %14875 = sext i32 %14874 to i64
  %14876 = shl nsw i64 %14875, 4
  store i64 %14876, i64* %RDI.i2141, align 8
  %14877 = add i64 %14876, %14844
  store i64 %14877, i64* %RSI.i1889, align 8
  %14878 = icmp ult i64 %14877, %14844
  %14879 = icmp ult i64 %14877, %14876
  %14880 = or i1 %14878, %14879
  %14881 = zext i1 %14880 to i8
  store i8 %14881, i8* %18, align 1
  %14882 = trunc i64 %14877 to i32
  %14883 = and i32 %14882, 255
  %14884 = tail call i32 @llvm.ctpop.i32(i32 %14883)
  %14885 = trunc i32 %14884 to i8
  %14886 = and i8 %14885, 1
  %14887 = xor i8 %14886, 1
  store i8 %14887, i8* %19, align 1
  %14888 = xor i64 %14876, %14844
  %14889 = xor i64 %14888, %14877
  %14890 = lshr i64 %14889, 4
  %14891 = trunc i64 %14890 to i8
  %14892 = and i8 %14891, 1
  store i8 %14892, i8* %20, align 1
  %14893 = icmp eq i64 %14877, 0
  %14894 = zext i1 %14893 to i8
  store i8 %14894, i8* %21, align 1
  %14895 = lshr i64 %14877, 63
  %14896 = trunc i64 %14895 to i8
  store i8 %14896, i8* %22, align 1
  %14897 = lshr i64 %14875, 59
  %14898 = and i64 %14897, 1
  %14899 = xor i64 %14895, %14861
  %14900 = xor i64 %14895, %14898
  %14901 = add nuw nsw i64 %14899, %14900
  %14902 = icmp eq i64 %14901, 2
  %14903 = zext i1 %14902 to i8
  store i8 %14903, i8* %23, align 1
  %14904 = add i64 %14870, -44
  %14905 = add i64 %14813, 71
  store i64 %14905, i64* %3, align 8
  %14906 = inttoptr i64 %14904 to i32*
  %14907 = load i32, i32* %14906, align 4
  %14908 = sext i32 %14907 to i64
  store i64 %14908, i64* %RDI.i2141, align 8
  %14909 = shl nsw i64 %14908, 1
  %14910 = add i64 %14909, %14877
  %14911 = add i64 %14813, 76
  store i64 %14911, i64* %3, align 8
  %14912 = inttoptr i64 %14910 to i16*
  %14913 = load i16, i16* %14912, align 2
  store i16 %14913, i16* %R8W.i3020, align 2
  %14914 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %14915 = add i64 %14914, 12600
  store i64 %14915, i64* %RSI.i1889, align 8
  %14916 = icmp ugt i64 %14914, -12601
  %14917 = zext i1 %14916 to i8
  store i8 %14917, i8* %18, align 1
  %14918 = trunc i64 %14915 to i32
  %14919 = and i32 %14918, 255
  %14920 = tail call i32 @llvm.ctpop.i32(i32 %14919)
  %14921 = trunc i32 %14920 to i8
  %14922 = and i8 %14921, 1
  %14923 = xor i8 %14922, 1
  store i8 %14923, i8* %19, align 1
  %14924 = xor i64 %14914, 16
  %14925 = xor i64 %14924, %14915
  %14926 = lshr i64 %14925, 4
  %14927 = trunc i64 %14926 to i8
  %14928 = and i8 %14927, 1
  store i8 %14928, i8* %20, align 1
  %14929 = icmp eq i64 %14915, 0
  %14930 = zext i1 %14929 to i8
  store i8 %14930, i8* %21, align 1
  %14931 = lshr i64 %14915, 63
  %14932 = trunc i64 %14931 to i8
  store i8 %14932, i8* %22, align 1
  %14933 = lshr i64 %14914, 63
  %14934 = xor i64 %14931, %14933
  %14935 = add nuw nsw i64 %14934, %14931
  %14936 = icmp eq i64 %14935, 2
  %14937 = zext i1 %14936 to i8
  store i8 %14937, i8* %23, align 1
  %14938 = load i64, i64* %RBP.i, align 8
  %14939 = add i64 %14938, -484
  %14940 = add i64 %14813, 98
  store i64 %14940, i64* %3, align 8
  %14941 = inttoptr i64 %14939 to i32*
  %14942 = load i32, i32* %14941, align 4
  %14943 = zext i32 %14942 to i64
  store i64 %14943, i64* %R9.i, align 8
  %14944 = add i64 %14938, -44
  %14945 = add i64 %14813, 102
  store i64 %14945, i64* %3, align 8
  %14946 = inttoptr i64 %14944 to i32*
  %14947 = load i32, i32* %14946, align 4
  %14948 = add i32 %14947, %14942
  %14949 = zext i32 %14948 to i64
  store i64 %14949, i64* %R9.i, align 8
  %14950 = sext i32 %14948 to i64
  %14951 = shl nsw i64 %14950, 5
  store i64 %14951, i64* %RDI.i2141, align 8
  %14952 = load i64, i64* %RSI.i1889, align 8
  %14953 = add i64 %14951, %14952
  store i64 %14953, i64* %RSI.i1889, align 8
  %14954 = icmp ult i64 %14953, %14952
  %14955 = icmp ult i64 %14953, %14951
  %14956 = or i1 %14954, %14955
  %14957 = zext i1 %14956 to i8
  store i8 %14957, i8* %18, align 1
  %14958 = trunc i64 %14953 to i32
  %14959 = and i32 %14958, 255
  %14960 = tail call i32 @llvm.ctpop.i32(i32 %14959)
  %14961 = trunc i32 %14960 to i8
  %14962 = and i8 %14961, 1
  %14963 = xor i8 %14962, 1
  store i8 %14963, i8* %19, align 1
  %14964 = xor i64 %14952, %14953
  %14965 = lshr i64 %14964, 4
  %14966 = trunc i64 %14965 to i8
  %14967 = and i8 %14966, 1
  store i8 %14967, i8* %20, align 1
  %14968 = icmp eq i64 %14953, 0
  %14969 = zext i1 %14968 to i8
  store i8 %14969, i8* %21, align 1
  %14970 = lshr i64 %14953, 63
  %14971 = trunc i64 %14970 to i8
  store i8 %14971, i8* %22, align 1
  %14972 = lshr i64 %14952, 63
  %14973 = lshr i64 %14950, 58
  %14974 = and i64 %14973, 1
  %14975 = xor i64 %14970, %14972
  %14976 = xor i64 %14970, %14974
  %14977 = add nuw nsw i64 %14975, %14976
  %14978 = icmp eq i64 %14977, 2
  %14979 = zext i1 %14978 to i8
  store i8 %14979, i8* %23, align 1
  %14980 = load i64, i64* %RBP.i, align 8
  %14981 = add i64 %14980, -488
  %14982 = add i64 %14813, 119
  store i64 %14982, i64* %3, align 8
  %14983 = inttoptr i64 %14981 to i32*
  %14984 = load i32, i32* %14983, align 4
  %14985 = zext i32 %14984 to i64
  store i64 %14985, i64* %R9.i, align 8
  %14986 = add i64 %14980, -48
  %14987 = add i64 %14813, 123
  store i64 %14987, i64* %3, align 8
  %14988 = inttoptr i64 %14986 to i32*
  %14989 = load i32, i32* %14988, align 4
  %14990 = add i32 %14989, %14984
  %14991 = zext i32 %14990 to i64
  store i64 %14991, i64* %R9.i, align 8
  %14992 = icmp ult i32 %14990, %14984
  %14993 = icmp ult i32 %14990, %14989
  %14994 = or i1 %14992, %14993
  %14995 = zext i1 %14994 to i8
  store i8 %14995, i8* %18, align 1
  %14996 = and i32 %14990, 255
  %14997 = tail call i32 @llvm.ctpop.i32(i32 %14996)
  %14998 = trunc i32 %14997 to i8
  %14999 = and i8 %14998, 1
  %15000 = xor i8 %14999, 1
  store i8 %15000, i8* %19, align 1
  %15001 = xor i32 %14989, %14984
  %15002 = xor i32 %15001, %14990
  %15003 = lshr i32 %15002, 4
  %15004 = trunc i32 %15003 to i8
  %15005 = and i8 %15004, 1
  store i8 %15005, i8* %20, align 1
  %15006 = icmp eq i32 %14990, 0
  %15007 = zext i1 %15006 to i8
  store i8 %15007, i8* %21, align 1
  %15008 = lshr i32 %14990, 31
  %15009 = trunc i32 %15008 to i8
  store i8 %15009, i8* %22, align 1
  %15010 = lshr i32 %14984, 31
  %15011 = lshr i32 %14989, 31
  %15012 = xor i32 %15008, %15010
  %15013 = xor i32 %15008, %15011
  %15014 = add nuw nsw i32 %15012, %15013
  %15015 = icmp eq i32 %15014, 2
  %15016 = zext i1 %15015 to i8
  store i8 %15016, i8* %23, align 1
  %15017 = sext i32 %14990 to i64
  store i64 %15017, i64* %RDI.i2141, align 8
  %15018 = shl nsw i64 %15017, 1
  %15019 = add i64 %14953, %15018
  %15020 = load i16, i16* %R8W.i3020, align 2
  %15021 = add i64 %14813, 131
  store i64 %15021, i64* %3, align 8
  %15022 = inttoptr i64 %15019 to i16*
  store i16 %15020, i16* %15022, align 2
  %15023 = load i64, i64* %3, align 8
  %15024 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %15024, i64* %RSI.i1889, align 8
  %15025 = add i64 %15023, 11
  store i64 %15025, i64* %3, align 8
  %15026 = inttoptr i64 %15024 to i64*
  %15027 = load i64, i64* %15026, align 8
  store i64 %15027, i64* %RSI.i1889, align 8
  %15028 = load i64, i64* %RBP.i, align 8
  %15029 = add i64 %15028, -504
  %15030 = add i64 %15023, 18
  store i64 %15030, i64* %3, align 8
  %15031 = inttoptr i64 %15029 to i32*
  %15032 = load i32, i32* %15031, align 4
  %15033 = zext i32 %15032 to i64
  store i64 %15033, i64* %R9.i, align 8
  %15034 = add i64 %15028, -48
  %15035 = add i64 %15023, 22
  store i64 %15035, i64* %3, align 8
  %15036 = inttoptr i64 %15034 to i32*
  %15037 = load i32, i32* %15036, align 4
  %15038 = add i32 %15037, %15032
  %15039 = zext i32 %15038 to i64
  store i64 %15039, i64* %R9.i, align 8
  %15040 = icmp ult i32 %15038, %15032
  %15041 = icmp ult i32 %15038, %15037
  %15042 = or i1 %15040, %15041
  %15043 = zext i1 %15042 to i8
  store i8 %15043, i8* %18, align 1
  %15044 = and i32 %15038, 255
  %15045 = tail call i32 @llvm.ctpop.i32(i32 %15044)
  %15046 = trunc i32 %15045 to i8
  %15047 = and i8 %15046, 1
  %15048 = xor i8 %15047, 1
  store i8 %15048, i8* %19, align 1
  %15049 = xor i32 %15037, %15032
  %15050 = xor i32 %15049, %15038
  %15051 = lshr i32 %15050, 4
  %15052 = trunc i32 %15051 to i8
  %15053 = and i8 %15052, 1
  store i8 %15053, i8* %20, align 1
  %15054 = icmp eq i32 %15038, 0
  %15055 = zext i1 %15054 to i8
  store i8 %15055, i8* %21, align 1
  %15056 = lshr i32 %15038, 31
  %15057 = trunc i32 %15056 to i8
  store i8 %15057, i8* %22, align 1
  %15058 = lshr i32 %15032, 31
  %15059 = lshr i32 %15037, 31
  %15060 = xor i32 %15056, %15058
  %15061 = xor i32 %15056, %15059
  %15062 = add nuw nsw i32 %15060, %15061
  %15063 = icmp eq i32 %15062, 2
  %15064 = zext i1 %15063 to i8
  store i8 %15064, i8* %23, align 1
  %15065 = sext i32 %15038 to i64
  store i64 %15065, i64* %RDI.i2141, align 8
  %15066 = shl nsw i64 %15065, 3
  %15067 = add i64 %15027, %15066
  %15068 = add i64 %15023, 29
  store i64 %15068, i64* %3, align 8
  %15069 = inttoptr i64 %15067 to i64*
  %15070 = load i64, i64* %15069, align 8
  store i64 %15070, i64* %RSI.i1889, align 8
  %15071 = add i64 %15028, -500
  %15072 = add i64 %15023, 36
  store i64 %15072, i64* %3, align 8
  %15073 = inttoptr i64 %15071 to i32*
  %15074 = load i32, i32* %15073, align 4
  %15075 = zext i32 %15074 to i64
  store i64 %15075, i64* %R9.i, align 8
  %15076 = add i64 %15028, -44
  %15077 = add i64 %15023, 40
  store i64 %15077, i64* %3, align 8
  %15078 = inttoptr i64 %15076 to i32*
  %15079 = load i32, i32* %15078, align 4
  %15080 = add i32 %15079, %15074
  %15081 = zext i32 %15080 to i64
  store i64 %15081, i64* %R9.i, align 8
  %15082 = icmp ult i32 %15080, %15074
  %15083 = icmp ult i32 %15080, %15079
  %15084 = or i1 %15082, %15083
  %15085 = zext i1 %15084 to i8
  store i8 %15085, i8* %18, align 1
  %15086 = and i32 %15080, 255
  %15087 = tail call i32 @llvm.ctpop.i32(i32 %15086)
  %15088 = trunc i32 %15087 to i8
  %15089 = and i8 %15088, 1
  %15090 = xor i8 %15089, 1
  store i8 %15090, i8* %19, align 1
  %15091 = xor i32 %15079, %15074
  %15092 = xor i32 %15091, %15080
  %15093 = lshr i32 %15092, 4
  %15094 = trunc i32 %15093 to i8
  %15095 = and i8 %15094, 1
  store i8 %15095, i8* %20, align 1
  %15096 = icmp eq i32 %15080, 0
  %15097 = zext i1 %15096 to i8
  store i8 %15097, i8* %21, align 1
  %15098 = lshr i32 %15080, 31
  %15099 = trunc i32 %15098 to i8
  store i8 %15099, i8* %22, align 1
  %15100 = lshr i32 %15074, 31
  %15101 = lshr i32 %15079, 31
  %15102 = xor i32 %15098, %15100
  %15103 = xor i32 %15098, %15101
  %15104 = add nuw nsw i32 %15102, %15103
  %15105 = icmp eq i32 %15104, 2
  %15106 = zext i1 %15105 to i8
  store i8 %15106, i8* %23, align 1
  %15107 = sext i32 %15080 to i64
  store i64 %15107, i64* %RDI.i2141, align 8
  %15108 = shl nsw i64 %15107, 1
  %15109 = add i64 %15070, %15108
  %15110 = add i64 %15023, 48
  store i64 %15110, i64* %3, align 8
  %15111 = inttoptr i64 %15109 to i16*
  %15112 = load i16, i16* %15111, align 2
  %15113 = zext i16 %15112 to i64
  store i64 %15113, i64* %R9.i, align 8
  %15114 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %15115 = add i64 %15114, 8504
  store i64 %15115, i64* %RSI.i1889, align 8
  %15116 = icmp ugt i64 %15114, -8505
  %15117 = zext i1 %15116 to i8
  store i8 %15117, i8* %18, align 1
  %15118 = trunc i64 %15115 to i32
  %15119 = and i32 %15118, 255
  %15120 = tail call i32 @llvm.ctpop.i32(i32 %15119)
  %15121 = trunc i32 %15120 to i8
  %15122 = and i8 %15121, 1
  %15123 = xor i8 %15122, 1
  store i8 %15123, i8* %19, align 1
  %15124 = xor i64 %15114, 16
  %15125 = xor i64 %15124, %15115
  %15126 = lshr i64 %15125, 4
  %15127 = trunc i64 %15126 to i8
  %15128 = and i8 %15127, 1
  store i8 %15128, i8* %20, align 1
  %15129 = icmp eq i64 %15115, 0
  %15130 = zext i1 %15129 to i8
  store i8 %15130, i8* %21, align 1
  %15131 = lshr i64 %15115, 63
  %15132 = trunc i64 %15131 to i8
  store i8 %15132, i8* %22, align 1
  %15133 = lshr i64 %15114, 63
  %15134 = xor i64 %15131, %15133
  %15135 = add nuw nsw i64 %15134, %15131
  %15136 = icmp eq i64 %15135, 2
  %15137 = zext i1 %15136 to i8
  store i8 %15137, i8* %23, align 1
  %15138 = load i64, i64* %RBP.i, align 8
  %15139 = add i64 %15138, -632
  %15140 = add i64 %15023, 70
  store i64 %15140, i64* %3, align 8
  %15141 = inttoptr i64 %15139 to i32*
  %15142 = load i32, i32* %15141, align 4
  %15143 = sext i32 %15142 to i64
  %15144 = shl nsw i64 %15143, 9
  store i64 %15144, i64* %RDI.i2141, align 8
  %15145 = add i64 %15144, %15115
  store i64 %15145, i64* %RSI.i1889, align 8
  %15146 = icmp ult i64 %15145, %15115
  %15147 = icmp ult i64 %15145, %15144
  %15148 = or i1 %15146, %15147
  %15149 = zext i1 %15148 to i8
  store i8 %15149, i8* %18, align 1
  %15150 = trunc i64 %15145 to i32
  %15151 = and i32 %15150, 255
  %15152 = tail call i32 @llvm.ctpop.i32(i32 %15151)
  %15153 = trunc i32 %15152 to i8
  %15154 = and i8 %15153, 1
  %15155 = xor i8 %15154, 1
  store i8 %15155, i8* %19, align 1
  %15156 = xor i64 %15115, %15145
  %15157 = lshr i64 %15156, 4
  %15158 = trunc i64 %15157 to i8
  %15159 = and i8 %15158, 1
  store i8 %15159, i8* %20, align 1
  %15160 = icmp eq i64 %15145, 0
  %15161 = zext i1 %15160 to i8
  store i8 %15161, i8* %21, align 1
  %15162 = lshr i64 %15145, 63
  %15163 = trunc i64 %15162 to i8
  store i8 %15163, i8* %22, align 1
  %15164 = lshr i64 %15143, 54
  %15165 = and i64 %15164, 1
  %15166 = xor i64 %15162, %15131
  %15167 = xor i64 %15162, %15165
  %15168 = add nuw nsw i64 %15166, %15167
  %15169 = icmp eq i64 %15168, 2
  %15170 = zext i1 %15169 to i8
  store i8 %15170, i8* %23, align 1
  %15171 = add i64 %15138, -484
  %15172 = add i64 %15023, 84
  store i64 %15172, i64* %3, align 8
  %15173 = inttoptr i64 %15171 to i32*
  %15174 = load i32, i32* %15173, align 4
  %15175 = zext i32 %15174 to i64
  store i64 %15175, i64* %372, align 8
  %15176 = add i64 %15138, -44
  %15177 = add i64 %15023, 88
  store i64 %15177, i64* %3, align 8
  %15178 = inttoptr i64 %15176 to i32*
  %15179 = load i32, i32* %15178, align 4
  %15180 = add i32 %15179, %15174
  %15181 = zext i32 %15180 to i64
  store i64 %15181, i64* %372, align 8
  %15182 = sext i32 %15180 to i64
  %15183 = shl nsw i64 %15182, 5
  store i64 %15183, i64* %RDI.i2141, align 8
  %15184 = load i64, i64* %RSI.i1889, align 8
  %15185 = add i64 %15183, %15184
  store i64 %15185, i64* %RSI.i1889, align 8
  %15186 = icmp ult i64 %15185, %15184
  %15187 = icmp ult i64 %15185, %15183
  %15188 = or i1 %15186, %15187
  %15189 = zext i1 %15188 to i8
  store i8 %15189, i8* %18, align 1
  %15190 = trunc i64 %15185 to i32
  %15191 = and i32 %15190, 255
  %15192 = tail call i32 @llvm.ctpop.i32(i32 %15191)
  %15193 = trunc i32 %15192 to i8
  %15194 = and i8 %15193, 1
  %15195 = xor i8 %15194, 1
  store i8 %15195, i8* %19, align 1
  %15196 = xor i64 %15184, %15185
  %15197 = lshr i64 %15196, 4
  %15198 = trunc i64 %15197 to i8
  %15199 = and i8 %15198, 1
  store i8 %15199, i8* %20, align 1
  %15200 = icmp eq i64 %15185, 0
  %15201 = zext i1 %15200 to i8
  store i8 %15201, i8* %21, align 1
  %15202 = lshr i64 %15185, 63
  %15203 = trunc i64 %15202 to i8
  store i8 %15203, i8* %22, align 1
  %15204 = lshr i64 %15184, 63
  %15205 = lshr i64 %15182, 58
  %15206 = and i64 %15205, 1
  %15207 = xor i64 %15202, %15204
  %15208 = xor i64 %15202, %15206
  %15209 = add nuw nsw i64 %15207, %15208
  %15210 = icmp eq i64 %15209, 2
  %15211 = zext i1 %15210 to i8
  store i8 %15211, i8* %23, align 1
  %15212 = load i64, i64* %RBP.i, align 8
  %15213 = add i64 %15212, -488
  %15214 = add i64 %15023, 105
  store i64 %15214, i64* %3, align 8
  %15215 = inttoptr i64 %15213 to i32*
  %15216 = load i32, i32* %15215, align 4
  %15217 = zext i32 %15216 to i64
  store i64 %15217, i64* %372, align 8
  %15218 = add i64 %15212, -48
  %15219 = add i64 %15023, 109
  store i64 %15219, i64* %3, align 8
  %15220 = inttoptr i64 %15218 to i32*
  %15221 = load i32, i32* %15220, align 4
  %15222 = add i32 %15221, %15216
  %15223 = zext i32 %15222 to i64
  store i64 %15223, i64* %372, align 8
  %15224 = icmp ult i32 %15222, %15216
  %15225 = icmp ult i32 %15222, %15221
  %15226 = or i1 %15224, %15225
  %15227 = zext i1 %15226 to i8
  store i8 %15227, i8* %18, align 1
  %15228 = and i32 %15222, 255
  %15229 = tail call i32 @llvm.ctpop.i32(i32 %15228)
  %15230 = trunc i32 %15229 to i8
  %15231 = and i8 %15230, 1
  %15232 = xor i8 %15231, 1
  store i8 %15232, i8* %19, align 1
  %15233 = xor i32 %15221, %15216
  %15234 = xor i32 %15233, %15222
  %15235 = lshr i32 %15234, 4
  %15236 = trunc i32 %15235 to i8
  %15237 = and i8 %15236, 1
  store i8 %15237, i8* %20, align 1
  %15238 = icmp eq i32 %15222, 0
  %15239 = zext i1 %15238 to i8
  store i8 %15239, i8* %21, align 1
  %15240 = lshr i32 %15222, 31
  %15241 = trunc i32 %15240 to i8
  store i8 %15241, i8* %22, align 1
  %15242 = lshr i32 %15216, 31
  %15243 = lshr i32 %15221, 31
  %15244 = xor i32 %15240, %15242
  %15245 = xor i32 %15240, %15243
  %15246 = add nuw nsw i32 %15244, %15245
  %15247 = icmp eq i32 %15246, 2
  %15248 = zext i1 %15247 to i8
  store i8 %15248, i8* %23, align 1
  %15249 = sext i32 %15222 to i64
  store i64 %15249, i64* %RDI.i2141, align 8
  %15250 = shl nsw i64 %15249, 1
  %15251 = add i64 %15185, %15250
  %15252 = add i64 %15023, 117
  store i64 %15252, i64* %3, align 8
  %15253 = inttoptr i64 %15251 to i16*
  %15254 = load i16, i16* %15253, align 2
  %15255 = zext i16 %15254 to i64
  store i64 %15255, i64* %372, align 8
  %15256 = load i32, i32* %R9D.i6640, align 4
  %15257 = zext i16 %15254 to i32
  %15258 = sub i32 %15256, %15257
  %15259 = zext i32 %15258 to i64
  store i64 %15259, i64* %R9.i, align 8
  %15260 = icmp ult i32 %15256, %15257
  %15261 = zext i1 %15260 to i8
  store i8 %15261, i8* %18, align 1
  %15262 = and i32 %15258, 255
  %15263 = tail call i32 @llvm.ctpop.i32(i32 %15262)
  %15264 = trunc i32 %15263 to i8
  %15265 = and i8 %15264, 1
  %15266 = xor i8 %15265, 1
  store i8 %15266, i8* %19, align 1
  %15267 = xor i32 %15257, %15256
  %15268 = xor i32 %15267, %15258
  %15269 = lshr i32 %15268, 4
  %15270 = trunc i32 %15269 to i8
  %15271 = and i8 %15270, 1
  store i8 %15271, i8* %20, align 1
  %15272 = icmp eq i32 %15258, 0
  %15273 = zext i1 %15272 to i8
  store i8 %15273, i8* %21, align 1
  %15274 = lshr i32 %15258, 31
  %15275 = trunc i32 %15274 to i8
  store i8 %15275, i8* %22, align 1
  %15276 = lshr i32 %15256, 31
  %15277 = xor i32 %15274, %15276
  %15278 = add nuw nsw i32 %15277, %15276
  %15279 = icmp eq i32 %15278, 2
  %15280 = zext i1 %15279 to i8
  store i8 %15280, i8* %23, align 1
  %15281 = add i64 %15212, -612
  %15282 = add i64 %15023, 127
  store i64 %15282, i64* %3, align 8
  %15283 = inttoptr i64 %15281 to i32*
  store i32 %15258, i32* %15283, align 4
  %15284 = load i64, i64* %3, align 8
  %15285 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %15285, i64* %RSI.i1889, align 8
  %15286 = load i64, i64* %RBP.i, align 8
  %15287 = add i64 %15286, -504
  %15288 = add i64 %15284, 15
  store i64 %15288, i64* %3, align 8
  %15289 = inttoptr i64 %15287 to i32*
  %15290 = load i32, i32* %15289, align 4
  %15291 = zext i32 %15290 to i64
  store i64 %15291, i64* %R9.i, align 8
  %15292 = add i64 %15286, -48
  %15293 = add i64 %15284, 19
  store i64 %15293, i64* %3, align 8
  %15294 = inttoptr i64 %15292 to i32*
  %15295 = load i32, i32* %15294, align 4
  %15296 = add i32 %15295, %15290
  %15297 = zext i32 %15296 to i64
  store i64 %15297, i64* %R9.i, align 8
  %15298 = icmp ult i32 %15296, %15290
  %15299 = icmp ult i32 %15296, %15295
  %15300 = or i1 %15298, %15299
  %15301 = zext i1 %15300 to i8
  store i8 %15301, i8* %18, align 1
  %15302 = and i32 %15296, 255
  %15303 = tail call i32 @llvm.ctpop.i32(i32 %15302)
  %15304 = trunc i32 %15303 to i8
  %15305 = and i8 %15304, 1
  %15306 = xor i8 %15305, 1
  store i8 %15306, i8* %19, align 1
  %15307 = xor i32 %15295, %15290
  %15308 = xor i32 %15307, %15296
  %15309 = lshr i32 %15308, 4
  %15310 = trunc i32 %15309 to i8
  %15311 = and i8 %15310, 1
  store i8 %15311, i8* %20, align 1
  %15312 = icmp eq i32 %15296, 0
  %15313 = zext i1 %15312 to i8
  store i8 %15313, i8* %21, align 1
  %15314 = lshr i32 %15296, 31
  %15315 = trunc i32 %15314 to i8
  store i8 %15315, i8* %22, align 1
  %15316 = lshr i32 %15290, 31
  %15317 = lshr i32 %15295, 31
  %15318 = xor i32 %15314, %15316
  %15319 = xor i32 %15314, %15317
  %15320 = add nuw nsw i32 %15318, %15319
  %15321 = icmp eq i32 %15320, 2
  %15322 = zext i1 %15321 to i8
  store i8 %15322, i8* %23, align 1
  %15323 = sext i32 %15296 to i64
  store i64 %15323, i64* %RDI.i2141, align 8
  %15324 = shl nsw i64 %15323, 3
  %15325 = add i64 %15285, %15324
  %15326 = add i64 %15284, 26
  store i64 %15326, i64* %3, align 8
  %15327 = inttoptr i64 %15325 to i64*
  %15328 = load i64, i64* %15327, align 8
  store i64 %15328, i64* %RSI.i1889, align 8
  %15329 = add i64 %15286, -500
  %15330 = add i64 %15284, 33
  store i64 %15330, i64* %3, align 8
  %15331 = inttoptr i64 %15329 to i32*
  %15332 = load i32, i32* %15331, align 4
  %15333 = zext i32 %15332 to i64
  store i64 %15333, i64* %R9.i, align 8
  %15334 = add i64 %15286, -44
  %15335 = add i64 %15284, 37
  store i64 %15335, i64* %3, align 8
  %15336 = inttoptr i64 %15334 to i32*
  %15337 = load i32, i32* %15336, align 4
  %15338 = add i32 %15337, %15332
  %15339 = zext i32 %15338 to i64
  store i64 %15339, i64* %R9.i, align 8
  %15340 = icmp ult i32 %15338, %15332
  %15341 = icmp ult i32 %15338, %15337
  %15342 = or i1 %15340, %15341
  %15343 = zext i1 %15342 to i8
  store i8 %15343, i8* %18, align 1
  %15344 = and i32 %15338, 255
  %15345 = tail call i32 @llvm.ctpop.i32(i32 %15344)
  %15346 = trunc i32 %15345 to i8
  %15347 = and i8 %15346, 1
  %15348 = xor i8 %15347, 1
  store i8 %15348, i8* %19, align 1
  %15349 = xor i32 %15337, %15332
  %15350 = xor i32 %15349, %15338
  %15351 = lshr i32 %15350, 4
  %15352 = trunc i32 %15351 to i8
  %15353 = and i8 %15352, 1
  store i8 %15353, i8* %20, align 1
  %15354 = icmp eq i32 %15338, 0
  %15355 = zext i1 %15354 to i8
  store i8 %15355, i8* %21, align 1
  %15356 = lshr i32 %15338, 31
  %15357 = trunc i32 %15356 to i8
  store i8 %15357, i8* %22, align 1
  %15358 = lshr i32 %15332, 31
  %15359 = lshr i32 %15337, 31
  %15360 = xor i32 %15356, %15358
  %15361 = xor i32 %15356, %15359
  %15362 = add nuw nsw i32 %15360, %15361
  %15363 = icmp eq i32 %15362, 2
  %15364 = zext i1 %15363 to i8
  store i8 %15364, i8* %23, align 1
  %15365 = sext i32 %15338 to i64
  store i64 %15365, i64* %RDI.i2141, align 8
  %15366 = shl nsw i64 %15365, 1
  %15367 = add i64 %15328, %15366
  %15368 = add i64 %15284, 45
  store i64 %15368, i64* %3, align 8
  %15369 = inttoptr i64 %15367 to i16*
  %15370 = load i16, i16* %15369, align 2
  %15371 = zext i16 %15370 to i64
  store i64 %15371, i64* %R9.i, align 8
  %15372 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %15373 = add i64 %15372, 7352
  store i64 %15373, i64* %RSI.i1889, align 8
  %15374 = icmp ugt i64 %15372, -7353
  %15375 = zext i1 %15374 to i8
  store i8 %15375, i8* %18, align 1
  %15376 = trunc i64 %15373 to i32
  %15377 = and i32 %15376, 255
  %15378 = tail call i32 @llvm.ctpop.i32(i32 %15377)
  %15379 = trunc i32 %15378 to i8
  %15380 = and i8 %15379, 1
  %15381 = xor i8 %15380, 1
  store i8 %15381, i8* %19, align 1
  %15382 = xor i64 %15372, 16
  %15383 = xor i64 %15382, %15373
  %15384 = lshr i64 %15383, 4
  %15385 = trunc i64 %15384 to i8
  %15386 = and i8 %15385, 1
  store i8 %15386, i8* %20, align 1
  %15387 = icmp eq i64 %15373, 0
  %15388 = zext i1 %15387 to i8
  store i8 %15388, i8* %21, align 1
  %15389 = lshr i64 %15373, 63
  %15390 = trunc i64 %15389 to i8
  store i8 %15390, i8* %22, align 1
  %15391 = lshr i64 %15372, 63
  %15392 = xor i64 %15389, %15391
  %15393 = add nuw nsw i64 %15392, %15389
  %15394 = icmp eq i64 %15393, 2
  %15395 = zext i1 %15394 to i8
  store i8 %15395, i8* %23, align 1
  %15396 = load i64, i64* %RBP.i, align 8
  %15397 = add i64 %15396, -40
  %15398 = add i64 %15284, 64
  store i64 %15398, i64* %3, align 8
  %15399 = inttoptr i64 %15397 to i32*
  %15400 = load i32, i32* %15399, align 4
  %15401 = sext i32 %15400 to i64
  %15402 = shl nsw i64 %15401, 7
  store i64 %15402, i64* %RDI.i2141, align 8
  %15403 = add i64 %15402, %15373
  store i64 %15403, i64* %RSI.i1889, align 8
  %15404 = icmp ult i64 %15403, %15373
  %15405 = icmp ult i64 %15403, %15402
  %15406 = or i1 %15404, %15405
  %15407 = zext i1 %15406 to i8
  store i8 %15407, i8* %18, align 1
  %15408 = trunc i64 %15403 to i32
  %15409 = and i32 %15408, 255
  %15410 = tail call i32 @llvm.ctpop.i32(i32 %15409)
  %15411 = trunc i32 %15410 to i8
  %15412 = and i8 %15411, 1
  %15413 = xor i8 %15412, 1
  store i8 %15413, i8* %19, align 1
  %15414 = xor i64 %15373, %15403
  %15415 = lshr i64 %15414, 4
  %15416 = trunc i64 %15415 to i8
  %15417 = and i8 %15416, 1
  store i8 %15417, i8* %20, align 1
  %15418 = icmp eq i64 %15403, 0
  %15419 = zext i1 %15418 to i8
  store i8 %15419, i8* %21, align 1
  %15420 = lshr i64 %15403, 63
  %15421 = trunc i64 %15420 to i8
  store i8 %15421, i8* %22, align 1
  %15422 = lshr i64 %15401, 56
  %15423 = and i64 %15422, 1
  %15424 = xor i64 %15420, %15389
  %15425 = xor i64 %15420, %15423
  %15426 = add nuw nsw i64 %15424, %15425
  %15427 = icmp eq i64 %15426, 2
  %15428 = zext i1 %15427 to i8
  store i8 %15428, i8* %23, align 1
  %15429 = add i64 %15396, -48
  %15430 = add i64 %15284, 75
  store i64 %15430, i64* %3, align 8
  %15431 = inttoptr i64 %15429 to i32*
  %15432 = load i32, i32* %15431, align 4
  %15433 = sext i32 %15432 to i64
  %15434 = shl nsw i64 %15433, 4
  store i64 %15434, i64* %RDI.i2141, align 8
  %15435 = add i64 %15434, %15403
  store i64 %15435, i64* %RSI.i1889, align 8
  %15436 = icmp ult i64 %15435, %15403
  %15437 = icmp ult i64 %15435, %15434
  %15438 = or i1 %15436, %15437
  %15439 = zext i1 %15438 to i8
  store i8 %15439, i8* %18, align 1
  %15440 = trunc i64 %15435 to i32
  %15441 = and i32 %15440, 255
  %15442 = tail call i32 @llvm.ctpop.i32(i32 %15441)
  %15443 = trunc i32 %15442 to i8
  %15444 = and i8 %15443, 1
  %15445 = xor i8 %15444, 1
  store i8 %15445, i8* %19, align 1
  %15446 = xor i64 %15434, %15403
  %15447 = xor i64 %15446, %15435
  %15448 = lshr i64 %15447, 4
  %15449 = trunc i64 %15448 to i8
  %15450 = and i8 %15449, 1
  store i8 %15450, i8* %20, align 1
  %15451 = icmp eq i64 %15435, 0
  %15452 = zext i1 %15451 to i8
  store i8 %15452, i8* %21, align 1
  %15453 = lshr i64 %15435, 63
  %15454 = trunc i64 %15453 to i8
  store i8 %15454, i8* %22, align 1
  %15455 = lshr i64 %15433, 59
  %15456 = and i64 %15455, 1
  %15457 = xor i64 %15453, %15420
  %15458 = xor i64 %15453, %15456
  %15459 = add nuw nsw i64 %15457, %15458
  %15460 = icmp eq i64 %15459, 2
  %15461 = zext i1 %15460 to i8
  store i8 %15461, i8* %23, align 1
  %15462 = load i64, i64* %RBP.i, align 8
  %15463 = add i64 %15462, -44
  %15464 = add i64 %15284, 86
  store i64 %15464, i64* %3, align 8
  %15465 = inttoptr i64 %15463 to i32*
  %15466 = load i32, i32* %15465, align 4
  %15467 = sext i32 %15466 to i64
  store i64 %15467, i64* %RDI.i2141, align 8
  %15468 = shl nsw i64 %15467, 1
  %15469 = add i64 %15468, %15435
  %15470 = add i64 %15284, 91
  store i64 %15470, i64* %3, align 8
  %15471 = inttoptr i64 %15469 to i16*
  %15472 = load i16, i16* %15471, align 2
  %15473 = zext i16 %15472 to i64
  store i64 %15473, i64* %372, align 8
  %15474 = load i32, i32* %R9D.i6640, align 4
  %15475 = zext i16 %15472 to i32
  %15476 = sub i32 %15474, %15475
  %15477 = zext i32 %15476 to i64
  store i64 %15477, i64* %R9.i, align 8
  %15478 = icmp ult i32 %15474, %15475
  %15479 = zext i1 %15478 to i8
  store i8 %15479, i8* %18, align 1
  %15480 = and i32 %15476, 255
  %15481 = tail call i32 @llvm.ctpop.i32(i32 %15480)
  %15482 = trunc i32 %15481 to i8
  %15483 = and i8 %15482, 1
  %15484 = xor i8 %15483, 1
  store i8 %15484, i8* %19, align 1
  %15485 = xor i32 %15475, %15474
  %15486 = xor i32 %15485, %15476
  %15487 = lshr i32 %15486, 4
  %15488 = trunc i32 %15487 to i8
  %15489 = and i8 %15488, 1
  store i8 %15489, i8* %20, align 1
  %15490 = icmp eq i32 %15476, 0
  %15491 = zext i1 %15490 to i8
  store i8 %15491, i8* %21, align 1
  %15492 = lshr i32 %15476, 31
  %15493 = trunc i32 %15492 to i8
  store i8 %15493, i8* %22, align 1
  %15494 = lshr i32 %15474, 31
  %15495 = xor i32 %15492, %15494
  %15496 = add nuw nsw i32 %15495, %15494
  %15497 = icmp eq i32 %15496, 2
  %15498 = zext i1 %15497 to i8
  store i8 %15498, i8* %23, align 1
  %15499 = add i64 %15462, -608
  %15500 = add i64 %15284, 101
  store i64 %15500, i64* %3, align 8
  %15501 = inttoptr i64 %15499 to i32*
  store i32 %15476, i32* %15501, align 4
  %15502 = load i64, i64* %3, align 8
  %15503 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %15503, i64* %RSI.i1889, align 8
  %15504 = add i64 %15503, 8
  %15505 = add i64 %15502, 12
  store i64 %15505, i64* %3, align 8
  %15506 = inttoptr i64 %15504 to i64*
  %15507 = load i64, i64* %15506, align 8
  store i64 %15507, i64* %RSI.i1889, align 8
  %15508 = load i64, i64* %RBP.i, align 8
  %15509 = add i64 %15508, -504
  %15510 = add i64 %15502, 19
  store i64 %15510, i64* %3, align 8
  %15511 = inttoptr i64 %15509 to i32*
  %15512 = load i32, i32* %15511, align 4
  %15513 = zext i32 %15512 to i64
  store i64 %15513, i64* %R9.i, align 8
  %15514 = add i64 %15508, -48
  %15515 = add i64 %15502, 23
  store i64 %15515, i64* %3, align 8
  %15516 = inttoptr i64 %15514 to i32*
  %15517 = load i32, i32* %15516, align 4
  %15518 = add i32 %15517, %15512
  %15519 = zext i32 %15518 to i64
  store i64 %15519, i64* %R9.i, align 8
  %15520 = icmp ult i32 %15518, %15512
  %15521 = icmp ult i32 %15518, %15517
  %15522 = or i1 %15520, %15521
  %15523 = zext i1 %15522 to i8
  store i8 %15523, i8* %18, align 1
  %15524 = and i32 %15518, 255
  %15525 = tail call i32 @llvm.ctpop.i32(i32 %15524)
  %15526 = trunc i32 %15525 to i8
  %15527 = and i8 %15526, 1
  %15528 = xor i8 %15527, 1
  store i8 %15528, i8* %19, align 1
  %15529 = xor i32 %15517, %15512
  %15530 = xor i32 %15529, %15518
  %15531 = lshr i32 %15530, 4
  %15532 = trunc i32 %15531 to i8
  %15533 = and i8 %15532, 1
  store i8 %15533, i8* %20, align 1
  %15534 = icmp eq i32 %15518, 0
  %15535 = zext i1 %15534 to i8
  store i8 %15535, i8* %21, align 1
  %15536 = lshr i32 %15518, 31
  %15537 = trunc i32 %15536 to i8
  store i8 %15537, i8* %22, align 1
  %15538 = lshr i32 %15512, 31
  %15539 = lshr i32 %15517, 31
  %15540 = xor i32 %15536, %15538
  %15541 = xor i32 %15536, %15539
  %15542 = add nuw nsw i32 %15540, %15541
  %15543 = icmp eq i32 %15542, 2
  %15544 = zext i1 %15543 to i8
  store i8 %15544, i8* %23, align 1
  %15545 = sext i32 %15518 to i64
  store i64 %15545, i64* %RDI.i2141, align 8
  %15546 = shl nsw i64 %15545, 3
  %15547 = add i64 %15507, %15546
  %15548 = add i64 %15502, 30
  store i64 %15548, i64* %3, align 8
  %15549 = inttoptr i64 %15547 to i64*
  %15550 = load i64, i64* %15549, align 8
  store i64 %15550, i64* %RSI.i1889, align 8
  %15551 = add i64 %15508, -500
  %15552 = add i64 %15502, 37
  store i64 %15552, i64* %3, align 8
  %15553 = inttoptr i64 %15551 to i32*
  %15554 = load i32, i32* %15553, align 4
  %15555 = zext i32 %15554 to i64
  store i64 %15555, i64* %R9.i, align 8
  %15556 = add i64 %15508, -44
  %15557 = add i64 %15502, 41
  store i64 %15557, i64* %3, align 8
  %15558 = inttoptr i64 %15556 to i32*
  %15559 = load i32, i32* %15558, align 4
  %15560 = add i32 %15559, %15554
  %15561 = zext i32 %15560 to i64
  store i64 %15561, i64* %R9.i, align 8
  %15562 = icmp ult i32 %15560, %15554
  %15563 = icmp ult i32 %15560, %15559
  %15564 = or i1 %15562, %15563
  %15565 = zext i1 %15564 to i8
  store i8 %15565, i8* %18, align 1
  %15566 = and i32 %15560, 255
  %15567 = tail call i32 @llvm.ctpop.i32(i32 %15566)
  %15568 = trunc i32 %15567 to i8
  %15569 = and i8 %15568, 1
  %15570 = xor i8 %15569, 1
  store i8 %15570, i8* %19, align 1
  %15571 = xor i32 %15559, %15554
  %15572 = xor i32 %15571, %15560
  %15573 = lshr i32 %15572, 4
  %15574 = trunc i32 %15573 to i8
  %15575 = and i8 %15574, 1
  store i8 %15575, i8* %20, align 1
  %15576 = icmp eq i32 %15560, 0
  %15577 = zext i1 %15576 to i8
  store i8 %15577, i8* %21, align 1
  %15578 = lshr i32 %15560, 31
  %15579 = trunc i32 %15578 to i8
  store i8 %15579, i8* %22, align 1
  %15580 = lshr i32 %15554, 31
  %15581 = lshr i32 %15559, 31
  %15582 = xor i32 %15578, %15580
  %15583 = xor i32 %15578, %15581
  %15584 = add nuw nsw i32 %15582, %15583
  %15585 = icmp eq i32 %15584, 2
  %15586 = zext i1 %15585 to i8
  store i8 %15586, i8* %23, align 1
  %15587 = sext i32 %15560 to i64
  store i64 %15587, i64* %RDI.i2141, align 8
  %15588 = shl nsw i64 %15587, 1
  %15589 = add i64 %15550, %15588
  %15590 = add i64 %15502, 49
  store i64 %15590, i64* %3, align 8
  %15591 = inttoptr i64 %15589 to i16*
  %15592 = load i16, i16* %15591, align 2
  %15593 = zext i16 %15592 to i64
  store i64 %15593, i64* %R9.i, align 8
  %15594 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %15595 = add i64 %15594, 8504
  %15596 = lshr i64 %15595, 63
  %15597 = add i64 %15594, 10552
  store i64 %15597, i64* %RSI.i1889, align 8
  %15598 = icmp ugt i64 %15595, -2049
  %15599 = zext i1 %15598 to i8
  store i8 %15599, i8* %18, align 1
  %15600 = trunc i64 %15597 to i32
  %15601 = and i32 %15600, 255
  %15602 = tail call i32 @llvm.ctpop.i32(i32 %15601)
  %15603 = trunc i32 %15602 to i8
  %15604 = and i8 %15603, 1
  %15605 = xor i8 %15604, 1
  store i8 %15605, i8* %19, align 1
  %15606 = xor i64 %15597, %15595
  %15607 = lshr i64 %15606, 4
  %15608 = trunc i64 %15607 to i8
  %15609 = and i8 %15608, 1
  store i8 %15609, i8* %20, align 1
  %15610 = icmp eq i64 %15597, 0
  %15611 = zext i1 %15610 to i8
  store i8 %15611, i8* %21, align 1
  %15612 = lshr i64 %15597, 63
  %15613 = trunc i64 %15612 to i8
  store i8 %15613, i8* %22, align 1
  %15614 = xor i64 %15612, %15596
  %15615 = add nuw nsw i64 %15614, %15612
  %15616 = icmp eq i64 %15615, 2
  %15617 = zext i1 %15616 to i8
  store i8 %15617, i8* %23, align 1
  %15618 = load i64, i64* %RBP.i, align 8
  %15619 = add i64 %15618, -632
  %15620 = add i64 %15502, 78
  store i64 %15620, i64* %3, align 8
  %15621 = inttoptr i64 %15619 to i32*
  %15622 = load i32, i32* %15621, align 4
  %15623 = sext i32 %15622 to i64
  %15624 = shl nsw i64 %15623, 9
  store i64 %15624, i64* %RDI.i2141, align 8
  %15625 = add i64 %15624, %15597
  store i64 %15625, i64* %RSI.i1889, align 8
  %15626 = icmp ult i64 %15625, %15597
  %15627 = icmp ult i64 %15625, %15624
  %15628 = or i1 %15626, %15627
  %15629 = zext i1 %15628 to i8
  store i8 %15629, i8* %18, align 1
  %15630 = trunc i64 %15625 to i32
  %15631 = and i32 %15630, 255
  %15632 = tail call i32 @llvm.ctpop.i32(i32 %15631)
  %15633 = trunc i32 %15632 to i8
  %15634 = and i8 %15633, 1
  %15635 = xor i8 %15634, 1
  store i8 %15635, i8* %19, align 1
  %15636 = xor i64 %15597, %15625
  %15637 = lshr i64 %15636, 4
  %15638 = trunc i64 %15637 to i8
  %15639 = and i8 %15638, 1
  store i8 %15639, i8* %20, align 1
  %15640 = icmp eq i64 %15625, 0
  %15641 = zext i1 %15640 to i8
  store i8 %15641, i8* %21, align 1
  %15642 = lshr i64 %15625, 63
  %15643 = trunc i64 %15642 to i8
  store i8 %15643, i8* %22, align 1
  %15644 = lshr i64 %15623, 54
  %15645 = and i64 %15644, 1
  %15646 = xor i64 %15642, %15612
  %15647 = xor i64 %15642, %15645
  %15648 = add nuw nsw i64 %15646, %15647
  %15649 = icmp eq i64 %15648, 2
  %15650 = zext i1 %15649 to i8
  store i8 %15650, i8* %23, align 1
  %15651 = add i64 %15618, -484
  %15652 = add i64 %15502, 92
  store i64 %15652, i64* %3, align 8
  %15653 = inttoptr i64 %15651 to i32*
  %15654 = load i32, i32* %15653, align 4
  %15655 = zext i32 %15654 to i64
  store i64 %15655, i64* %372, align 8
  %15656 = add i64 %15618, -44
  %15657 = add i64 %15502, 96
  store i64 %15657, i64* %3, align 8
  %15658 = inttoptr i64 %15656 to i32*
  %15659 = load i32, i32* %15658, align 4
  %15660 = add i32 %15659, %15654
  %15661 = zext i32 %15660 to i64
  store i64 %15661, i64* %372, align 8
  %15662 = sext i32 %15660 to i64
  %15663 = shl nsw i64 %15662, 5
  store i64 %15663, i64* %RDI.i2141, align 8
  %15664 = load i64, i64* %RSI.i1889, align 8
  %15665 = add i64 %15663, %15664
  store i64 %15665, i64* %RSI.i1889, align 8
  %15666 = icmp ult i64 %15665, %15664
  %15667 = icmp ult i64 %15665, %15663
  %15668 = or i1 %15666, %15667
  %15669 = zext i1 %15668 to i8
  store i8 %15669, i8* %18, align 1
  %15670 = trunc i64 %15665 to i32
  %15671 = and i32 %15670, 255
  %15672 = tail call i32 @llvm.ctpop.i32(i32 %15671)
  %15673 = trunc i32 %15672 to i8
  %15674 = and i8 %15673, 1
  %15675 = xor i8 %15674, 1
  store i8 %15675, i8* %19, align 1
  %15676 = xor i64 %15664, %15665
  %15677 = lshr i64 %15676, 4
  %15678 = trunc i64 %15677 to i8
  %15679 = and i8 %15678, 1
  store i8 %15679, i8* %20, align 1
  %15680 = icmp eq i64 %15665, 0
  %15681 = zext i1 %15680 to i8
  store i8 %15681, i8* %21, align 1
  %15682 = lshr i64 %15665, 63
  %15683 = trunc i64 %15682 to i8
  store i8 %15683, i8* %22, align 1
  %15684 = lshr i64 %15664, 63
  %15685 = lshr i64 %15662, 58
  %15686 = and i64 %15685, 1
  %15687 = xor i64 %15682, %15684
  %15688 = xor i64 %15682, %15686
  %15689 = add nuw nsw i64 %15687, %15688
  %15690 = icmp eq i64 %15689, 2
  %15691 = zext i1 %15690 to i8
  store i8 %15691, i8* %23, align 1
  %15692 = load i64, i64* %RBP.i, align 8
  %15693 = add i64 %15692, -488
  %15694 = add i64 %15502, 113
  store i64 %15694, i64* %3, align 8
  %15695 = inttoptr i64 %15693 to i32*
  %15696 = load i32, i32* %15695, align 4
  %15697 = zext i32 %15696 to i64
  store i64 %15697, i64* %372, align 8
  %15698 = add i64 %15692, -48
  %15699 = add i64 %15502, 117
  store i64 %15699, i64* %3, align 8
  %15700 = inttoptr i64 %15698 to i32*
  %15701 = load i32, i32* %15700, align 4
  %15702 = add i32 %15701, %15696
  %15703 = zext i32 %15702 to i64
  store i64 %15703, i64* %372, align 8
  %15704 = icmp ult i32 %15702, %15696
  %15705 = icmp ult i32 %15702, %15701
  %15706 = or i1 %15704, %15705
  %15707 = zext i1 %15706 to i8
  store i8 %15707, i8* %18, align 1
  %15708 = and i32 %15702, 255
  %15709 = tail call i32 @llvm.ctpop.i32(i32 %15708)
  %15710 = trunc i32 %15709 to i8
  %15711 = and i8 %15710, 1
  %15712 = xor i8 %15711, 1
  store i8 %15712, i8* %19, align 1
  %15713 = xor i32 %15701, %15696
  %15714 = xor i32 %15713, %15702
  %15715 = lshr i32 %15714, 4
  %15716 = trunc i32 %15715 to i8
  %15717 = and i8 %15716, 1
  store i8 %15717, i8* %20, align 1
  %15718 = icmp eq i32 %15702, 0
  %15719 = zext i1 %15718 to i8
  store i8 %15719, i8* %21, align 1
  %15720 = lshr i32 %15702, 31
  %15721 = trunc i32 %15720 to i8
  store i8 %15721, i8* %22, align 1
  %15722 = lshr i32 %15696, 31
  %15723 = lshr i32 %15701, 31
  %15724 = xor i32 %15720, %15722
  %15725 = xor i32 %15720, %15723
  %15726 = add nuw nsw i32 %15724, %15725
  %15727 = icmp eq i32 %15726, 2
  %15728 = zext i1 %15727 to i8
  store i8 %15728, i8* %23, align 1
  %15729 = sext i32 %15702 to i64
  store i64 %15729, i64* %RDI.i2141, align 8
  %15730 = shl nsw i64 %15729, 1
  %15731 = add i64 %15665, %15730
  %15732 = add i64 %15502, 125
  store i64 %15732, i64* %3, align 8
  %15733 = inttoptr i64 %15731 to i16*
  %15734 = load i16, i16* %15733, align 2
  %15735 = zext i16 %15734 to i64
  store i64 %15735, i64* %372, align 8
  %15736 = load i32, i32* %R9D.i6640, align 4
  %15737 = zext i16 %15734 to i32
  %15738 = sub i32 %15736, %15737
  %15739 = zext i32 %15738 to i64
  store i64 %15739, i64* %R9.i, align 8
  %15740 = icmp ult i32 %15736, %15737
  %15741 = zext i1 %15740 to i8
  store i8 %15741, i8* %18, align 1
  %15742 = and i32 %15738, 255
  %15743 = tail call i32 @llvm.ctpop.i32(i32 %15742)
  %15744 = trunc i32 %15743 to i8
  %15745 = and i8 %15744, 1
  %15746 = xor i8 %15745, 1
  store i8 %15746, i8* %19, align 1
  %15747 = xor i32 %15737, %15736
  %15748 = xor i32 %15747, %15738
  %15749 = lshr i32 %15748, 4
  %15750 = trunc i32 %15749 to i8
  %15751 = and i8 %15750, 1
  store i8 %15751, i8* %20, align 1
  %15752 = icmp eq i32 %15738, 0
  %15753 = zext i1 %15752 to i8
  store i8 %15753, i8* %21, align 1
  %15754 = lshr i32 %15738, 31
  %15755 = trunc i32 %15754 to i8
  store i8 %15755, i8* %22, align 1
  %15756 = lshr i32 %15736, 31
  %15757 = xor i32 %15754, %15756
  %15758 = add nuw nsw i32 %15757, %15756
  %15759 = icmp eq i32 %15758, 2
  %15760 = zext i1 %15759 to i8
  store i8 %15760, i8* %23, align 1
  %15761 = add i64 %15692, -604
  %15762 = add i64 %15502, 135
  store i64 %15762, i64* %3, align 8
  %15763 = inttoptr i64 %15761 to i32*
  store i32 %15738, i32* %15763, align 4
  %15764 = load i64, i64* %RBP.i, align 8
  %15765 = add i64 %15764, -604
  %15766 = load i64, i64* %3, align 8
  %15767 = add i64 %15766, 7
  store i64 %15767, i64* %3, align 8
  %15768 = inttoptr i64 %15765 to i32*
  %15769 = load i32, i32* %15768, align 4
  %15770 = zext i32 %15769 to i64
  store i64 %15770, i64* %R9.i, align 8
  %15771 = add i64 %15764, -612
  %15772 = add i64 %15766, 14
  store i64 %15772, i64* %3, align 8
  %15773 = inttoptr i64 %15771 to i32*
  %15774 = load i32, i32* %15773, align 4
  %15775 = sub i32 %15769, %15774
  %15776 = zext i32 %15775 to i64
  store i64 %15776, i64* %R9.i, align 8
  %15777 = icmp ult i32 %15769, %15774
  %15778 = zext i1 %15777 to i8
  store i8 %15778, i8* %18, align 1
  %15779 = and i32 %15775, 255
  %15780 = tail call i32 @llvm.ctpop.i32(i32 %15779)
  %15781 = trunc i32 %15780 to i8
  %15782 = and i8 %15781, 1
  %15783 = xor i8 %15782, 1
  store i8 %15783, i8* %19, align 1
  %15784 = xor i32 %15774, %15769
  %15785 = xor i32 %15784, %15775
  %15786 = lshr i32 %15785, 4
  %15787 = trunc i32 %15786 to i8
  %15788 = and i8 %15787, 1
  store i8 %15788, i8* %20, align 1
  %15789 = icmp eq i32 %15775, 0
  %15790 = zext i1 %15789 to i8
  store i8 %15790, i8* %21, align 1
  %15791 = lshr i32 %15775, 31
  %15792 = trunc i32 %15791 to i8
  store i8 %15792, i8* %22, align 1
  %15793 = lshr i32 %15769, 31
  %15794 = lshr i32 %15774, 31
  %15795 = xor i32 %15794, %15793
  %15796 = xor i32 %15791, %15793
  %15797 = add nuw nsw i32 %15796, %15795
  %15798 = icmp eq i32 %15797, 2
  %15799 = zext i1 %15798 to i8
  store i8 %15799, i8* %23, align 1
  %15800 = add i64 %15764, -44
  %15801 = add i64 %15766, 18
  store i64 %15801, i64* %3, align 8
  %15802 = inttoptr i64 %15800 to i32*
  %15803 = load i32, i32* %15802, align 4
  %15804 = sext i32 %15803 to i64
  %15805 = shl nsw i64 %15804, 6
  store i64 %15805, i64* %RSI.i1889, align 8
  %15806 = load i64, i64* %RDX.i1805, align 8
  %15807 = add i64 %15805, %15806
  store i64 %15807, i64* %RDI.i2141, align 8
  %15808 = icmp ult i64 %15807, %15806
  %15809 = icmp ult i64 %15807, %15805
  %15810 = or i1 %15808, %15809
  %15811 = zext i1 %15810 to i8
  store i8 %15811, i8* %18, align 1
  %15812 = trunc i64 %15807 to i32
  %15813 = and i32 %15812, 255
  %15814 = tail call i32 @llvm.ctpop.i32(i32 %15813)
  %15815 = trunc i32 %15814 to i8
  %15816 = and i8 %15815, 1
  %15817 = xor i8 %15816, 1
  store i8 %15817, i8* %19, align 1
  %15818 = xor i64 %15806, %15807
  %15819 = lshr i64 %15818, 4
  %15820 = trunc i64 %15819 to i8
  %15821 = and i8 %15820, 1
  store i8 %15821, i8* %20, align 1
  %15822 = icmp eq i64 %15807, 0
  %15823 = zext i1 %15822 to i8
  store i8 %15823, i8* %21, align 1
  %15824 = lshr i64 %15807, 63
  %15825 = trunc i64 %15824 to i8
  store i8 %15825, i8* %22, align 1
  %15826 = lshr i64 %15806, 63
  %15827 = lshr i64 %15804, 57
  %15828 = and i64 %15827, 1
  %15829 = xor i64 %15824, %15826
  %15830 = xor i64 %15824, %15828
  %15831 = add nuw nsw i64 %15829, %15830
  %15832 = icmp eq i64 %15831, 2
  %15833 = zext i1 %15832 to i8
  store i8 %15833, i8* %23, align 1
  %15834 = load i64, i64* %RBP.i, align 8
  %15835 = add i64 %15834, -48
  %15836 = add i64 %15766, 32
  store i64 %15836, i64* %3, align 8
  %15837 = inttoptr i64 %15835 to i32*
  %15838 = load i32, i32* %15837, align 4
  %15839 = sext i32 %15838 to i64
  store i64 %15839, i64* %RSI.i1889, align 8
  %15840 = shl nsw i64 %15839, 2
  %15841 = add i64 %15840, %15807
  %15842 = load i32, i32* %R9D.i6640, align 4
  %15843 = add i64 %15766, 36
  store i64 %15843, i64* %3, align 8
  %15844 = inttoptr i64 %15841 to i32*
  store i32 %15842, i32* %15844, align 4
  %15845 = load i64, i64* %RBP.i, align 8
  %15846 = add i64 %15845, -612
  %15847 = load i64, i64* %3, align 8
  %15848 = add i64 %15847, 7
  store i64 %15848, i64* %3, align 8
  %15849 = inttoptr i64 %15846 to i32*
  %15850 = load i32, i32* %15849, align 4
  %15851 = zext i32 %15850 to i64
  store i64 %15851, i64* %R9.i, align 8
  %15852 = add i64 %15845, -44
  %15853 = add i64 %15847, 11
  store i64 %15853, i64* %3, align 8
  %15854 = inttoptr i64 %15852 to i32*
  %15855 = load i32, i32* %15854, align 4
  %15856 = sext i32 %15855 to i64
  %15857 = shl nsw i64 %15856, 6
  store i64 %15857, i64* %RSI.i1889, align 8
  %15858 = load i64, i64* %RDX.i1805, align 8
  %15859 = add i64 %15857, %15858
  store i64 %15859, i64* %RDX.i1805, align 8
  %15860 = icmp ult i64 %15859, %15858
  %15861 = icmp ult i64 %15859, %15857
  %15862 = or i1 %15860, %15861
  %15863 = zext i1 %15862 to i8
  store i8 %15863, i8* %18, align 1
  %15864 = trunc i64 %15859 to i32
  %15865 = and i32 %15864, 255
  %15866 = tail call i32 @llvm.ctpop.i32(i32 %15865)
  %15867 = trunc i32 %15866 to i8
  %15868 = and i8 %15867, 1
  %15869 = xor i8 %15868, 1
  store i8 %15869, i8* %19, align 1
  %15870 = xor i64 %15858, %15859
  %15871 = lshr i64 %15870, 4
  %15872 = trunc i64 %15871 to i8
  %15873 = and i8 %15872, 1
  store i8 %15873, i8* %20, align 1
  %15874 = icmp eq i64 %15859, 0
  %15875 = zext i1 %15874 to i8
  store i8 %15875, i8* %21, align 1
  %15876 = lshr i64 %15859, 63
  %15877 = trunc i64 %15876 to i8
  store i8 %15877, i8* %22, align 1
  %15878 = lshr i64 %15858, 63
  %15879 = lshr i64 %15856, 57
  %15880 = and i64 %15879, 1
  %15881 = xor i64 %15876, %15878
  %15882 = xor i64 %15876, %15880
  %15883 = add nuw nsw i64 %15881, %15882
  %15884 = icmp eq i64 %15883, 2
  %15885 = zext i1 %15884 to i8
  store i8 %15885, i8* %23, align 1
  %15886 = add i64 %15845, -48
  %15887 = add i64 %15847, 22
  store i64 %15887, i64* %3, align 8
  %15888 = inttoptr i64 %15886 to i32*
  %15889 = load i32, i32* %15888, align 4
  %15890 = sext i32 %15889 to i64
  store i64 %15890, i64* %RSI.i1889, align 8
  %15891 = shl nsw i64 %15890, 2
  %15892 = add i64 %15891, %15859
  %15893 = add i64 %15847, 26
  store i64 %15893, i64* %3, align 8
  %15894 = inttoptr i64 %15892 to i32*
  %15895 = load i32, i32* %15894, align 4
  %15896 = zext i32 %15895 to i64
  %15897 = shl nuw i64 %15896, 32
  %15898 = ashr i64 %15897, 33
  %15899 = and i64 %15898, 4294967295
  store i64 %15899, i64* %372, align 8
  %15900 = load i32, i32* %R9D.i6640, align 4
  %15901 = trunc i64 %15898 to i32
  %15902 = add i32 %15901, %15900
  %15903 = zext i32 %15902 to i64
  store i64 %15903, i64* %R9.i, align 8
  %15904 = icmp ult i32 %15902, %15900
  %15905 = icmp ult i32 %15902, %15901
  %15906 = or i1 %15904, %15905
  %15907 = zext i1 %15906 to i8
  store i8 %15907, i8* %18, align 1
  %15908 = and i32 %15902, 255
  %15909 = tail call i32 @llvm.ctpop.i32(i32 %15908)
  %15910 = trunc i32 %15909 to i8
  %15911 = and i8 %15910, 1
  %15912 = xor i8 %15911, 1
  store i8 %15912, i8* %19, align 1
  %15913 = xor i32 %15901, %15900
  %15914 = xor i32 %15913, %15902
  %15915 = lshr i32 %15914, 4
  %15916 = trunc i32 %15915 to i8
  %15917 = and i8 %15916, 1
  store i8 %15917, i8* %20, align 1
  %15918 = icmp eq i32 %15902, 0
  %15919 = zext i1 %15918 to i8
  store i8 %15919, i8* %21, align 1
  %15920 = lshr i32 %15902, 31
  %15921 = trunc i32 %15920 to i8
  store i8 %15921, i8* %22, align 1
  %15922 = lshr i32 %15900, 31
  %15923 = lshr i64 %15898, 31
  %15924 = trunc i64 %15923 to i32
  %15925 = and i32 %15924, 1
  %15926 = xor i32 %15920, %15922
  %15927 = xor i32 %15920, %15925
  %15928 = add nuw nsw i32 %15926, %15927
  %15929 = icmp eq i32 %15928, 2
  %15930 = zext i1 %15929 to i8
  store i8 %15930, i8* %23, align 1
  %15931 = load i64, i64* %RBP.i, align 8
  %15932 = add i64 %15931, -624
  %15933 = add i64 %15847, 39
  store i64 %15933, i64* %3, align 8
  %15934 = inttoptr i64 %15932 to i32*
  store i32 %15902, i32* %15934, align 4
  %15935 = load i64, i64* %RBP.i, align 8
  %15936 = add i64 %15935, -608
  %15937 = load i64, i64* %3, align 8
  %15938 = add i64 %15937, 7
  store i64 %15938, i64* %3, align 8
  %15939 = inttoptr i64 %15936 to i32*
  %15940 = load i32, i32* %15939, align 4
  %15941 = zext i32 %15940 to i64
  store i64 %15941, i64* %R9.i, align 8
  %15942 = add i64 %15935, -624
  %15943 = add i64 %15937, 14
  store i64 %15943, i64* %3, align 8
  %15944 = inttoptr i64 %15942 to i32*
  %15945 = load i32, i32* %15944, align 4
  %15946 = sub i32 %15940, %15945
  %15947 = zext i32 %15946 to i64
  store i64 %15947, i64* %R9.i, align 8
  %15948 = icmp ult i32 %15940, %15945
  %15949 = zext i1 %15948 to i8
  store i8 %15949, i8* %18, align 1
  %15950 = and i32 %15946, 255
  %15951 = tail call i32 @llvm.ctpop.i32(i32 %15950)
  %15952 = trunc i32 %15951 to i8
  %15953 = and i8 %15952, 1
  %15954 = xor i8 %15953, 1
  store i8 %15954, i8* %19, align 1
  %15955 = xor i32 %15945, %15940
  %15956 = xor i32 %15955, %15946
  %15957 = lshr i32 %15956, 4
  %15958 = trunc i32 %15957 to i8
  %15959 = and i8 %15958, 1
  store i8 %15959, i8* %20, align 1
  %15960 = icmp eq i32 %15946, 0
  %15961 = zext i1 %15960 to i8
  store i8 %15961, i8* %21, align 1
  %15962 = lshr i32 %15946, 31
  %15963 = trunc i32 %15962 to i8
  store i8 %15963, i8* %22, align 1
  %15964 = lshr i32 %15940, 31
  %15965 = lshr i32 %15945, 31
  %15966 = xor i32 %15965, %15964
  %15967 = xor i32 %15962, %15964
  %15968 = add nuw nsw i32 %15967, %15966
  %15969 = icmp eq i32 %15968, 2
  %15970 = zext i1 %15969 to i8
  store i8 %15970, i8* %23, align 1
  %15971 = add i64 %15935, -44
  %15972 = add i64 %15937, 18
  store i64 %15972, i64* %3, align 8
  %15973 = inttoptr i64 %15971 to i32*
  %15974 = load i32, i32* %15973, align 4
  %15975 = sext i32 %15974 to i64
  %15976 = shl nsw i64 %15975, 6
  store i64 %15976, i64* %RDX.i1805, align 8
  %15977 = load i64, i64* %RCX.i1692, align 8
  %15978 = add i64 %15976, %15977
  store i64 %15978, i64* %RSI.i1889, align 8
  %15979 = icmp ult i64 %15978, %15977
  %15980 = icmp ult i64 %15978, %15976
  %15981 = or i1 %15979, %15980
  %15982 = zext i1 %15981 to i8
  store i8 %15982, i8* %18, align 1
  %15983 = trunc i64 %15978 to i32
  %15984 = and i32 %15983, 255
  %15985 = tail call i32 @llvm.ctpop.i32(i32 %15984)
  %15986 = trunc i32 %15985 to i8
  %15987 = and i8 %15986, 1
  %15988 = xor i8 %15987, 1
  store i8 %15988, i8* %19, align 1
  %15989 = xor i64 %15977, %15978
  %15990 = lshr i64 %15989, 4
  %15991 = trunc i64 %15990 to i8
  %15992 = and i8 %15991, 1
  store i8 %15992, i8* %20, align 1
  %15993 = icmp eq i64 %15978, 0
  %15994 = zext i1 %15993 to i8
  store i8 %15994, i8* %21, align 1
  %15995 = lshr i64 %15978, 63
  %15996 = trunc i64 %15995 to i8
  store i8 %15996, i8* %22, align 1
  %15997 = lshr i64 %15977, 63
  %15998 = lshr i64 %15975, 57
  %15999 = and i64 %15998, 1
  %16000 = xor i64 %15995, %15997
  %16001 = xor i64 %15995, %15999
  %16002 = add nuw nsw i64 %16000, %16001
  %16003 = icmp eq i64 %16002, 2
  %16004 = zext i1 %16003 to i8
  store i8 %16004, i8* %23, align 1
  %16005 = load i64, i64* %RBP.i, align 8
  %16006 = add i64 %16005, -48
  %16007 = add i64 %15937, 32
  store i64 %16007, i64* %3, align 8
  %16008 = inttoptr i64 %16006 to i32*
  %16009 = load i32, i32* %16008, align 4
  %16010 = sext i32 %16009 to i64
  store i64 %16010, i64* %RDX.i1805, align 8
  %16011 = shl nsw i64 %16010, 2
  %16012 = add i64 %16011, %15978
  %16013 = load i32, i32* %R9D.i6640, align 4
  %16014 = add i64 %15937, 36
  store i64 %16014, i64* %3, align 8
  %16015 = inttoptr i64 %16012 to i32*
  store i32 %16013, i32* %16015, align 4
  %16016 = load i64, i64* %RBP.i, align 8
  %16017 = add i64 %16016, -624
  %16018 = load i64, i64* %3, align 8
  %16019 = add i64 %16018, 7
  store i64 %16019, i64* %3, align 8
  %16020 = inttoptr i64 %16017 to i32*
  %16021 = load i32, i32* %16020, align 4
  %16022 = zext i32 %16021 to i64
  store i64 %16022, i64* %R9.i, align 8
  %16023 = add i64 %16016, -44
  %16024 = add i64 %16018, 11
  store i64 %16024, i64* %3, align 8
  %16025 = inttoptr i64 %16023 to i32*
  %16026 = load i32, i32* %16025, align 4
  %16027 = sext i32 %16026 to i64
  %16028 = shl nsw i64 %16027, 6
  store i64 %16028, i64* %RDX.i1805, align 8
  %16029 = load i64, i64* %RCX.i1692, align 8
  %16030 = add i64 %16028, %16029
  store i64 %16030, i64* %RCX.i1692, align 8
  %16031 = icmp ult i64 %16030, %16029
  %16032 = icmp ult i64 %16030, %16028
  %16033 = or i1 %16031, %16032
  %16034 = zext i1 %16033 to i8
  store i8 %16034, i8* %18, align 1
  %16035 = trunc i64 %16030 to i32
  %16036 = and i32 %16035, 255
  %16037 = tail call i32 @llvm.ctpop.i32(i32 %16036)
  %16038 = trunc i32 %16037 to i8
  %16039 = and i8 %16038, 1
  %16040 = xor i8 %16039, 1
  store i8 %16040, i8* %19, align 1
  %16041 = xor i64 %16029, %16030
  %16042 = lshr i64 %16041, 4
  %16043 = trunc i64 %16042 to i8
  %16044 = and i8 %16043, 1
  store i8 %16044, i8* %20, align 1
  %16045 = icmp eq i64 %16030, 0
  %16046 = zext i1 %16045 to i8
  store i8 %16046, i8* %21, align 1
  %16047 = lshr i64 %16030, 63
  %16048 = trunc i64 %16047 to i8
  store i8 %16048, i8* %22, align 1
  %16049 = lshr i64 %16029, 63
  %16050 = lshr i64 %16027, 57
  %16051 = and i64 %16050, 1
  %16052 = xor i64 %16047, %16049
  %16053 = xor i64 %16047, %16051
  %16054 = add nuw nsw i64 %16052, %16053
  %16055 = icmp eq i64 %16054, 2
  %16056 = zext i1 %16055 to i8
  store i8 %16056, i8* %23, align 1
  %16057 = add i64 %16016, -48
  %16058 = add i64 %16018, 22
  store i64 %16058, i64* %3, align 8
  %16059 = inttoptr i64 %16057 to i32*
  %16060 = load i32, i32* %16059, align 4
  %16061 = sext i32 %16060 to i64
  store i64 %16061, i64* %RDX.i1805, align 8
  %16062 = shl nsw i64 %16061, 2
  %16063 = add i64 %16062, %16030
  %16064 = add i64 %16018, 26
  store i64 %16064, i64* %3, align 8
  %16065 = inttoptr i64 %16063 to i32*
  %16066 = load i32, i32* %16065, align 4
  %16067 = zext i32 %16066 to i64
  %16068 = shl nuw i64 %16067, 32
  %16069 = ashr i64 %16068, 33
  %16070 = and i64 %16069, 4294967295
  store i64 %16070, i64* %372, align 8
  %16071 = load i32, i32* %R9D.i6640, align 4
  %16072 = trunc i64 %16069 to i32
  %16073 = add i32 %16072, %16071
  %16074 = zext i32 %16073 to i64
  store i64 %16074, i64* %R9.i, align 8
  %16075 = icmp ult i32 %16073, %16071
  %16076 = icmp ult i32 %16073, %16072
  %16077 = or i1 %16075, %16076
  %16078 = zext i1 %16077 to i8
  store i8 %16078, i8* %18, align 1
  %16079 = and i32 %16073, 255
  %16080 = tail call i32 @llvm.ctpop.i32(i32 %16079)
  %16081 = trunc i32 %16080 to i8
  %16082 = and i8 %16081, 1
  %16083 = xor i8 %16082, 1
  store i8 %16083, i8* %19, align 1
  %16084 = xor i32 %16072, %16071
  %16085 = xor i32 %16084, %16073
  %16086 = lshr i32 %16085, 4
  %16087 = trunc i32 %16086 to i8
  %16088 = and i8 %16087, 1
  store i8 %16088, i8* %20, align 1
  %16089 = icmp eq i32 %16073, 0
  %16090 = zext i1 %16089 to i8
  store i8 %16090, i8* %21, align 1
  %16091 = lshr i32 %16073, 31
  %16092 = trunc i32 %16091 to i8
  store i8 %16092, i8* %22, align 1
  %16093 = lshr i32 %16071, 31
  %16094 = lshr i64 %16069, 31
  %16095 = trunc i64 %16094 to i32
  %16096 = and i32 %16095, 1
  %16097 = xor i32 %16091, %16093
  %16098 = xor i32 %16091, %16096
  %16099 = add nuw nsw i32 %16097, %16098
  %16100 = icmp eq i32 %16099, 2
  %16101 = zext i1 %16100 to i8
  store i8 %16101, i8* %23, align 1
  %16102 = load i64, i64* %RBP.i, align 8
  %16103 = add i64 %16102, -44
  %16104 = add i64 %16018, 36
  store i64 %16104, i64* %3, align 8
  %16105 = inttoptr i64 %16103 to i32*
  %16106 = load i32, i32* %16105, align 4
  %16107 = sext i32 %16106 to i64
  %16108 = shl nsw i64 %16107, 6
  store i64 %16108, i64* %RCX.i1692, align 8
  %16109 = load i64, i64* %RAX.i1763, align 8
  %16110 = add i64 %16108, %16109
  store i64 %16110, i64* %RAX.i1763, align 8
  %16111 = icmp ult i64 %16110, %16109
  %16112 = icmp ult i64 %16110, %16108
  %16113 = or i1 %16111, %16112
  %16114 = zext i1 %16113 to i8
  store i8 %16114, i8* %18, align 1
  %16115 = trunc i64 %16110 to i32
  %16116 = and i32 %16115, 255
  %16117 = tail call i32 @llvm.ctpop.i32(i32 %16116)
  %16118 = trunc i32 %16117 to i8
  %16119 = and i8 %16118, 1
  %16120 = xor i8 %16119, 1
  store i8 %16120, i8* %19, align 1
  %16121 = xor i64 %16109, %16110
  %16122 = lshr i64 %16121, 4
  %16123 = trunc i64 %16122 to i8
  %16124 = and i8 %16123, 1
  store i8 %16124, i8* %20, align 1
  %16125 = icmp eq i64 %16110, 0
  %16126 = zext i1 %16125 to i8
  store i8 %16126, i8* %21, align 1
  %16127 = lshr i64 %16110, 63
  %16128 = trunc i64 %16127 to i8
  store i8 %16128, i8* %22, align 1
  %16129 = lshr i64 %16109, 63
  %16130 = lshr i64 %16107, 57
  %16131 = and i64 %16130, 1
  %16132 = xor i64 %16127, %16129
  %16133 = xor i64 %16127, %16131
  %16134 = add nuw nsw i64 %16132, %16133
  %16135 = icmp eq i64 %16134, 2
  %16136 = zext i1 %16135 to i8
  store i8 %16136, i8* %23, align 1
  %16137 = add i64 %16102, -48
  %16138 = add i64 %16018, 47
  store i64 %16138, i64* %3, align 8
  %16139 = inttoptr i64 %16137 to i32*
  %16140 = load i32, i32* %16139, align 4
  %16141 = sext i32 %16140 to i64
  store i64 %16141, i64* %RCX.i1692, align 8
  %16142 = shl nsw i64 %16141, 2
  %16143 = add i64 %16142, %16110
  %16144 = load i32, i32* %R9D.i6640, align 4
  %16145 = add i64 %16018, 51
  store i64 %16145, i64* %3, align 8
  %16146 = inttoptr i64 %16143 to i32*
  store i32 %16144, i32* %16146, align 4
  %16147 = load i64, i64* %RBP.i, align 8
  %16148 = add i64 %16147, -44
  %16149 = load i64, i64* %3, align 8
  %16150 = add i64 %16149, 3
  store i64 %16150, i64* %3, align 8
  %16151 = inttoptr i64 %16148 to i32*
  %16152 = load i32, i32* %16151, align 4
  %16153 = add i32 %16152, 1
  %16154 = zext i32 %16153 to i64
  store i64 %16154, i64* %RAX.i1763, align 8
  %16155 = icmp eq i32 %16152, -1
  %16156 = icmp eq i32 %16153, 0
  %16157 = or i1 %16155, %16156
  %16158 = zext i1 %16157 to i8
  store i8 %16158, i8* %18, align 1
  %16159 = and i32 %16153, 255
  %16160 = tail call i32 @llvm.ctpop.i32(i32 %16159)
  %16161 = trunc i32 %16160 to i8
  %16162 = and i8 %16161, 1
  %16163 = xor i8 %16162, 1
  store i8 %16163, i8* %19, align 1
  %16164 = xor i32 %16153, %16152
  %16165 = lshr i32 %16164, 4
  %16166 = trunc i32 %16165 to i8
  %16167 = and i8 %16166, 1
  store i8 %16167, i8* %20, align 1
  %16168 = zext i1 %16156 to i8
  store i8 %16168, i8* %21, align 1
  %16169 = lshr i32 %16153, 31
  %16170 = trunc i32 %16169 to i8
  store i8 %16170, i8* %22, align 1
  %16171 = lshr i32 %16152, 31
  %16172 = xor i32 %16169, %16171
  %16173 = add nuw nsw i32 %16172, %16169
  %16174 = icmp eq i32 %16173, 2
  %16175 = zext i1 %16174 to i8
  store i8 %16175, i8* %23, align 1
  %16176 = add i64 %16149, 9
  store i64 %16176, i64* %3, align 8
  store i32 %16153, i32* %16151, align 4
  %16177 = load i64, i64* %3, align 8
  %16178 = add i64 %16177, -677
  store i64 %16178, i64* %3, align 8
  br label %block_.L_4a621c

block_.L_4a64c6:                                  ; preds = %block_.L_4a621c
  %16179 = add i64 %14785, -48
  %16180 = add i64 %14813, 8
  store i64 %16180, i64* %3, align 8
  %16181 = inttoptr i64 %16179 to i32*
  %16182 = load i32, i32* %16181, align 4
  %16183 = add i32 %16182, 1
  %16184 = zext i32 %16183 to i64
  store i64 %16184, i64* %RAX.i1763, align 8
  %16185 = icmp eq i32 %16182, -1
  %16186 = icmp eq i32 %16183, 0
  %16187 = or i1 %16185, %16186
  %16188 = zext i1 %16187 to i8
  store i8 %16188, i8* %18, align 1
  %16189 = and i32 %16183, 255
  %16190 = tail call i32 @llvm.ctpop.i32(i32 %16189)
  %16191 = trunc i32 %16190 to i8
  %16192 = and i8 %16191, 1
  %16193 = xor i8 %16192, 1
  store i8 %16193, i8* %19, align 1
  %16194 = xor i32 %16183, %16182
  %16195 = lshr i32 %16194, 4
  %16196 = trunc i32 %16195 to i8
  %16197 = and i8 %16196, 1
  store i8 %16197, i8* %20, align 1
  %16198 = zext i1 %16186 to i8
  store i8 %16198, i8* %21, align 1
  %16199 = lshr i32 %16183, 31
  %16200 = trunc i32 %16199 to i8
  store i8 %16200, i8* %22, align 1
  %16201 = lshr i32 %16182, 31
  %16202 = xor i32 %16199, %16201
  %16203 = add nuw nsw i32 %16202, %16199
  %16204 = icmp eq i32 %16203, 2
  %16205 = zext i1 %16204 to i8
  store i8 %16205, i8* %23, align 1
  %16206 = add i64 %14813, 14
  store i64 %16206, i64* %3, align 8
  store i32 %16183, i32* %16181, align 4
  %16207 = load i64, i64* %3, align 8
  %16208 = add i64 %16207, -713
  store i64 %16208, i64* %3, align 8
  br label %block_.L_4a620b

block_.L_4a64d9:                                  ; preds = %block_.L_4a620b
  %16209 = add i64 %14780, 7
  store i64 %16209, i64* %3, align 8
  store i32 0, i32* %14755, align 4
  %.pre540 = load i64, i64* %3, align 8
  br label %block_.L_4a64e0

block_.L_4a64e0:                                  ; preds = %block_.L_4a6545, %block_.L_4a64d9
  %16210 = phi i64 [ %16442, %block_.L_4a6545 ], [ %.pre540, %block_.L_4a64d9 ]
  %16211 = load i64, i64* %RBP.i, align 8
  %16212 = add i64 %16211, -48
  %16213 = add i64 %16210, 4
  store i64 %16213, i64* %3, align 8
  %16214 = inttoptr i64 %16212 to i32*
  %16215 = load i32, i32* %16214, align 4
  %16216 = add i32 %16215, -8
  %16217 = icmp ult i32 %16215, 8
  %16218 = zext i1 %16217 to i8
  store i8 %16218, i8* %18, align 1
  %16219 = and i32 %16216, 255
  %16220 = tail call i32 @llvm.ctpop.i32(i32 %16219)
  %16221 = trunc i32 %16220 to i8
  %16222 = and i8 %16221, 1
  %16223 = xor i8 %16222, 1
  store i8 %16223, i8* %19, align 1
  %16224 = xor i32 %16216, %16215
  %16225 = lshr i32 %16224, 4
  %16226 = trunc i32 %16225 to i8
  %16227 = and i8 %16226, 1
  store i8 %16227, i8* %20, align 1
  %16228 = icmp eq i32 %16216, 0
  %16229 = zext i1 %16228 to i8
  store i8 %16229, i8* %21, align 1
  %16230 = lshr i32 %16216, 31
  %16231 = trunc i32 %16230 to i8
  store i8 %16231, i8* %22, align 1
  %16232 = lshr i32 %16215, 31
  %16233 = xor i32 %16230, %16232
  %16234 = add nuw nsw i32 %16233, %16232
  %16235 = icmp eq i32 %16234, 2
  %16236 = zext i1 %16235 to i8
  store i8 %16236, i8* %23, align 1
  %16237 = icmp ne i8 %16231, 0
  %16238 = xor i1 %16237, %16235
  %.v824 = select i1 %16238, i64 10, i64 120
  %16239 = add i64 %16210, %.v824
  store i64 %16239, i64* %3, align 8
  br i1 %16238, label %block_4a64ea, label %block_.L_4a6558

block_4a64ea:                                     ; preds = %block_.L_4a64e0
  %16240 = add i64 %16211, -44
  %16241 = add i64 %16239, 7
  store i64 %16241, i64* %3, align 8
  %16242 = inttoptr i64 %16240 to i32*
  store i32 0, i32* %16242, align 4
  %.pre625 = load i64, i64* %3, align 8
  br label %block_.L_4a64f1

block_.L_4a64f1:                                  ; preds = %block_4a64fb, %block_4a64ea
  %16243 = phi i64 [ %16412, %block_4a64fb ], [ %.pre625, %block_4a64ea ]
  %16244 = load i64, i64* %RBP.i, align 8
  %16245 = add i64 %16244, -44
  %16246 = add i64 %16243, 4
  store i64 %16246, i64* %3, align 8
  %16247 = inttoptr i64 %16245 to i32*
  %16248 = load i32, i32* %16247, align 4
  %16249 = add i32 %16248, -8
  %16250 = icmp ult i32 %16248, 8
  %16251 = zext i1 %16250 to i8
  store i8 %16251, i8* %18, align 1
  %16252 = and i32 %16249, 255
  %16253 = tail call i32 @llvm.ctpop.i32(i32 %16252)
  %16254 = trunc i32 %16253 to i8
  %16255 = and i8 %16254, 1
  %16256 = xor i8 %16255, 1
  store i8 %16256, i8* %19, align 1
  %16257 = xor i32 %16249, %16248
  %16258 = lshr i32 %16257, 4
  %16259 = trunc i32 %16258 to i8
  %16260 = and i8 %16259, 1
  store i8 %16260, i8* %20, align 1
  %16261 = icmp eq i32 %16249, 0
  %16262 = zext i1 %16261 to i8
  store i8 %16262, i8* %21, align 1
  %16263 = lshr i32 %16249, 31
  %16264 = trunc i32 %16263 to i8
  store i8 %16264, i8* %22, align 1
  %16265 = lshr i32 %16248, 31
  %16266 = xor i32 %16263, %16265
  %16267 = add nuw nsw i32 %16266, %16265
  %16268 = icmp eq i32 %16267, 2
  %16269 = zext i1 %16268 to i8
  store i8 %16269, i8* %23, align 1
  %16270 = icmp ne i8 %16264, 0
  %16271 = xor i1 %16270, %16268
  %.v772 = select i1 %16271, i64 10, i64 84
  %16272 = add i64 %16243, %.v772
  store i64 %16272, i64* %3, align 8
  br i1 %16271, label %block_4a64fb, label %block_.L_4a6545

block_4a64fb:                                     ; preds = %block_.L_4a64f1
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX.i1763, align 8
  %16273 = add i64 %16272, 14
  store i64 %16273, i64* %3, align 8
  %16274 = load i32, i32* %16247, align 4
  %16275 = sext i32 %16274 to i64
  %16276 = shl nsw i64 %16275, 6
  store i64 %16276, i64* %RCX.i1692, align 8
  %16277 = add i64 %16276, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  store i64 %16277, i64* %RAX.i1763, align 8
  %16278 = icmp ult i64 %16277, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  %16279 = icmp ult i64 %16277, %16276
  %16280 = or i1 %16278, %16279
  %16281 = zext i1 %16280 to i8
  store i8 %16281, i8* %18, align 1
  %16282 = trunc i64 %16277 to i32
  %16283 = and i32 %16282, 248
  %16284 = tail call i32 @llvm.ctpop.i32(i32 %16283)
  %16285 = trunc i32 %16284 to i8
  %16286 = and i8 %16285, 1
  %16287 = xor i8 %16286, 1
  store i8 %16287, i8* %19, align 1
  %16288 = xor i64 %16277, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  %16289 = lshr i64 %16288, 4
  %16290 = trunc i64 %16289 to i8
  %16291 = and i8 %16290, 1
  store i8 %16291, i8* %20, align 1
  %16292 = icmp eq i64 %16277, 0
  %16293 = zext i1 %16292 to i8
  store i8 %16293, i8* %21, align 1
  %16294 = lshr i64 %16277, 63
  %16295 = trunc i64 %16294 to i8
  store i8 %16295, i8* %22, align 1
  %16296 = lshr i64 %16275, 57
  %16297 = and i64 %16296, 1
  %16298 = xor i64 %16294, lshr (i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64 63)
  %16299 = xor i64 %16294, %16297
  %16300 = add nuw nsw i64 %16298, %16299
  %16301 = icmp eq i64 %16300, 2
  %16302 = zext i1 %16301 to i8
  store i8 %16302, i8* %23, align 1
  %16303 = add i64 %16244, -48
  %16304 = add i64 %16272, 25
  store i64 %16304, i64* %3, align 8
  %16305 = inttoptr i64 %16303 to i32*
  %16306 = load i32, i32* %16305, align 4
  %16307 = sext i32 %16306 to i64
  store i64 %16307, i64* %RCX.i1692, align 8
  %16308 = shl nsw i64 %16307, 2
  %16309 = add i64 %16308, %16277
  %16310 = add i64 %16272, 28
  store i64 %16310, i64* %3, align 8
  %16311 = inttoptr i64 %16309 to i32*
  %16312 = load i32, i32* %16311, align 4
  %16313 = zext i32 %16312 to i64
  store i64 %16313, i64* %RDX.i1805, align 8
  %16314 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %16315 = add i64 %16314, 13112
  store i64 %16315, i64* %RAX.i1763, align 8
  %16316 = icmp ugt i64 %16314, -13113
  %16317 = zext i1 %16316 to i8
  store i8 %16317, i8* %18, align 1
  %16318 = trunc i64 %16315 to i32
  %16319 = and i32 %16318, 255
  %16320 = tail call i32 @llvm.ctpop.i32(i32 %16319)
  %16321 = trunc i32 %16320 to i8
  %16322 = and i8 %16321, 1
  %16323 = xor i8 %16322, 1
  store i8 %16323, i8* %19, align 1
  %16324 = xor i64 %16314, 16
  %16325 = xor i64 %16324, %16315
  %16326 = lshr i64 %16325, 4
  %16327 = trunc i64 %16326 to i8
  %16328 = and i8 %16327, 1
  store i8 %16328, i8* %20, align 1
  %16329 = icmp eq i64 %16315, 0
  %16330 = zext i1 %16329 to i8
  store i8 %16330, i8* %21, align 1
  %16331 = lshr i64 %16315, 63
  %16332 = trunc i64 %16331 to i8
  store i8 %16332, i8* %22, align 1
  %16333 = lshr i64 %16314, 63
  %16334 = xor i64 %16331, %16333
  %16335 = add nuw nsw i64 %16334, %16331
  %16336 = icmp eq i64 %16335, 2
  %16337 = zext i1 %16336 to i8
  store i8 %16337, i8* %23, align 1
  %16338 = load i64, i64* %RBP.i, align 8
  %16339 = add i64 %16338, -44
  %16340 = add i64 %16272, 46
  store i64 %16340, i64* %3, align 8
  %16341 = inttoptr i64 %16339 to i32*
  %16342 = load i32, i32* %16341, align 4
  %16343 = sext i32 %16342 to i64
  %16344 = shl nsw i64 %16343, 6
  store i64 %16344, i64* %RCX.i1692, align 8
  %16345 = add i64 %16344, %16315
  store i64 %16345, i64* %RAX.i1763, align 8
  %16346 = icmp ult i64 %16345, %16315
  %16347 = icmp ult i64 %16345, %16344
  %16348 = or i1 %16346, %16347
  %16349 = zext i1 %16348 to i8
  store i8 %16349, i8* %18, align 1
  %16350 = trunc i64 %16345 to i32
  %16351 = and i32 %16350, 255
  %16352 = tail call i32 @llvm.ctpop.i32(i32 %16351)
  %16353 = trunc i32 %16352 to i8
  %16354 = and i8 %16353, 1
  %16355 = xor i8 %16354, 1
  store i8 %16355, i8* %19, align 1
  %16356 = xor i64 %16315, %16345
  %16357 = lshr i64 %16356, 4
  %16358 = trunc i64 %16357 to i8
  %16359 = and i8 %16358, 1
  store i8 %16359, i8* %20, align 1
  %16360 = icmp eq i64 %16345, 0
  %16361 = zext i1 %16360 to i8
  store i8 %16361, i8* %21, align 1
  %16362 = lshr i64 %16345, 63
  %16363 = trunc i64 %16362 to i8
  store i8 %16363, i8* %22, align 1
  %16364 = lshr i64 %16343, 57
  %16365 = and i64 %16364, 1
  %16366 = xor i64 %16362, %16331
  %16367 = xor i64 %16362, %16365
  %16368 = add nuw nsw i64 %16366, %16367
  %16369 = icmp eq i64 %16368, 2
  %16370 = zext i1 %16369 to i8
  store i8 %16370, i8* %23, align 1
  %16371 = add i64 %16338, -48
  %16372 = add i64 %16272, 57
  store i64 %16372, i64* %3, align 8
  %16373 = inttoptr i64 %16371 to i32*
  %16374 = load i32, i32* %16373, align 4
  %16375 = sext i32 %16374 to i64
  store i64 %16375, i64* %RCX.i1692, align 8
  %16376 = shl nsw i64 %16375, 2
  %16377 = add i64 %16376, %16345
  %16378 = load i32, i32* %EDX.i2206, align 4
  %16379 = add i64 %16272, 60
  store i64 %16379, i64* %3, align 8
  %16380 = inttoptr i64 %16377 to i32*
  store i32 %16378, i32* %16380, align 4
  %16381 = load i64, i64* %RBP.i, align 8
  %16382 = add i64 %16381, -44
  %16383 = load i64, i64* %3, align 8
  %16384 = add i64 %16383, 3
  store i64 %16384, i64* %3, align 8
  %16385 = inttoptr i64 %16382 to i32*
  %16386 = load i32, i32* %16385, align 4
  %16387 = add i32 %16386, 1
  %16388 = zext i32 %16387 to i64
  store i64 %16388, i64* %RAX.i1763, align 8
  %16389 = icmp eq i32 %16386, -1
  %16390 = icmp eq i32 %16387, 0
  %16391 = or i1 %16389, %16390
  %16392 = zext i1 %16391 to i8
  store i8 %16392, i8* %18, align 1
  %16393 = and i32 %16387, 255
  %16394 = tail call i32 @llvm.ctpop.i32(i32 %16393)
  %16395 = trunc i32 %16394 to i8
  %16396 = and i8 %16395, 1
  %16397 = xor i8 %16396, 1
  store i8 %16397, i8* %19, align 1
  %16398 = xor i32 %16387, %16386
  %16399 = lshr i32 %16398, 4
  %16400 = trunc i32 %16399 to i8
  %16401 = and i8 %16400, 1
  store i8 %16401, i8* %20, align 1
  %16402 = zext i1 %16390 to i8
  store i8 %16402, i8* %21, align 1
  %16403 = lshr i32 %16387, 31
  %16404 = trunc i32 %16403 to i8
  store i8 %16404, i8* %22, align 1
  %16405 = lshr i32 %16386, 31
  %16406 = xor i32 %16403, %16405
  %16407 = add nuw nsw i32 %16406, %16403
  %16408 = icmp eq i32 %16407, 2
  %16409 = zext i1 %16408 to i8
  store i8 %16409, i8* %23, align 1
  %16410 = add i64 %16383, 9
  store i64 %16410, i64* %3, align 8
  store i32 %16387, i32* %16385, align 4
  %16411 = load i64, i64* %3, align 8
  %16412 = add i64 %16411, -79
  store i64 %16412, i64* %3, align 8
  br label %block_.L_4a64f1

block_.L_4a6545:                                  ; preds = %block_.L_4a64f1
  %16413 = add i64 %16244, -48
  %16414 = add i64 %16272, 8
  store i64 %16414, i64* %3, align 8
  %16415 = inttoptr i64 %16413 to i32*
  %16416 = load i32, i32* %16415, align 4
  %16417 = add i32 %16416, 1
  %16418 = zext i32 %16417 to i64
  store i64 %16418, i64* %RAX.i1763, align 8
  %16419 = icmp eq i32 %16416, -1
  %16420 = icmp eq i32 %16417, 0
  %16421 = or i1 %16419, %16420
  %16422 = zext i1 %16421 to i8
  store i8 %16422, i8* %18, align 1
  %16423 = and i32 %16417, 255
  %16424 = tail call i32 @llvm.ctpop.i32(i32 %16423)
  %16425 = trunc i32 %16424 to i8
  %16426 = and i8 %16425, 1
  %16427 = xor i8 %16426, 1
  store i8 %16427, i8* %19, align 1
  %16428 = xor i32 %16417, %16416
  %16429 = lshr i32 %16428, 4
  %16430 = trunc i32 %16429 to i8
  %16431 = and i8 %16430, 1
  store i8 %16431, i8* %20, align 1
  %16432 = zext i1 %16420 to i8
  store i8 %16432, i8* %21, align 1
  %16433 = lshr i32 %16417, 31
  %16434 = trunc i32 %16433 to i8
  store i8 %16434, i8* %22, align 1
  %16435 = lshr i32 %16416, 31
  %16436 = xor i32 %16433, %16435
  %16437 = add nuw nsw i32 %16436, %16433
  %16438 = icmp eq i32 %16437, 2
  %16439 = zext i1 %16438 to i8
  store i8 %16439, i8* %23, align 1
  %16440 = add i64 %16272, 14
  store i64 %16440, i64* %3, align 8
  store i32 %16417, i32* %16415, align 4
  %16441 = load i64, i64* %3, align 8
  %16442 = add i64 %16441, -115
  store i64 %16442, i64* %3, align 8
  br label %block_.L_4a64e0

block_.L_4a6558:                                  ; preds = %block_.L_4a64e0
  %16443 = add i64 %16211, -68
  store i64 %16443, i64* %RSI.i1889, align 8
  store i64 1, i64* %RDX.i1805, align 8
  %16444 = add i64 %16211, -12
  %16445 = add i64 %16239, 12
  store i64 %16445, i64* %3, align 8
  %16446 = inttoptr i64 %16444 to i32*
  %16447 = load i32, i32* %16446, align 4
  %16448 = zext i32 %16447 to i64
  store i64 %16448, i64* %RDI.i2141, align 8
  %16449 = add i64 %16239, 16872
  %16450 = add i64 %16239, 17
  %16451 = load i64, i64* %6, align 8
  %16452 = add i64 %16451, -8
  %16453 = inttoptr i64 %16452 to i64*
  store i64 %16450, i64* %16453, align 8
  store i64 %16452, i64* %6, align 8
  store i64 %16449, i64* %3, align 8
  %call2_4a6564 = tail call %struct.Memory* @sub_4aa740.dct_luma8x8(%struct.State* nonnull %0, i64 %16449, %struct.Memory* %MEMORY.75)
  %16454 = load i64, i64* %RBP.i, align 8
  %16455 = add i64 %16454, -76
  %16456 = load i32, i32* %EAX.i2159, align 4
  %16457 = load i64, i64* %3, align 8
  %16458 = add i64 %16457, 3
  store i64 %16458, i64* %3, align 8
  %16459 = inttoptr i64 %16455 to i32*
  store i32 %16456, i32* %16459, align 4
  %16460 = load i64, i64* %RBP.i, align 8
  %16461 = add i64 %16460, -48
  %16462 = load i64, i64* %3, align 8
  %16463 = add i64 %16462, 7
  store i64 %16463, i64* %3, align 8
  %16464 = inttoptr i64 %16461 to i32*
  store i32 0, i32* %16464, align 4
  %.pre541 = load i64, i64* %3, align 8
  br label %block_.L_4a6573

block_.L_4a6573:                                  ; preds = %block_.L_4a65d9, %block_.L_4a6558
  %16465 = phi i64 [ %16696, %block_.L_4a65d9 ], [ %.pre541, %block_.L_4a6558 ]
  %16466 = load i64, i64* %RBP.i, align 8
  %16467 = add i64 %16466, -48
  %16468 = add i64 %16465, 4
  store i64 %16468, i64* %3, align 8
  %16469 = inttoptr i64 %16467 to i32*
  %16470 = load i32, i32* %16469, align 4
  %16471 = add i32 %16470, -8
  %16472 = icmp ult i32 %16470, 8
  %16473 = zext i1 %16472 to i8
  store i8 %16473, i8* %18, align 1
  %16474 = and i32 %16471, 255
  %16475 = tail call i32 @llvm.ctpop.i32(i32 %16474)
  %16476 = trunc i32 %16475 to i8
  %16477 = and i8 %16476, 1
  %16478 = xor i8 %16477, 1
  store i8 %16478, i8* %19, align 1
  %16479 = xor i32 %16471, %16470
  %16480 = lshr i32 %16479, 4
  %16481 = trunc i32 %16480 to i8
  %16482 = and i8 %16481, 1
  store i8 %16482, i8* %20, align 1
  %16483 = icmp eq i32 %16471, 0
  %16484 = zext i1 %16483 to i8
  store i8 %16484, i8* %21, align 1
  %16485 = lshr i32 %16471, 31
  %16486 = trunc i32 %16485 to i8
  store i8 %16486, i8* %22, align 1
  %16487 = lshr i32 %16470, 31
  %16488 = xor i32 %16485, %16487
  %16489 = add nuw nsw i32 %16488, %16487
  %16490 = icmp eq i32 %16489, 2
  %16491 = zext i1 %16490 to i8
  store i8 %16491, i8* %23, align 1
  %16492 = icmp ne i8 %16486, 0
  %16493 = xor i1 %16492, %16490
  %.v825 = select i1 %16493, i64 10, i64 121
  %16494 = add i64 %16465, %.v825
  store i64 %16494, i64* %3, align 8
  br i1 %16493, label %block_4a657d, label %block_.L_4a65ec

block_4a657d:                                     ; preds = %block_.L_4a6573
  %16495 = add i64 %16466, -44
  %16496 = add i64 %16494, 7
  store i64 %16496, i64* %3, align 8
  %16497 = inttoptr i64 %16495 to i32*
  store i32 0, i32* %16497, align 4
  %.pre624 = load i64, i64* %3, align 8
  br label %block_.L_4a6584

block_.L_4a6584:                                  ; preds = %block_4a658e, %block_4a657d
  %16498 = phi i64 [ %16666, %block_4a658e ], [ %.pre624, %block_4a657d ]
  %16499 = load i64, i64* %RBP.i, align 8
  %16500 = add i64 %16499, -44
  %16501 = add i64 %16498, 4
  store i64 %16501, i64* %3, align 8
  %16502 = inttoptr i64 %16500 to i32*
  %16503 = load i32, i32* %16502, align 4
  %16504 = add i32 %16503, -8
  %16505 = icmp ult i32 %16503, 8
  %16506 = zext i1 %16505 to i8
  store i8 %16506, i8* %18, align 1
  %16507 = and i32 %16504, 255
  %16508 = tail call i32 @llvm.ctpop.i32(i32 %16507)
  %16509 = trunc i32 %16508 to i8
  %16510 = and i8 %16509, 1
  %16511 = xor i8 %16510, 1
  store i8 %16511, i8* %19, align 1
  %16512 = xor i32 %16504, %16503
  %16513 = lshr i32 %16512, 4
  %16514 = trunc i32 %16513 to i8
  %16515 = and i8 %16514, 1
  store i8 %16515, i8* %20, align 1
  %16516 = icmp eq i32 %16504, 0
  %16517 = zext i1 %16516 to i8
  store i8 %16517, i8* %21, align 1
  %16518 = lshr i32 %16504, 31
  %16519 = trunc i32 %16518 to i8
  store i8 %16519, i8* %22, align 1
  %16520 = lshr i32 %16503, 31
  %16521 = xor i32 %16518, %16520
  %16522 = add nuw nsw i32 %16521, %16520
  %16523 = icmp eq i32 %16522, 2
  %16524 = zext i1 %16523 to i8
  store i8 %16524, i8* %23, align 1
  %16525 = icmp ne i8 %16519, 0
  %16526 = xor i1 %16525, %16523
  %.v771 = select i1 %16526, i64 10, i64 85
  %16527 = add i64 %16498, %.v771
  store i64 %16527, i64* %3, align 8
  br i1 %16526, label %block_4a658e, label %block_.L_4a65d9

block_4a658e:                                     ; preds = %block_.L_4a6584
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RAX.i1763, align 8
  %16528 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %16529 = add i64 %16528, 13112
  store i64 %16529, i64* %RCX.i1692, align 8
  %16530 = icmp ugt i64 %16528, -13113
  %16531 = zext i1 %16530 to i8
  store i8 %16531, i8* %18, align 1
  %16532 = trunc i64 %16529 to i32
  %16533 = and i32 %16532, 255
  %16534 = tail call i32 @llvm.ctpop.i32(i32 %16533)
  %16535 = trunc i32 %16534 to i8
  %16536 = and i8 %16535, 1
  %16537 = xor i8 %16536, 1
  store i8 %16537, i8* %19, align 1
  %16538 = xor i64 %16528, 16
  %16539 = xor i64 %16538, %16529
  %16540 = lshr i64 %16539, 4
  %16541 = trunc i64 %16540 to i8
  %16542 = and i8 %16541, 1
  store i8 %16542, i8* %20, align 1
  %16543 = icmp eq i64 %16529, 0
  %16544 = zext i1 %16543 to i8
  store i8 %16544, i8* %21, align 1
  %16545 = lshr i64 %16529, 63
  %16546 = trunc i64 %16545 to i8
  store i8 %16546, i8* %22, align 1
  %16547 = lshr i64 %16528, 63
  %16548 = xor i64 %16545, %16547
  %16549 = add nuw nsw i64 %16548, %16545
  %16550 = icmp eq i64 %16549, 2
  %16551 = zext i1 %16550 to i8
  store i8 %16551, i8* %23, align 1
  %16552 = add i64 %16527, 29
  store i64 %16552, i64* %3, align 8
  %16553 = load i32, i32* %16502, align 4
  %16554 = sext i32 %16553 to i64
  %16555 = shl nsw i64 %16554, 6
  store i64 %16555, i64* %RDX.i1805, align 8
  %16556 = add i64 %16555, %16529
  store i64 %16556, i64* %RCX.i1692, align 8
  %16557 = icmp ult i64 %16556, %16529
  %16558 = icmp ult i64 %16556, %16555
  %16559 = or i1 %16557, %16558
  %16560 = zext i1 %16559 to i8
  store i8 %16560, i8* %18, align 1
  %16561 = trunc i64 %16556 to i32
  %16562 = and i32 %16561, 255
  %16563 = tail call i32 @llvm.ctpop.i32(i32 %16562)
  %16564 = trunc i32 %16563 to i8
  %16565 = and i8 %16564, 1
  %16566 = xor i8 %16565, 1
  store i8 %16566, i8* %19, align 1
  %16567 = xor i64 %16529, %16556
  %16568 = lshr i64 %16567, 4
  %16569 = trunc i64 %16568 to i8
  %16570 = and i8 %16569, 1
  store i8 %16570, i8* %20, align 1
  %16571 = icmp eq i64 %16556, 0
  %16572 = zext i1 %16571 to i8
  store i8 %16572, i8* %21, align 1
  %16573 = lshr i64 %16556, 63
  %16574 = trunc i64 %16573 to i8
  store i8 %16574, i8* %22, align 1
  %16575 = lshr i64 %16554, 57
  %16576 = and i64 %16575, 1
  %16577 = xor i64 %16573, %16545
  %16578 = xor i64 %16573, %16576
  %16579 = add nuw nsw i64 %16577, %16578
  %16580 = icmp eq i64 %16579, 2
  %16581 = zext i1 %16580 to i8
  store i8 %16581, i8* %23, align 1
  %16582 = load i64, i64* %RBP.i, align 8
  %16583 = add i64 %16582, -48
  %16584 = add i64 %16527, 40
  store i64 %16584, i64* %3, align 8
  %16585 = inttoptr i64 %16583 to i32*
  %16586 = load i32, i32* %16585, align 4
  %16587 = sext i32 %16586 to i64
  store i64 %16587, i64* %RDX.i1805, align 8
  %16588 = shl nsw i64 %16587, 2
  %16589 = add i64 %16588, %16556
  %16590 = add i64 %16527, 43
  store i64 %16590, i64* %3, align 8
  %16591 = inttoptr i64 %16589 to i32*
  %16592 = load i32, i32* %16591, align 4
  %16593 = zext i32 %16592 to i64
  store i64 %16593, i64* %RSI.i1889, align 8
  %16594 = add i64 %16582, -44
  %16595 = add i64 %16527, 47
  store i64 %16595, i64* %3, align 8
  %16596 = inttoptr i64 %16594 to i32*
  %16597 = load i32, i32* %16596, align 4
  %16598 = sext i32 %16597 to i64
  %16599 = shl nsw i64 %16598, 6
  store i64 %16599, i64* %RCX.i1692, align 8
  %16600 = load i64, i64* %RAX.i1763, align 8
  %16601 = add i64 %16599, %16600
  store i64 %16601, i64* %RAX.i1763, align 8
  %16602 = icmp ult i64 %16601, %16600
  %16603 = icmp ult i64 %16601, %16599
  %16604 = or i1 %16602, %16603
  %16605 = zext i1 %16604 to i8
  store i8 %16605, i8* %18, align 1
  %16606 = trunc i64 %16601 to i32
  %16607 = and i32 %16606, 255
  %16608 = tail call i32 @llvm.ctpop.i32(i32 %16607)
  %16609 = trunc i32 %16608 to i8
  %16610 = and i8 %16609, 1
  %16611 = xor i8 %16610, 1
  store i8 %16611, i8* %19, align 1
  %16612 = xor i64 %16600, %16601
  %16613 = lshr i64 %16612, 4
  %16614 = trunc i64 %16613 to i8
  %16615 = and i8 %16614, 1
  store i8 %16615, i8* %20, align 1
  %16616 = icmp eq i64 %16601, 0
  %16617 = zext i1 %16616 to i8
  store i8 %16617, i8* %21, align 1
  %16618 = lshr i64 %16601, 63
  %16619 = trunc i64 %16618 to i8
  store i8 %16619, i8* %22, align 1
  %16620 = lshr i64 %16600, 63
  %16621 = lshr i64 %16598, 57
  %16622 = and i64 %16621, 1
  %16623 = xor i64 %16618, %16620
  %16624 = xor i64 %16618, %16622
  %16625 = add nuw nsw i64 %16623, %16624
  %16626 = icmp eq i64 %16625, 2
  %16627 = zext i1 %16626 to i8
  store i8 %16627, i8* %23, align 1
  %16628 = add i64 %16527, 58
  store i64 %16628, i64* %3, align 8
  %16629 = load i32, i32* %16585, align 4
  %16630 = sext i32 %16629 to i64
  store i64 %16630, i64* %RCX.i1692, align 8
  %16631 = shl nsw i64 %16630, 2
  %16632 = add i64 %16631, %16601
  %16633 = add i64 %16527, 61
  store i64 %16633, i64* %3, align 8
  %16634 = inttoptr i64 %16632 to i32*
  store i32 %16592, i32* %16634, align 4
  %16635 = load i64, i64* %RBP.i, align 8
  %16636 = add i64 %16635, -44
  %16637 = load i64, i64* %3, align 8
  %16638 = add i64 %16637, 3
  store i64 %16638, i64* %3, align 8
  %16639 = inttoptr i64 %16636 to i32*
  %16640 = load i32, i32* %16639, align 4
  %16641 = add i32 %16640, 1
  %16642 = zext i32 %16641 to i64
  store i64 %16642, i64* %RAX.i1763, align 8
  %16643 = icmp eq i32 %16640, -1
  %16644 = icmp eq i32 %16641, 0
  %16645 = or i1 %16643, %16644
  %16646 = zext i1 %16645 to i8
  store i8 %16646, i8* %18, align 1
  %16647 = and i32 %16641, 255
  %16648 = tail call i32 @llvm.ctpop.i32(i32 %16647)
  %16649 = trunc i32 %16648 to i8
  %16650 = and i8 %16649, 1
  %16651 = xor i8 %16650, 1
  store i8 %16651, i8* %19, align 1
  %16652 = xor i32 %16641, %16640
  %16653 = lshr i32 %16652, 4
  %16654 = trunc i32 %16653 to i8
  %16655 = and i8 %16654, 1
  store i8 %16655, i8* %20, align 1
  %16656 = zext i1 %16644 to i8
  store i8 %16656, i8* %21, align 1
  %16657 = lshr i32 %16641, 31
  %16658 = trunc i32 %16657 to i8
  store i8 %16658, i8* %22, align 1
  %16659 = lshr i32 %16640, 31
  %16660 = xor i32 %16657, %16659
  %16661 = add nuw nsw i32 %16660, %16657
  %16662 = icmp eq i32 %16661, 2
  %16663 = zext i1 %16662 to i8
  store i8 %16663, i8* %23, align 1
  %16664 = add i64 %16637, 9
  store i64 %16664, i64* %3, align 8
  store i32 %16641, i32* %16639, align 4
  %16665 = load i64, i64* %3, align 8
  %16666 = add i64 %16665, -80
  store i64 %16666, i64* %3, align 8
  br label %block_.L_4a6584

block_.L_4a65d9:                                  ; preds = %block_.L_4a6584
  %16667 = add i64 %16499, -48
  %16668 = add i64 %16527, 8
  store i64 %16668, i64* %3, align 8
  %16669 = inttoptr i64 %16667 to i32*
  %16670 = load i32, i32* %16669, align 4
  %16671 = add i32 %16670, 1
  %16672 = zext i32 %16671 to i64
  store i64 %16672, i64* %RAX.i1763, align 8
  %16673 = icmp eq i32 %16670, -1
  %16674 = icmp eq i32 %16671, 0
  %16675 = or i1 %16673, %16674
  %16676 = zext i1 %16675 to i8
  store i8 %16676, i8* %18, align 1
  %16677 = and i32 %16671, 255
  %16678 = tail call i32 @llvm.ctpop.i32(i32 %16677)
  %16679 = trunc i32 %16678 to i8
  %16680 = and i8 %16679, 1
  %16681 = xor i8 %16680, 1
  store i8 %16681, i8* %19, align 1
  %16682 = xor i32 %16671, %16670
  %16683 = lshr i32 %16682, 4
  %16684 = trunc i32 %16683 to i8
  %16685 = and i8 %16684, 1
  store i8 %16685, i8* %20, align 1
  %16686 = zext i1 %16674 to i8
  store i8 %16686, i8* %21, align 1
  %16687 = lshr i32 %16671, 31
  %16688 = trunc i32 %16687 to i8
  store i8 %16688, i8* %22, align 1
  %16689 = lshr i32 %16670, 31
  %16690 = xor i32 %16687, %16689
  %16691 = add nuw nsw i32 %16690, %16687
  %16692 = icmp eq i32 %16691, 2
  %16693 = zext i1 %16692 to i8
  store i8 %16693, i8* %23, align 1
  %16694 = add i64 %16527, 14
  store i64 %16694, i64* %3, align 8
  store i32 %16671, i32* %16669, align 4
  %16695 = load i64, i64* %3, align 8
  %16696 = add i64 %16695, -116
  store i64 %16696, i64* %3, align 8
  br label %block_.L_4a6573

block_.L_4a65ec:                                  ; preds = %block_.L_4a6573
  %16697 = add i64 %16466, -628
  %16698 = add i64 %16494, 10
  store i64 %16698, i64* %3, align 8
  %16699 = inttoptr i64 %16697 to i32*
  store i32 0, i32* %16699, align 4
  %16700 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64) to i32), i32 255))
  %16701 = trunc i32 %16700 to i8
  %16702 = and i8 %16701, 1
  %16703 = xor i8 %16702, 1
  %.pre542 = load i64, i64* %3, align 8
  br label %block_.L_4a65f6

block_.L_4a65f6:                                  ; preds = %block_.L_4a6b14, %block_.L_4a65ec
  %16704 = phi i64 [ %.pre542, %block_.L_4a65ec ], [ %19384, %block_.L_4a6b14 ]
  %MEMORY.85 = phi %struct.Memory* [ %call2_4a6564, %block_.L_4a65ec ], [ %19031, %block_.L_4a6b14 ]
  %16705 = load i64, i64* %RBP.i, align 8
  %16706 = add i64 %16705, -628
  %16707 = add i64 %16704, 7
  store i64 %16707, i64* %3, align 8
  %16708 = inttoptr i64 %16706 to i32*
  %16709 = load i32, i32* %16708, align 4
  %16710 = add i32 %16709, -4
  %16711 = icmp ult i32 %16709, 4
  %16712 = zext i1 %16711 to i8
  store i8 %16712, i8* %18, align 1
  %16713 = and i32 %16710, 255
  %16714 = tail call i32 @llvm.ctpop.i32(i32 %16713)
  %16715 = trunc i32 %16714 to i8
  %16716 = and i8 %16715, 1
  %16717 = xor i8 %16716, 1
  store i8 %16717, i8* %19, align 1
  %16718 = xor i32 %16710, %16709
  %16719 = lshr i32 %16718, 4
  %16720 = trunc i32 %16719 to i8
  %16721 = and i8 %16720, 1
  store i8 %16721, i8* %20, align 1
  %16722 = icmp eq i32 %16710, 0
  %16723 = zext i1 %16722 to i8
  store i8 %16723, i8* %21, align 1
  %16724 = lshr i32 %16710, 31
  %16725 = trunc i32 %16724 to i8
  store i8 %16725, i8* %22, align 1
  %16726 = lshr i32 %16709, 31
  %16727 = xor i32 %16724, %16726
  %16728 = add nuw nsw i32 %16727, %16726
  %16729 = icmp eq i32 %16728, 2
  %16730 = zext i1 %16729 to i8
  store i8 %16730, i8* %23, align 1
  %16731 = icmp ne i8 %16725, 0
  %16732 = xor i1 %16731, %16729
  %.v826 = select i1 %16732, i64 13, i64 1335
  %16733 = add i64 %16704, %.v826
  store i64 %16733, i64* %3, align 8
  br i1 %16732, label %block_4a6603, label %block_.L_4a6b2d

block_4a6603:                                     ; preds = %block_.L_4a65f6
  store i64 2, i64* %RAX.i1763, align 8
  %16734 = add i64 %16733, 11
  store i64 %16734, i64* %3, align 8
  %16735 = load i32, i32* %16708, align 4
  %16736 = zext i32 %16735 to i64
  store i64 %16736, i64* %RCX.i1692, align 8
  %16737 = add i64 %16705, -1360
  %16738 = add i64 %16733, 17
  store i64 %16738, i64* %3, align 8
  %16739 = inttoptr i64 %16737 to i32*
  store i32 2, i32* %16739, align 4
  %16740 = load i32, i32* %ECX.i7699, align 4
  %16741 = zext i32 %16740 to i64
  %16742 = load i64, i64* %3, align 8
  store i64 %16741, i64* %RAX.i1763, align 8
  %16743 = sext i32 %16740 to i64
  %16744 = lshr i64 %16743, 32
  store i64 %16744, i64* %101, align 8
  %16745 = load i64, i64* %RBP.i, align 8
  %16746 = add i64 %16745, -1360
  %16747 = add i64 %16742, 9
  store i64 %16747, i64* %3, align 8
  %16748 = inttoptr i64 %16746 to i32*
  %16749 = load i32, i32* %16748, align 4
  %16750 = zext i32 %16749 to i64
  store i64 %16750, i64* %RCX.i1692, align 8
  %16751 = add i64 %16742, 11
  store i64 %16751, i64* %3, align 8
  %16752 = sext i32 %16749 to i64
  %16753 = shl nuw i64 %16744, 32
  %16754 = or i64 %16753, %16741
  %16755 = sdiv i64 %16754, %16752
  %16756 = shl i64 %16755, 32
  %16757 = ashr exact i64 %16756, 32
  %16758 = icmp eq i64 %16755, %16757
  br i1 %16758, label %16761, label %16759

; <label>:16759:                                  ; preds = %block_4a6603
  %16760 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16751, %struct.Memory* %MEMORY.85)
  %.pre554 = load i64, i64* %RDX.i1805, align 8
  %.pre555 = load i64, i64* %3, align 8
  %.pre556 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit2480

; <label>:16761:                                  ; preds = %block_4a6603
  %16762 = srem i64 %16754, %16752
  %16763 = and i64 %16755, 4294967295
  store i64 %16763, i64* %RAX.i1763, align 8
  %16764 = and i64 %16762, 4294967295
  store i64 %16764, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__ecx.exit2480

routine_idivl__ecx.exit2480:                      ; preds = %16761, %16759
  %16765 = phi i64 [ %.pre556, %16759 ], [ %16745, %16761 ]
  %16766 = phi i64 [ %.pre555, %16759 ], [ %16751, %16761 ]
  %16767 = phi i64 [ %.pre554, %16759 ], [ %16764, %16761 ]
  %16768 = phi %struct.Memory* [ %16760, %16759 ], [ %MEMORY.85, %16761 ]
  %.tr254 = trunc i64 %16767 to i32
  %16769 = shl i32 %.tr254, 2
  %16770 = zext i32 %16769 to i64
  store i64 %16770, i64* %RDX.i1805, align 8
  %16771 = lshr i64 %16767, 30
  %16772 = trunc i64 %16771 to i8
  %16773 = and i8 %16772, 1
  store i8 %16773, i8* %18, align 1
  %16774 = and i32 %16769, 252
  %16775 = tail call i32 @llvm.ctpop.i32(i32 %16774)
  %16776 = trunc i32 %16775 to i8
  %16777 = and i8 %16776, 1
  %16778 = xor i8 %16777, 1
  store i8 %16778, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %16779 = icmp eq i32 %16769, 0
  %16780 = zext i1 %16779 to i8
  store i8 %16780, i8* %21, align 1
  %16781 = lshr i32 %.tr254, 29
  %16782 = trunc i32 %16781 to i8
  %16783 = and i8 %16782, 1
  store i8 %16783, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %16784 = add i64 %16765, -476
  %16785 = add i64 %16766, 9
  store i64 %16785, i64* %3, align 8
  %16786 = inttoptr i64 %16784 to i32*
  store i32 %16769, i32* %16786, align 4
  %16787 = load i64, i64* %RBP.i, align 8
  %16788 = add i64 %16787, -628
  %16789 = load i64, i64* %3, align 8
  %16790 = add i64 %16789, 6
  store i64 %16790, i64* %3, align 8
  %16791 = inttoptr i64 %16788 to i32*
  %16792 = load i32, i32* %16791, align 4
  %16793 = zext i32 %16792 to i64
  store i64 %16793, i64* %RAX.i1763, align 8
  %16794 = sext i32 %16792 to i64
  %16795 = lshr i64 %16794, 32
  store i64 %16795, i64* %101, align 8
  %16796 = load i32, i32* %ECX.i7699, align 4
  %16797 = add i64 %16789, 11
  store i64 %16797, i64* %3, align 8
  %16798 = sext i32 %16796 to i64
  %16799 = shl nuw i64 %16795, 32
  %16800 = or i64 %16799, %16793
  %16801 = sdiv i64 %16800, %16798
  %16802 = shl i64 %16801, 32
  %16803 = ashr exact i64 %16802, 32
  %16804 = icmp eq i64 %16801, %16803
  br i1 %16804, label %16807, label %16805

; <label>:16805:                                  ; preds = %routine_idivl__ecx.exit2480
  %16806 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16797, %struct.Memory* %16768)
  %.pre557 = load i64, i64* %RAX.i1763, align 8
  %.pre558 = load i64, i64* %3, align 8
  %.pre559 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit2464

; <label>:16807:                                  ; preds = %routine_idivl__ecx.exit2480
  %16808 = srem i64 %16800, %16798
  %16809 = and i64 %16801, 4294967295
  store i64 %16809, i64* %RAX.i1763, align 8
  %16810 = and i64 %16808, 4294967295
  store i64 %16810, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__ecx.exit2464

routine_idivl__ecx.exit2464:                      ; preds = %16807, %16805
  %16811 = phi i64 [ %.pre559, %16805 ], [ %16787, %16807 ]
  %16812 = phi i64 [ %.pre558, %16805 ], [ %16797, %16807 ]
  %16813 = phi i64 [ %.pre557, %16805 ], [ %16809, %16807 ]
  %16814 = phi %struct.Memory* [ %16806, %16805 ], [ %16768, %16807 ]
  %.tr257 = trunc i64 %16813 to i32
  %16815 = shl i32 %.tr257, 2
  %16816 = zext i32 %16815 to i64
  store i64 %16816, i64* %RAX.i1763, align 8
  %16817 = lshr i64 %16813, 30
  %16818 = trunc i64 %16817 to i8
  %16819 = and i8 %16818, 1
  store i8 %16819, i8* %18, align 1
  %16820 = and i32 %16815, 252
  %16821 = tail call i32 @llvm.ctpop.i32(i32 %16820)
  %16822 = trunc i32 %16821 to i8
  %16823 = and i8 %16822, 1
  %16824 = xor i8 %16823, 1
  store i8 %16824, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %16825 = icmp eq i32 %16815, 0
  %16826 = zext i1 %16825 to i8
  store i8 %16826, i8* %21, align 1
  %16827 = lshr i32 %.tr257, 29
  %16828 = trunc i32 %16827 to i8
  %16829 = and i8 %16828, 1
  store i8 %16829, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %16830 = add i64 %16811, -480
  %16831 = add i64 %16812, 9
  store i64 %16831, i64* %3, align 8
  %16832 = inttoptr i64 %16830 to i32*
  store i32 %16815, i32* %16832, align 4
  %16833 = load i64, i64* %RBP.i, align 8
  %16834 = add i64 %16833, -48
  %16835 = load i64, i64* %3, align 8
  %16836 = add i64 %16835, 7
  store i64 %16836, i64* %3, align 8
  %16837 = inttoptr i64 %16834 to i32*
  store i32 0, i32* %16837, align 4
  %.pre560 = load i64, i64* %3, align 8
  br label %block_.L_4a6643

block_.L_4a6643:                                  ; preds = %block_.L_4a66b8, %routine_idivl__ecx.exit2464
  %16838 = phi i64 [ %17110, %block_.L_4a66b8 ], [ %.pre560, %routine_idivl__ecx.exit2464 ]
  %16839 = load i64, i64* %RBP.i, align 8
  %16840 = add i64 %16839, -48
  %16841 = add i64 %16838, 4
  store i64 %16841, i64* %3, align 8
  %16842 = inttoptr i64 %16840 to i32*
  %16843 = load i32, i32* %16842, align 4
  %16844 = add i32 %16843, -4
  %16845 = icmp ult i32 %16843, 4
  %16846 = zext i1 %16845 to i8
  store i8 %16846, i8* %18, align 1
  %16847 = and i32 %16844, 255
  %16848 = tail call i32 @llvm.ctpop.i32(i32 %16847)
  %16849 = trunc i32 %16848 to i8
  %16850 = and i8 %16849, 1
  %16851 = xor i8 %16850, 1
  store i8 %16851, i8* %19, align 1
  %16852 = xor i32 %16844, %16843
  %16853 = lshr i32 %16852, 4
  %16854 = trunc i32 %16853 to i8
  %16855 = and i8 %16854, 1
  store i8 %16855, i8* %20, align 1
  %16856 = icmp eq i32 %16844, 0
  %16857 = zext i1 %16856 to i8
  store i8 %16857, i8* %21, align 1
  %16858 = lshr i32 %16844, 31
  %16859 = trunc i32 %16858 to i8
  store i8 %16859, i8* %22, align 1
  %16860 = lshr i32 %16843, 31
  %16861 = xor i32 %16858, %16860
  %16862 = add nuw nsw i32 %16861, %16860
  %16863 = icmp eq i32 %16862, 2
  %16864 = zext i1 %16863 to i8
  store i8 %16864, i8* %23, align 1
  %16865 = icmp ne i8 %16859, 0
  %16866 = xor i1 %16865, %16863
  %.v834 = select i1 %16866, i64 10, i64 136
  %16867 = add i64 %16838, %.v834
  store i64 %16867, i64* %3, align 8
  br i1 %16866, label %block_4a664d, label %block_.L_4a66cb

block_4a664d:                                     ; preds = %block_.L_4a6643
  %16868 = add i64 %16839, -44
  %16869 = add i64 %16867, 7
  store i64 %16869, i64* %3, align 8
  %16870 = inttoptr i64 %16868 to i32*
  store i32 0, i32* %16870, align 4
  %.pre623 = load i64, i64* %3, align 8
  br label %block_.L_4a6654

block_.L_4a6654:                                  ; preds = %block_4a665e, %block_4a664d
  %16871 = phi i64 [ %17080, %block_4a665e ], [ %.pre623, %block_4a664d ]
  %16872 = load i64, i64* %RBP.i, align 8
  %16873 = add i64 %16872, -44
  %16874 = add i64 %16871, 4
  store i64 %16874, i64* %3, align 8
  %16875 = inttoptr i64 %16873 to i32*
  %16876 = load i32, i32* %16875, align 4
  %16877 = add i32 %16876, -4
  %16878 = icmp ult i32 %16876, 4
  %16879 = zext i1 %16878 to i8
  store i8 %16879, i8* %18, align 1
  %16880 = and i32 %16877, 255
  %16881 = tail call i32 @llvm.ctpop.i32(i32 %16880)
  %16882 = trunc i32 %16881 to i8
  %16883 = and i8 %16882, 1
  %16884 = xor i8 %16883, 1
  store i8 %16884, i8* %19, align 1
  %16885 = xor i32 %16877, %16876
  %16886 = lshr i32 %16885, 4
  %16887 = trunc i32 %16886 to i8
  %16888 = and i8 %16887, 1
  store i8 %16888, i8* %20, align 1
  %16889 = icmp eq i32 %16877, 0
  %16890 = zext i1 %16889 to i8
  store i8 %16890, i8* %21, align 1
  %16891 = lshr i32 %16877, 31
  %16892 = trunc i32 %16891 to i8
  store i8 %16892, i8* %22, align 1
  %16893 = lshr i32 %16876, 31
  %16894 = xor i32 %16891, %16893
  %16895 = add nuw nsw i32 %16894, %16893
  %16896 = icmp eq i32 %16895, 2
  %16897 = zext i1 %16896 to i8
  store i8 %16897, i8* %23, align 1
  %16898 = icmp ne i8 %16892, 0
  %16899 = xor i1 %16898, %16896
  %.v770 = select i1 %16899, i64 10, i64 100
  %16900 = add i64 %16871, %.v770
  store i64 %16900, i64* %3, align 8
  br i1 %16899, label %block_4a665e, label %block_.L_4a66b8

block_4a665e:                                     ; preds = %block_.L_4a6654
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RAX.i1763, align 8
  %16901 = add i64 %16900, 13
  store i64 %16901, i64* %3, align 8
  %16902 = load i32, i32* %16875, align 4
  %16903 = zext i32 %16902 to i64
  store i64 %16903, i64* %RCX.i1692, align 8
  %16904 = add i64 %16872, -476
  %16905 = add i64 %16900, 19
  store i64 %16905, i64* %3, align 8
  %16906 = inttoptr i64 %16904 to i32*
  %16907 = load i32, i32* %16906, align 4
  %16908 = add i32 %16907, %16902
  %16909 = zext i32 %16908 to i64
  store i64 %16909, i64* %RCX.i1692, align 8
  %16910 = sext i32 %16908 to i64
  %16911 = shl nsw i64 %16910, 6
  store i64 %16911, i64* %RDX.i1805, align 8
  %16912 = add i64 %16911, ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64)
  store i64 %16912, i64* %RAX.i1763, align 8
  %16913 = icmp ult i64 %16912, ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64)
  %16914 = icmp ult i64 %16912, %16911
  %16915 = or i1 %16913, %16914
  %16916 = zext i1 %16915 to i8
  store i8 %16916, i8* %18, align 1
  %16917 = trunc i64 %16912 to i32
  %16918 = and i32 %16917, 248
  %16919 = tail call i32 @llvm.ctpop.i32(i32 %16918)
  %16920 = trunc i32 %16919 to i8
  %16921 = and i8 %16920, 1
  %16922 = xor i8 %16921, 1
  store i8 %16922, i8* %19, align 1
  %16923 = xor i64 %16912, ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64)
  %16924 = lshr i64 %16923, 4
  %16925 = trunc i64 %16924 to i8
  %16926 = and i8 %16925, 1
  store i8 %16926, i8* %20, align 1
  %16927 = icmp eq i64 %16912, 0
  %16928 = zext i1 %16927 to i8
  store i8 %16928, i8* %21, align 1
  %16929 = lshr i64 %16912, 63
  %16930 = trunc i64 %16929 to i8
  store i8 %16930, i8* %22, align 1
  %16931 = lshr i64 %16910, 57
  %16932 = and i64 %16931, 1
  %16933 = xor i64 %16929, lshr (i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64 63)
  %16934 = xor i64 %16929, %16932
  %16935 = add nuw nsw i64 %16933, %16934
  %16936 = icmp eq i64 %16935, 2
  %16937 = zext i1 %16936 to i8
  store i8 %16937, i8* %23, align 1
  %16938 = load i64, i64* %RBP.i, align 8
  %16939 = add i64 %16938, -48
  %16940 = add i64 %16900, 32
  store i64 %16940, i64* %3, align 8
  %16941 = inttoptr i64 %16939 to i32*
  %16942 = load i32, i32* %16941, align 4
  %16943 = zext i32 %16942 to i64
  store i64 %16943, i64* %RCX.i1692, align 8
  %16944 = add i64 %16938, -480
  %16945 = add i64 %16900, 38
  store i64 %16945, i64* %3, align 8
  %16946 = inttoptr i64 %16944 to i32*
  %16947 = load i32, i32* %16946, align 4
  %16948 = add i32 %16947, %16942
  %16949 = zext i32 %16948 to i64
  store i64 %16949, i64* %RCX.i1692, align 8
  %16950 = icmp ult i32 %16948, %16942
  %16951 = icmp ult i32 %16948, %16947
  %16952 = or i1 %16950, %16951
  %16953 = zext i1 %16952 to i8
  store i8 %16953, i8* %18, align 1
  %16954 = and i32 %16948, 255
  %16955 = tail call i32 @llvm.ctpop.i32(i32 %16954)
  %16956 = trunc i32 %16955 to i8
  %16957 = and i8 %16956, 1
  %16958 = xor i8 %16957, 1
  store i8 %16958, i8* %19, align 1
  %16959 = xor i32 %16947, %16942
  %16960 = xor i32 %16959, %16948
  %16961 = lshr i32 %16960, 4
  %16962 = trunc i32 %16961 to i8
  %16963 = and i8 %16962, 1
  store i8 %16963, i8* %20, align 1
  %16964 = icmp eq i32 %16948, 0
  %16965 = zext i1 %16964 to i8
  store i8 %16965, i8* %21, align 1
  %16966 = lshr i32 %16948, 31
  %16967 = trunc i32 %16966 to i8
  store i8 %16967, i8* %22, align 1
  %16968 = lshr i32 %16942, 31
  %16969 = lshr i32 %16947, 31
  %16970 = xor i32 %16966, %16968
  %16971 = xor i32 %16966, %16969
  %16972 = add nuw nsw i32 %16970, %16971
  %16973 = icmp eq i32 %16972, 2
  %16974 = zext i1 %16973 to i8
  store i8 %16974, i8* %23, align 1
  %16975 = sext i32 %16948 to i64
  store i64 %16975, i64* %RDX.i1805, align 8
  %16976 = shl nsw i64 %16975, 2
  %16977 = add i64 %16912, %16976
  %16978 = add i64 %16900, 44
  store i64 %16978, i64* %3, align 8
  %16979 = inttoptr i64 %16977 to i32*
  %16980 = load i32, i32* %16979, align 4
  %16981 = zext i32 %16980 to i64
  store i64 %16981, i64* %RCX.i1692, align 8
  %16982 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %16983 = add i64 %16982, 13112
  store i64 %16983, i64* %RAX.i1763, align 8
  %16984 = icmp ugt i64 %16982, -13113
  %16985 = zext i1 %16984 to i8
  store i8 %16985, i8* %18, align 1
  %16986 = trunc i64 %16983 to i32
  %16987 = and i32 %16986, 255
  %16988 = tail call i32 @llvm.ctpop.i32(i32 %16987)
  %16989 = trunc i32 %16988 to i8
  %16990 = and i8 %16989, 1
  %16991 = xor i8 %16990, 1
  store i8 %16991, i8* %19, align 1
  %16992 = xor i64 %16982, 16
  %16993 = xor i64 %16992, %16983
  %16994 = lshr i64 %16993, 4
  %16995 = trunc i64 %16994 to i8
  %16996 = and i8 %16995, 1
  store i8 %16996, i8* %20, align 1
  %16997 = icmp eq i64 %16983, 0
  %16998 = zext i1 %16997 to i8
  store i8 %16998, i8* %21, align 1
  %16999 = lshr i64 %16983, 63
  %17000 = trunc i64 %16999 to i8
  store i8 %17000, i8* %22, align 1
  %17001 = lshr i64 %16982, 63
  %17002 = xor i64 %16999, %17001
  %17003 = add nuw nsw i64 %17002, %16999
  %17004 = icmp eq i64 %17003, 2
  %17005 = zext i1 %17004 to i8
  store i8 %17005, i8* %23, align 1
  %17006 = add i64 %16938, -44
  %17007 = add i64 %16900, 62
  store i64 %17007, i64* %3, align 8
  %17008 = inttoptr i64 %17006 to i32*
  %17009 = load i32, i32* %17008, align 4
  %17010 = sext i32 %17009 to i64
  %17011 = shl nsw i64 %17010, 6
  store i64 %17011, i64* %RDX.i1805, align 8
  %17012 = add i64 %17011, %16983
  store i64 %17012, i64* %RAX.i1763, align 8
  %17013 = icmp ult i64 %17012, %16983
  %17014 = icmp ult i64 %17012, %17011
  %17015 = or i1 %17013, %17014
  %17016 = zext i1 %17015 to i8
  store i8 %17016, i8* %18, align 1
  %17017 = trunc i64 %17012 to i32
  %17018 = and i32 %17017, 255
  %17019 = tail call i32 @llvm.ctpop.i32(i32 %17018)
  %17020 = trunc i32 %17019 to i8
  %17021 = and i8 %17020, 1
  %17022 = xor i8 %17021, 1
  store i8 %17022, i8* %19, align 1
  %17023 = xor i64 %16983, %17012
  %17024 = lshr i64 %17023, 4
  %17025 = trunc i64 %17024 to i8
  %17026 = and i8 %17025, 1
  store i8 %17026, i8* %20, align 1
  %17027 = icmp eq i64 %17012, 0
  %17028 = zext i1 %17027 to i8
  store i8 %17028, i8* %21, align 1
  %17029 = lshr i64 %17012, 63
  %17030 = trunc i64 %17029 to i8
  store i8 %17030, i8* %22, align 1
  %17031 = lshr i64 %17010, 57
  %17032 = and i64 %17031, 1
  %17033 = xor i64 %17029, %16999
  %17034 = xor i64 %17029, %17032
  %17035 = add nuw nsw i64 %17033, %17034
  %17036 = icmp eq i64 %17035, 2
  %17037 = zext i1 %17036 to i8
  store i8 %17037, i8* %23, align 1
  %17038 = load i64, i64* %RBP.i, align 8
  %17039 = add i64 %17038, -48
  %17040 = add i64 %16900, 73
  store i64 %17040, i64* %3, align 8
  %17041 = inttoptr i64 %17039 to i32*
  %17042 = load i32, i32* %17041, align 4
  %17043 = sext i32 %17042 to i64
  store i64 %17043, i64* %RDX.i1805, align 8
  %17044 = shl nsw i64 %17043, 2
  %17045 = add i64 %17044, %17012
  %17046 = load i32, i32* %ECX.i7699, align 4
  %17047 = add i64 %16900, 76
  store i64 %17047, i64* %3, align 8
  %17048 = inttoptr i64 %17045 to i32*
  store i32 %17046, i32* %17048, align 4
  %17049 = load i64, i64* %RBP.i, align 8
  %17050 = add i64 %17049, -44
  %17051 = load i64, i64* %3, align 8
  %17052 = add i64 %17051, 3
  store i64 %17052, i64* %3, align 8
  %17053 = inttoptr i64 %17050 to i32*
  %17054 = load i32, i32* %17053, align 4
  %17055 = add i32 %17054, 1
  %17056 = zext i32 %17055 to i64
  store i64 %17056, i64* %RAX.i1763, align 8
  %17057 = icmp eq i32 %17054, -1
  %17058 = icmp eq i32 %17055, 0
  %17059 = or i1 %17057, %17058
  %17060 = zext i1 %17059 to i8
  store i8 %17060, i8* %18, align 1
  %17061 = and i32 %17055, 255
  %17062 = tail call i32 @llvm.ctpop.i32(i32 %17061)
  %17063 = trunc i32 %17062 to i8
  %17064 = and i8 %17063, 1
  %17065 = xor i8 %17064, 1
  store i8 %17065, i8* %19, align 1
  %17066 = xor i32 %17055, %17054
  %17067 = lshr i32 %17066, 4
  %17068 = trunc i32 %17067 to i8
  %17069 = and i8 %17068, 1
  store i8 %17069, i8* %20, align 1
  %17070 = zext i1 %17058 to i8
  store i8 %17070, i8* %21, align 1
  %17071 = lshr i32 %17055, 31
  %17072 = trunc i32 %17071 to i8
  store i8 %17072, i8* %22, align 1
  %17073 = lshr i32 %17054, 31
  %17074 = xor i32 %17071, %17073
  %17075 = add nuw nsw i32 %17074, %17071
  %17076 = icmp eq i32 %17075, 2
  %17077 = zext i1 %17076 to i8
  store i8 %17077, i8* %23, align 1
  %17078 = add i64 %17051, 9
  store i64 %17078, i64* %3, align 8
  store i32 %17055, i32* %17053, align 4
  %17079 = load i64, i64* %3, align 8
  %17080 = add i64 %17079, -95
  store i64 %17080, i64* %3, align 8
  br label %block_.L_4a6654

block_.L_4a66b8:                                  ; preds = %block_.L_4a6654
  %17081 = add i64 %16872, -48
  %17082 = add i64 %16900, 8
  store i64 %17082, i64* %3, align 8
  %17083 = inttoptr i64 %17081 to i32*
  %17084 = load i32, i32* %17083, align 4
  %17085 = add i32 %17084, 1
  %17086 = zext i32 %17085 to i64
  store i64 %17086, i64* %RAX.i1763, align 8
  %17087 = icmp eq i32 %17084, -1
  %17088 = icmp eq i32 %17085, 0
  %17089 = or i1 %17087, %17088
  %17090 = zext i1 %17089 to i8
  store i8 %17090, i8* %18, align 1
  %17091 = and i32 %17085, 255
  %17092 = tail call i32 @llvm.ctpop.i32(i32 %17091)
  %17093 = trunc i32 %17092 to i8
  %17094 = and i8 %17093, 1
  %17095 = xor i8 %17094, 1
  store i8 %17095, i8* %19, align 1
  %17096 = xor i32 %17085, %17084
  %17097 = lshr i32 %17096, 4
  %17098 = trunc i32 %17097 to i8
  %17099 = and i8 %17098, 1
  store i8 %17099, i8* %20, align 1
  %17100 = zext i1 %17088 to i8
  store i8 %17100, i8* %21, align 1
  %17101 = lshr i32 %17085, 31
  %17102 = trunc i32 %17101 to i8
  store i8 %17102, i8* %22, align 1
  %17103 = lshr i32 %17084, 31
  %17104 = xor i32 %17101, %17103
  %17105 = add nuw nsw i32 %17104, %17101
  %17106 = icmp eq i32 %17105, 2
  %17107 = zext i1 %17106 to i8
  store i8 %17107, i8* %23, align 1
  %17108 = add i64 %16900, 14
  store i64 %17108, i64* %3, align 8
  store i32 %17085, i32* %17083, align 4
  %17109 = load i64, i64* %3, align 8
  %17110 = add i64 %17109, -131
  store i64 %17110, i64* %3, align 8
  br label %block_.L_4a6643

block_.L_4a66cb:                                  ; preds = %block_.L_4a6643
  store i64 0, i64* %RDI.i2141, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %17111 = add i64 %16839, -12
  %17112 = add i64 %16867, 5
  store i64 %17112, i64* %3, align 8
  %17113 = inttoptr i64 %17111 to i32*
  %17114 = load i32, i32* %17113, align 4
  %17115 = add i32 %17114, 4
  %17116 = zext i32 %17115 to i64
  store i64 %17116, i64* %RAX.i1763, align 8
  %17117 = icmp ugt i32 %17114, -5
  %17118 = zext i1 %17117 to i8
  store i8 %17118, i8* %18, align 1
  %17119 = and i32 %17115, 255
  %17120 = tail call i32 @llvm.ctpop.i32(i32 %17119)
  %17121 = trunc i32 %17120 to i8
  %17122 = and i8 %17121, 1
  %17123 = xor i8 %17122, 1
  store i8 %17123, i8* %19, align 1
  %17124 = xor i32 %17115, %17114
  %17125 = lshr i32 %17124, 4
  %17126 = trunc i32 %17125 to i8
  %17127 = and i8 %17126, 1
  store i8 %17127, i8* %20, align 1
  %17128 = icmp eq i32 %17115, 0
  %17129 = zext i1 %17128 to i8
  store i8 %17129, i8* %21, align 1
  %17130 = lshr i32 %17115, 31
  %17131 = trunc i32 %17130 to i8
  store i8 %17131, i8* %22, align 1
  %17132 = lshr i32 %17114, 31
  %17133 = xor i32 %17130, %17132
  %17134 = add nuw nsw i32 %17133, %17130
  %17135 = icmp eq i32 %17134, 2
  %17136 = zext i1 %17135 to i8
  store i8 %17136, i8* %23, align 1
  %17137 = add i64 %16839, -628
  %17138 = add i64 %16867, 14
  store i64 %17138, i64* %3, align 8
  %17139 = inttoptr i64 %17137 to i32*
  %17140 = load i32, i32* %17139, align 4
  %17141 = zext i32 %17140 to i64
  store i64 %17141, i64* %RDX.i1805, align 8
  store i64 %17116, i64* %RSI.i1889, align 8
  %17142 = add i64 %16867, -637451
  %17143 = add i64 %16867, 21
  %17144 = load i64, i64* %6, align 8
  %17145 = add i64 %17144, -8
  %17146 = inttoptr i64 %17145 to i64*
  store i64 %17143, i64* %17146, align 8
  store i64 %17145, i64* %6, align 8
  store i64 %17142, i64* %3, align 8
  %call2_4a66db = tail call %struct.Memory* @sub_40acc0.dct_chroma4x4(%struct.State* nonnull %0, i64 %17142, %struct.Memory* %16814)
  %17147 = load i64, i64* %3, align 8
  store i64 2, i64* %RDX.i1805, align 8
  store i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64* %RCX.i1692, align 8
  store i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64* %26, align 8
  store i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64* %R9.i, align 8
  %17148 = load i64, i64* %RBP.i, align 8
  %17149 = add i64 %17148, -12
  %17150 = add i64 %17147, 38
  store i64 %17150, i64* %3, align 8
  %17151 = inttoptr i64 %17149 to i32*
  %17152 = load i32, i32* %17151, align 4
  %17153 = zext i32 %17152 to i64
  store i64 %17153, i64* %RSI.i1889, align 8
  %17154 = add i64 %17148, -1364
  %17155 = load i32, i32* %EAX.i2159, align 4
  %17156 = add i64 %17147, 44
  store i64 %17156, i64* %3, align 8
  %17157 = inttoptr i64 %17154 to i32*
  store i32 %17155, i32* %17157, align 4
  %17158 = load i32, i32* %ESI.i7670, align 4
  %17159 = zext i32 %17158 to i64
  %17160 = load i64, i64* %3, align 8
  store i64 %17159, i64* %RAX.i1763, align 8
  %17161 = load i64, i64* %RBP.i, align 8
  %17162 = add i64 %17161, -1368
  %17163 = load i32, i32* %EDX.i2206, align 4
  %17164 = add i64 %17160, 8
  store i64 %17164, i64* %3, align 8
  %17165 = inttoptr i64 %17162 to i32*
  store i32 %17163, i32* %17165, align 4
  %17166 = load i64, i64* %3, align 8
  %17167 = load i32, i32* %EAX.i2159, align 8
  %17168 = sext i32 %17167 to i64
  %17169 = lshr i64 %17168, 32
  store i64 %17169, i64* %101, align 8
  %17170 = load i64, i64* %RBP.i, align 8
  %17171 = add i64 %17170, -1368
  %17172 = add i64 %17166, 7
  store i64 %17172, i64* %3, align 8
  %17173 = inttoptr i64 %17171 to i32*
  %17174 = load i32, i32* %17173, align 4
  %17175 = zext i32 %17174 to i64
  store i64 %17175, i64* %RSI.i1889, align 8
  %17176 = add i64 %17166, 9
  store i64 %17176, i64* %3, align 8
  %17177 = zext i32 %17167 to i64
  %17178 = sext i32 %17174 to i64
  %17179 = shl nuw i64 %17169, 32
  %17180 = or i64 %17179, %17177
  %17181 = sdiv i64 %17180, %17178
  %17182 = shl i64 %17181, 32
  %17183 = ashr exact i64 %17182, 32
  %17184 = icmp eq i64 %17181, %17183
  br i1 %17184, label %17187, label %17185

; <label>:17185:                                  ; preds = %block_.L_4a66cb
  %17186 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17176, %struct.Memory* %call2_4a66db)
  %.pre561 = load i64, i64* %RDX.i1805, align 8
  %.pre562 = load i64, i64* %3, align 8
  %.pre563 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2337

; <label>:17187:                                  ; preds = %block_.L_4a66cb
  %17188 = srem i64 %17180, %17178
  %17189 = and i64 %17181, 4294967295
  store i64 %17189, i64* %RAX.i1763, align 8
  %17190 = and i64 %17188, 4294967295
  store i64 %17190, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit2337

routine_idivl__esi.exit2337:                      ; preds = %17187, %17185
  %17191 = phi i64 [ %.pre563, %17185 ], [ %17170, %17187 ]
  %17192 = phi i64 [ %.pre562, %17185 ], [ %17176, %17187 ]
  %17193 = phi i64 [ %.pre561, %17185 ], [ %17190, %17187 ]
  %17194 = phi %struct.Memory* [ %17186, %17185 ], [ %call2_4a66db, %17187 ]
  %17195 = trunc i64 %17193 to i32
  %17196 = shl i32 %17195, 1
  %17197 = icmp slt i32 %17195, 0
  %17198 = icmp slt i32 %17196, 0
  %17199 = xor i1 %17197, %17198
  %17200 = zext i32 %17196 to i64
  store i64 %17200, i64* %RDX.i1805, align 8
  %.lobit262 = lshr i32 %17195, 31
  %17201 = trunc i32 %.lobit262 to i8
  store i8 %17201, i8* %18, align 1
  %17202 = and i32 %17196, 254
  %17203 = tail call i32 @llvm.ctpop.i32(i32 %17202)
  %17204 = trunc i32 %17203 to i8
  %17205 = and i8 %17204, 1
  %17206 = xor i8 %17205, 1
  store i8 %17206, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %17207 = icmp eq i32 %17196, 0
  %17208 = zext i1 %17207 to i8
  store i8 %17208, i8* %21, align 1
  %17209 = lshr i32 %17195, 30
  %17210 = trunc i32 %17209 to i8
  %17211 = and i8 %17210, 1
  store i8 %17211, i8* %22, align 1
  %17212 = zext i1 %17199 to i8
  store i8 %17212, i8* %23, align 1
  %17213 = add i64 %17191, -628
  %17214 = add i64 %17192, 8
  store i64 %17214, i64* %3, align 8
  %17215 = inttoptr i64 %17213 to i32*
  %17216 = load i32, i32* %17215, align 4
  %17217 = zext i32 %17216 to i64
  store i64 %17217, i64* %RDI.i2141, align 8
  store i64 %17217, i64* %RAX.i1763, align 8
  %17218 = add i64 %17191, -1372
  %17219 = add i64 %17192, 16
  store i64 %17219, i64* %3, align 8
  %17220 = inttoptr i64 %17218 to i32*
  store i32 %17196, i32* %17220, align 4
  %17221 = load i64, i64* %3, align 8
  %17222 = load i32, i32* %EAX.i2159, align 8
  %17223 = sext i32 %17222 to i64
  %17224 = lshr i64 %17223, 32
  store i64 %17224, i64* %101, align 8
  %17225 = load i32, i32* %ESI.i7670, align 4
  %17226 = add i64 %17221, 3
  store i64 %17226, i64* %3, align 8
  %17227 = zext i32 %17222 to i64
  %17228 = sext i32 %17225 to i64
  %17229 = shl nuw i64 %17224, 32
  %17230 = or i64 %17229, %17227
  %17231 = sdiv i64 %17230, %17228
  %17232 = shl i64 %17231, 32
  %17233 = ashr exact i64 %17232, 32
  %17234 = icmp eq i64 %17231, %17233
  br i1 %17234, label %17237, label %17235

; <label>:17235:                                  ; preds = %routine_idivl__esi.exit2337
  %17236 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17226, %struct.Memory* %17194)
  %.pre564 = load i64, i64* %3, align 8
  %.pre565 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__esi.exit2319

; <label>:17237:                                  ; preds = %routine_idivl__esi.exit2337
  %17238 = srem i64 %17230, %17228
  %17239 = and i64 %17231, 4294967295
  store i64 %17239, i64* %RAX.i1763, align 8
  %17240 = and i64 %17238, 4294967295
  store i64 %17240, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %17241 = trunc i64 %17238 to i32
  br label %routine_idivl__esi.exit2319

routine_idivl__esi.exit2319:                      ; preds = %17237, %17235
  %17242 = phi i32 [ %.pre565, %17235 ], [ %17241, %17237 ]
  %17243 = phi i64 [ %.pre564, %17235 ], [ %17226, %17237 ]
  %17244 = phi %struct.Memory* [ %17236, %17235 ], [ %17194, %17237 ]
  %17245 = load i64, i64* %RBP.i, align 8
  %17246 = add i64 %17245, -1372
  %17247 = add i64 %17243, 6
  store i64 %17247, i64* %3, align 8
  %17248 = inttoptr i64 %17246 to i32*
  %17249 = load i32, i32* %17248, align 4
  %17250 = add i32 %17242, %17249
  %17251 = zext i32 %17250 to i64
  store i64 %17251, i64* %RDI.i2141, align 8
  %17252 = sext i32 %17250 to i64
  %17253 = shl nsw i64 %17252, 4
  store i64 %17253, i64* %372, align 8
  %17254 = load i64, i64* %R9.i, align 8
  %17255 = add i64 %17253, %17254
  store i64 %17255, i64* %R9.i, align 8
  %17256 = icmp ult i64 %17255, %17254
  %17257 = icmp ult i64 %17255, %17253
  %17258 = or i1 %17256, %17257
  %17259 = zext i1 %17258 to i8
  store i8 %17259, i8* %18, align 1
  %17260 = trunc i64 %17255 to i32
  %17261 = and i32 %17260, 255
  %17262 = tail call i32 @llvm.ctpop.i32(i32 %17261)
  %17263 = trunc i32 %17262 to i8
  %17264 = and i8 %17263, 1
  %17265 = xor i8 %17264, 1
  store i8 %17265, i8* %19, align 1
  %17266 = xor i64 %17253, %17254
  %17267 = xor i64 %17266, %17255
  %17268 = lshr i64 %17267, 4
  %17269 = trunc i64 %17268 to i8
  %17270 = and i8 %17269, 1
  store i8 %17270, i8* %20, align 1
  %17271 = icmp eq i64 %17255, 0
  %17272 = zext i1 %17271 to i8
  store i8 %17272, i8* %21, align 1
  %17273 = lshr i64 %17255, 63
  %17274 = trunc i64 %17273 to i8
  store i8 %17274, i8* %22, align 1
  %17275 = lshr i64 %17254, 63
  %17276 = lshr i64 %17252, 59
  %17277 = and i64 %17276, 1
  %17278 = xor i64 %17273, %17275
  %17279 = xor i64 %17273, %17277
  %17280 = add nuw nsw i64 %17278, %17279
  %17281 = icmp eq i64 %17280, 2
  %17282 = zext i1 %17281 to i8
  store i8 %17282, i8* %23, align 1
  %17283 = load i64, i64* %RBP.i, align 8
  %17284 = add i64 %17283, -12
  %17285 = add i64 %17243, 21
  store i64 %17285, i64* %3, align 8
  %17286 = inttoptr i64 %17284 to i32*
  %17287 = load i32, i32* %17286, align 4
  %17288 = zext i32 %17287 to i64
  store i64 %17288, i64* %RAX.i1763, align 8
  %17289 = sext i32 %17287 to i64
  %17290 = lshr i64 %17289, 32
  store i64 %17290, i64* %101, align 8
  %17291 = load i32, i32* %ESI.i7670, align 4
  %17292 = add i64 %17243, 26
  store i64 %17292, i64* %3, align 8
  %17293 = sext i32 %17291 to i64
  %17294 = shl nuw i64 %17290, 32
  %17295 = or i64 %17294, %17288
  %17296 = sdiv i64 %17295, %17293
  %17297 = shl i64 %17296, 32
  %17298 = ashr exact i64 %17297, 32
  %17299 = icmp eq i64 %17296, %17298
  br i1 %17299, label %17302, label %17300

; <label>:17300:                                  ; preds = %routine_idivl__esi.exit2319
  %17301 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17292, %struct.Memory* %17244)
  %.pre566 = load i64, i64* %RAX.i1763, align 8
  %.pre567 = load i64, i64* %3, align 8
  %.pre568 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2292

; <label>:17302:                                  ; preds = %routine_idivl__esi.exit2319
  %17303 = srem i64 %17295, %17293
  %17304 = and i64 %17296, 4294967295
  store i64 %17304, i64* %RAX.i1763, align 8
  %17305 = and i64 %17303, 4294967295
  store i64 %17305, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit2292

routine_idivl__esi.exit2292:                      ; preds = %17302, %17300
  %17306 = phi i64 [ %.pre568, %17300 ], [ %17283, %17302 ]
  %17307 = phi i64 [ %.pre567, %17300 ], [ %17292, %17302 ]
  %17308 = phi i64 [ %.pre566, %17300 ], [ %17304, %17302 ]
  %17309 = phi %struct.Memory* [ %17301, %17300 ], [ %17244, %17302 ]
  %17310 = trunc i64 %17308 to i32
  %17311 = shl i32 %17310, 1
  %17312 = icmp slt i32 %17310, 0
  %17313 = icmp slt i32 %17311, 0
  %17314 = xor i1 %17312, %17313
  %17315 = zext i32 %17311 to i64
  store i64 %17315, i64* %RAX.i1763, align 8
  %.lobit264 = lshr i32 %17310, 31
  %17316 = trunc i32 %.lobit264 to i8
  store i8 %17316, i8* %18, align 1
  %17317 = and i32 %17311, 254
  %17318 = tail call i32 @llvm.ctpop.i32(i32 %17317)
  %17319 = trunc i32 %17318 to i8
  %17320 = and i8 %17319, 1
  %17321 = xor i8 %17320, 1
  store i8 %17321, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %17322 = icmp eq i32 %17311, 0
  %17323 = zext i1 %17322 to i8
  store i8 %17323, i8* %21, align 1
  %17324 = lshr i32 %17310, 30
  %17325 = trunc i32 %17324 to i8
  %17326 = and i8 %17325, 1
  store i8 %17326, i8* %22, align 1
  %17327 = zext i1 %17314 to i8
  store i8 %17327, i8* %23, align 1
  %17328 = add i64 %17306, -628
  %17329 = add i64 %17307, 8
  store i64 %17329, i64* %3, align 8
  %17330 = inttoptr i64 %17328 to i32*
  %17331 = load i32, i32* %17330, align 4
  %17332 = zext i32 %17331 to i64
  store i64 %17332, i64* %RDI.i2141, align 8
  %17333 = add i64 %17306, -1376
  %17334 = add i64 %17307, 14
  store i64 %17334, i64* %3, align 8
  %17335 = inttoptr i64 %17333 to i32*
  store i32 %17311, i32* %17335, align 4
  %17336 = load i32, i32* %EDI.i1845, align 4
  %17337 = zext i32 %17336 to i64
  %17338 = load i64, i64* %3, align 8
  store i64 %17337, i64* %RAX.i1763, align 8
  %17339 = sext i32 %17336 to i64
  %17340 = lshr i64 %17339, 32
  store i64 %17340, i64* %101, align 8
  %17341 = load i32, i32* %ESI.i7670, align 4
  %17342 = add i64 %17338, 5
  store i64 %17342, i64* %3, align 8
  %17343 = sext i32 %17341 to i64
  %17344 = shl nuw i64 %17340, 32
  %17345 = or i64 %17344, %17337
  %17346 = sdiv i64 %17345, %17343
  %17347 = shl i64 %17346, 32
  %17348 = ashr exact i64 %17347, 32
  %17349 = icmp eq i64 %17346, %17348
  br i1 %17349, label %17352, label %17350

; <label>:17350:                                  ; preds = %routine_idivl__esi.exit2292
  %17351 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17342, %struct.Memory* %17309)
  %.pre569 = load i64, i64* %3, align 8
  %.pre570 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__esi.exit2273

; <label>:17352:                                  ; preds = %routine_idivl__esi.exit2292
  %17353 = srem i64 %17345, %17343
  %17354 = and i64 %17346, 4294967295
  store i64 %17354, i64* %RAX.i1763, align 8
  %17355 = and i64 %17353, 4294967295
  store i64 %17355, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %17356 = trunc i64 %17346 to i32
  br label %routine_idivl__esi.exit2273

routine_idivl__esi.exit2273:                      ; preds = %17352, %17350
  %17357 = phi i32 [ %.pre570, %17350 ], [ %17356, %17352 ]
  %17358 = phi i64 [ %.pre569, %17350 ], [ %17342, %17352 ]
  %17359 = phi %struct.Memory* [ %17351, %17350 ], [ %17309, %17352 ]
  %17360 = load i64, i64* %RBP.i, align 8
  %17361 = add i64 %17360, -1376
  %17362 = add i64 %17358, 6
  store i64 %17362, i64* %3, align 8
  %17363 = inttoptr i64 %17361 to i32*
  %17364 = load i32, i32* %17363, align 4
  %17365 = add i32 %17357, %17364
  %17366 = zext i32 %17365 to i64
  store i64 %17366, i64* %RDI.i2141, align 8
  %17367 = icmp ult i32 %17365, %17364
  %17368 = icmp ult i32 %17365, %17357
  %17369 = or i1 %17367, %17368
  %17370 = zext i1 %17369 to i8
  store i8 %17370, i8* %18, align 1
  %17371 = and i32 %17365, 255
  %17372 = tail call i32 @llvm.ctpop.i32(i32 %17371)
  %17373 = trunc i32 %17372 to i8
  %17374 = and i8 %17373, 1
  %17375 = xor i8 %17374, 1
  store i8 %17375, i8* %19, align 1
  %17376 = xor i32 %17357, %17364
  %17377 = xor i32 %17376, %17365
  %17378 = lshr i32 %17377, 4
  %17379 = trunc i32 %17378 to i8
  %17380 = and i8 %17379, 1
  store i8 %17380, i8* %20, align 1
  %17381 = icmp eq i32 %17365, 0
  %17382 = zext i1 %17381 to i8
  store i8 %17382, i8* %21, align 1
  %17383 = lshr i32 %17365, 31
  %17384 = trunc i32 %17383 to i8
  store i8 %17384, i8* %22, align 1
  %17385 = lshr i32 %17364, 31
  %17386 = lshr i32 %17357, 31
  %17387 = xor i32 %17383, %17385
  %17388 = xor i32 %17383, %17386
  %17389 = add nuw nsw i32 %17387, %17388
  %17390 = icmp eq i32 %17389, 2
  %17391 = zext i1 %17390 to i8
  store i8 %17391, i8* %23, align 1
  %17392 = sext i32 %17365 to i64
  store i64 %17392, i64* %372, align 8
  %17393 = add i64 %17360, -1364
  %17394 = add i64 %17358, 17
  store i64 %17394, i64* %3, align 8
  %17395 = inttoptr i64 %17393 to i32*
  %17396 = load i32, i32* %17395, align 4
  %17397 = zext i32 %17396 to i64
  store i64 %17397, i64* %RAX.i1763, align 8
  %17398 = load i64, i64* %R9.i, align 8
  %17399 = shl nsw i64 %17392, 2
  %17400 = add i64 %17399, %17398
  %17401 = add i64 %17358, 21
  store i64 %17401, i64* %3, align 8
  %17402 = inttoptr i64 %17400 to i32*
  store i32 %17396, i32* %17402, align 4
  %17403 = load i64, i64* %RBP.i, align 8
  %17404 = add i64 %17403, -12
  %17405 = load i64, i64* %3, align 8
  %17406 = add i64 %17405, 3
  store i64 %17406, i64* %3, align 8
  %17407 = inttoptr i64 %17404 to i32*
  %17408 = load i32, i32* %17407, align 4
  %17409 = zext i32 %17408 to i64
  store i64 %17409, i64* %RAX.i1763, align 8
  %17410 = sext i32 %17408 to i64
  %17411 = lshr i64 %17410, 32
  store i64 %17411, i64* %101, align 8
  %17412 = load i32, i32* %ESI.i7670, align 4
  %17413 = add i64 %17405, 6
  store i64 %17413, i64* %3, align 8
  %17414 = sext i32 %17412 to i64
  %17415 = shl nuw i64 %17411, 32
  %17416 = or i64 %17415, %17409
  %17417 = sdiv i64 %17416, %17414
  %17418 = shl i64 %17417, 32
  %17419 = ashr exact i64 %17418, 32
  %17420 = icmp eq i64 %17417, %17419
  br i1 %17420, label %17423, label %17421

; <label>:17421:                                  ; preds = %routine_idivl__esi.exit2273
  %17422 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17413, %struct.Memory* %17359)
  %.pre571 = load i64, i64* %RDX.i1805, align 8
  %.pre572 = load i64, i64* %3, align 8
  %.pre573 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2247

; <label>:17423:                                  ; preds = %routine_idivl__esi.exit2273
  %17424 = srem i64 %17416, %17414
  %17425 = and i64 %17417, 4294967295
  store i64 %17425, i64* %RAX.i1763, align 8
  %17426 = and i64 %17424, 4294967295
  store i64 %17426, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit2247

routine_idivl__esi.exit2247:                      ; preds = %17423, %17421
  %17427 = phi i64 [ %.pre573, %17421 ], [ %17403, %17423 ]
  %17428 = phi i64 [ %.pre572, %17421 ], [ %17413, %17423 ]
  %17429 = phi i64 [ %.pre571, %17421 ], [ %17426, %17423 ]
  %17430 = phi %struct.Memory* [ %17422, %17421 ], [ %17359, %17423 ]
  %17431 = trunc i64 %17429 to i32
  %17432 = shl i32 %17431, 1
  %17433 = icmp slt i32 %17431, 0
  %17434 = icmp slt i32 %17432, 0
  %17435 = xor i1 %17433, %17434
  %17436 = zext i32 %17432 to i64
  store i64 %17436, i64* %RDX.i1805, align 8
  %.lobit265 = lshr i32 %17431, 31
  %17437 = trunc i32 %.lobit265 to i8
  store i8 %17437, i8* %18, align 1
  %17438 = and i32 %17432, 254
  %17439 = tail call i32 @llvm.ctpop.i32(i32 %17438)
  %17440 = trunc i32 %17439 to i8
  %17441 = and i8 %17440, 1
  %17442 = xor i8 %17441, 1
  store i8 %17442, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %17443 = icmp eq i32 %17432, 0
  %17444 = zext i1 %17443 to i8
  store i8 %17444, i8* %21, align 1
  %17445 = lshr i32 %17431, 30
  %17446 = trunc i32 %17445 to i8
  %17447 = and i8 %17446, 1
  store i8 %17447, i8* %22, align 1
  %17448 = zext i1 %17435 to i8
  store i8 %17448, i8* %23, align 1
  %17449 = add i64 %17427, -628
  %17450 = add i64 %17428, 8
  store i64 %17450, i64* %3, align 8
  %17451 = inttoptr i64 %17449 to i32*
  %17452 = load i32, i32* %17451, align 4
  %17453 = zext i32 %17452 to i64
  store i64 %17453, i64* %RDI.i2141, align 8
  store i64 %17453, i64* %RAX.i1763, align 8
  %17454 = add i64 %17427, -1380
  %17455 = add i64 %17428, 16
  store i64 %17455, i64* %3, align 8
  %17456 = inttoptr i64 %17454 to i32*
  store i32 %17432, i32* %17456, align 4
  %17457 = load i64, i64* %3, align 8
  %17458 = load i32, i32* %EAX.i2159, align 8
  %17459 = sext i32 %17458 to i64
  %17460 = lshr i64 %17459, 32
  store i64 %17460, i64* %101, align 8
  %17461 = load i32, i32* %ESI.i7670, align 4
  %17462 = add i64 %17457, 3
  store i64 %17462, i64* %3, align 8
  %17463 = zext i32 %17458 to i64
  %17464 = sext i32 %17461 to i64
  %17465 = shl nuw i64 %17460, 32
  %17466 = or i64 %17465, %17463
  %17467 = sdiv i64 %17466, %17464
  %17468 = shl i64 %17467, 32
  %17469 = ashr exact i64 %17468, 32
  %17470 = icmp eq i64 %17467, %17469
  br i1 %17470, label %17473, label %17471

; <label>:17471:                                  ; preds = %routine_idivl__esi.exit2247
  %17472 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17462, %struct.Memory* %17430)
  %.pre574 = load i64, i64* %3, align 8
  %.pre575 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__esi.exit2231

; <label>:17473:                                  ; preds = %routine_idivl__esi.exit2247
  %17474 = srem i64 %17466, %17464
  %17475 = and i64 %17467, 4294967295
  store i64 %17475, i64* %RAX.i1763, align 8
  %17476 = and i64 %17474, 4294967295
  store i64 %17476, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %17477 = trunc i64 %17474 to i32
  br label %routine_idivl__esi.exit2231

routine_idivl__esi.exit2231:                      ; preds = %17473, %17471
  %17478 = phi i32 [ %.pre575, %17471 ], [ %17477, %17473 ]
  %17479 = phi i64 [ %.pre574, %17471 ], [ %17462, %17473 ]
  %17480 = phi %struct.Memory* [ %17472, %17471 ], [ %17430, %17473 ]
  %17481 = load i64, i64* %RBP.i, align 8
  %17482 = add i64 %17481, -1380
  %17483 = add i64 %17479, 6
  store i64 %17483, i64* %3, align 8
  %17484 = inttoptr i64 %17482 to i32*
  %17485 = load i32, i32* %17484, align 4
  %17486 = add i32 %17478, %17485
  %17487 = zext i32 %17486 to i64
  store i64 %17487, i64* %RDI.i2141, align 8
  %17488 = sext i32 %17486 to i64
  %17489 = shl nsw i64 %17488, 4
  store i64 %17489, i64* %R9.i, align 8
  %17490 = load i64, i64* %26, align 8
  %17491 = add i64 %17489, %17490
  store i64 %17491, i64* %26, align 8
  %17492 = icmp ult i64 %17491, %17490
  %17493 = icmp ult i64 %17491, %17489
  %17494 = or i1 %17492, %17493
  %17495 = zext i1 %17494 to i8
  store i8 %17495, i8* %18, align 1
  %17496 = trunc i64 %17491 to i32
  %17497 = and i32 %17496, 255
  %17498 = tail call i32 @llvm.ctpop.i32(i32 %17497)
  %17499 = trunc i32 %17498 to i8
  %17500 = and i8 %17499, 1
  %17501 = xor i8 %17500, 1
  store i8 %17501, i8* %19, align 1
  %17502 = xor i64 %17489, %17490
  %17503 = xor i64 %17502, %17491
  %17504 = lshr i64 %17503, 4
  %17505 = trunc i64 %17504 to i8
  %17506 = and i8 %17505, 1
  store i8 %17506, i8* %20, align 1
  %17507 = icmp eq i64 %17491, 0
  %17508 = zext i1 %17507 to i8
  store i8 %17508, i8* %21, align 1
  %17509 = lshr i64 %17491, 63
  %17510 = trunc i64 %17509 to i8
  store i8 %17510, i8* %22, align 1
  %17511 = lshr i64 %17490, 63
  %17512 = lshr i64 %17488, 59
  %17513 = and i64 %17512, 1
  %17514 = xor i64 %17509, %17511
  %17515 = xor i64 %17509, %17513
  %17516 = add nuw nsw i64 %17514, %17515
  %17517 = icmp eq i64 %17516, 2
  %17518 = zext i1 %17517 to i8
  store i8 %17518, i8* %23, align 1
  %17519 = load i64, i64* %RBP.i, align 8
  %17520 = add i64 %17519, -12
  %17521 = add i64 %17479, 21
  store i64 %17521, i64* %3, align 8
  %17522 = inttoptr i64 %17520 to i32*
  %17523 = load i32, i32* %17522, align 4
  %17524 = zext i32 %17523 to i64
  store i64 %17524, i64* %RAX.i1763, align 8
  %17525 = sext i32 %17523 to i64
  %17526 = lshr i64 %17525, 32
  store i64 %17526, i64* %101, align 8
  %17527 = load i32, i32* %ESI.i7670, align 4
  %17528 = add i64 %17479, 26
  store i64 %17528, i64* %3, align 8
  %17529 = sext i32 %17527 to i64
  %17530 = shl nuw i64 %17526, 32
  %17531 = or i64 %17530, %17524
  %17532 = sdiv i64 %17531, %17529
  %17533 = shl i64 %17532, 32
  %17534 = ashr exact i64 %17533, 32
  %17535 = icmp eq i64 %17532, %17534
  br i1 %17535, label %17538, label %17536

; <label>:17536:                                  ; preds = %routine_idivl__esi.exit2231
  %17537 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17528, %struct.Memory* %17480)
  %.pre576 = load i64, i64* %RAX.i1763, align 8
  %.pre577 = load i64, i64* %3, align 8
  %.pre578 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2204

; <label>:17538:                                  ; preds = %routine_idivl__esi.exit2231
  %17539 = srem i64 %17531, %17529
  %17540 = and i64 %17532, 4294967295
  store i64 %17540, i64* %RAX.i1763, align 8
  %17541 = and i64 %17539, 4294967295
  store i64 %17541, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit2204

routine_idivl__esi.exit2204:                      ; preds = %17538, %17536
  %17542 = phi i64 [ %.pre578, %17536 ], [ %17519, %17538 ]
  %17543 = phi i64 [ %.pre577, %17536 ], [ %17528, %17538 ]
  %17544 = phi i64 [ %.pre576, %17536 ], [ %17540, %17538 ]
  %17545 = phi %struct.Memory* [ %17537, %17536 ], [ %17480, %17538 ]
  %17546 = trunc i64 %17544 to i32
  %17547 = shl i32 %17546, 1
  %17548 = icmp slt i32 %17546, 0
  %17549 = icmp slt i32 %17547, 0
  %17550 = xor i1 %17548, %17549
  %17551 = zext i32 %17547 to i64
  store i64 %17551, i64* %RAX.i1763, align 8
  %.lobit267 = lshr i32 %17546, 31
  %17552 = trunc i32 %.lobit267 to i8
  store i8 %17552, i8* %18, align 1
  %17553 = and i32 %17547, 254
  %17554 = tail call i32 @llvm.ctpop.i32(i32 %17553)
  %17555 = trunc i32 %17554 to i8
  %17556 = and i8 %17555, 1
  %17557 = xor i8 %17556, 1
  store i8 %17557, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %17558 = icmp eq i32 %17547, 0
  %17559 = zext i1 %17558 to i8
  store i8 %17559, i8* %21, align 1
  %17560 = lshr i32 %17546, 30
  %17561 = trunc i32 %17560 to i8
  %17562 = and i8 %17561, 1
  store i8 %17562, i8* %22, align 1
  %17563 = zext i1 %17550 to i8
  store i8 %17563, i8* %23, align 1
  %17564 = add i64 %17542, -628
  %17565 = add i64 %17543, 8
  store i64 %17565, i64* %3, align 8
  %17566 = inttoptr i64 %17564 to i32*
  %17567 = load i32, i32* %17566, align 4
  %17568 = zext i32 %17567 to i64
  store i64 %17568, i64* %RDI.i2141, align 8
  %17569 = add i64 %17542, -1384
  %17570 = add i64 %17543, 14
  store i64 %17570, i64* %3, align 8
  %17571 = inttoptr i64 %17569 to i32*
  store i32 %17547, i32* %17571, align 4
  %17572 = load i32, i32* %EDI.i1845, align 4
  %17573 = zext i32 %17572 to i64
  %17574 = load i64, i64* %3, align 8
  store i64 %17573, i64* %RAX.i1763, align 8
  %17575 = sext i32 %17572 to i64
  %17576 = lshr i64 %17575, 32
  store i64 %17576, i64* %101, align 8
  %17577 = load i32, i32* %ESI.i7670, align 4
  %17578 = add i64 %17574, 5
  store i64 %17578, i64* %3, align 8
  %17579 = sext i32 %17577 to i64
  %17580 = shl nuw i64 %17576, 32
  %17581 = or i64 %17580, %17573
  %17582 = sdiv i64 %17581, %17579
  %17583 = shl i64 %17582, 32
  %17584 = ashr exact i64 %17583, 32
  %17585 = icmp eq i64 %17582, %17584
  br i1 %17585, label %17588, label %17586

; <label>:17586:                                  ; preds = %routine_idivl__esi.exit2204
  %17587 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17578, %struct.Memory* %17545)
  %.pre579 = load i64, i64* %3, align 8
  %.pre580 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__esi.exit2186

; <label>:17588:                                  ; preds = %routine_idivl__esi.exit2204
  %17589 = srem i64 %17581, %17579
  %17590 = and i64 %17582, 4294967295
  store i64 %17590, i64* %RAX.i1763, align 8
  %17591 = and i64 %17589, 4294967295
  store i64 %17591, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %17592 = trunc i64 %17582 to i32
  br label %routine_idivl__esi.exit2186

routine_idivl__esi.exit2186:                      ; preds = %17588, %17586
  %17593 = phi i32 [ %.pre580, %17586 ], [ %17592, %17588 ]
  %17594 = phi i64 [ %.pre579, %17586 ], [ %17578, %17588 ]
  %17595 = phi %struct.Memory* [ %17587, %17586 ], [ %17545, %17588 ]
  %17596 = load i64, i64* %RBP.i, align 8
  %17597 = add i64 %17596, -1384
  %17598 = add i64 %17594, 6
  store i64 %17598, i64* %3, align 8
  %17599 = inttoptr i64 %17597 to i32*
  %17600 = load i32, i32* %17599, align 4
  %17601 = add i32 %17593, %17600
  %17602 = zext i32 %17601 to i64
  store i64 %17602, i64* %RDI.i2141, align 8
  %17603 = icmp ult i32 %17601, %17600
  %17604 = icmp ult i32 %17601, %17593
  %17605 = or i1 %17603, %17604
  %17606 = zext i1 %17605 to i8
  store i8 %17606, i8* %18, align 1
  %17607 = and i32 %17601, 255
  %17608 = tail call i32 @llvm.ctpop.i32(i32 %17607)
  %17609 = trunc i32 %17608 to i8
  %17610 = and i8 %17609, 1
  %17611 = xor i8 %17610, 1
  store i8 %17611, i8* %19, align 1
  %17612 = xor i32 %17593, %17600
  %17613 = xor i32 %17612, %17601
  %17614 = lshr i32 %17613, 4
  %17615 = trunc i32 %17614 to i8
  %17616 = and i8 %17615, 1
  store i8 %17616, i8* %20, align 1
  %17617 = icmp eq i32 %17601, 0
  %17618 = zext i1 %17617 to i8
  store i8 %17618, i8* %21, align 1
  %17619 = lshr i32 %17601, 31
  %17620 = trunc i32 %17619 to i8
  store i8 %17620, i8* %22, align 1
  %17621 = lshr i32 %17600, 31
  %17622 = lshr i32 %17593, 31
  %17623 = xor i32 %17619, %17621
  %17624 = xor i32 %17619, %17622
  %17625 = add nuw nsw i32 %17623, %17624
  %17626 = icmp eq i32 %17625, 2
  %17627 = zext i1 %17626 to i8
  store i8 %17627, i8* %23, align 1
  %17628 = sext i32 %17601 to i64
  store i64 %17628, i64* %R9.i, align 8
  %17629 = load i64, i64* %26, align 8
  %17630 = shl nsw i64 %17628, 2
  %17631 = add i64 %17629, %17630
  %17632 = add i64 %17594, 15
  store i64 %17632, i64* %3, align 8
  %17633 = inttoptr i64 %17631 to i32*
  %17634 = load i32, i32* %17633, align 4
  %17635 = zext i32 %17634 to i64
  store i64 %17635, i64* %RAX.i1763, align 8
  %17636 = add i64 %17596, -12
  %17637 = add i64 %17594, 18
  store i64 %17637, i64* %3, align 8
  %17638 = inttoptr i64 %17636 to i32*
  %17639 = load i32, i32* %17638, align 4
  %17640 = zext i32 %17639 to i64
  store i64 %17640, i64* %RDI.i2141, align 8
  %17641 = add i64 %17596, -1388
  %17642 = add i64 %17594, 24
  store i64 %17642, i64* %3, align 8
  %17643 = inttoptr i64 %17641 to i32*
  store i32 %17634, i32* %17643, align 4
  %17644 = load i32, i32* %EDI.i1845, align 4
  %17645 = zext i32 %17644 to i64
  %17646 = load i64, i64* %3, align 8
  store i64 %17645, i64* %RAX.i1763, align 8
  %17647 = sext i32 %17644 to i64
  %17648 = lshr i64 %17647, 32
  store i64 %17648, i64* %101, align 8
  %17649 = load i32, i32* %ESI.i7670, align 4
  %17650 = add i64 %17646, 5
  store i64 %17650, i64* %3, align 8
  %17651 = sext i32 %17649 to i64
  %17652 = shl nuw i64 %17648, 32
  %17653 = or i64 %17652, %17645
  %17654 = sdiv i64 %17653, %17651
  %17655 = shl i64 %17654, 32
  %17656 = ashr exact i64 %17655, 32
  %17657 = icmp eq i64 %17654, %17656
  br i1 %17657, label %17660, label %17658

; <label>:17658:                                  ; preds = %routine_idivl__esi.exit2186
  %17659 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17650, %struct.Memory* %17595)
  %.pre581 = load i64, i64* %RDX.i1805, align 8
  %.pre582 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit2157

; <label>:17660:                                  ; preds = %routine_idivl__esi.exit2186
  %17661 = srem i64 %17653, %17651
  %17662 = and i64 %17654, 4294967295
  store i64 %17662, i64* %RAX.i1763, align 8
  %17663 = and i64 %17661, 4294967295
  store i64 %17663, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit2157

routine_idivl__esi.exit2157:                      ; preds = %17660, %17658
  %17664 = phi i64 [ %.pre582, %17658 ], [ %17650, %17660 ]
  %17665 = phi i64 [ %.pre581, %17658 ], [ %17663, %17660 ]
  %17666 = phi %struct.Memory* [ %17659, %17658 ], [ %17595, %17660 ]
  %17667 = trunc i64 %17665 to i32
  %17668 = shl i32 %17667, 1
  %17669 = icmp slt i32 %17667, 0
  %17670 = icmp slt i32 %17668, 0
  %17671 = xor i1 %17669, %17670
  %17672 = zext i32 %17668 to i64
  store i64 %17672, i64* %RDX.i1805, align 8
  %.lobit268 = lshr i32 %17667, 31
  %17673 = trunc i32 %.lobit268 to i8
  store i8 %17673, i8* %18, align 1
  %17674 = and i32 %17668, 254
  %17675 = tail call i32 @llvm.ctpop.i32(i32 %17674)
  %17676 = trunc i32 %17675 to i8
  %17677 = and i8 %17676, 1
  %17678 = xor i8 %17677, 1
  store i8 %17678, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %17679 = icmp eq i32 %17668, 0
  %17680 = zext i1 %17679 to i8
  store i8 %17680, i8* %21, align 1
  %17681 = lshr i32 %17667, 30
  %17682 = trunc i32 %17681 to i8
  %17683 = and i8 %17682, 1
  store i8 %17683, i8* %22, align 1
  %17684 = zext i1 %17671 to i8
  store i8 %17684, i8* %23, align 1
  %17685 = load i64, i64* %RBP.i, align 8
  %17686 = add i64 %17685, -628
  %17687 = add i64 %17664, 8
  store i64 %17687, i64* %3, align 8
  %17688 = inttoptr i64 %17686 to i32*
  %17689 = load i32, i32* %17688, align 4
  %17690 = zext i32 %17689 to i64
  store i64 %17690, i64* %RDI.i2141, align 8
  store i64 %17690, i64* %RAX.i1763, align 8
  %17691 = add i64 %17685, -1392
  %17692 = add i64 %17664, 16
  store i64 %17692, i64* %3, align 8
  %17693 = inttoptr i64 %17691 to i32*
  store i32 %17668, i32* %17693, align 4
  %17694 = load i64, i64* %3, align 8
  %17695 = load i32, i32* %EAX.i2159, align 8
  %17696 = sext i32 %17695 to i64
  %17697 = lshr i64 %17696, 32
  store i64 %17697, i64* %101, align 8
  %17698 = load i32, i32* %ESI.i7670, align 4
  %17699 = add i64 %17694, 3
  store i64 %17699, i64* %3, align 8
  %17700 = zext i32 %17695 to i64
  %17701 = sext i32 %17698 to i64
  %17702 = shl nuw i64 %17697, 32
  %17703 = or i64 %17702, %17700
  %17704 = sdiv i64 %17703, %17701
  %17705 = shl i64 %17704, 32
  %17706 = ashr exact i64 %17705, 32
  %17707 = icmp eq i64 %17704, %17706
  br i1 %17707, label %17710, label %17708

; <label>:17708:                                  ; preds = %routine_idivl__esi.exit2157
  %17709 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17699, %struct.Memory* %17666)
  %.pre583 = load i64, i64* %3, align 8
  %.pre584 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__esi.exit2139

; <label>:17710:                                  ; preds = %routine_idivl__esi.exit2157
  %17711 = srem i64 %17703, %17701
  %17712 = and i64 %17704, 4294967295
  store i64 %17712, i64* %RAX.i1763, align 8
  %17713 = and i64 %17711, 4294967295
  store i64 %17713, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %17714 = trunc i64 %17711 to i32
  br label %routine_idivl__esi.exit2139

routine_idivl__esi.exit2139:                      ; preds = %17710, %17708
  %17715 = phi i32 [ %.pre584, %17708 ], [ %17714, %17710 ]
  %17716 = phi i64 [ %.pre583, %17708 ], [ %17699, %17710 ]
  %17717 = phi %struct.Memory* [ %17709, %17708 ], [ %17666, %17710 ]
  %17718 = load i64, i64* %RBP.i, align 8
  %17719 = add i64 %17718, -1392
  %17720 = add i64 %17716, 6
  store i64 %17720, i64* %3, align 8
  %17721 = inttoptr i64 %17719 to i32*
  %17722 = load i32, i32* %17721, align 4
  %17723 = add i32 %17715, %17722
  %17724 = zext i32 %17723 to i64
  store i64 %17724, i64* %RDI.i2141, align 8
  %17725 = sext i32 %17723 to i64
  %17726 = shl nsw i64 %17725, 4
  store i64 %17726, i64* %26, align 8
  %17727 = load i64, i64* %RCX.i1692, align 8
  %17728 = add i64 %17726, %17727
  store i64 %17728, i64* %RCX.i1692, align 8
  %17729 = icmp ult i64 %17728, %17727
  %17730 = icmp ult i64 %17728, %17726
  %17731 = or i1 %17729, %17730
  %17732 = zext i1 %17731 to i8
  store i8 %17732, i8* %18, align 1
  %17733 = trunc i64 %17728 to i32
  %17734 = and i32 %17733, 255
  %17735 = tail call i32 @llvm.ctpop.i32(i32 %17734)
  %17736 = trunc i32 %17735 to i8
  %17737 = and i8 %17736, 1
  %17738 = xor i8 %17737, 1
  store i8 %17738, i8* %19, align 1
  %17739 = xor i64 %17726, %17727
  %17740 = xor i64 %17739, %17728
  %17741 = lshr i64 %17740, 4
  %17742 = trunc i64 %17741 to i8
  %17743 = and i8 %17742, 1
  store i8 %17743, i8* %20, align 1
  %17744 = icmp eq i64 %17728, 0
  %17745 = zext i1 %17744 to i8
  store i8 %17745, i8* %21, align 1
  %17746 = lshr i64 %17728, 63
  %17747 = trunc i64 %17746 to i8
  store i8 %17747, i8* %22, align 1
  %17748 = lshr i64 %17727, 63
  %17749 = lshr i64 %17725, 59
  %17750 = and i64 %17749, 1
  %17751 = xor i64 %17746, %17748
  %17752 = xor i64 %17746, %17750
  %17753 = add nuw nsw i64 %17751, %17752
  %17754 = icmp eq i64 %17753, 2
  %17755 = zext i1 %17754 to i8
  store i8 %17755, i8* %23, align 1
  %17756 = load i64, i64* %RBP.i, align 8
  %17757 = add i64 %17756, -12
  %17758 = add i64 %17716, 21
  store i64 %17758, i64* %3, align 8
  %17759 = inttoptr i64 %17757 to i32*
  %17760 = load i32, i32* %17759, align 4
  %17761 = zext i32 %17760 to i64
  store i64 %17761, i64* %RAX.i1763, align 8
  %17762 = sext i32 %17760 to i64
  %17763 = lshr i64 %17762, 32
  store i64 %17763, i64* %101, align 8
  %17764 = load i32, i32* %ESI.i7670, align 4
  %17765 = add i64 %17716, 26
  store i64 %17765, i64* %3, align 8
  %17766 = sext i32 %17764 to i64
  %17767 = shl nuw i64 %17763, 32
  %17768 = or i64 %17767, %17761
  %17769 = sdiv i64 %17768, %17766
  %17770 = shl i64 %17769, 32
  %17771 = ashr exact i64 %17770, 32
  %17772 = icmp eq i64 %17769, %17771
  br i1 %17772, label %17775, label %17773

; <label>:17773:                                  ; preds = %routine_idivl__esi.exit2139
  %17774 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17765, %struct.Memory* %17717)
  %.pre585 = load i64, i64* %RAX.i1763, align 8
  %.pre586 = load i64, i64* %3, align 8
  %.pre587 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2112

; <label>:17775:                                  ; preds = %routine_idivl__esi.exit2139
  %17776 = srem i64 %17768, %17766
  %17777 = and i64 %17769, 4294967295
  store i64 %17777, i64* %RAX.i1763, align 8
  %17778 = and i64 %17776, 4294967295
  store i64 %17778, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit2112

routine_idivl__esi.exit2112:                      ; preds = %17775, %17773
  %17779 = phi i64 [ %.pre587, %17773 ], [ %17756, %17775 ]
  %17780 = phi i64 [ %.pre586, %17773 ], [ %17765, %17775 ]
  %17781 = phi i64 [ %.pre585, %17773 ], [ %17777, %17775 ]
  %17782 = phi %struct.Memory* [ %17774, %17773 ], [ %17717, %17775 ]
  %17783 = trunc i64 %17781 to i32
  %17784 = shl i32 %17783, 1
  %17785 = icmp slt i32 %17783, 0
  %17786 = icmp slt i32 %17784, 0
  %17787 = xor i1 %17785, %17786
  %17788 = zext i32 %17784 to i64
  store i64 %17788, i64* %RAX.i1763, align 8
  %.lobit270 = lshr i32 %17783, 31
  %17789 = trunc i32 %.lobit270 to i8
  store i8 %17789, i8* %18, align 1
  %17790 = and i32 %17784, 254
  %17791 = tail call i32 @llvm.ctpop.i32(i32 %17790)
  %17792 = trunc i32 %17791 to i8
  %17793 = and i8 %17792, 1
  %17794 = xor i8 %17793, 1
  store i8 %17794, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %17795 = icmp eq i32 %17784, 0
  %17796 = zext i1 %17795 to i8
  store i8 %17796, i8* %21, align 1
  %17797 = lshr i32 %17783, 30
  %17798 = trunc i32 %17797 to i8
  %17799 = and i8 %17798, 1
  store i8 %17799, i8* %22, align 1
  %17800 = zext i1 %17787 to i8
  store i8 %17800, i8* %23, align 1
  %17801 = add i64 %17779, -628
  %17802 = add i64 %17780, 8
  store i64 %17802, i64* %3, align 8
  %17803 = inttoptr i64 %17801 to i32*
  %17804 = load i32, i32* %17803, align 4
  %17805 = zext i32 %17804 to i64
  store i64 %17805, i64* %RDI.i2141, align 8
  %17806 = add i64 %17779, -1396
  %17807 = add i64 %17780, 14
  store i64 %17807, i64* %3, align 8
  %17808 = inttoptr i64 %17806 to i32*
  store i32 %17784, i32* %17808, align 4
  %17809 = load i32, i32* %EDI.i1845, align 4
  %17810 = zext i32 %17809 to i64
  %17811 = load i64, i64* %3, align 8
  store i64 %17810, i64* %RAX.i1763, align 8
  %17812 = sext i32 %17809 to i64
  %17813 = lshr i64 %17812, 32
  store i64 %17813, i64* %101, align 8
  %17814 = load i32, i32* %ESI.i7670, align 4
  %17815 = add i64 %17811, 5
  store i64 %17815, i64* %3, align 8
  %17816 = sext i32 %17814 to i64
  %17817 = shl nuw i64 %17813, 32
  %17818 = or i64 %17817, %17810
  %17819 = sdiv i64 %17818, %17816
  %17820 = shl i64 %17819, 32
  %17821 = ashr exact i64 %17820, 32
  %17822 = icmp eq i64 %17819, %17821
  br i1 %17822, label %17825, label %17823

; <label>:17823:                                  ; preds = %routine_idivl__esi.exit2112
  %17824 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17815, %struct.Memory* %17782)
  %.pre588 = load i64, i64* %3, align 8
  %.pre589 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__esi.exit2095

; <label>:17825:                                  ; preds = %routine_idivl__esi.exit2112
  %17826 = srem i64 %17818, %17816
  %17827 = and i64 %17819, 4294967295
  store i64 %17827, i64* %RAX.i1763, align 8
  %17828 = and i64 %17826, 4294967295
  store i64 %17828, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %17829 = trunc i64 %17819 to i32
  br label %routine_idivl__esi.exit2095

routine_idivl__esi.exit2095:                      ; preds = %17825, %17823
  %17830 = phi i32 [ %.pre589, %17823 ], [ %17829, %17825 ]
  %17831 = phi i64 [ %.pre588, %17823 ], [ %17815, %17825 ]
  %17832 = phi %struct.Memory* [ %17824, %17823 ], [ %17782, %17825 ]
  %17833 = load i64, i64* %RBP.i, align 8
  %17834 = add i64 %17833, -1396
  %17835 = add i64 %17831, 6
  store i64 %17835, i64* %3, align 8
  %17836 = inttoptr i64 %17834 to i32*
  %17837 = load i32, i32* %17836, align 4
  %17838 = add i32 %17830, %17837
  %17839 = zext i32 %17838 to i64
  store i64 %17839, i64* %RDI.i2141, align 8
  %17840 = icmp ult i32 %17838, %17837
  %17841 = icmp ult i32 %17838, %17830
  %17842 = or i1 %17840, %17841
  %17843 = zext i1 %17842 to i8
  store i8 %17843, i8* %18, align 1
  %17844 = and i32 %17838, 255
  %17845 = tail call i32 @llvm.ctpop.i32(i32 %17844)
  %17846 = trunc i32 %17845 to i8
  %17847 = and i8 %17846, 1
  %17848 = xor i8 %17847, 1
  store i8 %17848, i8* %19, align 1
  %17849 = xor i32 %17830, %17837
  %17850 = xor i32 %17849, %17838
  %17851 = lshr i32 %17850, 4
  %17852 = trunc i32 %17851 to i8
  %17853 = and i8 %17852, 1
  store i8 %17853, i8* %20, align 1
  %17854 = icmp eq i32 %17838, 0
  %17855 = zext i1 %17854 to i8
  store i8 %17855, i8* %21, align 1
  %17856 = lshr i32 %17838, 31
  %17857 = trunc i32 %17856 to i8
  store i8 %17857, i8* %22, align 1
  %17858 = lshr i32 %17837, 31
  %17859 = lshr i32 %17830, 31
  %17860 = xor i32 %17856, %17858
  %17861 = xor i32 %17856, %17859
  %17862 = add nuw nsw i32 %17860, %17861
  %17863 = icmp eq i32 %17862, 2
  %17864 = zext i1 %17863 to i8
  store i8 %17864, i8* %23, align 1
  %17865 = sext i32 %17838 to i64
  store i64 %17865, i64* %26, align 8
  %17866 = add i64 %17833, -1388
  %17867 = add i64 %17831, 17
  store i64 %17867, i64* %3, align 8
  %17868 = inttoptr i64 %17866 to i32*
  %17869 = load i32, i32* %17868, align 4
  %17870 = zext i32 %17869 to i64
  store i64 %17870, i64* %RAX.i1763, align 8
  %17871 = load i64, i64* %RCX.i1692, align 8
  %17872 = shl nsw i64 %17865, 2
  %17873 = add i64 %17872, %17871
  %17874 = add i64 %17831, 21
  store i64 %17874, i64* %3, align 8
  %17875 = inttoptr i64 %17873 to i32*
  store i32 %17869, i32* %17875, align 4
  %17876 = load i64, i64* %RBP.i, align 8
  %17877 = add i64 %17876, -48
  %17878 = load i64, i64* %3, align 8
  %17879 = add i64 %17878, 7
  store i64 %17879, i64* %3, align 8
  %17880 = inttoptr i64 %17877 to i32*
  store i32 0, i32* %17880, align 4
  %.pre590 = load i64, i64* %3, align 8
  br label %block_.L_4a6837

block_.L_4a6837:                                  ; preds = %block_.L_4a68fd, %routine_idivl__esi.exit2095
  %17881 = phi i64 [ %18309, %block_.L_4a68fd ], [ %.pre590, %routine_idivl__esi.exit2095 ]
  %17882 = load i64, i64* %RBP.i, align 8
  %17883 = add i64 %17882, -48
  %17884 = add i64 %17881, 4
  store i64 %17884, i64* %3, align 8
  %17885 = inttoptr i64 %17883 to i32*
  %17886 = load i32, i32* %17885, align 4
  %17887 = add i32 %17886, -4
  %17888 = icmp ult i32 %17886, 4
  %17889 = zext i1 %17888 to i8
  store i8 %17889, i8* %18, align 1
  %17890 = and i32 %17887, 255
  %17891 = tail call i32 @llvm.ctpop.i32(i32 %17890)
  %17892 = trunc i32 %17891 to i8
  %17893 = and i8 %17892, 1
  %17894 = xor i8 %17893, 1
  store i8 %17894, i8* %19, align 1
  %17895 = xor i32 %17887, %17886
  %17896 = lshr i32 %17895, 4
  %17897 = trunc i32 %17896 to i8
  %17898 = and i8 %17897, 1
  store i8 %17898, i8* %20, align 1
  %17899 = icmp eq i32 %17887, 0
  %17900 = zext i1 %17899 to i8
  store i8 %17900, i8* %21, align 1
  %17901 = lshr i32 %17887, 31
  %17902 = trunc i32 %17901 to i8
  store i8 %17902, i8* %22, align 1
  %17903 = lshr i32 %17886, 31
  %17904 = xor i32 %17901, %17903
  %17905 = add nuw nsw i32 %17904, %17903
  %17906 = icmp eq i32 %17905, 2
  %17907 = zext i1 %17906 to i8
  store i8 %17907, i8* %23, align 1
  %17908 = icmp ne i8 %17902, 0
  %17909 = xor i1 %17908, %17906
  %.v835 = select i1 %17909, i64 10, i64 217
  %17910 = add i64 %17881, %.v835
  store i64 %17910, i64* %3, align 8
  br i1 %17909, label %block_4a6841, label %block_.L_4a6910

block_4a6841:                                     ; preds = %block_.L_4a6837
  %17911 = add i64 %17882, -44
  %17912 = add i64 %17910, 7
  store i64 %17912, i64* %3, align 8
  %17913 = inttoptr i64 %17911 to i32*
  store i32 0, i32* %17913, align 4
  %.pre622 = load i64, i64* %3, align 8
  br label %block_.L_4a6848

block_.L_4a6848:                                  ; preds = %block_4a6852, %block_4a6841
  %17914 = phi i64 [ %18279, %block_4a6852 ], [ %.pre622, %block_4a6841 ]
  %17915 = load i64, i64* %RBP.i, align 8
  %17916 = add i64 %17915, -44
  %17917 = add i64 %17914, 4
  store i64 %17917, i64* %3, align 8
  %17918 = inttoptr i64 %17916 to i32*
  %17919 = load i32, i32* %17918, align 4
  %17920 = add i32 %17919, -4
  %17921 = icmp ult i32 %17919, 4
  %17922 = zext i1 %17921 to i8
  store i8 %17922, i8* %18, align 1
  %17923 = and i32 %17920, 255
  %17924 = tail call i32 @llvm.ctpop.i32(i32 %17923)
  %17925 = trunc i32 %17924 to i8
  %17926 = and i8 %17925, 1
  %17927 = xor i8 %17926, 1
  store i8 %17927, i8* %19, align 1
  %17928 = xor i32 %17920, %17919
  %17929 = lshr i32 %17928, 4
  %17930 = trunc i32 %17929 to i8
  %17931 = and i8 %17930, 1
  store i8 %17931, i8* %20, align 1
  %17932 = icmp eq i32 %17920, 0
  %17933 = zext i1 %17932 to i8
  store i8 %17933, i8* %21, align 1
  %17934 = lshr i32 %17920, 31
  %17935 = trunc i32 %17934 to i8
  store i8 %17935, i8* %22, align 1
  %17936 = lshr i32 %17919, 31
  %17937 = xor i32 %17934, %17936
  %17938 = add nuw nsw i32 %17937, %17936
  %17939 = icmp eq i32 %17938, 2
  %17940 = zext i1 %17939 to i8
  store i8 %17940, i8* %23, align 1
  %17941 = icmp ne i8 %17935, 0
  %17942 = xor i1 %17941, %17939
  %.v769 = select i1 %17942, i64 10, i64 181
  %17943 = add i64 %17914, %.v769
  store i64 %17943, i64* %3, align 8
  br i1 %17942, label %block_4a6852, label %block_.L_4a68fd

block_4a6852:                                     ; preds = %block_.L_4a6848
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RAX.i1763, align 8
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX.i1692, align 8
  %17944 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %17945 = add i64 %17944, 13112
  store i64 %17945, i64* %RDX.i1805, align 8
  %17946 = icmp ugt i64 %17944, -13113
  %17947 = zext i1 %17946 to i8
  store i8 %17947, i8* %18, align 1
  %17948 = trunc i64 %17945 to i32
  %17949 = and i32 %17948, 255
  %17950 = tail call i32 @llvm.ctpop.i32(i32 %17949)
  %17951 = trunc i32 %17950 to i8
  %17952 = and i8 %17951, 1
  %17953 = xor i8 %17952, 1
  store i8 %17953, i8* %19, align 1
  %17954 = xor i64 %17944, 16
  %17955 = xor i64 %17954, %17945
  %17956 = lshr i64 %17955, 4
  %17957 = trunc i64 %17956 to i8
  %17958 = and i8 %17957, 1
  store i8 %17958, i8* %20, align 1
  %17959 = icmp eq i64 %17945, 0
  %17960 = zext i1 %17959 to i8
  store i8 %17960, i8* %21, align 1
  %17961 = lshr i64 %17945, 63
  %17962 = trunc i64 %17961 to i8
  store i8 %17962, i8* %22, align 1
  %17963 = lshr i64 %17944, 63
  %17964 = xor i64 %17961, %17963
  %17965 = add nuw nsw i64 %17964, %17961
  %17966 = icmp eq i64 %17965, 2
  %17967 = zext i1 %17966 to i8
  store i8 %17967, i8* %23, align 1
  %17968 = add i64 %17943, 39
  store i64 %17968, i64* %3, align 8
  %17969 = load i32, i32* %17918, align 4
  %17970 = sext i32 %17969 to i64
  %17971 = shl nsw i64 %17970, 6
  store i64 %17971, i64* %RSI.i1889, align 8
  %17972 = add i64 %17971, %17945
  store i64 %17972, i64* %RDX.i1805, align 8
  %17973 = icmp ult i64 %17972, %17945
  %17974 = icmp ult i64 %17972, %17971
  %17975 = or i1 %17973, %17974
  %17976 = zext i1 %17975 to i8
  store i8 %17976, i8* %18, align 1
  %17977 = trunc i64 %17972 to i32
  %17978 = and i32 %17977, 255
  %17979 = tail call i32 @llvm.ctpop.i32(i32 %17978)
  %17980 = trunc i32 %17979 to i8
  %17981 = and i8 %17980, 1
  %17982 = xor i8 %17981, 1
  store i8 %17982, i8* %19, align 1
  %17983 = xor i64 %17945, %17972
  %17984 = lshr i64 %17983, 4
  %17985 = trunc i64 %17984 to i8
  %17986 = and i8 %17985, 1
  store i8 %17986, i8* %20, align 1
  %17987 = icmp eq i64 %17972, 0
  %17988 = zext i1 %17987 to i8
  store i8 %17988, i8* %21, align 1
  %17989 = lshr i64 %17972, 63
  %17990 = trunc i64 %17989 to i8
  store i8 %17990, i8* %22, align 1
  %17991 = lshr i64 %17970, 57
  %17992 = and i64 %17991, 1
  %17993 = xor i64 %17989, %17961
  %17994 = xor i64 %17989, %17992
  %17995 = add nuw nsw i64 %17993, %17994
  %17996 = icmp eq i64 %17995, 2
  %17997 = zext i1 %17996 to i8
  store i8 %17997, i8* %23, align 1
  %17998 = load i64, i64* %RBP.i, align 8
  %17999 = add i64 %17998, -48
  %18000 = add i64 %17943, 50
  store i64 %18000, i64* %3, align 8
  %18001 = inttoptr i64 %17999 to i32*
  %18002 = load i32, i32* %18001, align 4
  %18003 = sext i32 %18002 to i64
  store i64 %18003, i64* %RSI.i1889, align 8
  %18004 = shl nsw i64 %18003, 2
  %18005 = add i64 %18004, %17972
  %18006 = add i64 %17943, 53
  store i64 %18006, i64* %3, align 8
  %18007 = inttoptr i64 %18005 to i32*
  %18008 = load i32, i32* %18007, align 4
  %18009 = zext i32 %18008 to i64
  store i64 %18009, i64* %RDI.i2141, align 8
  %18010 = add i64 %17998, -44
  %18011 = add i64 %17943, 57
  store i64 %18011, i64* %3, align 8
  %18012 = inttoptr i64 %18010 to i32*
  %18013 = load i32, i32* %18012, align 4
  %18014 = zext i32 %18013 to i64
  store i64 %18014, i64* %26, align 8
  %18015 = add i64 %17998, -476
  %18016 = add i64 %17943, 64
  store i64 %18016, i64* %3, align 8
  %18017 = inttoptr i64 %18015 to i32*
  %18018 = load i32, i32* %18017, align 4
  %18019 = add i32 %18018, %18013
  %18020 = zext i32 %18019 to i64
  store i64 %18020, i64* %26, align 8
  %18021 = sext i32 %18019 to i64
  %18022 = shl nsw i64 %18021, 6
  store i64 %18022, i64* %RDX.i1805, align 8
  %18023 = load i64, i64* %RCX.i1692, align 8
  %18024 = add i64 %18022, %18023
  store i64 %18024, i64* %RCX.i1692, align 8
  %18025 = icmp ult i64 %18024, %18023
  %18026 = icmp ult i64 %18024, %18022
  %18027 = or i1 %18025, %18026
  %18028 = zext i1 %18027 to i8
  store i8 %18028, i8* %18, align 1
  %18029 = trunc i64 %18024 to i32
  %18030 = and i32 %18029, 255
  %18031 = tail call i32 @llvm.ctpop.i32(i32 %18030)
  %18032 = trunc i32 %18031 to i8
  %18033 = and i8 %18032, 1
  %18034 = xor i8 %18033, 1
  store i8 %18034, i8* %19, align 1
  %18035 = xor i64 %18023, %18024
  %18036 = lshr i64 %18035, 4
  %18037 = trunc i64 %18036 to i8
  %18038 = and i8 %18037, 1
  store i8 %18038, i8* %20, align 1
  %18039 = icmp eq i64 %18024, 0
  %18040 = zext i1 %18039 to i8
  store i8 %18040, i8* %21, align 1
  %18041 = lshr i64 %18024, 63
  %18042 = trunc i64 %18041 to i8
  store i8 %18042, i8* %22, align 1
  %18043 = lshr i64 %18023, 63
  %18044 = lshr i64 %18021, 57
  %18045 = and i64 %18044, 1
  %18046 = xor i64 %18041, %18043
  %18047 = xor i64 %18041, %18045
  %18048 = add nuw nsw i64 %18046, %18047
  %18049 = icmp eq i64 %18048, 2
  %18050 = zext i1 %18049 to i8
  store i8 %18050, i8* %23, align 1
  %18051 = load i64, i64* %RBP.i, align 8
  %18052 = add i64 %18051, -48
  %18053 = add i64 %17943, 78
  store i64 %18053, i64* %3, align 8
  %18054 = inttoptr i64 %18052 to i32*
  %18055 = load i32, i32* %18054, align 4
  %18056 = zext i32 %18055 to i64
  store i64 %18056, i64* %26, align 8
  %18057 = add i64 %18051, -480
  %18058 = add i64 %17943, 85
  store i64 %18058, i64* %3, align 8
  %18059 = inttoptr i64 %18057 to i32*
  %18060 = load i32, i32* %18059, align 4
  %18061 = add i32 %18060, %18055
  %18062 = zext i32 %18061 to i64
  store i64 %18062, i64* %26, align 8
  %18063 = icmp ult i32 %18061, %18055
  %18064 = icmp ult i32 %18061, %18060
  %18065 = or i1 %18063, %18064
  %18066 = zext i1 %18065 to i8
  store i8 %18066, i8* %18, align 1
  %18067 = and i32 %18061, 255
  %18068 = tail call i32 @llvm.ctpop.i32(i32 %18067)
  %18069 = trunc i32 %18068 to i8
  %18070 = and i8 %18069, 1
  %18071 = xor i8 %18070, 1
  store i8 %18071, i8* %19, align 1
  %18072 = xor i32 %18060, %18055
  %18073 = xor i32 %18072, %18061
  %18074 = lshr i32 %18073, 4
  %18075 = trunc i32 %18074 to i8
  %18076 = and i8 %18075, 1
  store i8 %18076, i8* %20, align 1
  %18077 = icmp eq i32 %18061, 0
  %18078 = zext i1 %18077 to i8
  store i8 %18078, i8* %21, align 1
  %18079 = lshr i32 %18061, 31
  %18080 = trunc i32 %18079 to i8
  store i8 %18080, i8* %22, align 1
  %18081 = lshr i32 %18055, 31
  %18082 = lshr i32 %18060, 31
  %18083 = xor i32 %18079, %18081
  %18084 = xor i32 %18079, %18082
  %18085 = add nuw nsw i32 %18083, %18084
  %18086 = icmp eq i32 %18085, 2
  %18087 = zext i1 %18086 to i8
  store i8 %18087, i8* %23, align 1
  %18088 = sext i32 %18061 to i64
  store i64 %18088, i64* %RDX.i1805, align 8
  %18089 = shl nsw i64 %18088, 2
  %18090 = add i64 %18024, %18089
  %18091 = load i32, i32* %EDI.i1845, align 4
  %18092 = add i64 %17943, 91
  store i64 %18092, i64* %3, align 8
  %18093 = inttoptr i64 %18090 to i32*
  store i32 %18091, i32* %18093, align 4
  %18094 = load i64, i64* %RBP.i, align 8
  %18095 = add i64 %18094, -44
  %18096 = load i64, i64* %3, align 8
  %18097 = add i64 %18096, 3
  store i64 %18097, i64* %3, align 8
  %18098 = inttoptr i64 %18095 to i32*
  %18099 = load i32, i32* %18098, align 4
  %18100 = zext i32 %18099 to i64
  store i64 %18100, i64* %RDI.i2141, align 8
  %18101 = add i64 %18094, -476
  %18102 = add i64 %18096, 9
  store i64 %18102, i64* %3, align 8
  %18103 = inttoptr i64 %18101 to i32*
  %18104 = load i32, i32* %18103, align 4
  %18105 = add i32 %18104, %18099
  %18106 = zext i32 %18105 to i64
  store i64 %18106, i64* %RDI.i2141, align 8
  %18107 = sext i32 %18105 to i64
  %18108 = shl nsw i64 %18107, 6
  store i64 %18108, i64* %RCX.i1692, align 8
  %18109 = load i64, i64* %RAX.i1763, align 8
  %18110 = add i64 %18108, %18109
  store i64 %18110, i64* %RAX.i1763, align 8
  %18111 = icmp ult i64 %18110, %18109
  %18112 = icmp ult i64 %18110, %18108
  %18113 = or i1 %18111, %18112
  %18114 = zext i1 %18113 to i8
  store i8 %18114, i8* %18, align 1
  %18115 = trunc i64 %18110 to i32
  %18116 = and i32 %18115, 255
  %18117 = tail call i32 @llvm.ctpop.i32(i32 %18116)
  %18118 = trunc i32 %18117 to i8
  %18119 = and i8 %18118, 1
  %18120 = xor i8 %18119, 1
  store i8 %18120, i8* %19, align 1
  %18121 = xor i64 %18109, %18110
  %18122 = lshr i64 %18121, 4
  %18123 = trunc i64 %18122 to i8
  %18124 = and i8 %18123, 1
  store i8 %18124, i8* %20, align 1
  %18125 = icmp eq i64 %18110, 0
  %18126 = zext i1 %18125 to i8
  store i8 %18126, i8* %21, align 1
  %18127 = lshr i64 %18110, 63
  %18128 = trunc i64 %18127 to i8
  store i8 %18128, i8* %22, align 1
  %18129 = lshr i64 %18109, 63
  %18130 = lshr i64 %18107, 57
  %18131 = and i64 %18130, 1
  %18132 = xor i64 %18127, %18129
  %18133 = xor i64 %18127, %18131
  %18134 = add nuw nsw i64 %18132, %18133
  %18135 = icmp eq i64 %18134, 2
  %18136 = zext i1 %18135 to i8
  store i8 %18136, i8* %23, align 1
  %18137 = load i64, i64* %RBP.i, align 8
  %18138 = add i64 %18137, -48
  %18139 = add i64 %18096, 22
  store i64 %18139, i64* %3, align 8
  %18140 = inttoptr i64 %18138 to i32*
  %18141 = load i32, i32* %18140, align 4
  %18142 = zext i32 %18141 to i64
  store i64 %18142, i64* %RDI.i2141, align 8
  %18143 = add i64 %18137, -480
  %18144 = add i64 %18096, 28
  store i64 %18144, i64* %3, align 8
  %18145 = inttoptr i64 %18143 to i32*
  %18146 = load i32, i32* %18145, align 4
  %18147 = add i32 %18146, %18141
  %18148 = zext i32 %18147 to i64
  store i64 %18148, i64* %RDI.i2141, align 8
  %18149 = icmp ult i32 %18147, %18141
  %18150 = icmp ult i32 %18147, %18146
  %18151 = or i1 %18149, %18150
  %18152 = zext i1 %18151 to i8
  store i8 %18152, i8* %18, align 1
  %18153 = and i32 %18147, 255
  %18154 = tail call i32 @llvm.ctpop.i32(i32 %18153)
  %18155 = trunc i32 %18154 to i8
  %18156 = and i8 %18155, 1
  %18157 = xor i8 %18156, 1
  store i8 %18157, i8* %19, align 1
  %18158 = xor i32 %18146, %18141
  %18159 = xor i32 %18158, %18147
  %18160 = lshr i32 %18159, 4
  %18161 = trunc i32 %18160 to i8
  %18162 = and i8 %18161, 1
  store i8 %18162, i8* %20, align 1
  %18163 = icmp eq i32 %18147, 0
  %18164 = zext i1 %18163 to i8
  store i8 %18164, i8* %21, align 1
  %18165 = lshr i32 %18147, 31
  %18166 = trunc i32 %18165 to i8
  store i8 %18166, i8* %22, align 1
  %18167 = lshr i32 %18141, 31
  %18168 = lshr i32 %18146, 31
  %18169 = xor i32 %18165, %18167
  %18170 = xor i32 %18165, %18168
  %18171 = add nuw nsw i32 %18169, %18170
  %18172 = icmp eq i32 %18171, 2
  %18173 = zext i1 %18172 to i8
  store i8 %18173, i8* %23, align 1
  %18174 = sext i32 %18147 to i64
  store i64 %18174, i64* %RCX.i1692, align 8
  %18175 = shl nsw i64 %18174, 2
  %18176 = add i64 %18110, %18175
  %18177 = add i64 %18096, 34
  store i64 %18177, i64* %3, align 8
  %18178 = inttoptr i64 %18176 to i32*
  %18179 = load i32, i32* %18178, align 4
  %18180 = zext i32 %18179 to i64
  store i64 %18180, i64* %RDI.i2141, align 8
  %18181 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %18182 = add i64 %18181, 13112
  store i64 %18182, i64* %RAX.i1763, align 8
  %18183 = icmp ugt i64 %18181, -13113
  %18184 = zext i1 %18183 to i8
  store i8 %18184, i8* %18, align 1
  %18185 = trunc i64 %18182 to i32
  %18186 = and i32 %18185, 255
  %18187 = tail call i32 @llvm.ctpop.i32(i32 %18186)
  %18188 = trunc i32 %18187 to i8
  %18189 = and i8 %18188, 1
  %18190 = xor i8 %18189, 1
  store i8 %18190, i8* %19, align 1
  %18191 = xor i64 %18181, 16
  %18192 = xor i64 %18191, %18182
  %18193 = lshr i64 %18192, 4
  %18194 = trunc i64 %18193 to i8
  %18195 = and i8 %18194, 1
  store i8 %18195, i8* %20, align 1
  %18196 = icmp eq i64 %18182, 0
  %18197 = zext i1 %18196 to i8
  store i8 %18197, i8* %21, align 1
  %18198 = lshr i64 %18182, 63
  %18199 = trunc i64 %18198 to i8
  store i8 %18199, i8* %22, align 1
  %18200 = lshr i64 %18181, 63
  %18201 = xor i64 %18198, %18200
  %18202 = add nuw nsw i64 %18201, %18198
  %18203 = icmp eq i64 %18202, 2
  %18204 = zext i1 %18203 to i8
  store i8 %18204, i8* %23, align 1
  %18205 = add i64 %18137, -44
  %18206 = add i64 %18096, 52
  store i64 %18206, i64* %3, align 8
  %18207 = inttoptr i64 %18205 to i32*
  %18208 = load i32, i32* %18207, align 4
  %18209 = sext i32 %18208 to i64
  %18210 = shl nsw i64 %18209, 6
  store i64 %18210, i64* %RCX.i1692, align 8
  %18211 = add i64 %18210, %18182
  store i64 %18211, i64* %RAX.i1763, align 8
  %18212 = icmp ult i64 %18211, %18182
  %18213 = icmp ult i64 %18211, %18210
  %18214 = or i1 %18212, %18213
  %18215 = zext i1 %18214 to i8
  store i8 %18215, i8* %18, align 1
  %18216 = trunc i64 %18211 to i32
  %18217 = and i32 %18216, 255
  %18218 = tail call i32 @llvm.ctpop.i32(i32 %18217)
  %18219 = trunc i32 %18218 to i8
  %18220 = and i8 %18219, 1
  %18221 = xor i8 %18220, 1
  store i8 %18221, i8* %19, align 1
  %18222 = xor i64 %18182, %18211
  %18223 = lshr i64 %18222, 4
  %18224 = trunc i64 %18223 to i8
  %18225 = and i8 %18224, 1
  store i8 %18225, i8* %20, align 1
  %18226 = icmp eq i64 %18211, 0
  %18227 = zext i1 %18226 to i8
  store i8 %18227, i8* %21, align 1
  %18228 = lshr i64 %18211, 63
  %18229 = trunc i64 %18228 to i8
  store i8 %18229, i8* %22, align 1
  %18230 = lshr i64 %18209, 57
  %18231 = and i64 %18230, 1
  %18232 = xor i64 %18228, %18198
  %18233 = xor i64 %18228, %18231
  %18234 = add nuw nsw i64 %18232, %18233
  %18235 = icmp eq i64 %18234, 2
  %18236 = zext i1 %18235 to i8
  store i8 %18236, i8* %23, align 1
  %18237 = load i64, i64* %RBP.i, align 8
  %18238 = add i64 %18237, -48
  %18239 = add i64 %18096, 63
  store i64 %18239, i64* %3, align 8
  %18240 = inttoptr i64 %18238 to i32*
  %18241 = load i32, i32* %18240, align 4
  %18242 = sext i32 %18241 to i64
  store i64 %18242, i64* %RCX.i1692, align 8
  %18243 = shl nsw i64 %18242, 2
  %18244 = add i64 %18243, %18211
  %18245 = load i32, i32* %EDI.i1845, align 4
  %18246 = add i64 %18096, 66
  store i64 %18246, i64* %3, align 8
  %18247 = inttoptr i64 %18244 to i32*
  store i32 %18245, i32* %18247, align 4
  %18248 = load i64, i64* %RBP.i, align 8
  %18249 = add i64 %18248, -44
  %18250 = load i64, i64* %3, align 8
  %18251 = add i64 %18250, 3
  store i64 %18251, i64* %3, align 8
  %18252 = inttoptr i64 %18249 to i32*
  %18253 = load i32, i32* %18252, align 4
  %18254 = add i32 %18253, 1
  %18255 = zext i32 %18254 to i64
  store i64 %18255, i64* %RAX.i1763, align 8
  %18256 = icmp eq i32 %18253, -1
  %18257 = icmp eq i32 %18254, 0
  %18258 = or i1 %18256, %18257
  %18259 = zext i1 %18258 to i8
  store i8 %18259, i8* %18, align 1
  %18260 = and i32 %18254, 255
  %18261 = tail call i32 @llvm.ctpop.i32(i32 %18260)
  %18262 = trunc i32 %18261 to i8
  %18263 = and i8 %18262, 1
  %18264 = xor i8 %18263, 1
  store i8 %18264, i8* %19, align 1
  %18265 = xor i32 %18254, %18253
  %18266 = lshr i32 %18265, 4
  %18267 = trunc i32 %18266 to i8
  %18268 = and i8 %18267, 1
  store i8 %18268, i8* %20, align 1
  %18269 = zext i1 %18257 to i8
  store i8 %18269, i8* %21, align 1
  %18270 = lshr i32 %18254, 31
  %18271 = trunc i32 %18270 to i8
  store i8 %18271, i8* %22, align 1
  %18272 = lshr i32 %18253, 31
  %18273 = xor i32 %18270, %18272
  %18274 = add nuw nsw i32 %18273, %18270
  %18275 = icmp eq i32 %18274, 2
  %18276 = zext i1 %18275 to i8
  store i8 %18276, i8* %23, align 1
  %18277 = add i64 %18250, 9
  store i64 %18277, i64* %3, align 8
  store i32 %18254, i32* %18252, align 4
  %18278 = load i64, i64* %3, align 8
  %18279 = add i64 %18278, -176
  store i64 %18279, i64* %3, align 8
  br label %block_.L_4a6848

block_.L_4a68fd:                                  ; preds = %block_.L_4a6848
  %18280 = add i64 %17915, -48
  %18281 = add i64 %17943, 8
  store i64 %18281, i64* %3, align 8
  %18282 = inttoptr i64 %18280 to i32*
  %18283 = load i32, i32* %18282, align 4
  %18284 = add i32 %18283, 1
  %18285 = zext i32 %18284 to i64
  store i64 %18285, i64* %RAX.i1763, align 8
  %18286 = icmp eq i32 %18283, -1
  %18287 = icmp eq i32 %18284, 0
  %18288 = or i1 %18286, %18287
  %18289 = zext i1 %18288 to i8
  store i8 %18289, i8* %18, align 1
  %18290 = and i32 %18284, 255
  %18291 = tail call i32 @llvm.ctpop.i32(i32 %18290)
  %18292 = trunc i32 %18291 to i8
  %18293 = and i8 %18292, 1
  %18294 = xor i8 %18293, 1
  store i8 %18294, i8* %19, align 1
  %18295 = xor i32 %18284, %18283
  %18296 = lshr i32 %18295, 4
  %18297 = trunc i32 %18296 to i8
  %18298 = and i8 %18297, 1
  store i8 %18298, i8* %20, align 1
  %18299 = zext i1 %18287 to i8
  store i8 %18299, i8* %21, align 1
  %18300 = lshr i32 %18284, 31
  %18301 = trunc i32 %18300 to i8
  store i8 %18301, i8* %22, align 1
  %18302 = lshr i32 %18283, 31
  %18303 = xor i32 %18300, %18302
  %18304 = add nuw nsw i32 %18303, %18300
  %18305 = icmp eq i32 %18304, 2
  %18306 = zext i1 %18305 to i8
  store i8 %18306, i8* %23, align 1
  %18307 = add i64 %17943, 14
  store i64 %18307, i64* %3, align 8
  store i32 %18284, i32* %18282, align 4
  %18308 = load i64, i64* %3, align 8
  %18309 = add i64 %18308, -212
  store i64 %18309, i64* %3, align 8
  br label %block_.L_4a6837

block_.L_4a6910:                                  ; preds = %block_.L_4a6837
  store i64 1, i64* %RDI.i2141, align 8
  %18310 = add i64 %17882, -12
  %18311 = add i64 %17910, 8
  store i64 %18311, i64* %3, align 8
  %18312 = inttoptr i64 %18310 to i32*
  %18313 = load i32, i32* %18312, align 4
  %18314 = add i32 %18313, 8
  %18315 = zext i32 %18314 to i64
  store i64 %18315, i64* %RAX.i1763, align 8
  %18316 = icmp ugt i32 %18313, -9
  %18317 = zext i1 %18316 to i8
  store i8 %18317, i8* %18, align 1
  %18318 = and i32 %18314, 255
  %18319 = tail call i32 @llvm.ctpop.i32(i32 %18318)
  %18320 = trunc i32 %18319 to i8
  %18321 = and i8 %18320, 1
  %18322 = xor i8 %18321, 1
  store i8 %18322, i8* %19, align 1
  %18323 = xor i32 %18314, %18313
  %18324 = lshr i32 %18323, 4
  %18325 = trunc i32 %18324 to i8
  %18326 = and i8 %18325, 1
  store i8 %18326, i8* %20, align 1
  %18327 = icmp eq i32 %18314, 0
  %18328 = zext i1 %18327 to i8
  store i8 %18328, i8* %21, align 1
  %18329 = lshr i32 %18314, 31
  %18330 = trunc i32 %18329 to i8
  store i8 %18330, i8* %22, align 1
  %18331 = lshr i32 %18313, 31
  %18332 = xor i32 %18329, %18331
  %18333 = add nuw nsw i32 %18332, %18329
  %18334 = icmp eq i32 %18333, 2
  %18335 = zext i1 %18334 to i8
  store i8 %18335, i8* %23, align 1
  %18336 = add i64 %17882, -628
  %18337 = add i64 %17910, 17
  store i64 %18337, i64* %3, align 8
  %18338 = inttoptr i64 %18336 to i32*
  %18339 = load i32, i32* %18338, align 4
  %18340 = zext i32 %18339 to i64
  store i64 %18340, i64* %RDX.i1805, align 8
  store i64 %18315, i64* %RSI.i1889, align 8
  %18341 = add i64 %17910, -638032
  %18342 = add i64 %17910, 24
  %18343 = load i64, i64* %6, align 8
  %18344 = add i64 %18343, -8
  %18345 = inttoptr i64 %18344 to i64*
  store i64 %18342, i64* %18345, align 8
  store i64 %18344, i64* %6, align 8
  store i64 %18341, i64* %3, align 8
  %call2_4a6923 = tail call %struct.Memory* @sub_40acc0.dct_chroma4x4(%struct.State* nonnull %0, i64 %18341, %struct.Memory* %17832)
  %18346 = load i64, i64* %3, align 8
  store i64 2, i64* %RDX.i1805, align 8
  store i64 add (i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64 64), i64* %RCX.i1692, align 8
  store i64 add (i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64 64), i64* %26, align 8
  store i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64* %R9.i, align 8
  store i8 zext (i1 or (i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64)), i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 64)) to i8), i8* %18, align 1
  store i8 %16703, i8* %19, align 1
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64)), i64 4) to i8), i8 1), i8* %20, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 0) to i8), i8* %21, align 1
  store i8 trunc (i64 lshr (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 63) to i8), i8* %22, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 63), i64 lshr (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 63)), i64 lshr (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 63)), i64 2) to i8), i8* %23, align 1
  %18347 = load i64, i64* %RBP.i, align 8
  %18348 = add i64 %18347, -12
  %18349 = add i64 %18346, 50
  store i64 %18349, i64* %3, align 8
  %18350 = inttoptr i64 %18348 to i32*
  %18351 = load i32, i32* %18350, align 4
  %18352 = zext i32 %18351 to i64
  store i64 %18352, i64* %RSI.i1889, align 8
  %18353 = add i64 %18347, -1400
  %18354 = load i32, i32* %EAX.i2159, align 4
  %18355 = add i64 %18346, 56
  store i64 %18355, i64* %3, align 8
  %18356 = inttoptr i64 %18353 to i32*
  store i32 %18354, i32* %18356, align 4
  %18357 = load i32, i32* %ESI.i7670, align 4
  %18358 = zext i32 %18357 to i64
  %18359 = load i64, i64* %3, align 8
  store i64 %18358, i64* %RAX.i1763, align 8
  %18360 = load i64, i64* %RBP.i, align 8
  %18361 = add i64 %18360, -1404
  %18362 = load i32, i32* %EDX.i2206, align 4
  %18363 = add i64 %18359, 8
  store i64 %18363, i64* %3, align 8
  %18364 = inttoptr i64 %18361 to i32*
  store i32 %18362, i32* %18364, align 4
  %18365 = load i64, i64* %3, align 8
  %18366 = load i32, i32* %EAX.i2159, align 8
  %18367 = sext i32 %18366 to i64
  %18368 = lshr i64 %18367, 32
  store i64 %18368, i64* %101, align 8
  %18369 = load i64, i64* %RBP.i, align 8
  %18370 = add i64 %18369, -1404
  %18371 = add i64 %18365, 7
  store i64 %18371, i64* %3, align 8
  %18372 = inttoptr i64 %18370 to i32*
  %18373 = load i32, i32* %18372, align 4
  %18374 = zext i32 %18373 to i64
  store i64 %18374, i64* %RSI.i1889, align 8
  %18375 = add i64 %18365, 9
  store i64 %18375, i64* %3, align 8
  %18376 = zext i32 %18366 to i64
  %18377 = sext i32 %18373 to i64
  %18378 = shl nuw i64 %18368, 32
  %18379 = or i64 %18378, %18376
  %18380 = sdiv i64 %18379, %18377
  %18381 = shl i64 %18380, 32
  %18382 = ashr exact i64 %18381, 32
  %18383 = icmp eq i64 %18380, %18382
  br i1 %18383, label %18386, label %18384

; <label>:18384:                                  ; preds = %block_.L_4a6910
  %18385 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18375, %struct.Memory* %call2_4a6923)
  %.pre591 = load i64, i64* %RDX.i1805, align 8
  %.pre592 = load i64, i64* %3, align 8
  %.pre593 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1905

; <label>:18386:                                  ; preds = %block_.L_4a6910
  %18387 = srem i64 %18379, %18377
  %18388 = and i64 %18380, 4294967295
  store i64 %18388, i64* %RAX.i1763, align 8
  %18389 = and i64 %18387, 4294967295
  store i64 %18389, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit1905

routine_idivl__esi.exit1905:                      ; preds = %18386, %18384
  %18390 = phi i64 [ %.pre593, %18384 ], [ %18369, %18386 ]
  %18391 = phi i64 [ %.pre592, %18384 ], [ %18375, %18386 ]
  %18392 = phi i64 [ %.pre591, %18384 ], [ %18389, %18386 ]
  %18393 = phi %struct.Memory* [ %18385, %18384 ], [ %call2_4a6923, %18386 ]
  %18394 = trunc i64 %18392 to i32
  %18395 = shl i32 %18394, 1
  %18396 = icmp slt i32 %18394, 0
  %18397 = icmp slt i32 %18395, 0
  %18398 = xor i1 %18396, %18397
  %18399 = zext i32 %18395 to i64
  store i64 %18399, i64* %RDX.i1805, align 8
  %.lobit275 = lshr i32 %18394, 31
  %18400 = trunc i32 %.lobit275 to i8
  store i8 %18400, i8* %18, align 1
  %18401 = and i32 %18395, 254
  %18402 = tail call i32 @llvm.ctpop.i32(i32 %18401)
  %18403 = trunc i32 %18402 to i8
  %18404 = and i8 %18403, 1
  %18405 = xor i8 %18404, 1
  store i8 %18405, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %18406 = icmp eq i32 %18395, 0
  %18407 = zext i1 %18406 to i8
  store i8 %18407, i8* %21, align 1
  %18408 = lshr i32 %18394, 30
  %18409 = trunc i32 %18408 to i8
  %18410 = and i8 %18409, 1
  store i8 %18410, i8* %22, align 1
  %18411 = zext i1 %18398 to i8
  store i8 %18411, i8* %23, align 1
  %18412 = add i64 %18390, -628
  %18413 = add i64 %18391, 8
  store i64 %18413, i64* %3, align 8
  %18414 = inttoptr i64 %18412 to i32*
  %18415 = load i32, i32* %18414, align 4
  %18416 = zext i32 %18415 to i64
  store i64 %18416, i64* %RDI.i2141, align 8
  store i64 %18416, i64* %RAX.i1763, align 8
  %18417 = add i64 %18390, -1408
  %18418 = add i64 %18391, 16
  store i64 %18418, i64* %3, align 8
  %18419 = inttoptr i64 %18417 to i32*
  store i32 %18395, i32* %18419, align 4
  %18420 = load i64, i64* %3, align 8
  %18421 = load i32, i32* %EAX.i2159, align 8
  %18422 = sext i32 %18421 to i64
  %18423 = lshr i64 %18422, 32
  store i64 %18423, i64* %101, align 8
  %18424 = load i32, i32* %ESI.i7670, align 4
  %18425 = add i64 %18420, 3
  store i64 %18425, i64* %3, align 8
  %18426 = zext i32 %18421 to i64
  %18427 = sext i32 %18424 to i64
  %18428 = shl nuw i64 %18423, 32
  %18429 = or i64 %18428, %18426
  %18430 = sdiv i64 %18429, %18427
  %18431 = shl i64 %18430, 32
  %18432 = ashr exact i64 %18431, 32
  %18433 = icmp eq i64 %18430, %18432
  br i1 %18433, label %18436, label %18434

; <label>:18434:                                  ; preds = %routine_idivl__esi.exit1905
  %18435 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18425, %struct.Memory* %18393)
  %.pre594 = load i64, i64* %3, align 8
  %.pre595 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__esi.exit1887

; <label>:18436:                                  ; preds = %routine_idivl__esi.exit1905
  %18437 = srem i64 %18429, %18427
  %18438 = and i64 %18430, 4294967295
  store i64 %18438, i64* %RAX.i1763, align 8
  %18439 = and i64 %18437, 4294967295
  store i64 %18439, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %18440 = trunc i64 %18437 to i32
  br label %routine_idivl__esi.exit1887

routine_idivl__esi.exit1887:                      ; preds = %18436, %18434
  %18441 = phi i32 [ %.pre595, %18434 ], [ %18440, %18436 ]
  %18442 = phi i64 [ %.pre594, %18434 ], [ %18425, %18436 ]
  %18443 = phi %struct.Memory* [ %18435, %18434 ], [ %18393, %18436 ]
  %18444 = load i64, i64* %RBP.i, align 8
  %18445 = add i64 %18444, -1408
  %18446 = add i64 %18442, 6
  store i64 %18446, i64* %3, align 8
  %18447 = inttoptr i64 %18445 to i32*
  %18448 = load i32, i32* %18447, align 4
  %18449 = add i32 %18441, %18448
  %18450 = zext i32 %18449 to i64
  store i64 %18450, i64* %RDI.i2141, align 8
  %18451 = sext i32 %18449 to i64
  %18452 = shl nsw i64 %18451, 4
  store i64 %18452, i64* %372, align 8
  %18453 = load i64, i64* %R9.i, align 8
  %18454 = add i64 %18452, %18453
  store i64 %18454, i64* %R9.i, align 8
  %18455 = icmp ult i64 %18454, %18453
  %18456 = icmp ult i64 %18454, %18452
  %18457 = or i1 %18455, %18456
  %18458 = zext i1 %18457 to i8
  store i8 %18458, i8* %18, align 1
  %18459 = trunc i64 %18454 to i32
  %18460 = and i32 %18459, 255
  %18461 = tail call i32 @llvm.ctpop.i32(i32 %18460)
  %18462 = trunc i32 %18461 to i8
  %18463 = and i8 %18462, 1
  %18464 = xor i8 %18463, 1
  store i8 %18464, i8* %19, align 1
  %18465 = xor i64 %18452, %18453
  %18466 = xor i64 %18465, %18454
  %18467 = lshr i64 %18466, 4
  %18468 = trunc i64 %18467 to i8
  %18469 = and i8 %18468, 1
  store i8 %18469, i8* %20, align 1
  %18470 = icmp eq i64 %18454, 0
  %18471 = zext i1 %18470 to i8
  store i8 %18471, i8* %21, align 1
  %18472 = lshr i64 %18454, 63
  %18473 = trunc i64 %18472 to i8
  store i8 %18473, i8* %22, align 1
  %18474 = lshr i64 %18453, 63
  %18475 = lshr i64 %18451, 59
  %18476 = and i64 %18475, 1
  %18477 = xor i64 %18472, %18474
  %18478 = xor i64 %18472, %18476
  %18479 = add nuw nsw i64 %18477, %18478
  %18480 = icmp eq i64 %18479, 2
  %18481 = zext i1 %18480 to i8
  store i8 %18481, i8* %23, align 1
  %18482 = load i64, i64* %RBP.i, align 8
  %18483 = add i64 %18482, -12
  %18484 = add i64 %18442, 21
  store i64 %18484, i64* %3, align 8
  %18485 = inttoptr i64 %18483 to i32*
  %18486 = load i32, i32* %18485, align 4
  %18487 = zext i32 %18486 to i64
  store i64 %18487, i64* %RAX.i1763, align 8
  %18488 = sext i32 %18486 to i64
  %18489 = lshr i64 %18488, 32
  store i64 %18489, i64* %101, align 8
  %18490 = load i32, i32* %ESI.i7670, align 4
  %18491 = add i64 %18442, 26
  store i64 %18491, i64* %3, align 8
  %18492 = sext i32 %18490 to i64
  %18493 = shl nuw i64 %18489, 32
  %18494 = or i64 %18493, %18487
  %18495 = sdiv i64 %18494, %18492
  %18496 = shl i64 %18495, 32
  %18497 = ashr exact i64 %18496, 32
  %18498 = icmp eq i64 %18495, %18497
  br i1 %18498, label %18501, label %18499

; <label>:18499:                                  ; preds = %routine_idivl__esi.exit1887
  %18500 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18491, %struct.Memory* %18443)
  %.pre596 = load i64, i64* %RAX.i1763, align 8
  %.pre597 = load i64, i64* %3, align 8
  %.pre598 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1861

; <label>:18501:                                  ; preds = %routine_idivl__esi.exit1887
  %18502 = srem i64 %18494, %18492
  %18503 = and i64 %18495, 4294967295
  store i64 %18503, i64* %RAX.i1763, align 8
  %18504 = and i64 %18502, 4294967295
  store i64 %18504, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit1861

routine_idivl__esi.exit1861:                      ; preds = %18501, %18499
  %18505 = phi i64 [ %.pre598, %18499 ], [ %18482, %18501 ]
  %18506 = phi i64 [ %.pre597, %18499 ], [ %18491, %18501 ]
  %18507 = phi i64 [ %.pre596, %18499 ], [ %18503, %18501 ]
  %18508 = phi %struct.Memory* [ %18500, %18499 ], [ %18443, %18501 ]
  %18509 = trunc i64 %18507 to i32
  %18510 = shl i32 %18509, 1
  %18511 = icmp slt i32 %18509, 0
  %18512 = icmp slt i32 %18510, 0
  %18513 = xor i1 %18511, %18512
  %18514 = zext i32 %18510 to i64
  store i64 %18514, i64* %RAX.i1763, align 8
  %.lobit277 = lshr i32 %18509, 31
  %18515 = trunc i32 %.lobit277 to i8
  store i8 %18515, i8* %18, align 1
  %18516 = and i32 %18510, 254
  %18517 = tail call i32 @llvm.ctpop.i32(i32 %18516)
  %18518 = trunc i32 %18517 to i8
  %18519 = and i8 %18518, 1
  %18520 = xor i8 %18519, 1
  store i8 %18520, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %18521 = icmp eq i32 %18510, 0
  %18522 = zext i1 %18521 to i8
  store i8 %18522, i8* %21, align 1
  %18523 = lshr i32 %18509, 30
  %18524 = trunc i32 %18523 to i8
  %18525 = and i8 %18524, 1
  store i8 %18525, i8* %22, align 1
  %18526 = zext i1 %18513 to i8
  store i8 %18526, i8* %23, align 1
  %18527 = add i64 %18505, -628
  %18528 = add i64 %18506, 8
  store i64 %18528, i64* %3, align 8
  %18529 = inttoptr i64 %18527 to i32*
  %18530 = load i32, i32* %18529, align 4
  %18531 = zext i32 %18530 to i64
  store i64 %18531, i64* %RDI.i2141, align 8
  %18532 = add i64 %18505, -1412
  %18533 = add i64 %18506, 14
  store i64 %18533, i64* %3, align 8
  %18534 = inttoptr i64 %18532 to i32*
  store i32 %18510, i32* %18534, align 4
  %18535 = load i32, i32* %EDI.i1845, align 4
  %18536 = zext i32 %18535 to i64
  %18537 = load i64, i64* %3, align 8
  store i64 %18536, i64* %RAX.i1763, align 8
  %18538 = sext i32 %18535 to i64
  %18539 = lshr i64 %18538, 32
  store i64 %18539, i64* %101, align 8
  %18540 = load i32, i32* %ESI.i7670, align 4
  %18541 = add i64 %18537, 5
  store i64 %18541, i64* %3, align 8
  %18542 = sext i32 %18540 to i64
  %18543 = shl nuw i64 %18539, 32
  %18544 = or i64 %18543, %18536
  %18545 = sdiv i64 %18544, %18542
  %18546 = shl i64 %18545, 32
  %18547 = ashr exact i64 %18546, 32
  %18548 = icmp eq i64 %18545, %18547
  br i1 %18548, label %18551, label %18549

; <label>:18549:                                  ; preds = %routine_idivl__esi.exit1861
  %18550 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18541, %struct.Memory* %18508)
  %.pre599 = load i64, i64* %3, align 8
  %.pre600 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__esi.exit1843

; <label>:18551:                                  ; preds = %routine_idivl__esi.exit1861
  %18552 = srem i64 %18544, %18542
  %18553 = and i64 %18545, 4294967295
  store i64 %18553, i64* %RAX.i1763, align 8
  %18554 = and i64 %18552, 4294967295
  store i64 %18554, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %18555 = trunc i64 %18545 to i32
  br label %routine_idivl__esi.exit1843

routine_idivl__esi.exit1843:                      ; preds = %18551, %18549
  %18556 = phi i32 [ %.pre600, %18549 ], [ %18555, %18551 ]
  %18557 = phi i64 [ %.pre599, %18549 ], [ %18541, %18551 ]
  %18558 = phi %struct.Memory* [ %18550, %18549 ], [ %18508, %18551 ]
  %18559 = load i64, i64* %RBP.i, align 8
  %18560 = add i64 %18559, -1412
  %18561 = add i64 %18557, 6
  store i64 %18561, i64* %3, align 8
  %18562 = inttoptr i64 %18560 to i32*
  %18563 = load i32, i32* %18562, align 4
  %18564 = add i32 %18556, %18563
  %18565 = zext i32 %18564 to i64
  store i64 %18565, i64* %RDI.i2141, align 8
  %18566 = icmp ult i32 %18564, %18563
  %18567 = icmp ult i32 %18564, %18556
  %18568 = or i1 %18566, %18567
  %18569 = zext i1 %18568 to i8
  store i8 %18569, i8* %18, align 1
  %18570 = and i32 %18564, 255
  %18571 = tail call i32 @llvm.ctpop.i32(i32 %18570)
  %18572 = trunc i32 %18571 to i8
  %18573 = and i8 %18572, 1
  %18574 = xor i8 %18573, 1
  store i8 %18574, i8* %19, align 1
  %18575 = xor i32 %18556, %18563
  %18576 = xor i32 %18575, %18564
  %18577 = lshr i32 %18576, 4
  %18578 = trunc i32 %18577 to i8
  %18579 = and i8 %18578, 1
  store i8 %18579, i8* %20, align 1
  %18580 = icmp eq i32 %18564, 0
  %18581 = zext i1 %18580 to i8
  store i8 %18581, i8* %21, align 1
  %18582 = lshr i32 %18564, 31
  %18583 = trunc i32 %18582 to i8
  store i8 %18583, i8* %22, align 1
  %18584 = lshr i32 %18563, 31
  %18585 = lshr i32 %18556, 31
  %18586 = xor i32 %18582, %18584
  %18587 = xor i32 %18582, %18585
  %18588 = add nuw nsw i32 %18586, %18587
  %18589 = icmp eq i32 %18588, 2
  %18590 = zext i1 %18589 to i8
  store i8 %18590, i8* %23, align 1
  %18591 = sext i32 %18564 to i64
  store i64 %18591, i64* %372, align 8
  %18592 = add i64 %18559, -1400
  %18593 = add i64 %18557, 17
  store i64 %18593, i64* %3, align 8
  %18594 = inttoptr i64 %18592 to i32*
  %18595 = load i32, i32* %18594, align 4
  %18596 = zext i32 %18595 to i64
  store i64 %18596, i64* %RAX.i1763, align 8
  %18597 = load i64, i64* %R9.i, align 8
  %18598 = shl nsw i64 %18591, 2
  %18599 = add i64 %18598, %18597
  %18600 = add i64 %18557, 21
  store i64 %18600, i64* %3, align 8
  %18601 = inttoptr i64 %18599 to i32*
  store i32 %18595, i32* %18601, align 4
  %18602 = load i64, i64* %RBP.i, align 8
  %18603 = add i64 %18602, -12
  %18604 = load i64, i64* %3, align 8
  %18605 = add i64 %18604, 3
  store i64 %18605, i64* %3, align 8
  %18606 = inttoptr i64 %18603 to i32*
  %18607 = load i32, i32* %18606, align 4
  %18608 = zext i32 %18607 to i64
  store i64 %18608, i64* %RAX.i1763, align 8
  %18609 = sext i32 %18607 to i64
  %18610 = lshr i64 %18609, 32
  store i64 %18610, i64* %101, align 8
  %18611 = load i32, i32* %ESI.i7670, align 4
  %18612 = add i64 %18604, 6
  store i64 %18612, i64* %3, align 8
  %18613 = sext i32 %18611 to i64
  %18614 = shl nuw i64 %18610, 32
  %18615 = or i64 %18614, %18608
  %18616 = sdiv i64 %18615, %18613
  %18617 = shl i64 %18616, 32
  %18618 = ashr exact i64 %18617, 32
  %18619 = icmp eq i64 %18616, %18618
  br i1 %18619, label %18622, label %18620

; <label>:18620:                                  ; preds = %routine_idivl__esi.exit1843
  %18621 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18612, %struct.Memory* %18558)
  %.pre601 = load i64, i64* %RDX.i1805, align 8
  %.pre602 = load i64, i64* %3, align 8
  %.pre603 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1820

; <label>:18622:                                  ; preds = %routine_idivl__esi.exit1843
  %18623 = srem i64 %18615, %18613
  %18624 = and i64 %18616, 4294967295
  store i64 %18624, i64* %RAX.i1763, align 8
  %18625 = and i64 %18623, 4294967295
  store i64 %18625, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit1820

routine_idivl__esi.exit1820:                      ; preds = %18622, %18620
  %18626 = phi i64 [ %.pre603, %18620 ], [ %18602, %18622 ]
  %18627 = phi i64 [ %.pre602, %18620 ], [ %18612, %18622 ]
  %18628 = phi i64 [ %.pre601, %18620 ], [ %18625, %18622 ]
  %18629 = phi %struct.Memory* [ %18621, %18620 ], [ %18558, %18622 ]
  %18630 = trunc i64 %18628 to i32
  %18631 = shl i32 %18630, 1
  %18632 = icmp slt i32 %18630, 0
  %18633 = icmp slt i32 %18631, 0
  %18634 = xor i1 %18632, %18633
  %18635 = zext i32 %18631 to i64
  store i64 %18635, i64* %RDX.i1805, align 8
  %.lobit278 = lshr i32 %18630, 31
  %18636 = trunc i32 %.lobit278 to i8
  store i8 %18636, i8* %18, align 1
  %18637 = and i32 %18631, 254
  %18638 = tail call i32 @llvm.ctpop.i32(i32 %18637)
  %18639 = trunc i32 %18638 to i8
  %18640 = and i8 %18639, 1
  %18641 = xor i8 %18640, 1
  store i8 %18641, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %18642 = icmp eq i32 %18631, 0
  %18643 = zext i1 %18642 to i8
  store i8 %18643, i8* %21, align 1
  %18644 = lshr i32 %18630, 30
  %18645 = trunc i32 %18644 to i8
  %18646 = and i8 %18645, 1
  store i8 %18646, i8* %22, align 1
  %18647 = zext i1 %18634 to i8
  store i8 %18647, i8* %23, align 1
  %18648 = add i64 %18626, -628
  %18649 = add i64 %18627, 8
  store i64 %18649, i64* %3, align 8
  %18650 = inttoptr i64 %18648 to i32*
  %18651 = load i32, i32* %18650, align 4
  %18652 = zext i32 %18651 to i64
  store i64 %18652, i64* %RDI.i2141, align 8
  store i64 %18652, i64* %RAX.i1763, align 8
  %18653 = add i64 %18626, -1416
  %18654 = add i64 %18627, 16
  store i64 %18654, i64* %3, align 8
  %18655 = inttoptr i64 %18653 to i32*
  store i32 %18631, i32* %18655, align 4
  %18656 = load i64, i64* %3, align 8
  %18657 = load i32, i32* %EAX.i2159, align 8
  %18658 = sext i32 %18657 to i64
  %18659 = lshr i64 %18658, 32
  store i64 %18659, i64* %101, align 8
  %18660 = load i32, i32* %ESI.i7670, align 4
  %18661 = add i64 %18656, 3
  store i64 %18661, i64* %3, align 8
  %18662 = zext i32 %18657 to i64
  %18663 = sext i32 %18660 to i64
  %18664 = shl nuw i64 %18659, 32
  %18665 = or i64 %18664, %18662
  %18666 = sdiv i64 %18665, %18663
  %18667 = shl i64 %18666, 32
  %18668 = ashr exact i64 %18667, 32
  %18669 = icmp eq i64 %18666, %18668
  br i1 %18669, label %18672, label %18670

; <label>:18670:                                  ; preds = %routine_idivl__esi.exit1820
  %18671 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18661, %struct.Memory* %18629)
  %.pre604 = load i64, i64* %3, align 8
  %.pre605 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__esi.exit1803

; <label>:18672:                                  ; preds = %routine_idivl__esi.exit1820
  %18673 = srem i64 %18665, %18663
  %18674 = and i64 %18666, 4294967295
  store i64 %18674, i64* %RAX.i1763, align 8
  %18675 = and i64 %18673, 4294967295
  store i64 %18675, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %18676 = trunc i64 %18673 to i32
  br label %routine_idivl__esi.exit1803

routine_idivl__esi.exit1803:                      ; preds = %18672, %18670
  %18677 = phi i32 [ %.pre605, %18670 ], [ %18676, %18672 ]
  %18678 = phi i64 [ %.pre604, %18670 ], [ %18661, %18672 ]
  %18679 = phi %struct.Memory* [ %18671, %18670 ], [ %18629, %18672 ]
  %18680 = load i64, i64* %RBP.i, align 8
  %18681 = add i64 %18680, -1416
  %18682 = add i64 %18678, 6
  store i64 %18682, i64* %3, align 8
  %18683 = inttoptr i64 %18681 to i32*
  %18684 = load i32, i32* %18683, align 4
  %18685 = add i32 %18677, %18684
  %18686 = zext i32 %18685 to i64
  store i64 %18686, i64* %RDI.i2141, align 8
  %18687 = sext i32 %18685 to i64
  %18688 = shl nsw i64 %18687, 4
  store i64 %18688, i64* %R9.i, align 8
  %18689 = load i64, i64* %26, align 8
  %18690 = add i64 %18688, %18689
  store i64 %18690, i64* %26, align 8
  %18691 = icmp ult i64 %18690, %18689
  %18692 = icmp ult i64 %18690, %18688
  %18693 = or i1 %18691, %18692
  %18694 = zext i1 %18693 to i8
  store i8 %18694, i8* %18, align 1
  %18695 = trunc i64 %18690 to i32
  %18696 = and i32 %18695, 255
  %18697 = tail call i32 @llvm.ctpop.i32(i32 %18696)
  %18698 = trunc i32 %18697 to i8
  %18699 = and i8 %18698, 1
  %18700 = xor i8 %18699, 1
  store i8 %18700, i8* %19, align 1
  %18701 = xor i64 %18688, %18689
  %18702 = xor i64 %18701, %18690
  %18703 = lshr i64 %18702, 4
  %18704 = trunc i64 %18703 to i8
  %18705 = and i8 %18704, 1
  store i8 %18705, i8* %20, align 1
  %18706 = icmp eq i64 %18690, 0
  %18707 = zext i1 %18706 to i8
  store i8 %18707, i8* %21, align 1
  %18708 = lshr i64 %18690, 63
  %18709 = trunc i64 %18708 to i8
  store i8 %18709, i8* %22, align 1
  %18710 = lshr i64 %18689, 63
  %18711 = lshr i64 %18687, 59
  %18712 = and i64 %18711, 1
  %18713 = xor i64 %18708, %18710
  %18714 = xor i64 %18708, %18712
  %18715 = add nuw nsw i64 %18713, %18714
  %18716 = icmp eq i64 %18715, 2
  %18717 = zext i1 %18716 to i8
  store i8 %18717, i8* %23, align 1
  %18718 = load i64, i64* %RBP.i, align 8
  %18719 = add i64 %18718, -12
  %18720 = add i64 %18678, 21
  store i64 %18720, i64* %3, align 8
  %18721 = inttoptr i64 %18719 to i32*
  %18722 = load i32, i32* %18721, align 4
  %18723 = zext i32 %18722 to i64
  store i64 %18723, i64* %RAX.i1763, align 8
  %18724 = sext i32 %18722 to i64
  %18725 = lshr i64 %18724, 32
  store i64 %18725, i64* %101, align 8
  %18726 = load i32, i32* %ESI.i7670, align 4
  %18727 = add i64 %18678, 26
  store i64 %18727, i64* %3, align 8
  %18728 = sext i32 %18726 to i64
  %18729 = shl nuw i64 %18725, 32
  %18730 = or i64 %18729, %18723
  %18731 = sdiv i64 %18730, %18728
  %18732 = shl i64 %18731, 32
  %18733 = ashr exact i64 %18732, 32
  %18734 = icmp eq i64 %18731, %18733
  br i1 %18734, label %18737, label %18735

; <label>:18735:                                  ; preds = %routine_idivl__esi.exit1803
  %18736 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18727, %struct.Memory* %18679)
  %.pre606 = load i64, i64* %RAX.i1763, align 8
  %.pre607 = load i64, i64* %3, align 8
  %.pre608 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1778

; <label>:18737:                                  ; preds = %routine_idivl__esi.exit1803
  %18738 = srem i64 %18730, %18728
  %18739 = and i64 %18731, 4294967295
  store i64 %18739, i64* %RAX.i1763, align 8
  %18740 = and i64 %18738, 4294967295
  store i64 %18740, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit1778

routine_idivl__esi.exit1778:                      ; preds = %18737, %18735
  %18741 = phi i64 [ %.pre608, %18735 ], [ %18718, %18737 ]
  %18742 = phi i64 [ %.pre607, %18735 ], [ %18727, %18737 ]
  %18743 = phi i64 [ %.pre606, %18735 ], [ %18739, %18737 ]
  %18744 = phi %struct.Memory* [ %18736, %18735 ], [ %18679, %18737 ]
  %18745 = trunc i64 %18743 to i32
  %18746 = shl i32 %18745, 1
  %18747 = icmp slt i32 %18745, 0
  %18748 = icmp slt i32 %18746, 0
  %18749 = xor i1 %18747, %18748
  %18750 = zext i32 %18746 to i64
  store i64 %18750, i64* %RAX.i1763, align 8
  %.lobit280 = lshr i32 %18745, 31
  %18751 = trunc i32 %.lobit280 to i8
  store i8 %18751, i8* %18, align 1
  %18752 = and i32 %18746, 254
  %18753 = tail call i32 @llvm.ctpop.i32(i32 %18752)
  %18754 = trunc i32 %18753 to i8
  %18755 = and i8 %18754, 1
  %18756 = xor i8 %18755, 1
  store i8 %18756, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %18757 = icmp eq i32 %18746, 0
  %18758 = zext i1 %18757 to i8
  store i8 %18758, i8* %21, align 1
  %18759 = lshr i32 %18745, 30
  %18760 = trunc i32 %18759 to i8
  %18761 = and i8 %18760, 1
  store i8 %18761, i8* %22, align 1
  %18762 = zext i1 %18749 to i8
  store i8 %18762, i8* %23, align 1
  %18763 = add i64 %18741, -628
  %18764 = add i64 %18742, 8
  store i64 %18764, i64* %3, align 8
  %18765 = inttoptr i64 %18763 to i32*
  %18766 = load i32, i32* %18765, align 4
  %18767 = zext i32 %18766 to i64
  store i64 %18767, i64* %RDI.i2141, align 8
  %18768 = add i64 %18741, -1420
  %18769 = add i64 %18742, 14
  store i64 %18769, i64* %3, align 8
  %18770 = inttoptr i64 %18768 to i32*
  store i32 %18746, i32* %18770, align 4
  %18771 = load i32, i32* %EDI.i1845, align 4
  %18772 = zext i32 %18771 to i64
  %18773 = load i64, i64* %3, align 8
  store i64 %18772, i64* %RAX.i1763, align 8
  %18774 = sext i32 %18771 to i64
  %18775 = lshr i64 %18774, 32
  store i64 %18775, i64* %101, align 8
  %18776 = load i32, i32* %ESI.i7670, align 4
  %18777 = add i64 %18773, 5
  store i64 %18777, i64* %3, align 8
  %18778 = sext i32 %18776 to i64
  %18779 = shl nuw i64 %18775, 32
  %18780 = or i64 %18779, %18772
  %18781 = sdiv i64 %18780, %18778
  %18782 = shl i64 %18781, 32
  %18783 = ashr exact i64 %18782, 32
  %18784 = icmp eq i64 %18781, %18783
  br i1 %18784, label %18787, label %18785

; <label>:18785:                                  ; preds = %routine_idivl__esi.exit1778
  %18786 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18777, %struct.Memory* %18744)
  %.pre609 = load i64, i64* %3, align 8
  %.pre610 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__esi.exit1761

; <label>:18787:                                  ; preds = %routine_idivl__esi.exit1778
  %18788 = srem i64 %18780, %18778
  %18789 = and i64 %18781, 4294967295
  store i64 %18789, i64* %RAX.i1763, align 8
  %18790 = and i64 %18788, 4294967295
  store i64 %18790, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %18791 = trunc i64 %18781 to i32
  br label %routine_idivl__esi.exit1761

routine_idivl__esi.exit1761:                      ; preds = %18787, %18785
  %18792 = phi i32 [ %.pre610, %18785 ], [ %18791, %18787 ]
  %18793 = phi i64 [ %.pre609, %18785 ], [ %18777, %18787 ]
  %18794 = phi %struct.Memory* [ %18786, %18785 ], [ %18744, %18787 ]
  %18795 = load i64, i64* %RBP.i, align 8
  %18796 = add i64 %18795, -1420
  %18797 = add i64 %18793, 6
  store i64 %18797, i64* %3, align 8
  %18798 = inttoptr i64 %18796 to i32*
  %18799 = load i32, i32* %18798, align 4
  %18800 = add i32 %18792, %18799
  %18801 = zext i32 %18800 to i64
  store i64 %18801, i64* %RDI.i2141, align 8
  %18802 = icmp ult i32 %18800, %18799
  %18803 = icmp ult i32 %18800, %18792
  %18804 = or i1 %18802, %18803
  %18805 = zext i1 %18804 to i8
  store i8 %18805, i8* %18, align 1
  %18806 = and i32 %18800, 255
  %18807 = tail call i32 @llvm.ctpop.i32(i32 %18806)
  %18808 = trunc i32 %18807 to i8
  %18809 = and i8 %18808, 1
  %18810 = xor i8 %18809, 1
  store i8 %18810, i8* %19, align 1
  %18811 = xor i32 %18792, %18799
  %18812 = xor i32 %18811, %18800
  %18813 = lshr i32 %18812, 4
  %18814 = trunc i32 %18813 to i8
  %18815 = and i8 %18814, 1
  store i8 %18815, i8* %20, align 1
  %18816 = icmp eq i32 %18800, 0
  %18817 = zext i1 %18816 to i8
  store i8 %18817, i8* %21, align 1
  %18818 = lshr i32 %18800, 31
  %18819 = trunc i32 %18818 to i8
  store i8 %18819, i8* %22, align 1
  %18820 = lshr i32 %18799, 31
  %18821 = lshr i32 %18792, 31
  %18822 = xor i32 %18818, %18820
  %18823 = xor i32 %18818, %18821
  %18824 = add nuw nsw i32 %18822, %18823
  %18825 = icmp eq i32 %18824, 2
  %18826 = zext i1 %18825 to i8
  store i8 %18826, i8* %23, align 1
  %18827 = sext i32 %18800 to i64
  store i64 %18827, i64* %R9.i, align 8
  %18828 = load i64, i64* %26, align 8
  %18829 = shl nsw i64 %18827, 2
  %18830 = add i64 %18828, %18829
  %18831 = add i64 %18793, 15
  store i64 %18831, i64* %3, align 8
  %18832 = inttoptr i64 %18830 to i32*
  %18833 = load i32, i32* %18832, align 4
  %18834 = zext i32 %18833 to i64
  store i64 %18834, i64* %RAX.i1763, align 8
  %18835 = add i64 %18795, -12
  %18836 = add i64 %18793, 18
  store i64 %18836, i64* %3, align 8
  %18837 = inttoptr i64 %18835 to i32*
  %18838 = load i32, i32* %18837, align 4
  %18839 = zext i32 %18838 to i64
  store i64 %18839, i64* %RDI.i2141, align 8
  %18840 = add i64 %18795, -1424
  %18841 = add i64 %18793, 24
  store i64 %18841, i64* %3, align 8
  %18842 = inttoptr i64 %18840 to i32*
  store i32 %18833, i32* %18842, align 4
  %18843 = load i32, i32* %EDI.i1845, align 4
  %18844 = zext i32 %18843 to i64
  %18845 = load i64, i64* %3, align 8
  store i64 %18844, i64* %RAX.i1763, align 8
  %18846 = sext i32 %18843 to i64
  %18847 = lshr i64 %18846, 32
  store i64 %18847, i64* %101, align 8
  %18848 = load i32, i32* %ESI.i7670, align 4
  %18849 = add i64 %18845, 5
  store i64 %18849, i64* %3, align 8
  %18850 = sext i32 %18848 to i64
  %18851 = shl nuw i64 %18847, 32
  %18852 = or i64 %18851, %18844
  %18853 = sdiv i64 %18852, %18850
  %18854 = shl i64 %18853, 32
  %18855 = ashr exact i64 %18854, 32
  %18856 = icmp eq i64 %18853, %18855
  br i1 %18856, label %18859, label %18857

; <label>:18857:                                  ; preds = %routine_idivl__esi.exit1761
  %18858 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18849, %struct.Memory* %18794)
  %.pre611 = load i64, i64* %RDX.i1805, align 8
  %.pre612 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit1733

; <label>:18859:                                  ; preds = %routine_idivl__esi.exit1761
  %18860 = srem i64 %18852, %18850
  %18861 = and i64 %18853, 4294967295
  store i64 %18861, i64* %RAX.i1763, align 8
  %18862 = and i64 %18860, 4294967295
  store i64 %18862, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit1733

routine_idivl__esi.exit1733:                      ; preds = %18859, %18857
  %18863 = phi i64 [ %.pre612, %18857 ], [ %18849, %18859 ]
  %18864 = phi i64 [ %.pre611, %18857 ], [ %18862, %18859 ]
  %18865 = phi %struct.Memory* [ %18858, %18857 ], [ %18794, %18859 ]
  %18866 = trunc i64 %18864 to i32
  %18867 = shl i32 %18866, 1
  %18868 = icmp slt i32 %18866, 0
  %18869 = icmp slt i32 %18867, 0
  %18870 = xor i1 %18868, %18869
  %18871 = zext i32 %18867 to i64
  store i64 %18871, i64* %RDX.i1805, align 8
  %.lobit281 = lshr i32 %18866, 31
  %18872 = trunc i32 %.lobit281 to i8
  store i8 %18872, i8* %18, align 1
  %18873 = and i32 %18867, 254
  %18874 = tail call i32 @llvm.ctpop.i32(i32 %18873)
  %18875 = trunc i32 %18874 to i8
  %18876 = and i8 %18875, 1
  %18877 = xor i8 %18876, 1
  store i8 %18877, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %18878 = icmp eq i32 %18867, 0
  %18879 = zext i1 %18878 to i8
  store i8 %18879, i8* %21, align 1
  %18880 = lshr i32 %18866, 30
  %18881 = trunc i32 %18880 to i8
  %18882 = and i8 %18881, 1
  store i8 %18882, i8* %22, align 1
  %18883 = zext i1 %18870 to i8
  store i8 %18883, i8* %23, align 1
  %18884 = load i64, i64* %RBP.i, align 8
  %18885 = add i64 %18884, -628
  %18886 = add i64 %18863, 8
  store i64 %18886, i64* %3, align 8
  %18887 = inttoptr i64 %18885 to i32*
  %18888 = load i32, i32* %18887, align 4
  %18889 = zext i32 %18888 to i64
  store i64 %18889, i64* %RDI.i2141, align 8
  store i64 %18889, i64* %RAX.i1763, align 8
  %18890 = add i64 %18884, -1428
  %18891 = add i64 %18863, 16
  store i64 %18891, i64* %3, align 8
  %18892 = inttoptr i64 %18890 to i32*
  store i32 %18867, i32* %18892, align 4
  %18893 = load i64, i64* %3, align 8
  %18894 = load i32, i32* %EAX.i2159, align 8
  %18895 = sext i32 %18894 to i64
  %18896 = lshr i64 %18895, 32
  store i64 %18896, i64* %101, align 8
  %18897 = load i32, i32* %ESI.i7670, align 4
  %18898 = add i64 %18893, 3
  store i64 %18898, i64* %3, align 8
  %18899 = zext i32 %18894 to i64
  %18900 = sext i32 %18897 to i64
  %18901 = shl nuw i64 %18896, 32
  %18902 = or i64 %18901, %18899
  %18903 = sdiv i64 %18902, %18900
  %18904 = shl i64 %18903, 32
  %18905 = ashr exact i64 %18904, 32
  %18906 = icmp eq i64 %18903, %18905
  br i1 %18906, label %18909, label %18907

; <label>:18907:                                  ; preds = %routine_idivl__esi.exit1733
  %18908 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18898, %struct.Memory* %18865)
  %.pre613 = load i64, i64* %3, align 8
  %.pre614 = load i32, i32* %EDX.i2206, align 4
  br label %routine_idivl__esi.exit1716

; <label>:18909:                                  ; preds = %routine_idivl__esi.exit1733
  %18910 = srem i64 %18902, %18900
  %18911 = and i64 %18903, 4294967295
  store i64 %18911, i64* %RAX.i1763, align 8
  %18912 = and i64 %18910, 4294967295
  store i64 %18912, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %18913 = trunc i64 %18910 to i32
  br label %routine_idivl__esi.exit1716

routine_idivl__esi.exit1716:                      ; preds = %18909, %18907
  %18914 = phi i32 [ %.pre614, %18907 ], [ %18913, %18909 ]
  %18915 = phi i64 [ %.pre613, %18907 ], [ %18898, %18909 ]
  %18916 = phi %struct.Memory* [ %18908, %18907 ], [ %18865, %18909 ]
  %18917 = load i64, i64* %RBP.i, align 8
  %18918 = add i64 %18917, -1428
  %18919 = add i64 %18915, 6
  store i64 %18919, i64* %3, align 8
  %18920 = inttoptr i64 %18918 to i32*
  %18921 = load i32, i32* %18920, align 4
  %18922 = add i32 %18914, %18921
  %18923 = zext i32 %18922 to i64
  store i64 %18923, i64* %RDI.i2141, align 8
  %18924 = sext i32 %18922 to i64
  %18925 = shl nsw i64 %18924, 4
  store i64 %18925, i64* %26, align 8
  %18926 = load i64, i64* %RCX.i1692, align 8
  %18927 = add i64 %18925, %18926
  store i64 %18927, i64* %RCX.i1692, align 8
  %18928 = icmp ult i64 %18927, %18926
  %18929 = icmp ult i64 %18927, %18925
  %18930 = or i1 %18928, %18929
  %18931 = zext i1 %18930 to i8
  store i8 %18931, i8* %18, align 1
  %18932 = trunc i64 %18927 to i32
  %18933 = and i32 %18932, 255
  %18934 = tail call i32 @llvm.ctpop.i32(i32 %18933)
  %18935 = trunc i32 %18934 to i8
  %18936 = and i8 %18935, 1
  %18937 = xor i8 %18936, 1
  store i8 %18937, i8* %19, align 1
  %18938 = xor i64 %18925, %18926
  %18939 = xor i64 %18938, %18927
  %18940 = lshr i64 %18939, 4
  %18941 = trunc i64 %18940 to i8
  %18942 = and i8 %18941, 1
  store i8 %18942, i8* %20, align 1
  %18943 = icmp eq i64 %18927, 0
  %18944 = zext i1 %18943 to i8
  store i8 %18944, i8* %21, align 1
  %18945 = lshr i64 %18927, 63
  %18946 = trunc i64 %18945 to i8
  store i8 %18946, i8* %22, align 1
  %18947 = lshr i64 %18926, 63
  %18948 = lshr i64 %18924, 59
  %18949 = and i64 %18948, 1
  %18950 = xor i64 %18945, %18947
  %18951 = xor i64 %18945, %18949
  %18952 = add nuw nsw i64 %18950, %18951
  %18953 = icmp eq i64 %18952, 2
  %18954 = zext i1 %18953 to i8
  store i8 %18954, i8* %23, align 1
  %18955 = load i64, i64* %RBP.i, align 8
  %18956 = add i64 %18955, -12
  %18957 = add i64 %18915, 21
  store i64 %18957, i64* %3, align 8
  %18958 = inttoptr i64 %18956 to i32*
  %18959 = load i32, i32* %18958, align 4
  %18960 = zext i32 %18959 to i64
  store i64 %18960, i64* %RAX.i1763, align 8
  %18961 = sext i32 %18959 to i64
  %18962 = lshr i64 %18961, 32
  store i64 %18962, i64* %101, align 8
  %18963 = load i32, i32* %ESI.i7670, align 4
  %18964 = add i64 %18915, 26
  store i64 %18964, i64* %3, align 8
  %18965 = sext i32 %18963 to i64
  %18966 = shl nuw i64 %18962, 32
  %18967 = or i64 %18966, %18960
  %18968 = sdiv i64 %18967, %18965
  %18969 = shl i64 %18968, 32
  %18970 = ashr exact i64 %18969, 32
  %18971 = icmp eq i64 %18968, %18970
  br i1 %18971, label %18974, label %18972

; <label>:18972:                                  ; preds = %routine_idivl__esi.exit1716
  %18973 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %18964, %struct.Memory* %18916)
  %.pre615 = load i64, i64* %RAX.i1763, align 8
  %.pre616 = load i64, i64* %3, align 8
  %.pre617 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1690

; <label>:18974:                                  ; preds = %routine_idivl__esi.exit1716
  %18975 = srem i64 %18967, %18965
  %18976 = and i64 %18968, 4294967295
  store i64 %18976, i64* %RAX.i1763, align 8
  %18977 = and i64 %18975, 4294967295
  store i64 %18977, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__esi.exit1690

routine_idivl__esi.exit1690:                      ; preds = %18974, %18972
  %18978 = phi i64 [ %.pre617, %18972 ], [ %18955, %18974 ]
  %18979 = phi i64 [ %.pre616, %18972 ], [ %18964, %18974 ]
  %18980 = phi i64 [ %.pre615, %18972 ], [ %18976, %18974 ]
  %18981 = phi %struct.Memory* [ %18973, %18972 ], [ %18916, %18974 ]
  %18982 = trunc i64 %18980 to i32
  %18983 = shl i32 %18982, 1
  %18984 = icmp slt i32 %18982, 0
  %18985 = icmp slt i32 %18983, 0
  %18986 = xor i1 %18984, %18985
  %18987 = zext i32 %18983 to i64
  store i64 %18987, i64* %RAX.i1763, align 8
  %.lobit283 = lshr i32 %18982, 31
  %18988 = trunc i32 %.lobit283 to i8
  store i8 %18988, i8* %18, align 1
  %18989 = and i32 %18983, 254
  %18990 = tail call i32 @llvm.ctpop.i32(i32 %18989)
  %18991 = trunc i32 %18990 to i8
  %18992 = and i8 %18991, 1
  %18993 = xor i8 %18992, 1
  store i8 %18993, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %18994 = icmp eq i32 %18983, 0
  %18995 = zext i1 %18994 to i8
  store i8 %18995, i8* %21, align 1
  %18996 = lshr i32 %18982, 30
  %18997 = trunc i32 %18996 to i8
  %18998 = and i8 %18997, 1
  store i8 %18998, i8* %22, align 1
  %18999 = zext i1 %18986 to i8
  store i8 %18999, i8* %23, align 1
  %19000 = add i64 %18978, -628
  %19001 = add i64 %18979, 8
  store i64 %19001, i64* %3, align 8
  %19002 = inttoptr i64 %19000 to i32*
  %19003 = load i32, i32* %19002, align 4
  %19004 = zext i32 %19003 to i64
  store i64 %19004, i64* %RDI.i2141, align 8
  %19005 = add i64 %18978, -1432
  %19006 = add i64 %18979, 14
  store i64 %19006, i64* %3, align 8
  %19007 = inttoptr i64 %19005 to i32*
  store i32 %18983, i32* %19007, align 4
  %19008 = load i32, i32* %EDI.i1845, align 4
  %19009 = zext i32 %19008 to i64
  %19010 = load i64, i64* %3, align 8
  store i64 %19009, i64* %RAX.i1763, align 8
  %19011 = sext i32 %19008 to i64
  %19012 = lshr i64 %19011, 32
  store i64 %19012, i64* %101, align 8
  %19013 = load i32, i32* %ESI.i7670, align 4
  %19014 = add i64 %19010, 5
  store i64 %19014, i64* %3, align 8
  %19015 = sext i32 %19013 to i64
  %19016 = shl nuw i64 %19012, 32
  %19017 = or i64 %19016, %19009
  %19018 = sdiv i64 %19017, %19015
  %19019 = shl i64 %19018, 32
  %19020 = ashr exact i64 %19019, 32
  %19021 = icmp eq i64 %19018, %19020
  br i1 %19021, label %19024, label %19022

; <label>:19022:                                  ; preds = %routine_idivl__esi.exit1690
  %19023 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %19014, %struct.Memory* %18981)
  %.pre618 = load i64, i64* %3, align 8
  %.pre619 = load i32, i32* %EAX.i2159, align 4
  br label %routine_idivl__esi.exit

; <label>:19024:                                  ; preds = %routine_idivl__esi.exit1690
  %19025 = srem i64 %19017, %19015
  %19026 = and i64 %19018, 4294967295
  store i64 %19026, i64* %RAX.i1763, align 8
  %19027 = and i64 %19025, 4294967295
  store i64 %19027, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %19028 = trunc i64 %19018 to i32
  br label %routine_idivl__esi.exit

routine_idivl__esi.exit:                          ; preds = %19024, %19022
  %19029 = phi i32 [ %.pre619, %19022 ], [ %19028, %19024 ]
  %19030 = phi i64 [ %.pre618, %19022 ], [ %19014, %19024 ]
  %19031 = phi %struct.Memory* [ %19023, %19022 ], [ %18981, %19024 ]
  %19032 = load i64, i64* %RBP.i, align 8
  %19033 = add i64 %19032, -1432
  %19034 = add i64 %19030, 6
  store i64 %19034, i64* %3, align 8
  %19035 = inttoptr i64 %19033 to i32*
  %19036 = load i32, i32* %19035, align 4
  %19037 = add i32 %19029, %19036
  %19038 = zext i32 %19037 to i64
  store i64 %19038, i64* %RDI.i2141, align 8
  %19039 = icmp ult i32 %19037, %19036
  %19040 = icmp ult i32 %19037, %19029
  %19041 = or i1 %19039, %19040
  %19042 = zext i1 %19041 to i8
  store i8 %19042, i8* %18, align 1
  %19043 = and i32 %19037, 255
  %19044 = tail call i32 @llvm.ctpop.i32(i32 %19043)
  %19045 = trunc i32 %19044 to i8
  %19046 = and i8 %19045, 1
  %19047 = xor i8 %19046, 1
  store i8 %19047, i8* %19, align 1
  %19048 = xor i32 %19029, %19036
  %19049 = xor i32 %19048, %19037
  %19050 = lshr i32 %19049, 4
  %19051 = trunc i32 %19050 to i8
  %19052 = and i8 %19051, 1
  store i8 %19052, i8* %20, align 1
  %19053 = icmp eq i32 %19037, 0
  %19054 = zext i1 %19053 to i8
  store i8 %19054, i8* %21, align 1
  %19055 = lshr i32 %19037, 31
  %19056 = trunc i32 %19055 to i8
  store i8 %19056, i8* %22, align 1
  %19057 = lshr i32 %19036, 31
  %19058 = lshr i32 %19029, 31
  %19059 = xor i32 %19055, %19057
  %19060 = xor i32 %19055, %19058
  %19061 = add nuw nsw i32 %19059, %19060
  %19062 = icmp eq i32 %19061, 2
  %19063 = zext i1 %19062 to i8
  store i8 %19063, i8* %23, align 1
  %19064 = sext i32 %19037 to i64
  store i64 %19064, i64* %26, align 8
  %19065 = add i64 %19032, -1424
  %19066 = add i64 %19030, 17
  store i64 %19066, i64* %3, align 8
  %19067 = inttoptr i64 %19065 to i32*
  %19068 = load i32, i32* %19067, align 4
  %19069 = zext i32 %19068 to i64
  store i64 %19069, i64* %RAX.i1763, align 8
  %19070 = load i64, i64* %RCX.i1692, align 8
  %19071 = shl nsw i64 %19064, 2
  %19072 = add i64 %19071, %19070
  %19073 = add i64 %19030, 21
  store i64 %19073, i64* %3, align 8
  %19074 = inttoptr i64 %19072 to i32*
  store i32 %19068, i32* %19074, align 4
  %19075 = load i64, i64* %RBP.i, align 8
  %19076 = add i64 %19075, -48
  %19077 = load i64, i64* %3, align 8
  %19078 = add i64 %19077, 7
  store i64 %19078, i64* %3, align 8
  %19079 = inttoptr i64 %19076 to i32*
  store i32 0, i32* %19079, align 4
  %.pre620 = load i64, i64* %3, align 8
  br label %block_.L_4a6a8b

block_.L_4a6a8b:                                  ; preds = %block_.L_4a6b01, %routine_idivl__esi.exit
  %19080 = phi i64 [ %19354, %block_.L_4a6b01 ], [ %.pre620, %routine_idivl__esi.exit ]
  %19081 = load i64, i64* %RBP.i, align 8
  %19082 = add i64 %19081, -48
  %19083 = add i64 %19080, 4
  store i64 %19083, i64* %3, align 8
  %19084 = inttoptr i64 %19082 to i32*
  %19085 = load i32, i32* %19084, align 4
  %19086 = add i32 %19085, -4
  %19087 = icmp ult i32 %19085, 4
  %19088 = zext i1 %19087 to i8
  store i8 %19088, i8* %18, align 1
  %19089 = and i32 %19086, 255
  %19090 = tail call i32 @llvm.ctpop.i32(i32 %19089)
  %19091 = trunc i32 %19090 to i8
  %19092 = and i8 %19091, 1
  %19093 = xor i8 %19092, 1
  store i8 %19093, i8* %19, align 1
  %19094 = xor i32 %19086, %19085
  %19095 = lshr i32 %19094, 4
  %19096 = trunc i32 %19095 to i8
  %19097 = and i8 %19096, 1
  store i8 %19097, i8* %20, align 1
  %19098 = icmp eq i32 %19086, 0
  %19099 = zext i1 %19098 to i8
  store i8 %19099, i8* %21, align 1
  %19100 = lshr i32 %19086, 31
  %19101 = trunc i32 %19100 to i8
  store i8 %19101, i8* %22, align 1
  %19102 = lshr i32 %19085, 31
  %19103 = xor i32 %19100, %19102
  %19104 = add nuw nsw i32 %19103, %19102
  %19105 = icmp eq i32 %19104, 2
  %19106 = zext i1 %19105 to i8
  store i8 %19106, i8* %23, align 1
  %19107 = icmp ne i8 %19101, 0
  %19108 = xor i1 %19107, %19105
  %.v767 = select i1 %19108, i64 10, i64 137
  %19109 = add i64 %19080, %.v767
  store i64 %19109, i64* %3, align 8
  br i1 %19108, label %block_4a6a95, label %block_.L_4a6b14

block_4a6a95:                                     ; preds = %block_.L_4a6a8b
  %19110 = add i64 %19081, -44
  %19111 = add i64 %19109, 7
  store i64 %19111, i64* %3, align 8
  %19112 = inttoptr i64 %19110 to i32*
  store i32 0, i32* %19112, align 4
  %.pre621 = load i64, i64* %3, align 8
  br label %block_.L_4a6a9c

block_.L_4a6a9c:                                  ; preds = %block_4a6aa6, %block_4a6a95
  %19113 = phi i64 [ %19324, %block_4a6aa6 ], [ %.pre621, %block_4a6a95 ]
  %19114 = load i64, i64* %RBP.i, align 8
  %19115 = add i64 %19114, -44
  %19116 = add i64 %19113, 4
  store i64 %19116, i64* %3, align 8
  %19117 = inttoptr i64 %19115 to i32*
  %19118 = load i32, i32* %19117, align 4
  %19119 = add i32 %19118, -4
  %19120 = icmp ult i32 %19118, 4
  %19121 = zext i1 %19120 to i8
  store i8 %19121, i8* %18, align 1
  %19122 = and i32 %19119, 255
  %19123 = tail call i32 @llvm.ctpop.i32(i32 %19122)
  %19124 = trunc i32 %19123 to i8
  %19125 = and i8 %19124, 1
  %19126 = xor i8 %19125, 1
  store i8 %19126, i8* %19, align 1
  %19127 = xor i32 %19119, %19118
  %19128 = lshr i32 %19127, 4
  %19129 = trunc i32 %19128 to i8
  %19130 = and i8 %19129, 1
  store i8 %19130, i8* %20, align 1
  %19131 = icmp eq i32 %19119, 0
  %19132 = zext i1 %19131 to i8
  store i8 %19132, i8* %21, align 1
  %19133 = lshr i32 %19119, 31
  %19134 = trunc i32 %19133 to i8
  store i8 %19134, i8* %22, align 1
  %19135 = lshr i32 %19118, 31
  %19136 = xor i32 %19133, %19135
  %19137 = add nuw nsw i32 %19136, %19135
  %19138 = icmp eq i32 %19137, 2
  %19139 = zext i1 %19138 to i8
  store i8 %19139, i8* %23, align 1
  %19140 = icmp ne i8 %19134, 0
  %19141 = xor i1 %19140, %19138
  %.v768 = select i1 %19141, i64 10, i64 101
  %19142 = add i64 %19113, %.v768
  store i64 %19142, i64* %3, align 8
  br i1 %19141, label %block_4a6aa6, label %block_.L_4a6b01

block_4a6aa6:                                     ; preds = %block_.L_4a6a9c
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RAX.i1763, align 8
  %19143 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %19144 = add i64 %19143, 13112
  store i64 %19144, i64* %RCX.i1692, align 8
  %19145 = icmp ugt i64 %19143, -13113
  %19146 = zext i1 %19145 to i8
  store i8 %19146, i8* %18, align 1
  %19147 = trunc i64 %19144 to i32
  %19148 = and i32 %19147, 255
  %19149 = tail call i32 @llvm.ctpop.i32(i32 %19148)
  %19150 = trunc i32 %19149 to i8
  %19151 = and i8 %19150, 1
  %19152 = xor i8 %19151, 1
  store i8 %19152, i8* %19, align 1
  %19153 = xor i64 %19143, 16
  %19154 = xor i64 %19153, %19144
  %19155 = lshr i64 %19154, 4
  %19156 = trunc i64 %19155 to i8
  %19157 = and i8 %19156, 1
  store i8 %19157, i8* %20, align 1
  %19158 = icmp eq i64 %19144, 0
  %19159 = zext i1 %19158 to i8
  store i8 %19159, i8* %21, align 1
  %19160 = lshr i64 %19144, 63
  %19161 = trunc i64 %19160 to i8
  store i8 %19161, i8* %22, align 1
  %19162 = lshr i64 %19143, 63
  %19163 = xor i64 %19160, %19162
  %19164 = add nuw nsw i64 %19163, %19160
  %19165 = icmp eq i64 %19164, 2
  %19166 = zext i1 %19165 to i8
  store i8 %19166, i8* %23, align 1
  %19167 = add i64 %19142, 29
  store i64 %19167, i64* %3, align 8
  %19168 = load i32, i32* %19117, align 4
  %19169 = sext i32 %19168 to i64
  %19170 = shl nsw i64 %19169, 6
  store i64 %19170, i64* %RDX.i1805, align 8
  %19171 = add i64 %19170, %19144
  store i64 %19171, i64* %RCX.i1692, align 8
  %19172 = icmp ult i64 %19171, %19144
  %19173 = icmp ult i64 %19171, %19170
  %19174 = or i1 %19172, %19173
  %19175 = zext i1 %19174 to i8
  store i8 %19175, i8* %18, align 1
  %19176 = trunc i64 %19171 to i32
  %19177 = and i32 %19176, 255
  %19178 = tail call i32 @llvm.ctpop.i32(i32 %19177)
  %19179 = trunc i32 %19178 to i8
  %19180 = and i8 %19179, 1
  %19181 = xor i8 %19180, 1
  store i8 %19181, i8* %19, align 1
  %19182 = xor i64 %19144, %19171
  %19183 = lshr i64 %19182, 4
  %19184 = trunc i64 %19183 to i8
  %19185 = and i8 %19184, 1
  store i8 %19185, i8* %20, align 1
  %19186 = icmp eq i64 %19171, 0
  %19187 = zext i1 %19186 to i8
  store i8 %19187, i8* %21, align 1
  %19188 = lshr i64 %19171, 63
  %19189 = trunc i64 %19188 to i8
  store i8 %19189, i8* %22, align 1
  %19190 = lshr i64 %19169, 57
  %19191 = and i64 %19190, 1
  %19192 = xor i64 %19188, %19160
  %19193 = xor i64 %19188, %19191
  %19194 = add nuw nsw i64 %19192, %19193
  %19195 = icmp eq i64 %19194, 2
  %19196 = zext i1 %19195 to i8
  store i8 %19196, i8* %23, align 1
  %19197 = load i64, i64* %RBP.i, align 8
  %19198 = add i64 %19197, -48
  %19199 = add i64 %19142, 40
  store i64 %19199, i64* %3, align 8
  %19200 = inttoptr i64 %19198 to i32*
  %19201 = load i32, i32* %19200, align 4
  %19202 = sext i32 %19201 to i64
  store i64 %19202, i64* %RDX.i1805, align 8
  %19203 = shl nsw i64 %19202, 2
  %19204 = add i64 %19203, %19171
  %19205 = add i64 %19142, 43
  store i64 %19205, i64* %3, align 8
  %19206 = inttoptr i64 %19204 to i32*
  %19207 = load i32, i32* %19206, align 4
  %19208 = zext i32 %19207 to i64
  store i64 %19208, i64* %RSI.i1889, align 8
  %19209 = add i64 %19197, -44
  %19210 = add i64 %19142, 46
  store i64 %19210, i64* %3, align 8
  %19211 = inttoptr i64 %19209 to i32*
  %19212 = load i32, i32* %19211, align 4
  %19213 = zext i32 %19212 to i64
  store i64 %19213, i64* %RDI.i2141, align 8
  %19214 = add i64 %19197, -476
  %19215 = add i64 %19142, 52
  store i64 %19215, i64* %3, align 8
  %19216 = inttoptr i64 %19214 to i32*
  %19217 = load i32, i32* %19216, align 4
  %19218 = add i32 %19217, %19212
  %19219 = zext i32 %19218 to i64
  store i64 %19219, i64* %RDI.i2141, align 8
  %19220 = sext i32 %19218 to i64
  %19221 = shl nsw i64 %19220, 6
  store i64 %19221, i64* %RCX.i1692, align 8
  %19222 = load i64, i64* %RAX.i1763, align 8
  %19223 = add i64 %19221, %19222
  store i64 %19223, i64* %RAX.i1763, align 8
  %19224 = icmp ult i64 %19223, %19222
  %19225 = icmp ult i64 %19223, %19221
  %19226 = or i1 %19224, %19225
  %19227 = zext i1 %19226 to i8
  store i8 %19227, i8* %18, align 1
  %19228 = trunc i64 %19223 to i32
  %19229 = and i32 %19228, 255
  %19230 = tail call i32 @llvm.ctpop.i32(i32 %19229)
  %19231 = trunc i32 %19230 to i8
  %19232 = and i8 %19231, 1
  %19233 = xor i8 %19232, 1
  store i8 %19233, i8* %19, align 1
  %19234 = xor i64 %19222, %19223
  %19235 = lshr i64 %19234, 4
  %19236 = trunc i64 %19235 to i8
  %19237 = and i8 %19236, 1
  store i8 %19237, i8* %20, align 1
  %19238 = icmp eq i64 %19223, 0
  %19239 = zext i1 %19238 to i8
  store i8 %19239, i8* %21, align 1
  %19240 = lshr i64 %19223, 63
  %19241 = trunc i64 %19240 to i8
  store i8 %19241, i8* %22, align 1
  %19242 = lshr i64 %19222, 63
  %19243 = lshr i64 %19220, 57
  %19244 = and i64 %19243, 1
  %19245 = xor i64 %19240, %19242
  %19246 = xor i64 %19240, %19244
  %19247 = add nuw nsw i64 %19245, %19246
  %19248 = icmp eq i64 %19247, 2
  %19249 = zext i1 %19248 to i8
  store i8 %19249, i8* %23, align 1
  %19250 = load i64, i64* %RBP.i, align 8
  %19251 = add i64 %19250, -48
  %19252 = add i64 %19142, 65
  store i64 %19252, i64* %3, align 8
  %19253 = inttoptr i64 %19251 to i32*
  %19254 = load i32, i32* %19253, align 4
  %19255 = zext i32 %19254 to i64
  store i64 %19255, i64* %RDI.i2141, align 8
  %19256 = add i64 %19250, -480
  %19257 = add i64 %19142, 71
  store i64 %19257, i64* %3, align 8
  %19258 = inttoptr i64 %19256 to i32*
  %19259 = load i32, i32* %19258, align 4
  %19260 = add i32 %19259, %19254
  %19261 = zext i32 %19260 to i64
  store i64 %19261, i64* %RDI.i2141, align 8
  %19262 = icmp ult i32 %19260, %19254
  %19263 = icmp ult i32 %19260, %19259
  %19264 = or i1 %19262, %19263
  %19265 = zext i1 %19264 to i8
  store i8 %19265, i8* %18, align 1
  %19266 = and i32 %19260, 255
  %19267 = tail call i32 @llvm.ctpop.i32(i32 %19266)
  %19268 = trunc i32 %19267 to i8
  %19269 = and i8 %19268, 1
  %19270 = xor i8 %19269, 1
  store i8 %19270, i8* %19, align 1
  %19271 = xor i32 %19259, %19254
  %19272 = xor i32 %19271, %19260
  %19273 = lshr i32 %19272, 4
  %19274 = trunc i32 %19273 to i8
  %19275 = and i8 %19274, 1
  store i8 %19275, i8* %20, align 1
  %19276 = icmp eq i32 %19260, 0
  %19277 = zext i1 %19276 to i8
  store i8 %19277, i8* %21, align 1
  %19278 = lshr i32 %19260, 31
  %19279 = trunc i32 %19278 to i8
  store i8 %19279, i8* %22, align 1
  %19280 = lshr i32 %19254, 31
  %19281 = lshr i32 %19259, 31
  %19282 = xor i32 %19278, %19280
  %19283 = xor i32 %19278, %19281
  %19284 = add nuw nsw i32 %19282, %19283
  %19285 = icmp eq i32 %19284, 2
  %19286 = zext i1 %19285 to i8
  store i8 %19286, i8* %23, align 1
  %19287 = sext i32 %19260 to i64
  store i64 %19287, i64* %RCX.i1692, align 8
  %19288 = shl nsw i64 %19287, 2
  %19289 = add i64 %19223, %19288
  %19290 = load i32, i32* %ESI.i7670, align 4
  %19291 = add i64 %19142, 77
  store i64 %19291, i64* %3, align 8
  %19292 = inttoptr i64 %19289 to i32*
  store i32 %19290, i32* %19292, align 4
  %19293 = load i64, i64* %RBP.i, align 8
  %19294 = add i64 %19293, -44
  %19295 = load i64, i64* %3, align 8
  %19296 = add i64 %19295, 3
  store i64 %19296, i64* %3, align 8
  %19297 = inttoptr i64 %19294 to i32*
  %19298 = load i32, i32* %19297, align 4
  %19299 = add i32 %19298, 1
  %19300 = zext i32 %19299 to i64
  store i64 %19300, i64* %RAX.i1763, align 8
  %19301 = icmp eq i32 %19298, -1
  %19302 = icmp eq i32 %19299, 0
  %19303 = or i1 %19301, %19302
  %19304 = zext i1 %19303 to i8
  store i8 %19304, i8* %18, align 1
  %19305 = and i32 %19299, 255
  %19306 = tail call i32 @llvm.ctpop.i32(i32 %19305)
  %19307 = trunc i32 %19306 to i8
  %19308 = and i8 %19307, 1
  %19309 = xor i8 %19308, 1
  store i8 %19309, i8* %19, align 1
  %19310 = xor i32 %19299, %19298
  %19311 = lshr i32 %19310, 4
  %19312 = trunc i32 %19311 to i8
  %19313 = and i8 %19312, 1
  store i8 %19313, i8* %20, align 1
  %19314 = zext i1 %19302 to i8
  store i8 %19314, i8* %21, align 1
  %19315 = lshr i32 %19299, 31
  %19316 = trunc i32 %19315 to i8
  store i8 %19316, i8* %22, align 1
  %19317 = lshr i32 %19298, 31
  %19318 = xor i32 %19315, %19317
  %19319 = add nuw nsw i32 %19318, %19315
  %19320 = icmp eq i32 %19319, 2
  %19321 = zext i1 %19320 to i8
  store i8 %19321, i8* %23, align 1
  %19322 = add i64 %19295, 9
  store i64 %19322, i64* %3, align 8
  store i32 %19299, i32* %19297, align 4
  %19323 = load i64, i64* %3, align 8
  %19324 = add i64 %19323, -96
  store i64 %19324, i64* %3, align 8
  br label %block_.L_4a6a9c

block_.L_4a6b01:                                  ; preds = %block_.L_4a6a9c
  %19325 = add i64 %19114, -48
  %19326 = add i64 %19142, 8
  store i64 %19326, i64* %3, align 8
  %19327 = inttoptr i64 %19325 to i32*
  %19328 = load i32, i32* %19327, align 4
  %19329 = add i32 %19328, 1
  %19330 = zext i32 %19329 to i64
  store i64 %19330, i64* %RAX.i1763, align 8
  %19331 = icmp eq i32 %19328, -1
  %19332 = icmp eq i32 %19329, 0
  %19333 = or i1 %19331, %19332
  %19334 = zext i1 %19333 to i8
  store i8 %19334, i8* %18, align 1
  %19335 = and i32 %19329, 255
  %19336 = tail call i32 @llvm.ctpop.i32(i32 %19335)
  %19337 = trunc i32 %19336 to i8
  %19338 = and i8 %19337, 1
  %19339 = xor i8 %19338, 1
  store i8 %19339, i8* %19, align 1
  %19340 = xor i32 %19329, %19328
  %19341 = lshr i32 %19340, 4
  %19342 = trunc i32 %19341 to i8
  %19343 = and i8 %19342, 1
  store i8 %19343, i8* %20, align 1
  %19344 = zext i1 %19332 to i8
  store i8 %19344, i8* %21, align 1
  %19345 = lshr i32 %19329, 31
  %19346 = trunc i32 %19345 to i8
  store i8 %19346, i8* %22, align 1
  %19347 = lshr i32 %19328, 31
  %19348 = xor i32 %19345, %19347
  %19349 = add nuw nsw i32 %19348, %19345
  %19350 = icmp eq i32 %19349, 2
  %19351 = zext i1 %19350 to i8
  store i8 %19351, i8* %23, align 1
  %19352 = add i64 %19142, 14
  store i64 %19352, i64* %3, align 8
  store i32 %19329, i32* %19327, align 4
  %19353 = load i64, i64* %3, align 8
  %19354 = add i64 %19353, -132
  store i64 %19354, i64* %3, align 8
  br label %block_.L_4a6a8b

block_.L_4a6b14:                                  ; preds = %block_.L_4a6a8b
  %19355 = add i64 %19081, -628
  %19356 = add i64 %19109, 11
  store i64 %19356, i64* %3, align 8
  %19357 = inttoptr i64 %19355 to i32*
  %19358 = load i32, i32* %19357, align 4
  %19359 = add i32 %19358, 1
  %19360 = zext i32 %19359 to i64
  store i64 %19360, i64* %RAX.i1763, align 8
  %19361 = icmp eq i32 %19358, -1
  %19362 = icmp eq i32 %19359, 0
  %19363 = or i1 %19361, %19362
  %19364 = zext i1 %19363 to i8
  store i8 %19364, i8* %18, align 1
  %19365 = and i32 %19359, 255
  %19366 = tail call i32 @llvm.ctpop.i32(i32 %19365)
  %19367 = trunc i32 %19366 to i8
  %19368 = and i8 %19367, 1
  %19369 = xor i8 %19368, 1
  store i8 %19369, i8* %19, align 1
  %19370 = xor i32 %19359, %19358
  %19371 = lshr i32 %19370, 4
  %19372 = trunc i32 %19371 to i8
  %19373 = and i8 %19372, 1
  store i8 %19373, i8* %20, align 1
  %19374 = zext i1 %19362 to i8
  store i8 %19374, i8* %21, align 1
  %19375 = lshr i32 %19359, 31
  %19376 = trunc i32 %19375 to i8
  store i8 %19376, i8* %22, align 1
  %19377 = lshr i32 %19358, 31
  %19378 = xor i32 %19375, %19377
  %19379 = add nuw nsw i32 %19378, %19375
  %19380 = icmp eq i32 %19379, 2
  %19381 = zext i1 %19380 to i8
  store i8 %19381, i8* %23, align 1
  %19382 = add i64 %19109, 20
  store i64 %19382, i64* %3, align 8
  store i32 %19359, i32* %19357, align 4
  %19383 = load i64, i64* %3, align 8
  %19384 = add i64 %19383, -1330
  store i64 %19384, i64* %3, align 8
  br label %block_.L_4a65f6

block_.L_4a6b2d:                                  ; preds = %block_.L_4a65f6
  %19385 = add i64 %16705, -48
  %19386 = add i64 %16733, 7
  store i64 %19386, i64* %3, align 8
  %19387 = inttoptr i64 %19385 to i32*
  store i32 0, i32* %19387, align 4
  %.pre543 = load i64, i64* %3, align 8
  br label %block_.L_4a6b34

block_.L_4a6b34:                                  ; preds = %block_.L_4a71a9, %block_.L_4a6b2d
  %19388 = phi i64 [ %22464, %block_.L_4a71a9 ], [ %.pre543, %block_.L_4a6b2d ]
  %19389 = load i64, i64* %RBP.i, align 8
  %19390 = add i64 %19389, -48
  %19391 = add i64 %19388, 4
  store i64 %19391, i64* %3, align 8
  %19392 = inttoptr i64 %19390 to i32*
  %19393 = load i32, i32* %19392, align 4
  %19394 = add i32 %19393, -8
  %19395 = icmp ult i32 %19393, 8
  %19396 = zext i1 %19395 to i8
  store i8 %19396, i8* %18, align 1
  %19397 = and i32 %19394, 255
  %19398 = tail call i32 @llvm.ctpop.i32(i32 %19397)
  %19399 = trunc i32 %19398 to i8
  %19400 = and i8 %19399, 1
  %19401 = xor i8 %19400, 1
  store i8 %19401, i8* %19, align 1
  %19402 = xor i32 %19394, %19393
  %19403 = lshr i32 %19402, 4
  %19404 = trunc i32 %19403 to i8
  %19405 = and i8 %19404, 1
  store i8 %19405, i8* %20, align 1
  %19406 = icmp eq i32 %19394, 0
  %19407 = zext i1 %19406 to i8
  store i8 %19407, i8* %21, align 1
  %19408 = lshr i32 %19394, 31
  %19409 = trunc i32 %19408 to i8
  store i8 %19409, i8* %22, align 1
  %19410 = lshr i32 %19393, 31
  %19411 = xor i32 %19408, %19410
  %19412 = add nuw nsw i32 %19411, %19410
  %19413 = icmp eq i32 %19412, 2
  %19414 = zext i1 %19413 to i8
  store i8 %19414, i8* %23, align 1
  %19415 = icmp ne i8 %19409, 0
  %19416 = xor i1 %19415, %19413
  %.v827 = select i1 %19416, i64 10, i64 1672
  %19417 = add i64 %19388, %.v827
  store i64 %19417, i64* %3, align 8
  br i1 %19416, label %block_4a6b3e, label %block_.L_4a71bc

block_4a6b3e:                                     ; preds = %block_.L_4a6b34
  %19418 = add i64 %19389, -44
  %19419 = add i64 %19417, 7
  store i64 %19419, i64* %3, align 8
  %19420 = inttoptr i64 %19418 to i32*
  store i32 0, i32* %19420, align 4
  %.pre544 = load i64, i64* %3, align 8
  br label %block_.L_4a6b45

block_.L_4a6b45:                                  ; preds = %block_.L_4a715f, %block_4a6b3e
  %19421 = phi i64 [ %22434, %block_.L_4a715f ], [ %.pre544, %block_4a6b3e ]
  %19422 = load i64, i64* %RBP.i, align 8
  %19423 = add i64 %19422, -44
  %19424 = add i64 %19421, 4
  store i64 %19424, i64* %3, align 8
  %19425 = inttoptr i64 %19423 to i32*
  %19426 = load i32, i32* %19425, align 4
  %19427 = add i32 %19426, -8
  %19428 = icmp ult i32 %19426, 8
  %19429 = zext i1 %19428 to i8
  store i8 %19429, i8* %18, align 1
  %19430 = and i32 %19427, 255
  %19431 = tail call i32 @llvm.ctpop.i32(i32 %19430)
  %19432 = trunc i32 %19431 to i8
  %19433 = and i8 %19432, 1
  %19434 = xor i8 %19433, 1
  store i8 %19434, i8* %19, align 1
  %19435 = xor i32 %19427, %19426
  %19436 = lshr i32 %19435, 4
  %19437 = trunc i32 %19436 to i8
  %19438 = and i8 %19437, 1
  store i8 %19438, i8* %20, align 1
  %19439 = icmp eq i32 %19427, 0
  %19440 = zext i1 %19439 to i8
  store i8 %19440, i8* %21, align 1
  %19441 = lshr i32 %19427, 31
  %19442 = trunc i32 %19441 to i8
  store i8 %19442, i8* %22, align 1
  %19443 = lshr i32 %19426, 31
  %19444 = xor i32 %19441, %19443
  %19445 = add nuw nsw i32 %19444, %19443
  %19446 = icmp eq i32 %19445, 2
  %19447 = zext i1 %19446 to i8
  store i8 %19447, i8* %23, align 1
  %19448 = icmp ne i8 %19442, 0
  %19449 = xor i1 %19448, %19446
  %.v766 = select i1 %19449, i64 10, i64 1636
  %19450 = add i64 %19421, %.v766
  store i64 %19450, i64* %3, align 8
  br i1 %19449, label %block_4a6b4f, label %block_.L_4a71a9

block_4a6b4f:                                     ; preds = %block_.L_4a6b45
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX.i1692, align 8
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RDX.i1805, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RSI.i1889, align 8
  %19451 = add i64 %19450, 36
  store i64 %19451, i64* %3, align 8
  %19452 = load i32, i32* %19425, align 4
  %19453 = sext i32 %19452 to i64
  %19454 = shl nsw i64 %19453, 6
  store i64 %19454, i64* %RDI.i2141, align 8
  %19455 = add i64 %19454, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  store i64 %19455, i64* %RSI.i1889, align 8
  %19456 = icmp ult i64 %19455, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  %19457 = icmp ult i64 %19455, %19454
  %19458 = or i1 %19456, %19457
  %19459 = zext i1 %19458 to i8
  store i8 %19459, i8* %18, align 1
  %19460 = trunc i64 %19455 to i32
  %19461 = and i32 %19460, 248
  %19462 = tail call i32 @llvm.ctpop.i32(i32 %19461)
  %19463 = trunc i32 %19462 to i8
  %19464 = and i8 %19463, 1
  %19465 = xor i8 %19464, 1
  store i8 %19465, i8* %19, align 1
  %19466 = xor i64 %19455, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  %19467 = lshr i64 %19466, 4
  %19468 = trunc i64 %19467 to i8
  %19469 = and i8 %19468, 1
  store i8 %19469, i8* %20, align 1
  %19470 = icmp eq i64 %19455, 0
  %19471 = zext i1 %19470 to i8
  store i8 %19471, i8* %21, align 1
  %19472 = lshr i64 %19455, 63
  %19473 = trunc i64 %19472 to i8
  store i8 %19473, i8* %22, align 1
  %19474 = lshr i64 %19453, 57
  %19475 = and i64 %19474, 1
  %19476 = xor i64 %19472, lshr (i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64 63)
  %19477 = xor i64 %19472, %19475
  %19478 = add nuw nsw i64 %19476, %19477
  %19479 = icmp eq i64 %19478, 2
  %19480 = zext i1 %19479 to i8
  store i8 %19480, i8* %23, align 1
  %19481 = add i64 %19422, -48
  %19482 = add i64 %19450, 47
  store i64 %19482, i64* %3, align 8
  %19483 = inttoptr i64 %19481 to i32*
  %19484 = load i32, i32* %19483, align 4
  %19485 = sext i32 %19484 to i64
  store i64 %19485, i64* %RDI.i2141, align 8
  %19486 = shl nsw i64 %19485, 2
  %19487 = add i64 %19486, %19455
  %19488 = add i64 %19450, 51
  store i64 %19488, i64* %3, align 8
  %19489 = inttoptr i64 %19487 to i32*
  %19490 = load i32, i32* %19489, align 4
  %19491 = zext i32 %19490 to i64
  store i64 %19491, i64* %26, align 8
  %19492 = load i64, i64* %RBP.i, align 8
  %19493 = add i64 %19492, -44
  %19494 = add i64 %19450, 55
  store i64 %19494, i64* %3, align 8
  %19495 = inttoptr i64 %19493 to i32*
  %19496 = load i32, i32* %19495, align 4
  %19497 = sext i32 %19496 to i64
  %19498 = shl nsw i64 %19497, 6
  store i64 %19498, i64* %RSI.i1889, align 8
  %19499 = load i64, i64* %RDX.i1805, align 8
  %19500 = add i64 %19498, %19499
  store i64 %19500, i64* %RDI.i2141, align 8
  %19501 = icmp ult i64 %19500, %19499
  %19502 = icmp ult i64 %19500, %19498
  %19503 = or i1 %19501, %19502
  %19504 = zext i1 %19503 to i8
  store i8 %19504, i8* %18, align 1
  %19505 = trunc i64 %19500 to i32
  %19506 = and i32 %19505, 255
  %19507 = tail call i32 @llvm.ctpop.i32(i32 %19506)
  %19508 = trunc i32 %19507 to i8
  %19509 = and i8 %19508, 1
  %19510 = xor i8 %19509, 1
  store i8 %19510, i8* %19, align 1
  %19511 = xor i64 %19499, %19500
  %19512 = lshr i64 %19511, 4
  %19513 = trunc i64 %19512 to i8
  %19514 = and i8 %19513, 1
  store i8 %19514, i8* %20, align 1
  %19515 = icmp eq i64 %19500, 0
  %19516 = zext i1 %19515 to i8
  store i8 %19516, i8* %21, align 1
  %19517 = lshr i64 %19500, 63
  %19518 = trunc i64 %19517 to i8
  store i8 %19518, i8* %22, align 1
  %19519 = lshr i64 %19499, 63
  %19520 = lshr i64 %19497, 57
  %19521 = and i64 %19520, 1
  %19522 = xor i64 %19517, %19519
  %19523 = xor i64 %19517, %19521
  %19524 = add nuw nsw i64 %19522, %19523
  %19525 = icmp eq i64 %19524, 2
  %19526 = zext i1 %19525 to i8
  store i8 %19526, i8* %23, align 1
  %19527 = add i64 %19492, -48
  %19528 = add i64 %19450, 69
  store i64 %19528, i64* %3, align 8
  %19529 = inttoptr i64 %19527 to i32*
  %19530 = load i32, i32* %19529, align 4
  %19531 = sext i32 %19530 to i64
  store i64 %19531, i64* %RSI.i1889, align 8
  %19532 = shl nsw i64 %19531, 2
  %19533 = add i64 %19532, %19500
  %19534 = add i64 %19450, 73
  store i64 %19534, i64* %3, align 8
  %19535 = inttoptr i64 %19533 to i32*
  %19536 = load i32, i32* %19535, align 4
  %19537 = zext i32 %19536 to i64
  %19538 = shl nuw i64 %19537, 32
  %19539 = ashr i64 %19538, 33
  %19540 = and i64 %19539, 4294967295
  store i64 %19540, i64* %R9.i, align 8
  %19541 = load i32, i32* %R8D.i1718, align 4
  %19542 = trunc i64 %19539 to i32
  %19543 = sub i32 %19541, %19542
  %19544 = zext i32 %19543 to i64
  store i64 %19544, i64* %26, align 8
  %19545 = icmp ult i32 %19541, %19542
  %19546 = zext i1 %19545 to i8
  store i8 %19546, i8* %18, align 1
  %19547 = and i32 %19543, 255
  %19548 = tail call i32 @llvm.ctpop.i32(i32 %19547)
  %19549 = trunc i32 %19548 to i8
  %19550 = and i8 %19549, 1
  %19551 = xor i8 %19550, 1
  store i8 %19551, i8* %19, align 1
  %19552 = xor i32 %19542, %19541
  %19553 = xor i32 %19552, %19543
  %19554 = lshr i32 %19553, 4
  %19555 = trunc i32 %19554 to i8
  %19556 = and i8 %19555, 1
  store i8 %19556, i8* %20, align 1
  %19557 = icmp eq i32 %19543, 0
  %19558 = zext i1 %19557 to i8
  store i8 %19558, i8* %21, align 1
  %19559 = lshr i32 %19543, 31
  %19560 = trunc i32 %19559 to i8
  store i8 %19560, i8* %22, align 1
  %19561 = lshr i32 %19541, 31
  %19562 = lshr i64 %19539, 31
  %19563 = trunc i64 %19562 to i32
  %19564 = and i32 %19563, 1
  %19565 = xor i32 %19564, %19561
  %19566 = xor i32 %19559, %19561
  %19567 = add nuw nsw i32 %19566, %19565
  %19568 = icmp eq i32 %19567, 2
  %19569 = zext i1 %19568 to i8
  store i8 %19569, i8* %23, align 1
  %19570 = load i64, i64* %RBP.i, align 8
  %19571 = add i64 %19570, -624
  %19572 = add i64 %19450, 86
  store i64 %19572, i64* %3, align 8
  %19573 = inttoptr i64 %19571 to i32*
  store i32 %19543, i32* %19573, align 4
  %19574 = load i64, i64* %RBP.i, align 8
  %19575 = add i64 %19574, -44
  %19576 = load i64, i64* %3, align 8
  %19577 = add i64 %19576, 4
  store i64 %19577, i64* %3, align 8
  %19578 = inttoptr i64 %19575 to i32*
  %19579 = load i32, i32* %19578, align 4
  %19580 = sext i32 %19579 to i64
  %19581 = shl nsw i64 %19580, 6
  store i64 %19581, i64* %RSI.i1889, align 8
  %19582 = load i64, i64* %RDX.i1805, align 8
  %19583 = add i64 %19581, %19582
  store i64 %19583, i64* %RDX.i1805, align 8
  %19584 = icmp ult i64 %19583, %19582
  %19585 = icmp ult i64 %19583, %19581
  %19586 = or i1 %19584, %19585
  %19587 = zext i1 %19586 to i8
  store i8 %19587, i8* %18, align 1
  %19588 = trunc i64 %19583 to i32
  %19589 = and i32 %19588, 255
  %19590 = tail call i32 @llvm.ctpop.i32(i32 %19589)
  %19591 = trunc i32 %19590 to i8
  %19592 = and i8 %19591, 1
  %19593 = xor i8 %19592, 1
  store i8 %19593, i8* %19, align 1
  %19594 = xor i64 %19582, %19583
  %19595 = lshr i64 %19594, 4
  %19596 = trunc i64 %19595 to i8
  %19597 = and i8 %19596, 1
  store i8 %19597, i8* %20, align 1
  %19598 = icmp eq i64 %19583, 0
  %19599 = zext i1 %19598 to i8
  store i8 %19599, i8* %21, align 1
  %19600 = lshr i64 %19583, 63
  %19601 = trunc i64 %19600 to i8
  store i8 %19601, i8* %22, align 1
  %19602 = lshr i64 %19582, 63
  %19603 = lshr i64 %19580, 57
  %19604 = and i64 %19603, 1
  %19605 = xor i64 %19600, %19602
  %19606 = xor i64 %19600, %19604
  %19607 = add nuw nsw i64 %19605, %19606
  %19608 = icmp eq i64 %19607, 2
  %19609 = zext i1 %19608 to i8
  store i8 %19609, i8* %23, align 1
  %19610 = add i64 %19574, -48
  %19611 = add i64 %19576, 15
  store i64 %19611, i64* %3, align 8
  %19612 = inttoptr i64 %19610 to i32*
  %19613 = load i32, i32* %19612, align 4
  %19614 = sext i32 %19613 to i64
  store i64 %19614, i64* %RSI.i1889, align 8
  %19615 = shl nsw i64 %19614, 2
  %19616 = add i64 %19615, %19583
  %19617 = add i64 %19576, 19
  store i64 %19617, i64* %3, align 8
  %19618 = inttoptr i64 %19616 to i32*
  %19619 = load i32, i32* %19618, align 4
  %19620 = zext i32 %19619 to i64
  store i64 %19620, i64* %26, align 8
  %19621 = add i64 %19574, -624
  %19622 = add i64 %19576, 26
  store i64 %19622, i64* %3, align 8
  %19623 = inttoptr i64 %19621 to i32*
  %19624 = load i32, i32* %19623, align 4
  %19625 = add i32 %19624, %19619
  %19626 = zext i32 %19625 to i64
  store i64 %19626, i64* %26, align 8
  %19627 = icmp ult i32 %19625, %19619
  %19628 = icmp ult i32 %19625, %19624
  %19629 = or i1 %19627, %19628
  %19630 = zext i1 %19629 to i8
  store i8 %19630, i8* %18, align 1
  %19631 = and i32 %19625, 255
  %19632 = tail call i32 @llvm.ctpop.i32(i32 %19631)
  %19633 = trunc i32 %19632 to i8
  %19634 = and i8 %19633, 1
  %19635 = xor i8 %19634, 1
  store i8 %19635, i8* %19, align 1
  %19636 = xor i32 %19624, %19619
  %19637 = xor i32 %19636, %19625
  %19638 = lshr i32 %19637, 4
  %19639 = trunc i32 %19638 to i8
  %19640 = and i8 %19639, 1
  store i8 %19640, i8* %20, align 1
  %19641 = icmp eq i32 %19625, 0
  %19642 = zext i1 %19641 to i8
  store i8 %19642, i8* %21, align 1
  %19643 = lshr i32 %19625, 31
  %19644 = trunc i32 %19643 to i8
  store i8 %19644, i8* %22, align 1
  %19645 = lshr i32 %19619, 31
  %19646 = lshr i32 %19624, 31
  %19647 = xor i32 %19643, %19645
  %19648 = xor i32 %19643, %19646
  %19649 = add nuw nsw i32 %19647, %19648
  %19650 = icmp eq i32 %19649, 2
  %19651 = zext i1 %19650 to i8
  store i8 %19651, i8* %23, align 1
  %19652 = load i64, i64* %RBP.i, align 8
  %19653 = add i64 %19652, -608
  %19654 = add i64 %19576, 33
  store i64 %19654, i64* %3, align 8
  %19655 = inttoptr i64 %19653 to i32*
  store i32 %19625, i32* %19655, align 4
  %19656 = load i64, i64* %RBP.i, align 8
  %19657 = add i64 %19656, -624
  %19658 = load i64, i64* %3, align 8
  %19659 = add i64 %19658, 7
  store i64 %19659, i64* %3, align 8
  %19660 = inttoptr i64 %19657 to i32*
  %19661 = load i32, i32* %19660, align 4
  %19662 = zext i32 %19661 to i64
  store i64 %19662, i64* %26, align 8
  %19663 = add i64 %19656, -44
  %19664 = add i64 %19658, 11
  store i64 %19664, i64* %3, align 8
  %19665 = inttoptr i64 %19663 to i32*
  %19666 = load i32, i32* %19665, align 4
  %19667 = sext i32 %19666 to i64
  %19668 = shl nsw i64 %19667, 6
  store i64 %19668, i64* %RDX.i1805, align 8
  %19669 = load i64, i64* %RCX.i1692, align 8
  %19670 = add i64 %19668, %19669
  store i64 %19670, i64* %RSI.i1889, align 8
  %19671 = icmp ult i64 %19670, %19669
  %19672 = icmp ult i64 %19670, %19668
  %19673 = or i1 %19671, %19672
  %19674 = zext i1 %19673 to i8
  store i8 %19674, i8* %18, align 1
  %19675 = trunc i64 %19670 to i32
  %19676 = and i32 %19675, 255
  %19677 = tail call i32 @llvm.ctpop.i32(i32 %19676)
  %19678 = trunc i32 %19677 to i8
  %19679 = and i8 %19678, 1
  %19680 = xor i8 %19679, 1
  store i8 %19680, i8* %19, align 1
  %19681 = xor i64 %19669, %19670
  %19682 = lshr i64 %19681, 4
  %19683 = trunc i64 %19682 to i8
  %19684 = and i8 %19683, 1
  store i8 %19684, i8* %20, align 1
  %19685 = icmp eq i64 %19670, 0
  %19686 = zext i1 %19685 to i8
  store i8 %19686, i8* %21, align 1
  %19687 = lshr i64 %19670, 63
  %19688 = trunc i64 %19687 to i8
  store i8 %19688, i8* %22, align 1
  %19689 = lshr i64 %19669, 63
  %19690 = lshr i64 %19667, 57
  %19691 = and i64 %19690, 1
  %19692 = xor i64 %19687, %19689
  %19693 = xor i64 %19687, %19691
  %19694 = add nuw nsw i64 %19692, %19693
  %19695 = icmp eq i64 %19694, 2
  %19696 = zext i1 %19695 to i8
  store i8 %19696, i8* %23, align 1
  %19697 = add i64 %19656, -48
  %19698 = add i64 %19658, 25
  store i64 %19698, i64* %3, align 8
  %19699 = inttoptr i64 %19697 to i32*
  %19700 = load i32, i32* %19699, align 4
  %19701 = sext i32 %19700 to i64
  store i64 %19701, i64* %RDX.i1805, align 8
  %19702 = shl nsw i64 %19701, 2
  %19703 = add i64 %19702, %19670
  %19704 = add i64 %19658, 29
  store i64 %19704, i64* %3, align 8
  %19705 = inttoptr i64 %19703 to i32*
  %19706 = load i32, i32* %19705, align 4
  %19707 = zext i32 %19706 to i64
  %19708 = shl nuw i64 %19707, 32
  %19709 = ashr i64 %19708, 33
  %19710 = and i64 %19709, 4294967295
  store i64 %19710, i64* %R9.i, align 8
  %19711 = load i32, i32* %R8D.i1718, align 4
  %19712 = trunc i64 %19709 to i32
  %19713 = sub i32 %19711, %19712
  %19714 = zext i32 %19713 to i64
  store i64 %19714, i64* %26, align 8
  %19715 = icmp ult i32 %19711, %19712
  %19716 = zext i1 %19715 to i8
  store i8 %19716, i8* %18, align 1
  %19717 = and i32 %19713, 255
  %19718 = tail call i32 @llvm.ctpop.i32(i32 %19717)
  %19719 = trunc i32 %19718 to i8
  %19720 = and i8 %19719, 1
  %19721 = xor i8 %19720, 1
  store i8 %19721, i8* %19, align 1
  %19722 = xor i32 %19712, %19711
  %19723 = xor i32 %19722, %19713
  %19724 = lshr i32 %19723, 4
  %19725 = trunc i32 %19724 to i8
  %19726 = and i8 %19725, 1
  store i8 %19726, i8* %20, align 1
  %19727 = icmp eq i32 %19713, 0
  %19728 = zext i1 %19727 to i8
  store i8 %19728, i8* %21, align 1
  %19729 = lshr i32 %19713, 31
  %19730 = trunc i32 %19729 to i8
  store i8 %19730, i8* %22, align 1
  %19731 = lshr i32 %19711, 31
  %19732 = lshr i64 %19709, 31
  %19733 = trunc i64 %19732 to i32
  %19734 = and i32 %19733, 1
  %19735 = xor i32 %19734, %19731
  %19736 = xor i32 %19729, %19731
  %19737 = add nuw nsw i32 %19736, %19735
  %19738 = icmp eq i32 %19737, 2
  %19739 = zext i1 %19738 to i8
  store i8 %19739, i8* %23, align 1
  %19740 = load i64, i64* %RBP.i, align 8
  %19741 = add i64 %19740, -612
  %19742 = add i64 %19658, 42
  store i64 %19742, i64* %3, align 8
  %19743 = inttoptr i64 %19741 to i32*
  store i32 %19713, i32* %19743, align 4
  %19744 = load i64, i64* %RBP.i, align 8
  %19745 = add i64 %19744, -612
  %19746 = load i64, i64* %3, align 8
  %19747 = add i64 %19746, 7
  store i64 %19747, i64* %3, align 8
  %19748 = inttoptr i64 %19745 to i32*
  %19749 = load i32, i32* %19748, align 4
  %19750 = zext i32 %19749 to i64
  store i64 %19750, i64* %26, align 8
  %19751 = add i64 %19744, -44
  %19752 = add i64 %19746, 11
  store i64 %19752, i64* %3, align 8
  %19753 = inttoptr i64 %19751 to i32*
  %19754 = load i32, i32* %19753, align 4
  %19755 = sext i32 %19754 to i64
  %19756 = shl nsw i64 %19755, 6
  store i64 %19756, i64* %RDX.i1805, align 8
  %19757 = load i64, i64* %RCX.i1692, align 8
  %19758 = add i64 %19756, %19757
  store i64 %19758, i64* %RCX.i1692, align 8
  %19759 = icmp ult i64 %19758, %19757
  %19760 = icmp ult i64 %19758, %19756
  %19761 = or i1 %19759, %19760
  %19762 = zext i1 %19761 to i8
  store i8 %19762, i8* %18, align 1
  %19763 = trunc i64 %19758 to i32
  %19764 = and i32 %19763, 255
  %19765 = tail call i32 @llvm.ctpop.i32(i32 %19764)
  %19766 = trunc i32 %19765 to i8
  %19767 = and i8 %19766, 1
  %19768 = xor i8 %19767, 1
  store i8 %19768, i8* %19, align 1
  %19769 = xor i64 %19757, %19758
  %19770 = lshr i64 %19769, 4
  %19771 = trunc i64 %19770 to i8
  %19772 = and i8 %19771, 1
  store i8 %19772, i8* %20, align 1
  %19773 = icmp eq i64 %19758, 0
  %19774 = zext i1 %19773 to i8
  store i8 %19774, i8* %21, align 1
  %19775 = lshr i64 %19758, 63
  %19776 = trunc i64 %19775 to i8
  store i8 %19776, i8* %22, align 1
  %19777 = lshr i64 %19757, 63
  %19778 = lshr i64 %19755, 57
  %19779 = and i64 %19778, 1
  %19780 = xor i64 %19775, %19777
  %19781 = xor i64 %19775, %19779
  %19782 = add nuw nsw i64 %19780, %19781
  %19783 = icmp eq i64 %19782, 2
  %19784 = zext i1 %19783 to i8
  store i8 %19784, i8* %23, align 1
  %19785 = add i64 %19744, -48
  %19786 = add i64 %19746, 22
  store i64 %19786, i64* %3, align 8
  %19787 = inttoptr i64 %19785 to i32*
  %19788 = load i32, i32* %19787, align 4
  %19789 = sext i32 %19788 to i64
  store i64 %19789, i64* %RDX.i1805, align 8
  %19790 = shl nsw i64 %19789, 2
  %19791 = add i64 %19758, %19790
  %19792 = add i64 %19746, 26
  store i64 %19792, i64* %3, align 8
  %19793 = inttoptr i64 %19791 to i32*
  %19794 = load i32, i32* %19793, align 4
  %19795 = add i32 %19794, %19749
  %19796 = zext i32 %19795 to i64
  store i64 %19796, i64* %26, align 8
  %19797 = icmp ult i32 %19795, %19749
  %19798 = icmp ult i32 %19795, %19794
  %19799 = or i1 %19797, %19798
  %19800 = zext i1 %19799 to i8
  store i8 %19800, i8* %18, align 1
  %19801 = and i32 %19795, 255
  %19802 = tail call i32 @llvm.ctpop.i32(i32 %19801)
  %19803 = trunc i32 %19802 to i8
  %19804 = and i8 %19803, 1
  %19805 = xor i8 %19804, 1
  store i8 %19805, i8* %19, align 1
  %19806 = xor i32 %19794, %19749
  %19807 = xor i32 %19806, %19795
  %19808 = lshr i32 %19807, 4
  %19809 = trunc i32 %19808 to i8
  %19810 = and i8 %19809, 1
  store i8 %19810, i8* %20, align 1
  %19811 = icmp eq i32 %19795, 0
  %19812 = zext i1 %19811 to i8
  store i8 %19812, i8* %21, align 1
  %19813 = lshr i32 %19795, 31
  %19814 = trunc i32 %19813 to i8
  store i8 %19814, i8* %22, align 1
  %19815 = lshr i32 %19749, 31
  %19816 = lshr i32 %19794, 31
  %19817 = xor i32 %19813, %19815
  %19818 = xor i32 %19813, %19816
  %19819 = add nuw nsw i32 %19817, %19818
  %19820 = icmp eq i32 %19819, 2
  %19821 = zext i1 %19820 to i8
  store i8 %19821, i8* %23, align 1
  %19822 = load i64, i64* %RBP.i, align 8
  %19823 = add i64 %19822, -604
  %19824 = add i64 %19746, 33
  store i64 %19824, i64* %3, align 8
  %19825 = inttoptr i64 %19823 to i32*
  store i32 %19795, i32* %19825, align 4
  %19826 = load i64, i64* %3, align 8
  %19827 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %19827, i64* %RCX.i1692, align 8
  %19828 = add i64 %19827, 72688
  %19829 = add i64 %19826, 15
  store i64 %19829, i64* %3, align 8
  %19830 = inttoptr i64 %19828 to i32*
  %19831 = load i32, i32* %19830, align 4
  %19832 = zext i32 %19831 to i64
  store i64 %19832, i64* %26, align 8
  %19833 = load i64, i64* %RBP.i, align 8
  %19834 = add i64 %19833, -612
  %19835 = add i64 %19826, 22
  store i64 %19835, i64* %3, align 8
  %19836 = inttoptr i64 %19834 to i32*
  %19837 = load i32, i32* %19836, align 4
  %19838 = zext i32 %19837 to i64
  store i64 %19838, i64* %R9.i, align 8
  %19839 = add i64 %19827, 8504
  store i64 %19839, i64* %RCX.i1692, align 8
  %19840 = icmp ugt i64 %19827, -8505
  %19841 = zext i1 %19840 to i8
  store i8 %19841, i8* %18, align 1
  %19842 = trunc i64 %19839 to i32
  %19843 = and i32 %19842, 255
  %19844 = tail call i32 @llvm.ctpop.i32(i32 %19843)
  %19845 = trunc i32 %19844 to i8
  %19846 = and i8 %19845, 1
  %19847 = xor i8 %19846, 1
  store i8 %19847, i8* %19, align 1
  %19848 = xor i64 %19827, 16
  %19849 = xor i64 %19848, %19839
  %19850 = lshr i64 %19849, 4
  %19851 = trunc i64 %19850 to i8
  %19852 = and i8 %19851, 1
  store i8 %19852, i8* %20, align 1
  %19853 = icmp eq i64 %19839, 0
  %19854 = zext i1 %19853 to i8
  store i8 %19854, i8* %21, align 1
  %19855 = lshr i64 %19839, 63
  %19856 = trunc i64 %19855 to i8
  store i8 %19856, i8* %22, align 1
  %19857 = lshr i64 %19827, 63
  %19858 = xor i64 %19855, %19857
  %19859 = add nuw nsw i64 %19858, %19855
  %19860 = icmp eq i64 %19859, 2
  %19861 = zext i1 %19860 to i8
  store i8 %19861, i8* %23, align 1
  %19862 = add i64 %19833, -632
  %19863 = add i64 %19826, 44
  store i64 %19863, i64* %3, align 8
  %19864 = inttoptr i64 %19862 to i32*
  %19865 = load i32, i32* %19864, align 4
  %19866 = sext i32 %19865 to i64
  %19867 = shl nsw i64 %19866, 9
  store i64 %19867, i64* %RDX.i1805, align 8
  %19868 = add i64 %19867, %19839
  store i64 %19868, i64* %RCX.i1692, align 8
  %19869 = icmp ult i64 %19868, %19839
  %19870 = icmp ult i64 %19868, %19867
  %19871 = or i1 %19869, %19870
  %19872 = zext i1 %19871 to i8
  store i8 %19872, i8* %18, align 1
  %19873 = trunc i64 %19868 to i32
  %19874 = and i32 %19873, 255
  %19875 = tail call i32 @llvm.ctpop.i32(i32 %19874)
  %19876 = trunc i32 %19875 to i8
  %19877 = and i8 %19876, 1
  %19878 = xor i8 %19877, 1
  store i8 %19878, i8* %19, align 1
  %19879 = xor i64 %19839, %19868
  %19880 = lshr i64 %19879, 4
  %19881 = trunc i64 %19880 to i8
  %19882 = and i8 %19881, 1
  store i8 %19882, i8* %20, align 1
  %19883 = icmp eq i64 %19868, 0
  %19884 = zext i1 %19883 to i8
  store i8 %19884, i8* %21, align 1
  %19885 = lshr i64 %19868, 63
  %19886 = trunc i64 %19885 to i8
  store i8 %19886, i8* %22, align 1
  %19887 = lshr i64 %19866, 54
  %19888 = and i64 %19887, 1
  %19889 = xor i64 %19885, %19855
  %19890 = xor i64 %19885, %19888
  %19891 = add nuw nsw i64 %19889, %19890
  %19892 = icmp eq i64 %19891, 2
  %19893 = zext i1 %19892 to i8
  store i8 %19893, i8* %23, align 1
  %19894 = load i64, i64* %RBP.i, align 8
  %19895 = add i64 %19894, -484
  %19896 = add i64 %19826, 58
  store i64 %19896, i64* %3, align 8
  %19897 = inttoptr i64 %19895 to i32*
  %19898 = load i32, i32* %19897, align 4
  %19899 = zext i32 %19898 to i64
  store i64 %19899, i64* %372, align 8
  %19900 = add i64 %19894, -44
  %19901 = add i64 %19826, 62
  store i64 %19901, i64* %3, align 8
  %19902 = inttoptr i64 %19900 to i32*
  %19903 = load i32, i32* %19902, align 4
  %19904 = add i32 %19903, %19898
  %19905 = zext i32 %19904 to i64
  store i64 %19905, i64* %372, align 8
  %19906 = sext i32 %19904 to i64
  %19907 = shl nsw i64 %19906, 5
  store i64 %19907, i64* %RDX.i1805, align 8
  %19908 = load i64, i64* %RCX.i1692, align 8
  %19909 = add i64 %19907, %19908
  store i64 %19909, i64* %RCX.i1692, align 8
  %19910 = icmp ult i64 %19909, %19908
  %19911 = icmp ult i64 %19909, %19907
  %19912 = or i1 %19910, %19911
  %19913 = zext i1 %19912 to i8
  store i8 %19913, i8* %18, align 1
  %19914 = trunc i64 %19909 to i32
  %19915 = and i32 %19914, 255
  %19916 = tail call i32 @llvm.ctpop.i32(i32 %19915)
  %19917 = trunc i32 %19916 to i8
  %19918 = and i8 %19917, 1
  %19919 = xor i8 %19918, 1
  store i8 %19919, i8* %19, align 1
  %19920 = xor i64 %19908, %19909
  %19921 = lshr i64 %19920, 4
  %19922 = trunc i64 %19921 to i8
  %19923 = and i8 %19922, 1
  store i8 %19923, i8* %20, align 1
  %19924 = icmp eq i64 %19909, 0
  %19925 = zext i1 %19924 to i8
  store i8 %19925, i8* %21, align 1
  %19926 = lshr i64 %19909, 63
  %19927 = trunc i64 %19926 to i8
  store i8 %19927, i8* %22, align 1
  %19928 = lshr i64 %19908, 63
  %19929 = lshr i64 %19906, 58
  %19930 = and i64 %19929, 1
  %19931 = xor i64 %19926, %19928
  %19932 = xor i64 %19926, %19930
  %19933 = add nuw nsw i64 %19931, %19932
  %19934 = icmp eq i64 %19933, 2
  %19935 = zext i1 %19934 to i8
  store i8 %19935, i8* %23, align 1
  %19936 = load i64, i64* %RBP.i, align 8
  %19937 = add i64 %19936, -488
  %19938 = add i64 %19826, 79
  store i64 %19938, i64* %3, align 8
  %19939 = inttoptr i64 %19937 to i32*
  %19940 = load i32, i32* %19939, align 4
  %19941 = zext i32 %19940 to i64
  store i64 %19941, i64* %372, align 8
  %19942 = add i64 %19936, -48
  %19943 = add i64 %19826, 83
  store i64 %19943, i64* %3, align 8
  %19944 = inttoptr i64 %19942 to i32*
  %19945 = load i32, i32* %19944, align 4
  %19946 = add i32 %19945, %19940
  %19947 = zext i32 %19946 to i64
  store i64 %19947, i64* %372, align 8
  %19948 = icmp ult i32 %19946, %19940
  %19949 = icmp ult i32 %19946, %19945
  %19950 = or i1 %19948, %19949
  %19951 = zext i1 %19950 to i8
  store i8 %19951, i8* %18, align 1
  %19952 = and i32 %19946, 255
  %19953 = tail call i32 @llvm.ctpop.i32(i32 %19952)
  %19954 = trunc i32 %19953 to i8
  %19955 = and i8 %19954, 1
  %19956 = xor i8 %19955, 1
  store i8 %19956, i8* %19, align 1
  %19957 = xor i32 %19945, %19940
  %19958 = xor i32 %19957, %19946
  %19959 = lshr i32 %19958, 4
  %19960 = trunc i32 %19959 to i8
  %19961 = and i8 %19960, 1
  store i8 %19961, i8* %20, align 1
  %19962 = icmp eq i32 %19946, 0
  %19963 = zext i1 %19962 to i8
  store i8 %19963, i8* %21, align 1
  %19964 = lshr i32 %19946, 31
  %19965 = trunc i32 %19964 to i8
  store i8 %19965, i8* %22, align 1
  %19966 = lshr i32 %19940, 31
  %19967 = lshr i32 %19945, 31
  %19968 = xor i32 %19964, %19966
  %19969 = xor i32 %19964, %19967
  %19970 = add nuw nsw i32 %19968, %19969
  %19971 = icmp eq i32 %19970, 2
  %19972 = zext i1 %19971 to i8
  store i8 %19972, i8* %23, align 1
  %19973 = sext i32 %19946 to i64
  store i64 %19973, i64* %RDX.i1805, align 8
  %19974 = shl nsw i64 %19973, 1
  %19975 = add i64 %19909, %19974
  %19976 = add i64 %19826, 91
  store i64 %19976, i64* %3, align 8
  %19977 = inttoptr i64 %19975 to i16*
  %19978 = load i16, i16* %19977, align 2
  %19979 = zext i16 %19978 to i64
  store i64 %19979, i64* %372, align 8
  %19980 = load i32, i32* %R9D.i6640, align 4
  %19981 = zext i16 %19978 to i32
  %19982 = add i32 %19981, %19980
  %19983 = zext i32 %19982 to i64
  store i64 %19983, i64* %R9.i, align 8
  %19984 = lshr i32 %19982, 31
  %19985 = load i32, i32* %EAX.i2159, align 4
  %19986 = sub i32 %19985, %19982
  %19987 = icmp ult i32 %19985, %19982
  %19988 = zext i1 %19987 to i8
  store i8 %19988, i8* %18, align 1
  %19989 = and i32 %19986, 255
  %19990 = tail call i32 @llvm.ctpop.i32(i32 %19989)
  %19991 = trunc i32 %19990 to i8
  %19992 = and i8 %19991, 1
  %19993 = xor i8 %19992, 1
  store i8 %19993, i8* %19, align 1
  %19994 = xor i32 %19982, %19985
  %19995 = xor i32 %19994, %19986
  %19996 = lshr i32 %19995, 4
  %19997 = trunc i32 %19996 to i8
  %19998 = and i8 %19997, 1
  store i8 %19998, i8* %20, align 1
  %19999 = icmp eq i32 %19986, 0
  %20000 = zext i1 %19999 to i8
  store i8 %20000, i8* %21, align 1
  %20001 = lshr i32 %19986, 31
  %20002 = trunc i32 %20001 to i8
  store i8 %20002, i8* %22, align 1
  %20003 = lshr i32 %19985, 31
  %20004 = xor i32 %19984, %20003
  %20005 = xor i32 %20001, %20003
  %20006 = add nuw nsw i32 %20005, %20004
  %20007 = icmp eq i32 %20006, 2
  %20008 = zext i1 %20007 to i8
  store i8 %20008, i8* %23, align 1
  %20009 = load i64, i64* %RBP.i, align 8
  %20010 = add i64 %20009, -1436
  %20011 = load i32, i32* %R8D.i1718, align 4
  %20012 = add i64 %19826, 104
  store i64 %20012, i64* %3, align 8
  %20013 = inttoptr i64 %20010 to i32*
  store i32 %20011, i32* %20013, align 4
  %20014 = load i64, i64* %3, align 8
  %20015 = load i8, i8* %21, align 1
  %20016 = icmp ne i8 %20015, 0
  %20017 = load i8, i8* %22, align 1
  %20018 = icmp ne i8 %20017, 0
  %20019 = load i8, i8* %23, align 1
  %20020 = icmp ne i8 %20019, 0
  %20021 = xor i1 %20018, %20020
  %20022 = or i1 %20016, %20021
  %.v1011 = select i1 %20022, i64 19, i64 6
  %20023 = add i64 %20014, %.v1011
  store i64 %20023, i64* %3, align 8
  br i1 %20022, label %block_.L_4a6c8e, label %block_4a6c81

block_4a6c81:                                     ; preds = %block_4a6b4f
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %20024 = load i64, i64* %RBP.i, align 8
  %20025 = add i64 %20024, -1440
  %20026 = add i64 %20023, 8
  store i64 %20026, i64* %3, align 8
  %20027 = inttoptr i64 %20025 to i32*
  store i32 0, i32* %20027, align 4
  %20028 = load i64, i64* %3, align 8
  %20029 = add i64 %20028, 83
  store i64 %20029, i64* %3, align 8
  br label %block_.L_4a6cdc

block_.L_4a6c8e:                                  ; preds = %block_4a6b4f
  %20030 = load i64, i64* %RBP.i, align 8
  %20031 = add i64 %20030, -612
  %20032 = add i64 %20023, 6
  store i64 %20032, i64* %3, align 8
  %20033 = inttoptr i64 %20031 to i32*
  %20034 = load i32, i32* %20033, align 4
  %20035 = zext i32 %20034 to i64
  store i64 %20035, i64* %RAX.i1763, align 8
  %20036 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %20037 = add i64 %20036, 8504
  store i64 %20037, i64* %RCX.i1692, align 8
  %20038 = icmp ugt i64 %20036, -8505
  %20039 = zext i1 %20038 to i8
  store i8 %20039, i8* %18, align 1
  %20040 = trunc i64 %20037 to i32
  %20041 = and i32 %20040, 255
  %20042 = tail call i32 @llvm.ctpop.i32(i32 %20041)
  %20043 = trunc i32 %20042 to i8
  %20044 = and i8 %20043, 1
  %20045 = xor i8 %20044, 1
  store i8 %20045, i8* %19, align 1
  %20046 = xor i64 %20036, 16
  %20047 = xor i64 %20046, %20037
  %20048 = lshr i64 %20047, 4
  %20049 = trunc i64 %20048 to i8
  %20050 = and i8 %20049, 1
  store i8 %20050, i8* %20, align 1
  %20051 = icmp eq i64 %20037, 0
  %20052 = zext i1 %20051 to i8
  store i8 %20052, i8* %21, align 1
  %20053 = lshr i64 %20037, 63
  %20054 = trunc i64 %20053 to i8
  store i8 %20054, i8* %22, align 1
  %20055 = lshr i64 %20036, 63
  %20056 = xor i64 %20053, %20055
  %20057 = add nuw nsw i64 %20056, %20053
  %20058 = icmp eq i64 %20057, 2
  %20059 = zext i1 %20058 to i8
  store i8 %20059, i8* %23, align 1
  %20060 = add i64 %20030, -632
  %20061 = add i64 %20023, 28
  store i64 %20061, i64* %3, align 8
  %20062 = inttoptr i64 %20060 to i32*
  %20063 = load i32, i32* %20062, align 4
  %20064 = sext i32 %20063 to i64
  %20065 = shl nsw i64 %20064, 9
  store i64 %20065, i64* %RDX.i1805, align 8
  %20066 = add i64 %20065, %20037
  store i64 %20066, i64* %RCX.i1692, align 8
  %20067 = icmp ult i64 %20066, %20037
  %20068 = icmp ult i64 %20066, %20065
  %20069 = or i1 %20067, %20068
  %20070 = zext i1 %20069 to i8
  store i8 %20070, i8* %18, align 1
  %20071 = trunc i64 %20066 to i32
  %20072 = and i32 %20071, 255
  %20073 = tail call i32 @llvm.ctpop.i32(i32 %20072)
  %20074 = trunc i32 %20073 to i8
  %20075 = and i8 %20074, 1
  %20076 = xor i8 %20075, 1
  store i8 %20076, i8* %19, align 1
  %20077 = xor i64 %20037, %20066
  %20078 = lshr i64 %20077, 4
  %20079 = trunc i64 %20078 to i8
  %20080 = and i8 %20079, 1
  store i8 %20080, i8* %20, align 1
  %20081 = icmp eq i64 %20066, 0
  %20082 = zext i1 %20081 to i8
  store i8 %20082, i8* %21, align 1
  %20083 = lshr i64 %20066, 63
  %20084 = trunc i64 %20083 to i8
  store i8 %20084, i8* %22, align 1
  %20085 = lshr i64 %20064, 54
  %20086 = and i64 %20085, 1
  %20087 = xor i64 %20083, %20053
  %20088 = xor i64 %20083, %20086
  %20089 = add nuw nsw i64 %20087, %20088
  %20090 = icmp eq i64 %20089, 2
  %20091 = zext i1 %20090 to i8
  store i8 %20091, i8* %23, align 1
  %20092 = load i64, i64* %RBP.i, align 8
  %20093 = add i64 %20092, -484
  %20094 = add i64 %20023, 41
  store i64 %20094, i64* %3, align 8
  %20095 = inttoptr i64 %20093 to i32*
  %20096 = load i32, i32* %20095, align 4
  %20097 = zext i32 %20096 to i64
  store i64 %20097, i64* %RSI.i1889, align 8
  %20098 = add i64 %20092, -44
  %20099 = add i64 %20023, 44
  store i64 %20099, i64* %3, align 8
  %20100 = inttoptr i64 %20098 to i32*
  %20101 = load i32, i32* %20100, align 4
  %20102 = add i32 %20101, %20096
  %20103 = zext i32 %20102 to i64
  store i64 %20103, i64* %RSI.i1889, align 8
  %20104 = sext i32 %20102 to i64
  %20105 = shl nsw i64 %20104, 5
  store i64 %20105, i64* %RDX.i1805, align 8
  %20106 = load i64, i64* %RCX.i1692, align 8
  %20107 = add i64 %20105, %20106
  store i64 %20107, i64* %RCX.i1692, align 8
  %20108 = icmp ult i64 %20107, %20106
  %20109 = icmp ult i64 %20107, %20105
  %20110 = or i1 %20108, %20109
  %20111 = zext i1 %20110 to i8
  store i8 %20111, i8* %18, align 1
  %20112 = trunc i64 %20107 to i32
  %20113 = and i32 %20112, 255
  %20114 = tail call i32 @llvm.ctpop.i32(i32 %20113)
  %20115 = trunc i32 %20114 to i8
  %20116 = and i8 %20115, 1
  %20117 = xor i8 %20116, 1
  store i8 %20117, i8* %19, align 1
  %20118 = xor i64 %20106, %20107
  %20119 = lshr i64 %20118, 4
  %20120 = trunc i64 %20119 to i8
  %20121 = and i8 %20120, 1
  store i8 %20121, i8* %20, align 1
  %20122 = icmp eq i64 %20107, 0
  %20123 = zext i1 %20122 to i8
  store i8 %20123, i8* %21, align 1
  %20124 = lshr i64 %20107, 63
  %20125 = trunc i64 %20124 to i8
  store i8 %20125, i8* %22, align 1
  %20126 = lshr i64 %20106, 63
  %20127 = lshr i64 %20104, 58
  %20128 = and i64 %20127, 1
  %20129 = xor i64 %20124, %20126
  %20130 = xor i64 %20124, %20128
  %20131 = add nuw nsw i64 %20129, %20130
  %20132 = icmp eq i64 %20131, 2
  %20133 = zext i1 %20132 to i8
  store i8 %20133, i8* %23, align 1
  %20134 = load i64, i64* %RBP.i, align 8
  %20135 = add i64 %20134, -488
  %20136 = add i64 %20023, 60
  store i64 %20136, i64* %3, align 8
  %20137 = inttoptr i64 %20135 to i32*
  %20138 = load i32, i32* %20137, align 4
  %20139 = zext i32 %20138 to i64
  store i64 %20139, i64* %RSI.i1889, align 8
  %20140 = add i64 %20134, -48
  %20141 = add i64 %20023, 63
  store i64 %20141, i64* %3, align 8
  %20142 = inttoptr i64 %20140 to i32*
  %20143 = load i32, i32* %20142, align 4
  %20144 = add i32 %20143, %20138
  %20145 = zext i32 %20144 to i64
  store i64 %20145, i64* %RSI.i1889, align 8
  %20146 = icmp ult i32 %20144, %20138
  %20147 = icmp ult i32 %20144, %20143
  %20148 = or i1 %20146, %20147
  %20149 = zext i1 %20148 to i8
  store i8 %20149, i8* %18, align 1
  %20150 = and i32 %20144, 255
  %20151 = tail call i32 @llvm.ctpop.i32(i32 %20150)
  %20152 = trunc i32 %20151 to i8
  %20153 = and i8 %20152, 1
  %20154 = xor i8 %20153, 1
  store i8 %20154, i8* %19, align 1
  %20155 = xor i32 %20143, %20138
  %20156 = xor i32 %20155, %20144
  %20157 = lshr i32 %20156, 4
  %20158 = trunc i32 %20157 to i8
  %20159 = and i8 %20158, 1
  store i8 %20159, i8* %20, align 1
  %20160 = icmp eq i32 %20144, 0
  %20161 = zext i1 %20160 to i8
  store i8 %20161, i8* %21, align 1
  %20162 = lshr i32 %20144, 31
  %20163 = trunc i32 %20162 to i8
  store i8 %20163, i8* %22, align 1
  %20164 = lshr i32 %20138, 31
  %20165 = lshr i32 %20143, 31
  %20166 = xor i32 %20162, %20164
  %20167 = xor i32 %20162, %20165
  %20168 = add nuw nsw i32 %20166, %20167
  %20169 = icmp eq i32 %20168, 2
  %20170 = zext i1 %20169 to i8
  store i8 %20170, i8* %23, align 1
  %20171 = sext i32 %20144 to i64
  store i64 %20171, i64* %RDX.i1805, align 8
  %20172 = shl nsw i64 %20171, 1
  %20173 = add i64 %20107, %20172
  %20174 = add i64 %20023, 70
  store i64 %20174, i64* %3, align 8
  %20175 = inttoptr i64 %20173 to i16*
  %20176 = load i16, i16* %20175, align 2
  %20177 = zext i16 %20176 to i64
  store i64 %20177, i64* %RSI.i1889, align 8
  %20178 = load i64, i64* %RAX.i1763, align 8
  %20179 = zext i16 %20176 to i32
  %20180 = zext i16 %20176 to i64
  %20181 = trunc i64 %20178 to i32
  %20182 = add i32 %20179, %20181
  %20183 = zext i32 %20182 to i64
  store i64 %20183, i64* %RAX.i1763, align 8
  %20184 = icmp ult i32 %20182, %20181
  %20185 = icmp ult i32 %20182, %20179
  %20186 = or i1 %20184, %20185
  %20187 = zext i1 %20186 to i8
  store i8 %20187, i8* %18, align 1
  %20188 = and i32 %20182, 255
  %20189 = tail call i32 @llvm.ctpop.i32(i32 %20188)
  %20190 = trunc i32 %20189 to i8
  %20191 = and i8 %20190, 1
  %20192 = xor i8 %20191, 1
  store i8 %20192, i8* %19, align 1
  %20193 = xor i64 %20180, %20178
  %20194 = trunc i64 %20193 to i32
  %20195 = xor i32 %20194, %20182
  %20196 = lshr i32 %20195, 4
  %20197 = trunc i32 %20196 to i8
  %20198 = and i8 %20197, 1
  store i8 %20198, i8* %20, align 1
  %20199 = icmp eq i32 %20182, 0
  %20200 = zext i1 %20199 to i8
  store i8 %20200, i8* %21, align 1
  %20201 = lshr i32 %20182, 31
  %20202 = trunc i32 %20201 to i8
  store i8 %20202, i8* %22, align 1
  %20203 = lshr i32 %20181, 31
  %20204 = xor i32 %20201, %20203
  %20205 = add nuw nsw i32 %20204, %20201
  %20206 = icmp eq i32 %20205, 2
  %20207 = zext i1 %20206 to i8
  store i8 %20207, i8* %23, align 1
  %20208 = add i64 %20134, -1440
  %20209 = add i64 %20023, 78
  store i64 %20209, i64* %3, align 8
  %20210 = inttoptr i64 %20208 to i32*
  store i32 %20182, i32* %20210, align 4
  %.pre545 = load i64, i64* %3, align 8
  br label %block_.L_4a6cdc

block_.L_4a6cdc:                                  ; preds = %block_.L_4a6c8e, %block_4a6c81
  %20211 = phi i64 [ %.pre545, %block_.L_4a6c8e ], [ %20029, %block_4a6c81 ]
  %20212 = load i64, i64* %RBP.i, align 8
  %20213 = add i64 %20212, -1440
  %20214 = add i64 %20211, 6
  store i64 %20214, i64* %3, align 8
  %20215 = inttoptr i64 %20213 to i32*
  %20216 = load i32, i32* %20215, align 4
  %20217 = zext i32 %20216 to i64
  store i64 %20217, i64* %RAX.i1763, align 8
  %20218 = add i64 %20212, -1436
  %20219 = add i64 %20211, 12
  store i64 %20219, i64* %3, align 8
  %20220 = inttoptr i64 %20218 to i32*
  %20221 = load i32, i32* %20220, align 4
  %20222 = zext i32 %20221 to i64
  store i64 %20222, i64* %RCX.i1692, align 8
  %20223 = sub i32 %20221, %20216
  %20224 = icmp ult i32 %20221, %20216
  %20225 = zext i1 %20224 to i8
  store i8 %20225, i8* %18, align 1
  %20226 = and i32 %20223, 255
  %20227 = tail call i32 @llvm.ctpop.i32(i32 %20226)
  %20228 = trunc i32 %20227 to i8
  %20229 = and i8 %20228, 1
  %20230 = xor i8 %20229, 1
  store i8 %20230, i8* %19, align 1
  %20231 = xor i32 %20216, %20221
  %20232 = xor i32 %20231, %20223
  %20233 = lshr i32 %20232, 4
  %20234 = trunc i32 %20233 to i8
  %20235 = and i8 %20234, 1
  store i8 %20235, i8* %20, align 1
  %20236 = icmp eq i32 %20223, 0
  %20237 = zext i1 %20236 to i8
  store i8 %20237, i8* %21, align 1
  %20238 = lshr i32 %20223, 31
  %20239 = trunc i32 %20238 to i8
  store i8 %20239, i8* %22, align 1
  %20240 = lshr i32 %20221, 31
  %20241 = lshr i32 %20216, 31
  %20242 = xor i32 %20241, %20240
  %20243 = xor i32 %20238, %20240
  %20244 = add nuw nsw i32 %20243, %20242
  %20245 = icmp eq i32 %20244, 2
  %20246 = zext i1 %20245 to i8
  store i8 %20246, i8* %23, align 1
  %20247 = icmp ne i8 %20239, 0
  %20248 = xor i1 %20247, %20245
  %.v828 = select i1 %20248, i64 20, i64 45
  %20249 = add i64 %20211, %.v828
  store i64 %20249, i64* %3, align 8
  br i1 %20248, label %block_4a6cf0, label %block_.L_4a6d09

block_4a6cf0:                                     ; preds = %block_.L_4a6cdc
  %20250 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %20250, i64* %RAX.i1763, align 8
  %20251 = add i64 %20250, 72688
  %20252 = add i64 %20249, 14
  store i64 %20252, i64* %3, align 8
  %20253 = inttoptr i64 %20251 to i32*
  %20254 = load i32, i32* %20253, align 4
  %20255 = zext i32 %20254 to i64
  store i64 %20255, i64* %RCX.i1692, align 8
  %20256 = add i64 %20212, -1444
  %20257 = add i64 %20249, 20
  store i64 %20257, i64* %3, align 8
  %20258 = inttoptr i64 %20256 to i32*
  store i32 %20254, i32* %20258, align 4
  %20259 = load i64, i64* %3, align 8
  %20260 = add i64 %20259, 190
  store i64 %20260, i64* %3, align 8
  br label %block_.L_4a6dc2

block_.L_4a6d09:                                  ; preds = %block_.L_4a6cdc
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %20261 = add i64 %20212, -612
  %20262 = add i64 %20249, 8
  store i64 %20262, i64* %3, align 8
  %20263 = inttoptr i64 %20261 to i32*
  %20264 = load i32, i32* %20263, align 4
  %20265 = zext i32 %20264 to i64
  store i64 %20265, i64* %RCX.i1692, align 8
  %20266 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %20267 = add i64 %20266, 8504
  store i64 %20267, i64* %RDX.i1805, align 8
  %20268 = icmp ugt i64 %20266, -8505
  %20269 = zext i1 %20268 to i8
  store i8 %20269, i8* %18, align 1
  %20270 = trunc i64 %20267 to i32
  %20271 = and i32 %20270, 255
  %20272 = tail call i32 @llvm.ctpop.i32(i32 %20271)
  %20273 = trunc i32 %20272 to i8
  %20274 = and i8 %20273, 1
  %20275 = xor i8 %20274, 1
  store i8 %20275, i8* %19, align 1
  %20276 = xor i64 %20266, 16
  %20277 = xor i64 %20276, %20267
  %20278 = lshr i64 %20277, 4
  %20279 = trunc i64 %20278 to i8
  %20280 = and i8 %20279, 1
  store i8 %20280, i8* %20, align 1
  %20281 = icmp eq i64 %20267, 0
  %20282 = zext i1 %20281 to i8
  store i8 %20282, i8* %21, align 1
  %20283 = lshr i64 %20267, 63
  %20284 = trunc i64 %20283 to i8
  store i8 %20284, i8* %22, align 1
  %20285 = lshr i64 %20266, 63
  %20286 = xor i64 %20283, %20285
  %20287 = add nuw nsw i64 %20286, %20283
  %20288 = icmp eq i64 %20287, 2
  %20289 = zext i1 %20288 to i8
  store i8 %20289, i8* %23, align 1
  %20290 = add i64 %20212, -632
  %20291 = add i64 %20249, 30
  store i64 %20291, i64* %3, align 8
  %20292 = inttoptr i64 %20290 to i32*
  %20293 = load i32, i32* %20292, align 4
  %20294 = sext i32 %20293 to i64
  %20295 = shl nsw i64 %20294, 9
  store i64 %20295, i64* %RSI.i1889, align 8
  %20296 = add i64 %20295, %20267
  store i64 %20296, i64* %RDX.i1805, align 8
  %20297 = icmp ult i64 %20296, %20267
  %20298 = icmp ult i64 %20296, %20295
  %20299 = or i1 %20297, %20298
  %20300 = zext i1 %20299 to i8
  store i8 %20300, i8* %18, align 1
  %20301 = trunc i64 %20296 to i32
  %20302 = and i32 %20301, 255
  %20303 = tail call i32 @llvm.ctpop.i32(i32 %20302)
  %20304 = trunc i32 %20303 to i8
  %20305 = and i8 %20304, 1
  %20306 = xor i8 %20305, 1
  store i8 %20306, i8* %19, align 1
  %20307 = xor i64 %20267, %20296
  %20308 = lshr i64 %20307, 4
  %20309 = trunc i64 %20308 to i8
  %20310 = and i8 %20309, 1
  store i8 %20310, i8* %20, align 1
  %20311 = icmp eq i64 %20296, 0
  %20312 = zext i1 %20311 to i8
  store i8 %20312, i8* %21, align 1
  %20313 = lshr i64 %20296, 63
  %20314 = trunc i64 %20313 to i8
  store i8 %20314, i8* %22, align 1
  %20315 = lshr i64 %20294, 54
  %20316 = and i64 %20315, 1
  %20317 = xor i64 %20313, %20283
  %20318 = xor i64 %20313, %20316
  %20319 = add nuw nsw i64 %20317, %20318
  %20320 = icmp eq i64 %20319, 2
  %20321 = zext i1 %20320 to i8
  store i8 %20321, i8* %23, align 1
  %20322 = load i64, i64* %RBP.i, align 8
  %20323 = add i64 %20322, -484
  %20324 = add i64 %20249, 43
  store i64 %20324, i64* %3, align 8
  %20325 = inttoptr i64 %20323 to i32*
  %20326 = load i32, i32* %20325, align 4
  %20327 = zext i32 %20326 to i64
  store i64 %20327, i64* %RDI.i2141, align 8
  %20328 = add i64 %20322, -44
  %20329 = add i64 %20249, 46
  store i64 %20329, i64* %3, align 8
  %20330 = inttoptr i64 %20328 to i32*
  %20331 = load i32, i32* %20330, align 4
  %20332 = add i32 %20331, %20326
  %20333 = zext i32 %20332 to i64
  store i64 %20333, i64* %RDI.i2141, align 8
  %20334 = sext i32 %20332 to i64
  %20335 = shl nsw i64 %20334, 5
  store i64 %20335, i64* %RSI.i1889, align 8
  %20336 = load i64, i64* %RDX.i1805, align 8
  %20337 = add i64 %20335, %20336
  store i64 %20337, i64* %RDX.i1805, align 8
  %20338 = icmp ult i64 %20337, %20336
  %20339 = icmp ult i64 %20337, %20335
  %20340 = or i1 %20338, %20339
  %20341 = zext i1 %20340 to i8
  store i8 %20341, i8* %18, align 1
  %20342 = trunc i64 %20337 to i32
  %20343 = and i32 %20342, 255
  %20344 = tail call i32 @llvm.ctpop.i32(i32 %20343)
  %20345 = trunc i32 %20344 to i8
  %20346 = and i8 %20345, 1
  %20347 = xor i8 %20346, 1
  store i8 %20347, i8* %19, align 1
  %20348 = xor i64 %20336, %20337
  %20349 = lshr i64 %20348, 4
  %20350 = trunc i64 %20349 to i8
  %20351 = and i8 %20350, 1
  store i8 %20351, i8* %20, align 1
  %20352 = icmp eq i64 %20337, 0
  %20353 = zext i1 %20352 to i8
  store i8 %20353, i8* %21, align 1
  %20354 = lshr i64 %20337, 63
  %20355 = trunc i64 %20354 to i8
  store i8 %20355, i8* %22, align 1
  %20356 = lshr i64 %20336, 63
  %20357 = lshr i64 %20334, 58
  %20358 = and i64 %20357, 1
  %20359 = xor i64 %20354, %20356
  %20360 = xor i64 %20354, %20358
  %20361 = add nuw nsw i64 %20359, %20360
  %20362 = icmp eq i64 %20361, 2
  %20363 = zext i1 %20362 to i8
  store i8 %20363, i8* %23, align 1
  %20364 = load i64, i64* %RBP.i, align 8
  %20365 = add i64 %20364, -488
  %20366 = add i64 %20249, 62
  store i64 %20366, i64* %3, align 8
  %20367 = inttoptr i64 %20365 to i32*
  %20368 = load i32, i32* %20367, align 4
  %20369 = zext i32 %20368 to i64
  store i64 %20369, i64* %RDI.i2141, align 8
  %20370 = add i64 %20364, -48
  %20371 = add i64 %20249, 65
  store i64 %20371, i64* %3, align 8
  %20372 = inttoptr i64 %20370 to i32*
  %20373 = load i32, i32* %20372, align 4
  %20374 = add i32 %20373, %20368
  %20375 = zext i32 %20374 to i64
  store i64 %20375, i64* %RDI.i2141, align 8
  %20376 = icmp ult i32 %20374, %20368
  %20377 = icmp ult i32 %20374, %20373
  %20378 = or i1 %20376, %20377
  %20379 = zext i1 %20378 to i8
  store i8 %20379, i8* %18, align 1
  %20380 = and i32 %20374, 255
  %20381 = tail call i32 @llvm.ctpop.i32(i32 %20380)
  %20382 = trunc i32 %20381 to i8
  %20383 = and i8 %20382, 1
  %20384 = xor i8 %20383, 1
  store i8 %20384, i8* %19, align 1
  %20385 = xor i32 %20373, %20368
  %20386 = xor i32 %20385, %20374
  %20387 = lshr i32 %20386, 4
  %20388 = trunc i32 %20387 to i8
  %20389 = and i8 %20388, 1
  store i8 %20389, i8* %20, align 1
  %20390 = icmp eq i32 %20374, 0
  %20391 = zext i1 %20390 to i8
  store i8 %20391, i8* %21, align 1
  %20392 = lshr i32 %20374, 31
  %20393 = trunc i32 %20392 to i8
  store i8 %20393, i8* %22, align 1
  %20394 = lshr i32 %20368, 31
  %20395 = lshr i32 %20373, 31
  %20396 = xor i32 %20392, %20394
  %20397 = xor i32 %20392, %20395
  %20398 = add nuw nsw i32 %20396, %20397
  %20399 = icmp eq i32 %20398, 2
  %20400 = zext i1 %20399 to i8
  store i8 %20400, i8* %23, align 1
  %20401 = sext i32 %20374 to i64
  store i64 %20401, i64* %RSI.i1889, align 8
  %20402 = shl nsw i64 %20401, 1
  %20403 = add i64 %20337, %20402
  %20404 = add i64 %20249, 72
  store i64 %20404, i64* %3, align 8
  %20405 = inttoptr i64 %20403 to i16*
  %20406 = load i16, i16* %20405, align 2
  %20407 = zext i16 %20406 to i64
  store i64 %20407, i64* %RDI.i2141, align 8
  %20408 = load i64, i64* %RCX.i1692, align 8
  %20409 = zext i16 %20406 to i32
  %20410 = trunc i64 %20408 to i32
  %20411 = add i32 %20409, %20410
  %20412 = zext i32 %20411 to i64
  store i64 %20412, i64* %RCX.i1692, align 8
  %20413 = lshr i32 %20411, 31
  %20414 = load i32, i32* %EAX.i2159, align 4
  %20415 = sub i32 %20414, %20411
  %20416 = icmp ult i32 %20414, %20411
  %20417 = zext i1 %20416 to i8
  store i8 %20417, i8* %18, align 1
  %20418 = and i32 %20415, 255
  %20419 = tail call i32 @llvm.ctpop.i32(i32 %20418)
  %20420 = trunc i32 %20419 to i8
  %20421 = and i8 %20420, 1
  %20422 = xor i8 %20421, 1
  store i8 %20422, i8* %19, align 1
  %20423 = xor i32 %20411, %20414
  %20424 = xor i32 %20423, %20415
  %20425 = lshr i32 %20424, 4
  %20426 = trunc i32 %20425 to i8
  %20427 = and i8 %20426, 1
  store i8 %20427, i8* %20, align 1
  %20428 = icmp eq i32 %20415, 0
  %20429 = zext i1 %20428 to i8
  store i8 %20429, i8* %21, align 1
  %20430 = lshr i32 %20415, 31
  %20431 = trunc i32 %20430 to i8
  store i8 %20431, i8* %22, align 1
  %20432 = lshr i32 %20414, 31
  %20433 = xor i32 %20413, %20432
  %20434 = xor i32 %20430, %20432
  %20435 = add nuw nsw i32 %20434, %20433
  %20436 = icmp eq i32 %20435, 2
  %20437 = zext i1 %20436 to i8
  store i8 %20437, i8* %23, align 1
  %20438 = icmp ne i8 %20431, 0
  %20439 = xor i1 %20438, %20436
  %20440 = or i1 %20428, %20439
  %.v829 = select i1 %20440, i64 95, i64 82
  %20441 = add i64 %20249, %.v829
  store i64 %20441, i64* %3, align 8
  br i1 %20440, label %block_.L_4a6d68, label %block_4a6d5b

block_4a6d5b:                                     ; preds = %block_.L_4a6d09
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %20442 = load i64, i64* %RBP.i, align 8
  %20443 = add i64 %20442, -1448
  %20444 = add i64 %20441, 8
  store i64 %20444, i64* %3, align 8
  %20445 = inttoptr i64 %20443 to i32*
  store i32 0, i32* %20445, align 4
  %20446 = load i64, i64* %3, align 8
  %20447 = add i64 %20446, 83
  store i64 %20447, i64* %3, align 8
  br label %block_.L_4a6db6

block_.L_4a6d68:                                  ; preds = %block_.L_4a6d09
  %20448 = load i64, i64* %RBP.i, align 8
  %20449 = add i64 %20448, -612
  %20450 = add i64 %20441, 6
  store i64 %20450, i64* %3, align 8
  %20451 = inttoptr i64 %20449 to i32*
  %20452 = load i32, i32* %20451, align 4
  %20453 = zext i32 %20452 to i64
  store i64 %20453, i64* %RAX.i1763, align 8
  %20454 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %20455 = add i64 %20454, 8504
  store i64 %20455, i64* %RCX.i1692, align 8
  %20456 = icmp ugt i64 %20454, -8505
  %20457 = zext i1 %20456 to i8
  store i8 %20457, i8* %18, align 1
  %20458 = trunc i64 %20455 to i32
  %20459 = and i32 %20458, 255
  %20460 = tail call i32 @llvm.ctpop.i32(i32 %20459)
  %20461 = trunc i32 %20460 to i8
  %20462 = and i8 %20461, 1
  %20463 = xor i8 %20462, 1
  store i8 %20463, i8* %19, align 1
  %20464 = xor i64 %20454, 16
  %20465 = xor i64 %20464, %20455
  %20466 = lshr i64 %20465, 4
  %20467 = trunc i64 %20466 to i8
  %20468 = and i8 %20467, 1
  store i8 %20468, i8* %20, align 1
  %20469 = icmp eq i64 %20455, 0
  %20470 = zext i1 %20469 to i8
  store i8 %20470, i8* %21, align 1
  %20471 = lshr i64 %20455, 63
  %20472 = trunc i64 %20471 to i8
  store i8 %20472, i8* %22, align 1
  %20473 = lshr i64 %20454, 63
  %20474 = xor i64 %20471, %20473
  %20475 = add nuw nsw i64 %20474, %20471
  %20476 = icmp eq i64 %20475, 2
  %20477 = zext i1 %20476 to i8
  store i8 %20477, i8* %23, align 1
  %20478 = add i64 %20448, -632
  %20479 = add i64 %20441, 28
  store i64 %20479, i64* %3, align 8
  %20480 = inttoptr i64 %20478 to i32*
  %20481 = load i32, i32* %20480, align 4
  %20482 = sext i32 %20481 to i64
  %20483 = shl nsw i64 %20482, 9
  store i64 %20483, i64* %RDX.i1805, align 8
  %20484 = add i64 %20483, %20455
  store i64 %20484, i64* %RCX.i1692, align 8
  %20485 = icmp ult i64 %20484, %20455
  %20486 = icmp ult i64 %20484, %20483
  %20487 = or i1 %20485, %20486
  %20488 = zext i1 %20487 to i8
  store i8 %20488, i8* %18, align 1
  %20489 = trunc i64 %20484 to i32
  %20490 = and i32 %20489, 255
  %20491 = tail call i32 @llvm.ctpop.i32(i32 %20490)
  %20492 = trunc i32 %20491 to i8
  %20493 = and i8 %20492, 1
  %20494 = xor i8 %20493, 1
  store i8 %20494, i8* %19, align 1
  %20495 = xor i64 %20455, %20484
  %20496 = lshr i64 %20495, 4
  %20497 = trunc i64 %20496 to i8
  %20498 = and i8 %20497, 1
  store i8 %20498, i8* %20, align 1
  %20499 = icmp eq i64 %20484, 0
  %20500 = zext i1 %20499 to i8
  store i8 %20500, i8* %21, align 1
  %20501 = lshr i64 %20484, 63
  %20502 = trunc i64 %20501 to i8
  store i8 %20502, i8* %22, align 1
  %20503 = lshr i64 %20482, 54
  %20504 = and i64 %20503, 1
  %20505 = xor i64 %20501, %20471
  %20506 = xor i64 %20501, %20504
  %20507 = add nuw nsw i64 %20505, %20506
  %20508 = icmp eq i64 %20507, 2
  %20509 = zext i1 %20508 to i8
  store i8 %20509, i8* %23, align 1
  %20510 = load i64, i64* %RBP.i, align 8
  %20511 = add i64 %20510, -484
  %20512 = add i64 %20441, 41
  store i64 %20512, i64* %3, align 8
  %20513 = inttoptr i64 %20511 to i32*
  %20514 = load i32, i32* %20513, align 4
  %20515 = zext i32 %20514 to i64
  store i64 %20515, i64* %RSI.i1889, align 8
  %20516 = add i64 %20510, -44
  %20517 = add i64 %20441, 44
  store i64 %20517, i64* %3, align 8
  %20518 = inttoptr i64 %20516 to i32*
  %20519 = load i32, i32* %20518, align 4
  %20520 = add i32 %20519, %20514
  %20521 = zext i32 %20520 to i64
  store i64 %20521, i64* %RSI.i1889, align 8
  %20522 = sext i32 %20520 to i64
  %20523 = shl nsw i64 %20522, 5
  store i64 %20523, i64* %RDX.i1805, align 8
  %20524 = load i64, i64* %RCX.i1692, align 8
  %20525 = add i64 %20523, %20524
  store i64 %20525, i64* %RCX.i1692, align 8
  %20526 = icmp ult i64 %20525, %20524
  %20527 = icmp ult i64 %20525, %20523
  %20528 = or i1 %20526, %20527
  %20529 = zext i1 %20528 to i8
  store i8 %20529, i8* %18, align 1
  %20530 = trunc i64 %20525 to i32
  %20531 = and i32 %20530, 255
  %20532 = tail call i32 @llvm.ctpop.i32(i32 %20531)
  %20533 = trunc i32 %20532 to i8
  %20534 = and i8 %20533, 1
  %20535 = xor i8 %20534, 1
  store i8 %20535, i8* %19, align 1
  %20536 = xor i64 %20524, %20525
  %20537 = lshr i64 %20536, 4
  %20538 = trunc i64 %20537 to i8
  %20539 = and i8 %20538, 1
  store i8 %20539, i8* %20, align 1
  %20540 = icmp eq i64 %20525, 0
  %20541 = zext i1 %20540 to i8
  store i8 %20541, i8* %21, align 1
  %20542 = lshr i64 %20525, 63
  %20543 = trunc i64 %20542 to i8
  store i8 %20543, i8* %22, align 1
  %20544 = lshr i64 %20524, 63
  %20545 = lshr i64 %20522, 58
  %20546 = and i64 %20545, 1
  %20547 = xor i64 %20542, %20544
  %20548 = xor i64 %20542, %20546
  %20549 = add nuw nsw i64 %20547, %20548
  %20550 = icmp eq i64 %20549, 2
  %20551 = zext i1 %20550 to i8
  store i8 %20551, i8* %23, align 1
  %20552 = load i64, i64* %RBP.i, align 8
  %20553 = add i64 %20552, -488
  %20554 = add i64 %20441, 60
  store i64 %20554, i64* %3, align 8
  %20555 = inttoptr i64 %20553 to i32*
  %20556 = load i32, i32* %20555, align 4
  %20557 = zext i32 %20556 to i64
  store i64 %20557, i64* %RSI.i1889, align 8
  %20558 = add i64 %20552, -48
  %20559 = add i64 %20441, 63
  store i64 %20559, i64* %3, align 8
  %20560 = inttoptr i64 %20558 to i32*
  %20561 = load i32, i32* %20560, align 4
  %20562 = add i32 %20561, %20556
  %20563 = zext i32 %20562 to i64
  store i64 %20563, i64* %RSI.i1889, align 8
  %20564 = icmp ult i32 %20562, %20556
  %20565 = icmp ult i32 %20562, %20561
  %20566 = or i1 %20564, %20565
  %20567 = zext i1 %20566 to i8
  store i8 %20567, i8* %18, align 1
  %20568 = and i32 %20562, 255
  %20569 = tail call i32 @llvm.ctpop.i32(i32 %20568)
  %20570 = trunc i32 %20569 to i8
  %20571 = and i8 %20570, 1
  %20572 = xor i8 %20571, 1
  store i8 %20572, i8* %19, align 1
  %20573 = xor i32 %20561, %20556
  %20574 = xor i32 %20573, %20562
  %20575 = lshr i32 %20574, 4
  %20576 = trunc i32 %20575 to i8
  %20577 = and i8 %20576, 1
  store i8 %20577, i8* %20, align 1
  %20578 = icmp eq i32 %20562, 0
  %20579 = zext i1 %20578 to i8
  store i8 %20579, i8* %21, align 1
  %20580 = lshr i32 %20562, 31
  %20581 = trunc i32 %20580 to i8
  store i8 %20581, i8* %22, align 1
  %20582 = lshr i32 %20556, 31
  %20583 = lshr i32 %20561, 31
  %20584 = xor i32 %20580, %20582
  %20585 = xor i32 %20580, %20583
  %20586 = add nuw nsw i32 %20584, %20585
  %20587 = icmp eq i32 %20586, 2
  %20588 = zext i1 %20587 to i8
  store i8 %20588, i8* %23, align 1
  %20589 = sext i32 %20562 to i64
  store i64 %20589, i64* %RDX.i1805, align 8
  %20590 = shl nsw i64 %20589, 1
  %20591 = add i64 %20525, %20590
  %20592 = add i64 %20441, 70
  store i64 %20592, i64* %3, align 8
  %20593 = inttoptr i64 %20591 to i16*
  %20594 = load i16, i16* %20593, align 2
  %20595 = zext i16 %20594 to i64
  store i64 %20595, i64* %RSI.i1889, align 8
  %20596 = load i64, i64* %RAX.i1763, align 8
  %20597 = zext i16 %20594 to i32
  %20598 = zext i16 %20594 to i64
  %20599 = trunc i64 %20596 to i32
  %20600 = add i32 %20597, %20599
  %20601 = zext i32 %20600 to i64
  store i64 %20601, i64* %RAX.i1763, align 8
  %20602 = icmp ult i32 %20600, %20599
  %20603 = icmp ult i32 %20600, %20597
  %20604 = or i1 %20602, %20603
  %20605 = zext i1 %20604 to i8
  store i8 %20605, i8* %18, align 1
  %20606 = and i32 %20600, 255
  %20607 = tail call i32 @llvm.ctpop.i32(i32 %20606)
  %20608 = trunc i32 %20607 to i8
  %20609 = and i8 %20608, 1
  %20610 = xor i8 %20609, 1
  store i8 %20610, i8* %19, align 1
  %20611 = xor i64 %20598, %20596
  %20612 = trunc i64 %20611 to i32
  %20613 = xor i32 %20612, %20600
  %20614 = lshr i32 %20613, 4
  %20615 = trunc i32 %20614 to i8
  %20616 = and i8 %20615, 1
  store i8 %20616, i8* %20, align 1
  %20617 = icmp eq i32 %20600, 0
  %20618 = zext i1 %20617 to i8
  store i8 %20618, i8* %21, align 1
  %20619 = lshr i32 %20600, 31
  %20620 = trunc i32 %20619 to i8
  store i8 %20620, i8* %22, align 1
  %20621 = lshr i32 %20599, 31
  %20622 = xor i32 %20619, %20621
  %20623 = add nuw nsw i32 %20622, %20619
  %20624 = icmp eq i32 %20623, 2
  %20625 = zext i1 %20624 to i8
  store i8 %20625, i8* %23, align 1
  %20626 = add i64 %20552, -1448
  %20627 = add i64 %20441, 78
  store i64 %20627, i64* %3, align 8
  %20628 = inttoptr i64 %20626 to i32*
  store i32 %20600, i32* %20628, align 4
  %.pre546 = load i64, i64* %3, align 8
  br label %block_.L_4a6db6

block_.L_4a6db6:                                  ; preds = %block_.L_4a6d68, %block_4a6d5b
  %20629 = phi i64 [ %.pre546, %block_.L_4a6d68 ], [ %20447, %block_4a6d5b ]
  %20630 = load i64, i64* %RBP.i, align 8
  %20631 = add i64 %20630, -1448
  %20632 = add i64 %20629, 6
  store i64 %20632, i64* %3, align 8
  %20633 = inttoptr i64 %20631 to i32*
  %20634 = load i32, i32* %20633, align 4
  %20635 = zext i32 %20634 to i64
  store i64 %20635, i64* %RAX.i1763, align 8
  %20636 = add i64 %20630, -1444
  %20637 = add i64 %20629, 12
  store i64 %20637, i64* %3, align 8
  %20638 = inttoptr i64 %20636 to i32*
  store i32 %20634, i32* %20638, align 4
  %.pre547 = load i64, i64* %3, align 8
  br label %block_.L_4a6dc2

block_.L_4a6dc2:                                  ; preds = %block_.L_4a6db6, %block_4a6cf0
  %20639 = phi i64 [ %.pre547, %block_.L_4a6db6 ], [ %20260, %block_4a6cf0 ]
  %20640 = load i64, i64* %RBP.i, align 8
  %20641 = add i64 %20640, -1444
  %20642 = add i64 %20639, 6
  store i64 %20642, i64* %3, align 8
  %20643 = inttoptr i64 %20641 to i32*
  %20644 = load i32, i32* %20643, align 4
  %20645 = zext i32 %20644 to i64
  store i64 %20645, i64* %RAX.i1763, align 8
  store i64 0, i64* %RCX.i1692, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %20646 = trunc i32 %20644 to i16
  store i16 %20646, i16* %DX.i5417, align 2
  %20647 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %20647, i64* %RSI.i1889, align 8
  %20648 = add i64 %20647, 6464
  %20649 = add i64 %20639, 26
  store i64 %20649, i64* %3, align 8
  %20650 = inttoptr i64 %20648 to i64*
  %20651 = load i64, i64* %20650, align 8
  store i64 %20651, i64* %RSI.i1889, align 8
  %20652 = add i64 %20639, 29
  store i64 %20652, i64* %3, align 8
  %20653 = inttoptr i64 %20651 to i64*
  %20654 = load i64, i64* %20653, align 8
  store i64 %20654, i64* %RSI.i1889, align 8
  %20655 = add i64 %20640, -496
  %20656 = add i64 %20639, 35
  store i64 %20656, i64* %3, align 8
  %20657 = inttoptr i64 %20655 to i32*
  %20658 = load i32, i32* %20657, align 4
  %20659 = zext i32 %20658 to i64
  store i64 %20659, i64* %RAX.i1763, align 8
  %20660 = add i64 %20640, -48
  %20661 = add i64 %20639, 38
  store i64 %20661, i64* %3, align 8
  %20662 = inttoptr i64 %20660 to i32*
  %20663 = load i32, i32* %20662, align 4
  %20664 = add i32 %20663, %20658
  %20665 = zext i32 %20664 to i64
  store i64 %20665, i64* %RAX.i1763, align 8
  %20666 = icmp ult i32 %20664, %20658
  %20667 = icmp ult i32 %20664, %20663
  %20668 = or i1 %20666, %20667
  %20669 = zext i1 %20668 to i8
  store i8 %20669, i8* %18, align 1
  %20670 = and i32 %20664, 255
  %20671 = tail call i32 @llvm.ctpop.i32(i32 %20670)
  %20672 = trunc i32 %20671 to i8
  %20673 = and i8 %20672, 1
  %20674 = xor i8 %20673, 1
  store i8 %20674, i8* %19, align 1
  %20675 = xor i32 %20663, %20658
  %20676 = xor i32 %20675, %20664
  %20677 = lshr i32 %20676, 4
  %20678 = trunc i32 %20677 to i8
  %20679 = and i8 %20678, 1
  store i8 %20679, i8* %20, align 1
  %20680 = icmp eq i32 %20664, 0
  %20681 = zext i1 %20680 to i8
  store i8 %20681, i8* %21, align 1
  %20682 = lshr i32 %20664, 31
  %20683 = trunc i32 %20682 to i8
  store i8 %20683, i8* %22, align 1
  %20684 = lshr i32 %20658, 31
  %20685 = lshr i32 %20663, 31
  %20686 = xor i32 %20682, %20684
  %20687 = xor i32 %20682, %20685
  %20688 = add nuw nsw i32 %20686, %20687
  %20689 = icmp eq i32 %20688, 2
  %20690 = zext i1 %20689 to i8
  store i8 %20690, i8* %23, align 1
  %20691 = sext i32 %20664 to i64
  store i64 %20691, i64* %RDI.i2141, align 8
  %20692 = shl nsw i64 %20691, 3
  %20693 = add i64 %20654, %20692
  %20694 = add i64 %20639, 45
  store i64 %20694, i64* %3, align 8
  %20695 = inttoptr i64 %20693 to i64*
  %20696 = load i64, i64* %20695, align 8
  store i64 %20696, i64* %RSI.i1889, align 8
  %20697 = load i64, i64* %RBP.i, align 8
  %20698 = add i64 %20697, -492
  %20699 = add i64 %20639, 51
  store i64 %20699, i64* %3, align 8
  %20700 = inttoptr i64 %20698 to i32*
  %20701 = load i32, i32* %20700, align 4
  %20702 = zext i32 %20701 to i64
  store i64 %20702, i64* %RAX.i1763, align 8
  %20703 = add i64 %20697, -44
  %20704 = add i64 %20639, 54
  store i64 %20704, i64* %3, align 8
  %20705 = inttoptr i64 %20703 to i32*
  %20706 = load i32, i32* %20705, align 4
  %20707 = add i32 %20706, %20701
  %20708 = zext i32 %20707 to i64
  store i64 %20708, i64* %RAX.i1763, align 8
  %20709 = icmp ult i32 %20707, %20701
  %20710 = icmp ult i32 %20707, %20706
  %20711 = or i1 %20709, %20710
  %20712 = zext i1 %20711 to i8
  store i8 %20712, i8* %18, align 1
  %20713 = and i32 %20707, 255
  %20714 = tail call i32 @llvm.ctpop.i32(i32 %20713)
  %20715 = trunc i32 %20714 to i8
  %20716 = and i8 %20715, 1
  %20717 = xor i8 %20716, 1
  store i8 %20717, i8* %19, align 1
  %20718 = xor i32 %20706, %20701
  %20719 = xor i32 %20718, %20707
  %20720 = lshr i32 %20719, 4
  %20721 = trunc i32 %20720 to i8
  %20722 = and i8 %20721, 1
  store i8 %20722, i8* %20, align 1
  %20723 = icmp eq i32 %20707, 0
  %20724 = zext i1 %20723 to i8
  store i8 %20724, i8* %21, align 1
  %20725 = lshr i32 %20707, 31
  %20726 = trunc i32 %20725 to i8
  store i8 %20726, i8* %22, align 1
  %20727 = lshr i32 %20701, 31
  %20728 = lshr i32 %20706, 31
  %20729 = xor i32 %20725, %20727
  %20730 = xor i32 %20725, %20728
  %20731 = add nuw nsw i32 %20729, %20730
  %20732 = icmp eq i32 %20731, 2
  %20733 = zext i1 %20732 to i8
  store i8 %20733, i8* %23, align 1
  %20734 = sext i32 %20707 to i64
  store i64 %20734, i64* %RDI.i2141, align 8
  %20735 = shl nsw i64 %20734, 1
  %20736 = add i64 %20696, %20735
  %20737 = load i16, i16* %DX.i5417, align 2
  %20738 = add i64 %20639, 61
  store i64 %20738, i64* %3, align 8
  %20739 = inttoptr i64 %20736 to i16*
  store i16 %20737, i16* %20739, align 2
  %20740 = load i64, i64* %3, align 8
  %20741 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %20741, i64* %RSI.i1889, align 8
  %20742 = add i64 %20741, 72684
  %20743 = add i64 %20740, 14
  store i64 %20743, i64* %3, align 8
  %20744 = inttoptr i64 %20742 to i32*
  %20745 = load i32, i32* %20744, align 4
  %20746 = zext i32 %20745 to i64
  store i64 %20746, i64* %RAX.i1763, align 8
  %20747 = load i64, i64* %RBP.i, align 8
  %20748 = add i64 %20747, -608
  %20749 = add i64 %20740, 21
  store i64 %20749, i64* %3, align 8
  %20750 = inttoptr i64 %20748 to i32*
  %20751 = load i32, i32* %20750, align 4
  %20752 = zext i32 %20751 to i64
  store i64 %20752, i64* %26, align 8
  %20753 = add i64 %20741, 7352
  store i64 %20753, i64* %RSI.i1889, align 8
  %20754 = icmp ugt i64 %20741, -7353
  %20755 = zext i1 %20754 to i8
  store i8 %20755, i8* %18, align 1
  %20756 = trunc i64 %20753 to i32
  %20757 = and i32 %20756, 255
  %20758 = tail call i32 @llvm.ctpop.i32(i32 %20757)
  %20759 = trunc i32 %20758 to i8
  %20760 = and i8 %20759, 1
  %20761 = xor i8 %20760, 1
  store i8 %20761, i8* %19, align 1
  %20762 = xor i64 %20741, 16
  %20763 = xor i64 %20762, %20753
  %20764 = lshr i64 %20763, 4
  %20765 = trunc i64 %20764 to i8
  %20766 = and i8 %20765, 1
  store i8 %20766, i8* %20, align 1
  %20767 = icmp eq i64 %20753, 0
  %20768 = zext i1 %20767 to i8
  store i8 %20768, i8* %21, align 1
  %20769 = lshr i64 %20753, 63
  %20770 = trunc i64 %20769 to i8
  store i8 %20770, i8* %22, align 1
  %20771 = lshr i64 %20741, 63
  %20772 = xor i64 %20769, %20771
  %20773 = add nuw nsw i64 %20772, %20769
  %20774 = icmp eq i64 %20773, 2
  %20775 = zext i1 %20774 to i8
  store i8 %20775, i8* %23, align 1
  %20776 = add i64 %20747, -40
  %20777 = add i64 %20740, 40
  store i64 %20777, i64* %3, align 8
  %20778 = inttoptr i64 %20776 to i32*
  %20779 = load i32, i32* %20778, align 4
  %20780 = sext i32 %20779 to i64
  %20781 = shl nsw i64 %20780, 7
  store i64 %20781, i64* %RDI.i2141, align 8
  %20782 = add i64 %20781, %20753
  store i64 %20782, i64* %RSI.i1889, align 8
  %20783 = icmp ult i64 %20782, %20753
  %20784 = icmp ult i64 %20782, %20781
  %20785 = or i1 %20783, %20784
  %20786 = zext i1 %20785 to i8
  store i8 %20786, i8* %18, align 1
  %20787 = trunc i64 %20782 to i32
  %20788 = and i32 %20787, 255
  %20789 = tail call i32 @llvm.ctpop.i32(i32 %20788)
  %20790 = trunc i32 %20789 to i8
  %20791 = and i8 %20790, 1
  %20792 = xor i8 %20791, 1
  store i8 %20792, i8* %19, align 1
  %20793 = xor i64 %20753, %20782
  %20794 = lshr i64 %20793, 4
  %20795 = trunc i64 %20794 to i8
  %20796 = and i8 %20795, 1
  store i8 %20796, i8* %20, align 1
  %20797 = icmp eq i64 %20782, 0
  %20798 = zext i1 %20797 to i8
  store i8 %20798, i8* %21, align 1
  %20799 = lshr i64 %20782, 63
  %20800 = trunc i64 %20799 to i8
  store i8 %20800, i8* %22, align 1
  %20801 = lshr i64 %20780, 56
  %20802 = and i64 %20801, 1
  %20803 = xor i64 %20799, %20769
  %20804 = xor i64 %20799, %20802
  %20805 = add nuw nsw i64 %20803, %20804
  %20806 = icmp eq i64 %20805, 2
  %20807 = zext i1 %20806 to i8
  store i8 %20807, i8* %23, align 1
  %20808 = load i64, i64* %RBP.i, align 8
  %20809 = add i64 %20808, -48
  %20810 = add i64 %20740, 51
  store i64 %20810, i64* %3, align 8
  %20811 = inttoptr i64 %20809 to i32*
  %20812 = load i32, i32* %20811, align 4
  %20813 = sext i32 %20812 to i64
  %20814 = shl nsw i64 %20813, 4
  store i64 %20814, i64* %RDI.i2141, align 8
  %20815 = add i64 %20814, %20782
  store i64 %20815, i64* %RSI.i1889, align 8
  %20816 = icmp ult i64 %20815, %20782
  %20817 = icmp ult i64 %20815, %20814
  %20818 = or i1 %20816, %20817
  %20819 = zext i1 %20818 to i8
  store i8 %20819, i8* %18, align 1
  %20820 = trunc i64 %20815 to i32
  %20821 = and i32 %20820, 255
  %20822 = tail call i32 @llvm.ctpop.i32(i32 %20821)
  %20823 = trunc i32 %20822 to i8
  %20824 = and i8 %20823, 1
  %20825 = xor i8 %20824, 1
  store i8 %20825, i8* %19, align 1
  %20826 = xor i64 %20814, %20782
  %20827 = xor i64 %20826, %20815
  %20828 = lshr i64 %20827, 4
  %20829 = trunc i64 %20828 to i8
  %20830 = and i8 %20829, 1
  store i8 %20830, i8* %20, align 1
  %20831 = icmp eq i64 %20815, 0
  %20832 = zext i1 %20831 to i8
  store i8 %20832, i8* %21, align 1
  %20833 = lshr i64 %20815, 63
  %20834 = trunc i64 %20833 to i8
  store i8 %20834, i8* %22, align 1
  %20835 = lshr i64 %20813, 59
  %20836 = and i64 %20835, 1
  %20837 = xor i64 %20833, %20799
  %20838 = xor i64 %20833, %20836
  %20839 = add nuw nsw i64 %20837, %20838
  %20840 = icmp eq i64 %20839, 2
  %20841 = zext i1 %20840 to i8
  store i8 %20841, i8* %23, align 1
  %20842 = add i64 %20808, -44
  %20843 = add i64 %20740, 62
  store i64 %20843, i64* %3, align 8
  %20844 = inttoptr i64 %20842 to i32*
  %20845 = load i32, i32* %20844, align 4
  %20846 = sext i32 %20845 to i64
  store i64 %20846, i64* %RDI.i2141, align 8
  %20847 = shl nsw i64 %20846, 1
  %20848 = add i64 %20847, %20815
  %20849 = add i64 %20740, 67
  store i64 %20849, i64* %3, align 8
  %20850 = inttoptr i64 %20848 to i16*
  %20851 = load i16, i16* %20850, align 2
  %20852 = zext i16 %20851 to i64
  store i64 %20852, i64* %R9.i, align 8
  %20853 = load i32, i32* %R8D.i1718, align 4
  %20854 = zext i16 %20851 to i32
  %20855 = add i32 %20854, %20853
  %20856 = zext i32 %20855 to i64
  store i64 %20856, i64* %26, align 8
  %20857 = lshr i32 %20855, 31
  %20858 = load i32, i32* %ECX.i7699, align 4
  %20859 = sub i32 %20858, %20855
  %20860 = icmp ult i32 %20858, %20855
  %20861 = zext i1 %20860 to i8
  store i8 %20861, i8* %18, align 1
  %20862 = and i32 %20859, 255
  %20863 = tail call i32 @llvm.ctpop.i32(i32 %20862)
  %20864 = trunc i32 %20863 to i8
  %20865 = and i8 %20864, 1
  %20866 = xor i8 %20865, 1
  store i8 %20866, i8* %19, align 1
  %20867 = xor i32 %20855, %20858
  %20868 = xor i32 %20867, %20859
  %20869 = lshr i32 %20868, 4
  %20870 = trunc i32 %20869 to i8
  %20871 = and i8 %20870, 1
  store i8 %20871, i8* %20, align 1
  %20872 = icmp eq i32 %20859, 0
  %20873 = zext i1 %20872 to i8
  store i8 %20873, i8* %21, align 1
  %20874 = lshr i32 %20859, 31
  %20875 = trunc i32 %20874 to i8
  store i8 %20875, i8* %22, align 1
  %20876 = lshr i32 %20858, 31
  %20877 = xor i32 %20857, %20876
  %20878 = xor i32 %20874, %20876
  %20879 = add nuw nsw i32 %20878, %20877
  %20880 = icmp eq i32 %20879, 2
  %20881 = zext i1 %20880 to i8
  store i8 %20881, i8* %23, align 1
  %20882 = load i64, i64* %RBP.i, align 8
  %20883 = add i64 %20882, -1452
  %20884 = load i32, i32* %EAX.i2159, align 4
  %20885 = add i64 %20740, 79
  store i64 %20885, i64* %3, align 8
  %20886 = inttoptr i64 %20883 to i32*
  store i32 %20884, i32* %20886, align 4
  %20887 = load i64, i64* %3, align 8
  %20888 = load i8, i8* %21, align 1
  %20889 = icmp ne i8 %20888, 0
  %20890 = load i8, i8* %22, align 1
  %20891 = icmp ne i8 %20890, 0
  %20892 = load i8, i8* %23, align 1
  %20893 = icmp ne i8 %20892, 0
  %20894 = xor i1 %20891, %20893
  %20895 = or i1 %20889, %20894
  %.v1012 = select i1 %20895, i64 19, i64 6
  %20896 = add i64 %20887, %.v1012
  store i64 %20896, i64* %3, align 8
  br i1 %20895, label %block_.L_4a6e61, label %block_4a6e54

block_4a6e54:                                     ; preds = %block_.L_4a6dc2
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %20897 = load i64, i64* %RBP.i, align 8
  %20898 = add i64 %20897, -1456
  %20899 = add i64 %20896, 8
  store i64 %20899, i64* %3, align 8
  %20900 = inttoptr i64 %20898 to i32*
  store i32 0, i32* %20900, align 4
  %20901 = load i64, i64* %3, align 8
  %20902 = add i64 %20901, 64
  store i64 %20902, i64* %3, align 8
  br label %block_.L_4a6e9c

block_.L_4a6e61:                                  ; preds = %block_.L_4a6dc2
  %20903 = load i64, i64* %RBP.i, align 8
  %20904 = add i64 %20903, -608
  %20905 = add i64 %20896, 6
  store i64 %20905, i64* %3, align 8
  %20906 = inttoptr i64 %20904 to i32*
  %20907 = load i32, i32* %20906, align 4
  %20908 = zext i32 %20907 to i64
  store i64 %20908, i64* %RAX.i1763, align 8
  %20909 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %20910 = add i64 %20909, 7352
  store i64 %20910, i64* %RCX.i1692, align 8
  %20911 = icmp ugt i64 %20909, -7353
  %20912 = zext i1 %20911 to i8
  store i8 %20912, i8* %18, align 1
  %20913 = trunc i64 %20910 to i32
  %20914 = and i32 %20913, 255
  %20915 = tail call i32 @llvm.ctpop.i32(i32 %20914)
  %20916 = trunc i32 %20915 to i8
  %20917 = and i8 %20916, 1
  %20918 = xor i8 %20917, 1
  store i8 %20918, i8* %19, align 1
  %20919 = xor i64 %20909, 16
  %20920 = xor i64 %20919, %20910
  %20921 = lshr i64 %20920, 4
  %20922 = trunc i64 %20921 to i8
  %20923 = and i8 %20922, 1
  store i8 %20923, i8* %20, align 1
  %20924 = icmp eq i64 %20910, 0
  %20925 = zext i1 %20924 to i8
  store i8 %20925, i8* %21, align 1
  %20926 = lshr i64 %20910, 63
  %20927 = trunc i64 %20926 to i8
  store i8 %20927, i8* %22, align 1
  %20928 = lshr i64 %20909, 63
  %20929 = xor i64 %20926, %20928
  %20930 = add nuw nsw i64 %20929, %20926
  %20931 = icmp eq i64 %20930, 2
  %20932 = zext i1 %20931 to i8
  store i8 %20932, i8* %23, align 1
  %20933 = add i64 %20903, -40
  %20934 = add i64 %20896, 25
  store i64 %20934, i64* %3, align 8
  %20935 = inttoptr i64 %20933 to i32*
  %20936 = load i32, i32* %20935, align 4
  %20937 = sext i32 %20936 to i64
  %20938 = shl nsw i64 %20937, 7
  store i64 %20938, i64* %RDX.i1805, align 8
  %20939 = add i64 %20938, %20910
  store i64 %20939, i64* %RCX.i1692, align 8
  %20940 = icmp ult i64 %20939, %20910
  %20941 = icmp ult i64 %20939, %20938
  %20942 = or i1 %20940, %20941
  %20943 = zext i1 %20942 to i8
  store i8 %20943, i8* %18, align 1
  %20944 = trunc i64 %20939 to i32
  %20945 = and i32 %20944, 255
  %20946 = tail call i32 @llvm.ctpop.i32(i32 %20945)
  %20947 = trunc i32 %20946 to i8
  %20948 = and i8 %20947, 1
  %20949 = xor i8 %20948, 1
  store i8 %20949, i8* %19, align 1
  %20950 = xor i64 %20910, %20939
  %20951 = lshr i64 %20950, 4
  %20952 = trunc i64 %20951 to i8
  %20953 = and i8 %20952, 1
  store i8 %20953, i8* %20, align 1
  %20954 = icmp eq i64 %20939, 0
  %20955 = zext i1 %20954 to i8
  store i8 %20955, i8* %21, align 1
  %20956 = lshr i64 %20939, 63
  %20957 = trunc i64 %20956 to i8
  store i8 %20957, i8* %22, align 1
  %20958 = lshr i64 %20937, 56
  %20959 = and i64 %20958, 1
  %20960 = xor i64 %20956, %20926
  %20961 = xor i64 %20956, %20959
  %20962 = add nuw nsw i64 %20960, %20961
  %20963 = icmp eq i64 %20962, 2
  %20964 = zext i1 %20963 to i8
  store i8 %20964, i8* %23, align 1
  %20965 = load i64, i64* %RBP.i, align 8
  %20966 = add i64 %20965, -48
  %20967 = add i64 %20896, 36
  store i64 %20967, i64* %3, align 8
  %20968 = inttoptr i64 %20966 to i32*
  %20969 = load i32, i32* %20968, align 4
  %20970 = sext i32 %20969 to i64
  %20971 = shl nsw i64 %20970, 4
  store i64 %20971, i64* %RDX.i1805, align 8
  %20972 = add i64 %20971, %20939
  store i64 %20972, i64* %RCX.i1692, align 8
  %20973 = icmp ult i64 %20972, %20939
  %20974 = icmp ult i64 %20972, %20971
  %20975 = or i1 %20973, %20974
  %20976 = zext i1 %20975 to i8
  store i8 %20976, i8* %18, align 1
  %20977 = trunc i64 %20972 to i32
  %20978 = and i32 %20977, 255
  %20979 = tail call i32 @llvm.ctpop.i32(i32 %20978)
  %20980 = trunc i32 %20979 to i8
  %20981 = and i8 %20980, 1
  %20982 = xor i8 %20981, 1
  store i8 %20982, i8* %19, align 1
  %20983 = xor i64 %20971, %20939
  %20984 = xor i64 %20983, %20972
  %20985 = lshr i64 %20984, 4
  %20986 = trunc i64 %20985 to i8
  %20987 = and i8 %20986, 1
  store i8 %20987, i8* %20, align 1
  %20988 = icmp eq i64 %20972, 0
  %20989 = zext i1 %20988 to i8
  store i8 %20989, i8* %21, align 1
  %20990 = lshr i64 %20972, 63
  %20991 = trunc i64 %20990 to i8
  store i8 %20991, i8* %22, align 1
  %20992 = lshr i64 %20970, 59
  %20993 = and i64 %20992, 1
  %20994 = xor i64 %20990, %20956
  %20995 = xor i64 %20990, %20993
  %20996 = add nuw nsw i64 %20994, %20995
  %20997 = icmp eq i64 %20996, 2
  %20998 = zext i1 %20997 to i8
  store i8 %20998, i8* %23, align 1
  %20999 = add i64 %20965, -44
  %21000 = add i64 %20896, 47
  store i64 %21000, i64* %3, align 8
  %21001 = inttoptr i64 %20999 to i32*
  %21002 = load i32, i32* %21001, align 4
  %21003 = sext i32 %21002 to i64
  store i64 %21003, i64* %RDX.i1805, align 8
  %21004 = shl nsw i64 %21003, 1
  %21005 = add i64 %21004, %20972
  %21006 = add i64 %20896, 51
  store i64 %21006, i64* %3, align 8
  %21007 = inttoptr i64 %21005 to i16*
  %21008 = load i16, i16* %21007, align 2
  %21009 = zext i16 %21008 to i64
  store i64 %21009, i64* %RSI.i1889, align 8
  %21010 = load i64, i64* %RAX.i1763, align 8
  %21011 = zext i16 %21008 to i32
  %21012 = zext i16 %21008 to i64
  %21013 = trunc i64 %21010 to i32
  %21014 = add i32 %21011, %21013
  %21015 = zext i32 %21014 to i64
  store i64 %21015, i64* %RAX.i1763, align 8
  %21016 = icmp ult i32 %21014, %21013
  %21017 = icmp ult i32 %21014, %21011
  %21018 = or i1 %21016, %21017
  %21019 = zext i1 %21018 to i8
  store i8 %21019, i8* %18, align 1
  %21020 = and i32 %21014, 255
  %21021 = tail call i32 @llvm.ctpop.i32(i32 %21020)
  %21022 = trunc i32 %21021 to i8
  %21023 = and i8 %21022, 1
  %21024 = xor i8 %21023, 1
  store i8 %21024, i8* %19, align 1
  %21025 = xor i64 %21012, %21010
  %21026 = trunc i64 %21025 to i32
  %21027 = xor i32 %21026, %21014
  %21028 = lshr i32 %21027, 4
  %21029 = trunc i32 %21028 to i8
  %21030 = and i8 %21029, 1
  store i8 %21030, i8* %20, align 1
  %21031 = icmp eq i32 %21014, 0
  %21032 = zext i1 %21031 to i8
  store i8 %21032, i8* %21, align 1
  %21033 = lshr i32 %21014, 31
  %21034 = trunc i32 %21033 to i8
  store i8 %21034, i8* %22, align 1
  %21035 = lshr i32 %21013, 31
  %21036 = xor i32 %21033, %21035
  %21037 = add nuw nsw i32 %21036, %21033
  %21038 = icmp eq i32 %21037, 2
  %21039 = zext i1 %21038 to i8
  store i8 %21039, i8* %23, align 1
  %21040 = load i64, i64* %RBP.i, align 8
  %21041 = add i64 %21040, -1456
  %21042 = add i64 %20896, 59
  store i64 %21042, i64* %3, align 8
  %21043 = inttoptr i64 %21041 to i32*
  store i32 %21014, i32* %21043, align 4
  %.pre548 = load i64, i64* %3, align 8
  br label %block_.L_4a6e9c

block_.L_4a6e9c:                                  ; preds = %block_.L_4a6e61, %block_4a6e54
  %21044 = phi i64 [ %.pre548, %block_.L_4a6e61 ], [ %20902, %block_4a6e54 ]
  %21045 = load i64, i64* %RBP.i, align 8
  %21046 = add i64 %21045, -1456
  %21047 = add i64 %21044, 6
  store i64 %21047, i64* %3, align 8
  %21048 = inttoptr i64 %21046 to i32*
  %21049 = load i32, i32* %21048, align 4
  %21050 = zext i32 %21049 to i64
  store i64 %21050, i64* %RAX.i1763, align 8
  %21051 = add i64 %21045, -1452
  %21052 = add i64 %21044, 12
  store i64 %21052, i64* %3, align 8
  %21053 = inttoptr i64 %21051 to i32*
  %21054 = load i32, i32* %21053, align 4
  %21055 = zext i32 %21054 to i64
  store i64 %21055, i64* %RCX.i1692, align 8
  %21056 = sub i32 %21054, %21049
  %21057 = icmp ult i32 %21054, %21049
  %21058 = zext i1 %21057 to i8
  store i8 %21058, i8* %18, align 1
  %21059 = and i32 %21056, 255
  %21060 = tail call i32 @llvm.ctpop.i32(i32 %21059)
  %21061 = trunc i32 %21060 to i8
  %21062 = and i8 %21061, 1
  %21063 = xor i8 %21062, 1
  store i8 %21063, i8* %19, align 1
  %21064 = xor i32 %21049, %21054
  %21065 = xor i32 %21064, %21056
  %21066 = lshr i32 %21065, 4
  %21067 = trunc i32 %21066 to i8
  %21068 = and i8 %21067, 1
  store i8 %21068, i8* %20, align 1
  %21069 = icmp eq i32 %21056, 0
  %21070 = zext i1 %21069 to i8
  store i8 %21070, i8* %21, align 1
  %21071 = lshr i32 %21056, 31
  %21072 = trunc i32 %21071 to i8
  store i8 %21072, i8* %22, align 1
  %21073 = lshr i32 %21054, 31
  %21074 = lshr i32 %21049, 31
  %21075 = xor i32 %21074, %21073
  %21076 = xor i32 %21071, %21073
  %21077 = add nuw nsw i32 %21076, %21075
  %21078 = icmp eq i32 %21077, 2
  %21079 = zext i1 %21078 to i8
  store i8 %21079, i8* %23, align 1
  %21080 = icmp ne i8 %21072, 0
  %21081 = xor i1 %21080, %21078
  %.v830 = select i1 %21081, i64 20, i64 45
  %21082 = add i64 %21044, %.v830
  store i64 %21082, i64* %3, align 8
  br i1 %21081, label %block_4a6eb0, label %block_.L_4a6ec9

block_4a6eb0:                                     ; preds = %block_.L_4a6e9c
  %21083 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %21083, i64* %RAX.i1763, align 8
  %21084 = add i64 %21083, 72684
  %21085 = add i64 %21082, 14
  store i64 %21085, i64* %3, align 8
  %21086 = inttoptr i64 %21084 to i32*
  %21087 = load i32, i32* %21086, align 4
  %21088 = zext i32 %21087 to i64
  store i64 %21088, i64* %RCX.i1692, align 8
  %21089 = add i64 %21045, -1460
  %21090 = add i64 %21082, 20
  store i64 %21090, i64* %3, align 8
  %21091 = inttoptr i64 %21089 to i32*
  store i32 %21087, i32* %21091, align 4
  %21092 = load i64, i64* %3, align 8
  %21093 = add i64 %21092, 152
  store i64 %21093, i64* %3, align 8
  br label %block_.L_4a6f5c

block_.L_4a6ec9:                                  ; preds = %block_.L_4a6e9c
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %21094 = add i64 %21045, -608
  %21095 = add i64 %21082, 8
  store i64 %21095, i64* %3, align 8
  %21096 = inttoptr i64 %21094 to i32*
  %21097 = load i32, i32* %21096, align 4
  %21098 = zext i32 %21097 to i64
  store i64 %21098, i64* %RCX.i1692, align 8
  %21099 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %21100 = add i64 %21099, 7352
  store i64 %21100, i64* %RDX.i1805, align 8
  %21101 = icmp ugt i64 %21099, -7353
  %21102 = zext i1 %21101 to i8
  store i8 %21102, i8* %18, align 1
  %21103 = trunc i64 %21100 to i32
  %21104 = and i32 %21103, 255
  %21105 = tail call i32 @llvm.ctpop.i32(i32 %21104)
  %21106 = trunc i32 %21105 to i8
  %21107 = and i8 %21106, 1
  %21108 = xor i8 %21107, 1
  store i8 %21108, i8* %19, align 1
  %21109 = xor i64 %21099, 16
  %21110 = xor i64 %21109, %21100
  %21111 = lshr i64 %21110, 4
  %21112 = trunc i64 %21111 to i8
  %21113 = and i8 %21112, 1
  store i8 %21113, i8* %20, align 1
  %21114 = icmp eq i64 %21100, 0
  %21115 = zext i1 %21114 to i8
  store i8 %21115, i8* %21, align 1
  %21116 = lshr i64 %21100, 63
  %21117 = trunc i64 %21116 to i8
  store i8 %21117, i8* %22, align 1
  %21118 = lshr i64 %21099, 63
  %21119 = xor i64 %21116, %21118
  %21120 = add nuw nsw i64 %21119, %21116
  %21121 = icmp eq i64 %21120, 2
  %21122 = zext i1 %21121 to i8
  store i8 %21122, i8* %23, align 1
  %21123 = add i64 %21045, -40
  %21124 = add i64 %21082, 27
  store i64 %21124, i64* %3, align 8
  %21125 = inttoptr i64 %21123 to i32*
  %21126 = load i32, i32* %21125, align 4
  %21127 = sext i32 %21126 to i64
  %21128 = shl nsw i64 %21127, 7
  store i64 %21128, i64* %RSI.i1889, align 8
  %21129 = add i64 %21128, %21100
  store i64 %21129, i64* %RDX.i1805, align 8
  %21130 = icmp ult i64 %21129, %21100
  %21131 = icmp ult i64 %21129, %21128
  %21132 = or i1 %21130, %21131
  %21133 = zext i1 %21132 to i8
  store i8 %21133, i8* %18, align 1
  %21134 = trunc i64 %21129 to i32
  %21135 = and i32 %21134, 255
  %21136 = tail call i32 @llvm.ctpop.i32(i32 %21135)
  %21137 = trunc i32 %21136 to i8
  %21138 = and i8 %21137, 1
  %21139 = xor i8 %21138, 1
  store i8 %21139, i8* %19, align 1
  %21140 = xor i64 %21100, %21129
  %21141 = lshr i64 %21140, 4
  %21142 = trunc i64 %21141 to i8
  %21143 = and i8 %21142, 1
  store i8 %21143, i8* %20, align 1
  %21144 = icmp eq i64 %21129, 0
  %21145 = zext i1 %21144 to i8
  store i8 %21145, i8* %21, align 1
  %21146 = lshr i64 %21129, 63
  %21147 = trunc i64 %21146 to i8
  store i8 %21147, i8* %22, align 1
  %21148 = lshr i64 %21127, 56
  %21149 = and i64 %21148, 1
  %21150 = xor i64 %21146, %21116
  %21151 = xor i64 %21146, %21149
  %21152 = add nuw nsw i64 %21150, %21151
  %21153 = icmp eq i64 %21152, 2
  %21154 = zext i1 %21153 to i8
  store i8 %21154, i8* %23, align 1
  %21155 = load i64, i64* %RBP.i, align 8
  %21156 = add i64 %21155, -48
  %21157 = add i64 %21082, 38
  store i64 %21157, i64* %3, align 8
  %21158 = inttoptr i64 %21156 to i32*
  %21159 = load i32, i32* %21158, align 4
  %21160 = sext i32 %21159 to i64
  %21161 = shl nsw i64 %21160, 4
  store i64 %21161, i64* %RSI.i1889, align 8
  %21162 = add i64 %21161, %21129
  store i64 %21162, i64* %RDX.i1805, align 8
  %21163 = icmp ult i64 %21162, %21129
  %21164 = icmp ult i64 %21162, %21161
  %21165 = or i1 %21163, %21164
  %21166 = zext i1 %21165 to i8
  store i8 %21166, i8* %18, align 1
  %21167 = trunc i64 %21162 to i32
  %21168 = and i32 %21167, 255
  %21169 = tail call i32 @llvm.ctpop.i32(i32 %21168)
  %21170 = trunc i32 %21169 to i8
  %21171 = and i8 %21170, 1
  %21172 = xor i8 %21171, 1
  store i8 %21172, i8* %19, align 1
  %21173 = xor i64 %21161, %21129
  %21174 = xor i64 %21173, %21162
  %21175 = lshr i64 %21174, 4
  %21176 = trunc i64 %21175 to i8
  %21177 = and i8 %21176, 1
  store i8 %21177, i8* %20, align 1
  %21178 = icmp eq i64 %21162, 0
  %21179 = zext i1 %21178 to i8
  store i8 %21179, i8* %21, align 1
  %21180 = lshr i64 %21162, 63
  %21181 = trunc i64 %21180 to i8
  store i8 %21181, i8* %22, align 1
  %21182 = lshr i64 %21160, 59
  %21183 = and i64 %21182, 1
  %21184 = xor i64 %21180, %21146
  %21185 = xor i64 %21180, %21183
  %21186 = add nuw nsw i64 %21184, %21185
  %21187 = icmp eq i64 %21186, 2
  %21188 = zext i1 %21187 to i8
  store i8 %21188, i8* %23, align 1
  %21189 = add i64 %21155, -44
  %21190 = add i64 %21082, 49
  store i64 %21190, i64* %3, align 8
  %21191 = inttoptr i64 %21189 to i32*
  %21192 = load i32, i32* %21191, align 4
  %21193 = sext i32 %21192 to i64
  store i64 %21193, i64* %RSI.i1889, align 8
  %21194 = shl nsw i64 %21193, 1
  %21195 = add i64 %21194, %21162
  %21196 = add i64 %21082, 53
  store i64 %21196, i64* %3, align 8
  %21197 = inttoptr i64 %21195 to i16*
  %21198 = load i16, i16* %21197, align 2
  %21199 = zext i16 %21198 to i64
  store i64 %21199, i64* %RDI.i2141, align 8
  %21200 = load i64, i64* %RCX.i1692, align 8
  %21201 = zext i16 %21198 to i32
  %21202 = trunc i64 %21200 to i32
  %21203 = add i32 %21201, %21202
  %21204 = zext i32 %21203 to i64
  store i64 %21204, i64* %RCX.i1692, align 8
  %21205 = lshr i32 %21203, 31
  %21206 = load i32, i32* %EAX.i2159, align 4
  %21207 = sub i32 %21206, %21203
  %21208 = icmp ult i32 %21206, %21203
  %21209 = zext i1 %21208 to i8
  store i8 %21209, i8* %18, align 1
  %21210 = and i32 %21207, 255
  %21211 = tail call i32 @llvm.ctpop.i32(i32 %21210)
  %21212 = trunc i32 %21211 to i8
  %21213 = and i8 %21212, 1
  %21214 = xor i8 %21213, 1
  store i8 %21214, i8* %19, align 1
  %21215 = xor i32 %21203, %21206
  %21216 = xor i32 %21215, %21207
  %21217 = lshr i32 %21216, 4
  %21218 = trunc i32 %21217 to i8
  %21219 = and i8 %21218, 1
  store i8 %21219, i8* %20, align 1
  %21220 = icmp eq i32 %21207, 0
  %21221 = zext i1 %21220 to i8
  store i8 %21221, i8* %21, align 1
  %21222 = lshr i32 %21207, 31
  %21223 = trunc i32 %21222 to i8
  store i8 %21223, i8* %22, align 1
  %21224 = lshr i32 %21206, 31
  %21225 = xor i32 %21205, %21224
  %21226 = xor i32 %21222, %21224
  %21227 = add nuw nsw i32 %21226, %21225
  %21228 = icmp eq i32 %21227, 2
  %21229 = zext i1 %21228 to i8
  store i8 %21229, i8* %23, align 1
  %21230 = icmp ne i8 %21223, 0
  %21231 = xor i1 %21230, %21228
  %21232 = or i1 %21220, %21231
  %.v831 = select i1 %21232, i64 76, i64 63
  %21233 = add i64 %21082, %.v831
  store i64 %21233, i64* %3, align 8
  br i1 %21232, label %block_.L_4a6f15, label %block_4a6f08

block_4a6f08:                                     ; preds = %block_.L_4a6ec9
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %21234 = load i64, i64* %RBP.i, align 8
  %21235 = add i64 %21234, -1464
  %21236 = add i64 %21233, 8
  store i64 %21236, i64* %3, align 8
  %21237 = inttoptr i64 %21235 to i32*
  store i32 0, i32* %21237, align 4
  %21238 = load i64, i64* %3, align 8
  %21239 = add i64 %21238, 64
  store i64 %21239, i64* %3, align 8
  br label %block_.L_4a6f50

block_.L_4a6f15:                                  ; preds = %block_.L_4a6ec9
  %21240 = load i64, i64* %RBP.i, align 8
  %21241 = add i64 %21240, -608
  %21242 = add i64 %21233, 6
  store i64 %21242, i64* %3, align 8
  %21243 = inttoptr i64 %21241 to i32*
  %21244 = load i32, i32* %21243, align 4
  %21245 = zext i32 %21244 to i64
  store i64 %21245, i64* %RAX.i1763, align 8
  %21246 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %21247 = add i64 %21246, 7352
  store i64 %21247, i64* %RCX.i1692, align 8
  %21248 = icmp ugt i64 %21246, -7353
  %21249 = zext i1 %21248 to i8
  store i8 %21249, i8* %18, align 1
  %21250 = trunc i64 %21247 to i32
  %21251 = and i32 %21250, 255
  %21252 = tail call i32 @llvm.ctpop.i32(i32 %21251)
  %21253 = trunc i32 %21252 to i8
  %21254 = and i8 %21253, 1
  %21255 = xor i8 %21254, 1
  store i8 %21255, i8* %19, align 1
  %21256 = xor i64 %21246, 16
  %21257 = xor i64 %21256, %21247
  %21258 = lshr i64 %21257, 4
  %21259 = trunc i64 %21258 to i8
  %21260 = and i8 %21259, 1
  store i8 %21260, i8* %20, align 1
  %21261 = icmp eq i64 %21247, 0
  %21262 = zext i1 %21261 to i8
  store i8 %21262, i8* %21, align 1
  %21263 = lshr i64 %21247, 63
  %21264 = trunc i64 %21263 to i8
  store i8 %21264, i8* %22, align 1
  %21265 = lshr i64 %21246, 63
  %21266 = xor i64 %21263, %21265
  %21267 = add nuw nsw i64 %21266, %21263
  %21268 = icmp eq i64 %21267, 2
  %21269 = zext i1 %21268 to i8
  store i8 %21269, i8* %23, align 1
  %21270 = add i64 %21240, -40
  %21271 = add i64 %21233, 25
  store i64 %21271, i64* %3, align 8
  %21272 = inttoptr i64 %21270 to i32*
  %21273 = load i32, i32* %21272, align 4
  %21274 = sext i32 %21273 to i64
  %21275 = shl nsw i64 %21274, 7
  store i64 %21275, i64* %RDX.i1805, align 8
  %21276 = add i64 %21275, %21247
  store i64 %21276, i64* %RCX.i1692, align 8
  %21277 = icmp ult i64 %21276, %21247
  %21278 = icmp ult i64 %21276, %21275
  %21279 = or i1 %21277, %21278
  %21280 = zext i1 %21279 to i8
  store i8 %21280, i8* %18, align 1
  %21281 = trunc i64 %21276 to i32
  %21282 = and i32 %21281, 255
  %21283 = tail call i32 @llvm.ctpop.i32(i32 %21282)
  %21284 = trunc i32 %21283 to i8
  %21285 = and i8 %21284, 1
  %21286 = xor i8 %21285, 1
  store i8 %21286, i8* %19, align 1
  %21287 = xor i64 %21247, %21276
  %21288 = lshr i64 %21287, 4
  %21289 = trunc i64 %21288 to i8
  %21290 = and i8 %21289, 1
  store i8 %21290, i8* %20, align 1
  %21291 = icmp eq i64 %21276, 0
  %21292 = zext i1 %21291 to i8
  store i8 %21292, i8* %21, align 1
  %21293 = lshr i64 %21276, 63
  %21294 = trunc i64 %21293 to i8
  store i8 %21294, i8* %22, align 1
  %21295 = lshr i64 %21274, 56
  %21296 = and i64 %21295, 1
  %21297 = xor i64 %21293, %21263
  %21298 = xor i64 %21293, %21296
  %21299 = add nuw nsw i64 %21297, %21298
  %21300 = icmp eq i64 %21299, 2
  %21301 = zext i1 %21300 to i8
  store i8 %21301, i8* %23, align 1
  %21302 = load i64, i64* %RBP.i, align 8
  %21303 = add i64 %21302, -48
  %21304 = add i64 %21233, 36
  store i64 %21304, i64* %3, align 8
  %21305 = inttoptr i64 %21303 to i32*
  %21306 = load i32, i32* %21305, align 4
  %21307 = sext i32 %21306 to i64
  %21308 = shl nsw i64 %21307, 4
  store i64 %21308, i64* %RDX.i1805, align 8
  %21309 = add i64 %21308, %21276
  store i64 %21309, i64* %RCX.i1692, align 8
  %21310 = icmp ult i64 %21309, %21276
  %21311 = icmp ult i64 %21309, %21308
  %21312 = or i1 %21310, %21311
  %21313 = zext i1 %21312 to i8
  store i8 %21313, i8* %18, align 1
  %21314 = trunc i64 %21309 to i32
  %21315 = and i32 %21314, 255
  %21316 = tail call i32 @llvm.ctpop.i32(i32 %21315)
  %21317 = trunc i32 %21316 to i8
  %21318 = and i8 %21317, 1
  %21319 = xor i8 %21318, 1
  store i8 %21319, i8* %19, align 1
  %21320 = xor i64 %21308, %21276
  %21321 = xor i64 %21320, %21309
  %21322 = lshr i64 %21321, 4
  %21323 = trunc i64 %21322 to i8
  %21324 = and i8 %21323, 1
  store i8 %21324, i8* %20, align 1
  %21325 = icmp eq i64 %21309, 0
  %21326 = zext i1 %21325 to i8
  store i8 %21326, i8* %21, align 1
  %21327 = lshr i64 %21309, 63
  %21328 = trunc i64 %21327 to i8
  store i8 %21328, i8* %22, align 1
  %21329 = lshr i64 %21307, 59
  %21330 = and i64 %21329, 1
  %21331 = xor i64 %21327, %21293
  %21332 = xor i64 %21327, %21330
  %21333 = add nuw nsw i64 %21331, %21332
  %21334 = icmp eq i64 %21333, 2
  %21335 = zext i1 %21334 to i8
  store i8 %21335, i8* %23, align 1
  %21336 = add i64 %21302, -44
  %21337 = add i64 %21233, 47
  store i64 %21337, i64* %3, align 8
  %21338 = inttoptr i64 %21336 to i32*
  %21339 = load i32, i32* %21338, align 4
  %21340 = sext i32 %21339 to i64
  store i64 %21340, i64* %RDX.i1805, align 8
  %21341 = shl nsw i64 %21340, 1
  %21342 = add i64 %21341, %21309
  %21343 = add i64 %21233, 51
  store i64 %21343, i64* %3, align 8
  %21344 = inttoptr i64 %21342 to i16*
  %21345 = load i16, i16* %21344, align 2
  %21346 = zext i16 %21345 to i64
  store i64 %21346, i64* %RSI.i1889, align 8
  %21347 = load i64, i64* %RAX.i1763, align 8
  %21348 = zext i16 %21345 to i32
  %21349 = zext i16 %21345 to i64
  %21350 = trunc i64 %21347 to i32
  %21351 = add i32 %21348, %21350
  %21352 = zext i32 %21351 to i64
  store i64 %21352, i64* %RAX.i1763, align 8
  %21353 = icmp ult i32 %21351, %21350
  %21354 = icmp ult i32 %21351, %21348
  %21355 = or i1 %21353, %21354
  %21356 = zext i1 %21355 to i8
  store i8 %21356, i8* %18, align 1
  %21357 = and i32 %21351, 255
  %21358 = tail call i32 @llvm.ctpop.i32(i32 %21357)
  %21359 = trunc i32 %21358 to i8
  %21360 = and i8 %21359, 1
  %21361 = xor i8 %21360, 1
  store i8 %21361, i8* %19, align 1
  %21362 = xor i64 %21349, %21347
  %21363 = trunc i64 %21362 to i32
  %21364 = xor i32 %21363, %21351
  %21365 = lshr i32 %21364, 4
  %21366 = trunc i32 %21365 to i8
  %21367 = and i8 %21366, 1
  store i8 %21367, i8* %20, align 1
  %21368 = icmp eq i32 %21351, 0
  %21369 = zext i1 %21368 to i8
  store i8 %21369, i8* %21, align 1
  %21370 = lshr i32 %21351, 31
  %21371 = trunc i32 %21370 to i8
  store i8 %21371, i8* %22, align 1
  %21372 = lshr i32 %21350, 31
  %21373 = xor i32 %21370, %21372
  %21374 = add nuw nsw i32 %21373, %21370
  %21375 = icmp eq i32 %21374, 2
  %21376 = zext i1 %21375 to i8
  store i8 %21376, i8* %23, align 1
  %21377 = load i64, i64* %RBP.i, align 8
  %21378 = add i64 %21377, -1464
  %21379 = add i64 %21233, 59
  store i64 %21379, i64* %3, align 8
  %21380 = inttoptr i64 %21378 to i32*
  store i32 %21351, i32* %21380, align 4
  %.pre549 = load i64, i64* %3, align 8
  br label %block_.L_4a6f50

block_.L_4a6f50:                                  ; preds = %block_.L_4a6f15, %block_4a6f08
  %21381 = phi i64 [ %.pre549, %block_.L_4a6f15 ], [ %21239, %block_4a6f08 ]
  %21382 = load i64, i64* %RBP.i, align 8
  %21383 = add i64 %21382, -1464
  %21384 = add i64 %21381, 6
  store i64 %21384, i64* %3, align 8
  %21385 = inttoptr i64 %21383 to i32*
  %21386 = load i32, i32* %21385, align 4
  %21387 = zext i32 %21386 to i64
  store i64 %21387, i64* %RAX.i1763, align 8
  %21388 = add i64 %21382, -1460
  %21389 = add i64 %21381, 12
  store i64 %21389, i64* %3, align 8
  %21390 = inttoptr i64 %21388 to i32*
  store i32 %21386, i32* %21390, align 4
  %.pre550 = load i64, i64* %3, align 8
  br label %block_.L_4a6f5c

block_.L_4a6f5c:                                  ; preds = %block_.L_4a6f50, %block_4a6eb0
  %21391 = phi i64 [ %.pre550, %block_.L_4a6f50 ], [ %21093, %block_4a6eb0 ]
  %21392 = load i64, i64* %RBP.i, align 8
  %21393 = add i64 %21392, -1460
  %21394 = add i64 %21391, 6
  store i64 %21394, i64* %3, align 8
  %21395 = inttoptr i64 %21393 to i32*
  %21396 = load i32, i32* %21395, align 4
  %21397 = zext i32 %21396 to i64
  store i64 %21397, i64* %RAX.i1763, align 8
  store i64 0, i64* %RCX.i1692, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %21398 = trunc i32 %21396 to i16
  store i16 %21398, i16* %DX.i5417, align 2
  %21399 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %21399, i64* %RSI.i1889, align 8
  %21400 = add i64 %21399, 6424
  %21401 = add i64 %21391, 26
  store i64 %21401, i64* %3, align 8
  %21402 = inttoptr i64 %21400 to i64*
  %21403 = load i64, i64* %21402, align 8
  store i64 %21403, i64* %RSI.i1889, align 8
  %21404 = add i64 %21392, -496
  %21405 = add i64 %21391, 32
  store i64 %21405, i64* %3, align 8
  %21406 = inttoptr i64 %21404 to i32*
  %21407 = load i32, i32* %21406, align 4
  %21408 = zext i32 %21407 to i64
  store i64 %21408, i64* %RAX.i1763, align 8
  %21409 = add i64 %21392, -48
  %21410 = add i64 %21391, 35
  store i64 %21410, i64* %3, align 8
  %21411 = inttoptr i64 %21409 to i32*
  %21412 = load i32, i32* %21411, align 4
  %21413 = add i32 %21412, %21407
  %21414 = zext i32 %21413 to i64
  store i64 %21414, i64* %RAX.i1763, align 8
  %21415 = icmp ult i32 %21413, %21407
  %21416 = icmp ult i32 %21413, %21412
  %21417 = or i1 %21415, %21416
  %21418 = zext i1 %21417 to i8
  store i8 %21418, i8* %18, align 1
  %21419 = and i32 %21413, 255
  %21420 = tail call i32 @llvm.ctpop.i32(i32 %21419)
  %21421 = trunc i32 %21420 to i8
  %21422 = and i8 %21421, 1
  %21423 = xor i8 %21422, 1
  store i8 %21423, i8* %19, align 1
  %21424 = xor i32 %21412, %21407
  %21425 = xor i32 %21424, %21413
  %21426 = lshr i32 %21425, 4
  %21427 = trunc i32 %21426 to i8
  %21428 = and i8 %21427, 1
  store i8 %21428, i8* %20, align 1
  %21429 = icmp eq i32 %21413, 0
  %21430 = zext i1 %21429 to i8
  store i8 %21430, i8* %21, align 1
  %21431 = lshr i32 %21413, 31
  %21432 = trunc i32 %21431 to i8
  store i8 %21432, i8* %22, align 1
  %21433 = lshr i32 %21407, 31
  %21434 = lshr i32 %21412, 31
  %21435 = xor i32 %21431, %21433
  %21436 = xor i32 %21431, %21434
  %21437 = add nuw nsw i32 %21435, %21436
  %21438 = icmp eq i32 %21437, 2
  %21439 = zext i1 %21438 to i8
  store i8 %21439, i8* %23, align 1
  %21440 = sext i32 %21413 to i64
  store i64 %21440, i64* %RDI.i2141, align 8
  %21441 = shl nsw i64 %21440, 3
  %21442 = add i64 %21403, %21441
  %21443 = add i64 %21391, 42
  store i64 %21443, i64* %3, align 8
  %21444 = inttoptr i64 %21442 to i64*
  %21445 = load i64, i64* %21444, align 8
  store i64 %21445, i64* %RSI.i1889, align 8
  %21446 = load i64, i64* %RBP.i, align 8
  %21447 = add i64 %21446, -492
  %21448 = add i64 %21391, 48
  store i64 %21448, i64* %3, align 8
  %21449 = inttoptr i64 %21447 to i32*
  %21450 = load i32, i32* %21449, align 4
  %21451 = zext i32 %21450 to i64
  store i64 %21451, i64* %RAX.i1763, align 8
  %21452 = add i64 %21446, -44
  %21453 = add i64 %21391, 51
  store i64 %21453, i64* %3, align 8
  %21454 = inttoptr i64 %21452 to i32*
  %21455 = load i32, i32* %21454, align 4
  %21456 = add i32 %21455, %21450
  %21457 = zext i32 %21456 to i64
  store i64 %21457, i64* %RAX.i1763, align 8
  %21458 = icmp ult i32 %21456, %21450
  %21459 = icmp ult i32 %21456, %21455
  %21460 = or i1 %21458, %21459
  %21461 = zext i1 %21460 to i8
  store i8 %21461, i8* %18, align 1
  %21462 = and i32 %21456, 255
  %21463 = tail call i32 @llvm.ctpop.i32(i32 %21462)
  %21464 = trunc i32 %21463 to i8
  %21465 = and i8 %21464, 1
  %21466 = xor i8 %21465, 1
  store i8 %21466, i8* %19, align 1
  %21467 = xor i32 %21455, %21450
  %21468 = xor i32 %21467, %21456
  %21469 = lshr i32 %21468, 4
  %21470 = trunc i32 %21469 to i8
  %21471 = and i8 %21470, 1
  store i8 %21471, i8* %20, align 1
  %21472 = icmp eq i32 %21456, 0
  %21473 = zext i1 %21472 to i8
  store i8 %21473, i8* %21, align 1
  %21474 = lshr i32 %21456, 31
  %21475 = trunc i32 %21474 to i8
  store i8 %21475, i8* %22, align 1
  %21476 = lshr i32 %21450, 31
  %21477 = lshr i32 %21455, 31
  %21478 = xor i32 %21474, %21476
  %21479 = xor i32 %21474, %21477
  %21480 = add nuw nsw i32 %21478, %21479
  %21481 = icmp eq i32 %21480, 2
  %21482 = zext i1 %21481 to i8
  store i8 %21482, i8* %23, align 1
  %21483 = sext i32 %21456 to i64
  store i64 %21483, i64* %RDI.i2141, align 8
  %21484 = shl nsw i64 %21483, 1
  %21485 = add i64 %21445, %21484
  %21486 = load i16, i16* %DX.i5417, align 2
  %21487 = add i64 %21391, 58
  store i64 %21487, i64* %3, align 8
  %21488 = inttoptr i64 %21485 to i16*
  store i16 %21486, i16* %21488, align 2
  %21489 = load i64, i64* %3, align 8
  %21490 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %21490, i64* %RSI.i1889, align 8
  %21491 = add i64 %21490, 72688
  %21492 = add i64 %21489, 14
  store i64 %21492, i64* %3, align 8
  %21493 = inttoptr i64 %21491 to i32*
  %21494 = load i32, i32* %21493, align 4
  %21495 = zext i32 %21494 to i64
  store i64 %21495, i64* %RAX.i1763, align 8
  %21496 = load i64, i64* %RBP.i, align 8
  %21497 = add i64 %21496, -604
  %21498 = add i64 %21489, 21
  store i64 %21498, i64* %3, align 8
  %21499 = inttoptr i64 %21497 to i32*
  %21500 = load i32, i32* %21499, align 4
  %21501 = zext i32 %21500 to i64
  store i64 %21501, i64* %26, align 8
  %21502 = add i64 %21490, 8504
  %21503 = lshr i64 %21502, 63
  %21504 = add i64 %21490, 10552
  store i64 %21504, i64* %RSI.i1889, align 8
  %21505 = icmp ugt i64 %21502, -2049
  %21506 = zext i1 %21505 to i8
  store i8 %21506, i8* %18, align 1
  %21507 = trunc i64 %21504 to i32
  %21508 = and i32 %21507, 255
  %21509 = tail call i32 @llvm.ctpop.i32(i32 %21508)
  %21510 = trunc i32 %21509 to i8
  %21511 = and i8 %21510, 1
  %21512 = xor i8 %21511, 1
  store i8 %21512, i8* %19, align 1
  %21513 = xor i64 %21504, %21502
  %21514 = lshr i64 %21513, 4
  %21515 = trunc i64 %21514 to i8
  %21516 = and i8 %21515, 1
  store i8 %21516, i8* %20, align 1
  %21517 = icmp eq i64 %21504, 0
  %21518 = zext i1 %21517 to i8
  store i8 %21518, i8* %21, align 1
  %21519 = lshr i64 %21504, 63
  %21520 = trunc i64 %21519 to i8
  store i8 %21520, i8* %22, align 1
  %21521 = xor i64 %21519, %21503
  %21522 = add nuw nsw i64 %21521, %21519
  %21523 = icmp eq i64 %21522, 2
  %21524 = zext i1 %21523 to i8
  store i8 %21524, i8* %23, align 1
  %21525 = add i64 %21496, -632
  %21526 = add i64 %21489, 50
  store i64 %21526, i64* %3, align 8
  %21527 = inttoptr i64 %21525 to i32*
  %21528 = load i32, i32* %21527, align 4
  %21529 = sext i32 %21528 to i64
  %21530 = shl nsw i64 %21529, 9
  store i64 %21530, i64* %RDI.i2141, align 8
  %21531 = add i64 %21530, %21504
  store i64 %21531, i64* %RSI.i1889, align 8
  %21532 = icmp ult i64 %21531, %21504
  %21533 = icmp ult i64 %21531, %21530
  %21534 = or i1 %21532, %21533
  %21535 = zext i1 %21534 to i8
  store i8 %21535, i8* %18, align 1
  %21536 = trunc i64 %21531 to i32
  %21537 = and i32 %21536, 255
  %21538 = tail call i32 @llvm.ctpop.i32(i32 %21537)
  %21539 = trunc i32 %21538 to i8
  %21540 = and i8 %21539, 1
  %21541 = xor i8 %21540, 1
  store i8 %21541, i8* %19, align 1
  %21542 = xor i64 %21504, %21531
  %21543 = lshr i64 %21542, 4
  %21544 = trunc i64 %21543 to i8
  %21545 = and i8 %21544, 1
  store i8 %21545, i8* %20, align 1
  %21546 = icmp eq i64 %21531, 0
  %21547 = zext i1 %21546 to i8
  store i8 %21547, i8* %21, align 1
  %21548 = lshr i64 %21531, 63
  %21549 = trunc i64 %21548 to i8
  store i8 %21549, i8* %22, align 1
  %21550 = lshr i64 %21529, 54
  %21551 = and i64 %21550, 1
  %21552 = xor i64 %21548, %21519
  %21553 = xor i64 %21548, %21551
  %21554 = add nuw nsw i64 %21552, %21553
  %21555 = icmp eq i64 %21554, 2
  %21556 = zext i1 %21555 to i8
  store i8 %21556, i8* %23, align 1
  %21557 = load i64, i64* %RBP.i, align 8
  %21558 = add i64 %21557, -484
  %21559 = add i64 %21489, 64
  store i64 %21559, i64* %3, align 8
  %21560 = inttoptr i64 %21558 to i32*
  %21561 = load i32, i32* %21560, align 4
  %21562 = zext i32 %21561 to i64
  store i64 %21562, i64* %R9.i, align 8
  %21563 = add i64 %21557, -44
  %21564 = add i64 %21489, 68
  store i64 %21564, i64* %3, align 8
  %21565 = inttoptr i64 %21563 to i32*
  %21566 = load i32, i32* %21565, align 4
  %21567 = add i32 %21566, %21561
  %21568 = zext i32 %21567 to i64
  store i64 %21568, i64* %R9.i, align 8
  %21569 = sext i32 %21567 to i64
  %21570 = shl nsw i64 %21569, 5
  store i64 %21570, i64* %RDI.i2141, align 8
  %21571 = load i64, i64* %RSI.i1889, align 8
  %21572 = add i64 %21570, %21571
  store i64 %21572, i64* %RSI.i1889, align 8
  %21573 = icmp ult i64 %21572, %21571
  %21574 = icmp ult i64 %21572, %21570
  %21575 = or i1 %21573, %21574
  %21576 = zext i1 %21575 to i8
  store i8 %21576, i8* %18, align 1
  %21577 = trunc i64 %21572 to i32
  %21578 = and i32 %21577, 255
  %21579 = tail call i32 @llvm.ctpop.i32(i32 %21578)
  %21580 = trunc i32 %21579 to i8
  %21581 = and i8 %21580, 1
  %21582 = xor i8 %21581, 1
  store i8 %21582, i8* %19, align 1
  %21583 = xor i64 %21571, %21572
  %21584 = lshr i64 %21583, 4
  %21585 = trunc i64 %21584 to i8
  %21586 = and i8 %21585, 1
  store i8 %21586, i8* %20, align 1
  %21587 = icmp eq i64 %21572, 0
  %21588 = zext i1 %21587 to i8
  store i8 %21588, i8* %21, align 1
  %21589 = lshr i64 %21572, 63
  %21590 = trunc i64 %21589 to i8
  store i8 %21590, i8* %22, align 1
  %21591 = lshr i64 %21571, 63
  %21592 = lshr i64 %21569, 58
  %21593 = and i64 %21592, 1
  %21594 = xor i64 %21589, %21591
  %21595 = xor i64 %21589, %21593
  %21596 = add nuw nsw i64 %21594, %21595
  %21597 = icmp eq i64 %21596, 2
  %21598 = zext i1 %21597 to i8
  store i8 %21598, i8* %23, align 1
  %21599 = load i64, i64* %RBP.i, align 8
  %21600 = add i64 %21599, -488
  %21601 = add i64 %21489, 85
  store i64 %21601, i64* %3, align 8
  %21602 = inttoptr i64 %21600 to i32*
  %21603 = load i32, i32* %21602, align 4
  %21604 = zext i32 %21603 to i64
  store i64 %21604, i64* %R9.i, align 8
  %21605 = add i64 %21599, -48
  %21606 = add i64 %21489, 89
  store i64 %21606, i64* %3, align 8
  %21607 = inttoptr i64 %21605 to i32*
  %21608 = load i32, i32* %21607, align 4
  %21609 = add i32 %21608, %21603
  %21610 = zext i32 %21609 to i64
  store i64 %21610, i64* %R9.i, align 8
  %21611 = icmp ult i32 %21609, %21603
  %21612 = icmp ult i32 %21609, %21608
  %21613 = or i1 %21611, %21612
  %21614 = zext i1 %21613 to i8
  store i8 %21614, i8* %18, align 1
  %21615 = and i32 %21609, 255
  %21616 = tail call i32 @llvm.ctpop.i32(i32 %21615)
  %21617 = trunc i32 %21616 to i8
  %21618 = and i8 %21617, 1
  %21619 = xor i8 %21618, 1
  store i8 %21619, i8* %19, align 1
  %21620 = xor i32 %21608, %21603
  %21621 = xor i32 %21620, %21609
  %21622 = lshr i32 %21621, 4
  %21623 = trunc i32 %21622 to i8
  %21624 = and i8 %21623, 1
  store i8 %21624, i8* %20, align 1
  %21625 = icmp eq i32 %21609, 0
  %21626 = zext i1 %21625 to i8
  store i8 %21626, i8* %21, align 1
  %21627 = lshr i32 %21609, 31
  %21628 = trunc i32 %21627 to i8
  store i8 %21628, i8* %22, align 1
  %21629 = lshr i32 %21603, 31
  %21630 = lshr i32 %21608, 31
  %21631 = xor i32 %21627, %21629
  %21632 = xor i32 %21627, %21630
  %21633 = add nuw nsw i32 %21631, %21632
  %21634 = icmp eq i32 %21633, 2
  %21635 = zext i1 %21634 to i8
  store i8 %21635, i8* %23, align 1
  %21636 = sext i32 %21609 to i64
  store i64 %21636, i64* %RDI.i2141, align 8
  %21637 = shl nsw i64 %21636, 1
  %21638 = add i64 %21572, %21637
  %21639 = add i64 %21489, 97
  store i64 %21639, i64* %3, align 8
  %21640 = inttoptr i64 %21638 to i16*
  %21641 = load i16, i16* %21640, align 2
  %21642 = zext i16 %21641 to i64
  store i64 %21642, i64* %R9.i, align 8
  %21643 = load i32, i32* %R8D.i1718, align 4
  %21644 = zext i16 %21641 to i32
  %21645 = add i32 %21644, %21643
  %21646 = zext i32 %21645 to i64
  store i64 %21646, i64* %26, align 8
  %21647 = lshr i32 %21645, 31
  %21648 = load i32, i32* %ECX.i7699, align 4
  %21649 = sub i32 %21648, %21645
  %21650 = icmp ult i32 %21648, %21645
  %21651 = zext i1 %21650 to i8
  store i8 %21651, i8* %18, align 1
  %21652 = and i32 %21649, 255
  %21653 = tail call i32 @llvm.ctpop.i32(i32 %21652)
  %21654 = trunc i32 %21653 to i8
  %21655 = and i8 %21654, 1
  %21656 = xor i8 %21655, 1
  store i8 %21656, i8* %19, align 1
  %21657 = xor i32 %21645, %21648
  %21658 = xor i32 %21657, %21649
  %21659 = lshr i32 %21658, 4
  %21660 = trunc i32 %21659 to i8
  %21661 = and i8 %21660, 1
  store i8 %21661, i8* %20, align 1
  %21662 = icmp eq i32 %21649, 0
  %21663 = zext i1 %21662 to i8
  store i8 %21663, i8* %21, align 1
  %21664 = lshr i32 %21649, 31
  %21665 = trunc i32 %21664 to i8
  store i8 %21665, i8* %22, align 1
  %21666 = lshr i32 %21648, 31
  %21667 = xor i32 %21647, %21666
  %21668 = xor i32 %21664, %21666
  %21669 = add nuw nsw i32 %21668, %21667
  %21670 = icmp eq i32 %21669, 2
  %21671 = zext i1 %21670 to i8
  store i8 %21671, i8* %23, align 1
  %21672 = load i64, i64* %RBP.i, align 8
  %21673 = add i64 %21672, -1468
  %21674 = load i32, i32* %EAX.i2159, align 4
  %21675 = add i64 %21489, 109
  store i64 %21675, i64* %3, align 8
  %21676 = inttoptr i64 %21673 to i32*
  store i32 %21674, i32* %21676, align 4
  %21677 = load i64, i64* %3, align 8
  %21678 = load i8, i8* %21, align 1
  %21679 = icmp ne i8 %21678, 0
  %21680 = load i8, i8* %22, align 1
  %21681 = icmp ne i8 %21680, 0
  %21682 = load i8, i8* %23, align 1
  %21683 = icmp ne i8 %21682, 0
  %21684 = xor i1 %21681, %21683
  %21685 = or i1 %21679, %21684
  %.v1013 = select i1 %21685, i64 19, i64 6
  %21686 = add i64 %21677, %.v1013
  store i64 %21686, i64* %3, align 8
  br i1 %21685, label %block_.L_4a7016, label %block_4a7009

block_4a7009:                                     ; preds = %block_.L_4a6f5c
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %21687 = load i64, i64* %RBP.i, align 8
  %21688 = add i64 %21687, -1472
  %21689 = add i64 %21686, 8
  store i64 %21689, i64* %3, align 8
  %21690 = inttoptr i64 %21688 to i32*
  store i32 0, i32* %21690, align 4
  %21691 = load i64, i64* %3, align 8
  %21692 = add i64 %21691, 90
  store i64 %21692, i64* %3, align 8
  br label %block_.L_4a706b

block_.L_4a7016:                                  ; preds = %block_.L_4a6f5c
  %21693 = load i64, i64* %RBP.i, align 8
  %21694 = add i64 %21693, -604
  %21695 = add i64 %21686, 6
  store i64 %21695, i64* %3, align 8
  %21696 = inttoptr i64 %21694 to i32*
  %21697 = load i32, i32* %21696, align 4
  %21698 = zext i32 %21697 to i64
  store i64 %21698, i64* %RAX.i1763, align 8
  %21699 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %21700 = add i64 %21699, 8504
  %21701 = lshr i64 %21700, 63
  %21702 = add i64 %21699, 10552
  store i64 %21702, i64* %RCX.i1692, align 8
  %21703 = icmp ugt i64 %21700, -2049
  %21704 = zext i1 %21703 to i8
  store i8 %21704, i8* %18, align 1
  %21705 = trunc i64 %21702 to i32
  %21706 = and i32 %21705, 255
  %21707 = tail call i32 @llvm.ctpop.i32(i32 %21706)
  %21708 = trunc i32 %21707 to i8
  %21709 = and i8 %21708, 1
  %21710 = xor i8 %21709, 1
  store i8 %21710, i8* %19, align 1
  %21711 = xor i64 %21702, %21700
  %21712 = lshr i64 %21711, 4
  %21713 = trunc i64 %21712 to i8
  %21714 = and i8 %21713, 1
  store i8 %21714, i8* %20, align 1
  %21715 = icmp eq i64 %21702, 0
  %21716 = zext i1 %21715 to i8
  store i8 %21716, i8* %21, align 1
  %21717 = lshr i64 %21702, 63
  %21718 = trunc i64 %21717 to i8
  store i8 %21718, i8* %22, align 1
  %21719 = xor i64 %21717, %21701
  %21720 = add nuw nsw i64 %21719, %21717
  %21721 = icmp eq i64 %21720, 2
  %21722 = zext i1 %21721 to i8
  store i8 %21722, i8* %23, align 1
  %21723 = add i64 %21693, -632
  %21724 = add i64 %21686, 35
  store i64 %21724, i64* %3, align 8
  %21725 = inttoptr i64 %21723 to i32*
  %21726 = load i32, i32* %21725, align 4
  %21727 = sext i32 %21726 to i64
  %21728 = shl nsw i64 %21727, 9
  store i64 %21728, i64* %RDX.i1805, align 8
  %21729 = add i64 %21728, %21702
  store i64 %21729, i64* %RCX.i1692, align 8
  %21730 = icmp ult i64 %21729, %21702
  %21731 = icmp ult i64 %21729, %21728
  %21732 = or i1 %21730, %21731
  %21733 = zext i1 %21732 to i8
  store i8 %21733, i8* %18, align 1
  %21734 = trunc i64 %21729 to i32
  %21735 = and i32 %21734, 255
  %21736 = tail call i32 @llvm.ctpop.i32(i32 %21735)
  %21737 = trunc i32 %21736 to i8
  %21738 = and i8 %21737, 1
  %21739 = xor i8 %21738, 1
  store i8 %21739, i8* %19, align 1
  %21740 = xor i64 %21702, %21729
  %21741 = lshr i64 %21740, 4
  %21742 = trunc i64 %21741 to i8
  %21743 = and i8 %21742, 1
  store i8 %21743, i8* %20, align 1
  %21744 = icmp eq i64 %21729, 0
  %21745 = zext i1 %21744 to i8
  store i8 %21745, i8* %21, align 1
  %21746 = lshr i64 %21729, 63
  %21747 = trunc i64 %21746 to i8
  store i8 %21747, i8* %22, align 1
  %21748 = lshr i64 %21727, 54
  %21749 = and i64 %21748, 1
  %21750 = xor i64 %21746, %21717
  %21751 = xor i64 %21746, %21749
  %21752 = add nuw nsw i64 %21750, %21751
  %21753 = icmp eq i64 %21752, 2
  %21754 = zext i1 %21753 to i8
  store i8 %21754, i8* %23, align 1
  %21755 = load i64, i64* %RBP.i, align 8
  %21756 = add i64 %21755, -484
  %21757 = add i64 %21686, 48
  store i64 %21757, i64* %3, align 8
  %21758 = inttoptr i64 %21756 to i32*
  %21759 = load i32, i32* %21758, align 4
  %21760 = zext i32 %21759 to i64
  store i64 %21760, i64* %RSI.i1889, align 8
  %21761 = add i64 %21755, -44
  %21762 = add i64 %21686, 51
  store i64 %21762, i64* %3, align 8
  %21763 = inttoptr i64 %21761 to i32*
  %21764 = load i32, i32* %21763, align 4
  %21765 = add i32 %21764, %21759
  %21766 = zext i32 %21765 to i64
  store i64 %21766, i64* %RSI.i1889, align 8
  %21767 = sext i32 %21765 to i64
  %21768 = shl nsw i64 %21767, 5
  store i64 %21768, i64* %RDX.i1805, align 8
  %21769 = load i64, i64* %RCX.i1692, align 8
  %21770 = add i64 %21768, %21769
  store i64 %21770, i64* %RCX.i1692, align 8
  %21771 = icmp ult i64 %21770, %21769
  %21772 = icmp ult i64 %21770, %21768
  %21773 = or i1 %21771, %21772
  %21774 = zext i1 %21773 to i8
  store i8 %21774, i8* %18, align 1
  %21775 = trunc i64 %21770 to i32
  %21776 = and i32 %21775, 255
  %21777 = tail call i32 @llvm.ctpop.i32(i32 %21776)
  %21778 = trunc i32 %21777 to i8
  %21779 = and i8 %21778, 1
  %21780 = xor i8 %21779, 1
  store i8 %21780, i8* %19, align 1
  %21781 = xor i64 %21769, %21770
  %21782 = lshr i64 %21781, 4
  %21783 = trunc i64 %21782 to i8
  %21784 = and i8 %21783, 1
  store i8 %21784, i8* %20, align 1
  %21785 = icmp eq i64 %21770, 0
  %21786 = zext i1 %21785 to i8
  store i8 %21786, i8* %21, align 1
  %21787 = lshr i64 %21770, 63
  %21788 = trunc i64 %21787 to i8
  store i8 %21788, i8* %22, align 1
  %21789 = lshr i64 %21769, 63
  %21790 = lshr i64 %21767, 58
  %21791 = and i64 %21790, 1
  %21792 = xor i64 %21787, %21789
  %21793 = xor i64 %21787, %21791
  %21794 = add nuw nsw i64 %21792, %21793
  %21795 = icmp eq i64 %21794, 2
  %21796 = zext i1 %21795 to i8
  store i8 %21796, i8* %23, align 1
  %21797 = load i64, i64* %RBP.i, align 8
  %21798 = add i64 %21797, -488
  %21799 = add i64 %21686, 67
  store i64 %21799, i64* %3, align 8
  %21800 = inttoptr i64 %21798 to i32*
  %21801 = load i32, i32* %21800, align 4
  %21802 = zext i32 %21801 to i64
  store i64 %21802, i64* %RSI.i1889, align 8
  %21803 = add i64 %21797, -48
  %21804 = add i64 %21686, 70
  store i64 %21804, i64* %3, align 8
  %21805 = inttoptr i64 %21803 to i32*
  %21806 = load i32, i32* %21805, align 4
  %21807 = add i32 %21806, %21801
  %21808 = zext i32 %21807 to i64
  store i64 %21808, i64* %RSI.i1889, align 8
  %21809 = icmp ult i32 %21807, %21801
  %21810 = icmp ult i32 %21807, %21806
  %21811 = or i1 %21809, %21810
  %21812 = zext i1 %21811 to i8
  store i8 %21812, i8* %18, align 1
  %21813 = and i32 %21807, 255
  %21814 = tail call i32 @llvm.ctpop.i32(i32 %21813)
  %21815 = trunc i32 %21814 to i8
  %21816 = and i8 %21815, 1
  %21817 = xor i8 %21816, 1
  store i8 %21817, i8* %19, align 1
  %21818 = xor i32 %21806, %21801
  %21819 = xor i32 %21818, %21807
  %21820 = lshr i32 %21819, 4
  %21821 = trunc i32 %21820 to i8
  %21822 = and i8 %21821, 1
  store i8 %21822, i8* %20, align 1
  %21823 = icmp eq i32 %21807, 0
  %21824 = zext i1 %21823 to i8
  store i8 %21824, i8* %21, align 1
  %21825 = lshr i32 %21807, 31
  %21826 = trunc i32 %21825 to i8
  store i8 %21826, i8* %22, align 1
  %21827 = lshr i32 %21801, 31
  %21828 = lshr i32 %21806, 31
  %21829 = xor i32 %21825, %21827
  %21830 = xor i32 %21825, %21828
  %21831 = add nuw nsw i32 %21829, %21830
  %21832 = icmp eq i32 %21831, 2
  %21833 = zext i1 %21832 to i8
  store i8 %21833, i8* %23, align 1
  %21834 = sext i32 %21807 to i64
  store i64 %21834, i64* %RDX.i1805, align 8
  %21835 = shl nsw i64 %21834, 1
  %21836 = add i64 %21770, %21835
  %21837 = add i64 %21686, 77
  store i64 %21837, i64* %3, align 8
  %21838 = inttoptr i64 %21836 to i16*
  %21839 = load i16, i16* %21838, align 2
  %21840 = zext i16 %21839 to i64
  store i64 %21840, i64* %RSI.i1889, align 8
  %21841 = load i64, i64* %RAX.i1763, align 8
  %21842 = zext i16 %21839 to i32
  %21843 = zext i16 %21839 to i64
  %21844 = trunc i64 %21841 to i32
  %21845 = add i32 %21842, %21844
  %21846 = zext i32 %21845 to i64
  store i64 %21846, i64* %RAX.i1763, align 8
  %21847 = icmp ult i32 %21845, %21844
  %21848 = icmp ult i32 %21845, %21842
  %21849 = or i1 %21847, %21848
  %21850 = zext i1 %21849 to i8
  store i8 %21850, i8* %18, align 1
  %21851 = and i32 %21845, 255
  %21852 = tail call i32 @llvm.ctpop.i32(i32 %21851)
  %21853 = trunc i32 %21852 to i8
  %21854 = and i8 %21853, 1
  %21855 = xor i8 %21854, 1
  store i8 %21855, i8* %19, align 1
  %21856 = xor i64 %21843, %21841
  %21857 = trunc i64 %21856 to i32
  %21858 = xor i32 %21857, %21845
  %21859 = lshr i32 %21858, 4
  %21860 = trunc i32 %21859 to i8
  %21861 = and i8 %21860, 1
  store i8 %21861, i8* %20, align 1
  %21862 = icmp eq i32 %21845, 0
  %21863 = zext i1 %21862 to i8
  store i8 %21863, i8* %21, align 1
  %21864 = lshr i32 %21845, 31
  %21865 = trunc i32 %21864 to i8
  store i8 %21865, i8* %22, align 1
  %21866 = lshr i32 %21844, 31
  %21867 = xor i32 %21864, %21866
  %21868 = add nuw nsw i32 %21867, %21864
  %21869 = icmp eq i32 %21868, 2
  %21870 = zext i1 %21869 to i8
  store i8 %21870, i8* %23, align 1
  %21871 = add i64 %21797, -1472
  %21872 = add i64 %21686, 85
  store i64 %21872, i64* %3, align 8
  %21873 = inttoptr i64 %21871 to i32*
  store i32 %21845, i32* %21873, align 4
  %.pre551 = load i64, i64* %3, align 8
  br label %block_.L_4a706b

block_.L_4a706b:                                  ; preds = %block_.L_4a7016, %block_4a7009
  %21874 = phi i64 [ %.pre551, %block_.L_4a7016 ], [ %21692, %block_4a7009 ]
  %21875 = load i64, i64* %RBP.i, align 8
  %21876 = add i64 %21875, -1472
  %21877 = add i64 %21874, 6
  store i64 %21877, i64* %3, align 8
  %21878 = inttoptr i64 %21876 to i32*
  %21879 = load i32, i32* %21878, align 4
  %21880 = zext i32 %21879 to i64
  store i64 %21880, i64* %RAX.i1763, align 8
  %21881 = add i64 %21875, -1468
  %21882 = add i64 %21874, 12
  store i64 %21882, i64* %3, align 8
  %21883 = inttoptr i64 %21881 to i32*
  %21884 = load i32, i32* %21883, align 4
  %21885 = zext i32 %21884 to i64
  store i64 %21885, i64* %RCX.i1692, align 8
  %21886 = sub i32 %21884, %21879
  %21887 = icmp ult i32 %21884, %21879
  %21888 = zext i1 %21887 to i8
  store i8 %21888, i8* %18, align 1
  %21889 = and i32 %21886, 255
  %21890 = tail call i32 @llvm.ctpop.i32(i32 %21889)
  %21891 = trunc i32 %21890 to i8
  %21892 = and i8 %21891, 1
  %21893 = xor i8 %21892, 1
  store i8 %21893, i8* %19, align 1
  %21894 = xor i32 %21879, %21884
  %21895 = xor i32 %21894, %21886
  %21896 = lshr i32 %21895, 4
  %21897 = trunc i32 %21896 to i8
  %21898 = and i8 %21897, 1
  store i8 %21898, i8* %20, align 1
  %21899 = icmp eq i32 %21886, 0
  %21900 = zext i1 %21899 to i8
  store i8 %21900, i8* %21, align 1
  %21901 = lshr i32 %21886, 31
  %21902 = trunc i32 %21901 to i8
  store i8 %21902, i8* %22, align 1
  %21903 = lshr i32 %21884, 31
  %21904 = lshr i32 %21879, 31
  %21905 = xor i32 %21904, %21903
  %21906 = xor i32 %21901, %21903
  %21907 = add nuw nsw i32 %21906, %21905
  %21908 = icmp eq i32 %21907, 2
  %21909 = zext i1 %21908 to i8
  store i8 %21909, i8* %23, align 1
  %21910 = icmp ne i8 %21902, 0
  %21911 = xor i1 %21910, %21908
  %.v832 = select i1 %21911, i64 20, i64 45
  %21912 = add i64 %21874, %.v832
  store i64 %21912, i64* %3, align 8
  br i1 %21911, label %block_4a707f, label %block_.L_4a7098

block_4a707f:                                     ; preds = %block_.L_4a706b
  %21913 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %21913, i64* %RAX.i1763, align 8
  %21914 = add i64 %21913, 72688
  %21915 = add i64 %21912, 14
  store i64 %21915, i64* %3, align 8
  %21916 = inttoptr i64 %21914 to i32*
  %21917 = load i32, i32* %21916, align 4
  %21918 = zext i32 %21917 to i64
  store i64 %21918, i64* %RCX.i1692, align 8
  %21919 = add i64 %21875, -1476
  %21920 = add i64 %21912, 20
  store i64 %21920, i64* %3, align 8
  %21921 = inttoptr i64 %21919 to i32*
  store i32 %21917, i32* %21921, align 4
  %21922 = load i64, i64* %3, align 8
  %21923 = add i64 %21922, 204
  store i64 %21923, i64* %3, align 8
  br label %block_.L_4a715f

block_.L_4a7098:                                  ; preds = %block_.L_4a706b
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %21924 = add i64 %21875, -604
  %21925 = add i64 %21912, 8
  store i64 %21925, i64* %3, align 8
  %21926 = inttoptr i64 %21924 to i32*
  %21927 = load i32, i32* %21926, align 4
  %21928 = zext i32 %21927 to i64
  store i64 %21928, i64* %RCX.i1692, align 8
  %21929 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %21930 = add i64 %21929, 8504
  %21931 = lshr i64 %21930, 63
  %21932 = add i64 %21929, 10552
  store i64 %21932, i64* %RDX.i1805, align 8
  %21933 = icmp ugt i64 %21930, -2049
  %21934 = zext i1 %21933 to i8
  store i8 %21934, i8* %18, align 1
  %21935 = trunc i64 %21932 to i32
  %21936 = and i32 %21935, 255
  %21937 = tail call i32 @llvm.ctpop.i32(i32 %21936)
  %21938 = trunc i32 %21937 to i8
  %21939 = and i8 %21938, 1
  %21940 = xor i8 %21939, 1
  store i8 %21940, i8* %19, align 1
  %21941 = xor i64 %21932, %21930
  %21942 = lshr i64 %21941, 4
  %21943 = trunc i64 %21942 to i8
  %21944 = and i8 %21943, 1
  store i8 %21944, i8* %20, align 1
  %21945 = icmp eq i64 %21932, 0
  %21946 = zext i1 %21945 to i8
  store i8 %21946, i8* %21, align 1
  %21947 = lshr i64 %21932, 63
  %21948 = trunc i64 %21947 to i8
  store i8 %21948, i8* %22, align 1
  %21949 = xor i64 %21947, %21931
  %21950 = add nuw nsw i64 %21949, %21947
  %21951 = icmp eq i64 %21950, 2
  %21952 = zext i1 %21951 to i8
  store i8 %21952, i8* %23, align 1
  %21953 = add i64 %21875, -632
  %21954 = add i64 %21912, 37
  store i64 %21954, i64* %3, align 8
  %21955 = inttoptr i64 %21953 to i32*
  %21956 = load i32, i32* %21955, align 4
  %21957 = sext i32 %21956 to i64
  %21958 = shl nsw i64 %21957, 9
  store i64 %21958, i64* %RSI.i1889, align 8
  %21959 = add i64 %21958, %21932
  store i64 %21959, i64* %RDX.i1805, align 8
  %21960 = icmp ult i64 %21959, %21932
  %21961 = icmp ult i64 %21959, %21958
  %21962 = or i1 %21960, %21961
  %21963 = zext i1 %21962 to i8
  store i8 %21963, i8* %18, align 1
  %21964 = trunc i64 %21959 to i32
  %21965 = and i32 %21964, 255
  %21966 = tail call i32 @llvm.ctpop.i32(i32 %21965)
  %21967 = trunc i32 %21966 to i8
  %21968 = and i8 %21967, 1
  %21969 = xor i8 %21968, 1
  store i8 %21969, i8* %19, align 1
  %21970 = xor i64 %21932, %21959
  %21971 = lshr i64 %21970, 4
  %21972 = trunc i64 %21971 to i8
  %21973 = and i8 %21972, 1
  store i8 %21973, i8* %20, align 1
  %21974 = icmp eq i64 %21959, 0
  %21975 = zext i1 %21974 to i8
  store i8 %21975, i8* %21, align 1
  %21976 = lshr i64 %21959, 63
  %21977 = trunc i64 %21976 to i8
  store i8 %21977, i8* %22, align 1
  %21978 = lshr i64 %21957, 54
  %21979 = and i64 %21978, 1
  %21980 = xor i64 %21976, %21947
  %21981 = xor i64 %21976, %21979
  %21982 = add nuw nsw i64 %21980, %21981
  %21983 = icmp eq i64 %21982, 2
  %21984 = zext i1 %21983 to i8
  store i8 %21984, i8* %23, align 1
  %21985 = load i64, i64* %RBP.i, align 8
  %21986 = add i64 %21985, -484
  %21987 = add i64 %21912, 50
  store i64 %21987, i64* %3, align 8
  %21988 = inttoptr i64 %21986 to i32*
  %21989 = load i32, i32* %21988, align 4
  %21990 = zext i32 %21989 to i64
  store i64 %21990, i64* %RDI.i2141, align 8
  %21991 = add i64 %21985, -44
  %21992 = add i64 %21912, 53
  store i64 %21992, i64* %3, align 8
  %21993 = inttoptr i64 %21991 to i32*
  %21994 = load i32, i32* %21993, align 4
  %21995 = add i32 %21994, %21989
  %21996 = zext i32 %21995 to i64
  store i64 %21996, i64* %RDI.i2141, align 8
  %21997 = sext i32 %21995 to i64
  %21998 = shl nsw i64 %21997, 5
  store i64 %21998, i64* %RSI.i1889, align 8
  %21999 = load i64, i64* %RDX.i1805, align 8
  %22000 = add i64 %21998, %21999
  store i64 %22000, i64* %RDX.i1805, align 8
  %22001 = icmp ult i64 %22000, %21999
  %22002 = icmp ult i64 %22000, %21998
  %22003 = or i1 %22001, %22002
  %22004 = zext i1 %22003 to i8
  store i8 %22004, i8* %18, align 1
  %22005 = trunc i64 %22000 to i32
  %22006 = and i32 %22005, 255
  %22007 = tail call i32 @llvm.ctpop.i32(i32 %22006)
  %22008 = trunc i32 %22007 to i8
  %22009 = and i8 %22008, 1
  %22010 = xor i8 %22009, 1
  store i8 %22010, i8* %19, align 1
  %22011 = xor i64 %21999, %22000
  %22012 = lshr i64 %22011, 4
  %22013 = trunc i64 %22012 to i8
  %22014 = and i8 %22013, 1
  store i8 %22014, i8* %20, align 1
  %22015 = icmp eq i64 %22000, 0
  %22016 = zext i1 %22015 to i8
  store i8 %22016, i8* %21, align 1
  %22017 = lshr i64 %22000, 63
  %22018 = trunc i64 %22017 to i8
  store i8 %22018, i8* %22, align 1
  %22019 = lshr i64 %21999, 63
  %22020 = lshr i64 %21997, 58
  %22021 = and i64 %22020, 1
  %22022 = xor i64 %22017, %22019
  %22023 = xor i64 %22017, %22021
  %22024 = add nuw nsw i64 %22022, %22023
  %22025 = icmp eq i64 %22024, 2
  %22026 = zext i1 %22025 to i8
  store i8 %22026, i8* %23, align 1
  %22027 = load i64, i64* %RBP.i, align 8
  %22028 = add i64 %22027, -488
  %22029 = add i64 %21912, 69
  store i64 %22029, i64* %3, align 8
  %22030 = inttoptr i64 %22028 to i32*
  %22031 = load i32, i32* %22030, align 4
  %22032 = zext i32 %22031 to i64
  store i64 %22032, i64* %RDI.i2141, align 8
  %22033 = add i64 %22027, -48
  %22034 = add i64 %21912, 72
  store i64 %22034, i64* %3, align 8
  %22035 = inttoptr i64 %22033 to i32*
  %22036 = load i32, i32* %22035, align 4
  %22037 = add i32 %22036, %22031
  %22038 = zext i32 %22037 to i64
  store i64 %22038, i64* %RDI.i2141, align 8
  %22039 = icmp ult i32 %22037, %22031
  %22040 = icmp ult i32 %22037, %22036
  %22041 = or i1 %22039, %22040
  %22042 = zext i1 %22041 to i8
  store i8 %22042, i8* %18, align 1
  %22043 = and i32 %22037, 255
  %22044 = tail call i32 @llvm.ctpop.i32(i32 %22043)
  %22045 = trunc i32 %22044 to i8
  %22046 = and i8 %22045, 1
  %22047 = xor i8 %22046, 1
  store i8 %22047, i8* %19, align 1
  %22048 = xor i32 %22036, %22031
  %22049 = xor i32 %22048, %22037
  %22050 = lshr i32 %22049, 4
  %22051 = trunc i32 %22050 to i8
  %22052 = and i8 %22051, 1
  store i8 %22052, i8* %20, align 1
  %22053 = icmp eq i32 %22037, 0
  %22054 = zext i1 %22053 to i8
  store i8 %22054, i8* %21, align 1
  %22055 = lshr i32 %22037, 31
  %22056 = trunc i32 %22055 to i8
  store i8 %22056, i8* %22, align 1
  %22057 = lshr i32 %22031, 31
  %22058 = lshr i32 %22036, 31
  %22059 = xor i32 %22055, %22057
  %22060 = xor i32 %22055, %22058
  %22061 = add nuw nsw i32 %22059, %22060
  %22062 = icmp eq i32 %22061, 2
  %22063 = zext i1 %22062 to i8
  store i8 %22063, i8* %23, align 1
  %22064 = sext i32 %22037 to i64
  store i64 %22064, i64* %RSI.i1889, align 8
  %22065 = shl nsw i64 %22064, 1
  %22066 = add i64 %22000, %22065
  %22067 = add i64 %21912, 79
  store i64 %22067, i64* %3, align 8
  %22068 = inttoptr i64 %22066 to i16*
  %22069 = load i16, i16* %22068, align 2
  %22070 = zext i16 %22069 to i64
  store i64 %22070, i64* %RDI.i2141, align 8
  %22071 = load i64, i64* %RCX.i1692, align 8
  %22072 = zext i16 %22069 to i32
  %22073 = trunc i64 %22071 to i32
  %22074 = add i32 %22072, %22073
  %22075 = zext i32 %22074 to i64
  store i64 %22075, i64* %RCX.i1692, align 8
  %22076 = lshr i32 %22074, 31
  %22077 = load i32, i32* %EAX.i2159, align 4
  %22078 = sub i32 %22077, %22074
  %22079 = icmp ult i32 %22077, %22074
  %22080 = zext i1 %22079 to i8
  store i8 %22080, i8* %18, align 1
  %22081 = and i32 %22078, 255
  %22082 = tail call i32 @llvm.ctpop.i32(i32 %22081)
  %22083 = trunc i32 %22082 to i8
  %22084 = and i8 %22083, 1
  %22085 = xor i8 %22084, 1
  store i8 %22085, i8* %19, align 1
  %22086 = xor i32 %22074, %22077
  %22087 = xor i32 %22086, %22078
  %22088 = lshr i32 %22087, 4
  %22089 = trunc i32 %22088 to i8
  %22090 = and i8 %22089, 1
  store i8 %22090, i8* %20, align 1
  %22091 = icmp eq i32 %22078, 0
  %22092 = zext i1 %22091 to i8
  store i8 %22092, i8* %21, align 1
  %22093 = lshr i32 %22078, 31
  %22094 = trunc i32 %22093 to i8
  store i8 %22094, i8* %22, align 1
  %22095 = lshr i32 %22077, 31
  %22096 = xor i32 %22076, %22095
  %22097 = xor i32 %22093, %22095
  %22098 = add nuw nsw i32 %22097, %22096
  %22099 = icmp eq i32 %22098, 2
  %22100 = zext i1 %22099 to i8
  store i8 %22100, i8* %23, align 1
  %22101 = icmp ne i8 %22094, 0
  %22102 = xor i1 %22101, %22099
  %22103 = or i1 %22091, %22102
  %.v833 = select i1 %22103, i64 102, i64 89
  %22104 = add i64 %21912, %.v833
  store i64 %22104, i64* %3, align 8
  br i1 %22103, label %block_.L_4a70fe, label %block_4a70f1

block_4a70f1:                                     ; preds = %block_.L_4a7098
  store i64 0, i64* %RAX.i1763, align 8
  store i8 0, i8* %18, align 1
  store i8 1, i8* %19, align 1
  store i8 1, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  store i8 0, i8* %20, align 1
  %22105 = load i64, i64* %RBP.i, align 8
  %22106 = add i64 %22105, -1480
  %22107 = add i64 %22104, 8
  store i64 %22107, i64* %3, align 8
  %22108 = inttoptr i64 %22106 to i32*
  store i32 0, i32* %22108, align 4
  %22109 = load i64, i64* %3, align 8
  %22110 = add i64 %22109, 90
  store i64 %22110, i64* %3, align 8
  br label %block_.L_4a7153

block_.L_4a70fe:                                  ; preds = %block_.L_4a7098
  %22111 = load i64, i64* %RBP.i, align 8
  %22112 = add i64 %22111, -604
  %22113 = add i64 %22104, 6
  store i64 %22113, i64* %3, align 8
  %22114 = inttoptr i64 %22112 to i32*
  %22115 = load i32, i32* %22114, align 4
  %22116 = zext i32 %22115 to i64
  store i64 %22116, i64* %RAX.i1763, align 8
  %22117 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %22118 = add i64 %22117, 8504
  %22119 = lshr i64 %22118, 63
  %22120 = add i64 %22117, 10552
  store i64 %22120, i64* %RCX.i1692, align 8
  %22121 = icmp ugt i64 %22118, -2049
  %22122 = zext i1 %22121 to i8
  store i8 %22122, i8* %18, align 1
  %22123 = trunc i64 %22120 to i32
  %22124 = and i32 %22123, 255
  %22125 = tail call i32 @llvm.ctpop.i32(i32 %22124)
  %22126 = trunc i32 %22125 to i8
  %22127 = and i8 %22126, 1
  %22128 = xor i8 %22127, 1
  store i8 %22128, i8* %19, align 1
  %22129 = xor i64 %22120, %22118
  %22130 = lshr i64 %22129, 4
  %22131 = trunc i64 %22130 to i8
  %22132 = and i8 %22131, 1
  store i8 %22132, i8* %20, align 1
  %22133 = icmp eq i64 %22120, 0
  %22134 = zext i1 %22133 to i8
  store i8 %22134, i8* %21, align 1
  %22135 = lshr i64 %22120, 63
  %22136 = trunc i64 %22135 to i8
  store i8 %22136, i8* %22, align 1
  %22137 = xor i64 %22135, %22119
  %22138 = add nuw nsw i64 %22137, %22135
  %22139 = icmp eq i64 %22138, 2
  %22140 = zext i1 %22139 to i8
  store i8 %22140, i8* %23, align 1
  %22141 = add i64 %22111, -632
  %22142 = add i64 %22104, 35
  store i64 %22142, i64* %3, align 8
  %22143 = inttoptr i64 %22141 to i32*
  %22144 = load i32, i32* %22143, align 4
  %22145 = sext i32 %22144 to i64
  %22146 = shl nsw i64 %22145, 9
  store i64 %22146, i64* %RDX.i1805, align 8
  %22147 = add i64 %22146, %22120
  store i64 %22147, i64* %RCX.i1692, align 8
  %22148 = icmp ult i64 %22147, %22120
  %22149 = icmp ult i64 %22147, %22146
  %22150 = or i1 %22148, %22149
  %22151 = zext i1 %22150 to i8
  store i8 %22151, i8* %18, align 1
  %22152 = trunc i64 %22147 to i32
  %22153 = and i32 %22152, 255
  %22154 = tail call i32 @llvm.ctpop.i32(i32 %22153)
  %22155 = trunc i32 %22154 to i8
  %22156 = and i8 %22155, 1
  %22157 = xor i8 %22156, 1
  store i8 %22157, i8* %19, align 1
  %22158 = xor i64 %22120, %22147
  %22159 = lshr i64 %22158, 4
  %22160 = trunc i64 %22159 to i8
  %22161 = and i8 %22160, 1
  store i8 %22161, i8* %20, align 1
  %22162 = icmp eq i64 %22147, 0
  %22163 = zext i1 %22162 to i8
  store i8 %22163, i8* %21, align 1
  %22164 = lshr i64 %22147, 63
  %22165 = trunc i64 %22164 to i8
  store i8 %22165, i8* %22, align 1
  %22166 = lshr i64 %22145, 54
  %22167 = and i64 %22166, 1
  %22168 = xor i64 %22164, %22135
  %22169 = xor i64 %22164, %22167
  %22170 = add nuw nsw i64 %22168, %22169
  %22171 = icmp eq i64 %22170, 2
  %22172 = zext i1 %22171 to i8
  store i8 %22172, i8* %23, align 1
  %22173 = load i64, i64* %RBP.i, align 8
  %22174 = add i64 %22173, -484
  %22175 = add i64 %22104, 48
  store i64 %22175, i64* %3, align 8
  %22176 = inttoptr i64 %22174 to i32*
  %22177 = load i32, i32* %22176, align 4
  %22178 = zext i32 %22177 to i64
  store i64 %22178, i64* %RSI.i1889, align 8
  %22179 = add i64 %22173, -44
  %22180 = add i64 %22104, 51
  store i64 %22180, i64* %3, align 8
  %22181 = inttoptr i64 %22179 to i32*
  %22182 = load i32, i32* %22181, align 4
  %22183 = add i32 %22182, %22177
  %22184 = zext i32 %22183 to i64
  store i64 %22184, i64* %RSI.i1889, align 8
  %22185 = sext i32 %22183 to i64
  %22186 = shl nsw i64 %22185, 5
  store i64 %22186, i64* %RDX.i1805, align 8
  %22187 = load i64, i64* %RCX.i1692, align 8
  %22188 = add i64 %22186, %22187
  store i64 %22188, i64* %RCX.i1692, align 8
  %22189 = icmp ult i64 %22188, %22187
  %22190 = icmp ult i64 %22188, %22186
  %22191 = or i1 %22189, %22190
  %22192 = zext i1 %22191 to i8
  store i8 %22192, i8* %18, align 1
  %22193 = trunc i64 %22188 to i32
  %22194 = and i32 %22193, 255
  %22195 = tail call i32 @llvm.ctpop.i32(i32 %22194)
  %22196 = trunc i32 %22195 to i8
  %22197 = and i8 %22196, 1
  %22198 = xor i8 %22197, 1
  store i8 %22198, i8* %19, align 1
  %22199 = xor i64 %22187, %22188
  %22200 = lshr i64 %22199, 4
  %22201 = trunc i64 %22200 to i8
  %22202 = and i8 %22201, 1
  store i8 %22202, i8* %20, align 1
  %22203 = icmp eq i64 %22188, 0
  %22204 = zext i1 %22203 to i8
  store i8 %22204, i8* %21, align 1
  %22205 = lshr i64 %22188, 63
  %22206 = trunc i64 %22205 to i8
  store i8 %22206, i8* %22, align 1
  %22207 = lshr i64 %22187, 63
  %22208 = lshr i64 %22185, 58
  %22209 = and i64 %22208, 1
  %22210 = xor i64 %22205, %22207
  %22211 = xor i64 %22205, %22209
  %22212 = add nuw nsw i64 %22210, %22211
  %22213 = icmp eq i64 %22212, 2
  %22214 = zext i1 %22213 to i8
  store i8 %22214, i8* %23, align 1
  %22215 = load i64, i64* %RBP.i, align 8
  %22216 = add i64 %22215, -488
  %22217 = add i64 %22104, 67
  store i64 %22217, i64* %3, align 8
  %22218 = inttoptr i64 %22216 to i32*
  %22219 = load i32, i32* %22218, align 4
  %22220 = zext i32 %22219 to i64
  store i64 %22220, i64* %RSI.i1889, align 8
  %22221 = add i64 %22215, -48
  %22222 = add i64 %22104, 70
  store i64 %22222, i64* %3, align 8
  %22223 = inttoptr i64 %22221 to i32*
  %22224 = load i32, i32* %22223, align 4
  %22225 = add i32 %22224, %22219
  %22226 = zext i32 %22225 to i64
  store i64 %22226, i64* %RSI.i1889, align 8
  %22227 = icmp ult i32 %22225, %22219
  %22228 = icmp ult i32 %22225, %22224
  %22229 = or i1 %22227, %22228
  %22230 = zext i1 %22229 to i8
  store i8 %22230, i8* %18, align 1
  %22231 = and i32 %22225, 255
  %22232 = tail call i32 @llvm.ctpop.i32(i32 %22231)
  %22233 = trunc i32 %22232 to i8
  %22234 = and i8 %22233, 1
  %22235 = xor i8 %22234, 1
  store i8 %22235, i8* %19, align 1
  %22236 = xor i32 %22224, %22219
  %22237 = xor i32 %22236, %22225
  %22238 = lshr i32 %22237, 4
  %22239 = trunc i32 %22238 to i8
  %22240 = and i8 %22239, 1
  store i8 %22240, i8* %20, align 1
  %22241 = icmp eq i32 %22225, 0
  %22242 = zext i1 %22241 to i8
  store i8 %22242, i8* %21, align 1
  %22243 = lshr i32 %22225, 31
  %22244 = trunc i32 %22243 to i8
  store i8 %22244, i8* %22, align 1
  %22245 = lshr i32 %22219, 31
  %22246 = lshr i32 %22224, 31
  %22247 = xor i32 %22243, %22245
  %22248 = xor i32 %22243, %22246
  %22249 = add nuw nsw i32 %22247, %22248
  %22250 = icmp eq i32 %22249, 2
  %22251 = zext i1 %22250 to i8
  store i8 %22251, i8* %23, align 1
  %22252 = sext i32 %22225 to i64
  store i64 %22252, i64* %RDX.i1805, align 8
  %22253 = shl nsw i64 %22252, 1
  %22254 = add i64 %22188, %22253
  %22255 = add i64 %22104, 77
  store i64 %22255, i64* %3, align 8
  %22256 = inttoptr i64 %22254 to i16*
  %22257 = load i16, i16* %22256, align 2
  %22258 = zext i16 %22257 to i64
  store i64 %22258, i64* %RSI.i1889, align 8
  %22259 = load i64, i64* %RAX.i1763, align 8
  %22260 = zext i16 %22257 to i32
  %22261 = zext i16 %22257 to i64
  %22262 = trunc i64 %22259 to i32
  %22263 = add i32 %22260, %22262
  %22264 = zext i32 %22263 to i64
  store i64 %22264, i64* %RAX.i1763, align 8
  %22265 = icmp ult i32 %22263, %22262
  %22266 = icmp ult i32 %22263, %22260
  %22267 = or i1 %22265, %22266
  %22268 = zext i1 %22267 to i8
  store i8 %22268, i8* %18, align 1
  %22269 = and i32 %22263, 255
  %22270 = tail call i32 @llvm.ctpop.i32(i32 %22269)
  %22271 = trunc i32 %22270 to i8
  %22272 = and i8 %22271, 1
  %22273 = xor i8 %22272, 1
  store i8 %22273, i8* %19, align 1
  %22274 = xor i64 %22261, %22259
  %22275 = trunc i64 %22274 to i32
  %22276 = xor i32 %22275, %22263
  %22277 = lshr i32 %22276, 4
  %22278 = trunc i32 %22277 to i8
  %22279 = and i8 %22278, 1
  store i8 %22279, i8* %20, align 1
  %22280 = icmp eq i32 %22263, 0
  %22281 = zext i1 %22280 to i8
  store i8 %22281, i8* %21, align 1
  %22282 = lshr i32 %22263, 31
  %22283 = trunc i32 %22282 to i8
  store i8 %22283, i8* %22, align 1
  %22284 = lshr i32 %22262, 31
  %22285 = xor i32 %22282, %22284
  %22286 = add nuw nsw i32 %22285, %22282
  %22287 = icmp eq i32 %22286, 2
  %22288 = zext i1 %22287 to i8
  store i8 %22288, i8* %23, align 1
  %22289 = add i64 %22215, -1480
  %22290 = add i64 %22104, 85
  store i64 %22290, i64* %3, align 8
  %22291 = inttoptr i64 %22289 to i32*
  store i32 %22263, i32* %22291, align 4
  %.pre552 = load i64, i64* %3, align 8
  br label %block_.L_4a7153

block_.L_4a7153:                                  ; preds = %block_.L_4a70fe, %block_4a70f1
  %22292 = phi i64 [ %.pre552, %block_.L_4a70fe ], [ %22110, %block_4a70f1 ]
  %22293 = load i64, i64* %RBP.i, align 8
  %22294 = add i64 %22293, -1480
  %22295 = add i64 %22292, 6
  store i64 %22295, i64* %3, align 8
  %22296 = inttoptr i64 %22294 to i32*
  %22297 = load i32, i32* %22296, align 4
  %22298 = zext i32 %22297 to i64
  store i64 %22298, i64* %RAX.i1763, align 8
  %22299 = add i64 %22293, -1476
  %22300 = add i64 %22292, 12
  store i64 %22300, i64* %3, align 8
  %22301 = inttoptr i64 %22299 to i32*
  store i32 %22297, i32* %22301, align 4
  %.pre553 = load i64, i64* %3, align 8
  br label %block_.L_4a715f

block_.L_4a715f:                                  ; preds = %block_.L_4a7153, %block_4a707f
  %22302 = phi i64 [ %.pre553, %block_.L_4a7153 ], [ %21923, %block_4a707f ]
  %22303 = load i64, i64* %RBP.i, align 8
  %22304 = add i64 %22303, -1476
  %22305 = add i64 %22302, 6
  store i64 %22305, i64* %3, align 8
  %22306 = inttoptr i64 %22304 to i32*
  %22307 = load i32, i32* %22306, align 4
  %22308 = zext i32 %22307 to i64
  store i64 %22308, i64* %RAX.i1763, align 8
  %22309 = trunc i32 %22307 to i16
  store i16 %22309, i16* %CX.i4894, align 2
  %22310 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %22310, i64* %RDX.i1805, align 8
  %22311 = add i64 %22310, 6464
  %22312 = add i64 %22302, 24
  store i64 %22312, i64* %3, align 8
  %22313 = inttoptr i64 %22311 to i64*
  %22314 = load i64, i64* %22313, align 8
  store i64 %22314, i64* %RDX.i1805, align 8
  %22315 = add i64 %22314, 8
  %22316 = add i64 %22302, 28
  store i64 %22316, i64* %3, align 8
  %22317 = inttoptr i64 %22315 to i64*
  %22318 = load i64, i64* %22317, align 8
  store i64 %22318, i64* %RDX.i1805, align 8
  %22319 = add i64 %22303, -496
  %22320 = add i64 %22302, 34
  store i64 %22320, i64* %3, align 8
  %22321 = inttoptr i64 %22319 to i32*
  %22322 = load i32, i32* %22321, align 4
  %22323 = zext i32 %22322 to i64
  store i64 %22323, i64* %RAX.i1763, align 8
  %22324 = add i64 %22303, -48
  %22325 = add i64 %22302, 37
  store i64 %22325, i64* %3, align 8
  %22326 = inttoptr i64 %22324 to i32*
  %22327 = load i32, i32* %22326, align 4
  %22328 = add i32 %22327, %22322
  %22329 = zext i32 %22328 to i64
  store i64 %22329, i64* %RAX.i1763, align 8
  %22330 = icmp ult i32 %22328, %22322
  %22331 = icmp ult i32 %22328, %22327
  %22332 = or i1 %22330, %22331
  %22333 = zext i1 %22332 to i8
  store i8 %22333, i8* %18, align 1
  %22334 = and i32 %22328, 255
  %22335 = tail call i32 @llvm.ctpop.i32(i32 %22334)
  %22336 = trunc i32 %22335 to i8
  %22337 = and i8 %22336, 1
  %22338 = xor i8 %22337, 1
  store i8 %22338, i8* %19, align 1
  %22339 = xor i32 %22327, %22322
  %22340 = xor i32 %22339, %22328
  %22341 = lshr i32 %22340, 4
  %22342 = trunc i32 %22341 to i8
  %22343 = and i8 %22342, 1
  store i8 %22343, i8* %20, align 1
  %22344 = icmp eq i32 %22328, 0
  %22345 = zext i1 %22344 to i8
  store i8 %22345, i8* %21, align 1
  %22346 = lshr i32 %22328, 31
  %22347 = trunc i32 %22346 to i8
  store i8 %22347, i8* %22, align 1
  %22348 = lshr i32 %22322, 31
  %22349 = lshr i32 %22327, 31
  %22350 = xor i32 %22346, %22348
  %22351 = xor i32 %22346, %22349
  %22352 = add nuw nsw i32 %22350, %22351
  %22353 = icmp eq i32 %22352, 2
  %22354 = zext i1 %22353 to i8
  store i8 %22354, i8* %23, align 1
  %22355 = sext i32 %22328 to i64
  store i64 %22355, i64* %RSI.i1889, align 8
  %22356 = shl nsw i64 %22355, 3
  %22357 = add i64 %22318, %22356
  %22358 = add i64 %22302, 44
  store i64 %22358, i64* %3, align 8
  %22359 = inttoptr i64 %22357 to i64*
  %22360 = load i64, i64* %22359, align 8
  store i64 %22360, i64* %RDX.i1805, align 8
  %22361 = add i64 %22303, -492
  %22362 = add i64 %22302, 50
  store i64 %22362, i64* %3, align 8
  %22363 = inttoptr i64 %22361 to i32*
  %22364 = load i32, i32* %22363, align 4
  %22365 = zext i32 %22364 to i64
  store i64 %22365, i64* %RAX.i1763, align 8
  %22366 = add i64 %22303, -44
  %22367 = add i64 %22302, 53
  store i64 %22367, i64* %3, align 8
  %22368 = inttoptr i64 %22366 to i32*
  %22369 = load i32, i32* %22368, align 4
  %22370 = add i32 %22369, %22364
  %22371 = zext i32 %22370 to i64
  store i64 %22371, i64* %RAX.i1763, align 8
  %22372 = icmp ult i32 %22370, %22364
  %22373 = icmp ult i32 %22370, %22369
  %22374 = or i1 %22372, %22373
  %22375 = zext i1 %22374 to i8
  store i8 %22375, i8* %18, align 1
  %22376 = and i32 %22370, 255
  %22377 = tail call i32 @llvm.ctpop.i32(i32 %22376)
  %22378 = trunc i32 %22377 to i8
  %22379 = and i8 %22378, 1
  %22380 = xor i8 %22379, 1
  store i8 %22380, i8* %19, align 1
  %22381 = xor i32 %22369, %22364
  %22382 = xor i32 %22381, %22370
  %22383 = lshr i32 %22382, 4
  %22384 = trunc i32 %22383 to i8
  %22385 = and i8 %22384, 1
  store i8 %22385, i8* %20, align 1
  %22386 = icmp eq i32 %22370, 0
  %22387 = zext i1 %22386 to i8
  store i8 %22387, i8* %21, align 1
  %22388 = lshr i32 %22370, 31
  %22389 = trunc i32 %22388 to i8
  store i8 %22389, i8* %22, align 1
  %22390 = lshr i32 %22364, 31
  %22391 = lshr i32 %22369, 31
  %22392 = xor i32 %22388, %22390
  %22393 = xor i32 %22388, %22391
  %22394 = add nuw nsw i32 %22392, %22393
  %22395 = icmp eq i32 %22394, 2
  %22396 = zext i1 %22395 to i8
  store i8 %22396, i8* %23, align 1
  %22397 = sext i32 %22370 to i64
  store i64 %22397, i64* %RSI.i1889, align 8
  %22398 = shl nsw i64 %22397, 1
  %22399 = add i64 %22360, %22398
  %22400 = load i16, i16* %CX.i4894, align 2
  %22401 = add i64 %22302, 60
  store i64 %22401, i64* %3, align 8
  %22402 = inttoptr i64 %22399 to i16*
  store i16 %22400, i16* %22402, align 2
  %22403 = load i64, i64* %RBP.i, align 8
  %22404 = add i64 %22403, -44
  %22405 = load i64, i64* %3, align 8
  %22406 = add i64 %22405, 3
  store i64 %22406, i64* %3, align 8
  %22407 = inttoptr i64 %22404 to i32*
  %22408 = load i32, i32* %22407, align 4
  %22409 = add i32 %22408, 1
  %22410 = zext i32 %22409 to i64
  store i64 %22410, i64* %RAX.i1763, align 8
  %22411 = icmp eq i32 %22408, -1
  %22412 = icmp eq i32 %22409, 0
  %22413 = or i1 %22411, %22412
  %22414 = zext i1 %22413 to i8
  store i8 %22414, i8* %18, align 1
  %22415 = and i32 %22409, 255
  %22416 = tail call i32 @llvm.ctpop.i32(i32 %22415)
  %22417 = trunc i32 %22416 to i8
  %22418 = and i8 %22417, 1
  %22419 = xor i8 %22418, 1
  store i8 %22419, i8* %19, align 1
  %22420 = xor i32 %22409, %22408
  %22421 = lshr i32 %22420, 4
  %22422 = trunc i32 %22421 to i8
  %22423 = and i8 %22422, 1
  store i8 %22423, i8* %20, align 1
  %22424 = zext i1 %22412 to i8
  store i8 %22424, i8* %21, align 1
  %22425 = lshr i32 %22409, 31
  %22426 = trunc i32 %22425 to i8
  store i8 %22426, i8* %22, align 1
  %22427 = lshr i32 %22408, 31
  %22428 = xor i32 %22425, %22427
  %22429 = add nuw nsw i32 %22428, %22425
  %22430 = icmp eq i32 %22429, 2
  %22431 = zext i1 %22430 to i8
  store i8 %22431, i8* %23, align 1
  %22432 = add i64 %22405, 9
  store i64 %22432, i64* %3, align 8
  store i32 %22409, i32* %22407, align 4
  %22433 = load i64, i64* %3, align 8
  %22434 = add i64 %22433, -1631
  store i64 %22434, i64* %3, align 8
  br label %block_.L_4a6b45

block_.L_4a71a9:                                  ; preds = %block_.L_4a6b45
  %22435 = add i64 %19422, -48
  %22436 = add i64 %19450, 8
  store i64 %22436, i64* %3, align 8
  %22437 = inttoptr i64 %22435 to i32*
  %22438 = load i32, i32* %22437, align 4
  %22439 = add i32 %22438, 1
  %22440 = zext i32 %22439 to i64
  store i64 %22440, i64* %RAX.i1763, align 8
  %22441 = icmp eq i32 %22438, -1
  %22442 = icmp eq i32 %22439, 0
  %22443 = or i1 %22441, %22442
  %22444 = zext i1 %22443 to i8
  store i8 %22444, i8* %18, align 1
  %22445 = and i32 %22439, 255
  %22446 = tail call i32 @llvm.ctpop.i32(i32 %22445)
  %22447 = trunc i32 %22446 to i8
  %22448 = and i8 %22447, 1
  %22449 = xor i8 %22448, 1
  store i8 %22449, i8* %19, align 1
  %22450 = xor i32 %22439, %22438
  %22451 = lshr i32 %22450, 4
  %22452 = trunc i32 %22451 to i8
  %22453 = and i8 %22452, 1
  store i8 %22453, i8* %20, align 1
  %22454 = zext i1 %22442 to i8
  store i8 %22454, i8* %21, align 1
  %22455 = lshr i32 %22439, 31
  %22456 = trunc i32 %22455 to i8
  store i8 %22456, i8* %22, align 1
  %22457 = lshr i32 %22438, 31
  %22458 = xor i32 %22455, %22457
  %22459 = add nuw nsw i32 %22458, %22455
  %22460 = icmp eq i32 %22459, 2
  %22461 = zext i1 %22460 to i8
  store i8 %22461, i8* %23, align 1
  %22462 = add i64 %19450, 14
  store i64 %22462, i64* %3, align 8
  store i32 %22439, i32* %22437, align 4
  %22463 = load i64, i64* %3, align 8
  %22464 = add i64 %22463, -1667
  store i64 %22464, i64* %3, align 8
  br label %block_.L_4a6b34

block_.L_4a71bc:                                  ; preds = %block_.L_4a6b34
  %22465 = add i64 %19417, 5
  store i64 %22465, i64* %3, align 8
  br label %block_.L_4a71c1

block_.L_4a71c1:                                  ; preds = %block_.L_4a71bc, %block_.L_4a61eb
  %.pre644 = phi i64 [ %.pre644.pre, %block_.L_4a61eb ], [ %19389, %block_.L_4a71bc ]
  %storemerge234 = phi i64 [ %14750, %block_.L_4a61eb ], [ %22465, %block_.L_4a71bc ]
  %MEMORY.103 = phi %struct.Memory* [ %call2_4a61f7, %block_.L_4a61eb ], [ %MEMORY.85, %block_.L_4a71bc ]
  %22466 = add i64 %storemerge234, 1197
  br label %block_.L_4a766e

block_.L_4a71c6:                                  ; preds = %block_.L_4a60ac
  %22467 = add i64 %14119, 7
  store i64 %22467, i64* %3, align 8
  store i32 0, i32* %13715, align 4
  %.pre627 = load i64, i64* %3, align 8
  br label %block_.L_4a71cd

block_.L_4a71cd:                                  ; preds = %block_.L_4a726f, %block_.L_4a71c6
  %22468 = phi i64 [ %22734, %block_.L_4a726f ], [ %.pre627, %block_.L_4a71c6 ]
  %22469 = load i64, i64* %RBP.i, align 8
  %22470 = add i64 %22469, -48
  %22471 = add i64 %22468, 4
  store i64 %22471, i64* %3, align 8
  %22472 = inttoptr i64 %22470 to i32*
  %22473 = load i32, i32* %22472, align 4
  %22474 = add i32 %22473, -2
  %22475 = icmp ult i32 %22473, 2
  %22476 = zext i1 %22475 to i8
  store i8 %22476, i8* %18, align 1
  %22477 = and i32 %22474, 255
  %22478 = tail call i32 @llvm.ctpop.i32(i32 %22477)
  %22479 = trunc i32 %22478 to i8
  %22480 = and i8 %22479, 1
  %22481 = xor i8 %22480, 1
  store i8 %22481, i8* %19, align 1
  %22482 = xor i32 %22474, %22473
  %22483 = lshr i32 %22482, 4
  %22484 = trunc i32 %22483 to i8
  %22485 = and i8 %22484, 1
  store i8 %22485, i8* %20, align 1
  %22486 = icmp eq i32 %22474, 0
  %22487 = zext i1 %22486 to i8
  store i8 %22487, i8* %21, align 1
  %22488 = lshr i32 %22474, 31
  %22489 = trunc i32 %22488 to i8
  store i8 %22489, i8* %22, align 1
  %22490 = lshr i32 %22473, 31
  %22491 = xor i32 %22488, %22490
  %22492 = add nuw nsw i32 %22491, %22490
  %22493 = icmp eq i32 %22492, 2
  %22494 = zext i1 %22493 to i8
  store i8 %22494, i8* %23, align 1
  %22495 = icmp ne i8 %22489, 0
  %22496 = xor i1 %22495, %22493
  %.v816 = select i1 %22496, i64 10, i64 181
  %22497 = add i64 %22468, %.v816
  store i64 %22497, i64* %3, align 8
  br i1 %22496, label %block_4a71d7, label %block_.L_4a7282

block_4a71d7:                                     ; preds = %block_.L_4a71cd
  %22498 = add i64 %22469, -44
  %22499 = add i64 %22497, 7
  store i64 %22499, i64* %3, align 8
  %22500 = inttoptr i64 %22498 to i32*
  store i32 0, i32* %22500, align 4
  %.pre646 = load i64, i64* %3, align 8
  br label %block_.L_4a71de

block_.L_4a71de:                                  ; preds = %block_.L_4a725c, %block_4a71d7
  %22501 = phi i64 [ %22704, %block_.L_4a725c ], [ %.pre646, %block_4a71d7 ]
  %22502 = load i64, i64* %RBP.i, align 8
  %22503 = add i64 %22502, -44
  %22504 = add i64 %22501, 4
  store i64 %22504, i64* %3, align 8
  %22505 = inttoptr i64 %22503 to i32*
  %22506 = load i32, i32* %22505, align 4
  %22507 = add i32 %22506, -65
  %22508 = icmp ult i32 %22506, 65
  %22509 = zext i1 %22508 to i8
  store i8 %22509, i8* %18, align 1
  %22510 = and i32 %22507, 255
  %22511 = tail call i32 @llvm.ctpop.i32(i32 %22510)
  %22512 = trunc i32 %22511 to i8
  %22513 = and i8 %22512, 1
  %22514 = xor i8 %22513, 1
  store i8 %22514, i8* %19, align 1
  %22515 = xor i32 %22507, %22506
  %22516 = lshr i32 %22515, 4
  %22517 = trunc i32 %22516 to i8
  %22518 = and i8 %22517, 1
  store i8 %22518, i8* %20, align 1
  %22519 = icmp eq i32 %22507, 0
  %22520 = zext i1 %22519 to i8
  store i8 %22520, i8* %21, align 1
  %22521 = lshr i32 %22507, 31
  %22522 = trunc i32 %22521 to i8
  store i8 %22522, i8* %22, align 1
  %22523 = lshr i32 %22506, 31
  %22524 = xor i32 %22521, %22523
  %22525 = add nuw nsw i32 %22524, %22523
  %22526 = icmp eq i32 %22525, 2
  %22527 = zext i1 %22526 to i8
  store i8 %22527, i8* %23, align 1
  %22528 = icmp ne i8 %22522, 0
  %22529 = xor i1 %22528, %22526
  %.v781 = select i1 %22529, i64 10, i64 145
  %22530 = add i64 %22501, %.v781
  store i64 %22530, i64* %3, align 8
  br i1 %22529, label %block_4a71e8, label %block_.L_4a726f

block_4a71e8:                                     ; preds = %block_.L_4a71de
  %22531 = add i64 %22502, -52
  %22532 = add i64 %22530, 7
  store i64 %22532, i64* %3, align 8
  %22533 = inttoptr i64 %22531 to i32*
  store i32 0, i32* %22533, align 4
  %.pre647 = load i64, i64* %3, align 8
  br label %block_.L_4a71ef

block_.L_4a71ef:                                  ; preds = %block_4a71f9, %block_4a71e8
  %22534 = phi i64 [ %22674, %block_4a71f9 ], [ %.pre647, %block_4a71e8 ]
  %22535 = load i64, i64* %RBP.i, align 8
  %22536 = add i64 %22535, -52
  %22537 = add i64 %22534, 4
  store i64 %22537, i64* %3, align 8
  %22538 = inttoptr i64 %22536 to i32*
  %22539 = load i32, i32* %22538, align 4
  %22540 = add i32 %22539, -4
  %22541 = icmp ult i32 %22539, 4
  %22542 = zext i1 %22541 to i8
  store i8 %22542, i8* %18, align 1
  %22543 = and i32 %22540, 255
  %22544 = tail call i32 @llvm.ctpop.i32(i32 %22543)
  %22545 = trunc i32 %22544 to i8
  %22546 = and i8 %22545, 1
  %22547 = xor i8 %22546, 1
  store i8 %22547, i8* %19, align 1
  %22548 = xor i32 %22540, %22539
  %22549 = lshr i32 %22548, 4
  %22550 = trunc i32 %22549 to i8
  %22551 = and i8 %22550, 1
  store i8 %22551, i8* %20, align 1
  %22552 = icmp eq i32 %22540, 0
  %22553 = zext i1 %22552 to i8
  store i8 %22553, i8* %21, align 1
  %22554 = lshr i32 %22540, 31
  %22555 = trunc i32 %22554 to i8
  store i8 %22555, i8* %22, align 1
  %22556 = lshr i32 %22539, 31
  %22557 = xor i32 %22554, %22556
  %22558 = add nuw nsw i32 %22557, %22556
  %22559 = icmp eq i32 %22558, 2
  %22560 = zext i1 %22559 to i8
  store i8 %22560, i8* %23, align 1
  %22561 = icmp ne i8 %22555, 0
  %22562 = xor i1 %22561, %22559
  %.v782 = select i1 %22562, i64 10, i64 109
  %22563 = add i64 %22534, %.v782
  store i64 %22563, i64* %3, align 8
  br i1 %22562, label %block_4a71f9, label %block_.L_4a725c

block_4a71f9:                                     ; preds = %block_.L_4a71ef
  %22564 = load i64, i64* bitcast (%G_0x6cc5f8_type* @G_0x6cc5f8 to i64*), align 8
  store i64 %22564, i64* %RAX.i1763, align 8
  %22565 = add i64 %22535, -12
  %22566 = add i64 %22563, 12
  store i64 %22566, i64* %3, align 8
  %22567 = inttoptr i64 %22565 to i32*
  %22568 = load i32, i32* %22567, align 4
  %22569 = sext i32 %22568 to i64
  store i64 %22569, i64* %RCX.i1692, align 8
  %22570 = shl nsw i64 %22569, 3
  %22571 = add i64 %22570, %22564
  %22572 = add i64 %22563, 16
  store i64 %22572, i64* %3, align 8
  %22573 = inttoptr i64 %22571 to i64*
  %22574 = load i64, i64* %22573, align 8
  store i64 %22574, i64* %RAX.i1763, align 8
  %22575 = add i64 %22563, 20
  store i64 %22575, i64* %3, align 8
  %22576 = load i32, i32* %22538, align 4
  %22577 = sext i32 %22576 to i64
  store i64 %22577, i64* %RCX.i1692, align 8
  %22578 = shl nsw i64 %22577, 3
  %22579 = add i64 %22578, %22574
  %22580 = add i64 %22563, 24
  store i64 %22580, i64* %3, align 8
  %22581 = inttoptr i64 %22579 to i64*
  %22582 = load i64, i64* %22581, align 8
  store i64 %22582, i64* %RAX.i1763, align 8
  %22583 = add i64 %22535, -48
  %22584 = add i64 %22563, 28
  store i64 %22584, i64* %3, align 8
  %22585 = inttoptr i64 %22583 to i32*
  %22586 = load i32, i32* %22585, align 4
  %22587 = sext i32 %22586 to i64
  store i64 %22587, i64* %RCX.i1692, align 8
  %22588 = shl nsw i64 %22587, 3
  %22589 = add i64 %22588, %22582
  %22590 = add i64 %22563, 32
  store i64 %22590, i64* %3, align 8
  %22591 = inttoptr i64 %22589 to i64*
  %22592 = load i64, i64* %22591, align 8
  store i64 %22592, i64* %RAX.i1763, align 8
  %22593 = add i64 %22535, -44
  %22594 = add i64 %22563, 36
  store i64 %22594, i64* %3, align 8
  %22595 = inttoptr i64 %22593 to i32*
  %22596 = load i32, i32* %22595, align 4
  %22597 = sext i32 %22596 to i64
  store i64 %22597, i64* %RCX.i1692, align 8
  %22598 = shl nsw i64 %22597, 2
  %22599 = add i64 %22598, %22592
  %22600 = add i64 %22563, 39
  store i64 %22600, i64* %3, align 8
  %22601 = inttoptr i64 %22599 to i32*
  %22602 = load i32, i32* %22601, align 4
  %22603 = zext i32 %22602 to i64
  store i64 %22603, i64* %RDX.i1805, align 8
  %22604 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %22604, i64* %RAX.i1763, align 8
  %22605 = add i64 %22604, 14136
  %22606 = add i64 %22563, 54
  store i64 %22606, i64* %3, align 8
  %22607 = inttoptr i64 %22605 to i64*
  %22608 = load i64, i64* %22607, align 8
  store i64 %22608, i64* %RAX.i1763, align 8
  %22609 = add i64 %22563, 58
  store i64 %22609, i64* %3, align 8
  %22610 = load i32, i32* %22567, align 4
  %22611 = sext i32 %22610 to i64
  store i64 %22611, i64* %RCX.i1692, align 8
  %22612 = shl nsw i64 %22611, 3
  %22613 = add i64 %22612, %22608
  %22614 = add i64 %22563, 62
  store i64 %22614, i64* %3, align 8
  %22615 = inttoptr i64 %22613 to i64*
  %22616 = load i64, i64* %22615, align 8
  store i64 %22616, i64* %RAX.i1763, align 8
  %22617 = add i64 %22563, 66
  store i64 %22617, i64* %3, align 8
  %22618 = load i32, i32* %22538, align 4
  %22619 = sext i32 %22618 to i64
  store i64 %22619, i64* %RCX.i1692, align 8
  %22620 = shl nsw i64 %22619, 3
  %22621 = add i64 %22620, %22616
  %22622 = add i64 %22563, 70
  store i64 %22622, i64* %3, align 8
  %22623 = inttoptr i64 %22621 to i64*
  %22624 = load i64, i64* %22623, align 8
  store i64 %22624, i64* %RAX.i1763, align 8
  %22625 = add i64 %22563, 74
  store i64 %22625, i64* %3, align 8
  %22626 = load i32, i32* %22585, align 4
  %22627 = sext i32 %22626 to i64
  store i64 %22627, i64* %RCX.i1692, align 8
  %22628 = shl nsw i64 %22627, 3
  %22629 = add i64 %22628, %22624
  %22630 = add i64 %22563, 78
  store i64 %22630, i64* %3, align 8
  %22631 = inttoptr i64 %22629 to i64*
  %22632 = load i64, i64* %22631, align 8
  store i64 %22632, i64* %RAX.i1763, align 8
  %22633 = load i64, i64* %RBP.i, align 8
  %22634 = add i64 %22633, -44
  %22635 = add i64 %22563, 82
  store i64 %22635, i64* %3, align 8
  %22636 = inttoptr i64 %22634 to i32*
  %22637 = load i32, i32* %22636, align 4
  %22638 = sext i32 %22637 to i64
  store i64 %22638, i64* %RCX.i1692, align 8
  %22639 = shl nsw i64 %22638, 2
  %22640 = add i64 %22639, %22632
  %22641 = add i64 %22563, 85
  store i64 %22641, i64* %3, align 8
  %22642 = inttoptr i64 %22640 to i32*
  store i32 %22602, i32* %22642, align 4
  %22643 = load i64, i64* %RBP.i, align 8
  %22644 = add i64 %22643, -52
  %22645 = load i64, i64* %3, align 8
  %22646 = add i64 %22645, 3
  store i64 %22646, i64* %3, align 8
  %22647 = inttoptr i64 %22644 to i32*
  %22648 = load i32, i32* %22647, align 4
  %22649 = add i32 %22648, 1
  %22650 = zext i32 %22649 to i64
  store i64 %22650, i64* %RAX.i1763, align 8
  %22651 = icmp eq i32 %22648, -1
  %22652 = icmp eq i32 %22649, 0
  %22653 = or i1 %22651, %22652
  %22654 = zext i1 %22653 to i8
  store i8 %22654, i8* %18, align 1
  %22655 = and i32 %22649, 255
  %22656 = tail call i32 @llvm.ctpop.i32(i32 %22655)
  %22657 = trunc i32 %22656 to i8
  %22658 = and i8 %22657, 1
  %22659 = xor i8 %22658, 1
  store i8 %22659, i8* %19, align 1
  %22660 = xor i32 %22649, %22648
  %22661 = lshr i32 %22660, 4
  %22662 = trunc i32 %22661 to i8
  %22663 = and i8 %22662, 1
  store i8 %22663, i8* %20, align 1
  %22664 = zext i1 %22652 to i8
  store i8 %22664, i8* %21, align 1
  %22665 = lshr i32 %22649, 31
  %22666 = trunc i32 %22665 to i8
  store i8 %22666, i8* %22, align 1
  %22667 = lshr i32 %22648, 31
  %22668 = xor i32 %22665, %22667
  %22669 = add nuw nsw i32 %22668, %22665
  %22670 = icmp eq i32 %22669, 2
  %22671 = zext i1 %22670 to i8
  store i8 %22671, i8* %23, align 1
  %22672 = add i64 %22645, 9
  store i64 %22672, i64* %3, align 8
  store i32 %22649, i32* %22647, align 4
  %22673 = load i64, i64* %3, align 8
  %22674 = add i64 %22673, -104
  store i64 %22674, i64* %3, align 8
  br label %block_.L_4a71ef

block_.L_4a725c:                                  ; preds = %block_.L_4a71ef
  %22675 = add i64 %22535, -44
  %22676 = add i64 %22563, 8
  store i64 %22676, i64* %3, align 8
  %22677 = inttoptr i64 %22675 to i32*
  %22678 = load i32, i32* %22677, align 4
  %22679 = add i32 %22678, 1
  %22680 = zext i32 %22679 to i64
  store i64 %22680, i64* %RAX.i1763, align 8
  %22681 = icmp eq i32 %22678, -1
  %22682 = icmp eq i32 %22679, 0
  %22683 = or i1 %22681, %22682
  %22684 = zext i1 %22683 to i8
  store i8 %22684, i8* %18, align 1
  %22685 = and i32 %22679, 255
  %22686 = tail call i32 @llvm.ctpop.i32(i32 %22685)
  %22687 = trunc i32 %22686 to i8
  %22688 = and i8 %22687, 1
  %22689 = xor i8 %22688, 1
  store i8 %22689, i8* %19, align 1
  %22690 = xor i32 %22679, %22678
  %22691 = lshr i32 %22690, 4
  %22692 = trunc i32 %22691 to i8
  %22693 = and i8 %22692, 1
  store i8 %22693, i8* %20, align 1
  %22694 = zext i1 %22682 to i8
  store i8 %22694, i8* %21, align 1
  %22695 = lshr i32 %22679, 31
  %22696 = trunc i32 %22695 to i8
  store i8 %22696, i8* %22, align 1
  %22697 = lshr i32 %22678, 31
  %22698 = xor i32 %22695, %22697
  %22699 = add nuw nsw i32 %22698, %22695
  %22700 = icmp eq i32 %22699, 2
  %22701 = zext i1 %22700 to i8
  store i8 %22701, i8* %23, align 1
  %22702 = add i64 %22563, 14
  store i64 %22702, i64* %3, align 8
  store i32 %22679, i32* %22677, align 4
  %22703 = load i64, i64* %3, align 8
  %22704 = add i64 %22703, -140
  store i64 %22704, i64* %3, align 8
  br label %block_.L_4a71de

block_.L_4a726f:                                  ; preds = %block_.L_4a71de
  %22705 = add i64 %22502, -48
  %22706 = add i64 %22530, 8
  store i64 %22706, i64* %3, align 8
  %22707 = inttoptr i64 %22705 to i32*
  %22708 = load i32, i32* %22707, align 4
  %22709 = add i32 %22708, 1
  %22710 = zext i32 %22709 to i64
  store i64 %22710, i64* %RAX.i1763, align 8
  %22711 = icmp eq i32 %22708, -1
  %22712 = icmp eq i32 %22709, 0
  %22713 = or i1 %22711, %22712
  %22714 = zext i1 %22713 to i8
  store i8 %22714, i8* %18, align 1
  %22715 = and i32 %22709, 255
  %22716 = tail call i32 @llvm.ctpop.i32(i32 %22715)
  %22717 = trunc i32 %22716 to i8
  %22718 = and i8 %22717, 1
  %22719 = xor i8 %22718, 1
  store i8 %22719, i8* %19, align 1
  %22720 = xor i32 %22709, %22708
  %22721 = lshr i32 %22720, 4
  %22722 = trunc i32 %22721 to i8
  %22723 = and i8 %22722, 1
  store i8 %22723, i8* %20, align 1
  %22724 = zext i1 %22712 to i8
  store i8 %22724, i8* %21, align 1
  %22725 = lshr i32 %22709, 31
  %22726 = trunc i32 %22725 to i8
  store i8 %22726, i8* %22, align 1
  %22727 = lshr i32 %22708, 31
  %22728 = xor i32 %22725, %22727
  %22729 = add nuw nsw i32 %22728, %22725
  %22730 = icmp eq i32 %22729, 2
  %22731 = zext i1 %22730 to i8
  store i8 %22731, i8* %23, align 1
  %22732 = add i64 %22530, 14
  store i64 %22732, i64* %3, align 8
  store i32 %22709, i32* %22707, align 4
  %22733 = load i64, i64* %3, align 8
  %22734 = add i64 %22733, -176
  store i64 %22734, i64* %3, align 8
  br label %block_.L_4a71cd

block_.L_4a7282:                                  ; preds = %block_.L_4a71cd
  %22735 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %22735, i64* %RAX.i1763, align 8
  %22736 = add i64 %22735, 72724
  %22737 = add i64 %22497, 15
  store i64 %22737, i64* %3, align 8
  %22738 = inttoptr i64 %22736 to i32*
  %22739 = load i32, i32* %22738, align 4
  store i8 0, i8* %18, align 1
  %22740 = and i32 %22739, 255
  %22741 = tail call i32 @llvm.ctpop.i32(i32 %22740)
  %22742 = trunc i32 %22741 to i8
  %22743 = and i8 %22742, 1
  %22744 = xor i8 %22743, 1
  store i8 %22744, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %22745 = icmp eq i32 %22739, 0
  %22746 = zext i1 %22745 to i8
  store i8 %22746, i8* %21, align 1
  %22747 = lshr i32 %22739, 31
  %22748 = trunc i32 %22747 to i8
  store i8 %22748, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v817 = select i1 %22745, i64 412, i64 21
  %22749 = add i64 %22497, %.v817
  store i64 %22749, i64* %3, align 8
  br i1 %22745, label %block_.L_4a741e, label %block_4a7297

block_4a7297:                                     ; preds = %block_.L_4a7282
  %22750 = add i64 %22469, -628
  %22751 = add i64 %22749, 10
  store i64 %22751, i64* %3, align 8
  %22752 = inttoptr i64 %22750 to i32*
  store i32 0, i32* %22752, align 4
  %.pre628 = load i64, i64* %3, align 8
  br label %block_.L_4a72a1

block_.L_4a72a1:                                  ; preds = %block_.L_4a7400, %block_4a7297
  %22753 = phi i64 [ %23354, %block_.L_4a7400 ], [ %.pre628, %block_4a7297 ]
  %22754 = load i64, i64* %RBP.i, align 8
  %22755 = add i64 %22754, -628
  %22756 = add i64 %22753, 7
  store i64 %22756, i64* %3, align 8
  %22757 = inttoptr i64 %22755 to i32*
  %22758 = load i32, i32* %22757, align 4
  %22759 = add i32 %22758, -4
  %22760 = icmp ult i32 %22758, 4
  %22761 = zext i1 %22760 to i8
  store i8 %22761, i8* %18, align 1
  %22762 = and i32 %22759, 255
  %22763 = tail call i32 @llvm.ctpop.i32(i32 %22762)
  %22764 = trunc i32 %22763 to i8
  %22765 = and i8 %22764, 1
  %22766 = xor i8 %22765, 1
  store i8 %22766, i8* %19, align 1
  %22767 = xor i32 %22759, %22758
  %22768 = lshr i32 %22767, 4
  %22769 = trunc i32 %22768 to i8
  %22770 = and i8 %22769, 1
  store i8 %22770, i8* %20, align 1
  %22771 = icmp eq i32 %22759, 0
  %22772 = zext i1 %22771 to i8
  store i8 %22772, i8* %21, align 1
  %22773 = lshr i32 %22759, 31
  %22774 = trunc i32 %22773 to i8
  store i8 %22774, i8* %22, align 1
  %22775 = lshr i32 %22758, 31
  %22776 = xor i32 %22773, %22775
  %22777 = add nuw nsw i32 %22776, %22775
  %22778 = icmp eq i32 %22777, 2
  %22779 = zext i1 %22778 to i8
  store i8 %22779, i8* %23, align 1
  %22780 = icmp ne i8 %22774, 0
  %22781 = xor i1 %22780, %22778
  %.v818 = select i1 %22781, i64 13, i64 376
  %22782 = add i64 %22753, %.v818
  store i64 %22782, i64* %3, align 8
  br i1 %22781, label %block_4a72ae, label %block_.L_4a7419

block_4a72ae:                                     ; preds = %block_.L_4a72a1
  %22783 = add i64 %22754, -48
  %22784 = add i64 %22782, 7
  store i64 %22784, i64* %3, align 8
  %22785 = inttoptr i64 %22783 to i32*
  store i32 0, i32* %22785, align 4
  %.pre629 = load i64, i64* %3, align 8
  br label %block_.L_4a72b5

block_.L_4a72b5:                                  ; preds = %block_.L_4a7341, %block_4a72ae
  %22786 = phi i64 [ %23054, %block_.L_4a7341 ], [ %.pre629, %block_4a72ae ]
  %22787 = load i64, i64* %RBP.i, align 8
  %22788 = add i64 %22787, -48
  %22789 = add i64 %22786, 4
  store i64 %22789, i64* %3, align 8
  %22790 = inttoptr i64 %22788 to i32*
  %22791 = load i32, i32* %22790, align 4
  %22792 = add i32 %22791, -2
  %22793 = icmp ult i32 %22791, 2
  %22794 = zext i1 %22793 to i8
  store i8 %22794, i8* %18, align 1
  %22795 = and i32 %22792, 255
  %22796 = tail call i32 @llvm.ctpop.i32(i32 %22795)
  %22797 = trunc i32 %22796 to i8
  %22798 = and i8 %22797, 1
  %22799 = xor i8 %22798, 1
  store i8 %22799, i8* %19, align 1
  %22800 = xor i32 %22792, %22791
  %22801 = lshr i32 %22800, 4
  %22802 = trunc i32 %22801 to i8
  %22803 = and i8 %22802, 1
  store i8 %22803, i8* %20, align 1
  %22804 = icmp eq i32 %22792, 0
  %22805 = zext i1 %22804 to i8
  store i8 %22805, i8* %21, align 1
  %22806 = lshr i32 %22792, 31
  %22807 = trunc i32 %22806 to i8
  store i8 %22807, i8* %22, align 1
  %22808 = lshr i32 %22791, 31
  %22809 = xor i32 %22806, %22808
  %22810 = add nuw nsw i32 %22809, %22808
  %22811 = icmp eq i32 %22810, 2
  %22812 = zext i1 %22811 to i8
  store i8 %22812, i8* %23, align 1
  %22813 = icmp ne i8 %22807, 0
  %22814 = xor i1 %22813, %22811
  %.v822 = select i1 %22814, i64 10, i64 159
  %22815 = add i64 %22786, %.v822
  store i64 %22815, i64* %3, align 8
  br i1 %22814, label %block_4a72bf, label %block_.L_4a7354

block_4a72bf:                                     ; preds = %block_.L_4a72b5
  %22816 = add i64 %22787, -44
  %22817 = add i64 %22815, 7
  store i64 %22817, i64* %3, align 8
  %22818 = inttoptr i64 %22816 to i32*
  store i32 0, i32* %22818, align 4
  %.pre632 = load i64, i64* %3, align 8
  br label %block_.L_4a72c6

block_.L_4a72c6:                                  ; preds = %block_4a72d0, %block_4a72bf
  %22819 = phi i64 [ %23024, %block_4a72d0 ], [ %.pre632, %block_4a72bf ]
  %22820 = load i64, i64* %RBP.i, align 8
  %22821 = add i64 %22820, -44
  %22822 = add i64 %22819, 4
  store i64 %22822, i64* %3, align 8
  %22823 = inttoptr i64 %22821 to i32*
  %22824 = load i32, i32* %22823, align 4
  %22825 = add i32 %22824, -18
  %22826 = icmp ult i32 %22824, 18
  %22827 = zext i1 %22826 to i8
  store i8 %22827, i8* %18, align 1
  %22828 = and i32 %22825, 255
  %22829 = tail call i32 @llvm.ctpop.i32(i32 %22828)
  %22830 = trunc i32 %22829 to i8
  %22831 = and i8 %22830, 1
  %22832 = xor i8 %22831, 1
  store i8 %22832, i8* %19, align 1
  %22833 = xor i32 %22824, 16
  %22834 = xor i32 %22833, %22825
  %22835 = lshr i32 %22834, 4
  %22836 = trunc i32 %22835 to i8
  %22837 = and i8 %22836, 1
  store i8 %22837, i8* %20, align 1
  %22838 = icmp eq i32 %22825, 0
  %22839 = zext i1 %22838 to i8
  store i8 %22839, i8* %21, align 1
  %22840 = lshr i32 %22825, 31
  %22841 = trunc i32 %22840 to i8
  store i8 %22841, i8* %22, align 1
  %22842 = lshr i32 %22824, 31
  %22843 = xor i32 %22840, %22842
  %22844 = add nuw nsw i32 %22843, %22842
  %22845 = icmp eq i32 %22844, 2
  %22846 = zext i1 %22845 to i8
  store i8 %22846, i8* %23, align 1
  %22847 = icmp ne i8 %22841, 0
  %22848 = xor i1 %22847, %22845
  %.v780 = select i1 %22848, i64 10, i64 123
  %22849 = add i64 %22819, %.v780
  store i64 %22849, i64* %3, align 8
  br i1 %22848, label %block_4a72d0, label %block_.L_4a7341

block_4a72d0:                                     ; preds = %block_.L_4a72c6
  store i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64* %RAX.i1763, align 8
  %22850 = add i64 %22820, -628
  %22851 = add i64 %22849, 17
  store i64 %22851, i64* %3, align 8
  %22852 = inttoptr i64 %22850 to i32*
  %22853 = load i32, i32* %22852, align 4
  %22854 = sext i32 %22853 to i64
  %22855 = mul nsw i64 %22854, 144
  store i64 %22855, i64* %RCX.i1692, align 8
  %22856 = lshr i64 %22855, 63
  %22857 = add i64 %22855, ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64)
  store i64 %22857, i64* %RAX.i1763, align 8
  %22858 = icmp ult i64 %22857, ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64)
  %22859 = icmp ult i64 %22857, %22855
  %22860 = or i1 %22858, %22859
  %22861 = zext i1 %22860 to i8
  store i8 %22861, i8* %18, align 1
  %22862 = trunc i64 %22857 to i32
  %22863 = and i32 %22862, 248
  %22864 = tail call i32 @llvm.ctpop.i32(i32 %22863)
  %22865 = trunc i32 %22864 to i8
  %22866 = and i8 %22865, 1
  %22867 = xor i8 %22866, 1
  store i8 %22867, i8* %19, align 1
  %22868 = xor i64 %22855, ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64)
  %22869 = xor i64 %22868, %22857
  %22870 = lshr i64 %22869, 4
  %22871 = trunc i64 %22870 to i8
  %22872 = and i8 %22871, 1
  store i8 %22872, i8* %20, align 1
  %22873 = icmp eq i64 %22857, 0
  %22874 = zext i1 %22873 to i8
  store i8 %22874, i8* %21, align 1
  %22875 = lshr i64 %22857, 63
  %22876 = trunc i64 %22875 to i8
  store i8 %22876, i8* %22, align 1
  %22877 = xor i64 %22875, lshr (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 63)
  %22878 = xor i64 %22875, %22856
  %22879 = add nuw nsw i64 %22877, %22878
  %22880 = icmp eq i64 %22879, 2
  %22881 = zext i1 %22880 to i8
  store i8 %22881, i8* %23, align 1
  %22882 = add i64 %22820, -48
  %22883 = add i64 %22849, 31
  store i64 %22883, i64* %3, align 8
  %22884 = inttoptr i64 %22882 to i32*
  %22885 = load i32, i32* %22884, align 4
  %22886 = sext i32 %22885 to i64
  %22887 = mul nsw i64 %22886, 72
  store i64 %22887, i64* %RCX.i1692, align 8
  %22888 = lshr i64 %22887, 63
  %22889 = add i64 %22887, %22857
  store i64 %22889, i64* %RAX.i1763, align 8
  %22890 = icmp ult i64 %22889, %22857
  %22891 = icmp ult i64 %22889, %22887
  %22892 = or i1 %22890, %22891
  %22893 = zext i1 %22892 to i8
  store i8 %22893, i8* %18, align 1
  %22894 = trunc i64 %22889 to i32
  %22895 = and i32 %22894, 248
  %22896 = tail call i32 @llvm.ctpop.i32(i32 %22895)
  %22897 = trunc i32 %22896 to i8
  %22898 = and i8 %22897, 1
  %22899 = xor i8 %22898, 1
  store i8 %22899, i8* %19, align 1
  %22900 = xor i64 %22887, %22857
  %22901 = xor i64 %22900, %22889
  %22902 = lshr i64 %22901, 4
  %22903 = trunc i64 %22902 to i8
  %22904 = and i8 %22903, 1
  store i8 %22904, i8* %20, align 1
  %22905 = icmp eq i64 %22889, 0
  %22906 = zext i1 %22905 to i8
  store i8 %22906, i8* %21, align 1
  %22907 = lshr i64 %22889, 63
  %22908 = trunc i64 %22907 to i8
  store i8 %22908, i8* %22, align 1
  %22909 = xor i64 %22907, %22875
  %22910 = xor i64 %22907, %22888
  %22911 = add nuw nsw i64 %22909, %22910
  %22912 = icmp eq i64 %22911, 2
  %22913 = zext i1 %22912 to i8
  store i8 %22913, i8* %23, align 1
  %22914 = load i64, i64* %RBP.i, align 8
  %22915 = add i64 %22914, -44
  %22916 = add i64 %22849, 42
  store i64 %22916, i64* %3, align 8
  %22917 = inttoptr i64 %22915 to i32*
  %22918 = load i32, i32* %22917, align 4
  %22919 = sext i32 %22918 to i64
  store i64 %22919, i64* %RCX.i1692, align 8
  %22920 = shl nsw i64 %22919, 2
  %22921 = add i64 %22920, %22889
  %22922 = add i64 %22849, 45
  store i64 %22922, i64* %3, align 8
  %22923 = inttoptr i64 %22921 to i32*
  %22924 = load i32, i32* %22923, align 4
  %22925 = zext i32 %22924 to i64
  store i64 %22925, i64* %RDX.i1805, align 8
  %22926 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %22926, i64* %RAX.i1763, align 8
  %22927 = add i64 %22926, 14136
  %22928 = add i64 %22849, 60
  store i64 %22928, i64* %3, align 8
  %22929 = inttoptr i64 %22927 to i64*
  %22930 = load i64, i64* %22929, align 8
  store i64 %22930, i64* %RAX.i1763, align 8
  %22931 = add i64 %22914, -12
  %22932 = add i64 %22849, 63
  store i64 %22932, i64* %3, align 8
  %22933 = inttoptr i64 %22931 to i32*
  %22934 = load i32, i32* %22933, align 4
  %22935 = add i32 %22934, 4
  %22936 = zext i32 %22935 to i64
  store i64 %22936, i64* %RSI.i1889, align 8
  %22937 = icmp ugt i32 %22934, -5
  %22938 = zext i1 %22937 to i8
  store i8 %22938, i8* %18, align 1
  %22939 = and i32 %22935, 255
  %22940 = tail call i32 @llvm.ctpop.i32(i32 %22939)
  %22941 = trunc i32 %22940 to i8
  %22942 = and i8 %22941, 1
  %22943 = xor i8 %22942, 1
  store i8 %22943, i8* %19, align 1
  %22944 = xor i32 %22935, %22934
  %22945 = lshr i32 %22944, 4
  %22946 = trunc i32 %22945 to i8
  %22947 = and i8 %22946, 1
  store i8 %22947, i8* %20, align 1
  %22948 = icmp eq i32 %22935, 0
  %22949 = zext i1 %22948 to i8
  store i8 %22949, i8* %21, align 1
  %22950 = lshr i32 %22935, 31
  %22951 = trunc i32 %22950 to i8
  store i8 %22951, i8* %22, align 1
  %22952 = lshr i32 %22934, 31
  %22953 = xor i32 %22950, %22952
  %22954 = add nuw nsw i32 %22953, %22950
  %22955 = icmp eq i32 %22954, 2
  %22956 = zext i1 %22955 to i8
  store i8 %22956, i8* %23, align 1
  %22957 = sext i32 %22935 to i64
  store i64 %22957, i64* %RCX.i1692, align 8
  %22958 = shl nsw i64 %22957, 3
  %22959 = add i64 %22930, %22958
  %22960 = add i64 %22849, 73
  store i64 %22960, i64* %3, align 8
  %22961 = inttoptr i64 %22959 to i64*
  %22962 = load i64, i64* %22961, align 8
  store i64 %22962, i64* %RAX.i1763, align 8
  %22963 = add i64 %22914, -628
  %22964 = add i64 %22849, 80
  store i64 %22964, i64* %3, align 8
  %22965 = inttoptr i64 %22963 to i32*
  %22966 = load i32, i32* %22965, align 4
  %22967 = sext i32 %22966 to i64
  store i64 %22967, i64* %RCX.i1692, align 8
  %22968 = shl nsw i64 %22967, 3
  %22969 = add i64 %22968, %22962
  %22970 = add i64 %22849, 84
  store i64 %22970, i64* %3, align 8
  %22971 = inttoptr i64 %22969 to i64*
  %22972 = load i64, i64* %22971, align 8
  store i64 %22972, i64* %RAX.i1763, align 8
  %22973 = add i64 %22914, -48
  %22974 = add i64 %22849, 88
  store i64 %22974, i64* %3, align 8
  %22975 = inttoptr i64 %22973 to i32*
  %22976 = load i32, i32* %22975, align 4
  %22977 = sext i32 %22976 to i64
  store i64 %22977, i64* %RCX.i1692, align 8
  %22978 = shl nsw i64 %22977, 3
  %22979 = add i64 %22978, %22972
  %22980 = add i64 %22849, 92
  store i64 %22980, i64* %3, align 8
  %22981 = inttoptr i64 %22979 to i64*
  %22982 = load i64, i64* %22981, align 8
  store i64 %22982, i64* %RAX.i1763, align 8
  %22983 = load i64, i64* %RBP.i, align 8
  %22984 = add i64 %22983, -44
  %22985 = add i64 %22849, 96
  store i64 %22985, i64* %3, align 8
  %22986 = inttoptr i64 %22984 to i32*
  %22987 = load i32, i32* %22986, align 4
  %22988 = sext i32 %22987 to i64
  store i64 %22988, i64* %RCX.i1692, align 8
  %22989 = shl nsw i64 %22988, 2
  %22990 = add i64 %22989, %22982
  %22991 = add i64 %22849, 99
  store i64 %22991, i64* %3, align 8
  %22992 = inttoptr i64 %22990 to i32*
  store i32 %22924, i32* %22992, align 4
  %22993 = load i64, i64* %RBP.i, align 8
  %22994 = add i64 %22993, -44
  %22995 = load i64, i64* %3, align 8
  %22996 = add i64 %22995, 3
  store i64 %22996, i64* %3, align 8
  %22997 = inttoptr i64 %22994 to i32*
  %22998 = load i32, i32* %22997, align 4
  %22999 = add i32 %22998, 1
  %23000 = zext i32 %22999 to i64
  store i64 %23000, i64* %RAX.i1763, align 8
  %23001 = icmp eq i32 %22998, -1
  %23002 = icmp eq i32 %22999, 0
  %23003 = or i1 %23001, %23002
  %23004 = zext i1 %23003 to i8
  store i8 %23004, i8* %18, align 1
  %23005 = and i32 %22999, 255
  %23006 = tail call i32 @llvm.ctpop.i32(i32 %23005)
  %23007 = trunc i32 %23006 to i8
  %23008 = and i8 %23007, 1
  %23009 = xor i8 %23008, 1
  store i8 %23009, i8* %19, align 1
  %23010 = xor i32 %22999, %22998
  %23011 = lshr i32 %23010, 4
  %23012 = trunc i32 %23011 to i8
  %23013 = and i8 %23012, 1
  store i8 %23013, i8* %20, align 1
  %23014 = zext i1 %23002 to i8
  store i8 %23014, i8* %21, align 1
  %23015 = lshr i32 %22999, 31
  %23016 = trunc i32 %23015 to i8
  store i8 %23016, i8* %22, align 1
  %23017 = lshr i32 %22998, 31
  %23018 = xor i32 %23015, %23017
  %23019 = add nuw nsw i32 %23018, %23015
  %23020 = icmp eq i32 %23019, 2
  %23021 = zext i1 %23020 to i8
  store i8 %23021, i8* %23, align 1
  %23022 = add i64 %22995, 9
  store i64 %23022, i64* %3, align 8
  store i32 %22999, i32* %22997, align 4
  %23023 = load i64, i64* %3, align 8
  %23024 = add i64 %23023, -118
  store i64 %23024, i64* %3, align 8
  br label %block_.L_4a72c6

block_.L_4a7341:                                  ; preds = %block_.L_4a72c6
  %23025 = add i64 %22820, -48
  %23026 = add i64 %22849, 8
  store i64 %23026, i64* %3, align 8
  %23027 = inttoptr i64 %23025 to i32*
  %23028 = load i32, i32* %23027, align 4
  %23029 = add i32 %23028, 1
  %23030 = zext i32 %23029 to i64
  store i64 %23030, i64* %RAX.i1763, align 8
  %23031 = icmp eq i32 %23028, -1
  %23032 = icmp eq i32 %23029, 0
  %23033 = or i1 %23031, %23032
  %23034 = zext i1 %23033 to i8
  store i8 %23034, i8* %18, align 1
  %23035 = and i32 %23029, 255
  %23036 = tail call i32 @llvm.ctpop.i32(i32 %23035)
  %23037 = trunc i32 %23036 to i8
  %23038 = and i8 %23037, 1
  %23039 = xor i8 %23038, 1
  store i8 %23039, i8* %19, align 1
  %23040 = xor i32 %23029, %23028
  %23041 = lshr i32 %23040, 4
  %23042 = trunc i32 %23041 to i8
  %23043 = and i8 %23042, 1
  store i8 %23043, i8* %20, align 1
  %23044 = zext i1 %23032 to i8
  store i8 %23044, i8* %21, align 1
  %23045 = lshr i32 %23029, 31
  %23046 = trunc i32 %23045 to i8
  store i8 %23046, i8* %22, align 1
  %23047 = lshr i32 %23028, 31
  %23048 = xor i32 %23045, %23047
  %23049 = add nuw nsw i32 %23048, %23045
  %23050 = icmp eq i32 %23049, 2
  %23051 = zext i1 %23050 to i8
  store i8 %23051, i8* %23, align 1
  %23052 = add i64 %22849, 14
  store i64 %23052, i64* %3, align 8
  store i32 %23029, i32* %23027, align 4
  %23053 = load i64, i64* %3, align 8
  %23054 = add i64 %23053, -154
  store i64 %23054, i64* %3, align 8
  br label %block_.L_4a72b5

block_.L_4a7354:                                  ; preds = %block_.L_4a72b5
  %23055 = add i64 %22815, 7
  store i64 %23055, i64* %3, align 8
  store i32 0, i32* %22790, align 4
  %.pre630 = load i64, i64* %3, align 8
  br label %block_.L_4a735b

block_.L_4a735b:                                  ; preds = %block_.L_4a73ed, %block_.L_4a7354
  %23056 = phi i64 [ %23324, %block_.L_4a73ed ], [ %.pre630, %block_.L_4a7354 ]
  %23057 = load i64, i64* %RBP.i, align 8
  %23058 = add i64 %23057, -48
  %23059 = add i64 %23056, 4
  store i64 %23059, i64* %3, align 8
  %23060 = inttoptr i64 %23058 to i32*
  %23061 = load i32, i32* %23060, align 4
  %23062 = add i32 %23061, -2
  %23063 = icmp ult i32 %23061, 2
  %23064 = zext i1 %23063 to i8
  store i8 %23064, i8* %18, align 1
  %23065 = and i32 %23062, 255
  %23066 = tail call i32 @llvm.ctpop.i32(i32 %23065)
  %23067 = trunc i32 %23066 to i8
  %23068 = and i8 %23067, 1
  %23069 = xor i8 %23068, 1
  store i8 %23069, i8* %19, align 1
  %23070 = xor i32 %23062, %23061
  %23071 = lshr i32 %23070, 4
  %23072 = trunc i32 %23071 to i8
  %23073 = and i8 %23072, 1
  store i8 %23073, i8* %20, align 1
  %23074 = icmp eq i32 %23062, 0
  %23075 = zext i1 %23074 to i8
  store i8 %23075, i8* %21, align 1
  %23076 = lshr i32 %23062, 31
  %23077 = trunc i32 %23076 to i8
  store i8 %23077, i8* %22, align 1
  %23078 = lshr i32 %23061, 31
  %23079 = xor i32 %23076, %23078
  %23080 = add nuw nsw i32 %23079, %23078
  %23081 = icmp eq i32 %23080, 2
  %23082 = zext i1 %23081 to i8
  store i8 %23082, i8* %23, align 1
  %23083 = icmp ne i8 %23077, 0
  %23084 = xor i1 %23083, %23081
  %.v778 = select i1 %23084, i64 10, i64 165
  %23085 = add i64 %23056, %.v778
  store i64 %23085, i64* %3, align 8
  br i1 %23084, label %block_4a7365, label %block_.L_4a7400

block_4a7365:                                     ; preds = %block_.L_4a735b
  %23086 = add i64 %23057, -44
  %23087 = add i64 %23085, 7
  store i64 %23087, i64* %3, align 8
  %23088 = inttoptr i64 %23086 to i32*
  store i32 0, i32* %23088, align 4
  %.pre631 = load i64, i64* %3, align 8
  br label %block_.L_4a736c

block_.L_4a736c:                                  ; preds = %block_4a7376, %block_4a7365
  %23089 = phi i64 [ %23294, %block_4a7376 ], [ %.pre631, %block_4a7365 ]
  %23090 = load i64, i64* %RBP.i, align 8
  %23091 = add i64 %23090, -44
  %23092 = add i64 %23089, 4
  store i64 %23092, i64* %3, align 8
  %23093 = inttoptr i64 %23091 to i32*
  %23094 = load i32, i32* %23093, align 4
  %23095 = add i32 %23094, -18
  %23096 = icmp ult i32 %23094, 18
  %23097 = zext i1 %23096 to i8
  store i8 %23097, i8* %18, align 1
  %23098 = and i32 %23095, 255
  %23099 = tail call i32 @llvm.ctpop.i32(i32 %23098)
  %23100 = trunc i32 %23099 to i8
  %23101 = and i8 %23100, 1
  %23102 = xor i8 %23101, 1
  store i8 %23102, i8* %19, align 1
  %23103 = xor i32 %23094, 16
  %23104 = xor i32 %23103, %23095
  %23105 = lshr i32 %23104, 4
  %23106 = trunc i32 %23105 to i8
  %23107 = and i8 %23106, 1
  store i8 %23107, i8* %20, align 1
  %23108 = icmp eq i32 %23095, 0
  %23109 = zext i1 %23108 to i8
  store i8 %23109, i8* %21, align 1
  %23110 = lshr i32 %23095, 31
  %23111 = trunc i32 %23110 to i8
  store i8 %23111, i8* %22, align 1
  %23112 = lshr i32 %23094, 31
  %23113 = xor i32 %23110, %23112
  %23114 = add nuw nsw i32 %23113, %23112
  %23115 = icmp eq i32 %23114, 2
  %23116 = zext i1 %23115 to i8
  store i8 %23116, i8* %23, align 1
  %23117 = icmp ne i8 %23111, 0
  %23118 = xor i1 %23117, %23115
  %.v779 = select i1 %23118, i64 10, i64 129
  %23119 = add i64 %23089, %.v779
  store i64 %23119, i64* %3, align 8
  br i1 %23118, label %block_4a7376, label %block_.L_4a73ed

block_4a7376:                                     ; preds = %block_.L_4a736c
  store i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64* %RAX.i1763, align 8
  store i8 zext (i1 or (i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64)), i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 576)) to i8), i8* %18, align 1
  store i8 %1233, i8* %19, align 1
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576)), i64 4) to i8), i8 1), i8* %20, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 0) to i8), i8* %21, align 1
  store i8 trunc (i64 lshr (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 63) to i8), i8* %22, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 63), i64 lshr (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 63)), i64 lshr (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 63)), i64 2) to i8), i8* %23, align 1
  %23120 = add i64 %23090, -628
  %23121 = add i64 %23119, 23
  store i64 %23121, i64* %3, align 8
  %23122 = inttoptr i64 %23120 to i32*
  %23123 = load i32, i32* %23122, align 4
  %23124 = sext i32 %23123 to i64
  %23125 = mul nsw i64 %23124, 144
  store i64 %23125, i64* %RCX.i1692, align 8
  %23126 = lshr i64 %23125, 63
  %23127 = add i64 %23125, add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576)
  store i64 %23127, i64* %RAX.i1763, align 8
  %23128 = icmp ult i64 %23127, add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576)
  %23129 = icmp ult i64 %23127, %23125
  %23130 = or i1 %23128, %23129
  %23131 = zext i1 %23130 to i8
  store i8 %23131, i8* %18, align 1
  %23132 = trunc i64 %23127 to i32
  %23133 = and i32 %23132, 248
  %23134 = tail call i32 @llvm.ctpop.i32(i32 %23133)
  %23135 = trunc i32 %23134 to i8
  %23136 = and i8 %23135, 1
  %23137 = xor i8 %23136, 1
  store i8 %23137, i8* %19, align 1
  %23138 = xor i64 %23125, add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576)
  %23139 = xor i64 %23138, %23127
  %23140 = lshr i64 %23139, 4
  %23141 = trunc i64 %23140 to i8
  %23142 = and i8 %23141, 1
  store i8 %23142, i8* %20, align 1
  %23143 = icmp eq i64 %23127, 0
  %23144 = zext i1 %23143 to i8
  store i8 %23144, i8* %21, align 1
  %23145 = lshr i64 %23127, 63
  %23146 = trunc i64 %23145 to i8
  store i8 %23146, i8* %22, align 1
  %23147 = xor i64 %23145, lshr (i64 add (i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64 576), i64 63)
  %23148 = xor i64 %23145, %23126
  %23149 = add nuw nsw i64 %23147, %23148
  %23150 = icmp eq i64 %23149, 2
  %23151 = zext i1 %23150 to i8
  store i8 %23151, i8* %23, align 1
  %23152 = add i64 %23090, -48
  %23153 = add i64 %23119, 37
  store i64 %23153, i64* %3, align 8
  %23154 = inttoptr i64 %23152 to i32*
  %23155 = load i32, i32* %23154, align 4
  %23156 = sext i32 %23155 to i64
  %23157 = mul nsw i64 %23156, 72
  store i64 %23157, i64* %RCX.i1692, align 8
  %23158 = lshr i64 %23157, 63
  %23159 = add i64 %23157, %23127
  store i64 %23159, i64* %RAX.i1763, align 8
  %23160 = icmp ult i64 %23159, %23127
  %23161 = icmp ult i64 %23159, %23157
  %23162 = or i1 %23160, %23161
  %23163 = zext i1 %23162 to i8
  store i8 %23163, i8* %18, align 1
  %23164 = trunc i64 %23159 to i32
  %23165 = and i32 %23164, 255
  %23166 = tail call i32 @llvm.ctpop.i32(i32 %23165)
  %23167 = trunc i32 %23166 to i8
  %23168 = and i8 %23167, 1
  %23169 = xor i8 %23168, 1
  store i8 %23169, i8* %19, align 1
  %23170 = xor i64 %23157, %23127
  %23171 = xor i64 %23170, %23159
  %23172 = lshr i64 %23171, 4
  %23173 = trunc i64 %23172 to i8
  %23174 = and i8 %23173, 1
  store i8 %23174, i8* %20, align 1
  %23175 = icmp eq i64 %23159, 0
  %23176 = zext i1 %23175 to i8
  store i8 %23176, i8* %21, align 1
  %23177 = lshr i64 %23159, 63
  %23178 = trunc i64 %23177 to i8
  store i8 %23178, i8* %22, align 1
  %23179 = xor i64 %23177, %23145
  %23180 = xor i64 %23177, %23158
  %23181 = add nuw nsw i64 %23179, %23180
  %23182 = icmp eq i64 %23181, 2
  %23183 = zext i1 %23182 to i8
  store i8 %23183, i8* %23, align 1
  %23184 = load i64, i64* %RBP.i, align 8
  %23185 = add i64 %23184, -44
  %23186 = add i64 %23119, 48
  store i64 %23186, i64* %3, align 8
  %23187 = inttoptr i64 %23185 to i32*
  %23188 = load i32, i32* %23187, align 4
  %23189 = sext i32 %23188 to i64
  store i64 %23189, i64* %RCX.i1692, align 8
  %23190 = shl nsw i64 %23189, 2
  %23191 = add i64 %23190, %23159
  %23192 = add i64 %23119, 51
  store i64 %23192, i64* %3, align 8
  %23193 = inttoptr i64 %23191 to i32*
  %23194 = load i32, i32* %23193, align 4
  %23195 = zext i32 %23194 to i64
  store i64 %23195, i64* %RDX.i1805, align 8
  %23196 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %23196, i64* %RAX.i1763, align 8
  %23197 = add i64 %23196, 14136
  %23198 = add i64 %23119, 66
  store i64 %23198, i64* %3, align 8
  %23199 = inttoptr i64 %23197 to i64*
  %23200 = load i64, i64* %23199, align 8
  store i64 %23200, i64* %RAX.i1763, align 8
  %23201 = add i64 %23184, -12
  %23202 = add i64 %23119, 69
  store i64 %23202, i64* %3, align 8
  %23203 = inttoptr i64 %23201 to i32*
  %23204 = load i32, i32* %23203, align 4
  %23205 = add i32 %23204, 8
  %23206 = zext i32 %23205 to i64
  store i64 %23206, i64* %RSI.i1889, align 8
  %23207 = icmp ugt i32 %23204, -9
  %23208 = zext i1 %23207 to i8
  store i8 %23208, i8* %18, align 1
  %23209 = and i32 %23205, 255
  %23210 = tail call i32 @llvm.ctpop.i32(i32 %23209)
  %23211 = trunc i32 %23210 to i8
  %23212 = and i8 %23211, 1
  %23213 = xor i8 %23212, 1
  store i8 %23213, i8* %19, align 1
  %23214 = xor i32 %23205, %23204
  %23215 = lshr i32 %23214, 4
  %23216 = trunc i32 %23215 to i8
  %23217 = and i8 %23216, 1
  store i8 %23217, i8* %20, align 1
  %23218 = icmp eq i32 %23205, 0
  %23219 = zext i1 %23218 to i8
  store i8 %23219, i8* %21, align 1
  %23220 = lshr i32 %23205, 31
  %23221 = trunc i32 %23220 to i8
  store i8 %23221, i8* %22, align 1
  %23222 = lshr i32 %23204, 31
  %23223 = xor i32 %23220, %23222
  %23224 = add nuw nsw i32 %23223, %23220
  %23225 = icmp eq i32 %23224, 2
  %23226 = zext i1 %23225 to i8
  store i8 %23226, i8* %23, align 1
  %23227 = sext i32 %23205 to i64
  store i64 %23227, i64* %RCX.i1692, align 8
  %23228 = shl nsw i64 %23227, 3
  %23229 = add i64 %23200, %23228
  %23230 = add i64 %23119, 79
  store i64 %23230, i64* %3, align 8
  %23231 = inttoptr i64 %23229 to i64*
  %23232 = load i64, i64* %23231, align 8
  store i64 %23232, i64* %RAX.i1763, align 8
  %23233 = add i64 %23184, -628
  %23234 = add i64 %23119, 86
  store i64 %23234, i64* %3, align 8
  %23235 = inttoptr i64 %23233 to i32*
  %23236 = load i32, i32* %23235, align 4
  %23237 = sext i32 %23236 to i64
  store i64 %23237, i64* %RCX.i1692, align 8
  %23238 = shl nsw i64 %23237, 3
  %23239 = add i64 %23238, %23232
  %23240 = add i64 %23119, 90
  store i64 %23240, i64* %3, align 8
  %23241 = inttoptr i64 %23239 to i64*
  %23242 = load i64, i64* %23241, align 8
  store i64 %23242, i64* %RAX.i1763, align 8
  %23243 = add i64 %23184, -48
  %23244 = add i64 %23119, 94
  store i64 %23244, i64* %3, align 8
  %23245 = inttoptr i64 %23243 to i32*
  %23246 = load i32, i32* %23245, align 4
  %23247 = sext i32 %23246 to i64
  store i64 %23247, i64* %RCX.i1692, align 8
  %23248 = shl nsw i64 %23247, 3
  %23249 = add i64 %23248, %23242
  %23250 = add i64 %23119, 98
  store i64 %23250, i64* %3, align 8
  %23251 = inttoptr i64 %23249 to i64*
  %23252 = load i64, i64* %23251, align 8
  store i64 %23252, i64* %RAX.i1763, align 8
  %23253 = load i64, i64* %RBP.i, align 8
  %23254 = add i64 %23253, -44
  %23255 = add i64 %23119, 102
  store i64 %23255, i64* %3, align 8
  %23256 = inttoptr i64 %23254 to i32*
  %23257 = load i32, i32* %23256, align 4
  %23258 = sext i32 %23257 to i64
  store i64 %23258, i64* %RCX.i1692, align 8
  %23259 = shl nsw i64 %23258, 2
  %23260 = add i64 %23259, %23252
  %23261 = add i64 %23119, 105
  store i64 %23261, i64* %3, align 8
  %23262 = inttoptr i64 %23260 to i32*
  store i32 %23194, i32* %23262, align 4
  %23263 = load i64, i64* %RBP.i, align 8
  %23264 = add i64 %23263, -44
  %23265 = load i64, i64* %3, align 8
  %23266 = add i64 %23265, 3
  store i64 %23266, i64* %3, align 8
  %23267 = inttoptr i64 %23264 to i32*
  %23268 = load i32, i32* %23267, align 4
  %23269 = add i32 %23268, 1
  %23270 = zext i32 %23269 to i64
  store i64 %23270, i64* %RAX.i1763, align 8
  %23271 = icmp eq i32 %23268, -1
  %23272 = icmp eq i32 %23269, 0
  %23273 = or i1 %23271, %23272
  %23274 = zext i1 %23273 to i8
  store i8 %23274, i8* %18, align 1
  %23275 = and i32 %23269, 255
  %23276 = tail call i32 @llvm.ctpop.i32(i32 %23275)
  %23277 = trunc i32 %23276 to i8
  %23278 = and i8 %23277, 1
  %23279 = xor i8 %23278, 1
  store i8 %23279, i8* %19, align 1
  %23280 = xor i32 %23269, %23268
  %23281 = lshr i32 %23280, 4
  %23282 = trunc i32 %23281 to i8
  %23283 = and i8 %23282, 1
  store i8 %23283, i8* %20, align 1
  %23284 = zext i1 %23272 to i8
  store i8 %23284, i8* %21, align 1
  %23285 = lshr i32 %23269, 31
  %23286 = trunc i32 %23285 to i8
  store i8 %23286, i8* %22, align 1
  %23287 = lshr i32 %23268, 31
  %23288 = xor i32 %23285, %23287
  %23289 = add nuw nsw i32 %23288, %23285
  %23290 = icmp eq i32 %23289, 2
  %23291 = zext i1 %23290 to i8
  store i8 %23291, i8* %23, align 1
  %23292 = add i64 %23265, 9
  store i64 %23292, i64* %3, align 8
  store i32 %23269, i32* %23267, align 4
  %23293 = load i64, i64* %3, align 8
  %23294 = add i64 %23293, -124
  store i64 %23294, i64* %3, align 8
  br label %block_.L_4a736c

block_.L_4a73ed:                                  ; preds = %block_.L_4a736c
  %23295 = add i64 %23090, -48
  %23296 = add i64 %23119, 8
  store i64 %23296, i64* %3, align 8
  %23297 = inttoptr i64 %23295 to i32*
  %23298 = load i32, i32* %23297, align 4
  %23299 = add i32 %23298, 1
  %23300 = zext i32 %23299 to i64
  store i64 %23300, i64* %RAX.i1763, align 8
  %23301 = icmp eq i32 %23298, -1
  %23302 = icmp eq i32 %23299, 0
  %23303 = or i1 %23301, %23302
  %23304 = zext i1 %23303 to i8
  store i8 %23304, i8* %18, align 1
  %23305 = and i32 %23299, 255
  %23306 = tail call i32 @llvm.ctpop.i32(i32 %23305)
  %23307 = trunc i32 %23306 to i8
  %23308 = and i8 %23307, 1
  %23309 = xor i8 %23308, 1
  store i8 %23309, i8* %19, align 1
  %23310 = xor i32 %23299, %23298
  %23311 = lshr i32 %23310, 4
  %23312 = trunc i32 %23311 to i8
  %23313 = and i8 %23312, 1
  store i8 %23313, i8* %20, align 1
  %23314 = zext i1 %23302 to i8
  store i8 %23314, i8* %21, align 1
  %23315 = lshr i32 %23299, 31
  %23316 = trunc i32 %23315 to i8
  store i8 %23316, i8* %22, align 1
  %23317 = lshr i32 %23298, 31
  %23318 = xor i32 %23315, %23317
  %23319 = add nuw nsw i32 %23318, %23315
  %23320 = icmp eq i32 %23319, 2
  %23321 = zext i1 %23320 to i8
  store i8 %23321, i8* %23, align 1
  %23322 = add i64 %23119, 14
  store i64 %23322, i64* %3, align 8
  store i32 %23299, i32* %23297, align 4
  %23323 = load i64, i64* %3, align 8
  %23324 = add i64 %23323, -160
  store i64 %23324, i64* %3, align 8
  br label %block_.L_4a735b

block_.L_4a7400:                                  ; preds = %block_.L_4a735b
  %23325 = add i64 %23057, -628
  %23326 = add i64 %23085, 11
  store i64 %23326, i64* %3, align 8
  %23327 = inttoptr i64 %23325 to i32*
  %23328 = load i32, i32* %23327, align 4
  %23329 = add i32 %23328, 1
  %23330 = zext i32 %23329 to i64
  store i64 %23330, i64* %RAX.i1763, align 8
  %23331 = icmp eq i32 %23328, -1
  %23332 = icmp eq i32 %23329, 0
  %23333 = or i1 %23331, %23332
  %23334 = zext i1 %23333 to i8
  store i8 %23334, i8* %18, align 1
  %23335 = and i32 %23329, 255
  %23336 = tail call i32 @llvm.ctpop.i32(i32 %23335)
  %23337 = trunc i32 %23336 to i8
  %23338 = and i8 %23337, 1
  %23339 = xor i8 %23338, 1
  store i8 %23339, i8* %19, align 1
  %23340 = xor i32 %23329, %23328
  %23341 = lshr i32 %23340, 4
  %23342 = trunc i32 %23341 to i8
  %23343 = and i8 %23342, 1
  store i8 %23343, i8* %20, align 1
  %23344 = zext i1 %23332 to i8
  store i8 %23344, i8* %21, align 1
  %23345 = lshr i32 %23329, 31
  %23346 = trunc i32 %23345 to i8
  store i8 %23346, i8* %22, align 1
  %23347 = lshr i32 %23328, 31
  %23348 = xor i32 %23345, %23347
  %23349 = add nuw nsw i32 %23348, %23345
  %23350 = icmp eq i32 %23349, 2
  %23351 = zext i1 %23350 to i8
  store i8 %23351, i8* %23, align 1
  %23352 = add i64 %23085, 20
  store i64 %23352, i64* %3, align 8
  store i32 %23329, i32* %23327, align 4
  %23353 = load i64, i64* %3, align 8
  %23354 = add i64 %23353, -371
  store i64 %23354, i64* %3, align 8
  br label %block_.L_4a72a1

block_.L_4a7419:                                  ; preds = %block_.L_4a72a1
  %23355 = add i64 %22782, 5
  store i64 %23355, i64* %3, align 8
  br label %block_.L_4a741e

block_.L_4a741e:                                  ; preds = %block_.L_4a7419, %block_.L_4a7282
  %23356 = phi i64 [ %23355, %block_.L_4a7419 ], [ %22749, %block_.L_4a7282 ]
  %23357 = phi i64 [ %22754, %block_.L_4a7419 ], [ %22469, %block_.L_4a7282 ]
  %23358 = add i64 %23357, -60
  %23359 = add i64 %23356, 7
  store i64 %23359, i64* %3, align 8
  %23360 = inttoptr i64 %23358 to i32*
  store i32 0, i32* %23360, align 4
  %.pre633 = load i64, i64* %3, align 8
  br label %block_.L_4a7425

block_.L_4a7425:                                  ; preds = %block_.L_4a74f4, %block_.L_4a741e
  %23361 = phi i64 [ %23799, %block_.L_4a74f4 ], [ %.pre633, %block_.L_4a741e ]
  %23362 = load i64, i64* %RBP.i, align 8
  %23363 = add i64 %23362, -60
  %23364 = add i64 %23361, 4
  store i64 %23364, i64* %3, align 8
  %23365 = inttoptr i64 %23363 to i32*
  %23366 = load i32, i32* %23365, align 4
  %23367 = add i32 %23366, -8
  %23368 = icmp ult i32 %23366, 8
  %23369 = zext i1 %23368 to i8
  store i8 %23369, i8* %18, align 1
  %23370 = and i32 %23367, 255
  %23371 = tail call i32 @llvm.ctpop.i32(i32 %23370)
  %23372 = trunc i32 %23371 to i8
  %23373 = and i8 %23372, 1
  %23374 = xor i8 %23373, 1
  store i8 %23374, i8* %19, align 1
  %23375 = xor i32 %23367, %23366
  %23376 = lshr i32 %23375, 4
  %23377 = trunc i32 %23376 to i8
  %23378 = and i8 %23377, 1
  store i8 %23378, i8* %20, align 1
  %23379 = icmp eq i32 %23367, 0
  %23380 = zext i1 %23379 to i8
  store i8 %23380, i8* %21, align 1
  %23381 = lshr i32 %23367, 31
  %23382 = trunc i32 %23381 to i8
  store i8 %23382, i8* %22, align 1
  %23383 = lshr i32 %23366, 31
  %23384 = xor i32 %23381, %23383
  %23385 = add nuw nsw i32 %23384, %23383
  %23386 = icmp eq i32 %23385, 2
  %23387 = zext i1 %23386 to i8
  store i8 %23387, i8* %23, align 1
  %23388 = icmp ne i8 %23382, 0
  %23389 = xor i1 %23388, %23386
  %.v819 = select i1 %23389, i64 10, i64 226
  %23390 = add i64 %23361, %.v819
  store i64 %23390, i64* %3, align 8
  br i1 %23389, label %block_4a742f, label %block_.L_4a7507

block_4a742f:                                     ; preds = %block_.L_4a7425
  %23391 = add i64 %23362, -56
  %23392 = add i64 %23390, 7
  store i64 %23392, i64* %3, align 8
  %23393 = inttoptr i64 %23391 to i32*
  store i32 0, i32* %23393, align 4
  %.pre645 = load i64, i64* %3, align 8
  br label %block_.L_4a7436

block_.L_4a7436:                                  ; preds = %block_4a7440, %block_4a742f
  %23394 = phi i64 [ %23769, %block_4a7440 ], [ %.pre645, %block_4a742f ]
  %23395 = load i64, i64* %RBP.i, align 8
  %23396 = add i64 %23395, -56
  %23397 = add i64 %23394, 4
  store i64 %23397, i64* %3, align 8
  %23398 = inttoptr i64 %23396 to i32*
  %23399 = load i32, i32* %23398, align 4
  %23400 = add i32 %23399, -8
  %23401 = icmp ult i32 %23399, 8
  %23402 = zext i1 %23401 to i8
  store i8 %23402, i8* %18, align 1
  %23403 = and i32 %23400, 255
  %23404 = tail call i32 @llvm.ctpop.i32(i32 %23403)
  %23405 = trunc i32 %23404 to i8
  %23406 = and i8 %23405, 1
  %23407 = xor i8 %23406, 1
  store i8 %23407, i8* %19, align 1
  %23408 = xor i32 %23400, %23399
  %23409 = lshr i32 %23408, 4
  %23410 = trunc i32 %23409 to i8
  %23411 = and i8 %23410, 1
  store i8 %23411, i8* %20, align 1
  %23412 = icmp eq i32 %23400, 0
  %23413 = zext i1 %23412 to i8
  store i8 %23413, i8* %21, align 1
  %23414 = lshr i32 %23400, 31
  %23415 = trunc i32 %23414 to i8
  store i8 %23415, i8* %22, align 1
  %23416 = lshr i32 %23399, 31
  %23417 = xor i32 %23414, %23416
  %23418 = add nuw nsw i32 %23417, %23416
  %23419 = icmp eq i32 %23418, 2
  %23420 = zext i1 %23419 to i8
  store i8 %23420, i8* %23, align 1
  %23421 = icmp ne i8 %23415, 0
  %23422 = xor i1 %23421, %23419
  %.v777 = select i1 %23422, i64 10, i64 190
  %23423 = add i64 %23394, %.v777
  store i64 %23423, i64* %3, align 8
  br i1 %23422, label %block_4a7440, label %block_.L_4a74f4

block_4a7440:                                     ; preds = %block_.L_4a7436
  %23424 = add i64 %23395, -464
  store i64 %23424, i64* %RAX.i1763, align 8
  %23425 = add i64 %23395, -60
  %23426 = add i64 %23423, 11
  store i64 %23426, i64* %3, align 8
  %23427 = inttoptr i64 %23425 to i32*
  %23428 = load i32, i32* %23427, align 4
  %23429 = sext i32 %23428 to i64
  %23430 = shl nsw i64 %23429, 4
  store i64 %23430, i64* %RCX.i1692, align 8
  %23431 = add i64 %23430, %23424
  store i64 %23431, i64* %RAX.i1763, align 8
  %23432 = icmp ult i64 %23431, %23424
  %23433 = icmp ult i64 %23431, %23430
  %23434 = or i1 %23432, %23433
  %23435 = zext i1 %23434 to i8
  store i8 %23435, i8* %18, align 1
  %23436 = trunc i64 %23431 to i32
  %23437 = and i32 %23436, 255
  %23438 = tail call i32 @llvm.ctpop.i32(i32 %23437)
  %23439 = trunc i32 %23438 to i8
  %23440 = and i8 %23439, 1
  %23441 = xor i8 %23440, 1
  store i8 %23441, i8* %19, align 1
  %23442 = xor i64 %23430, %23424
  %23443 = xor i64 %23442, %23431
  %23444 = lshr i64 %23443, 4
  %23445 = trunc i64 %23444 to i8
  %23446 = and i8 %23445, 1
  store i8 %23446, i8* %20, align 1
  %23447 = icmp eq i64 %23431, 0
  %23448 = zext i1 %23447 to i8
  store i8 %23448, i8* %21, align 1
  %23449 = lshr i64 %23431, 63
  %23450 = trunc i64 %23449 to i8
  store i8 %23450, i8* %22, align 1
  %23451 = lshr i64 %23424, 63
  %23452 = lshr i64 %23429, 59
  %23453 = and i64 %23452, 1
  %23454 = xor i64 %23449, %23451
  %23455 = xor i64 %23449, %23453
  %23456 = add nuw nsw i64 %23454, %23455
  %23457 = icmp eq i64 %23456, 2
  %23458 = zext i1 %23457 to i8
  store i8 %23458, i8* %23, align 1
  %23459 = add i64 %23423, 22
  store i64 %23459, i64* %3, align 8
  %23460 = load i32, i32* %23398, align 4
  %23461 = sext i32 %23460 to i64
  store i64 %23461, i64* %RCX.i1692, align 8
  %23462 = shl nsw i64 %23461, 1
  %23463 = add i64 %23462, %23431
  %23464 = add i64 %23423, 26
  store i64 %23464, i64* %3, align 8
  %23465 = inttoptr i64 %23463 to i16*
  %23466 = load i16, i16* %23465, align 2
  store i16 %23466, i16* %DX.i5417, align 2
  %23467 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %23467, i64* %RAX.i1763, align 8
  %23468 = add i64 %23467, 6424
  %23469 = add i64 %23423, 41
  store i64 %23469, i64* %3, align 8
  %23470 = inttoptr i64 %23468 to i64*
  %23471 = load i64, i64* %23470, align 8
  store i64 %23471, i64* %RAX.i1763, align 8
  %23472 = add i64 %23395, -496
  %23473 = add i64 %23423, 47
  store i64 %23473, i64* %3, align 8
  %23474 = inttoptr i64 %23472 to i32*
  %23475 = load i32, i32* %23474, align 4
  %23476 = zext i32 %23475 to i64
  store i64 %23476, i64* %RSI.i1889, align 8
  %23477 = add i64 %23423, 50
  store i64 %23477, i64* %3, align 8
  %23478 = load i32, i32* %23427, align 4
  %23479 = add i32 %23478, %23475
  %23480 = zext i32 %23479 to i64
  store i64 %23480, i64* %RSI.i1889, align 8
  %23481 = icmp ult i32 %23479, %23475
  %23482 = icmp ult i32 %23479, %23478
  %23483 = or i1 %23481, %23482
  %23484 = zext i1 %23483 to i8
  store i8 %23484, i8* %18, align 1
  %23485 = and i32 %23479, 255
  %23486 = tail call i32 @llvm.ctpop.i32(i32 %23485)
  %23487 = trunc i32 %23486 to i8
  %23488 = and i8 %23487, 1
  %23489 = xor i8 %23488, 1
  store i8 %23489, i8* %19, align 1
  %23490 = xor i32 %23478, %23475
  %23491 = xor i32 %23490, %23479
  %23492 = lshr i32 %23491, 4
  %23493 = trunc i32 %23492 to i8
  %23494 = and i8 %23493, 1
  store i8 %23494, i8* %20, align 1
  %23495 = icmp eq i32 %23479, 0
  %23496 = zext i1 %23495 to i8
  store i8 %23496, i8* %21, align 1
  %23497 = lshr i32 %23479, 31
  %23498 = trunc i32 %23497 to i8
  store i8 %23498, i8* %22, align 1
  %23499 = lshr i32 %23475, 31
  %23500 = lshr i32 %23478, 31
  %23501 = xor i32 %23497, %23499
  %23502 = xor i32 %23497, %23500
  %23503 = add nuw nsw i32 %23501, %23502
  %23504 = icmp eq i32 %23503, 2
  %23505 = zext i1 %23504 to i8
  store i8 %23505, i8* %23, align 1
  %23506 = sext i32 %23479 to i64
  store i64 %23506, i64* %RCX.i1692, align 8
  %23507 = shl nsw i64 %23506, 3
  %23508 = add i64 %23471, %23507
  %23509 = add i64 %23423, 57
  store i64 %23509, i64* %3, align 8
  %23510 = inttoptr i64 %23508 to i64*
  %23511 = load i64, i64* %23510, align 8
  store i64 %23511, i64* %RAX.i1763, align 8
  %23512 = load i64, i64* %RBP.i, align 8
  %23513 = add i64 %23512, -492
  %23514 = add i64 %23423, 63
  store i64 %23514, i64* %3, align 8
  %23515 = inttoptr i64 %23513 to i32*
  %23516 = load i32, i32* %23515, align 4
  %23517 = zext i32 %23516 to i64
  store i64 %23517, i64* %RSI.i1889, align 8
  %23518 = add i64 %23512, -56
  %23519 = add i64 %23423, 66
  store i64 %23519, i64* %3, align 8
  %23520 = inttoptr i64 %23518 to i32*
  %23521 = load i32, i32* %23520, align 4
  %23522 = add i32 %23521, %23516
  %23523 = zext i32 %23522 to i64
  store i64 %23523, i64* %RSI.i1889, align 8
  %23524 = sext i32 %23522 to i64
  store i64 %23524, i64* %RCX.i1692, align 8
  %23525 = shl nsw i64 %23524, 1
  %23526 = add i64 %23511, %23525
  %23527 = load i16, i16* %DX.i5417, align 2
  %23528 = add i64 %23423, 73
  store i64 %23528, i64* %3, align 8
  %23529 = inttoptr i64 %23526 to i16*
  store i16 %23527, i16* %23529, align 2
  %23530 = load i64, i64* %3, align 8
  %23531 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %23532 = add i64 %23531, 7352
  store i64 %23532, i64* %RAX.i1763, align 8
  %23533 = icmp ugt i64 %23531, -7353
  %23534 = zext i1 %23533 to i8
  store i8 %23534, i8* %18, align 1
  %23535 = trunc i64 %23532 to i32
  %23536 = and i32 %23535, 255
  %23537 = tail call i32 @llvm.ctpop.i32(i32 %23536)
  %23538 = trunc i32 %23537 to i8
  %23539 = and i8 %23538, 1
  %23540 = xor i8 %23539, 1
  store i8 %23540, i8* %19, align 1
  %23541 = xor i64 %23531, 16
  %23542 = xor i64 %23541, %23532
  %23543 = lshr i64 %23542, 4
  %23544 = trunc i64 %23543 to i8
  %23545 = and i8 %23544, 1
  store i8 %23545, i8* %20, align 1
  %23546 = icmp eq i64 %23532, 0
  %23547 = zext i1 %23546 to i8
  store i8 %23547, i8* %21, align 1
  %23548 = lshr i64 %23532, 63
  %23549 = trunc i64 %23548 to i8
  store i8 %23549, i8* %22, align 1
  %23550 = lshr i64 %23531, 63
  %23551 = xor i64 %23548, %23550
  %23552 = add nuw nsw i64 %23551, %23548
  %23553 = icmp eq i64 %23552, 2
  %23554 = zext i1 %23553 to i8
  store i8 %23554, i8* %23, align 1
  %23555 = load i64, i64* %RBP.i, align 8
  %23556 = add i64 %23555, -40
  %23557 = add i64 %23530, 18
  store i64 %23557, i64* %3, align 8
  %23558 = inttoptr i64 %23556 to i32*
  %23559 = load i32, i32* %23558, align 4
  %23560 = sext i32 %23559 to i64
  %23561 = shl nsw i64 %23560, 7
  store i64 %23561, i64* %RCX.i1692, align 8
  %23562 = add i64 %23561, %23532
  store i64 %23562, i64* %RAX.i1763, align 8
  %23563 = icmp ult i64 %23562, %23532
  %23564 = icmp ult i64 %23562, %23561
  %23565 = or i1 %23563, %23564
  %23566 = zext i1 %23565 to i8
  store i8 %23566, i8* %18, align 1
  %23567 = trunc i64 %23562 to i32
  %23568 = and i32 %23567, 255
  %23569 = tail call i32 @llvm.ctpop.i32(i32 %23568)
  %23570 = trunc i32 %23569 to i8
  %23571 = and i8 %23570, 1
  %23572 = xor i8 %23571, 1
  store i8 %23572, i8* %19, align 1
  %23573 = xor i64 %23532, %23562
  %23574 = lshr i64 %23573, 4
  %23575 = trunc i64 %23574 to i8
  %23576 = and i8 %23575, 1
  store i8 %23576, i8* %20, align 1
  %23577 = icmp eq i64 %23562, 0
  %23578 = zext i1 %23577 to i8
  store i8 %23578, i8* %21, align 1
  %23579 = lshr i64 %23562, 63
  %23580 = trunc i64 %23579 to i8
  store i8 %23580, i8* %22, align 1
  %23581 = lshr i64 %23560, 56
  %23582 = and i64 %23581, 1
  %23583 = xor i64 %23579, %23548
  %23584 = xor i64 %23579, %23582
  %23585 = add nuw nsw i64 %23583, %23584
  %23586 = icmp eq i64 %23585, 2
  %23587 = zext i1 %23586 to i8
  store i8 %23587, i8* %23, align 1
  %23588 = add i64 %23555, -60
  %23589 = add i64 %23530, 29
  store i64 %23589, i64* %3, align 8
  %23590 = inttoptr i64 %23588 to i32*
  %23591 = load i32, i32* %23590, align 4
  %23592 = sext i32 %23591 to i64
  %23593 = shl nsw i64 %23592, 4
  store i64 %23593, i64* %RCX.i1692, align 8
  %23594 = add i64 %23593, %23562
  store i64 %23594, i64* %RAX.i1763, align 8
  %23595 = icmp ult i64 %23594, %23562
  %23596 = icmp ult i64 %23594, %23593
  %23597 = or i1 %23595, %23596
  %23598 = zext i1 %23597 to i8
  store i8 %23598, i8* %18, align 1
  %23599 = trunc i64 %23594 to i32
  %23600 = and i32 %23599, 255
  %23601 = tail call i32 @llvm.ctpop.i32(i32 %23600)
  %23602 = trunc i32 %23601 to i8
  %23603 = and i8 %23602, 1
  %23604 = xor i8 %23603, 1
  store i8 %23604, i8* %19, align 1
  %23605 = xor i64 %23593, %23562
  %23606 = xor i64 %23605, %23594
  %23607 = lshr i64 %23606, 4
  %23608 = trunc i64 %23607 to i8
  %23609 = and i8 %23608, 1
  store i8 %23609, i8* %20, align 1
  %23610 = icmp eq i64 %23594, 0
  %23611 = zext i1 %23610 to i8
  store i8 %23611, i8* %21, align 1
  %23612 = lshr i64 %23594, 63
  %23613 = trunc i64 %23612 to i8
  store i8 %23613, i8* %22, align 1
  %23614 = lshr i64 %23592, 59
  %23615 = and i64 %23614, 1
  %23616 = xor i64 %23612, %23579
  %23617 = xor i64 %23612, %23615
  %23618 = add nuw nsw i64 %23616, %23617
  %23619 = icmp eq i64 %23618, 2
  %23620 = zext i1 %23619 to i8
  store i8 %23620, i8* %23, align 1
  %23621 = load i64, i64* %RBP.i, align 8
  %23622 = add i64 %23621, -56
  %23623 = add i64 %23530, 40
  store i64 %23623, i64* %3, align 8
  %23624 = inttoptr i64 %23622 to i32*
  %23625 = load i32, i32* %23624, align 4
  %23626 = sext i32 %23625 to i64
  store i64 %23626, i64* %RCX.i1692, align 8
  %23627 = shl nsw i64 %23626, 1
  %23628 = add i64 %23627, %23594
  %23629 = add i64 %23530, 44
  store i64 %23629, i64* %3, align 8
  %23630 = inttoptr i64 %23628 to i16*
  %23631 = load i16, i16* %23630, align 2
  store i16 %23631, i16* %DX.i5417, align 2
  %23632 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %23633 = add i64 %23632, 12600
  store i64 %23633, i64* %RAX.i1763, align 8
  %23634 = icmp ugt i64 %23632, -12601
  %23635 = zext i1 %23634 to i8
  store i8 %23635, i8* %18, align 1
  %23636 = trunc i64 %23633 to i32
  %23637 = and i32 %23636, 255
  %23638 = tail call i32 @llvm.ctpop.i32(i32 %23637)
  %23639 = trunc i32 %23638 to i8
  %23640 = and i8 %23639, 1
  %23641 = xor i8 %23640, 1
  store i8 %23641, i8* %19, align 1
  %23642 = xor i64 %23632, 16
  %23643 = xor i64 %23642, %23633
  %23644 = lshr i64 %23643, 4
  %23645 = trunc i64 %23644 to i8
  %23646 = and i8 %23645, 1
  store i8 %23646, i8* %20, align 1
  %23647 = icmp eq i64 %23633, 0
  %23648 = zext i1 %23647 to i8
  store i8 %23648, i8* %21, align 1
  %23649 = lshr i64 %23633, 63
  %23650 = trunc i64 %23649 to i8
  store i8 %23650, i8* %22, align 1
  %23651 = lshr i64 %23632, 63
  %23652 = xor i64 %23649, %23651
  %23653 = add nuw nsw i64 %23652, %23649
  %23654 = icmp eq i64 %23653, 2
  %23655 = zext i1 %23654 to i8
  store i8 %23655, i8* %23, align 1
  %23656 = add i64 %23621, -484
  %23657 = add i64 %23530, 64
  store i64 %23657, i64* %3, align 8
  %23658 = inttoptr i64 %23656 to i32*
  %23659 = load i32, i32* %23658, align 4
  %23660 = zext i32 %23659 to i64
  store i64 %23660, i64* %RSI.i1889, align 8
  %23661 = add i64 %23530, 67
  store i64 %23661, i64* %3, align 8
  %23662 = load i32, i32* %23624, align 4
  %23663 = add i32 %23662, %23659
  %23664 = zext i32 %23663 to i64
  store i64 %23664, i64* %RSI.i1889, align 8
  %23665 = sext i32 %23663 to i64
  %23666 = shl nsw i64 %23665, 5
  store i64 %23666, i64* %RCX.i1692, align 8
  %23667 = load i64, i64* %RAX.i1763, align 8
  %23668 = add i64 %23666, %23667
  store i64 %23668, i64* %RAX.i1763, align 8
  %23669 = icmp ult i64 %23668, %23667
  %23670 = icmp ult i64 %23668, %23666
  %23671 = or i1 %23669, %23670
  %23672 = zext i1 %23671 to i8
  store i8 %23672, i8* %18, align 1
  %23673 = trunc i64 %23668 to i32
  %23674 = and i32 %23673, 255
  %23675 = tail call i32 @llvm.ctpop.i32(i32 %23674)
  %23676 = trunc i32 %23675 to i8
  %23677 = and i8 %23676, 1
  %23678 = xor i8 %23677, 1
  store i8 %23678, i8* %19, align 1
  %23679 = xor i64 %23667, %23668
  %23680 = lshr i64 %23679, 4
  %23681 = trunc i64 %23680 to i8
  %23682 = and i8 %23681, 1
  store i8 %23682, i8* %20, align 1
  %23683 = icmp eq i64 %23668, 0
  %23684 = zext i1 %23683 to i8
  store i8 %23684, i8* %21, align 1
  %23685 = lshr i64 %23668, 63
  %23686 = trunc i64 %23685 to i8
  store i8 %23686, i8* %22, align 1
  %23687 = lshr i64 %23667, 63
  %23688 = lshr i64 %23665, 58
  %23689 = and i64 %23688, 1
  %23690 = xor i64 %23685, %23687
  %23691 = xor i64 %23685, %23689
  %23692 = add nuw nsw i64 %23690, %23691
  %23693 = icmp eq i64 %23692, 2
  %23694 = zext i1 %23693 to i8
  store i8 %23694, i8* %23, align 1
  %23695 = load i64, i64* %RBP.i, align 8
  %23696 = add i64 %23695, -488
  %23697 = add i64 %23530, 83
  store i64 %23697, i64* %3, align 8
  %23698 = inttoptr i64 %23696 to i32*
  %23699 = load i32, i32* %23698, align 4
  %23700 = zext i32 %23699 to i64
  store i64 %23700, i64* %RSI.i1889, align 8
  %23701 = add i64 %23695, -60
  %23702 = add i64 %23530, 86
  store i64 %23702, i64* %3, align 8
  %23703 = inttoptr i64 %23701 to i32*
  %23704 = load i32, i32* %23703, align 4
  %23705 = add i32 %23704, %23699
  %23706 = zext i32 %23705 to i64
  store i64 %23706, i64* %RSI.i1889, align 8
  %23707 = icmp ult i32 %23705, %23699
  %23708 = icmp ult i32 %23705, %23704
  %23709 = or i1 %23707, %23708
  %23710 = zext i1 %23709 to i8
  store i8 %23710, i8* %18, align 1
  %23711 = and i32 %23705, 255
  %23712 = tail call i32 @llvm.ctpop.i32(i32 %23711)
  %23713 = trunc i32 %23712 to i8
  %23714 = and i8 %23713, 1
  %23715 = xor i8 %23714, 1
  store i8 %23715, i8* %19, align 1
  %23716 = xor i32 %23704, %23699
  %23717 = xor i32 %23716, %23705
  %23718 = lshr i32 %23717, 4
  %23719 = trunc i32 %23718 to i8
  %23720 = and i8 %23719, 1
  store i8 %23720, i8* %20, align 1
  %23721 = icmp eq i32 %23705, 0
  %23722 = zext i1 %23721 to i8
  store i8 %23722, i8* %21, align 1
  %23723 = lshr i32 %23705, 31
  %23724 = trunc i32 %23723 to i8
  store i8 %23724, i8* %22, align 1
  %23725 = lshr i32 %23699, 31
  %23726 = lshr i32 %23704, 31
  %23727 = xor i32 %23723, %23725
  %23728 = xor i32 %23723, %23726
  %23729 = add nuw nsw i32 %23727, %23728
  %23730 = icmp eq i32 %23729, 2
  %23731 = zext i1 %23730 to i8
  store i8 %23731, i8* %23, align 1
  %23732 = sext i32 %23705 to i64
  store i64 %23732, i64* %RCX.i1692, align 8
  %23733 = shl nsw i64 %23732, 1
  %23734 = add i64 %23668, %23733
  %23735 = load i16, i16* %DX.i5417, align 2
  %23736 = add i64 %23530, 93
  store i64 %23736, i64* %3, align 8
  %23737 = inttoptr i64 %23734 to i16*
  store i16 %23735, i16* %23737, align 2
  %23738 = load i64, i64* %RBP.i, align 8
  %23739 = add i64 %23738, -56
  %23740 = load i64, i64* %3, align 8
  %23741 = add i64 %23740, 3
  store i64 %23741, i64* %3, align 8
  %23742 = inttoptr i64 %23739 to i32*
  %23743 = load i32, i32* %23742, align 4
  %23744 = add i32 %23743, 1
  %23745 = zext i32 %23744 to i64
  store i64 %23745, i64* %RAX.i1763, align 8
  %23746 = icmp eq i32 %23743, -1
  %23747 = icmp eq i32 %23744, 0
  %23748 = or i1 %23746, %23747
  %23749 = zext i1 %23748 to i8
  store i8 %23749, i8* %18, align 1
  %23750 = and i32 %23744, 255
  %23751 = tail call i32 @llvm.ctpop.i32(i32 %23750)
  %23752 = trunc i32 %23751 to i8
  %23753 = and i8 %23752, 1
  %23754 = xor i8 %23753, 1
  store i8 %23754, i8* %19, align 1
  %23755 = xor i32 %23744, %23743
  %23756 = lshr i32 %23755, 4
  %23757 = trunc i32 %23756 to i8
  %23758 = and i8 %23757, 1
  store i8 %23758, i8* %20, align 1
  %23759 = zext i1 %23747 to i8
  store i8 %23759, i8* %21, align 1
  %23760 = lshr i32 %23744, 31
  %23761 = trunc i32 %23760 to i8
  store i8 %23761, i8* %22, align 1
  %23762 = lshr i32 %23743, 31
  %23763 = xor i32 %23760, %23762
  %23764 = add nuw nsw i32 %23763, %23760
  %23765 = icmp eq i32 %23764, 2
  %23766 = zext i1 %23765 to i8
  store i8 %23766, i8* %23, align 1
  %23767 = add i64 %23740, 9
  store i64 %23767, i64* %3, align 8
  store i32 %23744, i32* %23742, align 4
  %23768 = load i64, i64* %3, align 8
  %23769 = add i64 %23768, -185
  store i64 %23769, i64* %3, align 8
  br label %block_.L_4a7436

block_.L_4a74f4:                                  ; preds = %block_.L_4a7436
  %23770 = add i64 %23395, -60
  %23771 = add i64 %23423, 8
  store i64 %23771, i64* %3, align 8
  %23772 = inttoptr i64 %23770 to i32*
  %23773 = load i32, i32* %23772, align 4
  %23774 = add i32 %23773, 1
  %23775 = zext i32 %23774 to i64
  store i64 %23775, i64* %RAX.i1763, align 8
  %23776 = icmp eq i32 %23773, -1
  %23777 = icmp eq i32 %23774, 0
  %23778 = or i1 %23776, %23777
  %23779 = zext i1 %23778 to i8
  store i8 %23779, i8* %18, align 1
  %23780 = and i32 %23774, 255
  %23781 = tail call i32 @llvm.ctpop.i32(i32 %23780)
  %23782 = trunc i32 %23781 to i8
  %23783 = and i8 %23782, 1
  %23784 = xor i8 %23783, 1
  store i8 %23784, i8* %19, align 1
  %23785 = xor i32 %23774, %23773
  %23786 = lshr i32 %23785, 4
  %23787 = trunc i32 %23786 to i8
  %23788 = and i8 %23787, 1
  store i8 %23788, i8* %20, align 1
  %23789 = zext i1 %23777 to i8
  store i8 %23789, i8* %21, align 1
  %23790 = lshr i32 %23774, 31
  %23791 = trunc i32 %23790 to i8
  store i8 %23791, i8* %22, align 1
  %23792 = lshr i32 %23773, 31
  %23793 = xor i32 %23790, %23792
  %23794 = add nuw nsw i32 %23793, %23790
  %23795 = icmp eq i32 %23794, 2
  %23796 = zext i1 %23795 to i8
  store i8 %23796, i8* %23, align 1
  %23797 = add i64 %23423, 14
  store i64 %23797, i64* %3, align 8
  store i32 %23774, i32* %23772, align 4
  %23798 = load i64, i64* %3, align 8
  %23799 = add i64 %23798, -221
  store i64 %23799, i64* %3, align 8
  br label %block_.L_4a7425

block_.L_4a7507:                                  ; preds = %block_.L_4a7425
  %23800 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %23800, i64* %RAX.i1763, align 8
  %23801 = add i64 %23800, 72724
  %23802 = add i64 %23390, 15
  store i64 %23802, i64* %3, align 8
  %23803 = inttoptr i64 %23801 to i32*
  %23804 = load i32, i32* %23803, align 4
  store i8 0, i8* %18, align 1
  %23805 = and i32 %23804, 255
  %23806 = tail call i32 @llvm.ctpop.i32(i32 %23805)
  %23807 = trunc i32 %23806 to i8
  %23808 = and i8 %23807, 1
  %23809 = xor i8 %23808, 1
  store i8 %23809, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %23810 = icmp eq i32 %23804, 0
  %23811 = zext i1 %23810 to i8
  store i8 %23811, i8* %21, align 1
  %23812 = lshr i32 %23804, 31
  %23813 = trunc i32 %23812 to i8
  store i8 %23813, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %.v820 = select i1 %23810, i64 354, i64 21
  %23814 = add i64 %23390, %.v820
  store i64 %23814, i64* %3, align 8
  br i1 %23810, label %block_.L_4a7669, label %block_4a751c

block_4a751c:                                     ; preds = %block_.L_4a7507
  %23815 = add i64 %23362, -628
  %23816 = add i64 %23814, 10
  store i64 %23816, i64* %3, align 8
  %23817 = inttoptr i64 %23815 to i32*
  store i32 0, i32* %23817, align 4
  %SI.i86 = bitcast %union.anon* %57 to i16*
  %.pre634 = load i64, i64* %3, align 8
  br label %block_.L_4a7526

block_.L_4a7526:                                  ; preds = %block_.L_4a764b, %block_4a751c
  %23818 = phi i64 [ %.pre634, %block_4a751c ], [ %24443, %block_.L_4a764b ]
  %MEMORY.115 = phi %struct.Memory* [ %MEMORY.75, %block_4a751c ], [ %23929, %block_.L_4a764b ]
  %23819 = load i64, i64* %RBP.i, align 8
  %23820 = add i64 %23819, -628
  %23821 = add i64 %23818, 7
  store i64 %23821, i64* %3, align 8
  %23822 = inttoptr i64 %23820 to i32*
  %23823 = load i32, i32* %23822, align 4
  %23824 = add i32 %23823, -4
  %23825 = icmp ult i32 %23823, 4
  %23826 = zext i1 %23825 to i8
  store i8 %23826, i8* %18, align 1
  %23827 = and i32 %23824, 255
  %23828 = tail call i32 @llvm.ctpop.i32(i32 %23827)
  %23829 = trunc i32 %23828 to i8
  %23830 = and i8 %23829, 1
  %23831 = xor i8 %23830, 1
  store i8 %23831, i8* %19, align 1
  %23832 = xor i32 %23824, %23823
  %23833 = lshr i32 %23832, 4
  %23834 = trunc i32 %23833 to i8
  %23835 = and i8 %23834, 1
  store i8 %23835, i8* %20, align 1
  %23836 = icmp eq i32 %23824, 0
  %23837 = zext i1 %23836 to i8
  store i8 %23837, i8* %21, align 1
  %23838 = lshr i32 %23824, 31
  %23839 = trunc i32 %23838 to i8
  store i8 %23839, i8* %22, align 1
  %23840 = lshr i32 %23823, 31
  %23841 = xor i32 %23838, %23840
  %23842 = add nuw nsw i32 %23841, %23840
  %23843 = icmp eq i32 %23842, 2
  %23844 = zext i1 %23843 to i8
  store i8 %23844, i8* %23, align 1
  %23845 = icmp ne i8 %23839, 0
  %23846 = xor i1 %23845, %23843
  %.v821 = select i1 %23846, i64 13, i64 318
  %23847 = add i64 %23818, %.v821
  %23848 = add i64 %23847, 5
  store i64 %23848, i64* %3, align 8
  br i1 %23846, label %block_4a7533, label %block_.L_4a7669.loopexit

block_4a7533:                                     ; preds = %block_.L_4a7526
  store i64 2, i64* %RAX.i1763, align 8
  %23849 = add i64 %23847, 11
  store i64 %23849, i64* %3, align 8
  %23850 = load i32, i32* %23822, align 4
  %23851 = zext i32 %23850 to i64
  store i64 %23851, i64* %RCX.i1692, align 8
  %23852 = add i64 %23819, -1484
  %23853 = add i64 %23847, 17
  store i64 %23853, i64* %3, align 8
  %23854 = inttoptr i64 %23852 to i32*
  store i32 2, i32* %23854, align 4
  %23855 = load i32, i32* %ECX.i7699, align 4
  %23856 = zext i32 %23855 to i64
  %23857 = load i64, i64* %3, align 8
  store i64 %23856, i64* %RAX.i1763, align 8
  %23858 = sext i32 %23855 to i64
  %23859 = lshr i64 %23858, 32
  store i64 %23859, i64* %101, align 8
  %23860 = load i64, i64* %RBP.i, align 8
  %23861 = add i64 %23860, -1484
  %23862 = add i64 %23857, 9
  store i64 %23862, i64* %3, align 8
  %23863 = inttoptr i64 %23861 to i32*
  %23864 = load i32, i32* %23863, align 4
  %23865 = zext i32 %23864 to i64
  store i64 %23865, i64* %RCX.i1692, align 8
  %23866 = add i64 %23857, 11
  store i64 %23866, i64* %3, align 8
  %23867 = sext i32 %23864 to i64
  %23868 = shl nuw i64 %23859, 32
  %23869 = or i64 %23868, %23856
  %23870 = sdiv i64 %23869, %23867
  %23871 = shl i64 %23870, 32
  %23872 = ashr exact i64 %23871, 32
  %23873 = icmp eq i64 %23870, %23872
  br i1 %23873, label %23876, label %23874

; <label>:23874:                                  ; preds = %block_4a7533
  %23875 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %23866, %struct.Memory* %MEMORY.115)
  %.pre635 = load i64, i64* %RDX.i1805, align 8
  %.pre636 = load i64, i64* %3, align 8
  %.pre637 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit159

; <label>:23876:                                  ; preds = %block_4a7533
  %23877 = srem i64 %23869, %23867
  %23878 = and i64 %23870, 4294967295
  store i64 %23878, i64* %RAX.i1763, align 8
  %23879 = and i64 %23877, 4294967295
  store i64 %23879, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__ecx.exit159

routine_idivl__ecx.exit159:                       ; preds = %23876, %23874
  %23880 = phi i64 [ %.pre637, %23874 ], [ %23860, %23876 ]
  %23881 = phi i64 [ %.pre636, %23874 ], [ %23866, %23876 ]
  %23882 = phi i64 [ %.pre635, %23874 ], [ %23879, %23876 ]
  %23883 = phi %struct.Memory* [ %23875, %23874 ], [ %MEMORY.115, %23876 ]
  %.tr319 = trunc i64 %23882 to i32
  %23884 = shl i32 %.tr319, 2
  %23885 = zext i32 %23884 to i64
  store i64 %23885, i64* %RDX.i1805, align 8
  %23886 = lshr i64 %23882, 30
  %23887 = trunc i64 %23886 to i8
  %23888 = and i8 %23887, 1
  store i8 %23888, i8* %18, align 1
  %23889 = and i32 %23884, 252
  %23890 = tail call i32 @llvm.ctpop.i32(i32 %23889)
  %23891 = trunc i32 %23890 to i8
  %23892 = and i8 %23891, 1
  %23893 = xor i8 %23892, 1
  store i8 %23893, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %23894 = icmp eq i32 %23884, 0
  %23895 = zext i1 %23894 to i8
  store i8 %23895, i8* %21, align 1
  %23896 = lshr i32 %.tr319, 29
  %23897 = trunc i32 %23896 to i8
  %23898 = and i8 %23897, 1
  store i8 %23898, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %23899 = add i64 %23880, -476
  %23900 = add i64 %23881, 9
  store i64 %23900, i64* %3, align 8
  %23901 = inttoptr i64 %23899 to i32*
  store i32 %23884, i32* %23901, align 4
  %23902 = load i64, i64* %RBP.i, align 8
  %23903 = add i64 %23902, -628
  %23904 = load i64, i64* %3, align 8
  %23905 = add i64 %23904, 6
  store i64 %23905, i64* %3, align 8
  %23906 = inttoptr i64 %23903 to i32*
  %23907 = load i32, i32* %23906, align 4
  %23908 = zext i32 %23907 to i64
  store i64 %23908, i64* %RAX.i1763, align 8
  %23909 = sext i32 %23907 to i64
  %23910 = lshr i64 %23909, 32
  store i64 %23910, i64* %101, align 8
  %23911 = load i32, i32* %ECX.i7699, align 4
  %23912 = add i64 %23904, 11
  store i64 %23912, i64* %3, align 8
  %23913 = sext i32 %23911 to i64
  %23914 = shl nuw i64 %23910, 32
  %23915 = or i64 %23914, %23908
  %23916 = sdiv i64 %23915, %23913
  %23917 = shl i64 %23916, 32
  %23918 = ashr exact i64 %23917, 32
  %23919 = icmp eq i64 %23916, %23918
  br i1 %23919, label %23922, label %23920

; <label>:23920:                                  ; preds = %routine_idivl__ecx.exit159
  %23921 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %23912, %struct.Memory* %23883)
  %.pre638 = load i64, i64* %RAX.i1763, align 8
  %.pre639 = load i64, i64* %3, align 8
  %.pre640 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__ecx.exit

; <label>:23922:                                  ; preds = %routine_idivl__ecx.exit159
  %23923 = srem i64 %23915, %23913
  %23924 = and i64 %23916, 4294967295
  store i64 %23924, i64* %RAX.i1763, align 8
  %23925 = and i64 %23923, 4294967295
  store i64 %23925, i64* %RDX.i1805, align 8
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %23, align 1
  br label %routine_idivl__ecx.exit

routine_idivl__ecx.exit:                          ; preds = %23922, %23920
  %23926 = phi i64 [ %.pre640, %23920 ], [ %23902, %23922 ]
  %23927 = phi i64 [ %.pre639, %23920 ], [ %23912, %23922 ]
  %23928 = phi i64 [ %.pre638, %23920 ], [ %23924, %23922 ]
  %23929 = phi %struct.Memory* [ %23921, %23920 ], [ %23883, %23922 ]
  %.tr322 = trunc i64 %23928 to i32
  %23930 = shl i32 %.tr322, 2
  %23931 = zext i32 %23930 to i64
  store i64 %23931, i64* %RAX.i1763, align 8
  %23932 = lshr i64 %23928, 30
  %23933 = trunc i64 %23932 to i8
  %23934 = and i8 %23933, 1
  store i8 %23934, i8* %18, align 1
  %23935 = and i32 %23930, 252
  %23936 = tail call i32 @llvm.ctpop.i32(i32 %23935)
  %23937 = trunc i32 %23936 to i8
  %23938 = and i8 %23937, 1
  %23939 = xor i8 %23938, 1
  store i8 %23939, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %23940 = icmp eq i32 %23930, 0
  %23941 = zext i1 %23940 to i8
  store i8 %23941, i8* %21, align 1
  %23942 = lshr i32 %.tr322, 29
  %23943 = trunc i32 %23942 to i8
  %23944 = and i8 %23943, 1
  store i8 %23944, i8* %22, align 1
  store i8 0, i8* %23, align 1
  %23945 = add i64 %23926, -480
  %23946 = add i64 %23927, 9
  store i64 %23946, i64* %3, align 8
  %23947 = inttoptr i64 %23945 to i32*
  store i32 %23930, i32* %23947, align 4
  %23948 = load i64, i64* %RBP.i, align 8
  %23949 = add i64 %23948, -44
  %23950 = load i64, i64* %3, align 8
  %23951 = add i64 %23950, 7
  store i64 %23951, i64* %3, align 8
  %23952 = inttoptr i64 %23949 to i32*
  store i32 0, i32* %23952, align 4
  %.pre641 = load i64, i64* %3, align 8
  br label %block_.L_4a7573

block_.L_4a7573:                                  ; preds = %block_.L_4a7638, %routine_idivl__ecx.exit
  %23953 = phi i64 [ %24413, %block_.L_4a7638 ], [ %.pre641, %routine_idivl__ecx.exit ]
  %23954 = load i64, i64* %RBP.i, align 8
  %23955 = add i64 %23954, -44
  %23956 = add i64 %23953, 4
  store i64 %23956, i64* %3, align 8
  %23957 = inttoptr i64 %23955 to i32*
  %23958 = load i32, i32* %23957, align 4
  %23959 = add i32 %23958, -2
  %23960 = icmp ult i32 %23958, 2
  %23961 = zext i1 %23960 to i8
  store i8 %23961, i8* %18, align 1
  %23962 = and i32 %23959, 255
  %23963 = tail call i32 @llvm.ctpop.i32(i32 %23962)
  %23964 = trunc i32 %23963 to i8
  %23965 = and i8 %23964, 1
  %23966 = xor i8 %23965, 1
  store i8 %23966, i8* %19, align 1
  %23967 = xor i32 %23959, %23958
  %23968 = lshr i32 %23967, 4
  %23969 = trunc i32 %23968 to i8
  %23970 = and i8 %23969, 1
  store i8 %23970, i8* %20, align 1
  %23971 = icmp eq i32 %23959, 0
  %23972 = zext i1 %23971 to i8
  store i8 %23972, i8* %21, align 1
  %23973 = lshr i32 %23959, 31
  %23974 = trunc i32 %23973 to i8
  store i8 %23974, i8* %22, align 1
  %23975 = lshr i32 %23958, 31
  %23976 = xor i32 %23973, %23975
  %23977 = add nuw nsw i32 %23976, %23975
  %23978 = icmp eq i32 %23977, 2
  %23979 = zext i1 %23978 to i8
  store i8 %23979, i8* %23, align 1
  %23980 = icmp ne i8 %23974, 0
  %23981 = xor i1 %23980, %23978
  %.v774 = select i1 %23981, i64 10, i64 216
  %23982 = add i64 %23953, %.v774
  store i64 %23982, i64* %3, align 8
  br i1 %23981, label %block_4a757d, label %block_.L_4a764b

block_4a757d:                                     ; preds = %block_.L_4a7573
  %23983 = add i64 %23954, -60
  %23984 = add i64 %23982, 7
  store i64 %23984, i64* %3, align 8
  %23985 = inttoptr i64 %23983 to i32*
  store i32 0, i32* %23985, align 4
  %.pre642 = load i64, i64* %3, align 8
  br label %block_.L_4a7584

block_.L_4a7584:                                  ; preds = %block_.L_4a7625, %block_4a757d
  %23986 = phi i64 [ %24383, %block_.L_4a7625 ], [ %.pre642, %block_4a757d ]
  %23987 = load i64, i64* %RBP.i, align 8
  %23988 = add i64 %23987, -60
  %23989 = add i64 %23986, 4
  store i64 %23989, i64* %3, align 8
  %23990 = inttoptr i64 %23988 to i32*
  %23991 = load i32, i32* %23990, align 4
  %23992 = add i32 %23991, -4
  %23993 = icmp ult i32 %23991, 4
  %23994 = zext i1 %23993 to i8
  store i8 %23994, i8* %18, align 1
  %23995 = and i32 %23992, 255
  %23996 = tail call i32 @llvm.ctpop.i32(i32 %23995)
  %23997 = trunc i32 %23996 to i8
  %23998 = and i8 %23997, 1
  %23999 = xor i8 %23998, 1
  store i8 %23999, i8* %19, align 1
  %24000 = xor i32 %23992, %23991
  %24001 = lshr i32 %24000, 4
  %24002 = trunc i32 %24001 to i8
  %24003 = and i8 %24002, 1
  store i8 %24003, i8* %20, align 1
  %24004 = icmp eq i32 %23992, 0
  %24005 = zext i1 %24004 to i8
  store i8 %24005, i8* %21, align 1
  %24006 = lshr i32 %23992, 31
  %24007 = trunc i32 %24006 to i8
  store i8 %24007, i8* %22, align 1
  %24008 = lshr i32 %23991, 31
  %24009 = xor i32 %24006, %24008
  %24010 = add nuw nsw i32 %24009, %24008
  %24011 = icmp eq i32 %24010, 2
  %24012 = zext i1 %24011 to i8
  store i8 %24012, i8* %23, align 1
  %24013 = icmp ne i8 %24007, 0
  %24014 = xor i1 %24013, %24011
  %.v775 = select i1 %24014, i64 10, i64 180
  %24015 = add i64 %23986, %.v775
  store i64 %24015, i64* %3, align 8
  br i1 %24014, label %block_4a758e, label %block_.L_4a7638

block_4a758e:                                     ; preds = %block_.L_4a7584
  %24016 = add i64 %23987, -56
  %24017 = add i64 %24015, 7
  store i64 %24017, i64* %3, align 8
  %24018 = inttoptr i64 %24016 to i32*
  store i32 0, i32* %24018, align 4
  %.pre643 = load i64, i64* %3, align 8
  br label %block_.L_4a7595

block_.L_4a7595:                                  ; preds = %block_4a759f, %block_4a758e
  %24019 = phi i64 [ %24353, %block_4a759f ], [ %.pre643, %block_4a758e ]
  %24020 = load i64, i64* %RBP.i, align 8
  %24021 = add i64 %24020, -56
  %24022 = add i64 %24019, 4
  store i64 %24022, i64* %3, align 8
  %24023 = inttoptr i64 %24021 to i32*
  %24024 = load i32, i32* %24023, align 4
  %24025 = add i32 %24024, -4
  %24026 = icmp ult i32 %24024, 4
  %24027 = zext i1 %24026 to i8
  store i8 %24027, i8* %18, align 1
  %24028 = and i32 %24025, 255
  %24029 = tail call i32 @llvm.ctpop.i32(i32 %24028)
  %24030 = trunc i32 %24029 to i8
  %24031 = and i8 %24030, 1
  %24032 = xor i8 %24031, 1
  store i8 %24032, i8* %19, align 1
  %24033 = xor i32 %24025, %24024
  %24034 = lshr i32 %24033, 4
  %24035 = trunc i32 %24034 to i8
  %24036 = and i8 %24035, 1
  store i8 %24036, i8* %20, align 1
  %24037 = icmp eq i32 %24025, 0
  %24038 = zext i1 %24037 to i8
  store i8 %24038, i8* %21, align 1
  %24039 = lshr i32 %24025, 31
  %24040 = trunc i32 %24039 to i8
  store i8 %24040, i8* %22, align 1
  %24041 = lshr i32 %24024, 31
  %24042 = xor i32 %24039, %24041
  %24043 = add nuw nsw i32 %24042, %24041
  %24044 = icmp eq i32 %24043, 2
  %24045 = zext i1 %24044 to i8
  store i8 %24045, i8* %23, align 1
  %24046 = icmp ne i8 %24040, 0
  %24047 = xor i1 %24046, %24044
  %.v776 = select i1 %24047, i64 10, i64 144
  %24048 = add i64 %24019, %.v776
  store i64 %24048, i64* %3, align 8
  br i1 %24047, label %block_4a759f, label %block_.L_4a7625

block_4a759f:                                     ; preds = %block_.L_4a7595
  %24049 = add i64 %24020, -1152
  store i64 %24049, i64* %RAX.i1763, align 8
  %24050 = add i64 %24020, -44
  %24051 = add i64 %24048, 11
  store i64 %24051, i64* %3, align 8
  %24052 = inttoptr i64 %24050 to i32*
  %24053 = load i32, i32* %24052, align 4
  %24054 = sext i32 %24053 to i64
  %24055 = shl nsw i64 %24054, 8
  store i64 %24055, i64* %RCX.i1692, align 8
  %24056 = add i64 %24055, %24049
  store i64 %24056, i64* %RAX.i1763, align 8
  %24057 = icmp ult i64 %24056, %24049
  %24058 = icmp ult i64 %24056, %24055
  %24059 = or i1 %24057, %24058
  %24060 = zext i1 %24059 to i8
  store i8 %24060, i8* %18, align 1
  %24061 = trunc i64 %24056 to i32
  %24062 = and i32 %24061, 255
  %24063 = tail call i32 @llvm.ctpop.i32(i32 %24062)
  %24064 = trunc i32 %24063 to i8
  %24065 = and i8 %24064, 1
  %24066 = xor i8 %24065, 1
  store i8 %24066, i8* %19, align 1
  %24067 = xor i64 %24049, %24056
  %24068 = lshr i64 %24067, 4
  %24069 = trunc i64 %24068 to i8
  %24070 = and i8 %24069, 1
  store i8 %24070, i8* %20, align 1
  %24071 = icmp eq i64 %24056, 0
  %24072 = zext i1 %24071 to i8
  store i8 %24072, i8* %21, align 1
  %24073 = lshr i64 %24056, 63
  %24074 = trunc i64 %24073 to i8
  store i8 %24074, i8* %22, align 1
  %24075 = lshr i64 %24049, 63
  %24076 = lshr i64 %24054, 55
  %24077 = and i64 %24076, 1
  %24078 = xor i64 %24073, %24075
  %24079 = xor i64 %24073, %24077
  %24080 = add nuw nsw i64 %24078, %24079
  %24081 = icmp eq i64 %24080, 2
  %24082 = zext i1 %24081 to i8
  store i8 %24082, i8* %23, align 1
  %24083 = add i64 %24020, -628
  %24084 = add i64 %24048, 25
  store i64 %24084, i64* %3, align 8
  %24085 = inttoptr i64 %24083 to i32*
  %24086 = load i32, i32* %24085, align 4
  %24087 = sext i32 %24086 to i64
  %24088 = shl nsw i64 %24087, 6
  store i64 %24088, i64* %RCX.i1692, align 8
  %24089 = add i64 %24088, %24056
  store i64 %24089, i64* %RAX.i1763, align 8
  %24090 = icmp ult i64 %24089, %24056
  %24091 = icmp ult i64 %24089, %24088
  %24092 = or i1 %24090, %24091
  %24093 = zext i1 %24092 to i8
  store i8 %24093, i8* %18, align 1
  %24094 = trunc i64 %24089 to i32
  %24095 = and i32 %24094, 255
  %24096 = tail call i32 @llvm.ctpop.i32(i32 %24095)
  %24097 = trunc i32 %24096 to i8
  %24098 = and i8 %24097, 1
  %24099 = xor i8 %24098, 1
  store i8 %24099, i8* %19, align 1
  %24100 = xor i64 %24056, %24089
  %24101 = lshr i64 %24100, 4
  %24102 = trunc i64 %24101 to i8
  %24103 = and i8 %24102, 1
  store i8 %24103, i8* %20, align 1
  %24104 = icmp eq i64 %24089, 0
  %24105 = zext i1 %24104 to i8
  store i8 %24105, i8* %21, align 1
  %24106 = lshr i64 %24089, 63
  %24107 = trunc i64 %24106 to i8
  store i8 %24107, i8* %22, align 1
  %24108 = lshr i64 %24087, 57
  %24109 = and i64 %24108, 1
  %24110 = xor i64 %24106, %24073
  %24111 = xor i64 %24106, %24109
  %24112 = add nuw nsw i64 %24110, %24111
  %24113 = icmp eq i64 %24112, 2
  %24114 = zext i1 %24113 to i8
  store i8 %24114, i8* %23, align 1
  %24115 = load i64, i64* %RBP.i, align 8
  %24116 = add i64 %24115, -60
  %24117 = add i64 %24048, 36
  store i64 %24117, i64* %3, align 8
  %24118 = inttoptr i64 %24116 to i32*
  %24119 = load i32, i32* %24118, align 4
  %24120 = sext i32 %24119 to i64
  %24121 = shl nsw i64 %24120, 4
  store i64 %24121, i64* %RCX.i1692, align 8
  %24122 = add i64 %24121, %24089
  store i64 %24122, i64* %RAX.i1763, align 8
  %24123 = icmp ult i64 %24122, %24089
  %24124 = icmp ult i64 %24122, %24121
  %24125 = or i1 %24123, %24124
  %24126 = zext i1 %24125 to i8
  store i8 %24126, i8* %18, align 1
  %24127 = trunc i64 %24122 to i32
  %24128 = and i32 %24127, 255
  %24129 = tail call i32 @llvm.ctpop.i32(i32 %24128)
  %24130 = trunc i32 %24129 to i8
  %24131 = and i8 %24130, 1
  %24132 = xor i8 %24131, 1
  store i8 %24132, i8* %19, align 1
  %24133 = xor i64 %24121, %24089
  %24134 = xor i64 %24133, %24122
  %24135 = lshr i64 %24134, 4
  %24136 = trunc i64 %24135 to i8
  %24137 = and i8 %24136, 1
  store i8 %24137, i8* %20, align 1
  %24138 = icmp eq i64 %24122, 0
  %24139 = zext i1 %24138 to i8
  store i8 %24139, i8* %21, align 1
  %24140 = lshr i64 %24122, 63
  %24141 = trunc i64 %24140 to i8
  store i8 %24141, i8* %22, align 1
  %24142 = lshr i64 %24120, 59
  %24143 = and i64 %24142, 1
  %24144 = xor i64 %24140, %24106
  %24145 = xor i64 %24140, %24143
  %24146 = add nuw nsw i64 %24144, %24145
  %24147 = icmp eq i64 %24146, 2
  %24148 = zext i1 %24147 to i8
  store i8 %24148, i8* %23, align 1
  %24149 = add i64 %24115, -56
  %24150 = add i64 %24048, 47
  store i64 %24150, i64* %3, align 8
  %24151 = inttoptr i64 %24149 to i32*
  %24152 = load i32, i32* %24151, align 4
  %24153 = sext i32 %24152 to i64
  store i64 %24153, i64* %RCX.i1692, align 8
  %24154 = shl nsw i64 %24153, 2
  %24155 = add i64 %24154, %24122
  %24156 = add i64 %24048, 50
  store i64 %24156, i64* %3, align 8
  %24157 = inttoptr i64 %24155 to i32*
  %24158 = load i32, i32* %24157, align 4
  %24159 = zext i32 %24158 to i64
  store i64 %24159, i64* %RDX.i1805, align 8
  %24160 = trunc i32 %24158 to i16
  store i16 %24160, i16* %SI.i86, align 2
  %24161 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %24161, i64* %RAX.i1763, align 8
  %24162 = add i64 %24161, 6464
  %24163 = add i64 %24048, 68
  store i64 %24163, i64* %3, align 8
  %24164 = inttoptr i64 %24162 to i64*
  %24165 = load i64, i64* %24164, align 8
  store i64 %24165, i64* %RAX.i1763, align 8
  %24166 = add i64 %24115, -44
  %24167 = add i64 %24048, 72
  store i64 %24167, i64* %3, align 8
  %24168 = inttoptr i64 %24166 to i32*
  %24169 = load i32, i32* %24168, align 4
  %24170 = sext i32 %24169 to i64
  store i64 %24170, i64* %RCX.i1692, align 8
  %24171 = shl nsw i64 %24170, 3
  %24172 = add i64 %24171, %24165
  %24173 = add i64 %24048, 76
  store i64 %24173, i64* %3, align 8
  %24174 = inttoptr i64 %24172 to i64*
  %24175 = load i64, i64* %24174, align 8
  store i64 %24175, i64* %RAX.i1763, align 8
  %24176 = load i64, i64* %RBP.i, align 8
  %24177 = add i64 %24176, -496
  %24178 = add i64 %24048, 82
  store i64 %24178, i64* %3, align 8
  %24179 = inttoptr i64 %24177 to i32*
  %24180 = load i32, i32* %24179, align 4
  %24181 = zext i32 %24180 to i64
  store i64 %24181, i64* %RDX.i1805, align 8
  %24182 = add i64 %24176, -60
  %24183 = add i64 %24048, 85
  store i64 %24183, i64* %3, align 8
  %24184 = inttoptr i64 %24182 to i32*
  %24185 = load i32, i32* %24184, align 4
  %24186 = add i32 %24185, %24180
  %24187 = zext i32 %24186 to i64
  store i64 %24187, i64* %RDX.i1805, align 8
  %24188 = icmp ult i32 %24186, %24180
  %24189 = icmp ult i32 %24186, %24185
  %24190 = or i1 %24188, %24189
  %24191 = zext i1 %24190 to i8
  store i8 %24191, i8* %18, align 1
  %24192 = and i32 %24186, 255
  %24193 = tail call i32 @llvm.ctpop.i32(i32 %24192)
  %24194 = trunc i32 %24193 to i8
  %24195 = and i8 %24194, 1
  %24196 = xor i8 %24195, 1
  store i8 %24196, i8* %19, align 1
  %24197 = xor i32 %24185, %24180
  %24198 = xor i32 %24197, %24186
  %24199 = lshr i32 %24198, 4
  %24200 = trunc i32 %24199 to i8
  %24201 = and i8 %24200, 1
  store i8 %24201, i8* %20, align 1
  %24202 = icmp eq i32 %24186, 0
  %24203 = zext i1 %24202 to i8
  store i8 %24203, i8* %21, align 1
  %24204 = lshr i32 %24186, 31
  %24205 = trunc i32 %24204 to i8
  store i8 %24205, i8* %22, align 1
  %24206 = lshr i32 %24180, 31
  %24207 = lshr i32 %24185, 31
  %24208 = xor i32 %24204, %24206
  %24209 = xor i32 %24204, %24207
  %24210 = add nuw nsw i32 %24208, %24209
  %24211 = icmp eq i32 %24210, 2
  %24212 = zext i1 %24211 to i8
  store i8 %24212, i8* %23, align 1
  %24213 = add i64 %24176, -480
  %24214 = add i64 %24048, 91
  store i64 %24214, i64* %3, align 8
  %24215 = inttoptr i64 %24213 to i32*
  %24216 = load i32, i32* %24215, align 4
  %24217 = add i32 %24216, %24186
  %24218 = zext i32 %24217 to i64
  store i64 %24218, i64* %RDX.i1805, align 8
  %24219 = icmp ult i32 %24217, %24186
  %24220 = icmp ult i32 %24217, %24216
  %24221 = or i1 %24219, %24220
  %24222 = zext i1 %24221 to i8
  store i8 %24222, i8* %18, align 1
  %24223 = and i32 %24217, 255
  %24224 = tail call i32 @llvm.ctpop.i32(i32 %24223)
  %24225 = trunc i32 %24224 to i8
  %24226 = and i8 %24225, 1
  %24227 = xor i8 %24226, 1
  store i8 %24227, i8* %19, align 1
  %24228 = xor i32 %24216, %24186
  %24229 = xor i32 %24228, %24217
  %24230 = lshr i32 %24229, 4
  %24231 = trunc i32 %24230 to i8
  %24232 = and i8 %24231, 1
  store i8 %24232, i8* %20, align 1
  %24233 = icmp eq i32 %24217, 0
  %24234 = zext i1 %24233 to i8
  store i8 %24234, i8* %21, align 1
  %24235 = lshr i32 %24217, 31
  %24236 = trunc i32 %24235 to i8
  store i8 %24236, i8* %22, align 1
  %24237 = lshr i32 %24216, 31
  %24238 = xor i32 %24235, %24204
  %24239 = xor i32 %24235, %24237
  %24240 = add nuw nsw i32 %24238, %24239
  %24241 = icmp eq i32 %24240, 2
  %24242 = zext i1 %24241 to i8
  store i8 %24242, i8* %23, align 1
  %24243 = sext i32 %24217 to i64
  store i64 %24243, i64* %RCX.i1692, align 8
  %24244 = shl nsw i64 %24243, 3
  %24245 = add i64 %24175, %24244
  %24246 = add i64 %24048, 98
  store i64 %24246, i64* %3, align 8
  %24247 = inttoptr i64 %24245 to i64*
  %24248 = load i64, i64* %24247, align 8
  store i64 %24248, i64* %RAX.i1763, align 8
  %24249 = add i64 %24176, -492
  %24250 = add i64 %24048, 104
  store i64 %24250, i64* %3, align 8
  %24251 = inttoptr i64 %24249 to i32*
  %24252 = load i32, i32* %24251, align 4
  %24253 = zext i32 %24252 to i64
  store i64 %24253, i64* %RDX.i1805, align 8
  %24254 = load i64, i64* %RBP.i, align 8
  %24255 = add i64 %24254, -56
  %24256 = add i64 %24048, 107
  store i64 %24256, i64* %3, align 8
  %24257 = inttoptr i64 %24255 to i32*
  %24258 = load i32, i32* %24257, align 4
  %24259 = add i32 %24258, %24252
  %24260 = zext i32 %24259 to i64
  store i64 %24260, i64* %RDX.i1805, align 8
  %24261 = icmp ult i32 %24259, %24252
  %24262 = icmp ult i32 %24259, %24258
  %24263 = or i1 %24261, %24262
  %24264 = zext i1 %24263 to i8
  store i8 %24264, i8* %18, align 1
  %24265 = and i32 %24259, 255
  %24266 = tail call i32 @llvm.ctpop.i32(i32 %24265)
  %24267 = trunc i32 %24266 to i8
  %24268 = and i8 %24267, 1
  %24269 = xor i8 %24268, 1
  store i8 %24269, i8* %19, align 1
  %24270 = xor i32 %24258, %24252
  %24271 = xor i32 %24270, %24259
  %24272 = lshr i32 %24271, 4
  %24273 = trunc i32 %24272 to i8
  %24274 = and i8 %24273, 1
  store i8 %24274, i8* %20, align 1
  %24275 = icmp eq i32 %24259, 0
  %24276 = zext i1 %24275 to i8
  store i8 %24276, i8* %21, align 1
  %24277 = lshr i32 %24259, 31
  %24278 = trunc i32 %24277 to i8
  store i8 %24278, i8* %22, align 1
  %24279 = lshr i32 %24252, 31
  %24280 = lshr i32 %24258, 31
  %24281 = xor i32 %24277, %24279
  %24282 = xor i32 %24277, %24280
  %24283 = add nuw nsw i32 %24281, %24282
  %24284 = icmp eq i32 %24283, 2
  %24285 = zext i1 %24284 to i8
  store i8 %24285, i8* %23, align 1
  %24286 = add i64 %24254, -476
  %24287 = add i64 %24048, 113
  store i64 %24287, i64* %3, align 8
  %24288 = inttoptr i64 %24286 to i32*
  %24289 = load i32, i32* %24288, align 4
  %24290 = add i32 %24289, %24259
  %24291 = zext i32 %24290 to i64
  store i64 %24291, i64* %RDX.i1805, align 8
  %24292 = icmp ult i32 %24290, %24259
  %24293 = icmp ult i32 %24290, %24289
  %24294 = or i1 %24292, %24293
  %24295 = zext i1 %24294 to i8
  store i8 %24295, i8* %18, align 1
  %24296 = and i32 %24290, 255
  %24297 = tail call i32 @llvm.ctpop.i32(i32 %24296)
  %24298 = trunc i32 %24297 to i8
  %24299 = and i8 %24298, 1
  %24300 = xor i8 %24299, 1
  store i8 %24300, i8* %19, align 1
  %24301 = xor i32 %24289, %24259
  %24302 = xor i32 %24301, %24290
  %24303 = lshr i32 %24302, 4
  %24304 = trunc i32 %24303 to i8
  %24305 = and i8 %24304, 1
  store i8 %24305, i8* %20, align 1
  %24306 = icmp eq i32 %24290, 0
  %24307 = zext i1 %24306 to i8
  store i8 %24307, i8* %21, align 1
  %24308 = lshr i32 %24290, 31
  %24309 = trunc i32 %24308 to i8
  store i8 %24309, i8* %22, align 1
  %24310 = lshr i32 %24289, 31
  %24311 = xor i32 %24308, %24277
  %24312 = xor i32 %24308, %24310
  %24313 = add nuw nsw i32 %24311, %24312
  %24314 = icmp eq i32 %24313, 2
  %24315 = zext i1 %24314 to i8
  store i8 %24315, i8* %23, align 1
  %24316 = sext i32 %24290 to i64
  store i64 %24316, i64* %RCX.i1692, align 8
  %24317 = shl nsw i64 %24316, 1
  %24318 = add i64 %24248, %24317
  %24319 = load i16, i16* %SI.i86, align 2
  %24320 = add i64 %24048, 120
  store i64 %24320, i64* %3, align 8
  %24321 = inttoptr i64 %24318 to i16*
  store i16 %24319, i16* %24321, align 2
  %24322 = load i64, i64* %RBP.i, align 8
  %24323 = add i64 %24322, -56
  %24324 = load i64, i64* %3, align 8
  %24325 = add i64 %24324, 3
  store i64 %24325, i64* %3, align 8
  %24326 = inttoptr i64 %24323 to i32*
  %24327 = load i32, i32* %24326, align 4
  %24328 = add i32 %24327, 1
  %24329 = zext i32 %24328 to i64
  store i64 %24329, i64* %RAX.i1763, align 8
  %24330 = icmp eq i32 %24327, -1
  %24331 = icmp eq i32 %24328, 0
  %24332 = or i1 %24330, %24331
  %24333 = zext i1 %24332 to i8
  store i8 %24333, i8* %18, align 1
  %24334 = and i32 %24328, 255
  %24335 = tail call i32 @llvm.ctpop.i32(i32 %24334)
  %24336 = trunc i32 %24335 to i8
  %24337 = and i8 %24336, 1
  %24338 = xor i8 %24337, 1
  store i8 %24338, i8* %19, align 1
  %24339 = xor i32 %24328, %24327
  %24340 = lshr i32 %24339, 4
  %24341 = trunc i32 %24340 to i8
  %24342 = and i8 %24341, 1
  store i8 %24342, i8* %20, align 1
  %24343 = zext i1 %24331 to i8
  store i8 %24343, i8* %21, align 1
  %24344 = lshr i32 %24328, 31
  %24345 = trunc i32 %24344 to i8
  store i8 %24345, i8* %22, align 1
  %24346 = lshr i32 %24327, 31
  %24347 = xor i32 %24344, %24346
  %24348 = add nuw nsw i32 %24347, %24344
  %24349 = icmp eq i32 %24348, 2
  %24350 = zext i1 %24349 to i8
  store i8 %24350, i8* %23, align 1
  %24351 = add i64 %24324, 9
  store i64 %24351, i64* %3, align 8
  store i32 %24328, i32* %24326, align 4
  %24352 = load i64, i64* %3, align 8
  %24353 = add i64 %24352, -139
  store i64 %24353, i64* %3, align 8
  br label %block_.L_4a7595

block_.L_4a7625:                                  ; preds = %block_.L_4a7595
  %24354 = add i64 %24020, -60
  %24355 = add i64 %24048, 8
  store i64 %24355, i64* %3, align 8
  %24356 = inttoptr i64 %24354 to i32*
  %24357 = load i32, i32* %24356, align 4
  %24358 = add i32 %24357, 1
  %24359 = zext i32 %24358 to i64
  store i64 %24359, i64* %RAX.i1763, align 8
  %24360 = icmp eq i32 %24357, -1
  %24361 = icmp eq i32 %24358, 0
  %24362 = or i1 %24360, %24361
  %24363 = zext i1 %24362 to i8
  store i8 %24363, i8* %18, align 1
  %24364 = and i32 %24358, 255
  %24365 = tail call i32 @llvm.ctpop.i32(i32 %24364)
  %24366 = trunc i32 %24365 to i8
  %24367 = and i8 %24366, 1
  %24368 = xor i8 %24367, 1
  store i8 %24368, i8* %19, align 1
  %24369 = xor i32 %24358, %24357
  %24370 = lshr i32 %24369, 4
  %24371 = trunc i32 %24370 to i8
  %24372 = and i8 %24371, 1
  store i8 %24372, i8* %20, align 1
  %24373 = zext i1 %24361 to i8
  store i8 %24373, i8* %21, align 1
  %24374 = lshr i32 %24358, 31
  %24375 = trunc i32 %24374 to i8
  store i8 %24375, i8* %22, align 1
  %24376 = lshr i32 %24357, 31
  %24377 = xor i32 %24374, %24376
  %24378 = add nuw nsw i32 %24377, %24374
  %24379 = icmp eq i32 %24378, 2
  %24380 = zext i1 %24379 to i8
  store i8 %24380, i8* %23, align 1
  %24381 = add i64 %24048, 14
  store i64 %24381, i64* %3, align 8
  store i32 %24358, i32* %24356, align 4
  %24382 = load i64, i64* %3, align 8
  %24383 = add i64 %24382, -175
  store i64 %24383, i64* %3, align 8
  br label %block_.L_4a7584

block_.L_4a7638:                                  ; preds = %block_.L_4a7584
  %24384 = add i64 %23987, -44
  %24385 = add i64 %24015, 8
  store i64 %24385, i64* %3, align 8
  %24386 = inttoptr i64 %24384 to i32*
  %24387 = load i32, i32* %24386, align 4
  %24388 = add i32 %24387, 1
  %24389 = zext i32 %24388 to i64
  store i64 %24389, i64* %RAX.i1763, align 8
  %24390 = icmp eq i32 %24387, -1
  %24391 = icmp eq i32 %24388, 0
  %24392 = or i1 %24390, %24391
  %24393 = zext i1 %24392 to i8
  store i8 %24393, i8* %18, align 1
  %24394 = and i32 %24388, 255
  %24395 = tail call i32 @llvm.ctpop.i32(i32 %24394)
  %24396 = trunc i32 %24395 to i8
  %24397 = and i8 %24396, 1
  %24398 = xor i8 %24397, 1
  store i8 %24398, i8* %19, align 1
  %24399 = xor i32 %24388, %24387
  %24400 = lshr i32 %24399, 4
  %24401 = trunc i32 %24400 to i8
  %24402 = and i8 %24401, 1
  store i8 %24402, i8* %20, align 1
  %24403 = zext i1 %24391 to i8
  store i8 %24403, i8* %21, align 1
  %24404 = lshr i32 %24388, 31
  %24405 = trunc i32 %24404 to i8
  store i8 %24405, i8* %22, align 1
  %24406 = lshr i32 %24387, 31
  %24407 = xor i32 %24404, %24406
  %24408 = add nuw nsw i32 %24407, %24404
  %24409 = icmp eq i32 %24408, 2
  %24410 = zext i1 %24409 to i8
  store i8 %24410, i8* %23, align 1
  %24411 = add i64 %24015, 14
  store i64 %24411, i64* %3, align 8
  store i32 %24388, i32* %24386, align 4
  %24412 = load i64, i64* %3, align 8
  %24413 = add i64 %24412, -211
  store i64 %24413, i64* %3, align 8
  br label %block_.L_4a7573

block_.L_4a764b:                                  ; preds = %block_.L_4a7573
  %24414 = add i64 %23954, -628
  %24415 = add i64 %23982, 11
  store i64 %24415, i64* %3, align 8
  %24416 = inttoptr i64 %24414 to i32*
  %24417 = load i32, i32* %24416, align 4
  %24418 = add i32 %24417, 1
  %24419 = zext i32 %24418 to i64
  store i64 %24419, i64* %RAX.i1763, align 8
  %24420 = icmp eq i32 %24417, -1
  %24421 = icmp eq i32 %24418, 0
  %24422 = or i1 %24420, %24421
  %24423 = zext i1 %24422 to i8
  store i8 %24423, i8* %18, align 1
  %24424 = and i32 %24418, 255
  %24425 = tail call i32 @llvm.ctpop.i32(i32 %24424)
  %24426 = trunc i32 %24425 to i8
  %24427 = and i8 %24426, 1
  %24428 = xor i8 %24427, 1
  store i8 %24428, i8* %19, align 1
  %24429 = xor i32 %24418, %24417
  %24430 = lshr i32 %24429, 4
  %24431 = trunc i32 %24430 to i8
  %24432 = and i8 %24431, 1
  store i8 %24432, i8* %20, align 1
  %24433 = zext i1 %24421 to i8
  store i8 %24433, i8* %21, align 1
  %24434 = lshr i32 %24418, 31
  %24435 = trunc i32 %24434 to i8
  store i8 %24435, i8* %22, align 1
  %24436 = lshr i32 %24417, 31
  %24437 = xor i32 %24434, %24436
  %24438 = add nuw nsw i32 %24437, %24434
  %24439 = icmp eq i32 %24438, 2
  %24440 = zext i1 %24439 to i8
  store i8 %24440, i8* %23, align 1
  %24441 = add i64 %23982, 20
  store i64 %24441, i64* %3, align 8
  store i32 %24418, i32* %24416, align 4
  %24442 = load i64, i64* %3, align 8
  %24443 = add i64 %24442, -313
  store i64 %24443, i64* %3, align 8
  br label %block_.L_4a7526

block_.L_4a7669.loopexit:                         ; preds = %block_.L_4a7526
  br label %block_.L_4a7669

block_.L_4a7669:                                  ; preds = %block_.L_4a7669.loopexit, %block_.L_4a7507
  %24444 = phi i64 [ %23362, %block_.L_4a7507 ], [ %23819, %block_.L_4a7669.loopexit ]
  %24445 = phi i64 [ %23814, %block_.L_4a7507 ], [ %23848, %block_.L_4a7669.loopexit ]
  %MEMORY.119 = phi %struct.Memory* [ %MEMORY.75, %block_.L_4a7507 ], [ %MEMORY.115, %block_.L_4a7669.loopexit ]
  %24446 = add i64 %24445, 5
  store i64 %24446, i64* %3, align 8
  br label %block_.L_4a766e

block_.L_4a766e:                                  ; preds = %block_.L_4a7669, %block_.L_4a71c1
  %24447 = phi i64 [ %.pre644, %block_.L_4a71c1 ], [ %24444, %block_.L_4a7669 ]
  %storemerge235 = phi i64 [ %22466, %block_.L_4a71c1 ], [ %24446, %block_.L_4a7669 ]
  %MEMORY.120 = phi %struct.Memory* [ %MEMORY.103, %block_.L_4a71c1 ], [ %MEMORY.119, %block_.L_4a7669 ]
  %24448 = add i64 %24447, -76
  %24449 = add i64 %storemerge235, 3
  store i64 %24449, i64* %3, align 8
  %24450 = inttoptr i64 %24448 to i32*
  %24451 = load i32, i32* %24450, align 4
  %24452 = zext i32 %24451 to i64
  store i64 %24452, i64* %RAX.i1763, align 8
  %24453 = load i64, i64* %6, align 8
  %24454 = add i64 %24453, 1480
  store i64 %24454, i64* %6, align 8
  %24455 = icmp ugt i64 %24453, -1481
  %24456 = zext i1 %24455 to i8
  store i8 %24456, i8* %18, align 1
  %24457 = trunc i64 %24454 to i32
  %24458 = and i32 %24457, 255
  %24459 = tail call i32 @llvm.ctpop.i32(i32 %24458)
  %24460 = trunc i32 %24459 to i8
  %24461 = and i8 %24460, 1
  %24462 = xor i8 %24461, 1
  store i8 %24462, i8* %19, align 1
  %24463 = xor i64 %24454, %24453
  %24464 = lshr i64 %24463, 4
  %24465 = trunc i64 %24464 to i8
  %24466 = and i8 %24465, 1
  store i8 %24466, i8* %20, align 1
  %24467 = icmp eq i64 %24454, 0
  %24468 = zext i1 %24467 to i8
  store i8 %24468, i8* %21, align 1
  %24469 = lshr i64 %24454, 63
  %24470 = trunc i64 %24469 to i8
  store i8 %24470, i8* %22, align 1
  %24471 = lshr i64 %24453, 63
  %24472 = xor i64 %24469, %24471
  %24473 = add nuw nsw i64 %24472, %24469
  %24474 = icmp eq i64 %24473, 2
  %24475 = zext i1 %24474 to i8
  store i8 %24475, i8* %23, align 1
  %24476 = add i64 %storemerge235, 11
  store i64 %24476, i64* %3, align 8
  %24477 = add i64 %24453, 1488
  %24478 = inttoptr i64 %24454 to i64*
  %24479 = load i64, i64* %24478, align 8
  store i64 %24479, i64* %RBX.i161, align 8
  store i64 %24477, i64* %6, align 8
  %24480 = add i64 %storemerge235, 12
  store i64 %24480, i64* %3, align 8
  %24481 = add i64 %24453, 1496
  %24482 = inttoptr i64 %24477 to i64*
  %24483 = load i64, i64* %24482, align 8
  store i64 %24483, i64* %RBP.i, align 8
  store i64 %24481, i64* %6, align 8
  %24484 = add i64 %storemerge235, 13
  store i64 %24484, i64* %3, align 8
  %24485 = inttoptr i64 %24481 to i64*
  %24486 = load i64, i64* %24485, align 8
  store i64 %24486, i64* %3, align 8
  %24487 = add i64 %24453, 1504
  store i64 %24487, i64* %6, align 8
  ret %struct.Memory* %MEMORY.120
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_pushq__rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %3, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsp___rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RBP, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_pushq__rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %RBX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %3, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subq__0x5c8___rsp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, -1480
  store i64 %6, i64* %RSP, align 8
  %7 = icmp ult i64 %3, 1480
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %28
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 4294967295, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_xorl__r8d___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 0, i64* %3, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %10, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x240__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -576
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x4___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 4, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_0xd848__rip____xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, ptrtoint (%G_0xd848__rip__type* @G_0xd848__rip_ to i64)
  %5 = add i64 %3, 8
  store i64 %5, i64* %PC, align 8
  %6 = inttoptr i64 %4 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  store i64 %7, i64* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %10 = bitcast i64* %9 to double*
  store double 0.000000e+00, double* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 2, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_xorps__xmm2___xmm2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = bitcast %union.VectorReg* %3 to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %6, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0xc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm0__MINUS0x18__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 5
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsi__MINUS0x20__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %RSI, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x28__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x4c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -76
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm2__MINUS0x1d8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -472
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x484__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1156
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x488__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1160
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cltd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %7 = bitcast %union.anon* %6 to i32*
  %8 = load i32, i32* %7, align 8
  %9 = sext i32 %8 to i64
  %10 = lshr i64 %9, 32
  store i64 %10, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x488__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1160
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__edi(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x3___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 3
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RDX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 29
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 28
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x1e4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -484
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x3___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 3
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RAX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 29
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 28
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1e8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -488
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x98__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 152
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -484
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1ec__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -492
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x9c__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 156
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -488
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1f0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -496
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xa8__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1f4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -500
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xac__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 172
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1f8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -504
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ec__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -492
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x484__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1156
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__r10d(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1fc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -508
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -496
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x200__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -512
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm1__MINUS0x208__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -520
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x726418___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsi__MINUS0x210__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -528
  %5 = load i64, i64* %RSI, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3758__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 14168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0xc__r11____r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x278___r11___r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 632
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %R11, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r11___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R11, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x20c__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 524
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x278__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -632
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xc__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -484
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e8__rbp____ebx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -488
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RBX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x48c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1164
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ebx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0
  %EBX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %EBX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x48c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1164
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.getLuma4x4Neighbour(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__ecx___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RCX, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  store i64 4294967295, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x258__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -600
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xc__r11____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e4__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -484
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x490__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1168
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x490__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__esi(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e8__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -488
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x494__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1172
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r10d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x494__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1172
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0xd8__r9_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = add i64 %3, 216
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a4292(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x258__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -600
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a422f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x11868__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 71784
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x254__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -596
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rcx_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x498__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1176
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a423c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__eax___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x498__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1176
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x498__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1176
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x258__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -600
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x240__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -576
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a4279(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x23c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -572
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x49c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1180
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4286(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x49c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1180
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x49c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1180
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x240__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -576
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 2, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4a0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1184
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %ECX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4a0__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1184
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__ecx(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %ECX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %7, align 1
  %8 = and i32 %4, 255
  %9 = tail call i32 @llvm.ctpop.i32(i32 %8)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %14, align 1
  %15 = icmp eq i32 %4, 0
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %16, i8* %17, align 1
  %18 = lshr i32 %4, 31
  %19 = trunc i32 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %19, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %21, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a430e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a42ed(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 112
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x248__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -584
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax__rcx_8____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x244__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -580
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x4a4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1188
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a42fd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 4294967295, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4a4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1188
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4a4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1188
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x220__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -544
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4363(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a4347(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x68__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 104
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x4a8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1192
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4357(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4a8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1192
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4a8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1192
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4ac__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1196
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4ac__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1196
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %7, align 1
  %8 = and i32 %4, 255
  %9 = tail call i32 @llvm.ctpop.i32(i32 %8)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %14, align 1
  %15 = icmp eq i32 %4, 0
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %16, i8* %17, align 1
  %18 = lshr i32 %4, 31
  %19 = trunc i32 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %19, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %21, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a43df(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a43be(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x230__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -560
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x22c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -556
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x4b0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1200
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a43ce(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4b0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1200
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4b0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1200
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x224__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -548
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4434(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a4418(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x4b4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1204
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4428(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4b4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1204
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4b4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1204
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x220__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -544
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jl_.L_4a444e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = zext i1 %10 to i8
  store i8 %11, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off1, i64 %rel_off2
  %12 = add i64 %.v, %3
  store i64 %12, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x224__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -548
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a445e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4b8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1208
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4499(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x220__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -544
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl_MINUS0x224__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %5, -548
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %4, %10
  %12 = icmp ult i32 %4, %10
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %10, %4
  %22 = xor i32 %21, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %11, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %4, 31
  %34 = lshr i32 %10, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4481(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4bc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1212
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a448d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x224__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -548
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4bc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1212
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4b8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1208
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x214__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -532
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x218__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -536
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x21c__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -540
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x228__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -552
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x20__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x7fffffff____rsi_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = bitcast i64* %RSI to i32**
  %4 = load i32*, i32** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  store i32 2147483647, i32* %4, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ec__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -492
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -496
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.intrapred_luma8x8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x9__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -9
  %10 = icmp ult i32 %8, 9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5f1f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a4549(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a450e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x7__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -7
  %10 = icmp ult i32 %8, 7
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x3__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -3
  %10 = icmp ult i32 %8, 3
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a451b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x218__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -536
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a4549(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -1
  %10 = icmp eq i32 %8, 0
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a452f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a453c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x214__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -532
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x21c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -540
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a5f0c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x9a0__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 2464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a4692(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x34__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4611(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a45fe(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x210__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -528
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f8__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -504
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__ecx___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %ECX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax__rdx_8____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f4__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -500
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rdx_2____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x1cb8___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 7352
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -7353
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x7___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 7
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 57
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 128
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = xor i8 %15, 1
  store i8 %16, i8* %11, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %19 = icmp eq i64 %6, 0
  %20 = zext i1 %19 to i8
  store i8 %20, i8* %18, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %22 = lshr i64 %3, 56
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  store i8 %24, i8* %21, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RAX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rdx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__esi___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x34__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x150__rbp__rax_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RAX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -336
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ECX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 1
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp eq i32 %6, -1
  %10 = icmp eq i32 %7, 0
  %11 = or i1 %9, %10
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1
  %14 = and i32 %7, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i32 %7, %6
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = zext i1 %10 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %7, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %6, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %27
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x34__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x34__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -52
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a457d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4603(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x30__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a456c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x24__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl_MINUS0x228__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %5, -552
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %4, %10
  %12 = icmp ult i32 %4, %10
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %10, %4
  %22 = xor i32 %21, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %11, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %4, 31
  %34 = lshr i32 %10, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a462d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4c0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1216
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4649(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_0xd203__rip____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, ptrtoint (%G_0xd203__rip__type* @G_0xd203__rip_ to i64)
  %5 = add i64 %3, 8
  store i64 %5, i64* %PC, align 8
  %6 = inttoptr i64 %4 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %7, i64* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %10 = bitcast i64* %9 to double*
  store double 0.000000e+00, double* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_mulsd_MINUS0x18__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -24
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 5
  store i64 %7, i64* %PC, align 8
  %8 = bitcast %union.VectorReg* %3 to double*
  %9 = load double, double* %8, align 1
  %10 = inttoptr i64 %5 to double*
  %11 = load double, double* %10, align 8
  %12 = fmul double %9, %11
  store double %12, double* %8, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.floor_plt(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cvttsd2si__xmm0___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = bitcast %union.VectorReg* %3 to double*
  %7 = load double, double* %6, align 1
  %8 = tail call double @llvm.trunc.f64(double %7)
  %9 = tail call double @llvm.fabs.f64(double %8)
  %10 = fcmp ogt double %9, 0x41DFFFFFFFC00000
  %11 = fptosi double %8 to i32
  %12 = zext i32 %11 to i64
  %13 = select i1 %10, i64 2147483648, i64 %12
  store i64 %13, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4c0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1216
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x150__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -336
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x40__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -64
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x18__rcx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.SATD8X8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x40__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x40__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -64
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x20__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl___rcx____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = bitcast i64* %RCX to i32**
  %6 = load i32*, i32** %5, align 8
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = load i32, i32* %6, align 4
  %10 = sub i32 %4, %9
  %11 = icmp ult i32 %4, %9
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1
  %14 = and i32 %10, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i32 %9, %4
  %21 = xor i32 %20, %10
  %22 = lshr i32 %21, 4
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i32 %10, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %10, 31
  %30 = trunc i32 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %4, 31
  %33 = lshr i32 %9, 31
  %34 = xor i32 %33, %32
  %35 = xor i32 %29, %32
  %36 = add nuw nsw i32 %35, %34
  %37 = icmp eq i32 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a468d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x28__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -40
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = bitcast i64* %RCX to i32**
  %5 = load i32*, i32** %4, align 8
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  store i32 %6, i32* %5, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5f07(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11c14__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72724
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a496f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a47bc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a47a9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x7___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 7
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 57
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 128
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = xor i8 %15, 1
  store i8 %16, i8* %11, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %19 = icmp eq i64 %6, 0
  %20 = zext i1 %19 to i8
  store i8 %20, i8* %18, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %22 = lshr i64 %3, 56
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  store i8 %24, i8* %21, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rcx___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RAX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rax__rcx_2____dx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %DX, align 2
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3138___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 12600
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -12601
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -484
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -488
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__dx____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %DX, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -504
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -500
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rcx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rcx_2____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__edi___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EDI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %ESI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a46bf(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a47ae(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a46ae(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__0x0___al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  store i8 0, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.store_coding_state_cs_cm(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x48__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x24__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_MINUS0x18__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 5
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %8, i64* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %11 = bitcast i64* %10 to double*
  store double 0.000000e+00, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_MINUS0x208__rbp____xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -520
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  store i64 %8, i64* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %11 = bitcast i64* %10 to double*
  store double 0.000000e+00, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x228__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -552
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.RDCost_for_8x8IntraBlocks(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm0__MINUS0x1d8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -472
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_ucomisd__xmm0___xmm1(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = bitcast %union.VectorReg* %4 to double*
  %8 = load double, double* %7, align 1
  %9 = bitcast [32 x %union.VectorReg]* %3 to double*
  %10 = load double, double* %9, align 1
  %11 = fcmp uno double %8, %10
  br i1 %11, label %12, label %22

; <label>:12:                                     ; preds = %block_400488
  %13 = fadd double %8, %10
  %14 = bitcast double %13 to i64
  %15 = and i64 %14, 9221120237041090560
  %16 = icmp eq i64 %15, 9218868437227405312
  %17 = and i64 %14, 2251799813685247
  %18 = icmp ne i64 %17, 0
  %19 = and i1 %16, %18
  br i1 %19, label %20, label %28

; <label>:20:                                     ; preds = %12
  %21 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:22:                                     ; preds = %block_400488
  %23 = fcmp ogt double %8, %10
  br i1 %23, label %28, label %24

; <label>:24:                                     ; preds = %22
  %25 = fcmp olt double %8, %10
  br i1 %25, label %28, label %26

; <label>:26:                                     ; preds = %24
  %27 = fcmp oeq double %8, %10
  br i1 %27, label %28, label %35

; <label>:28:                                     ; preds = %26, %24, %22, %12
  %29 = phi i8 [ 0, %22 ], [ 0, %24 ], [ 1, %26 ], [ 1, %12 ]
  %30 = phi i8 [ 0, %22 ], [ 0, %24 ], [ 0, %26 ], [ 1, %12 ]
  %31 = phi i8 [ 0, %22 ], [ 1, %24 ], [ 0, %26 ], [ 1, %12 ]
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %30, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %31, i8* %34, align 1
  br label %35

; <label>:35:                                     ; preds = %28, %26
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %36, align 1
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %37, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %38, align 1
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %35, %20
  %39 = phi %struct.Memory* [ %21, %20 ], [ %2, %35 ]
  ret %struct.Memory* %39
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jbe_.L_4a4963(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %5 = load i8, i8* %4, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %7 = load i8, i8* %6, align 1
  %8 = or i8 %7, %5
  %9 = icmp ne i8 %8, 0
  %10 = zext i1 %9 to i8
  store i8 %10, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %9, i64 %rel_off1, i64 %rel_off2
  %11 = add i64 %.v, %3
  store i64 %11, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a48bb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x41__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -65
  %10 = icmp ult i32 %8, 65
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a48a8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x34__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4895(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3738__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xc__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x34__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cc5f8___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cc5f8_type* @G_0x6cc5f8 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4828(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a489a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4817(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a48ad(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4806(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4947(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4934(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x1d0__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1918__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 6424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f0__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -496
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x3c__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx__rsi_8____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ec__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -492
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x38__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -56
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rcx__rsi_2____di(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %DI = bitcast %union.anon* %3 to i16*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %DI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x3c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x38__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__di____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %DI = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %DI, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x38__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -56
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a48d3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4939(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x3c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a48c2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x48__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -76
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_MINUS0x1d8__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -472
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %8, i64* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %11 = bitcast i64* %10 to double*
  store double 0.000000e+00, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm0__MINUS0x208__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -520
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.reset_coding_state_cs_cm(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5f02(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4bc7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4bb4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x723720___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d40f0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6f6fa0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6f6f90___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = bitcast i64* %RSI to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -504
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi__r8_8____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -500
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rsi__r8_2____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 5
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x2138___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 8504
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -8505
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x278__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -632
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r8___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e4__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -484
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R9D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -44
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r9d___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i32, i32* %R9D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e8__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -488
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R9D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -48
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rsi__r8_2____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %R8, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 5
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__r9d___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %R9D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x264__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x1cb8___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 7352
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -7353
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x7___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 7
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 57
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 128
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = xor i8 %15, 1
  store i8 %16, i8* %11, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %19 = icmp eq i64 %6, 0
  %20 = zext i1 %19 to i8
  store i8 %20, i8* %18, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %22 = lshr i64 %3, 56
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  store i8 %24, i8* %21, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x260__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -608
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x800___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 2048
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -2049
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x25c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x25c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -604
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x264__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %R8, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____r8__rsi_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x264__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -612
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdx__rsi_4____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x1___r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R9D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = shl nuw i64 %6, 32
  %10 = ashr i64 %9, 33
  %11 = trunc i32 %5 to i8
  %12 = and i8 %11, 1
  %13 = trunc i64 %10 to i32
  %14 = and i64 %10, 4294967295
  store i64 %14, i64* %4, align 8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %17 = and i32 %13, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  store i8 %21, i8* %16, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %24 = icmp eq i32 %13, 0
  %25 = zext i1 %24 to i8
  store i8 %25, i8* %23, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %27 = lshr i64 %10, 31
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  store i8 %29, i8* %26, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %30, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__r9d___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %R9D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x270__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x260__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -608
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x270__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rcx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____rsi__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x270__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -624
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rcx__rdx_4____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4987(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4bb9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4976(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4c46(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4c33(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4bdf(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4c38(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4bce(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cvttsd2si__xmm0___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = bitcast %union.VectorReg* %3 to double*
  %7 = load double, double* %6, align 1
  %8 = tail call double @llvm.trunc.f64(double %7)
  %9 = tail call double @llvm.fabs.f64(double %8)
  %10 = fcmp ogt double %9, 0x41DFFFFFFFC00000
  %11 = fptosi double %8 to i32
  %12 = zext i32 %11 to i64
  %13 = select i1 %10, i64 2147483648, i64 %12
  store i64 %13, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x268__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -616
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4d00(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4ced(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x722ff0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4c98(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4cf2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4c87(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x274__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x274__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4fb4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x274__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4c4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1220
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4c4__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1220
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x2___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 2
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RDX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 30
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 252
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 29
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x1dc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -476
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x274__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x2___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 2
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RAX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 30
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 252
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 29
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1e0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -480
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4de6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4dd3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6f6fa0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1dc__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -476
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x30__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e0__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -480
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rdx_4____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx____rax__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %ECX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4d6f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4dd8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4d5e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__edx___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RDX, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x4___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp ugt i32 %6, -5
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x274__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.RDCost_for_4x4Blocks_Chroma(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x268__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -616
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x268__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -616
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4ee7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4ed4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d40f0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6f8f20___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdx__rsi_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1dc__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -476
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r8d___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %R8D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x30__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e0__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -480
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____rcx__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1dc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -476
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x30__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -480
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rcx_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4e1f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4ed9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4e0e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 1, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x8___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 8
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp ugt i32 %6, -9
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4f9b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a4f88(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d2ec0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4f23(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4f8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4f12(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4fa0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x274__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x274__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -628
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4d11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a564a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5637(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d2ec0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x722ff0___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdi___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rsi__rdi_4____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdi__rsi_4____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__r9d___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %6 = load i32, i32* %R8D, align 4
  %7 = load i32, i32* %R9D, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = sub i32 %6, %7
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %6, %7
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %7, %6
  %22 = xor i32 %21, %10
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %10, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %10, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %6, 31
  %34 = lshr i32 %7, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x270__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdx__rsi_4____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x270__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -624
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x260__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -608
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x270__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rsi__rdx_4____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x264__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x264__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl___rcx__rdx_4____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RCX, align 8
  %7 = load i64, i64* %RDX, align 8
  %8 = shl i64 %7, 2
  %9 = add i64 %8, %6
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 4
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %9 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i32 %13, %5
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %4, align 8
  %16 = icmp ult i32 %14, %5
  %17 = icmp ult i32 %14, %13
  %18 = or i1 %16, %17
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1
  %21 = and i32 %14, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21)
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1
  %27 = xor i32 %13, %5
  %28 = xor i32 %27, %14
  %29 = lshr i32 %28, 4
  %30 = trunc i32 %29 to i8
  %31 = and i8 %30, 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %31, i8* %32, align 1
  %33 = icmp eq i32 %14, 0
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %14, 31
  %37 = trunc i32 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %37, i8* %38, align 1
  %39 = lshr i32 %5, 31
  %40 = lshr i32 %13, 31
  %41 = xor i32 %36, %39
  %42 = xor i32 %36, %40
  %43 = add nuw nsw i32 %41, %42
  %44 = icmp eq i32 %43, 2
  %45 = zext i1 %44 to i8
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %45, i8* %46, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x25c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bf0__rcx____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 72688
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x264__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x2138___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 8504
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -8505
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x278__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -632
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e4__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -484
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R10D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -44
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R10D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -48
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rcx__rdx_2____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 5
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__r10d___r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %6 = load i32, i32* %R9D, align 4
  %7 = load i32, i32* %R10D, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__r9d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %EAX, align 4
  %6 = load i32, i32* %R9D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x4c8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1224
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a511c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4cc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1228
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a516a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x264__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -612
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rcx__rdx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__esi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4cc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1228
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4c8__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1224
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__eax___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %ECX, align 4
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5197(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bf0__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72688
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x4d0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1232
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5250(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x264__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -612
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x2138___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 8504
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -8505
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x278__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -632
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -484
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -488
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rdx__rsi_2____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edi___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i32, i32* %EDI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__ecx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %EAX, align 4
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a51f6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4d4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1236
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5244(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4d4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1236
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4d0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1232
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4d0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1232
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__ax___dx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AX = bitcast %union.anon* %3 to i16*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %4 to i16*
  %5 = load i16, i16* %AX, align 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i16 %5, i16* %DX, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi__rdi_8____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__dx____rsi__rdi_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %DX, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bec__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 72684
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x260__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -608
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x7___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 7
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 57
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 128
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = xor i8 %15, 1
  store i8 %16, i8* %11, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %19 = icmp eq i64 %6, 0
  %20 = zext i1 %19 to i8
  store i8 %20, i8* %18, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %22 = lshr i64 %3, 56
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  store i8 %24, i8* %21, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rsi__rdi_2____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 5
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__r9d___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %6 = load i32, i32* %R8D, align 4
  %7 = load i32, i32* %R9D, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__r8d___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %ECX, align 4
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4d8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1240
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a52ef(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4dc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1244
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a532a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x260__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -608
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x1cb8___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 7352
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -7353
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4dc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1244
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4d8__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1240
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5357(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bec__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72684
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x4e0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1248
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a53ea(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x260__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -608
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x1cb8___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 7352
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -7353
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x7___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 7
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 57
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 128
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = xor i8 %15, 1
  store i8 %16, i8* %11, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %19 = icmp eq i64 %6, 0
  %20 = zext i1 %19 to i8
  store i8 %20, i8* %18, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %22 = lshr i64 %3, 56
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  store i8 %24, i8* %21, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a53a3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4e4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1252
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a53de(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4e4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1252
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4e0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1248
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4e0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1248
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1918__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 6424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bf0__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 72688
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x25c__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x278__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -632
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r9d___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %R9D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4e8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1256
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a54a4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4ec__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1260
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a54f9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x25c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -604
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x800___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 2048
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -2049
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4ec__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1260
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4e8__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1256
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5526(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x4f0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1264
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a55ed(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x25c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -604
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x800___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 2048
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -2049
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a558c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4f4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1268
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a55e1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4f4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1268
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4f0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1264
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4f0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1264
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__ax___cx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AX = bitcast %union.anon* %3 to i16*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CX = bitcast %union.anon* %4 to i16*
  %5 = load i16, i16* %AX, align 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i16 %5, i16* %CX, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rdx__rsi_8____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__cx____rdx__rsi_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CX = bitcast %union.anon* %3 to i16*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %CX, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4fd3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a563c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a4fc2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x26c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -620
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a58a2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ec__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -492
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x8___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 8
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RCX, align 8
  %9 = icmp ugt i32 %6, -9
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a588f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x726418___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f0__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -496
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x3c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x38__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1918__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x3c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -496
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x3c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rdx_2____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imull__esi___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = shl i64 %4, 32
  %9 = ashr exact i64 %8, 32
  %10 = sext i32 %5 to i64
  %11 = mul nsw i64 %10, %9
  %12 = trunc i64 %11 to i32
  %13 = and i64 %11, 4294967295
  store i64 %13, i64* %RCX, align 8
  %14 = shl i64 %11, 32
  %15 = ashr exact i64 %14, 32
  %16 = icmp ne i64 %15, %11
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %25, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %26, align 1
  %27 = lshr i32 %12, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %17, i8* %30, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x26c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -620
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x26c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -620
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6f6f90___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = bitcast i64* %RAX to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a566e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5894(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a565b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cvtsi2sdl_MINUS0x26c__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -620
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = sitofp i32 %9 to double
  %11 = bitcast %union.VectorReg* %3 to double*
  store double %10, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_MINUS0x18__rbp____xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 5
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  store i64 %8, i64* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %11 = bitcast i64* %10 to double*
  store double 0.000000e+00, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cvtsi2sdl_MINUS0x268__rbp____xmm2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -616
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = sitofp i32 %9 to double
  %11 = bitcast %union.VectorReg* %3 to double*
  store double %10, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_mulsd__xmm2___xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = bitcast %union.VectorReg* %3 to double*
  %8 = load double, double* %7, align 1
  %9 = bitcast %union.VectorReg* %4 to double*
  %10 = load double, double* %9, align 1
  %11 = fmul double %8, %10
  store double %11, double* %7, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_addsd__xmm1___xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = bitcast [32 x %union.VectorReg]* %3 to double*
  %8 = load double, double* %7, align 1
  %9 = bitcast %union.VectorReg* %4 to double*
  %10 = load double, double* %9, align 1
  %11 = fadd double %8, %10
  store double %11, double* %7, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jbe_.L_4a5efd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %5 = load i8, i8* %4, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %7 = load i8, i8* %6, align 1
  %8 = or i8 %7, %5
  %9 = icmp ne i8 %8, 0
  %10 = zext i1 %9 to i8
  store i8 %10, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %9, i64 %rel_off1, i64 %rel_off2
  %11 = add i64 %.v, %3
  store i64 %11, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a599d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a598a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5977(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a590a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a597c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a58f9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a598f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a58e8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5e55(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4f8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1272
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4f8__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1272
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5a93(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x12__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -18
  %10 = icmp ult i32 %8, 18
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %8, 16
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %8, 31
  %32 = xor i32 %28, %31
  %33 = add nuw nsw i32 %32, %31
  %34 = icmp eq i32 %33, 2
  %35 = zext i1 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %35, i8* %36, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5a80(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6ccb00___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6ccb00_type* @G__0x6ccb00 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3738__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x4___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RDX, align 8
  %9 = icmp ugt i32 %6, -5
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x274__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rcx__rsi_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x274__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x90___rcx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 144
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 240
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x48___rcx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 72
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5a05(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5a85(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a59f4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5b3f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5b2c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x240___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 576
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -577
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x8___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 8
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RDX, align 8
  %9 = icmp ugt i32 %6, -9
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5aab(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5b31(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5a9a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5e3c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d0920___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6cd4f0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6cd4f0_type* @G__0x6cd4f0 to i64), i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x7107b0___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d4600___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r8___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4fc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1276
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %R9D, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0x508__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1288
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4fc__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1276
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__r9d(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %R9D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x1___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = shl i32 %6, 1
  %8 = icmp slt i32 %6, 0
  %9 = icmp slt i32 %7, 0
  %10 = xor i1 %8, %9
  %11 = zext i32 %7 to i64
  store i64 %11, i64* %RDX, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %.lobit = lshr i32 %6, 31
  %13 = trunc i32 %.lobit to i8
  store i8 %13, i8* %12, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %7, 254
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %7, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i32 %6, 30
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %29 = zext i1 %10 to i8
  store i8 %29, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x274__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -628
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x50c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1292
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x50c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1292
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edx___r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %6 = load i32, i32* %R10D, align 4
  %7 = load i32, i32* %EDX, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = shl i32 %6, 1
  %8 = icmp slt i32 %6, 0
  %9 = icmp slt i32 %7, 0
  %10 = xor i1 %8, %9
  %11 = zext i32 %7 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %.lobit = lshr i32 %6, 31
  %13 = trunc i32 %.lobit to i8
  store i8 %13, i8* %12, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %7, 254
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %7, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i32 %6, 30
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %29 = zext i1 %10 to i8
  store i8 %29, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x510__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1296
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x510__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1296
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %6 = load i32, i32* %R10D, align 4
  %7 = load i32, i32* %EAX, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdi__r8_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x514__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1300
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x518__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1304
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x518__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1304
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x51c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1308
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x51c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1308
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x514__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1300
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rsi__rdi_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x508__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1288
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x520__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1312
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x520__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1312
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x524__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1316
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x524__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1316
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdi__rsi_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x528__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1320
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x52c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1324
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x52c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1324
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x530__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1328
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x530__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1328
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x528__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1320
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx__rsi_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5e29(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5e16(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x480__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1152
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx__rdx_8____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -480
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ec__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -492
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x38__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -56
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1dc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -476
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x8___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 8
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 56
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 55
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5d89(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5e1b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5d78(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5e2e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5b46(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5e41(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a59a7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5ee1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5ece(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5e6d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5ed3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5e5c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5f0c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5f11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -36
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a44dc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x28__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 112
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x1fc__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -508
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x200__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -512
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x228__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -552
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl_MINUS0x28__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %5, -40
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %4, %10
  %12 = icmp ult i32 %4, %10
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %10, %4
  %22 = xor i32 %21, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %11, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %4, 31
  %34 = lshr i32 %10, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a5f62(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x534__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1332
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5f97(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a5f7f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x538__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1336
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5f8b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, -1
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp eq i32 %6, 0
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %29
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x538__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1336
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x534__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1332
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3758__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 14168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0xc__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x278___rdx___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 632
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RDX, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x2___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 2
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RSI, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 30
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 252
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 29
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x18c__rcx__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 396
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a60ac(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6099(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x28__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 112
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x88__rdi____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = add i64 %4, 136
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x2___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = shl i32 %5, 2
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %4, align 8
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %11 = lshr i32 %5, 30
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  store i8 %13, i8* %10, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %8, 252
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %8, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i32 %5, 29
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__r8d___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %R8D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x53c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1340
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %R8D, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0x548__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1352
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x53c__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1340
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__r8d(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %R8D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edx___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EDX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x548__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1352
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___r9__rdi_8____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x30__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___r10(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %R10, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x8c__r10____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %3 = load i64, i64* %R10, align 8
  %4 = add i64 %3, 140
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__esi___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x54c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1356
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x54c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1356
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EAX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___r10(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R10, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx____rdi__r10_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i64, i64* %R10, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %ECX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5fea(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a609e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a5fd9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a71c6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4a6204(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a61eb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a61d8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a60ee(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a61dd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a60dd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x44__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -68
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.dct_luma8x8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a71c1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a64d9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a64c6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rsi__rdi_2____r8w(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8W = bitcast %union.anon* %3 to i16*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 5
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %R8W, align 2
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3138___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 12600
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -12601
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__r8w____rsi__rdi_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8W = bitcast %union.anon* %3 to i16*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %R8W, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 5
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f8__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -504
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f4__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -500
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rsi__rdi_2____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 5
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__r10d___r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %6 = load i32, i32* %R9D, align 4
  %7 = load i32, i32* %R10D, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = sub i32 %6, %7
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %6, %7
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %7, %6
  %22 = xor i32 %21, %10
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %10, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %10, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %6, 31
  %34 = lshr i32 %7, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d__MINUS0x264__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i32, i32* %R9D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d__MINUS0x260__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -608
  %6 = load i32, i32* %R9D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d__MINUS0x25c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i32, i32* %R9D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x25c__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x264__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R9D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -612
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sub i32 %5, %11
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %5, %11
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %12, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %11, %5
  %24 = xor i32 %23, %12
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %12, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %12, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %5, 31
  %36 = lshr i32 %11, 31
  %37 = xor i32 %36, %35
  %38 = xor i32 %32, %35
  %39 = add nuw nsw i32 %38, %37
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d____rdi__rsi_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %R9D, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdx__rsi_4____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x1___r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R10D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = shl nuw i64 %6, 32
  %10 = ashr i64 %9, 33
  %11 = trunc i32 %5 to i8
  %12 = and i8 %11, 1
  %13 = trunc i64 %10 to i32
  %14 = and i64 %10, 4294967295
  store i64 %14, i64* %4, align 8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %17 = and i32 %13, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  store i8 %21, i8* %16, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %24 = icmp eq i32 %13, 0
  %25 = zext i1 %24 to i8
  store i8 %25, i8* %23, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %27 = lshr i64 %10, 31
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  store i8 %29, i8* %26, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %30, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d__MINUS0x270__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i32, i32* %R9D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x260__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -608
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x270__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R9D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -624
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sub i32 %5, %11
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %5, %11
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %12, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %11, %5
  %24 = xor i32 %23, %12
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %12, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %12, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %5, 31
  %36 = lshr i32 %11, 31
  %37 = xor i32 %36, %35
  %38 = xor i32 %32, %35
  %39 = add nuw nsw i32 %38, %37
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d____rsi__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %R9D, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x270__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rcx__rdx_4____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %R9D, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a621c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a64cb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a620b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6558(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6545(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a64f1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a654a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a64e0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a65ec(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a65d9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6584(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a65de(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6573(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6b2d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x550__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1360
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x550__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1360
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a66cb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a66b8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6654(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a66bd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6643(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__edi___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.dct_chroma4x4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x7107b0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d4600___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d0920___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x554__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1364
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x558__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1368
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x558__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1368
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x274__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x55c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1372
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x55c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1372
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edx___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %EDX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___r10(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R10, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___r10(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %3 = load i64, i64* %R10, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %R10, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r10___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %R10, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %R9, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x560__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1376
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x560__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1376
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %EAX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x554__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1364
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____r9__r10_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %R9, align 8
  %5 = load i64, i64* %R10, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x564__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1380
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x564__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1380
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %R9, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r9___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %R9, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %R8, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x568__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1384
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x568__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1384
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___r8__r9_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %R9, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x56c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1388
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x570__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1392
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x570__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1392
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r8___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x574__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1396
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x574__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1396
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x56c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1388
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx__r8_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %R8, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6910(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a68fd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6848(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6902(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6837(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 1, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x40___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 64
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -65
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x40___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 64
  store i64 %6, i64* %R8, align 8
  %7 = icmp ugt i64 %3, -65
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x40___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 64
  store i64 %6, i64* %R9, align 8
  %7 = icmp ugt i64 %3, -65
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x578__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1400
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x57c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1404
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x57c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1404
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x580__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1408
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x580__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1408
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x584__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1412
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x584__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1412
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x578__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1400
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x588__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1416
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x588__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1416
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x58c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1420
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x58c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1420
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x590__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1424
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x594__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1428
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x594__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1428
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x598__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1432
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x598__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1432
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x590__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6b14(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6b01(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6a9c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6b06(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6a8b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6b19(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a65f6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a71bc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a71a9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x59c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1436
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a6c8e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5a0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1440
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6cdc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5a0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1440
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x59c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1436
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6d09(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x5a4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1444
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6dc2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a6d68(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5a8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1448
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6db6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5a8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1448
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5a4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1444
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5a4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1444
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5ac__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1452
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a6e61(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5b0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1456
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6e9c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5b0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1456
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5ac__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1452
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a6ec9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x5b4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1460
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6f5c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a6f15(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5b8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1464
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6f50(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5b8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5b4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1460
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5b4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1460
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5bc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1468
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a7016(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5c0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1472
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a706b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5c0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1472
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5bc__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1468
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7098(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x5c4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1476
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a715f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4a70fe(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5c8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1480
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7153(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5c8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1480
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5c4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1476
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5c4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1476
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6b45(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a71ae(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a6b34(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a766e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7282(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a726f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a725c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a71ef(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7261(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a71de(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7274(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a71cd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a741e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7419(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7354(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7341(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x4___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RSI, align 8
  %9 = icmp ugt i32 %6, -5
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a72c6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7346(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a72b5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7400(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a73ed(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x8___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 8
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RSI, align 8
  %9 = icmp ugt i32 %6, -9
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a736c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a73f2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a735b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7405(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a72a1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a741e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7507(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a74f4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7436(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a74f9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7425(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4a7669(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7664(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5cc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -1484
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5cc__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -1484
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a764b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7638(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4a7625(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__dx___si(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %4 to i16*
  %5 = load i16, i16* %DX, align 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i16 %5, i16* %SI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e0__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -480
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1dc__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -476
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__si____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %SI, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7595(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a762a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7584(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a763d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7573(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7650(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7526(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4a7669(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -76
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x5c8___rsp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 1480
  store i64 %6, i64* %RSP, align 8
  %7 = icmp ugt i64 %3, -1481
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_popq__rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 8
  %8 = inttoptr i64 %6 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %RBX, align 8
  store i64 %7, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_popq__rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 8
  %8 = inttoptr i64 %6 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %RBP, align 8
  store i64 %7, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_retq(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = inttoptr i64 %6 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %PC, align 8
  %9 = add i64 %6, 8
  store i64 %9, i64* %5, align 8
  ret %struct.Memory* %2
}

attributes #0 = { nounwind readnone }
attributes #1 = { alwaysinline }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
