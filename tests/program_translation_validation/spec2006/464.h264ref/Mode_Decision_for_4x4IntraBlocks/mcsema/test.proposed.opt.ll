; ModuleID = 'mcsema/test.proposed.inline.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%__bss_start_type = type <{ [8 x i8] }>
%G_0x2d89e__rip__type = type <{ [8 x i8] }>
%G_0x2def0__rip__type = type <{ [8 x i8] }>
%G_0x2e030__rip__type = type <{ [8 x i8] }>
%G_0x3964c__rip__type = type <{ [16 x i8] }>
%G_0x6cb8f8_type = type <{ [8 x i8] }>
%G_0x6cb900_type = type <{ [8 x i8] }>
%G_0x6cc608_type = type <{ [8 x i8] }>
%G_0x6cc628_type = type <{ [8 x i8] }>
%G_0x6f6f90_type = type <{ [8 x i8] }>
%G_0x70fcf0_type = type <{ [8 x i8] }>
%G_0x726418_type = type <{ [8 x i8] }>
%G__0x6cd4f0_type = type <{ [8 x i8] }>
%G__0x6d0920_type = type <{ [8 x i8] }>
%G__0x6d2ec0_type = type <{ [8 x i8] }>
%G__0x6d40f0_type = type <{ [8 x i8] }>
%G__0x6d4600_type = type <{ [8 x i8] }>
%G__0x6f6fa0_type = type <{ [8 x i8] }>
%G__0x6f8f20_type = type <{ [8 x i8] }>
%G__0x6f9560_type = type <{ [8 x i8] }>
%G__0x7107b0_type = type <{ [8 x i8] }>
%G__0x722ff0_type = type <{ [8 x i8] }>
%G__0x723720_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.anon = type { i64 }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque

@__bss_start = local_unnamed_addr global %__bss_start_type zeroinitializer
@G_0x2d89e__rip_ = global %G_0x2d89e__rip__type zeroinitializer
@G_0x2def0__rip_ = global %G_0x2def0__rip__type zeroinitializer
@G_0x2e030__rip_ = global %G_0x2e030__rip__type zeroinitializer
@G_0x3964c__rip_ = global %G_0x3964c__rip__type zeroinitializer
@G_0x6cb8f8 = local_unnamed_addr global %G_0x6cb8f8_type zeroinitializer
@G_0x6cb900 = local_unnamed_addr global %G_0x6cb900_type zeroinitializer
@G_0x6cc608 = local_unnamed_addr global %G_0x6cc608_type zeroinitializer
@G_0x6cc628 = local_unnamed_addr global %G_0x6cc628_type zeroinitializer
@G_0x6f6f90 = local_unnamed_addr global %G_0x6f6f90_type zeroinitializer
@G_0x70fcf0 = local_unnamed_addr global %G_0x70fcf0_type zeroinitializer
@G_0x726418 = local_unnamed_addr global %G_0x726418_type zeroinitializer
@G__0x6cd4f0 = global %G__0x6cd4f0_type zeroinitializer
@G__0x6d0920 = global %G__0x6d0920_type zeroinitializer
@G__0x6d2ec0 = global %G__0x6d2ec0_type zeroinitializer
@G__0x6d40f0 = global %G__0x6d40f0_type zeroinitializer
@G__0x6d4600 = global %G__0x6d4600_type zeroinitializer
@G__0x6f6fa0 = global %G__0x6f6fa0_type zeroinitializer
@G__0x6f8f20 = global %G__0x6f8f20_type zeroinitializer
@G__0x6f9560 = global %G__0x6f9560_type zeroinitializer
@G__0x7107b0 = global %G__0x7107b0_type zeroinitializer
@G__0x722ff0 = global %G__0x722ff0_type zeroinitializer
@G__0x723720 = global %G__0x723720_type zeroinitializer

declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

; Function Attrs: nounwind readnone
declare double @llvm.fabs.f64(double) #0

; Function Attrs: nounwind readnone
declare double @llvm.trunc.f64(double) #0

declare extern_weak x86_64_sysvcc i64 @floor(i64)

declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr

declare %struct.Memory* @sub_44b230.getLuma4x4Neighbour(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4025b0.intrapred_luma(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_45f180.SATD(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_49d8c0.store_coding_state(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4830e0.RDCost_for_4x4IntraBlocks(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_49dc00.reset_coding_state(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_483520.RDCost_for_4x4Blocks_Chroma(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_406250.dct_luma(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_40acc0.dct_chroma4x4(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: alwaysinline
define %struct.Memory* @Mode_Decision_for_4x4IntraBlocks(%struct.State* noalias, i64, %struct.Memory* noalias) local_unnamed_addr #1 {
entry:
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP.i = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP.i, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %3, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  %10 = load i64, i64* %3, align 8
  store i64 %8, i64* %RBP.i, align 8
  %RBX.i1545 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %11 = load i64, i64* %RBX.i1545, align 8
  %12 = add i64 %10, 4
  store i64 %12, i64* %3, align 8
  %13 = add i64 %7, -16
  %14 = inttoptr i64 %13 to i64*
  store i64 %11, i64* %14, align 8
  %15 = load i64, i64* %3, align 8
  %16 = add i64 %7, -792
  store i64 %16, i64* %6, align 8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %RCX.i1588 = getelementptr inbounds %union.anon, %union.anon* %23, i64 0, i32 0
  store i64 4294967295, i64* %RCX.i1588, align 8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D.i1615 = bitcast %union.anon* %24 to i32*
  %25 = getelementptr inbounds %union.anon, %union.anon* %24, i64 0, i32 0
  store i64 0, i64* %25, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9.i1633 = getelementptr inbounds %union.anon, %union.anon* %26, i64 0, i32 0
  %27 = load i64, i64* %RBP.i, align 8
  %28 = add i64 %27, -312
  store i64 %28, i64* %R9.i1633, align 8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %RAX.i1659 = getelementptr inbounds %union.anon, %union.anon* %29, i64 0, i32 0
  store i64 4, i64* %RAX.i1659, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %31 = bitcast %union.VectorReg* %30 to i8*
  %32 = add i64 %15, add (i64 ptrtoint (%G_0x2e030__rip__type* @G_0x2e030__rip_ to i64), i64 27)
  %33 = add i64 %15, 35
  store i64 %33, i64* %3, align 8
  %34 = inttoptr i64 %32 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = bitcast %union.VectorReg* %30 to double*
  %37 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %30, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %35, i64* %37, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %39 = bitcast i64* %38 to double*
  store double 0.000000e+00, double* %39, align 1
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %41 = add i64 %15, add (i64 ptrtoint (%G_0x2def0__rip__type* @G_0x2def0__rip_ to i64), i64 35)
  %42 = add i64 %15, 43
  store i64 %42, i64* %3, align 8
  %43 = inttoptr i64 %41 to i64*
  %44 = load i64, i64* %43, align 8
  %45 = bitcast %union.VectorReg* %40 to double*
  %46 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %40, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %44, i64* %46, align 1
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %48 = bitcast i64* %47 to double*
  store double 0.000000e+00, double* %48, align 1
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D.i1715 = bitcast %union.anon* %49 to i32*
  %50 = getelementptr inbounds %union.anon, %union.anon* %49, i64 0, i32 0
  store i64 2, i64* %50, align 8
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI.i1741 = bitcast %union.anon* %51 to i32*
  %52 = add i64 %27, -12
  %53 = load i32, i32* %EDI.i1741, align 4
  %54 = add i64 %15, 52
  store i64 %54, i64* %3, align 8
  %55 = inttoptr i64 %52 to i32*
  store i32 %53, i32* %55, align 4
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI.i1759 = bitcast %union.anon* %56 to i32*
  %57 = load i64, i64* %RBP.i, align 8
  %58 = add i64 %57, -16
  %59 = load i32, i32* %ESI.i1759, align 4
  %60 = load i64, i64* %3, align 8
  %61 = add i64 %60, 3
  store i64 %61, i64* %3, align 8
  %62 = inttoptr i64 %58 to i32*
  store i32 %59, i32* %62, align 4
  %63 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %64 = load i64, i64* %RBP.i, align 8
  %65 = add i64 %64, -24
  %66 = load i64, i64* %3, align 8
  %67 = add i64 %66, 5
  store i64 %67, i64* %3, align 8
  %68 = bitcast %union.VectorReg* %63 to double*
  %69 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %63, i64 0, i32 0, i32 0, i32 0, i64 0
  %70 = load i64, i64* %69, align 1
  %71 = inttoptr i64 %65 to i64*
  store i64 %70, i64* %71, align 8
  %72 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %RDX.i1943 = getelementptr inbounds %union.anon, %union.anon* %72, i64 0, i32 0
  %73 = load i64, i64* %RBP.i, align 8
  %74 = add i64 %73, -32
  %75 = load i64, i64* %RDX.i1943, align 8
  %76 = load i64, i64* %3, align 8
  %77 = add i64 %76, 4
  store i64 %77, i64* %3, align 8
  %78 = inttoptr i64 %74 to i64*
  store i64 %75, i64* %78, align 8
  %79 = load i64, i64* %RBP.i, align 8
  %80 = add i64 %79, -40
  %81 = load i64, i64* %3, align 8
  %82 = add i64 %81, 7
  store i64 %82, i64* %3, align 8
  %83 = inttoptr i64 %80 to i32*
  store i32 0, i32* %83, align 4
  %84 = load i64, i64* %RBP.i, align 8
  %85 = add i64 %84, -76
  %86 = load i64, i64* %3, align 8
  %87 = add i64 %86, 7
  store i64 %87, i64* %3, align 8
  %88 = inttoptr i64 %85 to i32*
  store i32 0, i32* %88, align 4
  %RSI.i2015 = getelementptr inbounds %union.anon, %union.anon* %56, i64 0, i32 0
  %89 = load i64, i64* %RBP.i, align 8
  %90 = add i64 %89, -12
  %91 = load i64, i64* %3, align 8
  %92 = add i64 %91, 3
  store i64 %92, i64* %3, align 8
  %93 = inttoptr i64 %90 to i32*
  %94 = load i32, i32* %93, align 4
  %95 = zext i32 %94 to i64
  store i64 %95, i64* %RSI.i2015, align 8
  %EAX.i2033 = bitcast %union.anon* %29 to i32*
  %96 = add i64 %89, -504
  %97 = load i32, i32* %EAX.i2033, align 4
  %98 = add i64 %91, 9
  store i64 %98, i64* %3, align 8
  %99 = inttoptr i64 %96 to i32*
  store i32 %97, i32* %99, align 4
  %100 = load i32, i32* %ESI.i1759, align 4
  %101 = zext i32 %100 to i64
  %102 = load i64, i64* %3, align 8
  store i64 %101, i64* %RAX.i1659, align 8
  %103 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %104 = sext i32 %100 to i64
  %105 = lshr i64 %104, 32
  store i64 %105, i64* %103, align 8
  %106 = load i32, i32* %R10D.i1715, align 4
  %107 = add i64 %102, 6
  store i64 %107, i64* %3, align 8
  %108 = bitcast %union.anon* %72 to i32*
  %109 = sext i32 %106 to i64
  %110 = shl nuw i64 %105, 32
  %111 = or i64 %110, %101
  %112 = sdiv i64 %111, %109
  %113 = shl i64 %112, 32
  %114 = ashr exact i64 %113, 32
  %115 = icmp eq i64 %112, %114
  br i1 %115, label %118, label %116

; <label>:116:                                    ; preds = %entry
  %117 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %107, %struct.Memory* %2)
  %.pre = load i64, i64* %RDX.i1943, align 8
  %.pre441 = load i64, i64* %3, align 8
  br label %routine_idivl__r10d.exit

; <label>:118:                                    ; preds = %entry
  %119 = srem i64 %111, %109
  %120 = and i64 %112, 4294967295
  store i64 %120, i64* %RAX.i1659, align 8
  %121 = and i64 %119, 4294967295
  store i64 %121, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r10d.exit

routine_idivl__r10d.exit:                         ; preds = %118, %116
  %122 = phi i64 [ %.pre441, %116 ], [ %107, %118 ]
  %123 = phi i64 [ %.pre, %116 ], [ %121, %118 ]
  %124 = phi %struct.Memory* [ %117, %116 ], [ %2, %118 ]
  %.tr = trunc i64 %123 to i32
  %125 = shl i32 %.tr, 3
  %126 = zext i32 %125 to i64
  store i64 %126, i64* %RDX.i1943, align 8
  %127 = lshr i64 %123, 29
  %128 = trunc i64 %127 to i8
  %129 = and i8 %128, 1
  store i8 %129, i8* %17, align 1
  %130 = and i32 %125, 248
  %131 = tail call i32 @llvm.ctpop.i32(i32 %130)
  %132 = trunc i32 %131 to i8
  %133 = and i8 %132, 1
  %134 = xor i8 %133, 1
  store i8 %134, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %135 = icmp eq i32 %125, 0
  %136 = zext i1 %135 to i8
  store i8 %136, i8* %20, align 1
  %137 = lshr i32 %.tr, 28
  %138 = trunc i32 %137 to i8
  %139 = and i8 %138, 1
  store i8 %139, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %140 = load i64, i64* %RBP.i, align 8
  %141 = add i64 %140, -16
  %142 = add i64 %122, 6
  store i64 %142, i64* %3, align 8
  %143 = inttoptr i64 %141 to i32*
  %144 = load i32, i32* %143, align 4
  %145 = zext i32 %144 to i64
  store i64 %145, i64* %RSI.i2015, align 8
  store i64 %145, i64* %RAX.i1659, align 8
  %146 = add i64 %140, -508
  %147 = add i64 %122, 14
  store i64 %147, i64* %3, align 8
  %148 = inttoptr i64 %146 to i32*
  store i32 %125, i32* %148, align 4
  %149 = load i64, i64* %3, align 8
  %150 = load i32, i32* %EAX.i2033, align 8
  %151 = sext i32 %150 to i64
  %152 = lshr i64 %151, 32
  store i64 %152, i64* %103, align 8
  %153 = load i32, i32* %R10D.i1715, align 4
  %154 = add i64 %149, 4
  store i64 %154, i64* %3, align 8
  %155 = zext i32 %150 to i64
  %156 = sext i32 %153 to i64
  %157 = shl nuw i64 %152, 32
  %158 = or i64 %157, %155
  %159 = sdiv i64 %158, %156
  %160 = shl i64 %159, 32
  %161 = ashr exact i64 %160, 32
  %162 = icmp eq i64 %159, %161
  br i1 %162, label %165, label %163

; <label>:163:                                    ; preds = %routine_idivl__r10d.exit
  %164 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %154, %struct.Memory* %124)
  %.pre442 = load i64, i64* %RDX.i1943, align 8
  %.pre443 = load i64, i64* %3, align 8
  br label %routine_idivl__r10d.exit3268

; <label>:165:                                    ; preds = %routine_idivl__r10d.exit
  %166 = srem i64 %158, %156
  %167 = and i64 %159, 4294967295
  store i64 %167, i64* %RAX.i1659, align 8
  %168 = and i64 %166, 4294967295
  store i64 %168, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r10d.exit3268

routine_idivl__r10d.exit3268:                     ; preds = %165, %163
  %169 = phi i64 [ %.pre443, %163 ], [ %154, %165 ]
  %170 = phi i64 [ %.pre442, %163 ], [ %168, %165 ]
  %171 = phi %struct.Memory* [ %164, %163 ], [ %124, %165 ]
  %.tr118 = trunc i64 %170 to i32
  %172 = shl i32 %.tr118, 2
  %173 = zext i32 %172 to i64
  store i64 %173, i64* %RDX.i1943, align 8
  %174 = lshr i64 %170, 30
  %175 = trunc i64 %174 to i8
  %176 = and i8 %175, 1
  store i8 %176, i8* %17, align 1
  %177 = and i32 %172, 252
  %178 = tail call i32 @llvm.ctpop.i32(i32 %177)
  %179 = trunc i32 %178 to i8
  %180 = and i8 %179, 1
  %181 = xor i8 %180, 1
  store i8 %181, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %182 = icmp eq i32 %172, 0
  %183 = zext i1 %182 to i8
  store i8 %183, i8* %20, align 1
  %184 = lshr i32 %.tr118, 29
  %185 = trunc i32 %184 to i8
  %186 = and i8 %185, 1
  store i8 %186, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %187 = load i64, i64* %RBP.i, align 8
  %188 = add i64 %187, -508
  %189 = add i64 %169, 9
  store i64 %189, i64* %3, align 8
  %190 = inttoptr i64 %188 to i32*
  %191 = load i32, i32* %190, align 4
  %192 = add i32 %172, %191
  %193 = zext i32 %192 to i64
  store i64 %193, i64* %RSI.i2015, align 8
  %194 = icmp ult i32 %192, %191
  %195 = icmp ult i32 %192, %172
  %196 = or i1 %194, %195
  %197 = zext i1 %196 to i8
  store i8 %197, i8* %17, align 1
  %198 = and i32 %192, 255
  %199 = tail call i32 @llvm.ctpop.i32(i32 %198)
  %200 = trunc i32 %199 to i8
  %201 = and i8 %200, 1
  %202 = xor i8 %201, 1
  store i8 %202, i8* %18, align 1
  %203 = xor i32 %172, %191
  %204 = xor i32 %203, %192
  %205 = lshr i32 %204, 4
  %206 = trunc i32 %205 to i8
  %207 = and i8 %206, 1
  store i8 %207, i8* %19, align 1
  %208 = icmp eq i32 %192, 0
  %209 = zext i1 %208 to i8
  store i8 %209, i8* %20, align 1
  %210 = lshr i32 %192, 31
  %211 = trunc i32 %210 to i8
  store i8 %211, i8* %21, align 1
  %212 = lshr i32 %191, 31
  %213 = lshr i32 %.tr118, 29
  %214 = and i32 %213, 1
  %215 = xor i32 %210, %212
  %216 = xor i32 %210, %214
  %217 = add nuw nsw i32 %215, %216
  %218 = icmp eq i32 %217, 2
  %219 = zext i1 %218 to i8
  store i8 %219, i8* %22, align 1
  %220 = add i64 %187, -220
  %221 = add i64 %169, 17
  store i64 %221, i64* %3, align 8
  %222 = inttoptr i64 %220 to i32*
  store i32 %192, i32* %222, align 4
  %223 = load i64, i64* %RBP.i, align 8
  %224 = add i64 %223, -12
  %225 = load i64, i64* %3, align 8
  %226 = add i64 %225, 3
  store i64 %226, i64* %3, align 8
  %227 = inttoptr i64 %224 to i32*
  %228 = load i32, i32* %227, align 4
  %229 = zext i32 %228 to i64
  store i64 %229, i64* %RAX.i1659, align 8
  %230 = sext i32 %228 to i64
  %231 = lshr i64 %230, 32
  store i64 %231, i64* %103, align 8
  %232 = load i32, i32* %R10D.i1715, align 4
  %233 = add i64 %225, 9
  store i64 %233, i64* %3, align 8
  %234 = sext i32 %232 to i64
  %235 = shl nuw i64 %231, 32
  %236 = or i64 %235, %229
  %237 = sdiv i64 %236, %234
  %238 = shl i64 %237, 32
  %239 = ashr exact i64 %238, 32
  %240 = icmp eq i64 %237, %239
  br i1 %240, label %243, label %241

; <label>:241:                                    ; preds = %routine_idivl__r10d.exit3268
  %242 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %233, %struct.Memory* %171)
  %.pre444 = load i64, i64* %RAX.i1659, align 8
  %.pre445 = load i64, i64* %3, align 8
  %.pre446 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r10d.exit3450

; <label>:243:                                    ; preds = %routine_idivl__r10d.exit3268
  %244 = srem i64 %236, %234
  %245 = and i64 %237, 4294967295
  store i64 %245, i64* %RAX.i1659, align 8
  %246 = and i64 %244, 4294967295
  store i64 %246, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r10d.exit3450

routine_idivl__r10d.exit3450:                     ; preds = %243, %241
  %247 = phi i64 [ %.pre446, %241 ], [ %223, %243 ]
  %248 = phi i64 [ %.pre445, %241 ], [ %233, %243 ]
  %249 = phi i64 [ %.pre444, %241 ], [ %245, %243 ]
  %250 = phi %struct.Memory* [ %242, %241 ], [ %171, %243 ]
  %.tr120 = trunc i64 %249 to i32
  %251 = shl i32 %.tr120, 3
  %252 = zext i32 %251 to i64
  store i64 %252, i64* %RAX.i1659, align 8
  %253 = lshr i64 %249, 29
  %254 = trunc i64 %253 to i8
  %255 = and i8 %254, 1
  store i8 %255, i8* %17, align 1
  %256 = and i32 %251, 248
  %257 = tail call i32 @llvm.ctpop.i32(i32 %256)
  %258 = trunc i32 %257 to i8
  %259 = and i8 %258, 1
  %260 = xor i8 %259, 1
  store i8 %260, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %261 = icmp eq i32 %251, 0
  %262 = zext i1 %261 to i8
  store i8 %262, i8* %20, align 1
  %263 = lshr i32 %.tr120, 28
  %264 = trunc i32 %263 to i8
  %265 = and i8 %264, 1
  store i8 %265, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %266 = add i64 %247, -16
  %267 = add i64 %248, 6
  store i64 %267, i64* %3, align 8
  %268 = inttoptr i64 %266 to i32*
  %269 = load i32, i32* %268, align 4
  %270 = zext i32 %269 to i64
  store i64 %270, i64* %RSI.i2015, align 8
  %271 = add i64 %247, -512
  %272 = add i64 %248, 12
  store i64 %272, i64* %3, align 8
  %273 = inttoptr i64 %271 to i32*
  store i32 %251, i32* %273, align 4
  %274 = load i32, i32* %ESI.i1759, align 4
  %275 = zext i32 %274 to i64
  %276 = load i64, i64* %3, align 8
  store i64 %275, i64* %RAX.i1659, align 8
  %277 = sext i32 %274 to i64
  %278 = lshr i64 %277, 32
  store i64 %278, i64* %103, align 8
  %279 = load i32, i32* %R10D.i1715, align 4
  %280 = add i64 %276, 6
  store i64 %280, i64* %3, align 8
  %281 = sext i32 %279 to i64
  %282 = shl nuw i64 %278, 32
  %283 = or i64 %282, %275
  %284 = sdiv i64 %283, %281
  %285 = shl i64 %284, 32
  %286 = ashr exact i64 %285, 32
  %287 = icmp eq i64 %284, %286
  br i1 %287, label %290, label %288

; <label>:288:                                    ; preds = %routine_idivl__r10d.exit3450
  %289 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %280, %struct.Memory* %250)
  %.pre447 = load i64, i64* %RAX.i1659, align 8
  %.pre448 = load i64, i64* %3, align 8
  br label %routine_idivl__r10d.exit3568

; <label>:290:                                    ; preds = %routine_idivl__r10d.exit3450
  %291 = srem i64 %283, %281
  %292 = and i64 %284, 4294967295
  store i64 %292, i64* %RAX.i1659, align 8
  %293 = and i64 %291, 4294967295
  store i64 %293, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r10d.exit3568

routine_idivl__r10d.exit3568:                     ; preds = %290, %288
  %294 = phi i64 [ %.pre448, %288 ], [ %280, %290 ]
  %295 = phi i64 [ %.pre447, %288 ], [ %292, %290 ]
  %296 = phi %struct.Memory* [ %289, %288 ], [ %250, %290 ]
  %.tr122 = trunc i64 %295 to i32
  %297 = shl i32 %.tr122, 2
  %298 = zext i32 %297 to i64
  store i64 %298, i64* %RAX.i1659, align 8
  %299 = lshr i64 %295, 30
  %300 = trunc i64 %299 to i8
  %301 = and i8 %300, 1
  store i8 %301, i8* %17, align 1
  %302 = and i32 %297, 252
  %303 = tail call i32 @llvm.ctpop.i32(i32 %302)
  %304 = trunc i32 %303 to i8
  %305 = and i8 %304, 1
  %306 = xor i8 %305, 1
  store i8 %306, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %307 = icmp eq i32 %297, 0
  %308 = zext i1 %307 to i8
  store i8 %308, i8* %20, align 1
  %309 = lshr i32 %.tr122, 29
  %310 = trunc i32 %309 to i8
  %311 = and i8 %310, 1
  store i8 %311, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %312 = load i64, i64* %RBP.i, align 8
  %313 = add i64 %312, -512
  %314 = add i64 %294, 9
  store i64 %314, i64* %3, align 8
  %315 = inttoptr i64 %313 to i32*
  %316 = load i32, i32* %315, align 4
  %317 = add i32 %297, %316
  %318 = zext i32 %317 to i64
  store i64 %318, i64* %RSI.i2015, align 8
  %319 = icmp ult i32 %317, %316
  %320 = icmp ult i32 %317, %297
  %321 = or i1 %319, %320
  %322 = zext i1 %321 to i8
  store i8 %322, i8* %17, align 1
  %323 = and i32 %317, 255
  %324 = tail call i32 @llvm.ctpop.i32(i32 %323)
  %325 = trunc i32 %324 to i8
  %326 = and i8 %325, 1
  %327 = xor i8 %326, 1
  store i8 %327, i8* %18, align 1
  %328 = xor i32 %297, %316
  %329 = xor i32 %328, %317
  %330 = lshr i32 %329, 4
  %331 = trunc i32 %330 to i8
  %332 = and i8 %331, 1
  store i8 %332, i8* %19, align 1
  %333 = icmp eq i32 %317, 0
  %334 = zext i1 %333 to i8
  store i8 %334, i8* %20, align 1
  %335 = lshr i32 %317, 31
  %336 = trunc i32 %335 to i8
  store i8 %336, i8* %21, align 1
  %337 = lshr i32 %316, 31
  %338 = lshr i32 %.tr122, 29
  %339 = and i32 %338, 1
  %340 = xor i32 %335, %337
  %341 = xor i32 %335, %339
  %342 = add nuw nsw i32 %340, %341
  %343 = icmp eq i32 %342, 2
  %344 = zext i1 %343 to i8
  store i8 %344, i8* %22, align 1
  %345 = add i64 %312, -224
  %346 = add i64 %294, 17
  store i64 %346, i64* %3, align 8
  %347 = inttoptr i64 %345 to i32*
  store i32 %317, i32* %347, align 4
  %R11.i = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %348 = load i64, i64* %3, align 8
  %349 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %349, i64* %R11.i, align 8
  %350 = add i64 %349, 152
  %351 = add i64 %348, 15
  store i64 %351, i64* %3, align 8
  %352 = inttoptr i64 %350 to i32*
  %353 = load i32, i32* %352, align 4
  %354 = zext i32 %353 to i64
  store i64 %354, i64* %RAX.i1659, align 8
  %355 = load i64, i64* %RBP.i, align 8
  %356 = add i64 %355, -220
  %357 = add i64 %348, 21
  store i64 %357, i64* %3, align 8
  %358 = inttoptr i64 %356 to i32*
  %359 = load i32, i32* %358, align 4
  %360 = add i32 %359, %353
  %361 = zext i32 %360 to i64
  store i64 %361, i64* %RAX.i1659, align 8
  %362 = icmp ult i32 %360, %353
  %363 = icmp ult i32 %360, %359
  %364 = or i1 %362, %363
  %365 = zext i1 %364 to i8
  store i8 %365, i8* %17, align 1
  %366 = and i32 %360, 255
  %367 = tail call i32 @llvm.ctpop.i32(i32 %366)
  %368 = trunc i32 %367 to i8
  %369 = and i8 %368, 1
  %370 = xor i8 %369, 1
  store i8 %370, i8* %18, align 1
  %371 = xor i32 %359, %353
  %372 = xor i32 %371, %360
  %373 = lshr i32 %372, 4
  %374 = trunc i32 %373 to i8
  %375 = and i8 %374, 1
  store i8 %375, i8* %19, align 1
  %376 = icmp eq i32 %360, 0
  %377 = zext i1 %376 to i8
  store i8 %377, i8* %20, align 1
  %378 = lshr i32 %360, 31
  %379 = trunc i32 %378 to i8
  store i8 %379, i8* %21, align 1
  %380 = lshr i32 %353, 31
  %381 = lshr i32 %359, 31
  %382 = xor i32 %378, %380
  %383 = xor i32 %378, %381
  %384 = add nuw nsw i32 %382, %383
  %385 = icmp eq i32 %384, 2
  %386 = zext i1 %385 to i8
  store i8 %386, i8* %22, align 1
  %387 = add i64 %355, -228
  %388 = add i64 %348, 27
  store i64 %388, i64* %3, align 8
  %389 = inttoptr i64 %387 to i32*
  store i32 %360, i32* %389, align 4
  %390 = load i64, i64* %3, align 8
  %391 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %391, i64* %R11.i, align 8
  %392 = add i64 %391, 156
  %393 = add i64 %390, 15
  store i64 %393, i64* %3, align 8
  %394 = inttoptr i64 %392 to i32*
  %395 = load i32, i32* %394, align 4
  %396 = zext i32 %395 to i64
  store i64 %396, i64* %RAX.i1659, align 8
  %397 = load i64, i64* %RBP.i, align 8
  %398 = add i64 %397, -224
  %399 = add i64 %390, 21
  store i64 %399, i64* %3, align 8
  %400 = inttoptr i64 %398 to i32*
  %401 = load i32, i32* %400, align 4
  %402 = add i32 %401, %395
  %403 = zext i32 %402 to i64
  store i64 %403, i64* %RAX.i1659, align 8
  %404 = icmp ult i32 %402, %395
  %405 = icmp ult i32 %402, %401
  %406 = or i1 %404, %405
  %407 = zext i1 %406 to i8
  store i8 %407, i8* %17, align 1
  %408 = and i32 %402, 255
  %409 = tail call i32 @llvm.ctpop.i32(i32 %408)
  %410 = trunc i32 %409 to i8
  %411 = and i8 %410, 1
  %412 = xor i8 %411, 1
  store i8 %412, i8* %18, align 1
  %413 = xor i32 %401, %395
  %414 = xor i32 %413, %402
  %415 = lshr i32 %414, 4
  %416 = trunc i32 %415 to i8
  %417 = and i8 %416, 1
  store i8 %417, i8* %19, align 1
  %418 = icmp eq i32 %402, 0
  %419 = zext i1 %418 to i8
  store i8 %419, i8* %20, align 1
  %420 = lshr i32 %402, 31
  %421 = trunc i32 %420 to i8
  store i8 %421, i8* %21, align 1
  %422 = lshr i32 %395, 31
  %423 = lshr i32 %401, 31
  %424 = xor i32 %420, %422
  %425 = xor i32 %420, %423
  %426 = add nuw nsw i32 %424, %425
  %427 = icmp eq i32 %426, 2
  %428 = zext i1 %427 to i8
  store i8 %428, i8* %22, align 1
  %429 = add i64 %397, -232
  %430 = add i64 %390, 27
  store i64 %430, i64* %3, align 8
  %431 = inttoptr i64 %429 to i32*
  store i32 %402, i32* %431, align 4
  %432 = load i64, i64* %3, align 8
  %433 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %433, i64* %R11.i, align 8
  %434 = add i64 %433, 168
  %435 = add i64 %432, 15
  store i64 %435, i64* %3, align 8
  %436 = inttoptr i64 %434 to i32*
  %437 = load i32, i32* %436, align 4
  %438 = zext i32 %437 to i64
  store i64 %438, i64* %RAX.i1659, align 8
  %439 = load i64, i64* %RBP.i, align 8
  %440 = add i64 %439, -220
  %441 = add i64 %432, 21
  store i64 %441, i64* %3, align 8
  %442 = inttoptr i64 %440 to i32*
  %443 = load i32, i32* %442, align 4
  %444 = add i32 %443, %437
  %445 = zext i32 %444 to i64
  store i64 %445, i64* %RAX.i1659, align 8
  %446 = icmp ult i32 %444, %437
  %447 = icmp ult i32 %444, %443
  %448 = or i1 %446, %447
  %449 = zext i1 %448 to i8
  store i8 %449, i8* %17, align 1
  %450 = and i32 %444, 255
  %451 = tail call i32 @llvm.ctpop.i32(i32 %450)
  %452 = trunc i32 %451 to i8
  %453 = and i8 %452, 1
  %454 = xor i8 %453, 1
  store i8 %454, i8* %18, align 1
  %455 = xor i32 %443, %437
  %456 = xor i32 %455, %444
  %457 = lshr i32 %456, 4
  %458 = trunc i32 %457 to i8
  %459 = and i8 %458, 1
  store i8 %459, i8* %19, align 1
  %460 = icmp eq i32 %444, 0
  %461 = zext i1 %460 to i8
  store i8 %461, i8* %20, align 1
  %462 = lshr i32 %444, 31
  %463 = trunc i32 %462 to i8
  store i8 %463, i8* %21, align 1
  %464 = lshr i32 %437, 31
  %465 = lshr i32 %443, 31
  %466 = xor i32 %462, %464
  %467 = xor i32 %462, %465
  %468 = add nuw nsw i32 %466, %467
  %469 = icmp eq i32 %468, 2
  %470 = zext i1 %469 to i8
  store i8 %470, i8* %22, align 1
  %471 = add i64 %439, -236
  %472 = add i64 %432, 27
  store i64 %472, i64* %3, align 8
  %473 = inttoptr i64 %471 to i32*
  store i32 %444, i32* %473, align 4
  %474 = load i64, i64* %3, align 8
  %475 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %475, i64* %R11.i, align 8
  %476 = add i64 %475, 172
  %477 = add i64 %474, 15
  store i64 %477, i64* %3, align 8
  %478 = inttoptr i64 %476 to i32*
  %479 = load i32, i32* %478, align 4
  %480 = zext i32 %479 to i64
  store i64 %480, i64* %RAX.i1659, align 8
  %481 = load i64, i64* %RBP.i, align 8
  %482 = add i64 %481, -224
  %483 = add i64 %474, 21
  store i64 %483, i64* %3, align 8
  %484 = inttoptr i64 %482 to i32*
  %485 = load i32, i32* %484, align 4
  %486 = add i32 %485, %479
  %487 = zext i32 %486 to i64
  store i64 %487, i64* %RAX.i1659, align 8
  %488 = icmp ult i32 %486, %479
  %489 = icmp ult i32 %486, %485
  %490 = or i1 %488, %489
  %491 = zext i1 %490 to i8
  store i8 %491, i8* %17, align 1
  %492 = and i32 %486, 255
  %493 = tail call i32 @llvm.ctpop.i32(i32 %492)
  %494 = trunc i32 %493 to i8
  %495 = and i8 %494, 1
  %496 = xor i8 %495, 1
  store i8 %496, i8* %18, align 1
  %497 = xor i32 %485, %479
  %498 = xor i32 %497, %486
  %499 = lshr i32 %498, 4
  %500 = trunc i32 %499 to i8
  %501 = and i8 %500, 1
  store i8 %501, i8* %19, align 1
  %502 = icmp eq i32 %486, 0
  %503 = zext i1 %502 to i8
  store i8 %503, i8* %20, align 1
  %504 = lshr i32 %486, 31
  %505 = trunc i32 %504 to i8
  store i8 %505, i8* %21, align 1
  %506 = lshr i32 %479, 31
  %507 = lshr i32 %485, 31
  %508 = xor i32 %504, %506
  %509 = xor i32 %504, %507
  %510 = add nuw nsw i32 %508, %509
  %511 = icmp eq i32 %510, 2
  %512 = zext i1 %511 to i8
  store i8 %512, i8* %22, align 1
  %513 = add i64 %481, -240
  %514 = add i64 %474, 27
  store i64 %514, i64* %3, align 8
  %515 = inttoptr i64 %513 to i32*
  store i32 %486, i32* %515, align 4
  %516 = load i64, i64* %RBP.i, align 8
  %517 = add i64 %516, -228
  %518 = load i64, i64* %3, align 8
  %519 = add i64 %518, 6
  store i64 %519, i64* %3, align 8
  %520 = inttoptr i64 %517 to i32*
  %521 = load i32, i32* %520, align 4
  %522 = zext i32 %521 to i64
  store i64 %522, i64* %RAX.i1659, align 8
  %523 = sext i32 %521 to i64
  %524 = lshr i64 %523, 32
  store i64 %524, i64* %103, align 8
  %525 = add i64 %516, -504
  %526 = add i64 %518, 13
  store i64 %526, i64* %3, align 8
  %527 = inttoptr i64 %525 to i32*
  %528 = load i32, i32* %527, align 4
  %529 = zext i32 %528 to i64
  store i64 %529, i64* %RSI.i2015, align 8
  %530 = add i64 %518, 15
  store i64 %530, i64* %3, align 8
  %531 = sext i32 %528 to i64
  %532 = shl nuw i64 %524, 32
  %533 = or i64 %532, %522
  %534 = sdiv i64 %533, %531
  %535 = shl i64 %534, 32
  %536 = ashr exact i64 %535, 32
  %537 = icmp eq i64 %534, %536
  br i1 %537, label %540, label %538

; <label>:538:                                    ; preds = %routine_idivl__r10d.exit3568
  %539 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %530, %struct.Memory* %296)
  %.pre449 = load i64, i64* %RBP.i, align 8
  %.pre450 = load i32, i32* %EAX.i2033, align 4
  %.pre451 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit7045

; <label>:540:                                    ; preds = %routine_idivl__r10d.exit3568
  %541 = srem i64 %533, %531
  %542 = and i64 %534, 4294967295
  store i64 %542, i64* %RAX.i1659, align 8
  %543 = and i64 %541, 4294967295
  store i64 %543, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %544 = trunc i64 %534 to i32
  br label %routine_idivl__esi.exit7045

routine_idivl__esi.exit7045:                      ; preds = %540, %538
  %545 = phi i64 [ %.pre451, %538 ], [ %530, %540 ]
  %546 = phi i32 [ %.pre450, %538 ], [ %544, %540 ]
  %547 = phi i64 [ %.pre449, %538 ], [ %516, %540 ]
  %548 = phi %struct.Memory* [ %539, %538 ], [ %296, %540 ]
  %549 = add i64 %547, -244
  %550 = add i64 %545, 6
  store i64 %550, i64* %3, align 8
  %551 = inttoptr i64 %549 to i32*
  store i32 %546, i32* %551, align 4
  %552 = load i64, i64* %RBP.i, align 8
  %553 = add i64 %552, -232
  %554 = load i64, i64* %3, align 8
  %555 = add i64 %554, 6
  store i64 %555, i64* %3, align 8
  %556 = inttoptr i64 %553 to i32*
  %557 = load i32, i32* %556, align 4
  %558 = zext i32 %557 to i64
  store i64 %558, i64* %RAX.i1659, align 8
  %559 = sext i32 %557 to i64
  %560 = lshr i64 %559, 32
  store i64 %560, i64* %103, align 8
  %561 = load i32, i32* %ESI.i1759, align 4
  %562 = add i64 %554, 9
  store i64 %562, i64* %3, align 8
  %563 = sext i32 %561 to i64
  %564 = shl nuw i64 %560, 32
  %565 = or i64 %564, %558
  %566 = sdiv i64 %565, %563
  %567 = shl i64 %566, 32
  %568 = ashr exact i64 %567, 32
  %569 = icmp eq i64 %566, %568
  br i1 %569, label %572, label %570

; <label>:570:                                    ; preds = %routine_idivl__esi.exit7045
  %571 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %562, %struct.Memory* %548)
  %.pre452 = load i64, i64* %RBP.i, align 8
  %.pre453 = load i32, i32* %EAX.i2033, align 4
  %.pre454 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit7032

; <label>:572:                                    ; preds = %routine_idivl__esi.exit7045
  %573 = srem i64 %565, %563
  %574 = and i64 %566, 4294967295
  store i64 %574, i64* %RAX.i1659, align 8
  %575 = and i64 %573, 4294967295
  store i64 %575, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %576 = trunc i64 %566 to i32
  br label %routine_idivl__esi.exit7032

routine_idivl__esi.exit7032:                      ; preds = %572, %570
  %577 = phi i64 [ %.pre454, %570 ], [ %562, %572 ]
  %578 = phi i32 [ %.pre453, %570 ], [ %576, %572 ]
  %579 = phi i64 [ %.pre452, %570 ], [ %552, %572 ]
  %580 = phi %struct.Memory* [ %571, %570 ], [ %548, %572 ]
  %581 = add i64 %579, -248
  %582 = add i64 %577, 6
  store i64 %582, i64* %3, align 8
  %583 = inttoptr i64 %581 to i32*
  store i32 %578, i32* %583, align 4
  %584 = load i64, i64* %RBP.i, align 8
  %585 = add i64 %584, -256
  %586 = load i64, i64* %3, align 8
  %587 = add i64 %586, 8
  store i64 %587, i64* %3, align 8
  %588 = load i64, i64* %46, align 1
  %589 = inttoptr i64 %585 to i64*
  store i64 %588, i64* %589, align 8
  %590 = load i64, i64* %RBP.i, align 8
  %591 = add i64 %590, -264
  %592 = load i64, i64* %3, align 8
  %593 = add i64 %592, 8
  store i64 %593, i64* %3, align 8
  %594 = load i64, i64* %37, align 1
  %595 = inttoptr i64 %591 to i64*
  store i64 %594, i64* %595, align 8
  %596 = load i64, i64* %3, align 8
  %597 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %597, i64* %R11.i, align 8
  %598 = add i64 %597, 14168
  %599 = add i64 %596, 15
  store i64 %599, i64* %3, align 8
  %600 = inttoptr i64 %598 to i64*
  %601 = load i64, i64* %600, align 8
  store i64 %601, i64* %R11.i, align 8
  store i64 %597, i64* %RBX.i1545, align 8
  %602 = add i64 %597, 12
  %603 = add i64 %596, 27
  store i64 %603, i64* %3, align 8
  %604 = inttoptr i64 %602 to i32*
  %605 = load i32, i32* %604, align 4
  %606 = sext i32 %605 to i64
  %607 = mul nsw i64 %606, 632
  store i64 %607, i64* %RBX.i1545, align 8
  %608 = lshr i64 %607, 63
  %609 = add i64 %607, %601
  store i64 %609, i64* %R11.i, align 8
  %610 = icmp ult i64 %609, %601
  %611 = icmp ult i64 %609, %607
  %612 = or i1 %610, %611
  %613 = zext i1 %612 to i8
  store i8 %613, i8* %17, align 1
  %614 = trunc i64 %609 to i32
  %615 = and i32 %614, 255
  %616 = tail call i32 @llvm.ctpop.i32(i32 %615)
  %617 = trunc i32 %616 to i8
  %618 = and i8 %617, 1
  %619 = xor i8 %618, 1
  store i8 %619, i8* %18, align 1
  %620 = xor i64 %607, %601
  %621 = xor i64 %620, %609
  %622 = lshr i64 %621, 4
  %623 = trunc i64 %622 to i8
  %624 = and i8 %623, 1
  store i8 %624, i8* %19, align 1
  %625 = icmp eq i64 %609, 0
  %626 = zext i1 %625 to i8
  store i8 %626, i8* %20, align 1
  %627 = lshr i64 %609, 63
  %628 = trunc i64 %627 to i8
  store i8 %628, i8* %21, align 1
  %629 = lshr i64 %601, 63
  %630 = xor i64 %627, %629
  %631 = xor i64 %627, %608
  %632 = add nuw nsw i64 %630, %631
  %633 = icmp eq i64 %632, 2
  %634 = zext i1 %633 to i8
  store i8 %634, i8* %22, align 1
  %635 = add i64 %609, 524
  %636 = add i64 %596, 44
  store i64 %636, i64* %3, align 8
  %637 = inttoptr i64 %635 to i32*
  %638 = load i32, i32* %637, align 4
  %639 = zext i32 %638 to i64
  store i64 %639, i64* %RAX.i1659, align 8
  %640 = load i64, i64* %RBP.i, align 8
  %641 = add i64 %640, -364
  %642 = add i64 %596, 50
  store i64 %642, i64* %3, align 8
  %643 = inttoptr i64 %641 to i32*
  store i32 %638, i32* %643, align 4
  %644 = load i64, i64* %3, align 8
  %645 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %645, i64* %R11.i, align 8
  %RDI.i6998 = getelementptr inbounds %union.anon, %union.anon* %51, i64 0, i32 0
  %646 = add i64 %645, 12
  %647 = add i64 %644, 12
  store i64 %647, i64* %3, align 8
  %648 = inttoptr i64 %646 to i32*
  %649 = load i32, i32* %648, align 4
  %650 = zext i32 %649 to i64
  store i64 %650, i64* %RDI.i6998, align 8
  %651 = load i64, i64* %RBP.i, align 8
  %652 = add i64 %651, -220
  %653 = add i64 %644, 18
  store i64 %653, i64* %3, align 8
  %654 = inttoptr i64 %652 to i32*
  %655 = load i32, i32* %654, align 4
  %656 = zext i32 %655 to i64
  store i64 %656, i64* %RAX.i1659, align 8
  %657 = sext i32 %655 to i64
  %658 = lshr i64 %657, 32
  store i64 %658, i64* %103, align 8
  %659 = load i32, i32* %ESI.i1759, align 4
  %660 = add i64 %644, 21
  store i64 %660, i64* %3, align 8
  %661 = sext i32 %659 to i64
  %662 = shl nuw i64 %658, 32
  %663 = or i64 %662, %656
  %664 = sdiv i64 %663, %661
  %665 = shl i64 %664, 32
  %666 = ashr exact i64 %665, 32
  %667 = icmp eq i64 %664, %666
  br i1 %667, label %670, label %668

; <label>:668:                                    ; preds = %routine_idivl__esi.exit7032
  %669 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %660, %struct.Memory* %580)
  %.pre455 = load i64, i64* %RBP.i, align 8
  %.pre456 = load i64, i64* %3, align 8
  %.pre457 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit6989

; <label>:670:                                    ; preds = %routine_idivl__esi.exit7032
  %671 = srem i64 %663, %661
  %672 = and i64 %664, 4294967295
  store i64 %672, i64* %RAX.i1659, align 8
  %673 = and i64 %671, 4294967295
  store i64 %673, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %674 = trunc i64 %664 to i32
  br label %routine_idivl__esi.exit6989

routine_idivl__esi.exit6989:                      ; preds = %670, %668
  %675 = phi i32 [ %.pre457, %668 ], [ %674, %670 ]
  %676 = phi i64 [ %.pre456, %668 ], [ %660, %670 ]
  %677 = phi i64 [ %.pre455, %668 ], [ %651, %670 ]
  %678 = phi %struct.Memory* [ %669, %668 ], [ %580, %670 ]
  %679 = add i64 %677, -224
  %680 = add i64 %676, 7
  store i64 %680, i64* %3, align 8
  %681 = inttoptr i64 %679 to i32*
  %682 = load i32, i32* %681, align 4
  %683 = zext i32 %682 to i64
  store i64 %683, i64* %50, align 8
  %684 = add i64 %677, -516
  %685 = add i64 %676, 13
  store i64 %685, i64* %3, align 8
  %686 = inttoptr i64 %684 to i32*
  store i32 %675, i32* %686, align 4
  %687 = load i32, i32* %R10D.i1715, align 4
  %688 = zext i32 %687 to i64
  %689 = load i64, i64* %3, align 8
  store i64 %688, i64* %RAX.i1659, align 8
  %690 = sext i32 %687 to i64
  %691 = lshr i64 %690, 32
  store i64 %691, i64* %103, align 8
  %692 = load i32, i32* %ESI.i1759, align 4
  %693 = add i64 %689, 6
  store i64 %693, i64* %3, align 8
  %694 = sext i32 %692 to i64
  %695 = shl nuw i64 %691, 32
  %696 = or i64 %695, %688
  %697 = sdiv i64 %696, %694
  %698 = shl i64 %697, 32
  %699 = ashr exact i64 %698, 32
  %700 = icmp eq i64 %697, %699
  br i1 %700, label %703, label %701

; <label>:701:                                    ; preds = %routine_idivl__esi.exit6989
  %702 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %693, %struct.Memory* %678)
  %.pre458 = load i64, i64* %3, align 8
  %.pre459 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit6973

; <label>:703:                                    ; preds = %routine_idivl__esi.exit6989
  %704 = srem i64 %696, %694
  %705 = and i64 %697, 4294967295
  store i64 %705, i64* %RAX.i1659, align 8
  %706 = and i64 %704, 4294967295
  store i64 %706, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %707 = trunc i64 %697 to i32
  br label %routine_idivl__esi.exit6973

routine_idivl__esi.exit6973:                      ; preds = %703, %701
  %708 = phi i32 [ %.pre459, %701 ], [ %707, %703 ]
  %709 = phi i64 [ %.pre458, %701 ], [ %693, %703 ]
  %710 = phi %struct.Memory* [ %702, %701 ], [ %678, %703 ]
  %711 = load i64, i64* %RBP.i, align 8
  %712 = add i64 %711, -516
  %713 = add i64 %709, 6
  store i64 %713, i64* %3, align 8
  %714 = inttoptr i64 %712 to i32*
  %715 = load i32, i32* %714, align 4
  %716 = zext i32 %715 to i64
  store i64 %716, i64* %RSI.i2015, align 8
  %717 = zext i32 %708 to i64
  store i64 %717, i64* %RDX.i1943, align 8
  %718 = add i64 %709, -231627
  %719 = add i64 %709, 13
  %720 = load i64, i64* %6, align 8
  %721 = add i64 %720, -8
  %722 = inttoptr i64 %721 to i64*
  store i64 %719, i64* %722, align 8
  store i64 %721, i64* %6, align 8
  store i64 %718, i64* %3, align 8
  %call2_483b03 = tail call %struct.Memory* @sub_44b230.getLuma4x4Neighbour(%struct.State* nonnull %0, i64 %718, %struct.Memory* %710)
  %ECX.i6962 = bitcast %union.anon* %23 to i32*
  %723 = load i64, i64* %3, align 8
  store i64 0, i64* %RCX.i1588, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  store i64 4294967295, i64* %25, align 8
  %724 = load i64, i64* %RBP.i, align 8
  %725 = add i64 %724, -336
  store i64 %725, i64* %R9.i1633, align 8
  store i64 4, i64* %RAX.i1659, align 8
  %726 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %726, i64* %R11.i, align 8
  %727 = add i64 %726, 12
  %728 = add i64 %723, 32
  store i64 %728, i64* %3, align 8
  %729 = inttoptr i64 %727 to i32*
  %730 = load i32, i32* %729, align 4
  %731 = zext i32 %730 to i64
  store i64 %731, i64* %RDI.i6998, align 8
  %732 = add i64 %724, -220
  %733 = add i64 %723, 38
  store i64 %733, i64* %3, align 8
  %734 = inttoptr i64 %732 to i32*
  %735 = load i32, i32* %734, align 4
  %736 = zext i32 %735 to i64
  store i64 %736, i64* %RDX.i1943, align 8
  %737 = add i64 %724, -520
  %738 = add i64 %723, 44
  store i64 %738, i64* %3, align 8
  %739 = inttoptr i64 %737 to i32*
  store i32 4, i32* %739, align 4
  %740 = load i32, i32* %108, align 4
  %741 = zext i32 %740 to i64
  %742 = load i64, i64* %3, align 8
  store i64 %741, i64* %RAX.i1659, align 8
  %743 = sext i32 %740 to i64
  %744 = lshr i64 %743, 32
  store i64 %744, i64* %103, align 8
  %745 = load i64, i64* %RBP.i, align 8
  %746 = add i64 %745, -520
  %747 = add i64 %742, 9
  store i64 %747, i64* %3, align 8
  %748 = inttoptr i64 %746 to i32*
  %749 = load i32, i32* %748, align 4
  %750 = zext i32 %749 to i64
  store i64 %750, i64* %RSI.i2015, align 8
  %751 = add i64 %742, 11
  store i64 %751, i64* %3, align 8
  %752 = sext i32 %749 to i64
  %753 = shl nuw i64 %744, 32
  %754 = or i64 %753, %741
  %755 = sdiv i64 %754, %752
  %756 = shl i64 %755, 32
  %757 = ashr exact i64 %756, 32
  %758 = icmp eq i64 %755, %757
  br i1 %758, label %761, label %759

; <label>:759:                                    ; preds = %routine_idivl__esi.exit6973
  %760 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %751, %struct.Memory* %call2_483b03)
  %.pre460 = load i64, i64* %RBP.i, align 8
  %.pre461 = load i64, i64* %3, align 8
  %.pre462 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit6933

; <label>:761:                                    ; preds = %routine_idivl__esi.exit6973
  %762 = srem i64 %754, %752
  %763 = and i64 %755, 4294967295
  store i64 %763, i64* %RAX.i1659, align 8
  %764 = and i64 %762, 4294967295
  store i64 %764, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %765 = trunc i64 %755 to i32
  br label %routine_idivl__esi.exit6933

routine_idivl__esi.exit6933:                      ; preds = %761, %759
  %766 = phi i32 [ %.pre462, %759 ], [ %765, %761 ]
  %767 = phi i64 [ %.pre461, %759 ], [ %751, %761 ]
  %768 = phi i64 [ %.pre460, %759 ], [ %745, %761 ]
  %769 = phi %struct.Memory* [ %760, %759 ], [ %call2_483b03, %761 ]
  %770 = add i64 %768, -224
  %771 = add i64 %767, 7
  store i64 %771, i64* %3, align 8
  %772 = inttoptr i64 %770 to i32*
  %773 = load i32, i32* %772, align 4
  %774 = zext i32 %773 to i64
  store i64 %774, i64* %50, align 8
  %775 = add i64 %768, -524
  %776 = add i64 %767, 13
  store i64 %776, i64* %3, align 8
  %777 = inttoptr i64 %775 to i32*
  store i32 %766, i32* %777, align 4
  %778 = load i32, i32* %R10D.i1715, align 4
  %779 = zext i32 %778 to i64
  %780 = load i64, i64* %3, align 8
  store i64 %779, i64* %RAX.i1659, align 8
  %781 = sext i32 %778 to i64
  %782 = lshr i64 %781, 32
  store i64 %782, i64* %103, align 8
  %783 = load i32, i32* %ESI.i1759, align 4
  %784 = add i64 %780, 6
  store i64 %784, i64* %3, align 8
  %785 = sext i32 %783 to i64
  %786 = shl nuw i64 %782, 32
  %787 = or i64 %786, %779
  %788 = sdiv i64 %787, %785
  %789 = shl i64 %788, 32
  %790 = ashr exact i64 %789, 32
  %791 = icmp eq i64 %788, %790
  br i1 %791, label %794, label %792

; <label>:792:                                    ; preds = %routine_idivl__esi.exit6933
  %793 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %784, %struct.Memory* %769)
  %.pre463 = load i64, i64* %3, align 8
  %.pre464 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit6917

; <label>:794:                                    ; preds = %routine_idivl__esi.exit6933
  %795 = srem i64 %787, %785
  %796 = and i64 %788, 4294967295
  store i64 %796, i64* %RAX.i1659, align 8
  %797 = and i64 %795, 4294967295
  store i64 %797, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %798 = trunc i64 %788 to i32
  br label %routine_idivl__esi.exit6917

routine_idivl__esi.exit6917:                      ; preds = %794, %792
  %799 = phi i32 [ %.pre464, %792 ], [ %798, %794 ]
  %800 = phi i64 [ %.pre463, %792 ], [ %784, %794 ]
  %801 = phi %struct.Memory* [ %793, %792 ], [ %769, %794 ]
  %802 = load i64, i64* %RBP.i, align 8
  %803 = add i64 %802, -524
  %804 = add i64 %800, 6
  store i64 %804, i64* %3, align 8
  %805 = inttoptr i64 %803 to i32*
  %806 = load i32, i32* %805, align 4
  %807 = zext i32 %806 to i64
  store i64 %807, i64* %RSI.i2015, align 8
  %808 = zext i32 %799 to i64
  store i64 %808, i64* %RDX.i1943, align 8
  %809 = add i64 %800, -231714
  %810 = add i64 %800, 13
  %811 = load i64, i64* %6, align 8
  %812 = add i64 %811, -8
  %813 = inttoptr i64 %812 to i64*
  store i64 %810, i64* %813, align 8
  store i64 %812, i64* %6, align 8
  store i64 %809, i64* %3, align 8
  %call2_483b5a = tail call %struct.Memory* @sub_44b230.getLuma4x4Neighbour(%struct.State* nonnull %0, i64 %809, %struct.Memory* %801)
  %814 = load i64, i64* %3, align 8
  %815 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %815, i64* %R9.i1633, align 8
  %816 = add i64 %815, 216
  %817 = add i64 %814, 16
  store i64 %817, i64* %3, align 8
  %818 = inttoptr i64 %816 to i32*
  %819 = load i32, i32* %818, align 4
  store i8 0, i8* %17, align 1
  %820 = and i32 %819, 255
  %821 = tail call i32 @llvm.ctpop.i32(i32 %820)
  %822 = trunc i32 %821 to i8
  %823 = and i8 %822, 1
  %824 = xor i8 %823, 1
  store i8 %824, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %825 = icmp eq i32 %819, 0
  %826 = zext i1 %825 to i8
  store i8 %826, i8* %20, align 1
  %827 = lshr i32 %819, 31
  %828 = trunc i32 %827 to i8
  store i8 %828, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v694 = select i1 %825, i64 170, i64 22
  %829 = add i64 %814, %.v694
  store i64 %829, i64* %3, align 8
  br i1 %825, label %block_.L_483c09, label %block_483b75

block_483b75:                                     ; preds = %routine_idivl__esi.exit6917
  %830 = load i64, i64* %RBP.i, align 8
  %831 = add i64 %830, -312
  %832 = add i64 %829, 7
  store i64 %832, i64* %3, align 8
  %833 = inttoptr i64 %831 to i32*
  %834 = load i32, i32* %833, align 4
  store i8 0, i8* %17, align 1
  %835 = and i32 %834, 255
  %836 = tail call i32 @llvm.ctpop.i32(i32 %835)
  %837 = trunc i32 %836 to i8
  %838 = and i8 %837, 1
  %839 = xor i8 %838, 1
  store i8 %839, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %840 = icmp eq i32 %834, 0
  %841 = zext i1 %840 to i8
  store i8 %841, i8* %20, align 1
  %842 = lshr i32 %834, 31
  %843 = trunc i32 %842 to i8
  store i8 %843, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v695 = select i1 %840, i64 49, i64 13
  %844 = add i64 %829, %.v695
  store i64 %844, i64* %3, align 8
  br i1 %840, label %block_.L_483ba6, label %block_483b82

block_483b82:                                     ; preds = %block_483b75
  %845 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %845, i64* %RAX.i1659, align 8
  %846 = add i64 %845, 71784
  %847 = add i64 %844, 15
  store i64 %847, i64* %3, align 8
  %848 = inttoptr i64 %846 to i64*
  %849 = load i64, i64* %848, align 8
  store i64 %849, i64* %RAX.i1659, align 8
  %850 = add i64 %830, -308
  %851 = add i64 %844, 22
  store i64 %851, i64* %3, align 8
  %852 = inttoptr i64 %850 to i32*
  %853 = load i32, i32* %852, align 4
  %854 = sext i32 %853 to i64
  store i64 %854, i64* %RCX.i1588, align 8
  %855 = shl nsw i64 %854, 2
  %856 = add i64 %855, %849
  %857 = add i64 %844, 25
  store i64 %857, i64* %3, align 8
  %858 = inttoptr i64 %856 to i32*
  %859 = load i32, i32* %858, align 4
  %860 = zext i32 %859 to i64
  store i64 %860, i64* %RDX.i1943, align 8
  %861 = add i64 %830, -528
  %862 = add i64 %844, 31
  store i64 %862, i64* %3, align 8
  %863 = inttoptr i64 %861 to i32*
  store i32 %859, i32* %863, align 4
  %864 = load i64, i64* %3, align 8
  %865 = add i64 %864, 18
  br label %block_.L_483bb3

block_.L_483ba6:                                  ; preds = %block_483b75
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %866 = add i64 %830, -528
  %867 = add i64 %844, 8
  store i64 %867, i64* %3, align 8
  %868 = inttoptr i64 %866 to i32*
  store i32 0, i32* %868, align 4
  %869 = load i64, i64* %3, align 8
  %870 = add i64 %869, 5
  store i64 %870, i64* %3, align 8
  br label %block_.L_483bb3

block_.L_483bb3:                                  ; preds = %block_.L_483ba6, %block_483b82
  %storemerge = phi i64 [ %865, %block_483b82 ], [ %870, %block_.L_483ba6 ]
  %871 = load i64, i64* %RBP.i, align 8
  %872 = add i64 %871, -528
  %873 = add i64 %storemerge, 6
  store i64 %873, i64* %3, align 8
  %874 = inttoptr i64 %872 to i32*
  %875 = load i32, i32* %874, align 4
  %876 = zext i32 %875 to i64
  store i64 %876, i64* %RAX.i1659, align 8
  %877 = add i64 %871, -312
  %878 = add i64 %storemerge, 12
  store i64 %878, i64* %3, align 8
  %879 = inttoptr i64 %877 to i32*
  store i32 %875, i32* %879, align 4
  %880 = load i64, i64* %RBP.i, align 8
  %881 = add i64 %880, -336
  %882 = load i64, i64* %3, align 8
  %883 = add i64 %882, 7
  store i64 %883, i64* %3, align 8
  %884 = inttoptr i64 %881 to i32*
  %885 = load i32, i32* %884, align 4
  store i8 0, i8* %17, align 1
  %886 = and i32 %885, 255
  %887 = tail call i32 @llvm.ctpop.i32(i32 %886)
  %888 = trunc i32 %887 to i8
  %889 = and i8 %888, 1
  %890 = xor i8 %889, 1
  store i8 %890, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %891 = icmp eq i32 %885, 0
  %892 = zext i1 %891 to i8
  store i8 %892, i8* %20, align 1
  %893 = lshr i32 %885, 31
  %894 = trunc i32 %893 to i8
  store i8 %894, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v696 = select i1 %891, i64 49, i64 13
  %895 = add i64 %882, %.v696
  store i64 %895, i64* %3, align 8
  br i1 %891, label %block_.L_483bf0, label %block_483bcc

block_483bcc:                                     ; preds = %block_.L_483bb3
  %896 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %896, i64* %RAX.i1659, align 8
  %897 = add i64 %896, 71784
  %898 = add i64 %895, 15
  store i64 %898, i64* %3, align 8
  %899 = inttoptr i64 %897 to i64*
  %900 = load i64, i64* %899, align 8
  store i64 %900, i64* %RAX.i1659, align 8
  %901 = add i64 %880, -332
  %902 = add i64 %895, 22
  store i64 %902, i64* %3, align 8
  %903 = inttoptr i64 %901 to i32*
  %904 = load i32, i32* %903, align 4
  %905 = sext i32 %904 to i64
  store i64 %905, i64* %RCX.i1588, align 8
  %906 = shl nsw i64 %905, 2
  %907 = add i64 %906, %900
  %908 = add i64 %895, 25
  store i64 %908, i64* %3, align 8
  %909 = inttoptr i64 %907 to i32*
  %910 = load i32, i32* %909, align 4
  %911 = zext i32 %910 to i64
  store i64 %911, i64* %RDX.i1943, align 8
  %912 = add i64 %880, -532
  %913 = add i64 %895, 31
  store i64 %913, i64* %3, align 8
  %914 = inttoptr i64 %912 to i32*
  store i32 %910, i32* %914, align 4
  %915 = load i64, i64* %3, align 8
  %916 = add i64 %915, 18
  br label %block_.L_483bfd

block_.L_483bf0:                                  ; preds = %block_.L_483bb3
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %917 = add i64 %880, -532
  %918 = add i64 %895, 8
  store i64 %918, i64* %3, align 8
  %919 = inttoptr i64 %917 to i32*
  store i32 0, i32* %919, align 4
  %920 = load i64, i64* %3, align 8
  %921 = add i64 %920, 5
  store i64 %921, i64* %3, align 8
  br label %block_.L_483bfd

block_.L_483bfd:                                  ; preds = %block_.L_483bf0, %block_483bcc
  %storemerge124 = phi i64 [ %916, %block_483bcc ], [ %921, %block_.L_483bf0 ]
  %922 = load i64, i64* %RBP.i, align 8
  %923 = add i64 %922, -532
  %924 = add i64 %storemerge124, 6
  store i64 %924, i64* %3, align 8
  %925 = inttoptr i64 %923 to i32*
  %926 = load i32, i32* %925, align 4
  %927 = zext i32 %926 to i64
  store i64 %927, i64* %RAX.i1659, align 8
  %928 = add i64 %922, -336
  %929 = add i64 %storemerge124, 12
  store i64 %929, i64* %3, align 8
  %930 = inttoptr i64 %928 to i32*
  store i32 %926, i32* %930, align 4
  %.pre465 = load i64, i64* %3, align 8
  br label %block_.L_483c09

block_.L_483c09:                                  ; preds = %block_.L_483bfd, %routine_idivl__esi.exit6917
  %931 = phi i64 [ %.pre465, %block_.L_483bfd ], [ %829, %routine_idivl__esi.exit6917 ]
  %932 = load i64, i64* %RBP.i, align 8
  %933 = add i64 %932, -336
  %934 = add i64 %931, 7
  store i64 %934, i64* %3, align 8
  %935 = inttoptr i64 %933 to i32*
  %936 = load i32, i32* %935, align 4
  store i8 0, i8* %17, align 1
  %937 = and i32 %936, 255
  %938 = tail call i32 @llvm.ctpop.i32(i32 %937)
  %939 = trunc i32 %938 to i8
  %940 = and i8 %939, 1
  %941 = xor i8 %940, 1
  store i8 %941, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %942 = icmp eq i32 %936, 0
  %943 = zext i1 %942 to i8
  store i8 %943, i8* %20, align 1
  %944 = lshr i32 %936, 31
  %945 = trunc i32 %944 to i8
  store i8 %945, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v697 = select i1 %942, i64 57, i64 13
  %946 = add i64 %931, %.v697
  store i64 %946, i64* %3, align 8
  br i1 %942, label %block_.L_483c42, label %block_483c16

block_483c16:                                     ; preds = %block_.L_483c09
  %947 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %947, i64* %RAX.i1659, align 8
  %948 = add i64 %947, 104
  %949 = add i64 %946, 12
  store i64 %949, i64* %3, align 8
  %950 = inttoptr i64 %948 to i64*
  %951 = load i64, i64* %950, align 8
  store i64 %951, i64* %RAX.i1659, align 8
  %952 = add i64 %932, -320
  %953 = add i64 %946, 19
  store i64 %953, i64* %3, align 8
  %954 = inttoptr i64 %952 to i32*
  %955 = load i32, i32* %954, align 4
  %956 = sext i32 %955 to i64
  store i64 %956, i64* %RCX.i1588, align 8
  %957 = shl nsw i64 %956, 3
  %958 = add i64 %957, %951
  %959 = add i64 %946, 23
  store i64 %959, i64* %3, align 8
  %960 = inttoptr i64 %958 to i64*
  %961 = load i64, i64* %960, align 8
  store i64 %961, i64* %RAX.i1659, align 8
  %962 = add i64 %932, -316
  %963 = add i64 %946, 30
  store i64 %963, i64* %3, align 8
  %964 = inttoptr i64 %962 to i32*
  %965 = load i32, i32* %964, align 4
  %966 = sext i32 %965 to i64
  store i64 %966, i64* %RCX.i1588, align 8
  %967 = shl nsw i64 %966, 2
  %968 = add i64 %967, %961
  %969 = add i64 %946, 33
  store i64 %969, i64* %3, align 8
  %970 = inttoptr i64 %968 to i32*
  %971 = load i32, i32* %970, align 4
  %972 = zext i32 %971 to i64
  store i64 %972, i64* %RDX.i1943, align 8
  %973 = add i64 %932, -536
  %974 = add i64 %946, 39
  store i64 %974, i64* %3, align 8
  %975 = inttoptr i64 %973 to i32*
  store i32 %971, i32* %975, align 4
  %976 = load i64, i64* %3, align 8
  %977 = add i64 %976, 21
  br label %block_.L_483c52

block_.L_483c42:                                  ; preds = %block_.L_483c09
  store i64 4294967295, i64* %RAX.i1659, align 8
  %978 = add i64 %932, -536
  %979 = add i64 %946, 11
  store i64 %979, i64* %3, align 8
  %980 = inttoptr i64 %978 to i32*
  store i32 -1, i32* %980, align 4
  %981 = load i64, i64* %3, align 8
  %982 = add i64 %981, 5
  store i64 %982, i64* %3, align 8
  br label %block_.L_483c52

block_.L_483c52:                                  ; preds = %block_.L_483c42, %block_483c16
  %storemerge125 = phi i64 [ %977, %block_483c16 ], [ %982, %block_.L_483c42 ]
  %983 = load i64, i64* %RBP.i, align 8
  %984 = add i64 %983, -536
  %985 = add i64 %storemerge125, 6
  store i64 %985, i64* %3, align 8
  %986 = inttoptr i64 %984 to i32*
  %987 = load i32, i32* %986, align 4
  %988 = zext i32 %987 to i64
  store i64 %988, i64* %RAX.i1659, align 8
  %989 = add i64 %983, -280
  %990 = add i64 %storemerge125, 12
  store i64 %990, i64* %3, align 8
  %991 = inttoptr i64 %989 to i32*
  store i32 %987, i32* %991, align 4
  %992 = load i64, i64* %RBP.i, align 8
  %993 = add i64 %992, -312
  %994 = load i64, i64* %3, align 8
  %995 = add i64 %994, 7
  store i64 %995, i64* %3, align 8
  %996 = inttoptr i64 %993 to i32*
  %997 = load i32, i32* %996, align 4
  store i8 0, i8* %17, align 1
  %998 = and i32 %997, 255
  %999 = tail call i32 @llvm.ctpop.i32(i32 %998)
  %1000 = trunc i32 %999 to i8
  %1001 = and i8 %1000, 1
  %1002 = xor i8 %1001, 1
  store i8 %1002, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1003 = icmp eq i32 %997, 0
  %1004 = zext i1 %1003 to i8
  store i8 %1004, i8* %20, align 1
  %1005 = lshr i32 %997, 31
  %1006 = trunc i32 %1005 to i8
  store i8 %1006, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v698 = select i1 %1003, i64 57, i64 13
  %1007 = add i64 %994, %.v698
  store i64 %1007, i64* %3, align 8
  br i1 %1003, label %block_.L_483c97, label %block_483c6b

block_483c6b:                                     ; preds = %block_.L_483c52
  %1008 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1008, i64* %RAX.i1659, align 8
  %1009 = add i64 %1008, 104
  %1010 = add i64 %1007, 12
  store i64 %1010, i64* %3, align 8
  %1011 = inttoptr i64 %1009 to i64*
  %1012 = load i64, i64* %1011, align 8
  store i64 %1012, i64* %RAX.i1659, align 8
  %1013 = add i64 %992, -296
  %1014 = add i64 %1007, 19
  store i64 %1014, i64* %3, align 8
  %1015 = inttoptr i64 %1013 to i32*
  %1016 = load i32, i32* %1015, align 4
  %1017 = sext i32 %1016 to i64
  store i64 %1017, i64* %RCX.i1588, align 8
  %1018 = shl nsw i64 %1017, 3
  %1019 = add i64 %1018, %1012
  %1020 = add i64 %1007, 23
  store i64 %1020, i64* %3, align 8
  %1021 = inttoptr i64 %1019 to i64*
  %1022 = load i64, i64* %1021, align 8
  store i64 %1022, i64* %RAX.i1659, align 8
  %1023 = add i64 %992, -292
  %1024 = add i64 %1007, 30
  store i64 %1024, i64* %3, align 8
  %1025 = inttoptr i64 %1023 to i32*
  %1026 = load i32, i32* %1025, align 4
  %1027 = sext i32 %1026 to i64
  store i64 %1027, i64* %RCX.i1588, align 8
  %1028 = shl nsw i64 %1027, 2
  %1029 = add i64 %1028, %1022
  %1030 = add i64 %1007, 33
  store i64 %1030, i64* %3, align 8
  %1031 = inttoptr i64 %1029 to i32*
  %1032 = load i32, i32* %1031, align 4
  %1033 = zext i32 %1032 to i64
  store i64 %1033, i64* %RDX.i1943, align 8
  %1034 = add i64 %992, -540
  %1035 = add i64 %1007, 39
  store i64 %1035, i64* %3, align 8
  %1036 = inttoptr i64 %1034 to i32*
  store i32 %1032, i32* %1036, align 4
  %1037 = load i64, i64* %3, align 8
  %1038 = add i64 %1037, 21
  br label %block_.L_483ca7

block_.L_483c97:                                  ; preds = %block_.L_483c52
  store i64 4294967295, i64* %RAX.i1659, align 8
  %1039 = add i64 %992, -540
  %1040 = add i64 %1007, 11
  store i64 %1040, i64* %3, align 8
  %1041 = inttoptr i64 %1039 to i32*
  store i32 -1, i32* %1041, align 4
  %1042 = load i64, i64* %3, align 8
  %1043 = add i64 %1042, 5
  store i64 %1043, i64* %3, align 8
  br label %block_.L_483ca7

block_.L_483ca7:                                  ; preds = %block_.L_483c97, %block_483c6b
  %storemerge126 = phi i64 [ %1038, %block_483c6b ], [ %1043, %block_.L_483c97 ]
  %1044 = load i64, i64* %RBP.i, align 8
  %1045 = add i64 %1044, -540
  %1046 = add i64 %storemerge126, 6
  store i64 %1046, i64* %3, align 8
  %1047 = inttoptr i64 %1045 to i32*
  %1048 = load i32, i32* %1047, align 4
  %1049 = zext i32 %1048 to i64
  store i64 %1049, i64* %RAX.i1659, align 8
  %1050 = add i64 %1044, -284
  %1051 = add i64 %storemerge126, 12
  store i64 %1051, i64* %3, align 8
  %1052 = inttoptr i64 %1050 to i32*
  store i32 %1048, i32* %1052, align 4
  %1053 = load i64, i64* %RBP.i, align 8
  %1054 = add i64 %1053, -280
  %1055 = load i64, i64* %3, align 8
  %1056 = add i64 %1055, 7
  store i64 %1056, i64* %3, align 8
  %1057 = inttoptr i64 %1054 to i32*
  %1058 = load i32, i32* %1057, align 4
  store i8 0, i8* %17, align 1
  %1059 = and i32 %1058, 255
  %1060 = tail call i32 @llvm.ctpop.i32(i32 %1059)
  %1061 = trunc i32 %1060 to i8
  %1062 = and i8 %1061, 1
  %1063 = xor i8 %1062, 1
  store i8 %1063, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1064 = icmp eq i32 %1058, 0
  %1065 = zext i1 %1064 to i8
  store i8 %1065, i8* %20, align 1
  %1066 = lshr i32 %1058, 31
  %1067 = trunc i32 %1066 to i8
  store i8 %1067, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %1068 = icmp ne i8 %1067, 0
  %.v = select i1 %1068, i64 19, i64 6
  %1069 = add i64 %1056, %.v
  store i64 %1069, i64* %3, align 8
  br i1 %1068, label %block_.L_483ccd, label %block_483cc0

block_483cc0:                                     ; preds = %block_.L_483ca7
  %1070 = add i64 %1053, -284
  %1071 = add i64 %1069, 7
  store i64 %1071, i64* %3, align 8
  %1072 = inttoptr i64 %1070 to i32*
  %1073 = load i32, i32* %1072, align 4
  store i8 0, i8* %17, align 1
  %1074 = and i32 %1073, 255
  %1075 = tail call i32 @llvm.ctpop.i32(i32 %1074)
  %1076 = trunc i32 %1075 to i8
  %1077 = and i8 %1076, 1
  %1078 = xor i8 %1077, 1
  store i8 %1078, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1079 = icmp eq i32 %1073, 0
  %1080 = zext i1 %1079 to i8
  store i8 %1080, i8* %20, align 1
  %1081 = lshr i32 %1073, 31
  %1082 = trunc i32 %1081 to i8
  store i8 %1082, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %1083 = icmp ne i8 %1082, 0
  %.v294 = select i1 %1083, i64 6, i64 22
  %1084 = add i64 %1071, %.v294
  store i64 %1084, i64* %3, align 8
  br i1 %1083, label %block_.L_483ccd, label %block_.L_483cdd

block_.L_483ccd:                                  ; preds = %block_483cc0, %block_.L_483ca7
  %1085 = phi i64 [ %1084, %block_483cc0 ], [ %1069, %block_.L_483ca7 ]
  store i64 2, i64* %RAX.i1659, align 8
  %1086 = add i64 %1053, -544
  %1087 = add i64 %1085, 11
  store i64 %1087, i64* %3, align 8
  %1088 = inttoptr i64 %1086 to i32*
  store i32 2, i32* %1088, align 4
  %1089 = load i64, i64* %3, align 8
  %1090 = add i64 %1089, 64
  store i64 %1090, i64* %3, align 8
  br label %block_.L_483d18

block_.L_483cdd:                                  ; preds = %block_483cc0
  %1091 = add i64 %1084, 6
  store i64 %1091, i64* %3, align 8
  %1092 = load i32, i32* %1057, align 4
  %1093 = zext i32 %1092 to i64
  store i64 %1093, i64* %RAX.i1659, align 8
  %1094 = add i64 %1084, 12
  store i64 %1094, i64* %3, align 8
  %1095 = load i32, i32* %1072, align 4
  %1096 = sub i32 %1092, %1095
  %1097 = icmp ult i32 %1092, %1095
  %1098 = zext i1 %1097 to i8
  store i8 %1098, i8* %17, align 1
  %1099 = and i32 %1096, 255
  %1100 = tail call i32 @llvm.ctpop.i32(i32 %1099)
  %1101 = trunc i32 %1100 to i8
  %1102 = and i8 %1101, 1
  %1103 = xor i8 %1102, 1
  store i8 %1103, i8* %18, align 1
  %1104 = xor i32 %1095, %1092
  %1105 = xor i32 %1104, %1096
  %1106 = lshr i32 %1105, 4
  %1107 = trunc i32 %1106 to i8
  %1108 = and i8 %1107, 1
  store i8 %1108, i8* %19, align 1
  %1109 = icmp eq i32 %1096, 0
  %1110 = zext i1 %1109 to i8
  store i8 %1110, i8* %20, align 1
  %1111 = lshr i32 %1096, 31
  %1112 = trunc i32 %1111 to i8
  store i8 %1112, i8* %21, align 1
  %1113 = lshr i32 %1092, 31
  %1114 = lshr i32 %1095, 31
  %1115 = xor i32 %1114, %1113
  %1116 = xor i32 %1111, %1113
  %1117 = add nuw nsw i32 %1116, %1115
  %1118 = icmp eq i32 %1117, 2
  %1119 = zext i1 %1118 to i8
  store i8 %1119, i8* %22, align 1
  %1120 = icmp ne i8 %1112, 0
  %1121 = xor i1 %1120, %1118
  %.v699 = select i1 %1121, i64 18, i64 35
  %1122 = add i64 %1084, %.v699
  %1123 = add i64 %1122, 6
  store i64 %1123, i64* %3, align 8
  br i1 %1121, label %block_483cef, label %block_.L_483d00

block_483cef:                                     ; preds = %block_.L_483cdd
  %1124 = load i32, i32* %1057, align 4
  %1125 = zext i32 %1124 to i64
  store i64 %1125, i64* %RAX.i1659, align 8
  %1126 = add i64 %1053, -548
  %1127 = add i64 %1122, 12
  store i64 %1127, i64* %3, align 8
  %1128 = inttoptr i64 %1126 to i32*
  store i32 %1124, i32* %1128, align 4
  %1129 = load i64, i64* %3, align 8
  %1130 = add i64 %1129, 17
  store i64 %1130, i64* %3, align 8
  br label %block_.L_483d0c

block_.L_483d00:                                  ; preds = %block_.L_483cdd
  %1131 = load i32, i32* %1072, align 4
  %1132 = zext i32 %1131 to i64
  store i64 %1132, i64* %RAX.i1659, align 8
  %1133 = add i64 %1053, -548
  %1134 = add i64 %1122, 12
  store i64 %1134, i64* %3, align 8
  %1135 = inttoptr i64 %1133 to i32*
  store i32 %1131, i32* %1135, align 4
  %.pre466 = load i64, i64* %3, align 8
  br label %block_.L_483d0c

block_.L_483d0c:                                  ; preds = %block_.L_483d00, %block_483cef
  %1136 = phi i64 [ %.pre466, %block_.L_483d00 ], [ %1130, %block_483cef ]
  %1137 = load i64, i64* %RBP.i, align 8
  %1138 = add i64 %1137, -548
  %1139 = add i64 %1136, 6
  store i64 %1139, i64* %3, align 8
  %1140 = inttoptr i64 %1138 to i32*
  %1141 = load i32, i32* %1140, align 4
  %1142 = zext i32 %1141 to i64
  store i64 %1142, i64* %RAX.i1659, align 8
  %1143 = add i64 %1137, -544
  %1144 = add i64 %1136, 12
  store i64 %1144, i64* %3, align 8
  %1145 = inttoptr i64 %1143 to i32*
  store i32 %1141, i32* %1145, align 4
  %.pre467 = load i64, i64* %3, align 8
  br label %block_.L_483d18

block_.L_483d18:                                  ; preds = %block_.L_483d0c, %block_.L_483ccd
  %1146 = phi i64 [ %.pre467, %block_.L_483d0c ], [ %1090, %block_.L_483ccd ]
  %1147 = load i64, i64* %RBP.i, align 8
  %1148 = add i64 %1147, -544
  %1149 = add i64 %1146, 6
  store i64 %1149, i64* %3, align 8
  %1150 = inttoptr i64 %1148 to i32*
  %1151 = load i32, i32* %1150, align 4
  %1152 = zext i32 %1151 to i64
  store i64 %1152, i64* %RAX.i1659, align 8
  %1153 = add i64 %1147, -268
  store i64 %1153, i64* %RDX.i1943, align 8
  %1154 = add i64 %1147, -272
  store i64 %1154, i64* %RCX.i1588, align 8
  %1155 = add i64 %1147, -276
  store i64 %1155, i64* %25, align 8
  %1156 = add i64 %1147, -288
  %1157 = add i64 %1146, 33
  store i64 %1157, i64* %3, align 8
  %1158 = inttoptr i64 %1156 to i32*
  store i32 %1151, i32* %1158, align 4
  %1159 = load i64, i64* %RBP.i, align 8
  %1160 = add i64 %1159, -32
  %1161 = load i64, i64* %3, align 8
  %1162 = add i64 %1161, 4
  store i64 %1162, i64* %3, align 8
  %1163 = inttoptr i64 %1160 to i64*
  %1164 = load i64, i64* %1163, align 8
  store i64 %1164, i64* %RSI.i2015, align 8
  %1165 = add i64 %1161, 10
  store i64 %1165, i64* %3, align 8
  %1166 = inttoptr i64 %1164 to i32*
  store i32 2147483647, i32* %1166, align 4
  %1167 = load i64, i64* %RBP.i, align 8
  %1168 = add i64 %1167, -228
  %1169 = load i64, i64* %3, align 8
  %1170 = add i64 %1169, 6
  store i64 %1170, i64* %3, align 8
  %1171 = inttoptr i64 %1168 to i32*
  %1172 = load i32, i32* %1171, align 4
  %1173 = zext i32 %1172 to i64
  store i64 %1173, i64* %RDI.i6998, align 8
  %1174 = add i64 %1167, -232
  %1175 = add i64 %1169, 12
  store i64 %1175, i64* %3, align 8
  %1176 = inttoptr i64 %1174 to i32*
  %1177 = load i32, i32* %1176, align 4
  %1178 = zext i32 %1177 to i64
  store i64 %1178, i64* %RSI.i2015, align 8
  %1179 = add i64 %1169, -530323
  %1180 = add i64 %1169, 17
  %1181 = load i64, i64* %6, align 8
  %1182 = add i64 %1181, -8
  %1183 = inttoptr i64 %1182 to i64*
  store i64 %1180, i64* %1183, align 8
  store i64 %1182, i64* %6, align 8
  store i64 %1179, i64* %3, align 8
  %call2_483d4f = tail call %struct.Memory* @sub_4025b0.intrapred_luma(%struct.State* nonnull %0, i64 %1179, %struct.Memory* %call2_483b5a)
  %1184 = load i64, i64* %RBP.i, align 8
  %1185 = add i64 %1184, -36
  %1186 = load i64, i64* %3, align 8
  %1187 = add i64 %1186, 7
  store i64 %1187, i64* %3, align 8
  %1188 = inttoptr i64 %1185 to i32*
  store i32 0, i32* %1188, align 4
  %AL.i6698 = bitcast %union.anon* %29 to i8*
  %R9D.i5956 = bitcast %union.anon* %26 to i32*
  %1189 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1190 = bitcast i64* %1189 to double*
  %DX.i4863 = bitcast %union.anon* %72 to i16*
  %CX.i4340 = bitcast %union.anon* %23 to i16*
  %1191 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144) to i32), i32 255))
  %1192 = trunc i32 %1191 to i8
  %1193 = and i8 %1192, 1
  %1194 = xor i8 %1193, 1
  %1195 = bitcast %union.VectorReg* %63 to i8*
  %1196 = bitcast %union.VectorReg* %30 to i32*
  %1197 = getelementptr inbounds i8, i8* %31, i64 4
  %1198 = bitcast i8* %1197 to i32*
  %1199 = bitcast i64* %38 to i32*
  %1200 = getelementptr inbounds i8, i8* %31, i64 12
  %1201 = bitcast i8* %1200 to i32*
  %1202 = bitcast %union.VectorReg* %63 to i32*
  %1203 = getelementptr inbounds i8, i8* %1195, i64 4
  %1204 = bitcast i8* %1203 to i32*
  %1205 = bitcast i64* %1189 to i32*
  %1206 = getelementptr inbounds i8, i8* %1195, i64 12
  %1207 = bitcast i8* %1206 to i32*
  %.pre468 = load i64, i64* %3, align 8
  br label %block_.L_483d5b

block_.L_483d5b:                                  ; preds = %block_.L_4856b1, %block_.L_483d18
  %1208 = phi i64 [ %.pre468, %block_.L_483d18 ], [ %12861, %block_.L_4856b1 ]
  %MEMORY.8 = phi %struct.Memory* [ %call2_483d4f, %block_.L_483d18 ], [ %MEMORY.70, %block_.L_4856b1 ]
  %1209 = load i64, i64* %RBP.i, align 8
  %1210 = add i64 %1209, -36
  %1211 = add i64 %1208, 4
  store i64 %1211, i64* %3, align 8
  %1212 = inttoptr i64 %1210 to i32*
  %1213 = load i32, i32* %1212, align 4
  %1214 = add i32 %1213, -9
  %1215 = icmp ult i32 %1213, 9
  %1216 = zext i1 %1215 to i8
  store i8 %1216, i8* %17, align 1
  %1217 = and i32 %1214, 255
  %1218 = tail call i32 @llvm.ctpop.i32(i32 %1217)
  %1219 = trunc i32 %1218 to i8
  %1220 = and i8 %1219, 1
  %1221 = xor i8 %1220, 1
  store i8 %1221, i8* %18, align 1
  %1222 = xor i32 %1214, %1213
  %1223 = lshr i32 %1222, 4
  %1224 = trunc i32 %1223 to i8
  %1225 = and i8 %1224, 1
  store i8 %1225, i8* %19, align 1
  %1226 = icmp eq i32 %1214, 0
  %1227 = zext i1 %1226 to i8
  store i8 %1227, i8* %20, align 1
  %1228 = lshr i32 %1214, 31
  %1229 = trunc i32 %1228 to i8
  store i8 %1229, i8* %21, align 1
  %1230 = lshr i32 %1213, 31
  %1231 = xor i32 %1228, %1230
  %1232 = add nuw nsw i32 %1231, %1230
  %1233 = icmp eq i32 %1232, 2
  %1234 = zext i1 %1233 to i8
  store i8 %1234, i8* %22, align 1
  %1235 = icmp ne i8 %1229, 0
  %1236 = xor i1 %1235, %1233
  %.v700 = select i1 %1236, i64 10, i64 6500
  %1237 = add i64 %1208, %.v700
  store i64 %1237, i64* %3, align 8
  br i1 %1236, label %block_483d65, label %block_.L_4856bf

block_483d65:                                     ; preds = %block_.L_483d5b
  store i8 1, i8* %AL.i6698, align 1
  %1238 = add i64 %1237, 6
  store i64 %1238, i64* %3, align 8
  %1239 = load i32, i32* %1212, align 4
  %1240 = add i32 %1239, -2
  %1241 = icmp ult i32 %1239, 2
  %1242 = zext i1 %1241 to i8
  store i8 %1242, i8* %17, align 1
  %1243 = and i32 %1240, 255
  %1244 = tail call i32 @llvm.ctpop.i32(i32 %1243)
  %1245 = trunc i32 %1244 to i8
  %1246 = and i8 %1245, 1
  %1247 = xor i8 %1246, 1
  store i8 %1247, i8* %18, align 1
  %1248 = xor i32 %1240, %1239
  %1249 = lshr i32 %1248, 4
  %1250 = trunc i32 %1249 to i8
  %1251 = and i8 %1250, 1
  store i8 %1251, i8* %19, align 1
  %1252 = icmp eq i32 %1240, 0
  %1253 = zext i1 %1252 to i8
  store i8 %1253, i8* %20, align 1
  %1254 = lshr i32 %1240, 31
  %1255 = trunc i32 %1254 to i8
  store i8 %1255, i8* %21, align 1
  %1256 = lshr i32 %1239, 31
  %1257 = xor i32 %1254, %1256
  %1258 = add nuw nsw i32 %1257, %1256
  %1259 = icmp eq i32 %1258, 2
  %1260 = zext i1 %1259 to i8
  store i8 %1260, i8* %22, align 1
  %1261 = add i64 %1209, -549
  %1262 = add i64 %1237, 12
  store i64 %1262, i64* %3, align 8
  %1263 = inttoptr i64 %1261 to i8*
  store i8 1, i8* %1263, align 1
  %1264 = load i64, i64* %3, align 8
  %1265 = load i8, i8* %20, align 1
  %1266 = icmp ne i8 %1265, 0
  %.v878 = select i1 %1266, i64 114, i64 6
  %1267 = add i64 %1264, %.v878
  store i64 %1267, i64* %3, align 8
  %cmpBr_483d71 = icmp eq i8 %1265, 1
  br i1 %cmpBr_483d71, label %block_.L_483de3, label %block_483d77

block_483d77:                                     ; preds = %block_483d65
  %1268 = load i64, i64* %RBP.i, align 8
  %1269 = add i64 %1268, -36
  %1270 = add i64 %1267, 4
  store i64 %1270, i64* %3, align 8
  %1271 = inttoptr i64 %1269 to i32*
  %1272 = load i32, i32* %1271, align 4
  store i8 0, i8* %17, align 1
  %1273 = and i32 %1272, 255
  %1274 = tail call i32 @llvm.ctpop.i32(i32 %1273)
  %1275 = trunc i32 %1274 to i8
  %1276 = and i8 %1275, 1
  %1277 = xor i8 %1276, 1
  store i8 %1277, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1278 = icmp eq i32 %1272, 0
  %1279 = zext i1 %1278 to i8
  store i8 %1279, i8* %20, align 1
  %1280 = lshr i32 %1272, 31
  %1281 = trunc i32 %1280 to i8
  store i8 %1281, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v723 = select i1 %1278, i64 30, i64 10
  %1282 = add i64 %1267, %.v723
  store i64 %1282, i64* %3, align 8
  br i1 %1278, label %block_.L_483d95, label %block_483d81

block_483d81:                                     ; preds = %block_483d77
  %1283 = add i64 %1282, 4
  store i64 %1283, i64* %3, align 8
  %1284 = load i32, i32* %1271, align 4
  %1285 = add i32 %1284, -7
  %1286 = icmp ult i32 %1284, 7
  %1287 = zext i1 %1286 to i8
  store i8 %1287, i8* %17, align 1
  %1288 = and i32 %1285, 255
  %1289 = tail call i32 @llvm.ctpop.i32(i32 %1288)
  %1290 = trunc i32 %1289 to i8
  %1291 = and i8 %1290, 1
  %1292 = xor i8 %1291, 1
  store i8 %1292, i8* %18, align 1
  %1293 = xor i32 %1285, %1284
  %1294 = lshr i32 %1293, 4
  %1295 = trunc i32 %1294 to i8
  %1296 = and i8 %1295, 1
  store i8 %1296, i8* %19, align 1
  %1297 = icmp eq i32 %1285, 0
  %1298 = zext i1 %1297 to i8
  store i8 %1298, i8* %20, align 1
  %1299 = lshr i32 %1285, 31
  %1300 = trunc i32 %1299 to i8
  store i8 %1300, i8* %21, align 1
  %1301 = lshr i32 %1284, 31
  %1302 = xor i32 %1299, %1301
  %1303 = add nuw nsw i32 %1302, %1301
  %1304 = icmp eq i32 %1303, 2
  %1305 = zext i1 %1304 to i8
  store i8 %1305, i8* %22, align 1
  %.v724 = select i1 %1297, i64 20, i64 10
  %1306 = add i64 %1282, %.v724
  store i64 %1306, i64* %3, align 8
  br i1 %1297, label %block_.L_483d95, label %block_483d8b

block_483d8b:                                     ; preds = %block_483d81
  %1307 = add i64 %1306, 4
  store i64 %1307, i64* %3, align 8
  %1308 = load i32, i32* %1271, align 4
  %1309 = add i32 %1308, -3
  %1310 = icmp ult i32 %1308, 3
  %1311 = zext i1 %1310 to i8
  store i8 %1311, i8* %17, align 1
  %1312 = and i32 %1309, 255
  %1313 = tail call i32 @llvm.ctpop.i32(i32 %1312)
  %1314 = trunc i32 %1313 to i8
  %1315 = and i8 %1314, 1
  %1316 = xor i8 %1315, 1
  store i8 %1316, i8* %18, align 1
  %1317 = xor i32 %1309, %1308
  %1318 = lshr i32 %1317, 4
  %1319 = trunc i32 %1318 to i8
  %1320 = and i8 %1319, 1
  store i8 %1320, i8* %19, align 1
  %1321 = icmp eq i32 %1309, 0
  %1322 = zext i1 %1321 to i8
  store i8 %1322, i8* %20, align 1
  %1323 = lshr i32 %1309, 31
  %1324 = trunc i32 %1323 to i8
  store i8 %1324, i8* %21, align 1
  %1325 = lshr i32 %1308, 31
  %1326 = xor i32 %1323, %1325
  %1327 = add nuw nsw i32 %1326, %1325
  %1328 = icmp eq i32 %1327, 2
  %1329 = zext i1 %1328 to i8
  store i8 %1329, i8* %22, align 1
  %.v725 = select i1 %1321, i64 10, i64 31
  %1330 = add i64 %1306, %.v725
  store i64 %1330, i64* %3, align 8
  br i1 %1321, label %block_.L_483d95, label %block_.L_483daa

block_.L_483d95:                                  ; preds = %block_483d8b, %block_483d81, %block_483d77
  %1331 = phi i64 [ %1330, %block_483d8b ], [ %1306, %block_483d81 ], [ %1282, %block_483d77 ]
  store i8 1, i8* %AL.i6698, align 1
  %1332 = add i64 %1268, -272
  %1333 = add i64 %1331, 9
  store i64 %1333, i64* %3, align 8
  %1334 = inttoptr i64 %1332 to i32*
  %1335 = load i32, i32* %1334, align 4
  store i8 0, i8* %17, align 1
  %1336 = and i32 %1335, 255
  %1337 = tail call i32 @llvm.ctpop.i32(i32 %1336)
  %1338 = trunc i32 %1337 to i8
  %1339 = and i8 %1338, 1
  %1340 = xor i8 %1339, 1
  store i8 %1340, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1341 = icmp eq i32 %1335, 0
  %1342 = zext i1 %1341 to i8
  store i8 %1342, i8* %20, align 1
  %1343 = lshr i32 %1335, 31
  %1344 = trunc i32 %1343 to i8
  store i8 %1344, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %1345 = add i64 %1268, -549
  %1346 = add i64 %1331, 15
  store i64 %1346, i64* %3, align 8
  %1347 = inttoptr i64 %1345 to i8*
  store i8 1, i8* %1347, align 1
  %1348 = load i64, i64* %3, align 8
  %1349 = add i64 %1348, 63
  %1350 = add i64 %1348, 6
  %1351 = load i8, i8* %20, align 1
  %1352 = icmp eq i8 %1351, 0
  %1353 = select i1 %1352, i64 %1349, i64 %1350
  store i64 %1353, i64* %3, align 8
  br i1 %1352, label %block_.L_483de3, label %block_.L_483d95.block_.L_483daa_crit_edge

block_.L_483d95.block_.L_483daa_crit_edge:        ; preds = %block_.L_483d95
  %.pre564 = load i64, i64* %RBP.i, align 8
  br label %block_.L_483daa

block_.L_483daa:                                  ; preds = %block_483d8b, %block_.L_483d95.block_.L_483daa_crit_edge
  %1354 = phi i64 [ %1350, %block_.L_483d95.block_.L_483daa_crit_edge ], [ %1330, %block_483d8b ]
  %1355 = phi i64 [ %.pre564, %block_.L_483d95.block_.L_483daa_crit_edge ], [ %1268, %block_483d8b ]
  %1356 = add i64 %1355, -36
  %1357 = add i64 %1354, 4
  store i64 %1357, i64* %3, align 8
  %1358 = inttoptr i64 %1356 to i32*
  %1359 = load i32, i32* %1358, align 4
  %1360 = add i32 %1359, -1
  %1361 = icmp eq i32 %1359, 0
  %1362 = zext i1 %1361 to i8
  store i8 %1362, i8* %17, align 1
  %1363 = and i32 %1360, 255
  %1364 = tail call i32 @llvm.ctpop.i32(i32 %1363)
  %1365 = trunc i32 %1364 to i8
  %1366 = and i8 %1365, 1
  %1367 = xor i8 %1366, 1
  store i8 %1367, i8* %18, align 1
  %1368 = xor i32 %1360, %1359
  %1369 = lshr i32 %1368, 4
  %1370 = trunc i32 %1369 to i8
  %1371 = and i8 %1370, 1
  store i8 %1371, i8* %19, align 1
  %1372 = icmp eq i32 %1360, 0
  %1373 = zext i1 %1372 to i8
  store i8 %1373, i8* %20, align 1
  %1374 = lshr i32 %1360, 31
  %1375 = trunc i32 %1374 to i8
  store i8 %1375, i8* %21, align 1
  %1376 = lshr i32 %1359, 31
  %1377 = xor i32 %1374, %1376
  %1378 = add nuw nsw i32 %1377, %1376
  %1379 = icmp eq i32 %1378, 2
  %1380 = zext i1 %1379 to i8
  store i8 %1380, i8* %22, align 1
  %.v726 = select i1 %1372, i64 20, i64 10
  %1381 = add i64 %1354, %.v726
  store i64 %1381, i64* %3, align 8
  br i1 %1372, label %block_.L_483dbe, label %block_483db4

block_483db4:                                     ; preds = %block_.L_483daa
  %1382 = add i64 %1381, 4
  store i64 %1382, i64* %3, align 8
  %1383 = load i32, i32* %1358, align 4
  %1384 = add i32 %1383, -8
  %1385 = icmp ult i32 %1383, 8
  %1386 = zext i1 %1385 to i8
  store i8 %1386, i8* %17, align 1
  %1387 = and i32 %1384, 255
  %1388 = tail call i32 @llvm.ctpop.i32(i32 %1387)
  %1389 = trunc i32 %1388 to i8
  %1390 = and i8 %1389, 1
  %1391 = xor i8 %1390, 1
  store i8 %1391, i8* %18, align 1
  %1392 = xor i32 %1384, %1383
  %1393 = lshr i32 %1392, 4
  %1394 = trunc i32 %1393 to i8
  %1395 = and i8 %1394, 1
  store i8 %1395, i8* %19, align 1
  %1396 = icmp eq i32 %1384, 0
  %1397 = zext i1 %1396 to i8
  store i8 %1397, i8* %20, align 1
  %1398 = lshr i32 %1384, 31
  %1399 = trunc i32 %1398 to i8
  store i8 %1399, i8* %21, align 1
  %1400 = lshr i32 %1383, 31
  %1401 = xor i32 %1398, %1400
  %1402 = add nuw nsw i32 %1401, %1400
  %1403 = icmp eq i32 %1402, 2
  %1404 = zext i1 %1403 to i8
  store i8 %1404, i8* %22, align 1
  %.v727 = select i1 %1396, i64 10, i64 31
  %1405 = add i64 %1381, %.v727
  store i64 %1405, i64* %3, align 8
  br i1 %1396, label %block_.L_483dbe, label %block_.L_483dd3

block_.L_483dbe:                                  ; preds = %block_483db4, %block_.L_483daa
  %1406 = phi i64 [ %1405, %block_483db4 ], [ %1381, %block_.L_483daa ]
  store i8 1, i8* %AL.i6698, align 1
  %1407 = add i64 %1355, -268
  %1408 = add i64 %1406, 9
  store i64 %1408, i64* %3, align 8
  %1409 = inttoptr i64 %1407 to i32*
  %1410 = load i32, i32* %1409, align 4
  store i8 0, i8* %17, align 1
  %1411 = and i32 %1410, 255
  %1412 = tail call i32 @llvm.ctpop.i32(i32 %1411)
  %1413 = trunc i32 %1412 to i8
  %1414 = and i8 %1413, 1
  %1415 = xor i8 %1414, 1
  store i8 %1415, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1416 = icmp eq i32 %1410, 0
  %1417 = zext i1 %1416 to i8
  store i8 %1417, i8* %20, align 1
  %1418 = lshr i32 %1410, 31
  %1419 = trunc i32 %1418 to i8
  store i8 %1419, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %1420 = add i64 %1355, -549
  %1421 = add i64 %1406, 15
  store i64 %1421, i64* %3, align 8
  %1422 = inttoptr i64 %1420 to i8*
  store i8 1, i8* %1422, align 1
  %1423 = load i64, i64* %3, align 8
  %1424 = add i64 %1423, 22
  %1425 = add i64 %1423, 6
  %1426 = load i8, i8* %20, align 1
  %1427 = icmp eq i8 %1426, 0
  %1428 = select i1 %1427, i64 %1424, i64 %1425
  store i64 %1428, i64* %3, align 8
  br i1 %1427, label %block_.L_483de3, label %block_.L_483dbe.block_.L_483dd3_crit_edge

block_.L_483dbe.block_.L_483dd3_crit_edge:        ; preds = %block_.L_483dbe
  %.pre565 = load i64, i64* %RBP.i, align 8
  br label %block_.L_483dd3

block_.L_483dd3:                                  ; preds = %block_483db4, %block_.L_483dbe.block_.L_483dd3_crit_edge
  %1429 = phi i64 [ %1425, %block_.L_483dbe.block_.L_483dd3_crit_edge ], [ %1405, %block_483db4 ]
  %1430 = phi i64 [ %.pre565, %block_.L_483dbe.block_.L_483dd3_crit_edge ], [ %1355, %block_483db4 ]
  %1431 = add i64 %1430, -276
  %1432 = add i64 %1429, 7
  store i64 %1432, i64* %3, align 8
  %1433 = inttoptr i64 %1431 to i32*
  %1434 = load i32, i32* %1433, align 4
  store i8 0, i8* %17, align 1
  %1435 = and i32 %1434, 255
  %1436 = tail call i32 @llvm.ctpop.i32(i32 %1435)
  %1437 = trunc i32 %1436 to i8
  %1438 = and i8 %1437, 1
  %1439 = xor i8 %1438, 1
  store i8 %1439, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1440 = icmp eq i32 %1434, 0
  %1441 = zext i1 %1440 to i8
  store i8 %1441, i8* %20, align 1
  %1442 = lshr i32 %1434, 31
  %1443 = trunc i32 %1442 to i8
  store i8 %1443, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %1444 = xor i1 %1440, true
  %1445 = zext i1 %1444 to i8
  store i8 %1445, i8* %AL.i6698, align 1
  %1446 = add i64 %1430, -549
  %1447 = add i64 %1429, 16
  store i64 %1447, i64* %3, align 8
  %1448 = inttoptr i64 %1446 to i8*
  store i8 %1445, i8* %1448, align 1
  %.pre566 = load i64, i64* %3, align 8
  br label %block_.L_483de3

block_.L_483de3:                                  ; preds = %block_.L_483dd3, %block_.L_483dbe, %block_.L_483d95, %block_483d65
  %1449 = phi i64 [ %.pre566, %block_.L_483dd3 ], [ %1424, %block_.L_483dbe ], [ %1349, %block_.L_483d95 ], [ %1267, %block_483d65 ]
  %1450 = load i64, i64* %RBP.i, align 8
  %1451 = add i64 %1450, -549
  %1452 = add i64 %1449, 6
  store i64 %1452, i64* %3, align 8
  %1453 = inttoptr i64 %1451 to i8*
  %1454 = load i8, i8* %1453, align 1
  %1455 = and i8 %1454, 1
  store i8 %1455, i8* %AL.i6698, align 1
  store i8 0, i8* %17, align 1
  %1456 = zext i8 %1455 to i32
  %1457 = tail call i32 @llvm.ctpop.i32(i32 %1456)
  %1458 = trunc i32 %1457 to i8
  %1459 = xor i8 %1458, 1
  store i8 %1459, i8* %18, align 1
  %1460 = xor i8 %1455, 1
  store i8 %1460, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %1461 = zext i8 %1455 to i64
  store i64 %1461, i64* %RCX.i1588, align 8
  %1462 = add i64 %1450, -500
  %1463 = zext i8 %1455 to i32
  %1464 = add i64 %1449, 17
  store i64 %1464, i64* %3, align 8
  %1465 = inttoptr i64 %1462 to i32*
  store i32 %1463, i32* %1465, align 4
  %1466 = load i64, i64* %3, align 8
  %1467 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %1467, i64* %RDX.i1943, align 8
  %1468 = add i64 %1467, 2396
  %1469 = add i64 %1466, 15
  store i64 %1469, i64* %3, align 8
  %1470 = inttoptr i64 %1468 to i32*
  %1471 = load i32, i32* %1470, align 4
  store i8 0, i8* %17, align 1
  %1472 = and i32 %1471, 255
  %1473 = tail call i32 @llvm.ctpop.i32(i32 %1472)
  %1474 = trunc i32 %1473 to i8
  %1475 = and i8 %1474, 1
  %1476 = xor i8 %1475, 1
  store i8 %1476, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1477 = icmp eq i32 %1471, 0
  %1478 = zext i1 %1477 to i8
  store i8 %1478, i8* %20, align 1
  %1479 = lshr i32 %1471, 31
  %1480 = trunc i32 %1479 to i8
  store i8 %1480, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v728 = select i1 %1477, i64 39, i64 21
  %1481 = add i64 %1466, %.v728
  store i64 %1481, i64* %3, align 8
  br i1 %1477, label %block_.L_483e1b, label %block_483e09

block_483e09:                                     ; preds = %block_.L_483de3
  %1482 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1482, i64* %RAX.i1659, align 8
  %1483 = add i64 %1482, 24
  %1484 = add i64 %1481, 12
  store i64 %1484, i64* %3, align 8
  %1485 = inttoptr i64 %1483 to i32*
  %1486 = load i32, i32* %1485, align 4
  %1487 = add i32 %1486, -2
  %1488 = icmp ult i32 %1486, 2
  %1489 = zext i1 %1488 to i8
  store i8 %1489, i8* %17, align 1
  %1490 = and i32 %1487, 255
  %1491 = tail call i32 @llvm.ctpop.i32(i32 %1490)
  %1492 = trunc i32 %1491 to i8
  %1493 = and i8 %1492, 1
  %1494 = xor i8 %1493, 1
  store i8 %1494, i8* %18, align 1
  %1495 = xor i32 %1487, %1486
  %1496 = lshr i32 %1495, 4
  %1497 = trunc i32 %1496 to i8
  %1498 = and i8 %1497, 1
  store i8 %1498, i8* %19, align 1
  %1499 = icmp eq i32 %1487, 0
  %1500 = zext i1 %1499 to i8
  store i8 %1500, i8* %20, align 1
  %1501 = lshr i32 %1487, 31
  %1502 = trunc i32 %1501 to i8
  store i8 %1502, i8* %21, align 1
  %1503 = lshr i32 %1486, 31
  %1504 = xor i32 %1501, %1503
  %1505 = add nuw nsw i32 %1504, %1503
  %1506 = icmp eq i32 %1505, 2
  %1507 = zext i1 %1506 to i8
  store i8 %1507, i8* %22, align 1
  %.v729 = select i1 %1499, i64 151, i64 18
  %1508 = add i64 %1481, %.v729
  store i64 %1508, i64* %3, align 8
  br i1 %1499, label %block_.L_483ea0, label %block_.L_483e1b

block_.L_483e1b:                                  ; preds = %block_483e09, %block_.L_483de3
  %1509 = phi i64 [ %1508, %block_483e09 ], [ %1481, %block_.L_483de3 ]
  store i64 %1467, i64* %RAX.i1659, align 8
  %1510 = add i64 %1467, 2400
  %1511 = add i64 %1509, 15
  store i64 %1511, i64* %3, align 8
  %1512 = inttoptr i64 %1510 to i32*
  %1513 = load i32, i32* %1512, align 4
  store i8 0, i8* %17, align 1
  %1514 = and i32 %1513, 255
  %1515 = tail call i32 @llvm.ctpop.i32(i32 %1514)
  %1516 = trunc i32 %1515 to i8
  %1517 = and i8 %1516, 1
  %1518 = xor i8 %1517, 1
  store i8 %1518, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1519 = icmp eq i32 %1513, 0
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %20, align 1
  %1521 = lshr i32 %1513, 31
  %1522 = trunc i32 %1521 to i8
  store i8 %1522, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v730 = select i1 %1519, i64 46, i64 21
  %1523 = add i64 %1509, %.v730
  store i64 %1523, i64* %3, align 8
  br i1 %1519, label %block_.L_483e49, label %block_483e30

block_483e30:                                     ; preds = %block_.L_483e1b
  %1524 = load i64, i64* %RBP.i, align 8
  %1525 = add i64 %1524, -36
  %1526 = add i64 %1523, 4
  store i64 %1526, i64* %3, align 8
  %1527 = inttoptr i64 %1525 to i32*
  %1528 = load i32, i32* %1527, align 4
  store i8 0, i8* %17, align 1
  %1529 = and i32 %1528, 255
  %1530 = tail call i32 @llvm.ctpop.i32(i32 %1529)
  %1531 = trunc i32 %1530 to i8
  %1532 = and i8 %1531, 1
  %1533 = xor i8 %1532, 1
  store i8 %1533, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1534 = icmp eq i32 %1528, 0
  %1535 = zext i1 %1534 to i8
  store i8 %1535, i8* %20, align 1
  %1536 = lshr i32 %1528, 31
  %1537 = trunc i32 %1536 to i8
  store i8 %1537, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v731 = select i1 %1534, i64 20, i64 10
  %1538 = add i64 %1523, %.v731
  store i64 %1538, i64* %3, align 8
  br i1 %1534, label %block_.L_4856b1, label %block_483e3a

block_483e3a:                                     ; preds = %block_483e30
  %1539 = add i64 %1538, 4
  store i64 %1539, i64* %3, align 8
  %1540 = load i32, i32* %1527, align 4
  %1541 = add i32 %1540, -1
  %1542 = icmp eq i32 %1540, 0
  %1543 = zext i1 %1542 to i8
  store i8 %1543, i8* %17, align 1
  %1544 = and i32 %1541, 255
  %1545 = tail call i32 @llvm.ctpop.i32(i32 %1544)
  %1546 = trunc i32 %1545 to i8
  %1547 = and i8 %1546, 1
  %1548 = xor i8 %1547, 1
  store i8 %1548, i8* %18, align 1
  %1549 = xor i32 %1541, %1540
  %1550 = lshr i32 %1549, 4
  %1551 = trunc i32 %1550 to i8
  %1552 = and i8 %1551, 1
  store i8 %1552, i8* %19, align 1
  %1553 = icmp eq i32 %1541, 0
  %1554 = zext i1 %1553 to i8
  store i8 %1554, i8* %20, align 1
  %1555 = lshr i32 %1541, 31
  %1556 = trunc i32 %1555 to i8
  store i8 %1556, i8* %21, align 1
  %1557 = lshr i32 %1540, 31
  %1558 = xor i32 %1555, %1557
  %1559 = add nuw nsw i32 %1558, %1557
  %1560 = icmp eq i32 %1559, 2
  %1561 = zext i1 %1560 to i8
  store i8 %1561, i8* %22, align 1
  %.v732 = select i1 %1553, i64 10, i64 15
  %1562 = add i64 %1538, %.v732
  store i64 %1562, i64* %3, align 8
  br i1 %1553, label %block_.L_4856b1, label %block_.L_483e49

block_.L_483e49:                                  ; preds = %block_483e3a, %block_.L_483e1b
  %1563 = phi i64 [ %1562, %block_483e3a ], [ %1523, %block_.L_483e1b ]
  store i64 %1467, i64* %RAX.i1659, align 8
  %1564 = add i64 %1467, 2404
  %1565 = add i64 %1563, 15
  store i64 %1565, i64* %3, align 8
  %1566 = inttoptr i64 %1564 to i32*
  %1567 = load i32, i32* %1566, align 4
  store i8 0, i8* %17, align 1
  %1568 = and i32 %1567, 255
  %1569 = tail call i32 @llvm.ctpop.i32(i32 %1568)
  %1570 = trunc i32 %1569 to i8
  %1571 = and i8 %1570, 1
  %1572 = xor i8 %1571, 1
  store i8 %1572, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1573 = icmp eq i32 %1567, 0
  %1574 = zext i1 %1573 to i8
  store i8 %1574, i8* %20, align 1
  %1575 = lshr i32 %1567, 31
  %1576 = trunc i32 %1575 to i8
  store i8 %1576, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v733 = select i1 %1573, i64 46, i64 21
  %1577 = add i64 %1563, %.v733
  store i64 %1577, i64* %3, align 8
  br i1 %1573, label %block_.L_483e77, label %block_483e5e

block_483e5e:                                     ; preds = %block_.L_483e49
  %1578 = load i64, i64* %RBP.i, align 8
  %1579 = add i64 %1578, -36
  %1580 = add i64 %1577, 4
  store i64 %1580, i64* %3, align 8
  %1581 = inttoptr i64 %1579 to i32*
  %1582 = load i32, i32* %1581, align 4
  %1583 = add i32 %1582, -3
  %1584 = icmp ult i32 %1582, 3
  %1585 = zext i1 %1584 to i8
  store i8 %1585, i8* %17, align 1
  %1586 = and i32 %1583, 255
  %1587 = tail call i32 @llvm.ctpop.i32(i32 %1586)
  %1588 = trunc i32 %1587 to i8
  %1589 = and i8 %1588, 1
  %1590 = xor i8 %1589, 1
  store i8 %1590, i8* %18, align 1
  %1591 = xor i32 %1583, %1582
  %1592 = lshr i32 %1591, 4
  %1593 = trunc i32 %1592 to i8
  %1594 = and i8 %1593, 1
  store i8 %1594, i8* %19, align 1
  %1595 = icmp eq i32 %1583, 0
  %1596 = zext i1 %1595 to i8
  store i8 %1596, i8* %20, align 1
  %1597 = lshr i32 %1583, 31
  %1598 = trunc i32 %1597 to i8
  store i8 %1598, i8* %21, align 1
  %1599 = lshr i32 %1582, 31
  %1600 = xor i32 %1597, %1599
  %1601 = add nuw nsw i32 %1600, %1599
  %1602 = icmp eq i32 %1601, 2
  %1603 = zext i1 %1602 to i8
  store i8 %1603, i8* %22, align 1
  %.v734 = select i1 %1595, i64 20, i64 10
  %1604 = add i64 %1577, %.v734
  store i64 %1604, i64* %3, align 8
  br i1 %1595, label %block_.L_4856b1, label %block_483e68

block_483e68:                                     ; preds = %block_483e5e
  %1605 = add i64 %1604, 4
  store i64 %1605, i64* %3, align 8
  %1606 = load i32, i32* %1581, align 4
  %1607 = add i32 %1606, -4
  %1608 = icmp ult i32 %1606, 4
  %1609 = zext i1 %1608 to i8
  store i8 %1609, i8* %17, align 1
  %1610 = and i32 %1607, 255
  %1611 = tail call i32 @llvm.ctpop.i32(i32 %1610)
  %1612 = trunc i32 %1611 to i8
  %1613 = and i8 %1612, 1
  %1614 = xor i8 %1613, 1
  store i8 %1614, i8* %18, align 1
  %1615 = xor i32 %1607, %1606
  %1616 = lshr i32 %1615, 4
  %1617 = trunc i32 %1616 to i8
  %1618 = and i8 %1617, 1
  store i8 %1618, i8* %19, align 1
  %1619 = icmp eq i32 %1607, 0
  %1620 = zext i1 %1619 to i8
  store i8 %1620, i8* %20, align 1
  %1621 = lshr i32 %1607, 31
  %1622 = trunc i32 %1621 to i8
  store i8 %1622, i8* %21, align 1
  %1623 = lshr i32 %1606, 31
  %1624 = xor i32 %1621, %1623
  %1625 = add nuw nsw i32 %1624, %1623
  %1626 = icmp eq i32 %1625, 2
  %1627 = zext i1 %1626 to i8
  store i8 %1627, i8* %22, align 1
  %.v735 = select i1 %1619, i64 10, i64 15
  %1628 = add i64 %1604, %.v735
  store i64 %1628, i64* %3, align 8
  br i1 %1619, label %block_.L_4856b1, label %block_.L_483e77

block_.L_483e77:                                  ; preds = %block_483e68, %block_.L_483e49
  %1629 = phi i64 [ %1628, %block_483e68 ], [ %1577, %block_.L_483e49 ]
  store i64 %1467, i64* %RAX.i1659, align 8
  %1630 = add i64 %1467, 2408
  %1631 = add i64 %1629, 15
  store i64 %1631, i64* %3, align 8
  %1632 = inttoptr i64 %1630 to i32*
  %1633 = load i32, i32* %1632, align 4
  store i8 0, i8* %17, align 1
  %1634 = and i32 %1633, 255
  %1635 = tail call i32 @llvm.ctpop.i32(i32 %1634)
  %1636 = trunc i32 %1635 to i8
  %1637 = and i8 %1636, 1
  %1638 = xor i8 %1637, 1
  store i8 %1638, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1639 = icmp eq i32 %1633, 0
  %1640 = zext i1 %1639 to i8
  store i8 %1640, i8* %20, align 1
  %1641 = lshr i32 %1633, 31
  %1642 = trunc i32 %1641 to i8
  store i8 %1642, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v736 = select i1 %1639, i64 36, i64 21
  %1643 = add i64 %1629, %.v736
  store i64 %1643, i64* %3, align 8
  br i1 %1639, label %block_.L_483e9b, label %block_483e8c

block_483e8c:                                     ; preds = %block_.L_483e77
  %1644 = load i64, i64* %RBP.i, align 8
  %1645 = add i64 %1644, -36
  %1646 = add i64 %1643, 4
  store i64 %1646, i64* %3, align 8
  %1647 = inttoptr i64 %1645 to i32*
  %1648 = load i32, i32* %1647, align 4
  %1649 = add i32 %1648, -5
  %1650 = icmp ult i32 %1648, 5
  %1651 = zext i1 %1650 to i8
  store i8 %1651, i8* %17, align 1
  %1652 = and i32 %1649, 255
  %1653 = tail call i32 @llvm.ctpop.i32(i32 %1652)
  %1654 = trunc i32 %1653 to i8
  %1655 = and i8 %1654, 1
  %1656 = xor i8 %1655, 1
  store i8 %1656, i8* %18, align 1
  %1657 = xor i32 %1649, %1648
  %1658 = lshr i32 %1657, 4
  %1659 = trunc i32 %1658 to i8
  %1660 = and i8 %1659, 1
  store i8 %1660, i8* %19, align 1
  %1661 = icmp eq i32 %1649, 0
  %1662 = zext i1 %1661 to i8
  store i8 %1662, i8* %20, align 1
  %1663 = lshr i32 %1649, 31
  %1664 = trunc i32 %1663 to i8
  store i8 %1664, i8* %21, align 1
  %1665 = lshr i32 %1648, 31
  %1666 = xor i32 %1663, %1665
  %1667 = add nuw nsw i32 %1666, %1665
  %1668 = icmp eq i32 %1667, 2
  %1669 = zext i1 %1668 to i8
  store i8 %1669, i8* %22, align 1
  %1670 = icmp ne i8 %1664, 0
  %1671 = xor i1 %1670, %1668
  %.v737 = select i1 %1671, i64 15, i64 10
  %1672 = add i64 %1643, %.v737
  store i64 %1672, i64* %3, align 8
  br i1 %1671, label %block_.L_483e9b, label %block_.L_4856b1

block_.L_483e9b:                                  ; preds = %block_483e8c, %block_.L_483e77
  %1673 = phi i64 [ %1672, %block_483e8c ], [ %1643, %block_.L_483e77 ]
  %1674 = add i64 %1673, 5
  store i64 %1674, i64* %3, align 8
  br label %block_.L_483ea0

block_.L_483ea0:                                  ; preds = %block_.L_483e9b, %block_483e09
  %1675 = phi i64 [ %1674, %block_.L_483e9b ], [ %1508, %block_483e09 ]
  %1676 = load i64, i64* %RBP.i, align 8
  %1677 = add i64 %1676, -500
  %1678 = add i64 %1675, 7
  store i64 %1678, i64* %3, align 8
  %1679 = inttoptr i64 %1677 to i32*
  %1680 = load i32, i32* %1679, align 4
  store i8 0, i8* %17, align 1
  %1681 = and i32 %1680, 255
  %1682 = tail call i32 @llvm.ctpop.i32(i32 %1681)
  %1683 = trunc i32 %1682 to i8
  %1684 = and i8 %1683, 1
  %1685 = xor i8 %1684, 1
  store i8 %1685, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1686 = icmp eq i32 %1680, 0
  %1687 = zext i1 %1686 to i8
  store i8 %1687, i8* %20, align 1
  %1688 = lshr i32 %1680, 31
  %1689 = trunc i32 %1688 to i8
  store i8 %1689, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v676 = select i1 %1686, i64 6156, i64 13
  %1690 = add i64 %1675, %.v676
  store i64 %1690, i64* %3, align 8
  br i1 %1686, label %block_.L_4856b1, label %block_483ead

block_483ead:                                     ; preds = %block_.L_483ea0
  store i64 %1467, i64* %RAX.i1659, align 8
  %1691 = add i64 %1467, 2464
  %1692 = add i64 %1690, 15
  store i64 %1692, i64* %3, align 8
  %1693 = inttoptr i64 %1691 to i32*
  %1694 = load i32, i32* %1693, align 4
  store i8 0, i8* %17, align 1
  %1695 = and i32 %1694, 255
  %1696 = tail call i32 @llvm.ctpop.i32(i32 %1695)
  %1697 = trunc i32 %1696 to i8
  %1698 = and i8 %1697, 1
  %1699 = xor i8 %1698, 1
  store i8 %1699, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %1700 = icmp eq i32 %1694, 0
  %1701 = zext i1 %1700 to i8
  store i8 %1701, i8* %20, align 1
  %1702 = lshr i32 %1694, 31
  %1703 = trunc i32 %1702 to i8
  store i8 %1703, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v675 = select i1 %1700, i64 21, i64 330
  %1704 = add i64 %1690, %.v675
  store i64 %1704, i64* %3, align 8
  br i1 %1700, label %block_483ec2, label %block_.L_483ff7

block_483ec2:                                     ; preds = %block_483ead
  %1705 = add i64 %1676, -48
  %1706 = add i64 %1704, 7
  store i64 %1706, i64* %3, align 8
  %1707 = inttoptr i64 %1705 to i32*
  store i32 0, i32* %1707, align 4
  %1708 = load i64, i64* %RBP.i, align 8
  %1709 = add i64 %1708, -52
  %1710 = load i64, i64* %3, align 8
  %1711 = add i64 %1710, 7
  store i64 %1711, i64* %3, align 8
  %1712 = inttoptr i64 %1709 to i32*
  store i32 0, i32* %1712, align 4
  %.pre567 = load i64, i64* %3, align 8
  br label %block_.L_483ed0

block_.L_483ed0:                                  ; preds = %block_.L_483f63, %block_483ec2
  %1713 = phi i64 [ %2090, %block_.L_483f63 ], [ %.pre567, %block_483ec2 ]
  %1714 = load i64, i64* %RBP.i, align 8
  %1715 = add i64 %1714, -48
  %1716 = add i64 %1713, 4
  store i64 %1716, i64* %3, align 8
  %1717 = inttoptr i64 %1715 to i32*
  %1718 = load i32, i32* %1717, align 4
  %1719 = add i32 %1718, -4
  %1720 = icmp ult i32 %1718, 4
  %1721 = zext i1 %1720 to i8
  store i8 %1721, i8* %17, align 1
  %1722 = and i32 %1719, 255
  %1723 = tail call i32 @llvm.ctpop.i32(i32 %1722)
  %1724 = trunc i32 %1723 to i8
  %1725 = and i8 %1724, 1
  %1726 = xor i8 %1725, 1
  store i8 %1726, i8* %18, align 1
  %1727 = xor i32 %1719, %1718
  %1728 = lshr i32 %1727, 4
  %1729 = trunc i32 %1728 to i8
  %1730 = and i8 %1729, 1
  store i8 %1730, i8* %19, align 1
  %1731 = icmp eq i32 %1719, 0
  %1732 = zext i1 %1731 to i8
  store i8 %1732, i8* %20, align 1
  %1733 = lshr i32 %1719, 31
  %1734 = trunc i32 %1733 to i8
  store i8 %1734, i8* %21, align 1
  %1735 = lshr i32 %1718, 31
  %1736 = xor i32 %1733, %1735
  %1737 = add nuw nsw i32 %1736, %1735
  %1738 = icmp eq i32 %1737, 2
  %1739 = zext i1 %1738 to i8
  store i8 %1739, i8* %22, align 1
  %1740 = icmp ne i8 %1734, 0
  %1741 = xor i1 %1740, %1738
  %.v759 = select i1 %1741, i64 10, i64 166
  %1742 = add i64 %1713, %.v759
  store i64 %1742, i64* %3, align 8
  br i1 %1741, label %block_483eda, label %block_.L_483f76

block_483eda:                                     ; preds = %block_.L_483ed0
  %1743 = add i64 %1714, -44
  %1744 = add i64 %1742, 7
  store i64 %1744, i64* %3, align 8
  %1745 = inttoptr i64 %1743 to i32*
  store i32 0, i32* %1745, align 4
  %.pre570 = load i64, i64* %3, align 8
  br label %block_.L_483ee1

block_.L_483ee1:                                  ; preds = %block_483eeb, %block_483eda
  %1746 = phi i64 [ %2060, %block_483eeb ], [ %.pre570, %block_483eda ]
  %1747 = load i64, i64* %RBP.i, align 8
  %1748 = add i64 %1747, -44
  %1749 = add i64 %1746, 4
  store i64 %1749, i64* %3, align 8
  %1750 = inttoptr i64 %1748 to i32*
  %1751 = load i32, i32* %1750, align 4
  %1752 = add i32 %1751, -4
  %1753 = icmp ult i32 %1751, 4
  %1754 = zext i1 %1753 to i8
  store i8 %1754, i8* %17, align 1
  %1755 = and i32 %1752, 255
  %1756 = tail call i32 @llvm.ctpop.i32(i32 %1755)
  %1757 = trunc i32 %1756 to i8
  %1758 = and i8 %1757, 1
  %1759 = xor i8 %1758, 1
  store i8 %1759, i8* %18, align 1
  %1760 = xor i32 %1752, %1751
  %1761 = lshr i32 %1760, 4
  %1762 = trunc i32 %1761 to i8
  %1763 = and i8 %1762, 1
  store i8 %1763, i8* %19, align 1
  %1764 = icmp eq i32 %1752, 0
  %1765 = zext i1 %1764 to i8
  store i8 %1765, i8* %20, align 1
  %1766 = lshr i32 %1752, 31
  %1767 = trunc i32 %1766 to i8
  store i8 %1767, i8* %21, align 1
  %1768 = lshr i32 %1751, 31
  %1769 = xor i32 %1766, %1768
  %1770 = add nuw nsw i32 %1769, %1768
  %1771 = icmp eq i32 %1770, 2
  %1772 = zext i1 %1771 to i8
  store i8 %1772, i8* %22, align 1
  %1773 = icmp ne i8 %1767, 0
  %1774 = xor i1 %1773, %1771
  %.v673 = select i1 %1774, i64 10, i64 130
  %1775 = add i64 %1746, %.v673
  store i64 %1775, i64* %3, align 8
  br i1 %1774, label %block_483eeb, label %block_.L_483f63

block_483eeb:                                     ; preds = %block_.L_483ee1
  %1776 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %1776, i64* %RAX.i1659, align 8
  %1777 = add i64 %1747, -240
  %1778 = add i64 %1775, 14
  store i64 %1778, i64* %3, align 8
  %1779 = inttoptr i64 %1777 to i32*
  %1780 = load i32, i32* %1779, align 4
  %1781 = zext i32 %1780 to i64
  store i64 %1781, i64* %RCX.i1588, align 8
  %1782 = add i64 %1747, -48
  %1783 = add i64 %1775, 17
  store i64 %1783, i64* %3, align 8
  %1784 = inttoptr i64 %1782 to i32*
  %1785 = load i32, i32* %1784, align 4
  %1786 = add i32 %1785, %1780
  %1787 = zext i32 %1786 to i64
  store i64 %1787, i64* %RCX.i1588, align 8
  %1788 = icmp ult i32 %1786, %1780
  %1789 = icmp ult i32 %1786, %1785
  %1790 = or i1 %1788, %1789
  %1791 = zext i1 %1790 to i8
  store i8 %1791, i8* %17, align 1
  %1792 = and i32 %1786, 255
  %1793 = tail call i32 @llvm.ctpop.i32(i32 %1792)
  %1794 = trunc i32 %1793 to i8
  %1795 = and i8 %1794, 1
  %1796 = xor i8 %1795, 1
  store i8 %1796, i8* %18, align 1
  %1797 = xor i32 %1785, %1780
  %1798 = xor i32 %1797, %1786
  %1799 = lshr i32 %1798, 4
  %1800 = trunc i32 %1799 to i8
  %1801 = and i8 %1800, 1
  store i8 %1801, i8* %19, align 1
  %1802 = icmp eq i32 %1786, 0
  %1803 = zext i1 %1802 to i8
  store i8 %1803, i8* %20, align 1
  %1804 = lshr i32 %1786, 31
  %1805 = trunc i32 %1804 to i8
  store i8 %1805, i8* %21, align 1
  %1806 = lshr i32 %1780, 31
  %1807 = lshr i32 %1785, 31
  %1808 = xor i32 %1804, %1806
  %1809 = xor i32 %1804, %1807
  %1810 = add nuw nsw i32 %1808, %1809
  %1811 = icmp eq i32 %1810, 2
  %1812 = zext i1 %1811 to i8
  store i8 %1812, i8* %22, align 1
  %1813 = sext i32 %1786 to i64
  store i64 %1813, i64* %RDX.i1943, align 8
  %1814 = shl nsw i64 %1813, 3
  %1815 = add i64 %1776, %1814
  %1816 = add i64 %1775, 24
  store i64 %1816, i64* %3, align 8
  %1817 = inttoptr i64 %1815 to i64*
  %1818 = load i64, i64* %1817, align 8
  store i64 %1818, i64* %RAX.i1659, align 8
  %1819 = add i64 %1747, -236
  %1820 = add i64 %1775, 30
  store i64 %1820, i64* %3, align 8
  %1821 = inttoptr i64 %1819 to i32*
  %1822 = load i32, i32* %1821, align 4
  %1823 = zext i32 %1822 to i64
  store i64 %1823, i64* %RCX.i1588, align 8
  %1824 = add i64 %1775, 33
  store i64 %1824, i64* %3, align 8
  %1825 = load i32, i32* %1750, align 4
  %1826 = add i32 %1825, %1822
  %1827 = zext i32 %1826 to i64
  store i64 %1827, i64* %RCX.i1588, align 8
  %1828 = icmp ult i32 %1826, %1822
  %1829 = icmp ult i32 %1826, %1825
  %1830 = or i1 %1828, %1829
  %1831 = zext i1 %1830 to i8
  store i8 %1831, i8* %17, align 1
  %1832 = and i32 %1826, 255
  %1833 = tail call i32 @llvm.ctpop.i32(i32 %1832)
  %1834 = trunc i32 %1833 to i8
  %1835 = and i8 %1834, 1
  %1836 = xor i8 %1835, 1
  store i8 %1836, i8* %18, align 1
  %1837 = xor i32 %1825, %1822
  %1838 = xor i32 %1837, %1826
  %1839 = lshr i32 %1838, 4
  %1840 = trunc i32 %1839 to i8
  %1841 = and i8 %1840, 1
  store i8 %1841, i8* %19, align 1
  %1842 = icmp eq i32 %1826, 0
  %1843 = zext i1 %1842 to i8
  store i8 %1843, i8* %20, align 1
  %1844 = lshr i32 %1826, 31
  %1845 = trunc i32 %1844 to i8
  store i8 %1845, i8* %21, align 1
  %1846 = lshr i32 %1822, 31
  %1847 = lshr i32 %1825, 31
  %1848 = xor i32 %1844, %1846
  %1849 = xor i32 %1844, %1847
  %1850 = add nuw nsw i32 %1848, %1849
  %1851 = icmp eq i32 %1850, 2
  %1852 = zext i1 %1851 to i8
  store i8 %1852, i8* %22, align 1
  %1853 = sext i32 %1826 to i64
  store i64 %1853, i64* %RDX.i1943, align 8
  %1854 = shl nsw i64 %1853, 1
  %1855 = add i64 %1818, %1854
  %1856 = add i64 %1775, 40
  store i64 %1856, i64* %3, align 8
  %1857 = inttoptr i64 %1855 to i16*
  %1858 = load i16, i16* %1857, align 2
  %1859 = zext i16 %1858 to i64
  store i64 %1859, i64* %RCX.i1588, align 8
  %1860 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %1861 = add i64 %1860, 184
  store i64 %1861, i64* %RAX.i1659, align 8
  %1862 = icmp ugt i64 %1860, -185
  %1863 = zext i1 %1862 to i8
  store i8 %1863, i8* %17, align 1
  %1864 = trunc i64 %1861 to i32
  %1865 = and i32 %1864, 255
  %1866 = tail call i32 @llvm.ctpop.i32(i32 %1865)
  %1867 = trunc i32 %1866 to i8
  %1868 = and i8 %1867, 1
  %1869 = xor i8 %1868, 1
  store i8 %1869, i8* %18, align 1
  %1870 = xor i64 %1860, 16
  %1871 = xor i64 %1870, %1861
  %1872 = lshr i64 %1871, 4
  %1873 = trunc i64 %1872 to i8
  %1874 = and i8 %1873, 1
  store i8 %1874, i8* %19, align 1
  %1875 = icmp eq i64 %1861, 0
  %1876 = zext i1 %1875 to i8
  store i8 %1876, i8* %20, align 1
  %1877 = lshr i64 %1861, 63
  %1878 = trunc i64 %1877 to i8
  store i8 %1878, i8* %21, align 1
  %1879 = lshr i64 %1860, 63
  %1880 = xor i64 %1877, %1879
  %1881 = add nuw nsw i64 %1880, %1877
  %1882 = icmp eq i64 %1881, 2
  %1883 = zext i1 %1882 to i8
  store i8 %1883, i8* %22, align 1
  %1884 = load i64, i64* %RBP.i, align 8
  %1885 = add i64 %1884, -36
  %1886 = add i64 %1775, 58
  store i64 %1886, i64* %3, align 8
  %1887 = inttoptr i64 %1885 to i32*
  %1888 = load i32, i32* %1887, align 4
  %1889 = sext i32 %1888 to i64
  %1890 = shl nsw i64 %1889, 9
  store i64 %1890, i64* %RDX.i1943, align 8
  %1891 = add i64 %1890, %1861
  store i64 %1891, i64* %RAX.i1659, align 8
  %1892 = icmp ult i64 %1891, %1861
  %1893 = icmp ult i64 %1891, %1890
  %1894 = or i1 %1892, %1893
  %1895 = zext i1 %1894 to i8
  store i8 %1895, i8* %17, align 1
  %1896 = trunc i64 %1891 to i32
  %1897 = and i32 %1896, 255
  %1898 = tail call i32 @llvm.ctpop.i32(i32 %1897)
  %1899 = trunc i32 %1898 to i8
  %1900 = and i8 %1899, 1
  %1901 = xor i8 %1900, 1
  store i8 %1901, i8* %18, align 1
  %1902 = xor i64 %1861, %1891
  %1903 = lshr i64 %1902, 4
  %1904 = trunc i64 %1903 to i8
  %1905 = and i8 %1904, 1
  store i8 %1905, i8* %19, align 1
  %1906 = icmp eq i64 %1891, 0
  %1907 = zext i1 %1906 to i8
  store i8 %1907, i8* %20, align 1
  %1908 = lshr i64 %1891, 63
  %1909 = trunc i64 %1908 to i8
  store i8 %1909, i8* %21, align 1
  %1910 = lshr i64 %1889, 54
  %1911 = and i64 %1910, 1
  %1912 = xor i64 %1908, %1877
  %1913 = xor i64 %1908, %1911
  %1914 = add nuw nsw i64 %1912, %1913
  %1915 = icmp eq i64 %1914, 2
  %1916 = zext i1 %1915 to i8
  store i8 %1916, i8* %22, align 1
  %1917 = add i64 %1884, -48
  %1918 = add i64 %1775, 69
  store i64 %1918, i64* %3, align 8
  %1919 = inttoptr i64 %1917 to i32*
  %1920 = load i32, i32* %1919, align 4
  %1921 = sext i32 %1920 to i64
  %1922 = shl nsw i64 %1921, 5
  store i64 %1922, i64* %RDX.i1943, align 8
  %1923 = add i64 %1922, %1891
  store i64 %1923, i64* %RAX.i1659, align 8
  %1924 = icmp ult i64 %1923, %1891
  %1925 = icmp ult i64 %1923, %1922
  %1926 = or i1 %1924, %1925
  %1927 = zext i1 %1926 to i8
  store i8 %1927, i8* %17, align 1
  %1928 = trunc i64 %1923 to i32
  %1929 = and i32 %1928, 255
  %1930 = tail call i32 @llvm.ctpop.i32(i32 %1929)
  %1931 = trunc i32 %1930 to i8
  %1932 = and i8 %1931, 1
  %1933 = xor i8 %1932, 1
  store i8 %1933, i8* %18, align 1
  %1934 = xor i64 %1891, %1923
  %1935 = lshr i64 %1934, 4
  %1936 = trunc i64 %1935 to i8
  %1937 = and i8 %1936, 1
  store i8 %1937, i8* %19, align 1
  %1938 = icmp eq i64 %1923, 0
  %1939 = zext i1 %1938 to i8
  store i8 %1939, i8* %20, align 1
  %1940 = lshr i64 %1923, 63
  %1941 = trunc i64 %1940 to i8
  store i8 %1941, i8* %21, align 1
  %1942 = lshr i64 %1921, 58
  %1943 = and i64 %1942, 1
  %1944 = xor i64 %1940, %1908
  %1945 = xor i64 %1940, %1943
  %1946 = add nuw nsw i64 %1944, %1945
  %1947 = icmp eq i64 %1946, 2
  %1948 = zext i1 %1947 to i8
  store i8 %1948, i8* %22, align 1
  %1949 = load i64, i64* %RBP.i, align 8
  %1950 = add i64 %1949, -44
  %1951 = add i64 %1775, 80
  store i64 %1951, i64* %3, align 8
  %1952 = inttoptr i64 %1950 to i32*
  %1953 = load i32, i32* %1952, align 4
  %1954 = sext i32 %1953 to i64
  store i64 %1954, i64* %RDX.i1943, align 8
  %1955 = shl nsw i64 %1954, 1
  %1956 = add i64 %1955, %1923
  %1957 = add i64 %1775, 84
  store i64 %1957, i64* %3, align 8
  %1958 = inttoptr i64 %1956 to i16*
  %1959 = load i16, i16* %1958, align 2
  %1960 = zext i16 %1959 to i64
  store i64 %1960, i64* %RSI.i2015, align 8
  %1961 = load i64, i64* %RCX.i1588, align 8
  %1962 = zext i16 %1959 to i32
  %1963 = zext i16 %1959 to i64
  %1964 = trunc i64 %1961 to i32
  %1965 = sub i32 %1964, %1962
  %1966 = zext i32 %1965 to i64
  store i64 %1966, i64* %RCX.i1588, align 8
  %1967 = icmp ult i32 %1964, %1962
  %1968 = zext i1 %1967 to i8
  store i8 %1968, i8* %17, align 1
  %1969 = and i32 %1965, 255
  %1970 = tail call i32 @llvm.ctpop.i32(i32 %1969)
  %1971 = trunc i32 %1970 to i8
  %1972 = and i8 %1971, 1
  %1973 = xor i8 %1972, 1
  store i8 %1973, i8* %18, align 1
  %1974 = xor i64 %1963, %1961
  %1975 = trunc i64 %1974 to i32
  %1976 = xor i32 %1975, %1965
  %1977 = lshr i32 %1976, 4
  %1978 = trunc i32 %1977 to i8
  %1979 = and i8 %1978, 1
  store i8 %1979, i8* %19, align 1
  %1980 = icmp eq i32 %1965, 0
  %1981 = zext i1 %1980 to i8
  store i8 %1981, i8* %20, align 1
  %1982 = lshr i32 %1965, 31
  %1983 = trunc i32 %1982 to i8
  store i8 %1983, i8* %21, align 1
  %1984 = lshr i32 %1964, 31
  %1985 = xor i32 %1982, %1984
  %1986 = add nuw nsw i32 %1985, %1984
  %1987 = icmp eq i32 %1986, 2
  %1988 = zext i1 %1987 to i8
  store i8 %1988, i8* %22, align 1
  %1989 = add i64 %1949, -52
  %1990 = add i64 %1775, 90
  store i64 %1990, i64* %3, align 8
  %1991 = inttoptr i64 %1989 to i32*
  %1992 = load i32, i32* %1991, align 4
  %1993 = sext i32 %1992 to i64
  store i64 %1993, i64* %RAX.i1659, align 8
  %1994 = shl nsw i64 %1993, 2
  %1995 = add i64 %1949, -208
  %1996 = add i64 %1995, %1994
  %1997 = add i64 %1775, 97
  store i64 %1997, i64* %3, align 8
  %1998 = inttoptr i64 %1996 to i32*
  store i32 %1965, i32* %1998, align 4
  %1999 = load i64, i64* %RBP.i, align 8
  %2000 = add i64 %1999, -44
  %2001 = load i64, i64* %3, align 8
  %2002 = add i64 %2001, 3
  store i64 %2002, i64* %3, align 8
  %2003 = inttoptr i64 %2000 to i32*
  %2004 = load i32, i32* %2003, align 4
  %2005 = add i32 %2004, 1
  %2006 = zext i32 %2005 to i64
  store i64 %2006, i64* %RAX.i1659, align 8
  %2007 = icmp eq i32 %2004, -1
  %2008 = icmp eq i32 %2005, 0
  %2009 = or i1 %2007, %2008
  %2010 = zext i1 %2009 to i8
  store i8 %2010, i8* %17, align 1
  %2011 = and i32 %2005, 255
  %2012 = tail call i32 @llvm.ctpop.i32(i32 %2011)
  %2013 = trunc i32 %2012 to i8
  %2014 = and i8 %2013, 1
  %2015 = xor i8 %2014, 1
  store i8 %2015, i8* %18, align 1
  %2016 = xor i32 %2005, %2004
  %2017 = lshr i32 %2016, 4
  %2018 = trunc i32 %2017 to i8
  %2019 = and i8 %2018, 1
  store i8 %2019, i8* %19, align 1
  %2020 = zext i1 %2008 to i8
  store i8 %2020, i8* %20, align 1
  %2021 = lshr i32 %2005, 31
  %2022 = trunc i32 %2021 to i8
  store i8 %2022, i8* %21, align 1
  %2023 = lshr i32 %2004, 31
  %2024 = xor i32 %2021, %2023
  %2025 = add nuw nsw i32 %2024, %2021
  %2026 = icmp eq i32 %2025, 2
  %2027 = zext i1 %2026 to i8
  store i8 %2027, i8* %22, align 1
  %2028 = add i64 %2001, 9
  store i64 %2028, i64* %3, align 8
  store i32 %2005, i32* %2003, align 4
  %2029 = load i64, i64* %RBP.i, align 8
  %2030 = add i64 %2029, -52
  %2031 = load i64, i64* %3, align 8
  %2032 = add i64 %2031, 3
  store i64 %2032, i64* %3, align 8
  %2033 = inttoptr i64 %2030 to i32*
  %2034 = load i32, i32* %2033, align 4
  %2035 = add i32 %2034, 1
  %2036 = zext i32 %2035 to i64
  store i64 %2036, i64* %RAX.i1659, align 8
  %2037 = icmp eq i32 %2034, -1
  %2038 = icmp eq i32 %2035, 0
  %2039 = or i1 %2037, %2038
  %2040 = zext i1 %2039 to i8
  store i8 %2040, i8* %17, align 1
  %2041 = and i32 %2035, 255
  %2042 = tail call i32 @llvm.ctpop.i32(i32 %2041)
  %2043 = trunc i32 %2042 to i8
  %2044 = and i8 %2043, 1
  %2045 = xor i8 %2044, 1
  store i8 %2045, i8* %18, align 1
  %2046 = xor i32 %2035, %2034
  %2047 = lshr i32 %2046, 4
  %2048 = trunc i32 %2047 to i8
  %2049 = and i8 %2048, 1
  store i8 %2049, i8* %19, align 1
  %2050 = zext i1 %2038 to i8
  store i8 %2050, i8* %20, align 1
  %2051 = lshr i32 %2035, 31
  %2052 = trunc i32 %2051 to i8
  store i8 %2052, i8* %21, align 1
  %2053 = lshr i32 %2034, 31
  %2054 = xor i32 %2051, %2053
  %2055 = add nuw nsw i32 %2054, %2051
  %2056 = icmp eq i32 %2055, 2
  %2057 = zext i1 %2056 to i8
  store i8 %2057, i8* %22, align 1
  %2058 = add i64 %2031, 9
  store i64 %2058, i64* %3, align 8
  store i32 %2035, i32* %2033, align 4
  %2059 = load i64, i64* %3, align 8
  %2060 = add i64 %2059, -125
  store i64 %2060, i64* %3, align 8
  br label %block_.L_483ee1

block_.L_483f63:                                  ; preds = %block_.L_483ee1
  %2061 = add i64 %1747, -48
  %2062 = add i64 %1775, 8
  store i64 %2062, i64* %3, align 8
  %2063 = inttoptr i64 %2061 to i32*
  %2064 = load i32, i32* %2063, align 4
  %2065 = add i32 %2064, 1
  %2066 = zext i32 %2065 to i64
  store i64 %2066, i64* %RAX.i1659, align 8
  %2067 = icmp eq i32 %2064, -1
  %2068 = icmp eq i32 %2065, 0
  %2069 = or i1 %2067, %2068
  %2070 = zext i1 %2069 to i8
  store i8 %2070, i8* %17, align 1
  %2071 = and i32 %2065, 255
  %2072 = tail call i32 @llvm.ctpop.i32(i32 %2071)
  %2073 = trunc i32 %2072 to i8
  %2074 = and i8 %2073, 1
  %2075 = xor i8 %2074, 1
  store i8 %2075, i8* %18, align 1
  %2076 = xor i32 %2065, %2064
  %2077 = lshr i32 %2076, 4
  %2078 = trunc i32 %2077 to i8
  %2079 = and i8 %2078, 1
  store i8 %2079, i8* %19, align 1
  %2080 = zext i1 %2068 to i8
  store i8 %2080, i8* %20, align 1
  %2081 = lshr i32 %2065, 31
  %2082 = trunc i32 %2081 to i8
  store i8 %2082, i8* %21, align 1
  %2083 = lshr i32 %2064, 31
  %2084 = xor i32 %2081, %2083
  %2085 = add nuw nsw i32 %2084, %2081
  %2086 = icmp eq i32 %2085, 2
  %2087 = zext i1 %2086 to i8
  store i8 %2087, i8* %22, align 1
  %2088 = add i64 %1775, 14
  store i64 %2088, i64* %3, align 8
  store i32 %2065, i32* %2063, align 4
  %2089 = load i64, i64* %3, align 8
  %2090 = add i64 %2089, -161
  store i64 %2090, i64* %3, align 8
  br label %block_.L_483ed0

block_.L_483f76:                                  ; preds = %block_.L_483ed0
  %2091 = add i64 %1714, -36
  %2092 = add i64 %1742, 3
  store i64 %2092, i64* %3, align 8
  %2093 = inttoptr i64 %2091 to i32*
  %2094 = load i32, i32* %2093, align 4
  %2095 = zext i32 %2094 to i64
  store i64 %2095, i64* %RAX.i1659, align 8
  %2096 = add i64 %1714, -288
  %2097 = add i64 %1742, 9
  store i64 %2097, i64* %3, align 8
  %2098 = inttoptr i64 %2096 to i32*
  %2099 = load i32, i32* %2098, align 4
  %2100 = sub i32 %2094, %2099
  %2101 = icmp ult i32 %2094, %2099
  %2102 = zext i1 %2101 to i8
  store i8 %2102, i8* %17, align 1
  %2103 = and i32 %2100, 255
  %2104 = tail call i32 @llvm.ctpop.i32(i32 %2103)
  %2105 = trunc i32 %2104 to i8
  %2106 = and i8 %2105, 1
  %2107 = xor i8 %2106, 1
  store i8 %2107, i8* %18, align 1
  %2108 = xor i32 %2099, %2094
  %2109 = xor i32 %2108, %2100
  %2110 = lshr i32 %2109, 4
  %2111 = trunc i32 %2110 to i8
  %2112 = and i8 %2111, 1
  store i8 %2112, i8* %19, align 1
  %2113 = icmp eq i32 %2100, 0
  %2114 = zext i1 %2113 to i8
  store i8 %2114, i8* %20, align 1
  %2115 = lshr i32 %2100, 31
  %2116 = trunc i32 %2115 to i8
  store i8 %2116, i8* %21, align 1
  %2117 = lshr i32 %2094, 31
  %2118 = lshr i32 %2099, 31
  %2119 = xor i32 %2118, %2117
  %2120 = xor i32 %2115, %2117
  %2121 = add nuw nsw i32 %2120, %2119
  %2122 = icmp eq i32 %2121, 2
  %2123 = zext i1 %2122 to i8
  store i8 %2123, i8* %22, align 1
  %.v760 = select i1 %2113, i64 15, i64 28
  %2124 = add i64 %1742, %.v760
  store i64 %2124, i64* %3, align 8
  br i1 %2113, label %block_483f85, label %block_.L_483f92

block_483f85:                                     ; preds = %block_.L_483f76
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %2125 = add i64 %1714, -556
  %2126 = add i64 %2124, 8
  store i64 %2126, i64* %3, align 8
  %2127 = inttoptr i64 %2125 to i32*
  store i32 0, i32* %2127, align 4
  %2128 = load i64, i64* %3, align 8
  %2129 = add i64 %2128, 33
  store i64 %2129, i64* %3, align 8
  br label %block_.L_483fae

block_.L_483f92:                                  ; preds = %block_.L_483f76
  %2130 = add i64 %2124, ptrtoint (%G_0x2d89e__rip__type* @G_0x2d89e__rip_ to i64)
  %2131 = add i64 %2124, 8
  store i64 %2131, i64* %3, align 8
  %2132 = inttoptr i64 %2130 to i64*
  %2133 = load i64, i64* %2132, align 8
  store i64 %2133, i64* %69, align 1
  store double 0.000000e+00, double* %1190, align 1
  %2134 = add i64 %1714, -24
  %2135 = add i64 %2124, 13
  store i64 %2135, i64* %3, align 8
  %2136 = bitcast i64 %2133 to double
  %2137 = inttoptr i64 %2134 to double*
  %2138 = load double, double* %2137, align 8
  %2139 = fmul double %2136, %2138
  store double %2139, double* %68, align 1
  store i64 0, i64* %1189, align 1
  %2140 = add i64 %2124, -536034
  %2141 = add i64 %2124, 18
  %2142 = load i64, i64* %6, align 8
  %2143 = add i64 %2142, -8
  %2144 = inttoptr i64 %2143 to i64*
  store i64 %2141, i64* %2144, align 8
  store i64 %2143, i64* %6, align 8
  store i64 %2140, i64* %3, align 8
  %2145 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 ptrtoint (i64 (i64)* @floor to i64), %struct.Memory* %MEMORY.8)
  %2146 = load i64, i64* %3, align 8
  %2147 = load double, double* %68, align 1
  %2148 = tail call double @llvm.trunc.f64(double %2147)
  %2149 = tail call double @llvm.fabs.f64(double %2148)
  %2150 = fcmp ogt double %2149, 0x41DFFFFFFFC00000
  %2151 = fptosi double %2148 to i32
  %2152 = zext i32 %2151 to i64
  %2153 = select i1 %2150, i64 2147483648, i64 %2152
  store i64 %2153, i64* %RAX.i1659, align 8
  %2154 = load i64, i64* %RBP.i, align 8
  %2155 = add i64 %2154, -556
  %2156 = trunc i64 %2153 to i32
  %2157 = add i64 %2146, 10
  store i64 %2157, i64* %3, align 8
  %2158 = inttoptr i64 %2155 to i32*
  store i32 %2156, i32* %2158, align 4
  %.pre568 = load i64, i64* %3, align 8
  br label %block_.L_483fae

block_.L_483fae:                                  ; preds = %block_.L_483f92, %block_483f85
  %2159 = phi i64 [ %.pre568, %block_.L_483f92 ], [ %2129, %block_483f85 ]
  %MEMORY.23 = phi %struct.Memory* [ %2145, %block_.L_483f92 ], [ %MEMORY.8, %block_483f85 ]
  %2160 = load i64, i64* %RBP.i, align 8
  %2161 = add i64 %2160, -556
  %2162 = add i64 %2159, 6
  store i64 %2162, i64* %3, align 8
  %2163 = inttoptr i64 %2161 to i32*
  %2164 = load i32, i32* %2163, align 4
  %2165 = zext i32 %2164 to i64
  store i64 %2165, i64* %RAX.i1659, align 8
  %2166 = add i64 %2160, -208
  store i64 %2166, i64* %RDI.i6998, align 8
  %2167 = add i64 %2160, -64
  %2168 = add i64 %2159, 16
  store i64 %2168, i64* %3, align 8
  %2169 = inttoptr i64 %2167 to i32*
  store i32 %2164, i32* %2169, align 4
  %2170 = load i64, i64* %3, align 8
  %2171 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %2171, i64* %RCX.i1588, align 8
  %2172 = add i64 %2171, 24
  %2173 = add i64 %2170, 11
  store i64 %2173, i64* %3, align 8
  %2174 = inttoptr i64 %2172 to i32*
  %2175 = load i32, i32* %2174, align 4
  %2176 = zext i32 %2175 to i64
  store i64 %2176, i64* %RSI.i2015, align 8
  %2177 = add i64 %2170, -151102
  %2178 = add i64 %2170, 16
  %2179 = load i64, i64* %6, align 8
  %2180 = add i64 %2179, -8
  %2181 = inttoptr i64 %2180 to i64*
  store i64 %2178, i64* %2181, align 8
  store i64 %2180, i64* %6, align 8
  store i64 %2177, i64* %3, align 8
  %call2_483fc9 = tail call %struct.Memory* @sub_45f180.SATD(%struct.State* nonnull %0, i64 %2177, %struct.Memory* %MEMORY.23)
  %2182 = load i64, i64* %RAX.i1659, align 8
  %2183 = load i64, i64* %RBP.i, align 8
  %2184 = add i64 %2183, -64
  %2185 = load i64, i64* %3, align 8
  %2186 = add i64 %2185, 3
  store i64 %2186, i64* %3, align 8
  %2187 = trunc i64 %2182 to i32
  %2188 = inttoptr i64 %2184 to i32*
  %2189 = load i32, i32* %2188, align 4
  %2190 = add i32 %2189, %2187
  %2191 = zext i32 %2190 to i64
  store i64 %2191, i64* %RAX.i1659, align 8
  %2192 = icmp ult i32 %2190, %2187
  %2193 = icmp ult i32 %2190, %2189
  %2194 = or i1 %2192, %2193
  %2195 = zext i1 %2194 to i8
  store i8 %2195, i8* %17, align 1
  %2196 = and i32 %2190, 255
  %2197 = tail call i32 @llvm.ctpop.i32(i32 %2196)
  %2198 = trunc i32 %2197 to i8
  %2199 = and i8 %2198, 1
  %2200 = xor i8 %2199, 1
  store i8 %2200, i8* %18, align 1
  %2201 = xor i32 %2189, %2187
  %2202 = xor i32 %2201, %2190
  %2203 = lshr i32 %2202, 4
  %2204 = trunc i32 %2203 to i8
  %2205 = and i8 %2204, 1
  store i8 %2205, i8* %19, align 1
  %2206 = icmp eq i32 %2190, 0
  %2207 = zext i1 %2206 to i8
  store i8 %2207, i8* %20, align 1
  %2208 = lshr i32 %2190, 31
  %2209 = trunc i32 %2208 to i8
  store i8 %2209, i8* %21, align 1
  %2210 = lshr i32 %2187, 31
  %2211 = lshr i32 %2189, 31
  %2212 = xor i32 %2208, %2210
  %2213 = xor i32 %2208, %2211
  %2214 = add nuw nsw i32 %2212, %2213
  %2215 = icmp eq i32 %2214, 2
  %2216 = zext i1 %2215 to i8
  store i8 %2216, i8* %22, align 1
  %2217 = add i64 %2185, 6
  store i64 %2217, i64* %3, align 8
  store i32 %2190, i32* %2188, align 4
  %2218 = load i64, i64* %RBP.i, align 8
  %2219 = add i64 %2218, -64
  %2220 = load i64, i64* %3, align 8
  %2221 = add i64 %2220, 3
  store i64 %2221, i64* %3, align 8
  %2222 = inttoptr i64 %2219 to i32*
  %2223 = load i32, i32* %2222, align 4
  %2224 = zext i32 %2223 to i64
  store i64 %2224, i64* %RAX.i1659, align 8
  %2225 = add i64 %2218, -32
  %2226 = add i64 %2220, 7
  store i64 %2226, i64* %3, align 8
  %2227 = inttoptr i64 %2225 to i64*
  %2228 = load i64, i64* %2227, align 8
  store i64 %2228, i64* %RCX.i1588, align 8
  %2229 = add i64 %2220, 9
  store i64 %2229, i64* %3, align 8
  %2230 = inttoptr i64 %2228 to i32*
  %2231 = load i32, i32* %2230, align 4
  %2232 = sub i32 %2223, %2231
  %2233 = icmp ult i32 %2223, %2231
  %2234 = zext i1 %2233 to i8
  store i8 %2234, i8* %17, align 1
  %2235 = and i32 %2232, 255
  %2236 = tail call i32 @llvm.ctpop.i32(i32 %2235)
  %2237 = trunc i32 %2236 to i8
  %2238 = and i8 %2237, 1
  %2239 = xor i8 %2238, 1
  store i8 %2239, i8* %18, align 1
  %2240 = xor i32 %2231, %2223
  %2241 = xor i32 %2240, %2232
  %2242 = lshr i32 %2241, 4
  %2243 = trunc i32 %2242 to i8
  %2244 = and i8 %2243, 1
  store i8 %2244, i8* %19, align 1
  %2245 = icmp eq i32 %2232, 0
  %2246 = zext i1 %2245 to i8
  store i8 %2246, i8* %20, align 1
  %2247 = lshr i32 %2232, 31
  %2248 = trunc i32 %2247 to i8
  store i8 %2248, i8* %21, align 1
  %2249 = lshr i32 %2223, 31
  %2250 = lshr i32 %2231, 31
  %2251 = xor i32 %2250, %2249
  %2252 = xor i32 %2247, %2249
  %2253 = add nuw nsw i32 %2252, %2251
  %2254 = icmp eq i32 %2253, 2
  %2255 = zext i1 %2254 to i8
  store i8 %2255, i8* %22, align 1
  %2256 = icmp ne i8 %2248, 0
  %2257 = xor i1 %2256, %2254
  %.v761 = select i1 %2257, i64 15, i64 30
  %2258 = add i64 %2220, %.v761
  store i64 %2258, i64* %3, align 8
  br i1 %2257, label %block_483fe3, label %block_.L_483ff2

block_483fe3:                                     ; preds = %block_.L_483fae
  %2259 = add i64 %2218, -36
  %2260 = add i64 %2258, 3
  store i64 %2260, i64* %3, align 8
  %2261 = inttoptr i64 %2259 to i32*
  %2262 = load i32, i32* %2261, align 4
  %2263 = zext i32 %2262 to i64
  store i64 %2263, i64* %RAX.i1659, align 8
  %2264 = add i64 %2218, -40
  %2265 = add i64 %2258, 6
  store i64 %2265, i64* %3, align 8
  %2266 = inttoptr i64 %2264 to i32*
  store i32 %2262, i32* %2266, align 4
  %2267 = load i64, i64* %RBP.i, align 8
  %2268 = add i64 %2267, -64
  %2269 = load i64, i64* %3, align 8
  %2270 = add i64 %2269, 3
  store i64 %2270, i64* %3, align 8
  %2271 = inttoptr i64 %2268 to i32*
  %2272 = load i32, i32* %2271, align 4
  %2273 = zext i32 %2272 to i64
  store i64 %2273, i64* %RAX.i1659, align 8
  %2274 = add i64 %2267, -32
  %2275 = add i64 %2269, 7
  store i64 %2275, i64* %3, align 8
  %2276 = inttoptr i64 %2274 to i64*
  %2277 = load i64, i64* %2276, align 8
  store i64 %2277, i64* %RCX.i1588, align 8
  %2278 = add i64 %2269, 9
  store i64 %2278, i64* %3, align 8
  %2279 = inttoptr i64 %2277 to i32*
  store i32 %2272, i32* %2279, align 4
  %.pre569 = load i64, i64* %3, align 8
  br label %block_.L_483ff2

block_.L_483ff2:                                  ; preds = %block_.L_483fae, %block_483fe3
  %2280 = phi i64 [ %2258, %block_.L_483fae ], [ %.pre569, %block_483fe3 ]
  %2281 = add i64 %2280, 5813
  br label %block_.L_4856a7

block_.L_483ff7:                                  ; preds = %block_483ead
  %2282 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %2282, i64* %RAX.i1659, align 8
  %2283 = add i64 %2282, 72724
  %2284 = add i64 %1704, 15
  store i64 %2284, i64* %3, align 8
  %2285 = inttoptr i64 %2283 to i32*
  %2286 = load i32, i32* %2285, align 4
  store i8 0, i8* %17, align 1
  %2287 = and i32 %2286, 255
  %2288 = tail call i32 @llvm.ctpop.i32(i32 %2287)
  %2289 = trunc i32 %2288 to i8
  %2290 = and i8 %2289, 1
  %2291 = xor i8 %2290, 1
  store i8 %2291, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %2292 = icmp eq i32 %2286, 0
  %2293 = zext i1 %2292 to i8
  store i8 %2293, i8* %20, align 1
  %2294 = lshr i32 %2286, 31
  %2295 = trunc i32 %2294 to i8
  store i8 %2295, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v674 = select i1 %2292, i64 21, i64 746
  %2296 = add i64 %1704, %.v674
  %2297 = add i64 %1676, -48
  %2298 = add i64 %2296, 7
  store i64 %2298, i64* %3, align 8
  %2299 = inttoptr i64 %2297 to i32*
  store i32 0, i32* %2299, align 4
  %.pre571 = load i64, i64* %3, align 8
  br i1 %2292, label %block_.L_484013.preheader, label %block_.L_4842e8.preheader

block_.L_4842e8.preheader:                        ; preds = %block_.L_483ff7
  br label %block_.L_4842e8

block_.L_484013.preheader:                        ; preds = %block_.L_483ff7
  br label %block_.L_484013

block_.L_484013:                                  ; preds = %block_.L_484013.preheader, %block_.L_48410f
  %2300 = phi i64 [ %2887, %block_.L_48410f ], [ %.pre571, %block_.L_484013.preheader ]
  %2301 = load i64, i64* %RBP.i, align 8
  %2302 = add i64 %2301, -48
  %2303 = add i64 %2300, 4
  store i64 %2303, i64* %3, align 8
  %2304 = inttoptr i64 %2302 to i32*
  %2305 = load i32, i32* %2304, align 4
  %2306 = add i32 %2305, -4
  %2307 = icmp ult i32 %2305, 4
  %2308 = zext i1 %2307 to i8
  store i8 %2308, i8* %17, align 1
  %2309 = and i32 %2306, 255
  %2310 = tail call i32 @llvm.ctpop.i32(i32 %2309)
  %2311 = trunc i32 %2310 to i8
  %2312 = and i8 %2311, 1
  %2313 = xor i8 %2312, 1
  store i8 %2313, i8* %18, align 1
  %2314 = xor i32 %2306, %2305
  %2315 = lshr i32 %2314, 4
  %2316 = trunc i32 %2315 to i8
  %2317 = and i8 %2316, 1
  store i8 %2317, i8* %19, align 1
  %2318 = icmp eq i32 %2306, 0
  %2319 = zext i1 %2318 to i8
  store i8 %2319, i8* %20, align 1
  %2320 = lshr i32 %2306, 31
  %2321 = trunc i32 %2320 to i8
  store i8 %2321, i8* %21, align 1
  %2322 = lshr i32 %2305, 31
  %2323 = xor i32 %2320, %2322
  %2324 = add nuw nsw i32 %2323, %2322
  %2325 = icmp eq i32 %2324, 2
  %2326 = zext i1 %2325 to i8
  store i8 %2326, i8* %22, align 1
  %2327 = icmp ne i8 %2321, 0
  %2328 = xor i1 %2327, %2325
  %.v755 = select i1 %2328, i64 10, i64 271
  %2329 = add i64 %2300, %.v755
  store i64 %2329, i64* %3, align 8
  br i1 %2328, label %block_48401d, label %block_.L_484122

block_48401d:                                     ; preds = %block_.L_484013
  %2330 = add i64 %2301, -44
  %2331 = add i64 %2329, 7
  store i64 %2331, i64* %3, align 8
  %2332 = inttoptr i64 %2330 to i32*
  store i32 0, i32* %2332, align 4
  %.pre581 = load i64, i64* %3, align 8
  br label %block_.L_484024

block_.L_484024:                                  ; preds = %block_48402e, %block_48401d
  %2333 = phi i64 [ %2857, %block_48402e ], [ %.pre581, %block_48401d ]
  %2334 = load i64, i64* %RBP.i, align 8
  %2335 = add i64 %2334, -44
  %2336 = add i64 %2333, 4
  store i64 %2336, i64* %3, align 8
  %2337 = inttoptr i64 %2335 to i32*
  %2338 = load i32, i32* %2337, align 4
  %2339 = add i32 %2338, -4
  %2340 = icmp ult i32 %2338, 4
  %2341 = zext i1 %2340 to i8
  store i8 %2341, i8* %17, align 1
  %2342 = and i32 %2339, 255
  %2343 = tail call i32 @llvm.ctpop.i32(i32 %2342)
  %2344 = trunc i32 %2343 to i8
  %2345 = and i8 %2344, 1
  %2346 = xor i8 %2345, 1
  store i8 %2346, i8* %18, align 1
  %2347 = xor i32 %2339, %2338
  %2348 = lshr i32 %2347, 4
  %2349 = trunc i32 %2348 to i8
  %2350 = and i8 %2349, 1
  store i8 %2350, i8* %19, align 1
  %2351 = icmp eq i32 %2339, 0
  %2352 = zext i1 %2351 to i8
  store i8 %2352, i8* %20, align 1
  %2353 = lshr i32 %2339, 31
  %2354 = trunc i32 %2353 to i8
  store i8 %2354, i8* %21, align 1
  %2355 = lshr i32 %2338, 31
  %2356 = xor i32 %2353, %2355
  %2357 = add nuw nsw i32 %2356, %2355
  %2358 = icmp eq i32 %2357, 2
  %2359 = zext i1 %2358 to i8
  store i8 %2359, i8* %22, align 1
  %2360 = icmp ne i8 %2354, 0
  %2361 = xor i1 %2360, %2358
  %.v679 = select i1 %2361, i64 10, i64 235
  %2362 = add i64 %2333, %.v679
  store i64 %2362, i64* %3, align 8
  br i1 %2361, label %block_48402e, label %block_.L_48410f

block_48402e:                                     ; preds = %block_.L_484024
  %2363 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %2364 = add i64 %2363, 184
  store i64 %2364, i64* %RAX.i1659, align 8
  %2365 = icmp ugt i64 %2363, -185
  %2366 = zext i1 %2365 to i8
  store i8 %2366, i8* %17, align 1
  %2367 = trunc i64 %2364 to i32
  %2368 = and i32 %2367, 255
  %2369 = tail call i32 @llvm.ctpop.i32(i32 %2368)
  %2370 = trunc i32 %2369 to i8
  %2371 = and i8 %2370, 1
  %2372 = xor i8 %2371, 1
  store i8 %2372, i8* %18, align 1
  %2373 = xor i64 %2363, 16
  %2374 = xor i64 %2373, %2364
  %2375 = lshr i64 %2374, 4
  %2376 = trunc i64 %2375 to i8
  %2377 = and i8 %2376, 1
  store i8 %2377, i8* %19, align 1
  %2378 = icmp eq i64 %2364, 0
  %2379 = zext i1 %2378 to i8
  store i8 %2379, i8* %20, align 1
  %2380 = lshr i64 %2364, 63
  %2381 = trunc i64 %2380 to i8
  store i8 %2381, i8* %21, align 1
  %2382 = lshr i64 %2363, 63
  %2383 = xor i64 %2380, %2382
  %2384 = add nuw nsw i64 %2383, %2380
  %2385 = icmp eq i64 %2384, 2
  %2386 = zext i1 %2385 to i8
  store i8 %2386, i8* %22, align 1
  %2387 = add i64 %2334, -36
  %2388 = add i64 %2362, 18
  store i64 %2388, i64* %3, align 8
  %2389 = inttoptr i64 %2387 to i32*
  %2390 = load i32, i32* %2389, align 4
  %2391 = sext i32 %2390 to i64
  %2392 = shl nsw i64 %2391, 9
  store i64 %2392, i64* %RCX.i1588, align 8
  %2393 = add i64 %2392, %2364
  store i64 %2393, i64* %RAX.i1659, align 8
  %2394 = icmp ult i64 %2393, %2364
  %2395 = icmp ult i64 %2393, %2392
  %2396 = or i1 %2394, %2395
  %2397 = zext i1 %2396 to i8
  store i8 %2397, i8* %17, align 1
  %2398 = trunc i64 %2393 to i32
  %2399 = and i32 %2398, 255
  %2400 = tail call i32 @llvm.ctpop.i32(i32 %2399)
  %2401 = trunc i32 %2400 to i8
  %2402 = and i8 %2401, 1
  %2403 = xor i8 %2402, 1
  store i8 %2403, i8* %18, align 1
  %2404 = xor i64 %2364, %2393
  %2405 = lshr i64 %2404, 4
  %2406 = trunc i64 %2405 to i8
  %2407 = and i8 %2406, 1
  store i8 %2407, i8* %19, align 1
  %2408 = icmp eq i64 %2393, 0
  %2409 = zext i1 %2408 to i8
  store i8 %2409, i8* %20, align 1
  %2410 = lshr i64 %2393, 63
  %2411 = trunc i64 %2410 to i8
  store i8 %2411, i8* %21, align 1
  %2412 = lshr i64 %2391, 54
  %2413 = and i64 %2412, 1
  %2414 = xor i64 %2410, %2380
  %2415 = xor i64 %2410, %2413
  %2416 = add nuw nsw i64 %2414, %2415
  %2417 = icmp eq i64 %2416, 2
  %2418 = zext i1 %2417 to i8
  store i8 %2418, i8* %22, align 1
  %2419 = add i64 %2334, -48
  %2420 = add i64 %2362, 29
  store i64 %2420, i64* %3, align 8
  %2421 = inttoptr i64 %2419 to i32*
  %2422 = load i32, i32* %2421, align 4
  %2423 = sext i32 %2422 to i64
  %2424 = shl nsw i64 %2423, 5
  store i64 %2424, i64* %RCX.i1588, align 8
  %2425 = add i64 %2424, %2393
  store i64 %2425, i64* %RAX.i1659, align 8
  %2426 = icmp ult i64 %2425, %2393
  %2427 = icmp ult i64 %2425, %2424
  %2428 = or i1 %2426, %2427
  %2429 = zext i1 %2428 to i8
  store i8 %2429, i8* %17, align 1
  %2430 = trunc i64 %2425 to i32
  %2431 = and i32 %2430, 255
  %2432 = tail call i32 @llvm.ctpop.i32(i32 %2431)
  %2433 = trunc i32 %2432 to i8
  %2434 = and i8 %2433, 1
  %2435 = xor i8 %2434, 1
  store i8 %2435, i8* %18, align 1
  %2436 = xor i64 %2393, %2425
  %2437 = lshr i64 %2436, 4
  %2438 = trunc i64 %2437 to i8
  %2439 = and i8 %2438, 1
  store i8 %2439, i8* %19, align 1
  %2440 = icmp eq i64 %2425, 0
  %2441 = zext i1 %2440 to i8
  store i8 %2441, i8* %20, align 1
  %2442 = lshr i64 %2425, 63
  %2443 = trunc i64 %2442 to i8
  store i8 %2443, i8* %21, align 1
  %2444 = lshr i64 %2423, 58
  %2445 = and i64 %2444, 1
  %2446 = xor i64 %2442, %2410
  %2447 = xor i64 %2442, %2445
  %2448 = add nuw nsw i64 %2446, %2447
  %2449 = icmp eq i64 %2448, 2
  %2450 = zext i1 %2449 to i8
  store i8 %2450, i8* %22, align 1
  %2451 = load i64, i64* %RBP.i, align 8
  %2452 = add i64 %2451, -44
  %2453 = add i64 %2362, 40
  store i64 %2453, i64* %3, align 8
  %2454 = inttoptr i64 %2452 to i32*
  %2455 = load i32, i32* %2454, align 4
  %2456 = sext i32 %2455 to i64
  store i64 %2456, i64* %RCX.i1588, align 8
  %2457 = shl nsw i64 %2456, 1
  %2458 = add i64 %2457, %2425
  %2459 = add i64 %2362, 44
  store i64 %2459, i64* %3, align 8
  %2460 = inttoptr i64 %2458 to i16*
  %2461 = load i16, i16* %2460, align 2
  store i16 %2461, i16* %DX.i4863, align 2
  %2462 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %2463 = add i64 %2462, 12600
  store i64 %2463, i64* %RAX.i1659, align 8
  %2464 = icmp ugt i64 %2462, -12601
  %2465 = zext i1 %2464 to i8
  store i8 %2465, i8* %17, align 1
  %2466 = trunc i64 %2463 to i32
  %2467 = and i32 %2466, 255
  %2468 = tail call i32 @llvm.ctpop.i32(i32 %2467)
  %2469 = trunc i32 %2468 to i8
  %2470 = and i8 %2469, 1
  %2471 = xor i8 %2470, 1
  store i8 %2471, i8* %18, align 1
  %2472 = xor i64 %2462, 16
  %2473 = xor i64 %2472, %2463
  %2474 = lshr i64 %2473, 4
  %2475 = trunc i64 %2474 to i8
  %2476 = and i8 %2475, 1
  store i8 %2476, i8* %19, align 1
  %2477 = icmp eq i64 %2463, 0
  %2478 = zext i1 %2477 to i8
  store i8 %2478, i8* %20, align 1
  %2479 = lshr i64 %2463, 63
  %2480 = trunc i64 %2479 to i8
  store i8 %2480, i8* %21, align 1
  %2481 = lshr i64 %2462, 63
  %2482 = xor i64 %2479, %2481
  %2483 = add nuw nsw i64 %2482, %2479
  %2484 = icmp eq i64 %2483, 2
  %2485 = zext i1 %2484 to i8
  store i8 %2485, i8* %22, align 1
  %2486 = add i64 %2451, -220
  %2487 = add i64 %2362, 64
  store i64 %2487, i64* %3, align 8
  %2488 = inttoptr i64 %2486 to i32*
  %2489 = load i32, i32* %2488, align 4
  %2490 = zext i32 %2489 to i64
  store i64 %2490, i64* %RSI.i2015, align 8
  %2491 = add i64 %2362, 67
  store i64 %2491, i64* %3, align 8
  %2492 = load i32, i32* %2454, align 4
  %2493 = add i32 %2492, %2489
  %2494 = zext i32 %2493 to i64
  store i64 %2494, i64* %RSI.i2015, align 8
  %2495 = sext i32 %2493 to i64
  %2496 = shl nsw i64 %2495, 5
  store i64 %2496, i64* %RCX.i1588, align 8
  %2497 = load i64, i64* %RAX.i1659, align 8
  %2498 = add i64 %2496, %2497
  store i64 %2498, i64* %RAX.i1659, align 8
  %2499 = icmp ult i64 %2498, %2497
  %2500 = icmp ult i64 %2498, %2496
  %2501 = or i1 %2499, %2500
  %2502 = zext i1 %2501 to i8
  store i8 %2502, i8* %17, align 1
  %2503 = trunc i64 %2498 to i32
  %2504 = and i32 %2503, 255
  %2505 = tail call i32 @llvm.ctpop.i32(i32 %2504)
  %2506 = trunc i32 %2505 to i8
  %2507 = and i8 %2506, 1
  %2508 = xor i8 %2507, 1
  store i8 %2508, i8* %18, align 1
  %2509 = xor i64 %2497, %2498
  %2510 = lshr i64 %2509, 4
  %2511 = trunc i64 %2510 to i8
  %2512 = and i8 %2511, 1
  store i8 %2512, i8* %19, align 1
  %2513 = icmp eq i64 %2498, 0
  %2514 = zext i1 %2513 to i8
  store i8 %2514, i8* %20, align 1
  %2515 = lshr i64 %2498, 63
  %2516 = trunc i64 %2515 to i8
  store i8 %2516, i8* %21, align 1
  %2517 = lshr i64 %2497, 63
  %2518 = lshr i64 %2495, 58
  %2519 = and i64 %2518, 1
  %2520 = xor i64 %2515, %2517
  %2521 = xor i64 %2515, %2519
  %2522 = add nuw nsw i64 %2520, %2521
  %2523 = icmp eq i64 %2522, 2
  %2524 = zext i1 %2523 to i8
  store i8 %2524, i8* %22, align 1
  %2525 = load i64, i64* %RBP.i, align 8
  %2526 = add i64 %2525, -224
  %2527 = add i64 %2362, 83
  store i64 %2527, i64* %3, align 8
  %2528 = inttoptr i64 %2526 to i32*
  %2529 = load i32, i32* %2528, align 4
  %2530 = zext i32 %2529 to i64
  store i64 %2530, i64* %RSI.i2015, align 8
  %2531 = add i64 %2525, -48
  %2532 = add i64 %2362, 86
  store i64 %2532, i64* %3, align 8
  %2533 = inttoptr i64 %2531 to i32*
  %2534 = load i32, i32* %2533, align 4
  %2535 = add i32 %2534, %2529
  %2536 = zext i32 %2535 to i64
  store i64 %2536, i64* %RSI.i2015, align 8
  %2537 = icmp ult i32 %2535, %2529
  %2538 = icmp ult i32 %2535, %2534
  %2539 = or i1 %2537, %2538
  %2540 = zext i1 %2539 to i8
  store i8 %2540, i8* %17, align 1
  %2541 = and i32 %2535, 255
  %2542 = tail call i32 @llvm.ctpop.i32(i32 %2541)
  %2543 = trunc i32 %2542 to i8
  %2544 = and i8 %2543, 1
  %2545 = xor i8 %2544, 1
  store i8 %2545, i8* %18, align 1
  %2546 = xor i32 %2534, %2529
  %2547 = xor i32 %2546, %2535
  %2548 = lshr i32 %2547, 4
  %2549 = trunc i32 %2548 to i8
  %2550 = and i8 %2549, 1
  store i8 %2550, i8* %19, align 1
  %2551 = icmp eq i32 %2535, 0
  %2552 = zext i1 %2551 to i8
  store i8 %2552, i8* %20, align 1
  %2553 = lshr i32 %2535, 31
  %2554 = trunc i32 %2553 to i8
  store i8 %2554, i8* %21, align 1
  %2555 = lshr i32 %2529, 31
  %2556 = lshr i32 %2534, 31
  %2557 = xor i32 %2553, %2555
  %2558 = xor i32 %2553, %2556
  %2559 = add nuw nsw i32 %2557, %2558
  %2560 = icmp eq i32 %2559, 2
  %2561 = zext i1 %2560 to i8
  store i8 %2561, i8* %22, align 1
  %2562 = sext i32 %2535 to i64
  store i64 %2562, i64* %RCX.i1588, align 8
  %2563 = shl nsw i64 %2562, 1
  %2564 = add i64 %2498, %2563
  %2565 = load i16, i16* %DX.i4863, align 2
  %2566 = add i64 %2362, 93
  store i64 %2566, i64* %3, align 8
  %2567 = inttoptr i64 %2564 to i16*
  store i16 %2565, i16* %2567, align 2
  %2568 = load i64, i64* %3, align 8
  %2569 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %2569, i64* %RAX.i1659, align 8
  %2570 = load i64, i64* %RBP.i, align 8
  %2571 = add i64 %2570, -240
  %2572 = add i64 %2568, 14
  store i64 %2572, i64* %3, align 8
  %2573 = inttoptr i64 %2571 to i32*
  %2574 = load i32, i32* %2573, align 4
  %2575 = zext i32 %2574 to i64
  store i64 %2575, i64* %RSI.i2015, align 8
  %2576 = add i64 %2570, -48
  %2577 = add i64 %2568, 17
  store i64 %2577, i64* %3, align 8
  %2578 = inttoptr i64 %2576 to i32*
  %2579 = load i32, i32* %2578, align 4
  %2580 = add i32 %2579, %2574
  %2581 = zext i32 %2580 to i64
  store i64 %2581, i64* %RSI.i2015, align 8
  %2582 = icmp ult i32 %2580, %2574
  %2583 = icmp ult i32 %2580, %2579
  %2584 = or i1 %2582, %2583
  %2585 = zext i1 %2584 to i8
  store i8 %2585, i8* %17, align 1
  %2586 = and i32 %2580, 255
  %2587 = tail call i32 @llvm.ctpop.i32(i32 %2586)
  %2588 = trunc i32 %2587 to i8
  %2589 = and i8 %2588, 1
  %2590 = xor i8 %2589, 1
  store i8 %2590, i8* %18, align 1
  %2591 = xor i32 %2579, %2574
  %2592 = xor i32 %2591, %2580
  %2593 = lshr i32 %2592, 4
  %2594 = trunc i32 %2593 to i8
  %2595 = and i8 %2594, 1
  store i8 %2595, i8* %19, align 1
  %2596 = icmp eq i32 %2580, 0
  %2597 = zext i1 %2596 to i8
  store i8 %2597, i8* %20, align 1
  %2598 = lshr i32 %2580, 31
  %2599 = trunc i32 %2598 to i8
  store i8 %2599, i8* %21, align 1
  %2600 = lshr i32 %2574, 31
  %2601 = lshr i32 %2579, 31
  %2602 = xor i32 %2598, %2600
  %2603 = xor i32 %2598, %2601
  %2604 = add nuw nsw i32 %2602, %2603
  %2605 = icmp eq i32 %2604, 2
  %2606 = zext i1 %2605 to i8
  store i8 %2606, i8* %22, align 1
  %2607 = sext i32 %2580 to i64
  store i64 %2607, i64* %RCX.i1588, align 8
  %2608 = shl nsw i64 %2607, 3
  %2609 = add i64 %2569, %2608
  %2610 = add i64 %2568, 24
  store i64 %2610, i64* %3, align 8
  %2611 = inttoptr i64 %2609 to i64*
  %2612 = load i64, i64* %2611, align 8
  store i64 %2612, i64* %RAX.i1659, align 8
  %2613 = add i64 %2570, -236
  %2614 = add i64 %2568, 30
  store i64 %2614, i64* %3, align 8
  %2615 = inttoptr i64 %2613 to i32*
  %2616 = load i32, i32* %2615, align 4
  %2617 = zext i32 %2616 to i64
  store i64 %2617, i64* %RSI.i2015, align 8
  %2618 = add i64 %2570, -44
  %2619 = add i64 %2568, 33
  store i64 %2619, i64* %3, align 8
  %2620 = inttoptr i64 %2618 to i32*
  %2621 = load i32, i32* %2620, align 4
  %2622 = add i32 %2621, %2616
  %2623 = zext i32 %2622 to i64
  store i64 %2623, i64* %RSI.i2015, align 8
  %2624 = icmp ult i32 %2622, %2616
  %2625 = icmp ult i32 %2622, %2621
  %2626 = or i1 %2624, %2625
  %2627 = zext i1 %2626 to i8
  store i8 %2627, i8* %17, align 1
  %2628 = and i32 %2622, 255
  %2629 = tail call i32 @llvm.ctpop.i32(i32 %2628)
  %2630 = trunc i32 %2629 to i8
  %2631 = and i8 %2630, 1
  %2632 = xor i8 %2631, 1
  store i8 %2632, i8* %18, align 1
  %2633 = xor i32 %2621, %2616
  %2634 = xor i32 %2633, %2622
  %2635 = lshr i32 %2634, 4
  %2636 = trunc i32 %2635 to i8
  %2637 = and i8 %2636, 1
  store i8 %2637, i8* %19, align 1
  %2638 = icmp eq i32 %2622, 0
  %2639 = zext i1 %2638 to i8
  store i8 %2639, i8* %20, align 1
  %2640 = lshr i32 %2622, 31
  %2641 = trunc i32 %2640 to i8
  store i8 %2641, i8* %21, align 1
  %2642 = lshr i32 %2616, 31
  %2643 = lshr i32 %2621, 31
  %2644 = xor i32 %2640, %2642
  %2645 = xor i32 %2640, %2643
  %2646 = add nuw nsw i32 %2644, %2645
  %2647 = icmp eq i32 %2646, 2
  %2648 = zext i1 %2647 to i8
  store i8 %2648, i8* %22, align 1
  %2649 = sext i32 %2622 to i64
  store i64 %2649, i64* %RCX.i1588, align 8
  %2650 = shl nsw i64 %2649, 1
  %2651 = add i64 %2612, %2650
  %2652 = add i64 %2568, 40
  store i64 %2652, i64* %3, align 8
  %2653 = inttoptr i64 %2651 to i16*
  %2654 = load i16, i16* %2653, align 2
  %2655 = zext i16 %2654 to i64
  store i64 %2655, i64* %RSI.i2015, align 8
  %2656 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %2657 = add i64 %2656, 184
  store i64 %2657, i64* %RAX.i1659, align 8
  %2658 = icmp ugt i64 %2656, -185
  %2659 = zext i1 %2658 to i8
  store i8 %2659, i8* %17, align 1
  %2660 = trunc i64 %2657 to i32
  %2661 = and i32 %2660, 255
  %2662 = tail call i32 @llvm.ctpop.i32(i32 %2661)
  %2663 = trunc i32 %2662 to i8
  %2664 = and i8 %2663, 1
  %2665 = xor i8 %2664, 1
  store i8 %2665, i8* %18, align 1
  %2666 = xor i64 %2656, 16
  %2667 = xor i64 %2666, %2657
  %2668 = lshr i64 %2667, 4
  %2669 = trunc i64 %2668 to i8
  %2670 = and i8 %2669, 1
  store i8 %2670, i8* %19, align 1
  %2671 = icmp eq i64 %2657, 0
  %2672 = zext i1 %2671 to i8
  store i8 %2672, i8* %20, align 1
  %2673 = lshr i64 %2657, 63
  %2674 = trunc i64 %2673 to i8
  store i8 %2674, i8* %21, align 1
  %2675 = lshr i64 %2656, 63
  %2676 = xor i64 %2673, %2675
  %2677 = add nuw nsw i64 %2676, %2673
  %2678 = icmp eq i64 %2677, 2
  %2679 = zext i1 %2678 to i8
  store i8 %2679, i8* %22, align 1
  %2680 = load i64, i64* %RBP.i, align 8
  %2681 = add i64 %2680, -36
  %2682 = add i64 %2568, 58
  store i64 %2682, i64* %3, align 8
  %2683 = inttoptr i64 %2681 to i32*
  %2684 = load i32, i32* %2683, align 4
  %2685 = sext i32 %2684 to i64
  %2686 = shl nsw i64 %2685, 9
  store i64 %2686, i64* %RCX.i1588, align 8
  %2687 = add i64 %2686, %2657
  store i64 %2687, i64* %RAX.i1659, align 8
  %2688 = icmp ult i64 %2687, %2657
  %2689 = icmp ult i64 %2687, %2686
  %2690 = or i1 %2688, %2689
  %2691 = zext i1 %2690 to i8
  store i8 %2691, i8* %17, align 1
  %2692 = trunc i64 %2687 to i32
  %2693 = and i32 %2692, 255
  %2694 = tail call i32 @llvm.ctpop.i32(i32 %2693)
  %2695 = trunc i32 %2694 to i8
  %2696 = and i8 %2695, 1
  %2697 = xor i8 %2696, 1
  store i8 %2697, i8* %18, align 1
  %2698 = xor i64 %2657, %2687
  %2699 = lshr i64 %2698, 4
  %2700 = trunc i64 %2699 to i8
  %2701 = and i8 %2700, 1
  store i8 %2701, i8* %19, align 1
  %2702 = icmp eq i64 %2687, 0
  %2703 = zext i1 %2702 to i8
  store i8 %2703, i8* %20, align 1
  %2704 = lshr i64 %2687, 63
  %2705 = trunc i64 %2704 to i8
  store i8 %2705, i8* %21, align 1
  %2706 = lshr i64 %2685, 54
  %2707 = and i64 %2706, 1
  %2708 = xor i64 %2704, %2673
  %2709 = xor i64 %2704, %2707
  %2710 = add nuw nsw i64 %2708, %2709
  %2711 = icmp eq i64 %2710, 2
  %2712 = zext i1 %2711 to i8
  store i8 %2712, i8* %22, align 1
  %2713 = add i64 %2680, -48
  %2714 = add i64 %2568, 69
  store i64 %2714, i64* %3, align 8
  %2715 = inttoptr i64 %2713 to i32*
  %2716 = load i32, i32* %2715, align 4
  %2717 = sext i32 %2716 to i64
  %2718 = shl nsw i64 %2717, 5
  store i64 %2718, i64* %RCX.i1588, align 8
  %2719 = add i64 %2718, %2687
  store i64 %2719, i64* %RAX.i1659, align 8
  %2720 = icmp ult i64 %2719, %2687
  %2721 = icmp ult i64 %2719, %2718
  %2722 = or i1 %2720, %2721
  %2723 = zext i1 %2722 to i8
  store i8 %2723, i8* %17, align 1
  %2724 = trunc i64 %2719 to i32
  %2725 = and i32 %2724, 255
  %2726 = tail call i32 @llvm.ctpop.i32(i32 %2725)
  %2727 = trunc i32 %2726 to i8
  %2728 = and i8 %2727, 1
  %2729 = xor i8 %2728, 1
  store i8 %2729, i8* %18, align 1
  %2730 = xor i64 %2687, %2719
  %2731 = lshr i64 %2730, 4
  %2732 = trunc i64 %2731 to i8
  %2733 = and i8 %2732, 1
  store i8 %2733, i8* %19, align 1
  %2734 = icmp eq i64 %2719, 0
  %2735 = zext i1 %2734 to i8
  store i8 %2735, i8* %20, align 1
  %2736 = lshr i64 %2719, 63
  %2737 = trunc i64 %2736 to i8
  store i8 %2737, i8* %21, align 1
  %2738 = lshr i64 %2717, 58
  %2739 = and i64 %2738, 1
  %2740 = xor i64 %2736, %2704
  %2741 = xor i64 %2736, %2739
  %2742 = add nuw nsw i64 %2740, %2741
  %2743 = icmp eq i64 %2742, 2
  %2744 = zext i1 %2743 to i8
  store i8 %2744, i8* %22, align 1
  %2745 = load i64, i64* %RBP.i, align 8
  %2746 = add i64 %2745, -44
  %2747 = add i64 %2568, 80
  store i64 %2747, i64* %3, align 8
  %2748 = inttoptr i64 %2746 to i32*
  %2749 = load i32, i32* %2748, align 4
  %2750 = sext i32 %2749 to i64
  store i64 %2750, i64* %RCX.i1588, align 8
  %2751 = shl nsw i64 %2750, 1
  %2752 = add i64 %2751, %2719
  %2753 = add i64 %2568, 84
  store i64 %2753, i64* %3, align 8
  %2754 = inttoptr i64 %2752 to i16*
  %2755 = load i16, i16* %2754, align 2
  %2756 = zext i16 %2755 to i64
  store i64 %2756, i64* %RDI.i6998, align 8
  %2757 = load i64, i64* %RSI.i2015, align 8
  %2758 = zext i16 %2755 to i64
  %2759 = sub i64 %2757, %2758
  %2760 = and i64 %2759, 4294967295
  store i64 %2760, i64* %RSI.i2015, align 8
  %2761 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %2762 = add i64 %2761, 13112
  store i64 %2762, i64* %RAX.i1659, align 8
  %2763 = icmp ugt i64 %2761, -13113
  %2764 = zext i1 %2763 to i8
  store i8 %2764, i8* %17, align 1
  %2765 = trunc i64 %2762 to i32
  %2766 = and i32 %2765, 255
  %2767 = tail call i32 @llvm.ctpop.i32(i32 %2766)
  %2768 = trunc i32 %2767 to i8
  %2769 = and i8 %2768, 1
  %2770 = xor i8 %2769, 1
  store i8 %2770, i8* %18, align 1
  %2771 = xor i64 %2761, 16
  %2772 = xor i64 %2771, %2762
  %2773 = lshr i64 %2772, 4
  %2774 = trunc i64 %2773 to i8
  %2775 = and i8 %2774, 1
  store i8 %2775, i8* %19, align 1
  %2776 = icmp eq i64 %2762, 0
  %2777 = zext i1 %2776 to i8
  store i8 %2777, i8* %20, align 1
  %2778 = lshr i64 %2762, 63
  %2779 = trunc i64 %2778 to i8
  store i8 %2779, i8* %21, align 1
  %2780 = lshr i64 %2761, 63
  %2781 = xor i64 %2778, %2780
  %2782 = add nuw nsw i64 %2781, %2778
  %2783 = icmp eq i64 %2782, 2
  %2784 = zext i1 %2783 to i8
  store i8 %2784, i8* %22, align 1
  %2785 = add i64 %2568, 104
  store i64 %2785, i64* %3, align 8
  %2786 = load i32, i32* %2748, align 4
  %2787 = sext i32 %2786 to i64
  %2788 = shl nsw i64 %2787, 6
  store i64 %2788, i64* %RCX.i1588, align 8
  %2789 = add i64 %2788, %2762
  store i64 %2789, i64* %RAX.i1659, align 8
  %2790 = icmp ult i64 %2789, %2762
  %2791 = icmp ult i64 %2789, %2788
  %2792 = or i1 %2790, %2791
  %2793 = zext i1 %2792 to i8
  store i8 %2793, i8* %17, align 1
  %2794 = trunc i64 %2789 to i32
  %2795 = and i32 %2794, 255
  %2796 = tail call i32 @llvm.ctpop.i32(i32 %2795)
  %2797 = trunc i32 %2796 to i8
  %2798 = and i8 %2797, 1
  %2799 = xor i8 %2798, 1
  store i8 %2799, i8* %18, align 1
  %2800 = xor i64 %2762, %2789
  %2801 = lshr i64 %2800, 4
  %2802 = trunc i64 %2801 to i8
  %2803 = and i8 %2802, 1
  store i8 %2803, i8* %19, align 1
  %2804 = icmp eq i64 %2789, 0
  %2805 = zext i1 %2804 to i8
  store i8 %2805, i8* %20, align 1
  %2806 = lshr i64 %2789, 63
  %2807 = trunc i64 %2806 to i8
  store i8 %2807, i8* %21, align 1
  %2808 = lshr i64 %2787, 57
  %2809 = and i64 %2808, 1
  %2810 = xor i64 %2806, %2778
  %2811 = xor i64 %2806, %2809
  %2812 = add nuw nsw i64 %2810, %2811
  %2813 = icmp eq i64 %2812, 2
  %2814 = zext i1 %2813 to i8
  store i8 %2814, i8* %22, align 1
  %2815 = load i64, i64* %RBP.i, align 8
  %2816 = add i64 %2815, -48
  %2817 = add i64 %2568, 115
  store i64 %2817, i64* %3, align 8
  %2818 = inttoptr i64 %2816 to i32*
  %2819 = load i32, i32* %2818, align 4
  %2820 = sext i32 %2819 to i64
  store i64 %2820, i64* %RCX.i1588, align 8
  %2821 = shl nsw i64 %2820, 2
  %2822 = add i64 %2821, %2789
  %2823 = load i32, i32* %ESI.i1759, align 4
  %2824 = add i64 %2568, 118
  store i64 %2824, i64* %3, align 8
  %2825 = inttoptr i64 %2822 to i32*
  store i32 %2823, i32* %2825, align 4
  %2826 = load i64, i64* %RBP.i, align 8
  %2827 = add i64 %2826, -44
  %2828 = load i64, i64* %3, align 8
  %2829 = add i64 %2828, 3
  store i64 %2829, i64* %3, align 8
  %2830 = inttoptr i64 %2827 to i32*
  %2831 = load i32, i32* %2830, align 4
  %2832 = add i32 %2831, 1
  %2833 = zext i32 %2832 to i64
  store i64 %2833, i64* %RAX.i1659, align 8
  %2834 = icmp eq i32 %2831, -1
  %2835 = icmp eq i32 %2832, 0
  %2836 = or i1 %2834, %2835
  %2837 = zext i1 %2836 to i8
  store i8 %2837, i8* %17, align 1
  %2838 = and i32 %2832, 255
  %2839 = tail call i32 @llvm.ctpop.i32(i32 %2838)
  %2840 = trunc i32 %2839 to i8
  %2841 = and i8 %2840, 1
  %2842 = xor i8 %2841, 1
  store i8 %2842, i8* %18, align 1
  %2843 = xor i32 %2832, %2831
  %2844 = lshr i32 %2843, 4
  %2845 = trunc i32 %2844 to i8
  %2846 = and i8 %2845, 1
  store i8 %2846, i8* %19, align 1
  %2847 = zext i1 %2835 to i8
  store i8 %2847, i8* %20, align 1
  %2848 = lshr i32 %2832, 31
  %2849 = trunc i32 %2848 to i8
  store i8 %2849, i8* %21, align 1
  %2850 = lshr i32 %2831, 31
  %2851 = xor i32 %2848, %2850
  %2852 = add nuw nsw i32 %2851, %2848
  %2853 = icmp eq i32 %2852, 2
  %2854 = zext i1 %2853 to i8
  store i8 %2854, i8* %22, align 1
  %2855 = add i64 %2828, 9
  store i64 %2855, i64* %3, align 8
  store i32 %2832, i32* %2830, align 4
  %2856 = load i64, i64* %3, align 8
  %2857 = add i64 %2856, -230
  store i64 %2857, i64* %3, align 8
  br label %block_.L_484024

block_.L_48410f:                                  ; preds = %block_.L_484024
  %2858 = add i64 %2334, -48
  %2859 = add i64 %2362, 8
  store i64 %2859, i64* %3, align 8
  %2860 = inttoptr i64 %2858 to i32*
  %2861 = load i32, i32* %2860, align 4
  %2862 = add i32 %2861, 1
  %2863 = zext i32 %2862 to i64
  store i64 %2863, i64* %RAX.i1659, align 8
  %2864 = icmp eq i32 %2861, -1
  %2865 = icmp eq i32 %2862, 0
  %2866 = or i1 %2864, %2865
  %2867 = zext i1 %2866 to i8
  store i8 %2867, i8* %17, align 1
  %2868 = and i32 %2862, 255
  %2869 = tail call i32 @llvm.ctpop.i32(i32 %2868)
  %2870 = trunc i32 %2869 to i8
  %2871 = and i8 %2870, 1
  %2872 = xor i8 %2871, 1
  store i8 %2872, i8* %18, align 1
  %2873 = xor i32 %2862, %2861
  %2874 = lshr i32 %2873, 4
  %2875 = trunc i32 %2874 to i8
  %2876 = and i8 %2875, 1
  store i8 %2876, i8* %19, align 1
  %2877 = zext i1 %2865 to i8
  store i8 %2877, i8* %20, align 1
  %2878 = lshr i32 %2862, 31
  %2879 = trunc i32 %2878 to i8
  store i8 %2879, i8* %21, align 1
  %2880 = lshr i32 %2861, 31
  %2881 = xor i32 %2878, %2880
  %2882 = add nuw nsw i32 %2881, %2878
  %2883 = icmp eq i32 %2882, 2
  %2884 = zext i1 %2883 to i8
  store i8 %2884, i8* %22, align 1
  %2885 = add i64 %2362, 14
  store i64 %2885, i64* %3, align 8
  store i32 %2862, i32* %2860, align 4
  %2886 = load i64, i64* %3, align 8
  %2887 = add i64 %2886, -266
  store i64 %2887, i64* %3, align 8
  br label %block_.L_484013

block_.L_484122:                                  ; preds = %block_.L_484013
  %2888 = load i64, i64* bitcast (%G_0x6cc628_type* @G_0x6cc628 to i64*), align 8
  store i64 %2888, i64* %RDI.i6998, align 8
  %2889 = add i64 %2329, 104350
  %2890 = add i64 %2329, 13
  %2891 = load i64, i64* %6, align 8
  %2892 = add i64 %2891, -8
  %2893 = inttoptr i64 %2892 to i64*
  store i64 %2890, i64* %2893, align 8
  store i64 %2892, i64* %6, align 8
  store i64 %2889, i64* %3, align 8
  %call2_48412a = tail call %struct.Memory* @sub_49d8c0.store_coding_state(%struct.State* nonnull %0, i64 %2889, %struct.Memory* %MEMORY.8)
  %2894 = load i64, i64* %RBP.i, align 8
  %2895 = add i64 %2894, -72
  %2896 = load i64, i64* %3, align 8
  store i64 %2895, i64* %RDI.i6998, align 8
  %2897 = add i64 %2894, -12
  %2898 = add i64 %2896, 7
  store i64 %2898, i64* %3, align 8
  %2899 = inttoptr i64 %2897 to i32*
  %2900 = load i32, i32* %2899, align 4
  %2901 = zext i32 %2900 to i64
  store i64 %2901, i64* %RSI.i2015, align 8
  %2902 = add i64 %2894, -16
  %2903 = add i64 %2896, 10
  store i64 %2903, i64* %3, align 8
  %2904 = inttoptr i64 %2902 to i32*
  %2905 = load i32, i32* %2904, align 4
  %2906 = zext i32 %2905 to i64
  store i64 %2906, i64* %RDX.i1943, align 8
  %2907 = add i64 %2894, -36
  %2908 = add i64 %2896, 13
  store i64 %2908, i64* %3, align 8
  %2909 = inttoptr i64 %2907 to i32*
  %2910 = load i32, i32* %2909, align 4
  %2911 = zext i32 %2910 to i64
  store i64 %2911, i64* %RCX.i1588, align 8
  %2912 = add i64 %2894, -24
  %2913 = add i64 %2896, 18
  store i64 %2913, i64* %3, align 8
  %2914 = inttoptr i64 %2912 to i64*
  %2915 = load i64, i64* %2914, align 8
  store i64 %2915, i64* %69, align 1
  store double 0.000000e+00, double* %1190, align 1
  %2916 = add i64 %2894, -256
  %2917 = add i64 %2896, 26
  store i64 %2917, i64* %3, align 8
  %2918 = inttoptr i64 %2916 to i64*
  %2919 = load i64, i64* %2918, align 8
  store i64 %2919, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %2920 = add i64 %2894, -288
  %2921 = add i64 %2896, 33
  store i64 %2921, i64* %3, align 8
  %2922 = inttoptr i64 %2920 to i32*
  %2923 = load i32, i32* %2922, align 4
  %2924 = zext i32 %2923 to i64
  store i64 %2924, i64* %25, align 8
  %2925 = add i64 %2896, -4175
  %2926 = add i64 %2896, 38
  %2927 = load i64, i64* %6, align 8
  %2928 = add i64 %2927, -8
  %2929 = inttoptr i64 %2928 to i64*
  store i64 %2926, i64* %2929, align 8
  store i64 %2928, i64* %6, align 8
  store i64 %2925, i64* %3, align 8
  %call2_484150 = tail call %struct.Memory* @sub_4830e0.RDCost_for_4x4IntraBlocks(%struct.State* nonnull %0, i64 %2925, %struct.Memory* %MEMORY.8)
  %2930 = load i64, i64* %RBP.i, align 8
  %2931 = add i64 %2930, -216
  %2932 = load i64, i64* %3, align 8
  %2933 = add i64 %2932, 8
  store i64 %2933, i64* %3, align 8
  %2934 = load i64, i64* %69, align 1
  %2935 = inttoptr i64 %2931 to i64*
  store i64 %2934, i64* %2935, align 8
  %2936 = load i64, i64* %RBP.i, align 8
  %2937 = add i64 %2936, -216
  %2938 = load i64, i64* %3, align 8
  %2939 = add i64 %2938, 8
  store i64 %2939, i64* %3, align 8
  %2940 = inttoptr i64 %2937 to i64*
  %2941 = load i64, i64* %2940, align 8
  store i64 %2941, i64* %69, align 1
  store double 0.000000e+00, double* %1190, align 1
  %2942 = add i64 %2936, -256
  %2943 = add i64 %2938, 16
  store i64 %2943, i64* %3, align 8
  %2944 = bitcast i64 %2941 to double
  %2945 = inttoptr i64 %2942 to double*
  %2946 = load double, double* %2945, align 8
  %2947 = fsub double %2944, %2946
  store double %2947, double* %68, align 1
  store i64 0, i64* %1189, align 1
  %2948 = add i64 %2938, add (i64 ptrtoint (%G_0x3964c__rip__type* @G_0x3964c__rip_ to i64), i64 16)
  %2949 = add i64 %2938, 23
  store i64 %2949, i64* %3, align 8
  %2950 = inttoptr i64 %2948 to i32*
  %2951 = load i32, i32* %2950, align 4
  %2952 = add i64 %2938, add (i64 ptrtoint (%G_0x3964c__rip__type* @G_0x3964c__rip_ to i64), i64 20)
  %2953 = inttoptr i64 %2952 to i32*
  %2954 = load i32, i32* %2953, align 4
  %2955 = add i64 %2938, add (i64 ptrtoint (%G_0x3964c__rip__type* @G_0x3964c__rip_ to i64), i64 24)
  %2956 = inttoptr i64 %2955 to i32*
  %2957 = load i32, i32* %2956, align 4
  %2958 = add i64 %2938, add (i64 ptrtoint (%G_0x3964c__rip__type* @G_0x3964c__rip_ to i64), i64 28)
  %2959 = inttoptr i64 %2958 to i32*
  %2960 = load i32, i32* %2959, align 4
  store i32 %2951, i32* %1196, align 1
  store i32 %2954, i32* %1198, align 1
  store i32 %2957, i32* %1199, align 1
  store i32 %2960, i32* %1201, align 1
  %2961 = bitcast double %2947 to i64
  %2962 = load i64, i64* %37, align 1
  %2963 = and i64 %2962, %2961
  %2964 = trunc i64 %2963 to i32
  %2965 = lshr i64 %2963, 32
  %2966 = trunc i64 %2965 to i32
  store i32 %2964, i32* %1202, align 1
  store i32 %2966, i32* %1204, align 1
  store i32 0, i32* %1205, align 1
  store i32 0, i32* %1207, align 1
  %2967 = add i64 %2936, -264
  %2968 = add i64 %2938, 35
  store i64 %2968, i64* %3, align 8
  %2969 = load double, double* %68, align 1
  %2970 = inttoptr i64 %2967 to double*
  %2971 = load double, double* %2970, align 8
  %2972 = fcmp uno double %2969, %2971
  br i1 %2972, label %2973, label %2983

; <label>:2973:                                   ; preds = %block_.L_484122
  %2974 = fadd double %2969, %2971
  %2975 = bitcast double %2974 to i64
  %2976 = and i64 %2975, 9221120237041090560
  %2977 = icmp eq i64 %2976, 9218868437227405312
  %2978 = and i64 %2975, 2251799813685247
  %2979 = icmp ne i64 %2978, 0
  %2980 = and i1 %2977, %2979
  br i1 %2980, label %2981, label %2989

; <label>:2981:                                   ; preds = %2973
  %2982 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %2968, %struct.Memory* %MEMORY.8)
  %.pre572 = load i64, i64* %3, align 8
  br label %routine_ucomisd_MINUS0x108__rbp____xmm0.exit

; <label>:2983:                                   ; preds = %block_.L_484122
  %2984 = fcmp ogt double %2969, %2971
  br i1 %2984, label %2989, label %2985

; <label>:2985:                                   ; preds = %2983
  %2986 = fcmp olt double %2969, %2971
  br i1 %2986, label %2989, label %2987

; <label>:2987:                                   ; preds = %2985
  %2988 = fcmp oeq double %2969, %2971
  br i1 %2988, label %2989, label %2993

; <label>:2989:                                   ; preds = %2987, %2985, %2983, %2973
  %2990 = phi i8 [ 0, %2983 ], [ 0, %2985 ], [ 1, %2987 ], [ 1, %2973 ]
  %2991 = phi i8 [ 0, %2983 ], [ 0, %2985 ], [ 0, %2987 ], [ 1, %2973 ]
  %2992 = phi i8 [ 0, %2983 ], [ 1, %2985 ], [ 0, %2987 ], [ 1, %2973 ]
  store i8 %2990, i8* %20, align 1
  store i8 %2991, i8* %18, align 1
  store i8 %2992, i8* %17, align 1
  br label %2993

; <label>:2993:                                   ; preds = %2989, %2987
  store i8 0, i8* %22, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %19, align 1
  br label %routine_ucomisd_MINUS0x108__rbp____xmm0.exit

routine_ucomisd_MINUS0x108__rbp____xmm0.exit:     ; preds = %2993, %2981
  %2994 = phi i64 [ %.pre572, %2981 ], [ %2968, %2993 ]
  %2995 = phi %struct.Memory* [ %2982, %2981 ], [ %MEMORY.8, %2993 ]
  %2996 = add i64 %2994, 335
  %2997 = add i64 %2994, 6
  %2998 = load i8, i8* %17, align 1
  %2999 = load i8, i8* %20, align 1
  %3000 = or i8 %2999, %2998
  %3001 = icmp ne i8 %3000, 0
  %3002 = select i1 %3001, i64 %2996, i64 %2997
  store i64 %3002, i64* %3, align 8
  br i1 %3001, label %block_.L_4842cf, label %block_484186

block_484186:                                     ; preds = %routine_ucomisd_MINUS0x108__rbp____xmm0.exit
  %3003 = load i64, i64* %RBP.i, align 8
  %3004 = add i64 %3003, -216
  %3005 = add i64 %3002, 8
  store i64 %3005, i64* %3, align 8
  %3006 = inttoptr i64 %3004 to i64*
  %3007 = load i64, i64* %3006, align 8
  store i64 %3007, i64* %69, align 1
  store double 0.000000e+00, double* %1190, align 1
  %3008 = add i64 %3003, -256
  %3009 = add i64 %3002, 16
  store i64 %3009, i64* %3, align 8
  %3010 = inttoptr i64 %3008 to i64*
  %3011 = load i64, i64* %3010, align 8
  store i64 %3011, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %3012 = add i64 %3002, 20
  store i64 %3012, i64* %3, align 8
  %.cast = bitcast i64 %3011 to double
  %3013 = bitcast i64 %3007 to double
  %3014 = fcmp uno double %.cast, %3013
  br i1 %3014, label %3015, label %3025

; <label>:3015:                                   ; preds = %block_484186
  %3016 = fadd double %.cast, %3013
  %3017 = bitcast double %3016 to i64
  %3018 = and i64 %3017, 9221120237041090560
  %3019 = icmp eq i64 %3018, 9218868437227405312
  %3020 = and i64 %3017, 2251799813685247
  %3021 = icmp ne i64 %3020, 0
  %3022 = and i1 %3019, %3021
  br i1 %3022, label %3023, label %3031

; <label>:3023:                                   ; preds = %3015
  %3024 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %3012, %struct.Memory* %2995)
  %.pre573 = load i64, i64* %3, align 8
  %.pre574 = load i8, i8* %17, align 1
  %.pre575 = load i8, i8* %20, align 1
  br label %routine_ucomisd__xmm0___xmm1.exit6190

; <label>:3025:                                   ; preds = %block_484186
  %3026 = fcmp ogt double %.cast, %3013
  br i1 %3026, label %3031, label %3027

; <label>:3027:                                   ; preds = %3025
  %3028 = fcmp olt double %.cast, %3013
  br i1 %3028, label %3031, label %3029

; <label>:3029:                                   ; preds = %3027
  %3030 = fcmp oeq double %.cast, %3013
  br i1 %3030, label %3031, label %3035

; <label>:3031:                                   ; preds = %3029, %3027, %3025, %3015
  %3032 = phi i8 [ 0, %3025 ], [ 0, %3027 ], [ 1, %3029 ], [ 1, %3015 ]
  %3033 = phi i8 [ 0, %3025 ], [ 0, %3027 ], [ 0, %3029 ], [ 1, %3015 ]
  %3034 = phi i8 [ 0, %3025 ], [ 1, %3027 ], [ 0, %3029 ], [ 1, %3015 ]
  store i8 %3032, i8* %20, align 1
  store i8 %3033, i8* %18, align 1
  store i8 %3034, i8* %17, align 1
  br label %3035

; <label>:3035:                                   ; preds = %3031, %3029
  %3036 = phi i8 [ %3032, %3031 ], [ %2999, %3029 ]
  %3037 = phi i8 [ %3034, %3031 ], [ %2998, %3029 ]
  store i8 0, i8* %22, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %19, align 1
  br label %routine_ucomisd__xmm0___xmm1.exit6190

routine_ucomisd__xmm0___xmm1.exit6190:            ; preds = %3035, %3023
  %3038 = phi i8 [ %.pre575, %3023 ], [ %3036, %3035 ]
  %3039 = phi i8 [ %.pre574, %3023 ], [ %3037, %3035 ]
  %3040 = phi i64 [ %.pre573, %3023 ], [ %3012, %3035 ]
  %3041 = phi %struct.Memory* [ %3024, %3023 ], [ %2995, %3035 ]
  %3042 = or i8 %3038, %3039
  %3043 = icmp ne i8 %3042, 0
  %.v756 = select i1 %3043, i64 309, i64 6
  %3044 = add i64 %3040, %.v756
  store i64 %3044, i64* %3, align 8
  br i1 %3043, label %block_.L_4842cf, label %block_4841a0

block_4841a0:                                     ; preds = %routine_ucomisd__xmm0___xmm1.exit6190
  %3045 = load i64, i64* %RBP.i, align 8
  %3046 = add i64 %3045, -48
  %3047 = add i64 %3044, 7
  store i64 %3047, i64* %3, align 8
  %3048 = inttoptr i64 %3046 to i32*
  store i32 0, i32* %3048, align 4
  %.pre576 = load i64, i64* %3, align 8
  br label %block_.L_4841a7

block_.L_4841a7:                                  ; preds = %block_.L_484215, %block_4841a0
  %3049 = phi i64 [ %3234, %block_.L_484215 ], [ %.pre576, %block_4841a0 ]
  %3050 = load i64, i64* %RBP.i, align 8
  %3051 = add i64 %3050, -48
  %3052 = add i64 %3049, 4
  store i64 %3052, i64* %3, align 8
  %3053 = inttoptr i64 %3051 to i32*
  %3054 = load i32, i32* %3053, align 4
  %3055 = add i32 %3054, -2
  %3056 = icmp ult i32 %3054, 2
  %3057 = zext i1 %3056 to i8
  store i8 %3057, i8* %17, align 1
  %3058 = and i32 %3055, 255
  %3059 = tail call i32 @llvm.ctpop.i32(i32 %3058)
  %3060 = trunc i32 %3059 to i8
  %3061 = and i8 %3060, 1
  %3062 = xor i8 %3061, 1
  store i8 %3062, i8* %18, align 1
  %3063 = xor i32 %3055, %3054
  %3064 = lshr i32 %3063, 4
  %3065 = trunc i32 %3064 to i8
  %3066 = and i8 %3065, 1
  store i8 %3066, i8* %19, align 1
  %3067 = icmp eq i32 %3055, 0
  %3068 = zext i1 %3067 to i8
  store i8 %3068, i8* %20, align 1
  %3069 = lshr i32 %3055, 31
  %3070 = trunc i32 %3069 to i8
  store i8 %3070, i8* %21, align 1
  %3071 = lshr i32 %3054, 31
  %3072 = xor i32 %3069, %3071
  %3073 = add nuw nsw i32 %3072, %3071
  %3074 = icmp eq i32 %3073, 2
  %3075 = zext i1 %3074 to i8
  store i8 %3075, i8* %22, align 1
  %3076 = icmp ne i8 %3070, 0
  %3077 = xor i1 %3076, %3074
  %.v757 = select i1 %3077, i64 10, i64 129
  %3078 = add i64 %3049, %.v757
  store i64 %3078, i64* %3, align 8
  br i1 %3077, label %block_4841b1, label %block_.L_484228

block_4841b1:                                     ; preds = %block_.L_4841a7
  %3079 = add i64 %3050, -44
  %3080 = add i64 %3078, 7
  store i64 %3080, i64* %3, align 8
  %3081 = inttoptr i64 %3079 to i32*
  store i32 0, i32* %3081, align 4
  %.pre579 = load i64, i64* %3, align 8
  br label %block_.L_4841b8

block_.L_4841b8:                                  ; preds = %block_4841c2, %block_4841b1
  %3082 = phi i64 [ %3204, %block_4841c2 ], [ %.pre579, %block_4841b1 ]
  %3083 = load i64, i64* %RBP.i, align 8
  %3084 = add i64 %3083, -44
  %3085 = add i64 %3082, 4
  store i64 %3085, i64* %3, align 8
  %3086 = inttoptr i64 %3084 to i32*
  %3087 = load i32, i32* %3086, align 4
  %3088 = add i32 %3087, -18
  %3089 = icmp ult i32 %3087, 18
  %3090 = zext i1 %3089 to i8
  store i8 %3090, i8* %17, align 1
  %3091 = and i32 %3088, 255
  %3092 = tail call i32 @llvm.ctpop.i32(i32 %3091)
  %3093 = trunc i32 %3092 to i8
  %3094 = and i8 %3093, 1
  %3095 = xor i8 %3094, 1
  store i8 %3095, i8* %18, align 1
  %3096 = xor i32 %3087, 16
  %3097 = xor i32 %3096, %3088
  %3098 = lshr i32 %3097, 4
  %3099 = trunc i32 %3098 to i8
  %3100 = and i8 %3099, 1
  store i8 %3100, i8* %19, align 1
  %3101 = icmp eq i32 %3088, 0
  %3102 = zext i1 %3101 to i8
  store i8 %3102, i8* %20, align 1
  %3103 = lshr i32 %3088, 31
  %3104 = trunc i32 %3103 to i8
  store i8 %3104, i8* %21, align 1
  %3105 = lshr i32 %3087, 31
  %3106 = xor i32 %3103, %3105
  %3107 = add nuw nsw i32 %3106, %3105
  %3108 = icmp eq i32 %3107, 2
  %3109 = zext i1 %3108 to i8
  store i8 %3109, i8* %22, align 1
  %3110 = icmp ne i8 %3104, 0
  %3111 = xor i1 %3110, %3108
  %.v678 = select i1 %3111, i64 10, i64 93
  %3112 = add i64 %3082, %.v678
  store i64 %3112, i64* %3, align 8
  br i1 %3111, label %block_4841c2, label %block_.L_484215

block_4841c2:                                     ; preds = %block_.L_4841b8
  %3113 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %3113, i64* %RAX.i1659, align 8
  %3114 = add i64 %3113, 14136
  %3115 = add i64 %3112, 15
  store i64 %3115, i64* %3, align 8
  %3116 = inttoptr i64 %3114 to i64*
  %3117 = load i64, i64* %3116, align 8
  store i64 %3117, i64* %RAX.i1659, align 8
  %3118 = add i64 %3083, -12
  %3119 = add i64 %3112, 19
  store i64 %3119, i64* %3, align 8
  %3120 = inttoptr i64 %3118 to i32*
  %3121 = load i32, i32* %3120, align 4
  %3122 = sext i32 %3121 to i64
  store i64 %3122, i64* %RCX.i1588, align 8
  %3123 = shl nsw i64 %3122, 3
  %3124 = add i64 %3123, %3117
  %3125 = add i64 %3112, 23
  store i64 %3125, i64* %3, align 8
  %3126 = inttoptr i64 %3124 to i64*
  %3127 = load i64, i64* %3126, align 8
  store i64 %3127, i64* %RAX.i1659, align 8
  %3128 = add i64 %3083, -16
  %3129 = add i64 %3112, 27
  store i64 %3129, i64* %3, align 8
  %3130 = inttoptr i64 %3128 to i32*
  %3131 = load i32, i32* %3130, align 4
  %3132 = sext i32 %3131 to i64
  store i64 %3132, i64* %RCX.i1588, align 8
  %3133 = shl nsw i64 %3132, 3
  %3134 = add i64 %3133, %3127
  %3135 = add i64 %3112, 31
  store i64 %3135, i64* %3, align 8
  %3136 = inttoptr i64 %3134 to i64*
  %3137 = load i64, i64* %3136, align 8
  store i64 %3137, i64* %RAX.i1659, align 8
  %3138 = add i64 %3083, -48
  %3139 = add i64 %3112, 35
  store i64 %3139, i64* %3, align 8
  %3140 = inttoptr i64 %3138 to i32*
  %3141 = load i32, i32* %3140, align 4
  %3142 = sext i32 %3141 to i64
  store i64 %3142, i64* %RCX.i1588, align 8
  %3143 = shl nsw i64 %3142, 3
  %3144 = add i64 %3143, %3137
  %3145 = add i64 %3112, 39
  store i64 %3145, i64* %3, align 8
  %3146 = inttoptr i64 %3144 to i64*
  %3147 = load i64, i64* %3146, align 8
  store i64 %3147, i64* %RAX.i1659, align 8
  %3148 = add i64 %3112, 43
  store i64 %3148, i64* %3, align 8
  %3149 = load i32, i32* %3086, align 4
  %3150 = sext i32 %3149 to i64
  store i64 %3150, i64* %RCX.i1588, align 8
  %3151 = shl nsw i64 %3150, 2
  %3152 = add i64 %3151, %3147
  %3153 = add i64 %3112, 46
  store i64 %3153, i64* %3, align 8
  %3154 = inttoptr i64 %3152 to i32*
  %3155 = load i32, i32* %3154, align 4
  %3156 = zext i32 %3155 to i64
  store i64 %3156, i64* %RDX.i1943, align 8
  %3157 = load i64, i64* bitcast (%G_0x6cc608_type* @G_0x6cc608 to i64*), align 8
  store i64 %3157, i64* %RAX.i1659, align 8
  %3158 = add i64 %3112, 58
  store i64 %3158, i64* %3, align 8
  %3159 = load i32, i32* %3140, align 4
  %3160 = sext i32 %3159 to i64
  store i64 %3160, i64* %RCX.i1588, align 8
  %3161 = shl nsw i64 %3160, 3
  %3162 = add i64 %3161, %3157
  %3163 = add i64 %3112, 62
  store i64 %3163, i64* %3, align 8
  %3164 = inttoptr i64 %3162 to i64*
  %3165 = load i64, i64* %3164, align 8
  store i64 %3165, i64* %RAX.i1659, align 8
  %3166 = add i64 %3112, 66
  store i64 %3166, i64* %3, align 8
  %3167 = load i32, i32* %3086, align 4
  %3168 = sext i32 %3167 to i64
  store i64 %3168, i64* %RCX.i1588, align 8
  %3169 = shl nsw i64 %3168, 2
  %3170 = add i64 %3169, %3165
  %3171 = add i64 %3112, 69
  store i64 %3171, i64* %3, align 8
  %3172 = inttoptr i64 %3170 to i32*
  store i32 %3155, i32* %3172, align 4
  %3173 = load i64, i64* %RBP.i, align 8
  %3174 = add i64 %3173, -44
  %3175 = load i64, i64* %3, align 8
  %3176 = add i64 %3175, 3
  store i64 %3176, i64* %3, align 8
  %3177 = inttoptr i64 %3174 to i32*
  %3178 = load i32, i32* %3177, align 4
  %3179 = add i32 %3178, 1
  %3180 = zext i32 %3179 to i64
  store i64 %3180, i64* %RAX.i1659, align 8
  %3181 = icmp eq i32 %3178, -1
  %3182 = icmp eq i32 %3179, 0
  %3183 = or i1 %3181, %3182
  %3184 = zext i1 %3183 to i8
  store i8 %3184, i8* %17, align 1
  %3185 = and i32 %3179, 255
  %3186 = tail call i32 @llvm.ctpop.i32(i32 %3185)
  %3187 = trunc i32 %3186 to i8
  %3188 = and i8 %3187, 1
  %3189 = xor i8 %3188, 1
  store i8 %3189, i8* %18, align 1
  %3190 = xor i32 %3179, %3178
  %3191 = lshr i32 %3190, 4
  %3192 = trunc i32 %3191 to i8
  %3193 = and i8 %3192, 1
  store i8 %3193, i8* %19, align 1
  %3194 = zext i1 %3182 to i8
  store i8 %3194, i8* %20, align 1
  %3195 = lshr i32 %3179, 31
  %3196 = trunc i32 %3195 to i8
  store i8 %3196, i8* %21, align 1
  %3197 = lshr i32 %3178, 31
  %3198 = xor i32 %3195, %3197
  %3199 = add nuw nsw i32 %3198, %3195
  %3200 = icmp eq i32 %3199, 2
  %3201 = zext i1 %3200 to i8
  store i8 %3201, i8* %22, align 1
  %3202 = add i64 %3175, 9
  store i64 %3202, i64* %3, align 8
  store i32 %3179, i32* %3177, align 4
  %3203 = load i64, i64* %3, align 8
  %3204 = add i64 %3203, -88
  store i64 %3204, i64* %3, align 8
  br label %block_.L_4841b8

block_.L_484215:                                  ; preds = %block_.L_4841b8
  %3205 = add i64 %3083, -48
  %3206 = add i64 %3112, 8
  store i64 %3206, i64* %3, align 8
  %3207 = inttoptr i64 %3205 to i32*
  %3208 = load i32, i32* %3207, align 4
  %3209 = add i32 %3208, 1
  %3210 = zext i32 %3209 to i64
  store i64 %3210, i64* %RAX.i1659, align 8
  %3211 = icmp eq i32 %3208, -1
  %3212 = icmp eq i32 %3209, 0
  %3213 = or i1 %3211, %3212
  %3214 = zext i1 %3213 to i8
  store i8 %3214, i8* %17, align 1
  %3215 = and i32 %3209, 255
  %3216 = tail call i32 @llvm.ctpop.i32(i32 %3215)
  %3217 = trunc i32 %3216 to i8
  %3218 = and i8 %3217, 1
  %3219 = xor i8 %3218, 1
  store i8 %3219, i8* %18, align 1
  %3220 = xor i32 %3209, %3208
  %3221 = lshr i32 %3220, 4
  %3222 = trunc i32 %3221 to i8
  %3223 = and i8 %3222, 1
  store i8 %3223, i8* %19, align 1
  %3224 = zext i1 %3212 to i8
  store i8 %3224, i8* %20, align 1
  %3225 = lshr i32 %3209, 31
  %3226 = trunc i32 %3225 to i8
  store i8 %3226, i8* %21, align 1
  %3227 = lshr i32 %3208, 31
  %3228 = xor i32 %3225, %3227
  %3229 = add nuw nsw i32 %3228, %3225
  %3230 = icmp eq i32 %3229, 2
  %3231 = zext i1 %3230 to i8
  store i8 %3231, i8* %22, align 1
  %3232 = add i64 %3112, 14
  store i64 %3232, i64* %3, align 8
  store i32 %3209, i32* %3207, align 4
  %3233 = load i64, i64* %3, align 8
  %3234 = add i64 %3233, -124
  store i64 %3234, i64* %3, align 8
  br label %block_.L_4841a7

block_.L_484228:                                  ; preds = %block_.L_4841a7
  %3235 = add i64 %3050, -60
  %3236 = add i64 %3078, 7
  store i64 %3236, i64* %3, align 8
  %3237 = inttoptr i64 %3235 to i32*
  store i32 0, i32* %3237, align 4
  %.pre577 = load i64, i64* %3, align 8
  br label %block_.L_48422f

block_.L_48422f:                                  ; preds = %block_.L_4842a0, %block_.L_484228
  %3238 = phi i64 [ %3497, %block_.L_4842a0 ], [ %.pre577, %block_.L_484228 ]
  %3239 = load i64, i64* %RBP.i, align 8
  %3240 = add i64 %3239, -60
  %3241 = add i64 %3238, 4
  store i64 %3241, i64* %3, align 8
  %3242 = inttoptr i64 %3240 to i32*
  %3243 = load i32, i32* %3242, align 4
  %3244 = add i32 %3243, -4
  %3245 = icmp ult i32 %3243, 4
  %3246 = zext i1 %3245 to i8
  store i8 %3246, i8* %17, align 1
  %3247 = and i32 %3244, 255
  %3248 = tail call i32 @llvm.ctpop.i32(i32 %3247)
  %3249 = trunc i32 %3248 to i8
  %3250 = and i8 %3249, 1
  %3251 = xor i8 %3250, 1
  store i8 %3251, i8* %18, align 1
  %3252 = xor i32 %3244, %3243
  %3253 = lshr i32 %3252, 4
  %3254 = trunc i32 %3253 to i8
  %3255 = and i8 %3254, 1
  store i8 %3255, i8* %19, align 1
  %3256 = icmp eq i32 %3244, 0
  %3257 = zext i1 %3256 to i8
  store i8 %3257, i8* %20, align 1
  %3258 = lshr i32 %3244, 31
  %3259 = trunc i32 %3258 to i8
  store i8 %3259, i8* %21, align 1
  %3260 = lshr i32 %3243, 31
  %3261 = xor i32 %3258, %3260
  %3262 = add nuw nsw i32 %3261, %3260
  %3263 = icmp eq i32 %3262, 2
  %3264 = zext i1 %3263 to i8
  store i8 %3264, i8* %22, align 1
  %3265 = icmp ne i8 %3259, 0
  %3266 = xor i1 %3265, %3263
  %.v758 = select i1 %3266, i64 10, i64 132
  %3267 = add i64 %3238, %.v758
  store i64 %3267, i64* %3, align 8
  br i1 %3266, label %block_484239, label %block_.L_4842b3

block_484239:                                     ; preds = %block_.L_48422f
  %3268 = add i64 %3239, -56
  %3269 = add i64 %3267, 7
  store i64 %3269, i64* %3, align 8
  %3270 = inttoptr i64 %3268 to i32*
  store i32 0, i32* %3270, align 4
  %.pre578 = load i64, i64* %3, align 8
  br label %block_.L_484240

block_.L_484240:                                  ; preds = %block_48424a, %block_484239
  %3271 = phi i64 [ %3467, %block_48424a ], [ %.pre578, %block_484239 ]
  %3272 = load i64, i64* %RBP.i, align 8
  %3273 = add i64 %3272, -56
  %3274 = add i64 %3271, 4
  store i64 %3274, i64* %3, align 8
  %3275 = inttoptr i64 %3273 to i32*
  %3276 = load i32, i32* %3275, align 4
  %3277 = add i32 %3276, -4
  %3278 = icmp ult i32 %3276, 4
  %3279 = zext i1 %3278 to i8
  store i8 %3279, i8* %17, align 1
  %3280 = and i32 %3277, 255
  %3281 = tail call i32 @llvm.ctpop.i32(i32 %3280)
  %3282 = trunc i32 %3281 to i8
  %3283 = and i8 %3282, 1
  %3284 = xor i8 %3283, 1
  store i8 %3284, i8* %18, align 1
  %3285 = xor i32 %3277, %3276
  %3286 = lshr i32 %3285, 4
  %3287 = trunc i32 %3286 to i8
  %3288 = and i8 %3287, 1
  store i8 %3288, i8* %19, align 1
  %3289 = icmp eq i32 %3277, 0
  %3290 = zext i1 %3289 to i8
  store i8 %3290, i8* %20, align 1
  %3291 = lshr i32 %3277, 31
  %3292 = trunc i32 %3291 to i8
  store i8 %3292, i8* %21, align 1
  %3293 = lshr i32 %3276, 31
  %3294 = xor i32 %3291, %3293
  %3295 = add nuw nsw i32 %3294, %3293
  %3296 = icmp eq i32 %3295, 2
  %3297 = zext i1 %3296 to i8
  store i8 %3297, i8* %22, align 1
  %3298 = icmp ne i8 %3292, 0
  %3299 = xor i1 %3298, %3296
  %.v677 = select i1 %3299, i64 10, i64 96
  %3300 = add i64 %3271, %.v677
  store i64 %3300, i64* %3, align 8
  br i1 %3299, label %block_48424a, label %block_.L_4842a0

block_48424a:                                     ; preds = %block_.L_484240
  %3301 = add i64 %3272, -144
  store i64 %3301, i64* %RAX.i1659, align 8
  %3302 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %3302, i64* %RCX.i1588, align 8
  %3303 = add i64 %3302, 6424
  %3304 = add i64 %3300, 22
  store i64 %3304, i64* %3, align 8
  %3305 = inttoptr i64 %3303 to i64*
  %3306 = load i64, i64* %3305, align 8
  store i64 %3306, i64* %RCX.i1588, align 8
  %3307 = add i64 %3272, -232
  %3308 = add i64 %3300, 28
  store i64 %3308, i64* %3, align 8
  %3309 = inttoptr i64 %3307 to i32*
  %3310 = load i32, i32* %3309, align 4
  %3311 = zext i32 %3310 to i64
  store i64 %3311, i64* %RDX.i1943, align 8
  %3312 = add i64 %3272, -60
  %3313 = add i64 %3300, 31
  store i64 %3313, i64* %3, align 8
  %3314 = inttoptr i64 %3312 to i32*
  %3315 = load i32, i32* %3314, align 4
  %3316 = add i32 %3315, %3310
  %3317 = zext i32 %3316 to i64
  store i64 %3317, i64* %RDX.i1943, align 8
  %3318 = icmp ult i32 %3316, %3310
  %3319 = icmp ult i32 %3316, %3315
  %3320 = or i1 %3318, %3319
  %3321 = zext i1 %3320 to i8
  store i8 %3321, i8* %17, align 1
  %3322 = and i32 %3316, 255
  %3323 = tail call i32 @llvm.ctpop.i32(i32 %3322)
  %3324 = trunc i32 %3323 to i8
  %3325 = and i8 %3324, 1
  %3326 = xor i8 %3325, 1
  store i8 %3326, i8* %18, align 1
  %3327 = xor i32 %3315, %3310
  %3328 = xor i32 %3327, %3316
  %3329 = lshr i32 %3328, 4
  %3330 = trunc i32 %3329 to i8
  %3331 = and i8 %3330, 1
  store i8 %3331, i8* %19, align 1
  %3332 = icmp eq i32 %3316, 0
  %3333 = zext i1 %3332 to i8
  store i8 %3333, i8* %20, align 1
  %3334 = lshr i32 %3316, 31
  %3335 = trunc i32 %3334 to i8
  store i8 %3335, i8* %21, align 1
  %3336 = lshr i32 %3310, 31
  %3337 = lshr i32 %3315, 31
  %3338 = xor i32 %3334, %3336
  %3339 = xor i32 %3334, %3337
  %3340 = add nuw nsw i32 %3338, %3339
  %3341 = icmp eq i32 %3340, 2
  %3342 = zext i1 %3341 to i8
  store i8 %3342, i8* %22, align 1
  %3343 = sext i32 %3316 to i64
  store i64 %3343, i64* %RSI.i2015, align 8
  %3344 = shl nsw i64 %3343, 3
  %3345 = add i64 %3306, %3344
  %3346 = add i64 %3300, 38
  store i64 %3346, i64* %3, align 8
  %3347 = inttoptr i64 %3345 to i64*
  %3348 = load i64, i64* %3347, align 8
  store i64 %3348, i64* %RCX.i1588, align 8
  %3349 = add i64 %3272, -228
  %3350 = add i64 %3300, 44
  store i64 %3350, i64* %3, align 8
  %3351 = inttoptr i64 %3349 to i32*
  %3352 = load i32, i32* %3351, align 4
  %3353 = zext i32 %3352 to i64
  store i64 %3353, i64* %RDX.i1943, align 8
  %3354 = add i64 %3300, 47
  store i64 %3354, i64* %3, align 8
  %3355 = load i32, i32* %3275, align 4
  %3356 = add i32 %3355, %3352
  %3357 = zext i32 %3356 to i64
  store i64 %3357, i64* %RDX.i1943, align 8
  %3358 = icmp ult i32 %3356, %3352
  %3359 = icmp ult i32 %3356, %3355
  %3360 = or i1 %3358, %3359
  %3361 = zext i1 %3360 to i8
  store i8 %3361, i8* %17, align 1
  %3362 = and i32 %3356, 255
  %3363 = tail call i32 @llvm.ctpop.i32(i32 %3362)
  %3364 = trunc i32 %3363 to i8
  %3365 = and i8 %3364, 1
  %3366 = xor i8 %3365, 1
  store i8 %3366, i8* %18, align 1
  %3367 = xor i32 %3355, %3352
  %3368 = xor i32 %3367, %3356
  %3369 = lshr i32 %3368, 4
  %3370 = trunc i32 %3369 to i8
  %3371 = and i8 %3370, 1
  store i8 %3371, i8* %19, align 1
  %3372 = icmp eq i32 %3356, 0
  %3373 = zext i1 %3372 to i8
  store i8 %3373, i8* %20, align 1
  %3374 = lshr i32 %3356, 31
  %3375 = trunc i32 %3374 to i8
  store i8 %3375, i8* %21, align 1
  %3376 = lshr i32 %3352, 31
  %3377 = lshr i32 %3355, 31
  %3378 = xor i32 %3374, %3376
  %3379 = xor i32 %3374, %3377
  %3380 = add nuw nsw i32 %3378, %3379
  %3381 = icmp eq i32 %3380, 2
  %3382 = zext i1 %3381 to i8
  store i8 %3382, i8* %22, align 1
  %3383 = sext i32 %3356 to i64
  store i64 %3383, i64* %RSI.i2015, align 8
  %3384 = shl nsw i64 %3383, 1
  %3385 = add i64 %3348, %3384
  %3386 = add i64 %3300, 54
  store i64 %3386, i64* %3, align 8
  %3387 = inttoptr i64 %3385 to i16*
  %3388 = load i16, i16* %3387, align 2
  %3389 = zext i16 %3388 to i64
  store i64 %3389, i64* %RDX.i1943, align 8
  %3390 = load i64, i64* %RBP.i, align 8
  %3391 = add i64 %3390, -60
  %3392 = add i64 %3300, 58
  store i64 %3392, i64* %3, align 8
  %3393 = inttoptr i64 %3391 to i32*
  %3394 = load i32, i32* %3393, align 4
  %3395 = sext i32 %3394 to i64
  %3396 = shl nsw i64 %3395, 4
  store i64 %3396, i64* %RCX.i1588, align 8
  %3397 = load i64, i64* %RAX.i1659, align 8
  %3398 = add i64 %3396, %3397
  store i64 %3398, i64* %RAX.i1659, align 8
  %3399 = icmp ult i64 %3398, %3397
  %3400 = icmp ult i64 %3398, %3396
  %3401 = or i1 %3399, %3400
  %3402 = zext i1 %3401 to i8
  store i8 %3402, i8* %17, align 1
  %3403 = trunc i64 %3398 to i32
  %3404 = and i32 %3403, 255
  %3405 = tail call i32 @llvm.ctpop.i32(i32 %3404)
  %3406 = trunc i32 %3405 to i8
  %3407 = and i8 %3406, 1
  %3408 = xor i8 %3407, 1
  store i8 %3408, i8* %18, align 1
  %3409 = xor i64 %3396, %3397
  %3410 = xor i64 %3409, %3398
  %3411 = lshr i64 %3410, 4
  %3412 = trunc i64 %3411 to i8
  %3413 = and i8 %3412, 1
  store i8 %3413, i8* %19, align 1
  %3414 = icmp eq i64 %3398, 0
  %3415 = zext i1 %3414 to i8
  store i8 %3415, i8* %20, align 1
  %3416 = lshr i64 %3398, 63
  %3417 = trunc i64 %3416 to i8
  store i8 %3417, i8* %21, align 1
  %3418 = lshr i64 %3397, 63
  %3419 = lshr i64 %3395, 59
  %3420 = and i64 %3419, 1
  %3421 = xor i64 %3416, %3418
  %3422 = xor i64 %3416, %3420
  %3423 = add nuw nsw i64 %3421, %3422
  %3424 = icmp eq i64 %3423, 2
  %3425 = zext i1 %3424 to i8
  store i8 %3425, i8* %22, align 1
  %3426 = add i64 %3390, -56
  %3427 = add i64 %3300, 69
  store i64 %3427, i64* %3, align 8
  %3428 = inttoptr i64 %3426 to i32*
  %3429 = load i32, i32* %3428, align 4
  %3430 = sext i32 %3429 to i64
  store i64 %3430, i64* %RCX.i1588, align 8
  %3431 = shl nsw i64 %3430, 2
  %3432 = add i64 %3431, %3398
  %3433 = zext i16 %3388 to i32
  %3434 = add i64 %3300, 72
  store i64 %3434, i64* %3, align 8
  %3435 = inttoptr i64 %3432 to i32*
  store i32 %3433, i32* %3435, align 4
  %3436 = load i64, i64* %RBP.i, align 8
  %3437 = add i64 %3436, -56
  %3438 = load i64, i64* %3, align 8
  %3439 = add i64 %3438, 3
  store i64 %3439, i64* %3, align 8
  %3440 = inttoptr i64 %3437 to i32*
  %3441 = load i32, i32* %3440, align 4
  %3442 = add i32 %3441, 1
  %3443 = zext i32 %3442 to i64
  store i64 %3443, i64* %RAX.i1659, align 8
  %3444 = icmp eq i32 %3441, -1
  %3445 = icmp eq i32 %3442, 0
  %3446 = or i1 %3444, %3445
  %3447 = zext i1 %3446 to i8
  store i8 %3447, i8* %17, align 1
  %3448 = and i32 %3442, 255
  %3449 = tail call i32 @llvm.ctpop.i32(i32 %3448)
  %3450 = trunc i32 %3449 to i8
  %3451 = and i8 %3450, 1
  %3452 = xor i8 %3451, 1
  store i8 %3452, i8* %18, align 1
  %3453 = xor i32 %3442, %3441
  %3454 = lshr i32 %3453, 4
  %3455 = trunc i32 %3454 to i8
  %3456 = and i8 %3455, 1
  store i8 %3456, i8* %19, align 1
  %3457 = zext i1 %3445 to i8
  store i8 %3457, i8* %20, align 1
  %3458 = lshr i32 %3442, 31
  %3459 = trunc i32 %3458 to i8
  store i8 %3459, i8* %21, align 1
  %3460 = lshr i32 %3441, 31
  %3461 = xor i32 %3458, %3460
  %3462 = add nuw nsw i32 %3461, %3458
  %3463 = icmp eq i32 %3462, 2
  %3464 = zext i1 %3463 to i8
  store i8 %3464, i8* %22, align 1
  %3465 = add i64 %3438, 9
  store i64 %3465, i64* %3, align 8
  store i32 %3442, i32* %3440, align 4
  %3466 = load i64, i64* %3, align 8
  %3467 = add i64 %3466, -91
  store i64 %3467, i64* %3, align 8
  br label %block_.L_484240

block_.L_4842a0:                                  ; preds = %block_.L_484240
  %3468 = add i64 %3272, -60
  %3469 = add i64 %3300, 8
  store i64 %3469, i64* %3, align 8
  %3470 = inttoptr i64 %3468 to i32*
  %3471 = load i32, i32* %3470, align 4
  %3472 = add i32 %3471, 1
  %3473 = zext i32 %3472 to i64
  store i64 %3473, i64* %RAX.i1659, align 8
  %3474 = icmp eq i32 %3471, -1
  %3475 = icmp eq i32 %3472, 0
  %3476 = or i1 %3474, %3475
  %3477 = zext i1 %3476 to i8
  store i8 %3477, i8* %17, align 1
  %3478 = and i32 %3472, 255
  %3479 = tail call i32 @llvm.ctpop.i32(i32 %3478)
  %3480 = trunc i32 %3479 to i8
  %3481 = and i8 %3480, 1
  %3482 = xor i8 %3481, 1
  store i8 %3482, i8* %18, align 1
  %3483 = xor i32 %3472, %3471
  %3484 = lshr i32 %3483, 4
  %3485 = trunc i32 %3484 to i8
  %3486 = and i8 %3485, 1
  store i8 %3486, i8* %19, align 1
  %3487 = zext i1 %3475 to i8
  store i8 %3487, i8* %20, align 1
  %3488 = lshr i32 %3472, 31
  %3489 = trunc i32 %3488 to i8
  store i8 %3489, i8* %21, align 1
  %3490 = lshr i32 %3471, 31
  %3491 = xor i32 %3488, %3490
  %3492 = add nuw nsw i32 %3491, %3488
  %3493 = icmp eq i32 %3492, 2
  %3494 = zext i1 %3493 to i8
  store i8 %3494, i8* %22, align 1
  %3495 = add i64 %3300, 14
  store i64 %3495, i64* %3, align 8
  store i32 %3472, i32* %3470, align 4
  %3496 = load i64, i64* %3, align 8
  %3497 = add i64 %3496, -127
  store i64 %3497, i64* %3, align 8
  br label %block_.L_48422f

block_.L_4842b3:                                  ; preds = %block_.L_48422f
  %3498 = add i64 %3239, -72
  %3499 = add i64 %3267, 3
  store i64 %3499, i64* %3, align 8
  %3500 = inttoptr i64 %3498 to i32*
  %3501 = load i32, i32* %3500, align 4
  %3502 = zext i32 %3501 to i64
  store i64 %3502, i64* %RAX.i1659, align 8
  %3503 = add i64 %3239, -76
  %3504 = add i64 %3267, 6
  store i64 %3504, i64* %3, align 8
  %3505 = inttoptr i64 %3503 to i32*
  store i32 %3501, i32* %3505, align 4
  %3506 = load i64, i64* %RBP.i, align 8
  %3507 = add i64 %3506, -216
  %3508 = load i64, i64* %3, align 8
  %3509 = add i64 %3508, 8
  store i64 %3509, i64* %3, align 8
  %3510 = inttoptr i64 %3507 to i64*
  %3511 = load i64, i64* %3510, align 8
  store i64 %3511, i64* %69, align 1
  store double 0.000000e+00, double* %1190, align 1
  %3512 = add i64 %3506, -256
  %3513 = add i64 %3508, 16
  store i64 %3513, i64* %3, align 8
  %3514 = inttoptr i64 %3512 to i64*
  store i64 %3511, i64* %3514, align 8
  %3515 = load i64, i64* %RBP.i, align 8
  %3516 = add i64 %3515, -36
  %3517 = load i64, i64* %3, align 8
  %3518 = add i64 %3517, 3
  store i64 %3518, i64* %3, align 8
  %3519 = inttoptr i64 %3516 to i32*
  %3520 = load i32, i32* %3519, align 4
  %3521 = zext i32 %3520 to i64
  store i64 %3521, i64* %RAX.i1659, align 8
  %3522 = add i64 %3515, -40
  %3523 = add i64 %3517, 6
  store i64 %3523, i64* %3, align 8
  %3524 = inttoptr i64 %3522 to i32*
  store i32 %3520, i32* %3524, align 4
  %.pre580 = load i64, i64* %3, align 8
  br label %block_.L_4842cf

block_.L_4842cf:                                  ; preds = %block_.L_4842b3, %routine_ucomisd__xmm0___xmm1.exit6190, %routine_ucomisd_MINUS0x108__rbp____xmm0.exit
  %3525 = phi i64 [ %2996, %routine_ucomisd_MINUS0x108__rbp____xmm0.exit ], [ %3044, %routine_ucomisd__xmm0___xmm1.exit6190 ], [ %.pre580, %block_.L_4842b3 ]
  %MEMORY.31 = phi %struct.Memory* [ %2995, %routine_ucomisd_MINUS0x108__rbp____xmm0.exit ], [ %3041, %routine_ucomisd__xmm0___xmm1.exit6190 ], [ %3041, %block_.L_4842b3 ]
  %3526 = load i64, i64* bitcast (%G_0x6cc628_type* @G_0x6cc628 to i64*), align 8
  store i64 %3526, i64* %RDI.i6998, align 8
  %3527 = add i64 %3525, 104753
  %3528 = add i64 %3525, 13
  %3529 = load i64, i64* %6, align 8
  %3530 = add i64 %3529, -8
  %3531 = inttoptr i64 %3530 to i64*
  store i64 %3528, i64* %3531, align 8
  store i64 %3530, i64* %6, align 8
  store i64 %3527, i64* %3, align 8
  %call2_4842d7 = tail call %struct.Memory* @sub_49dc00.reset_coding_state(%struct.State* nonnull %0, i64 %3527, %struct.Memory* %MEMORY.31)
  %3532 = load i64, i64* %3, align 8
  %3533 = add i64 %3532, 5062
  br label %block_.L_4856a2

block_.L_4842e8:                                  ; preds = %block_.L_4842e8.preheader, %block_.L_484526
  %3534 = phi i64 [ %4790, %block_.L_484526 ], [ %.pre571, %block_.L_4842e8.preheader ]
  %3535 = load i64, i64* %RBP.i, align 8
  %3536 = add i64 %3535, -48
  %3537 = add i64 %3534, 4
  store i64 %3537, i64* %3, align 8
  %3538 = inttoptr i64 %3536 to i32*
  %3539 = load i32, i32* %3538, align 4
  %3540 = add i32 %3539, -4
  %3541 = icmp ult i32 %3539, 4
  %3542 = zext i1 %3541 to i8
  store i8 %3542, i8* %17, align 1
  %3543 = and i32 %3540, 255
  %3544 = tail call i32 @llvm.ctpop.i32(i32 %3543)
  %3545 = trunc i32 %3544 to i8
  %3546 = and i8 %3545, 1
  %3547 = xor i8 %3546, 1
  store i8 %3547, i8* %18, align 1
  %3548 = xor i32 %3540, %3539
  %3549 = lshr i32 %3548, 4
  %3550 = trunc i32 %3549 to i8
  %3551 = and i8 %3550, 1
  store i8 %3551, i8* %19, align 1
  %3552 = icmp eq i32 %3540, 0
  %3553 = zext i1 %3552 to i8
  store i8 %3553, i8* %20, align 1
  %3554 = lshr i32 %3540, 31
  %3555 = trunc i32 %3554 to i8
  store i8 %3555, i8* %21, align 1
  %3556 = lshr i32 %3539, 31
  %3557 = xor i32 %3554, %3556
  %3558 = add nuw nsw i32 %3557, %3556
  %3559 = icmp eq i32 %3558, 2
  %3560 = zext i1 %3559 to i8
  store i8 %3560, i8* %22, align 1
  %3561 = icmp ne i8 %3555, 0
  %3562 = xor i1 %3561, %3559
  %.v738 = select i1 %3562, i64 10, i64 593
  %3563 = add i64 %3534, %.v738
  store i64 %3563, i64* %3, align 8
  br i1 %3562, label %block_4842f2, label %block_.L_484539

block_4842f2:                                     ; preds = %block_.L_4842e8
  %3564 = add i64 %3535, -44
  %3565 = add i64 %3563, 7
  store i64 %3565, i64* %3, align 8
  %3566 = inttoptr i64 %3564 to i32*
  store i32 0, i32* %3566, align 4
  %.pre654 = load i64, i64* %3, align 8
  br label %block_.L_4842f9

block_.L_4842f9:                                  ; preds = %block_484303, %block_4842f2
  %3567 = phi i64 [ %4760, %block_484303 ], [ %.pre654, %block_4842f2 ]
  %3568 = load i64, i64* %RBP.i, align 8
  %3569 = add i64 %3568, -44
  %3570 = add i64 %3567, 4
  store i64 %3570, i64* %3, align 8
  %3571 = inttoptr i64 %3569 to i32*
  %3572 = load i32, i32* %3571, align 4
  %3573 = add i32 %3572, -4
  %3574 = icmp ult i32 %3572, 4
  %3575 = zext i1 %3574 to i8
  store i8 %3575, i8* %17, align 1
  %3576 = and i32 %3573, 255
  %3577 = tail call i32 @llvm.ctpop.i32(i32 %3576)
  %3578 = trunc i32 %3577 to i8
  %3579 = and i8 %3578, 1
  %3580 = xor i8 %3579, 1
  store i8 %3580, i8* %18, align 1
  %3581 = xor i32 %3573, %3572
  %3582 = lshr i32 %3581, 4
  %3583 = trunc i32 %3582 to i8
  %3584 = and i8 %3583, 1
  store i8 %3584, i8* %19, align 1
  %3585 = icmp eq i32 %3573, 0
  %3586 = zext i1 %3585 to i8
  store i8 %3586, i8* %20, align 1
  %3587 = lshr i32 %3573, 31
  %3588 = trunc i32 %3587 to i8
  store i8 %3588, i8* %21, align 1
  %3589 = lshr i32 %3572, 31
  %3590 = xor i32 %3587, %3589
  %3591 = add nuw nsw i32 %3590, %3589
  %3592 = icmp eq i32 %3591, 2
  %3593 = zext i1 %3592 to i8
  store i8 %3593, i8* %22, align 1
  %3594 = icmp ne i8 %3588, 0
  %3595 = xor i1 %3594, %3592
  %.v693 = select i1 %3595, i64 10, i64 557
  %3596 = add i64 %3567, %.v693
  store i64 %3596, i64* %3, align 8
  br i1 %3595, label %block_484303, label %block_.L_484526

block_484303:                                     ; preds = %block_.L_4842f9
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX.i1659, align 8
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RCX.i1588, align 8
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RDX.i1943, align 8
  %3597 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %3597, i64* %RSI.i2015, align 8
  %3598 = add i64 %3596, 41
  store i64 %3598, i64* %3, align 8
  %3599 = inttoptr i64 %3597 to i64*
  %3600 = load i64, i64* %3599, align 8
  store i64 %3600, i64* %RSI.i2015, align 8
  %3601 = add i64 %3568, -240
  %3602 = add i64 %3596, 47
  store i64 %3602, i64* %3, align 8
  %3603 = inttoptr i64 %3601 to i32*
  %3604 = load i32, i32* %3603, align 4
  %3605 = zext i32 %3604 to i64
  store i64 %3605, i64* %RDI.i6998, align 8
  %3606 = add i64 %3568, -48
  %3607 = add i64 %3596, 50
  store i64 %3607, i64* %3, align 8
  %3608 = inttoptr i64 %3606 to i32*
  %3609 = load i32, i32* %3608, align 4
  %3610 = add i32 %3609, %3604
  %3611 = zext i32 %3610 to i64
  store i64 %3611, i64* %RDI.i6998, align 8
  %3612 = icmp ult i32 %3610, %3604
  %3613 = icmp ult i32 %3610, %3609
  %3614 = or i1 %3612, %3613
  %3615 = zext i1 %3614 to i8
  store i8 %3615, i8* %17, align 1
  %3616 = and i32 %3610, 255
  %3617 = tail call i32 @llvm.ctpop.i32(i32 %3616)
  %3618 = trunc i32 %3617 to i8
  %3619 = and i8 %3618, 1
  %3620 = xor i8 %3619, 1
  store i8 %3620, i8* %18, align 1
  %3621 = xor i32 %3609, %3604
  %3622 = xor i32 %3621, %3610
  %3623 = lshr i32 %3622, 4
  %3624 = trunc i32 %3623 to i8
  %3625 = and i8 %3624, 1
  store i8 %3625, i8* %19, align 1
  %3626 = icmp eq i32 %3610, 0
  %3627 = zext i1 %3626 to i8
  store i8 %3627, i8* %20, align 1
  %3628 = lshr i32 %3610, 31
  %3629 = trunc i32 %3628 to i8
  store i8 %3629, i8* %21, align 1
  %3630 = lshr i32 %3604, 31
  %3631 = lshr i32 %3609, 31
  %3632 = xor i32 %3628, %3630
  %3633 = xor i32 %3628, %3631
  %3634 = add nuw nsw i32 %3632, %3633
  %3635 = icmp eq i32 %3634, 2
  %3636 = zext i1 %3635 to i8
  store i8 %3636, i8* %22, align 1
  %3637 = sext i32 %3610 to i64
  store i64 %3637, i64* %25, align 8
  %3638 = shl nsw i64 %3637, 3
  %3639 = add i64 %3600, %3638
  %3640 = add i64 %3596, 57
  store i64 %3640, i64* %3, align 8
  %3641 = inttoptr i64 %3639 to i64*
  %3642 = load i64, i64* %3641, align 8
  store i64 %3642, i64* %RSI.i2015, align 8
  %3643 = add i64 %3568, -236
  %3644 = add i64 %3596, 63
  store i64 %3644, i64* %3, align 8
  %3645 = inttoptr i64 %3643 to i32*
  %3646 = load i32, i32* %3645, align 4
  %3647 = zext i32 %3646 to i64
  store i64 %3647, i64* %RDI.i6998, align 8
  %3648 = add i64 %3596, 66
  store i64 %3648, i64* %3, align 8
  %3649 = load i32, i32* %3571, align 4
  %3650 = add i32 %3649, %3646
  %3651 = zext i32 %3650 to i64
  store i64 %3651, i64* %RDI.i6998, align 8
  %3652 = icmp ult i32 %3650, %3646
  %3653 = icmp ult i32 %3650, %3649
  %3654 = or i1 %3652, %3653
  %3655 = zext i1 %3654 to i8
  store i8 %3655, i8* %17, align 1
  %3656 = and i32 %3650, 255
  %3657 = tail call i32 @llvm.ctpop.i32(i32 %3656)
  %3658 = trunc i32 %3657 to i8
  %3659 = and i8 %3658, 1
  %3660 = xor i8 %3659, 1
  store i8 %3660, i8* %18, align 1
  %3661 = xor i32 %3649, %3646
  %3662 = xor i32 %3661, %3650
  %3663 = lshr i32 %3662, 4
  %3664 = trunc i32 %3663 to i8
  %3665 = and i8 %3664, 1
  store i8 %3665, i8* %19, align 1
  %3666 = icmp eq i32 %3650, 0
  %3667 = zext i1 %3666 to i8
  store i8 %3667, i8* %20, align 1
  %3668 = lshr i32 %3650, 31
  %3669 = trunc i32 %3668 to i8
  store i8 %3669, i8* %21, align 1
  %3670 = lshr i32 %3646, 31
  %3671 = lshr i32 %3649, 31
  %3672 = xor i32 %3668, %3670
  %3673 = xor i32 %3668, %3671
  %3674 = add nuw nsw i32 %3672, %3673
  %3675 = icmp eq i32 %3674, 2
  %3676 = zext i1 %3675 to i8
  store i8 %3676, i8* %22, align 1
  %3677 = sext i32 %3650 to i64
  store i64 %3677, i64* %25, align 8
  %3678 = shl nsw i64 %3677, 1
  %3679 = add i64 %3642, %3678
  %3680 = add i64 %3596, 74
  store i64 %3680, i64* %3, align 8
  %3681 = inttoptr i64 %3679 to i16*
  %3682 = load i16, i16* %3681, align 2
  %3683 = zext i16 %3682 to i64
  store i64 %3683, i64* %RDI.i6998, align 8
  %3684 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %3685 = add i64 %3684, 8504
  store i64 %3685, i64* %RSI.i2015, align 8
  %3686 = icmp ugt i64 %3684, -8505
  %3687 = zext i1 %3686 to i8
  store i8 %3687, i8* %17, align 1
  %3688 = trunc i64 %3685 to i32
  %3689 = and i32 %3688, 255
  %3690 = tail call i32 @llvm.ctpop.i32(i32 %3689)
  %3691 = trunc i32 %3690 to i8
  %3692 = and i8 %3691, 1
  %3693 = xor i8 %3692, 1
  store i8 %3693, i8* %18, align 1
  %3694 = xor i64 %3684, 16
  %3695 = xor i64 %3694, %3685
  %3696 = lshr i64 %3695, 4
  %3697 = trunc i64 %3696 to i8
  %3698 = and i8 %3697, 1
  store i8 %3698, i8* %19, align 1
  %3699 = icmp eq i64 %3685, 0
  %3700 = zext i1 %3699 to i8
  store i8 %3700, i8* %20, align 1
  %3701 = lshr i64 %3685, 63
  %3702 = trunc i64 %3701 to i8
  store i8 %3702, i8* %21, align 1
  %3703 = lshr i64 %3684, 63
  %3704 = xor i64 %3701, %3703
  %3705 = add nuw nsw i64 %3704, %3701
  %3706 = icmp eq i64 %3705, 2
  %3707 = zext i1 %3706 to i8
  store i8 %3707, i8* %22, align 1
  %3708 = load i64, i64* %RBP.i, align 8
  %3709 = add i64 %3708, -364
  %3710 = add i64 %3596, 96
  store i64 %3710, i64* %3, align 8
  %3711 = inttoptr i64 %3709 to i32*
  %3712 = load i32, i32* %3711, align 4
  %3713 = sext i32 %3712 to i64
  %3714 = shl nsw i64 %3713, 9
  store i64 %3714, i64* %25, align 8
  %3715 = add i64 %3714, %3685
  store i64 %3715, i64* %RSI.i2015, align 8
  %3716 = icmp ult i64 %3715, %3685
  %3717 = icmp ult i64 %3715, %3714
  %3718 = or i1 %3716, %3717
  %3719 = zext i1 %3718 to i8
  store i8 %3719, i8* %17, align 1
  %3720 = trunc i64 %3715 to i32
  %3721 = and i32 %3720, 255
  %3722 = tail call i32 @llvm.ctpop.i32(i32 %3721)
  %3723 = trunc i32 %3722 to i8
  %3724 = and i8 %3723, 1
  %3725 = xor i8 %3724, 1
  store i8 %3725, i8* %18, align 1
  %3726 = xor i64 %3685, %3715
  %3727 = lshr i64 %3726, 4
  %3728 = trunc i64 %3727 to i8
  %3729 = and i8 %3728, 1
  store i8 %3729, i8* %19, align 1
  %3730 = icmp eq i64 %3715, 0
  %3731 = zext i1 %3730 to i8
  store i8 %3731, i8* %20, align 1
  %3732 = lshr i64 %3715, 63
  %3733 = trunc i64 %3732 to i8
  store i8 %3733, i8* %21, align 1
  %3734 = lshr i64 %3713, 54
  %3735 = and i64 %3734, 1
  %3736 = xor i64 %3732, %3701
  %3737 = xor i64 %3732, %3735
  %3738 = add nuw nsw i64 %3736, %3737
  %3739 = icmp eq i64 %3738, 2
  %3740 = zext i1 %3739 to i8
  store i8 %3740, i8* %22, align 1
  %3741 = add i64 %3708, -220
  %3742 = add i64 %3596, 110
  store i64 %3742, i64* %3, align 8
  %3743 = inttoptr i64 %3741 to i32*
  %3744 = load i32, i32* %3743, align 4
  %3745 = zext i32 %3744 to i64
  store i64 %3745, i64* %R9.i1633, align 8
  %3746 = add i64 %3708, -44
  %3747 = add i64 %3596, 114
  store i64 %3747, i64* %3, align 8
  %3748 = inttoptr i64 %3746 to i32*
  %3749 = load i32, i32* %3748, align 4
  %3750 = add i32 %3749, %3744
  %3751 = zext i32 %3750 to i64
  store i64 %3751, i64* %R9.i1633, align 8
  %3752 = sext i32 %3750 to i64
  %3753 = shl nsw i64 %3752, 5
  store i64 %3753, i64* %25, align 8
  %3754 = load i64, i64* %RSI.i2015, align 8
  %3755 = add i64 %3753, %3754
  store i64 %3755, i64* %RSI.i2015, align 8
  %3756 = icmp ult i64 %3755, %3754
  %3757 = icmp ult i64 %3755, %3753
  %3758 = or i1 %3756, %3757
  %3759 = zext i1 %3758 to i8
  store i8 %3759, i8* %17, align 1
  %3760 = trunc i64 %3755 to i32
  %3761 = and i32 %3760, 255
  %3762 = tail call i32 @llvm.ctpop.i32(i32 %3761)
  %3763 = trunc i32 %3762 to i8
  %3764 = and i8 %3763, 1
  %3765 = xor i8 %3764, 1
  store i8 %3765, i8* %18, align 1
  %3766 = xor i64 %3754, %3755
  %3767 = lshr i64 %3766, 4
  %3768 = trunc i64 %3767 to i8
  %3769 = and i8 %3768, 1
  store i8 %3769, i8* %19, align 1
  %3770 = icmp eq i64 %3755, 0
  %3771 = zext i1 %3770 to i8
  store i8 %3771, i8* %20, align 1
  %3772 = lshr i64 %3755, 63
  %3773 = trunc i64 %3772 to i8
  store i8 %3773, i8* %21, align 1
  %3774 = lshr i64 %3754, 63
  %3775 = lshr i64 %3752, 58
  %3776 = and i64 %3775, 1
  %3777 = xor i64 %3772, %3774
  %3778 = xor i64 %3772, %3776
  %3779 = add nuw nsw i64 %3777, %3778
  %3780 = icmp eq i64 %3779, 2
  %3781 = zext i1 %3780 to i8
  store i8 %3781, i8* %22, align 1
  %3782 = load i64, i64* %RBP.i, align 8
  %3783 = add i64 %3782, -224
  %3784 = add i64 %3596, 131
  store i64 %3784, i64* %3, align 8
  %3785 = inttoptr i64 %3783 to i32*
  %3786 = load i32, i32* %3785, align 4
  %3787 = zext i32 %3786 to i64
  store i64 %3787, i64* %R9.i1633, align 8
  %3788 = add i64 %3782, -48
  %3789 = add i64 %3596, 135
  store i64 %3789, i64* %3, align 8
  %3790 = inttoptr i64 %3788 to i32*
  %3791 = load i32, i32* %3790, align 4
  %3792 = add i32 %3791, %3786
  %3793 = zext i32 %3792 to i64
  store i64 %3793, i64* %R9.i1633, align 8
  %3794 = icmp ult i32 %3792, %3786
  %3795 = icmp ult i32 %3792, %3791
  %3796 = or i1 %3794, %3795
  %3797 = zext i1 %3796 to i8
  store i8 %3797, i8* %17, align 1
  %3798 = and i32 %3792, 255
  %3799 = tail call i32 @llvm.ctpop.i32(i32 %3798)
  %3800 = trunc i32 %3799 to i8
  %3801 = and i8 %3800, 1
  %3802 = xor i8 %3801, 1
  store i8 %3802, i8* %18, align 1
  %3803 = xor i32 %3791, %3786
  %3804 = xor i32 %3803, %3792
  %3805 = lshr i32 %3804, 4
  %3806 = trunc i32 %3805 to i8
  %3807 = and i8 %3806, 1
  store i8 %3807, i8* %19, align 1
  %3808 = icmp eq i32 %3792, 0
  %3809 = zext i1 %3808 to i8
  store i8 %3809, i8* %20, align 1
  %3810 = lshr i32 %3792, 31
  %3811 = trunc i32 %3810 to i8
  store i8 %3811, i8* %21, align 1
  %3812 = lshr i32 %3786, 31
  %3813 = lshr i32 %3791, 31
  %3814 = xor i32 %3810, %3812
  %3815 = xor i32 %3810, %3813
  %3816 = add nuw nsw i32 %3814, %3815
  %3817 = icmp eq i32 %3816, 2
  %3818 = zext i1 %3817 to i8
  store i8 %3818, i8* %22, align 1
  %3819 = sext i32 %3792 to i64
  store i64 %3819, i64* %25, align 8
  %3820 = shl nsw i64 %3819, 1
  %3821 = add i64 %3755, %3820
  %3822 = add i64 %3596, 143
  store i64 %3822, i64* %3, align 8
  %3823 = inttoptr i64 %3821 to i16*
  %3824 = load i16, i16* %3823, align 2
  %3825 = zext i16 %3824 to i64
  store i64 %3825, i64* %R9.i1633, align 8
  %3826 = load i64, i64* %RDI.i6998, align 8
  %3827 = zext i16 %3824 to i32
  %3828 = zext i16 %3824 to i64
  %3829 = trunc i64 %3826 to i32
  %3830 = sub i32 %3829, %3827
  %3831 = zext i32 %3830 to i64
  store i64 %3831, i64* %RDI.i6998, align 8
  %3832 = icmp ult i32 %3829, %3827
  %3833 = zext i1 %3832 to i8
  store i8 %3833, i8* %17, align 1
  %3834 = and i32 %3830, 255
  %3835 = tail call i32 @llvm.ctpop.i32(i32 %3834)
  %3836 = trunc i32 %3835 to i8
  %3837 = and i8 %3836, 1
  %3838 = xor i8 %3837, 1
  store i8 %3838, i8* %18, align 1
  %3839 = xor i64 %3828, %3826
  %3840 = trunc i64 %3839 to i32
  %3841 = xor i32 %3840, %3830
  %3842 = lshr i32 %3841, 4
  %3843 = trunc i32 %3842 to i8
  %3844 = and i8 %3843, 1
  store i8 %3844, i8* %19, align 1
  %3845 = icmp eq i32 %3830, 0
  %3846 = zext i1 %3845 to i8
  store i8 %3846, i8* %20, align 1
  %3847 = lshr i32 %3830, 31
  %3848 = trunc i32 %3847 to i8
  store i8 %3848, i8* %21, align 1
  %3849 = lshr i32 %3829, 31
  %3850 = xor i32 %3847, %3849
  %3851 = add nuw nsw i32 %3850, %3849
  %3852 = icmp eq i32 %3851, 2
  %3853 = zext i1 %3852 to i8
  store i8 %3853, i8* %22, align 1
  %3854 = add i64 %3782, -348
  %3855 = add i64 %3596, 152
  store i64 %3855, i64* %3, align 8
  %3856 = inttoptr i64 %3854 to i32*
  store i32 %3830, i32* %3856, align 4
  %3857 = load i64, i64* %3, align 8
  %3858 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %3858, i64* %RSI.i2015, align 8
  %3859 = load i64, i64* %RBP.i, align 8
  %3860 = add i64 %3859, -240
  %3861 = add i64 %3857, 14
  store i64 %3861, i64* %3, align 8
  %3862 = inttoptr i64 %3860 to i32*
  %3863 = load i32, i32* %3862, align 4
  %3864 = zext i32 %3863 to i64
  store i64 %3864, i64* %RDI.i6998, align 8
  %3865 = add i64 %3859, -48
  %3866 = add i64 %3857, 17
  store i64 %3866, i64* %3, align 8
  %3867 = inttoptr i64 %3865 to i32*
  %3868 = load i32, i32* %3867, align 4
  %3869 = add i32 %3868, %3863
  %3870 = zext i32 %3869 to i64
  store i64 %3870, i64* %RDI.i6998, align 8
  %3871 = icmp ult i32 %3869, %3863
  %3872 = icmp ult i32 %3869, %3868
  %3873 = or i1 %3871, %3872
  %3874 = zext i1 %3873 to i8
  store i8 %3874, i8* %17, align 1
  %3875 = and i32 %3869, 255
  %3876 = tail call i32 @llvm.ctpop.i32(i32 %3875)
  %3877 = trunc i32 %3876 to i8
  %3878 = and i8 %3877, 1
  %3879 = xor i8 %3878, 1
  store i8 %3879, i8* %18, align 1
  %3880 = xor i32 %3868, %3863
  %3881 = xor i32 %3880, %3869
  %3882 = lshr i32 %3881, 4
  %3883 = trunc i32 %3882 to i8
  %3884 = and i8 %3883, 1
  store i8 %3884, i8* %19, align 1
  %3885 = icmp eq i32 %3869, 0
  %3886 = zext i1 %3885 to i8
  store i8 %3886, i8* %20, align 1
  %3887 = lshr i32 %3869, 31
  %3888 = trunc i32 %3887 to i8
  store i8 %3888, i8* %21, align 1
  %3889 = lshr i32 %3863, 31
  %3890 = lshr i32 %3868, 31
  %3891 = xor i32 %3887, %3889
  %3892 = xor i32 %3887, %3890
  %3893 = add nuw nsw i32 %3891, %3892
  %3894 = icmp eq i32 %3893, 2
  %3895 = zext i1 %3894 to i8
  store i8 %3895, i8* %22, align 1
  %3896 = sext i32 %3869 to i64
  store i64 %3896, i64* %25, align 8
  %3897 = shl nsw i64 %3896, 3
  %3898 = add i64 %3858, %3897
  %3899 = add i64 %3857, 24
  store i64 %3899, i64* %3, align 8
  %3900 = inttoptr i64 %3898 to i64*
  %3901 = load i64, i64* %3900, align 8
  store i64 %3901, i64* %RSI.i2015, align 8
  %3902 = add i64 %3859, -236
  %3903 = add i64 %3857, 30
  store i64 %3903, i64* %3, align 8
  %3904 = inttoptr i64 %3902 to i32*
  %3905 = load i32, i32* %3904, align 4
  %3906 = zext i32 %3905 to i64
  store i64 %3906, i64* %RDI.i6998, align 8
  %3907 = add i64 %3859, -44
  %3908 = add i64 %3857, 33
  store i64 %3908, i64* %3, align 8
  %3909 = inttoptr i64 %3907 to i32*
  %3910 = load i32, i32* %3909, align 4
  %3911 = add i32 %3910, %3905
  %3912 = zext i32 %3911 to i64
  store i64 %3912, i64* %RDI.i6998, align 8
  %3913 = icmp ult i32 %3911, %3905
  %3914 = icmp ult i32 %3911, %3910
  %3915 = or i1 %3913, %3914
  %3916 = zext i1 %3915 to i8
  store i8 %3916, i8* %17, align 1
  %3917 = and i32 %3911, 255
  %3918 = tail call i32 @llvm.ctpop.i32(i32 %3917)
  %3919 = trunc i32 %3918 to i8
  %3920 = and i8 %3919, 1
  %3921 = xor i8 %3920, 1
  store i8 %3921, i8* %18, align 1
  %3922 = xor i32 %3910, %3905
  %3923 = xor i32 %3922, %3911
  %3924 = lshr i32 %3923, 4
  %3925 = trunc i32 %3924 to i8
  %3926 = and i8 %3925, 1
  store i8 %3926, i8* %19, align 1
  %3927 = icmp eq i32 %3911, 0
  %3928 = zext i1 %3927 to i8
  store i8 %3928, i8* %20, align 1
  %3929 = lshr i32 %3911, 31
  %3930 = trunc i32 %3929 to i8
  store i8 %3930, i8* %21, align 1
  %3931 = lshr i32 %3905, 31
  %3932 = lshr i32 %3910, 31
  %3933 = xor i32 %3929, %3931
  %3934 = xor i32 %3929, %3932
  %3935 = add nuw nsw i32 %3933, %3934
  %3936 = icmp eq i32 %3935, 2
  %3937 = zext i1 %3936 to i8
  store i8 %3937, i8* %22, align 1
  %3938 = sext i32 %3911 to i64
  store i64 %3938, i64* %25, align 8
  %3939 = shl nsw i64 %3938, 1
  %3940 = add i64 %3901, %3939
  %3941 = add i64 %3857, 41
  store i64 %3941, i64* %3, align 8
  %3942 = inttoptr i64 %3940 to i16*
  %3943 = load i16, i16* %3942, align 2
  %3944 = zext i16 %3943 to i64
  store i64 %3944, i64* %RDI.i6998, align 8
  %3945 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %3946 = add i64 %3945, 184
  store i64 %3946, i64* %RSI.i2015, align 8
  %3947 = icmp ugt i64 %3945, -185
  %3948 = zext i1 %3947 to i8
  store i8 %3948, i8* %17, align 1
  %3949 = trunc i64 %3946 to i32
  %3950 = and i32 %3949, 255
  %3951 = tail call i32 @llvm.ctpop.i32(i32 %3950)
  %3952 = trunc i32 %3951 to i8
  %3953 = and i8 %3952, 1
  %3954 = xor i8 %3953, 1
  store i8 %3954, i8* %18, align 1
  %3955 = xor i64 %3945, 16
  %3956 = xor i64 %3955, %3946
  %3957 = lshr i64 %3956, 4
  %3958 = trunc i64 %3957 to i8
  %3959 = and i8 %3958, 1
  store i8 %3959, i8* %19, align 1
  %3960 = icmp eq i64 %3946, 0
  %3961 = zext i1 %3960 to i8
  store i8 %3961, i8* %20, align 1
  %3962 = lshr i64 %3946, 63
  %3963 = trunc i64 %3962 to i8
  store i8 %3963, i8* %21, align 1
  %3964 = lshr i64 %3945, 63
  %3965 = xor i64 %3962, %3964
  %3966 = add nuw nsw i64 %3965, %3962
  %3967 = icmp eq i64 %3966, 2
  %3968 = zext i1 %3967 to i8
  store i8 %3968, i8* %22, align 1
  %3969 = load i64, i64* %RBP.i, align 8
  %3970 = add i64 %3969, -36
  %3971 = add i64 %3857, 60
  store i64 %3971, i64* %3, align 8
  %3972 = inttoptr i64 %3970 to i32*
  %3973 = load i32, i32* %3972, align 4
  %3974 = sext i32 %3973 to i64
  %3975 = shl nsw i64 %3974, 9
  store i64 %3975, i64* %25, align 8
  %3976 = add i64 %3975, %3946
  store i64 %3976, i64* %RSI.i2015, align 8
  %3977 = icmp ult i64 %3976, %3946
  %3978 = icmp ult i64 %3976, %3975
  %3979 = or i1 %3977, %3978
  %3980 = zext i1 %3979 to i8
  store i8 %3980, i8* %17, align 1
  %3981 = trunc i64 %3976 to i32
  %3982 = and i32 %3981, 255
  %3983 = tail call i32 @llvm.ctpop.i32(i32 %3982)
  %3984 = trunc i32 %3983 to i8
  %3985 = and i8 %3984, 1
  %3986 = xor i8 %3985, 1
  store i8 %3986, i8* %18, align 1
  %3987 = xor i64 %3946, %3976
  %3988 = lshr i64 %3987, 4
  %3989 = trunc i64 %3988 to i8
  %3990 = and i8 %3989, 1
  store i8 %3990, i8* %19, align 1
  %3991 = icmp eq i64 %3976, 0
  %3992 = zext i1 %3991 to i8
  store i8 %3992, i8* %20, align 1
  %3993 = lshr i64 %3976, 63
  %3994 = trunc i64 %3993 to i8
  store i8 %3994, i8* %21, align 1
  %3995 = lshr i64 %3974, 54
  %3996 = and i64 %3995, 1
  %3997 = xor i64 %3993, %3962
  %3998 = xor i64 %3993, %3996
  %3999 = add nuw nsw i64 %3997, %3998
  %4000 = icmp eq i64 %3999, 2
  %4001 = zext i1 %4000 to i8
  store i8 %4001, i8* %22, align 1
  %4002 = add i64 %3969, -48
  %4003 = add i64 %3857, 71
  store i64 %4003, i64* %3, align 8
  %4004 = inttoptr i64 %4002 to i32*
  %4005 = load i32, i32* %4004, align 4
  %4006 = sext i32 %4005 to i64
  %4007 = shl nsw i64 %4006, 5
  store i64 %4007, i64* %25, align 8
  %4008 = add i64 %4007, %3976
  store i64 %4008, i64* %RSI.i2015, align 8
  %4009 = icmp ult i64 %4008, %3976
  %4010 = icmp ult i64 %4008, %4007
  %4011 = or i1 %4009, %4010
  %4012 = zext i1 %4011 to i8
  store i8 %4012, i8* %17, align 1
  %4013 = trunc i64 %4008 to i32
  %4014 = and i32 %4013, 255
  %4015 = tail call i32 @llvm.ctpop.i32(i32 %4014)
  %4016 = trunc i32 %4015 to i8
  %4017 = and i8 %4016, 1
  %4018 = xor i8 %4017, 1
  store i8 %4018, i8* %18, align 1
  %4019 = xor i64 %3976, %4008
  %4020 = lshr i64 %4019, 4
  %4021 = trunc i64 %4020 to i8
  %4022 = and i8 %4021, 1
  store i8 %4022, i8* %19, align 1
  %4023 = icmp eq i64 %4008, 0
  %4024 = zext i1 %4023 to i8
  store i8 %4024, i8* %20, align 1
  %4025 = lshr i64 %4008, 63
  %4026 = trunc i64 %4025 to i8
  store i8 %4026, i8* %21, align 1
  %4027 = lshr i64 %4006, 58
  %4028 = and i64 %4027, 1
  %4029 = xor i64 %4025, %3993
  %4030 = xor i64 %4025, %4028
  %4031 = add nuw nsw i64 %4029, %4030
  %4032 = icmp eq i64 %4031, 2
  %4033 = zext i1 %4032 to i8
  store i8 %4033, i8* %22, align 1
  %4034 = load i64, i64* %RBP.i, align 8
  %4035 = add i64 %4034, -44
  %4036 = add i64 %3857, 82
  store i64 %4036, i64* %3, align 8
  %4037 = inttoptr i64 %4035 to i32*
  %4038 = load i32, i32* %4037, align 4
  %4039 = sext i32 %4038 to i64
  store i64 %4039, i64* %25, align 8
  %4040 = shl nsw i64 %4039, 1
  %4041 = add i64 %4040, %4008
  %4042 = add i64 %3857, 87
  store i64 %4042, i64* %3, align 8
  %4043 = inttoptr i64 %4041 to i16*
  %4044 = load i16, i16* %4043, align 2
  %4045 = zext i16 %4044 to i64
  store i64 %4045, i64* %R9.i1633, align 8
  %4046 = load i64, i64* %RDI.i6998, align 8
  %4047 = zext i16 %4044 to i32
  %4048 = zext i16 %4044 to i64
  %4049 = trunc i64 %4046 to i32
  %4050 = sub i32 %4049, %4047
  %4051 = zext i32 %4050 to i64
  store i64 %4051, i64* %RDI.i6998, align 8
  %4052 = icmp ult i32 %4049, %4047
  %4053 = zext i1 %4052 to i8
  store i8 %4053, i8* %17, align 1
  %4054 = and i32 %4050, 255
  %4055 = tail call i32 @llvm.ctpop.i32(i32 %4054)
  %4056 = trunc i32 %4055 to i8
  %4057 = and i8 %4056, 1
  %4058 = xor i8 %4057, 1
  store i8 %4058, i8* %18, align 1
  %4059 = xor i64 %4048, %4046
  %4060 = trunc i64 %4059 to i32
  %4061 = xor i32 %4060, %4050
  %4062 = lshr i32 %4061, 4
  %4063 = trunc i32 %4062 to i8
  %4064 = and i8 %4063, 1
  store i8 %4064, i8* %19, align 1
  %4065 = icmp eq i32 %4050, 0
  %4066 = zext i1 %4065 to i8
  store i8 %4066, i8* %20, align 1
  %4067 = lshr i32 %4050, 31
  %4068 = trunc i32 %4067 to i8
  store i8 %4068, i8* %21, align 1
  %4069 = lshr i32 %4049, 31
  %4070 = xor i32 %4067, %4069
  %4071 = add nuw nsw i32 %4070, %4069
  %4072 = icmp eq i32 %4071, 2
  %4073 = zext i1 %4072 to i8
  store i8 %4073, i8* %22, align 1
  %4074 = add i64 %4034, -344
  %4075 = add i64 %3857, 96
  store i64 %4075, i64* %3, align 8
  %4076 = inttoptr i64 %4074 to i32*
  store i32 %4050, i32* %4076, align 4
  %4077 = load i64, i64* %3, align 8
  %4078 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %4078, i64* %RSI.i2015, align 8
  %4079 = add i64 %4078, 8
  %4080 = add i64 %4077, 12
  store i64 %4080, i64* %3, align 8
  %4081 = inttoptr i64 %4079 to i64*
  %4082 = load i64, i64* %4081, align 8
  store i64 %4082, i64* %RSI.i2015, align 8
  %4083 = load i64, i64* %RBP.i, align 8
  %4084 = add i64 %4083, -240
  %4085 = add i64 %4077, 18
  store i64 %4085, i64* %3, align 8
  %4086 = inttoptr i64 %4084 to i32*
  %4087 = load i32, i32* %4086, align 4
  %4088 = zext i32 %4087 to i64
  store i64 %4088, i64* %RDI.i6998, align 8
  %4089 = add i64 %4083, -48
  %4090 = add i64 %4077, 21
  store i64 %4090, i64* %3, align 8
  %4091 = inttoptr i64 %4089 to i32*
  %4092 = load i32, i32* %4091, align 4
  %4093 = add i32 %4092, %4087
  %4094 = zext i32 %4093 to i64
  store i64 %4094, i64* %RDI.i6998, align 8
  %4095 = icmp ult i32 %4093, %4087
  %4096 = icmp ult i32 %4093, %4092
  %4097 = or i1 %4095, %4096
  %4098 = zext i1 %4097 to i8
  store i8 %4098, i8* %17, align 1
  %4099 = and i32 %4093, 255
  %4100 = tail call i32 @llvm.ctpop.i32(i32 %4099)
  %4101 = trunc i32 %4100 to i8
  %4102 = and i8 %4101, 1
  %4103 = xor i8 %4102, 1
  store i8 %4103, i8* %18, align 1
  %4104 = xor i32 %4092, %4087
  %4105 = xor i32 %4104, %4093
  %4106 = lshr i32 %4105, 4
  %4107 = trunc i32 %4106 to i8
  %4108 = and i8 %4107, 1
  store i8 %4108, i8* %19, align 1
  %4109 = icmp eq i32 %4093, 0
  %4110 = zext i1 %4109 to i8
  store i8 %4110, i8* %20, align 1
  %4111 = lshr i32 %4093, 31
  %4112 = trunc i32 %4111 to i8
  store i8 %4112, i8* %21, align 1
  %4113 = lshr i32 %4087, 31
  %4114 = lshr i32 %4092, 31
  %4115 = xor i32 %4111, %4113
  %4116 = xor i32 %4111, %4114
  %4117 = add nuw nsw i32 %4115, %4116
  %4118 = icmp eq i32 %4117, 2
  %4119 = zext i1 %4118 to i8
  store i8 %4119, i8* %22, align 1
  %4120 = sext i32 %4093 to i64
  store i64 %4120, i64* %25, align 8
  %4121 = shl nsw i64 %4120, 3
  %4122 = add i64 %4082, %4121
  %4123 = add i64 %4077, 28
  store i64 %4123, i64* %3, align 8
  %4124 = inttoptr i64 %4122 to i64*
  %4125 = load i64, i64* %4124, align 8
  store i64 %4125, i64* %RSI.i2015, align 8
  %4126 = add i64 %4083, -236
  %4127 = add i64 %4077, 34
  store i64 %4127, i64* %3, align 8
  %4128 = inttoptr i64 %4126 to i32*
  %4129 = load i32, i32* %4128, align 4
  %4130 = zext i32 %4129 to i64
  store i64 %4130, i64* %RDI.i6998, align 8
  %4131 = add i64 %4083, -44
  %4132 = add i64 %4077, 37
  store i64 %4132, i64* %3, align 8
  %4133 = inttoptr i64 %4131 to i32*
  %4134 = load i32, i32* %4133, align 4
  %4135 = add i32 %4134, %4129
  %4136 = zext i32 %4135 to i64
  store i64 %4136, i64* %RDI.i6998, align 8
  %4137 = icmp ult i32 %4135, %4129
  %4138 = icmp ult i32 %4135, %4134
  %4139 = or i1 %4137, %4138
  %4140 = zext i1 %4139 to i8
  store i8 %4140, i8* %17, align 1
  %4141 = and i32 %4135, 255
  %4142 = tail call i32 @llvm.ctpop.i32(i32 %4141)
  %4143 = trunc i32 %4142 to i8
  %4144 = and i8 %4143, 1
  %4145 = xor i8 %4144, 1
  store i8 %4145, i8* %18, align 1
  %4146 = xor i32 %4134, %4129
  %4147 = xor i32 %4146, %4135
  %4148 = lshr i32 %4147, 4
  %4149 = trunc i32 %4148 to i8
  %4150 = and i8 %4149, 1
  store i8 %4150, i8* %19, align 1
  %4151 = icmp eq i32 %4135, 0
  %4152 = zext i1 %4151 to i8
  store i8 %4152, i8* %20, align 1
  %4153 = lshr i32 %4135, 31
  %4154 = trunc i32 %4153 to i8
  store i8 %4154, i8* %21, align 1
  %4155 = lshr i32 %4129, 31
  %4156 = lshr i32 %4134, 31
  %4157 = xor i32 %4153, %4155
  %4158 = xor i32 %4153, %4156
  %4159 = add nuw nsw i32 %4157, %4158
  %4160 = icmp eq i32 %4159, 2
  %4161 = zext i1 %4160 to i8
  store i8 %4161, i8* %22, align 1
  %4162 = sext i32 %4135 to i64
  store i64 %4162, i64* %25, align 8
  %4163 = shl nsw i64 %4162, 1
  %4164 = add i64 %4125, %4163
  %4165 = add i64 %4077, 45
  store i64 %4165, i64* %3, align 8
  %4166 = inttoptr i64 %4164 to i16*
  %4167 = load i16, i16* %4166, align 2
  %4168 = zext i16 %4167 to i64
  store i64 %4168, i64* %RDI.i6998, align 8
  %4169 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4170 = add i64 %4169, 8504
  %4171 = lshr i64 %4170, 63
  %4172 = add i64 %4169, 10552
  store i64 %4172, i64* %RSI.i2015, align 8
  %4173 = icmp ugt i64 %4170, -2049
  %4174 = zext i1 %4173 to i8
  store i8 %4174, i8* %17, align 1
  %4175 = trunc i64 %4172 to i32
  %4176 = and i32 %4175, 255
  %4177 = tail call i32 @llvm.ctpop.i32(i32 %4176)
  %4178 = trunc i32 %4177 to i8
  %4179 = and i8 %4178, 1
  %4180 = xor i8 %4179, 1
  store i8 %4180, i8* %18, align 1
  %4181 = xor i64 %4172, %4170
  %4182 = lshr i64 %4181, 4
  %4183 = trunc i64 %4182 to i8
  %4184 = and i8 %4183, 1
  store i8 %4184, i8* %19, align 1
  %4185 = icmp eq i64 %4172, 0
  %4186 = zext i1 %4185 to i8
  store i8 %4186, i8* %20, align 1
  %4187 = lshr i64 %4172, 63
  %4188 = trunc i64 %4187 to i8
  store i8 %4188, i8* %21, align 1
  %4189 = xor i64 %4187, %4171
  %4190 = add nuw nsw i64 %4189, %4187
  %4191 = icmp eq i64 %4190, 2
  %4192 = zext i1 %4191 to i8
  store i8 %4192, i8* %22, align 1
  %4193 = load i64, i64* %RBP.i, align 8
  %4194 = add i64 %4193, -364
  %4195 = add i64 %4077, 74
  store i64 %4195, i64* %3, align 8
  %4196 = inttoptr i64 %4194 to i32*
  %4197 = load i32, i32* %4196, align 4
  %4198 = sext i32 %4197 to i64
  %4199 = shl nsw i64 %4198, 9
  store i64 %4199, i64* %25, align 8
  %4200 = add i64 %4199, %4172
  store i64 %4200, i64* %RSI.i2015, align 8
  %4201 = icmp ult i64 %4200, %4172
  %4202 = icmp ult i64 %4200, %4199
  %4203 = or i1 %4201, %4202
  %4204 = zext i1 %4203 to i8
  store i8 %4204, i8* %17, align 1
  %4205 = trunc i64 %4200 to i32
  %4206 = and i32 %4205, 255
  %4207 = tail call i32 @llvm.ctpop.i32(i32 %4206)
  %4208 = trunc i32 %4207 to i8
  %4209 = and i8 %4208, 1
  %4210 = xor i8 %4209, 1
  store i8 %4210, i8* %18, align 1
  %4211 = xor i64 %4172, %4200
  %4212 = lshr i64 %4211, 4
  %4213 = trunc i64 %4212 to i8
  %4214 = and i8 %4213, 1
  store i8 %4214, i8* %19, align 1
  %4215 = icmp eq i64 %4200, 0
  %4216 = zext i1 %4215 to i8
  store i8 %4216, i8* %20, align 1
  %4217 = lshr i64 %4200, 63
  %4218 = trunc i64 %4217 to i8
  store i8 %4218, i8* %21, align 1
  %4219 = lshr i64 %4198, 54
  %4220 = and i64 %4219, 1
  %4221 = xor i64 %4217, %4187
  %4222 = xor i64 %4217, %4220
  %4223 = add nuw nsw i64 %4221, %4222
  %4224 = icmp eq i64 %4223, 2
  %4225 = zext i1 %4224 to i8
  store i8 %4225, i8* %22, align 1
  %4226 = add i64 %4193, -220
  %4227 = add i64 %4077, 88
  store i64 %4227, i64* %3, align 8
  %4228 = inttoptr i64 %4226 to i32*
  %4229 = load i32, i32* %4228, align 4
  %4230 = zext i32 %4229 to i64
  store i64 %4230, i64* %R9.i1633, align 8
  %4231 = add i64 %4193, -44
  %4232 = add i64 %4077, 92
  store i64 %4232, i64* %3, align 8
  %4233 = inttoptr i64 %4231 to i32*
  %4234 = load i32, i32* %4233, align 4
  %4235 = add i32 %4234, %4229
  %4236 = zext i32 %4235 to i64
  store i64 %4236, i64* %R9.i1633, align 8
  %4237 = sext i32 %4235 to i64
  %4238 = shl nsw i64 %4237, 5
  store i64 %4238, i64* %25, align 8
  %4239 = load i64, i64* %RSI.i2015, align 8
  %4240 = add i64 %4238, %4239
  store i64 %4240, i64* %RSI.i2015, align 8
  %4241 = icmp ult i64 %4240, %4239
  %4242 = icmp ult i64 %4240, %4238
  %4243 = or i1 %4241, %4242
  %4244 = zext i1 %4243 to i8
  store i8 %4244, i8* %17, align 1
  %4245 = trunc i64 %4240 to i32
  %4246 = and i32 %4245, 255
  %4247 = tail call i32 @llvm.ctpop.i32(i32 %4246)
  %4248 = trunc i32 %4247 to i8
  %4249 = and i8 %4248, 1
  %4250 = xor i8 %4249, 1
  store i8 %4250, i8* %18, align 1
  %4251 = xor i64 %4239, %4240
  %4252 = lshr i64 %4251, 4
  %4253 = trunc i64 %4252 to i8
  %4254 = and i8 %4253, 1
  store i8 %4254, i8* %19, align 1
  %4255 = icmp eq i64 %4240, 0
  %4256 = zext i1 %4255 to i8
  store i8 %4256, i8* %20, align 1
  %4257 = lshr i64 %4240, 63
  %4258 = trunc i64 %4257 to i8
  store i8 %4258, i8* %21, align 1
  %4259 = lshr i64 %4239, 63
  %4260 = lshr i64 %4237, 58
  %4261 = and i64 %4260, 1
  %4262 = xor i64 %4257, %4259
  %4263 = xor i64 %4257, %4261
  %4264 = add nuw nsw i64 %4262, %4263
  %4265 = icmp eq i64 %4264, 2
  %4266 = zext i1 %4265 to i8
  store i8 %4266, i8* %22, align 1
  %4267 = load i64, i64* %RBP.i, align 8
  %4268 = add i64 %4267, -224
  %4269 = add i64 %4077, 109
  store i64 %4269, i64* %3, align 8
  %4270 = inttoptr i64 %4268 to i32*
  %4271 = load i32, i32* %4270, align 4
  %4272 = zext i32 %4271 to i64
  store i64 %4272, i64* %R9.i1633, align 8
  %4273 = add i64 %4267, -48
  %4274 = add i64 %4077, 113
  store i64 %4274, i64* %3, align 8
  %4275 = inttoptr i64 %4273 to i32*
  %4276 = load i32, i32* %4275, align 4
  %4277 = add i32 %4276, %4271
  %4278 = zext i32 %4277 to i64
  store i64 %4278, i64* %R9.i1633, align 8
  %4279 = icmp ult i32 %4277, %4271
  %4280 = icmp ult i32 %4277, %4276
  %4281 = or i1 %4279, %4280
  %4282 = zext i1 %4281 to i8
  store i8 %4282, i8* %17, align 1
  %4283 = and i32 %4277, 255
  %4284 = tail call i32 @llvm.ctpop.i32(i32 %4283)
  %4285 = trunc i32 %4284 to i8
  %4286 = and i8 %4285, 1
  %4287 = xor i8 %4286, 1
  store i8 %4287, i8* %18, align 1
  %4288 = xor i32 %4276, %4271
  %4289 = xor i32 %4288, %4277
  %4290 = lshr i32 %4289, 4
  %4291 = trunc i32 %4290 to i8
  %4292 = and i8 %4291, 1
  store i8 %4292, i8* %19, align 1
  %4293 = icmp eq i32 %4277, 0
  %4294 = zext i1 %4293 to i8
  store i8 %4294, i8* %20, align 1
  %4295 = lshr i32 %4277, 31
  %4296 = trunc i32 %4295 to i8
  store i8 %4296, i8* %21, align 1
  %4297 = lshr i32 %4271, 31
  %4298 = lshr i32 %4276, 31
  %4299 = xor i32 %4295, %4297
  %4300 = xor i32 %4295, %4298
  %4301 = add nuw nsw i32 %4299, %4300
  %4302 = icmp eq i32 %4301, 2
  %4303 = zext i1 %4302 to i8
  store i8 %4303, i8* %22, align 1
  %4304 = sext i32 %4277 to i64
  store i64 %4304, i64* %25, align 8
  %4305 = shl nsw i64 %4304, 1
  %4306 = add i64 %4240, %4305
  %4307 = add i64 %4077, 121
  store i64 %4307, i64* %3, align 8
  %4308 = inttoptr i64 %4306 to i16*
  %4309 = load i16, i16* %4308, align 2
  %4310 = zext i16 %4309 to i64
  store i64 %4310, i64* %R9.i1633, align 8
  %4311 = load i64, i64* %RDI.i6998, align 8
  %4312 = zext i16 %4309 to i32
  %4313 = zext i16 %4309 to i64
  %4314 = trunc i64 %4311 to i32
  %4315 = sub i32 %4314, %4312
  %4316 = zext i32 %4315 to i64
  store i64 %4316, i64* %RDI.i6998, align 8
  %4317 = icmp ult i32 %4314, %4312
  %4318 = zext i1 %4317 to i8
  store i8 %4318, i8* %17, align 1
  %4319 = and i32 %4315, 255
  %4320 = tail call i32 @llvm.ctpop.i32(i32 %4319)
  %4321 = trunc i32 %4320 to i8
  %4322 = and i8 %4321, 1
  %4323 = xor i8 %4322, 1
  store i8 %4323, i8* %18, align 1
  %4324 = xor i64 %4313, %4311
  %4325 = trunc i64 %4324 to i32
  %4326 = xor i32 %4325, %4315
  %4327 = lshr i32 %4326, 4
  %4328 = trunc i32 %4327 to i8
  %4329 = and i8 %4328, 1
  store i8 %4329, i8* %19, align 1
  %4330 = icmp eq i32 %4315, 0
  %4331 = zext i1 %4330 to i8
  store i8 %4331, i8* %20, align 1
  %4332 = lshr i32 %4315, 31
  %4333 = trunc i32 %4332 to i8
  store i8 %4333, i8* %21, align 1
  %4334 = lshr i32 %4314, 31
  %4335 = xor i32 %4332, %4334
  %4336 = add nuw nsw i32 %4335, %4334
  %4337 = icmp eq i32 %4336, 2
  %4338 = zext i1 %4337 to i8
  store i8 %4338, i8* %22, align 1
  %4339 = add i64 %4267, -340
  %4340 = add i64 %4077, 130
  store i64 %4340, i64* %3, align 8
  %4341 = inttoptr i64 %4339 to i32*
  store i32 %4315, i32* %4341, align 4
  %4342 = load i64, i64* %RBP.i, align 8
  %4343 = add i64 %4342, -340
  %4344 = load i64, i64* %3, align 8
  %4345 = add i64 %4344, 6
  store i64 %4345, i64* %3, align 8
  %4346 = inttoptr i64 %4343 to i32*
  %4347 = load i32, i32* %4346, align 4
  %4348 = zext i32 %4347 to i64
  store i64 %4348, i64* %RDI.i6998, align 8
  %4349 = add i64 %4342, -348
  %4350 = add i64 %4344, 12
  store i64 %4350, i64* %3, align 8
  %4351 = inttoptr i64 %4349 to i32*
  %4352 = load i32, i32* %4351, align 4
  %4353 = sub i32 %4347, %4352
  %4354 = zext i32 %4353 to i64
  store i64 %4354, i64* %RDI.i6998, align 8
  %4355 = icmp ult i32 %4347, %4352
  %4356 = zext i1 %4355 to i8
  store i8 %4356, i8* %17, align 1
  %4357 = and i32 %4353, 255
  %4358 = tail call i32 @llvm.ctpop.i32(i32 %4357)
  %4359 = trunc i32 %4358 to i8
  %4360 = and i8 %4359, 1
  %4361 = xor i8 %4360, 1
  store i8 %4361, i8* %18, align 1
  %4362 = xor i32 %4352, %4347
  %4363 = xor i32 %4362, %4353
  %4364 = lshr i32 %4363, 4
  %4365 = trunc i32 %4364 to i8
  %4366 = and i8 %4365, 1
  store i8 %4366, i8* %19, align 1
  %4367 = icmp eq i32 %4353, 0
  %4368 = zext i1 %4367 to i8
  store i8 %4368, i8* %20, align 1
  %4369 = lshr i32 %4353, 31
  %4370 = trunc i32 %4369 to i8
  store i8 %4370, i8* %21, align 1
  %4371 = lshr i32 %4347, 31
  %4372 = lshr i32 %4352, 31
  %4373 = xor i32 %4372, %4371
  %4374 = xor i32 %4369, %4371
  %4375 = add nuw nsw i32 %4374, %4373
  %4376 = icmp eq i32 %4375, 2
  %4377 = zext i1 %4376 to i8
  store i8 %4377, i8* %22, align 1
  %4378 = add i64 %4342, -44
  %4379 = add i64 %4344, 16
  store i64 %4379, i64* %3, align 8
  %4380 = inttoptr i64 %4378 to i32*
  %4381 = load i32, i32* %4380, align 4
  %4382 = sext i32 %4381 to i64
  %4383 = shl nsw i64 %4382, 6
  store i64 %4383, i64* %RSI.i2015, align 8
  %4384 = load i64, i64* %RDX.i1943, align 8
  %4385 = add i64 %4383, %4384
  store i64 %4385, i64* %25, align 8
  %4386 = icmp ult i64 %4385, %4384
  %4387 = icmp ult i64 %4385, %4383
  %4388 = or i1 %4386, %4387
  %4389 = zext i1 %4388 to i8
  store i8 %4389, i8* %17, align 1
  %4390 = trunc i64 %4385 to i32
  %4391 = and i32 %4390, 255
  %4392 = tail call i32 @llvm.ctpop.i32(i32 %4391)
  %4393 = trunc i32 %4392 to i8
  %4394 = and i8 %4393, 1
  %4395 = xor i8 %4394, 1
  store i8 %4395, i8* %18, align 1
  %4396 = xor i64 %4384, %4385
  %4397 = lshr i64 %4396, 4
  %4398 = trunc i64 %4397 to i8
  %4399 = and i8 %4398, 1
  store i8 %4399, i8* %19, align 1
  %4400 = icmp eq i64 %4385, 0
  %4401 = zext i1 %4400 to i8
  store i8 %4401, i8* %20, align 1
  %4402 = lshr i64 %4385, 63
  %4403 = trunc i64 %4402 to i8
  store i8 %4403, i8* %21, align 1
  %4404 = lshr i64 %4384, 63
  %4405 = lshr i64 %4382, 57
  %4406 = and i64 %4405, 1
  %4407 = xor i64 %4402, %4404
  %4408 = xor i64 %4402, %4406
  %4409 = add nuw nsw i64 %4407, %4408
  %4410 = icmp eq i64 %4409, 2
  %4411 = zext i1 %4410 to i8
  store i8 %4411, i8* %22, align 1
  %4412 = load i64, i64* %RBP.i, align 8
  %4413 = add i64 %4412, -48
  %4414 = add i64 %4344, 30
  store i64 %4414, i64* %3, align 8
  %4415 = inttoptr i64 %4413 to i32*
  %4416 = load i32, i32* %4415, align 4
  %4417 = sext i32 %4416 to i64
  store i64 %4417, i64* %RSI.i2015, align 8
  %4418 = shl nsw i64 %4417, 2
  %4419 = add i64 %4418, %4385
  %4420 = load i32, i32* %EDI.i1741, align 4
  %4421 = add i64 %4344, 34
  store i64 %4421, i64* %3, align 8
  %4422 = inttoptr i64 %4419 to i32*
  store i32 %4420, i32* %4422, align 4
  %4423 = load i64, i64* %RBP.i, align 8
  %4424 = add i64 %4423, -348
  %4425 = load i64, i64* %3, align 8
  %4426 = add i64 %4425, 6
  store i64 %4426, i64* %3, align 8
  %4427 = inttoptr i64 %4424 to i32*
  %4428 = load i32, i32* %4427, align 4
  %4429 = zext i32 %4428 to i64
  store i64 %4429, i64* %RDI.i6998, align 8
  %4430 = add i64 %4423, -44
  %4431 = add i64 %4425, 10
  store i64 %4431, i64* %3, align 8
  %4432 = inttoptr i64 %4430 to i32*
  %4433 = load i32, i32* %4432, align 4
  %4434 = sext i32 %4433 to i64
  %4435 = shl nsw i64 %4434, 6
  store i64 %4435, i64* %RSI.i2015, align 8
  %4436 = load i64, i64* %RDX.i1943, align 8
  %4437 = add i64 %4435, %4436
  store i64 %4437, i64* %RDX.i1943, align 8
  %4438 = icmp ult i64 %4437, %4436
  %4439 = icmp ult i64 %4437, %4435
  %4440 = or i1 %4438, %4439
  %4441 = zext i1 %4440 to i8
  store i8 %4441, i8* %17, align 1
  %4442 = trunc i64 %4437 to i32
  %4443 = and i32 %4442, 255
  %4444 = tail call i32 @llvm.ctpop.i32(i32 %4443)
  %4445 = trunc i32 %4444 to i8
  %4446 = and i8 %4445, 1
  %4447 = xor i8 %4446, 1
  store i8 %4447, i8* %18, align 1
  %4448 = xor i64 %4436, %4437
  %4449 = lshr i64 %4448, 4
  %4450 = trunc i64 %4449 to i8
  %4451 = and i8 %4450, 1
  store i8 %4451, i8* %19, align 1
  %4452 = icmp eq i64 %4437, 0
  %4453 = zext i1 %4452 to i8
  store i8 %4453, i8* %20, align 1
  %4454 = lshr i64 %4437, 63
  %4455 = trunc i64 %4454 to i8
  store i8 %4455, i8* %21, align 1
  %4456 = lshr i64 %4436, 63
  %4457 = lshr i64 %4434, 57
  %4458 = and i64 %4457, 1
  %4459 = xor i64 %4454, %4456
  %4460 = xor i64 %4454, %4458
  %4461 = add nuw nsw i64 %4459, %4460
  %4462 = icmp eq i64 %4461, 2
  %4463 = zext i1 %4462 to i8
  store i8 %4463, i8* %22, align 1
  %4464 = add i64 %4423, -48
  %4465 = add i64 %4425, 21
  store i64 %4465, i64* %3, align 8
  %4466 = inttoptr i64 %4464 to i32*
  %4467 = load i32, i32* %4466, align 4
  %4468 = sext i32 %4467 to i64
  store i64 %4468, i64* %RSI.i2015, align 8
  %4469 = shl nsw i64 %4468, 2
  %4470 = add i64 %4469, %4437
  %4471 = add i64 %4425, 25
  store i64 %4471, i64* %3, align 8
  %4472 = inttoptr i64 %4470 to i32*
  %4473 = load i32, i32* %4472, align 4
  %4474 = zext i32 %4473 to i64
  %4475 = shl nuw i64 %4474, 32
  %4476 = ashr i64 %4475, 33
  %4477 = and i64 %4476, 4294967295
  store i64 %4477, i64* %R9.i1633, align 8
  %4478 = load i64, i64* %RDI.i6998, align 8
  %4479 = trunc i64 %4476 to i32
  %4480 = trunc i64 %4478 to i32
  %4481 = add i32 %4479, %4480
  %4482 = zext i32 %4481 to i64
  store i64 %4482, i64* %RDI.i6998, align 8
  %4483 = icmp ult i32 %4481, %4480
  %4484 = icmp ult i32 %4481, %4479
  %4485 = or i1 %4483, %4484
  %4486 = zext i1 %4485 to i8
  store i8 %4486, i8* %17, align 1
  %4487 = and i32 %4481, 255
  %4488 = tail call i32 @llvm.ctpop.i32(i32 %4487)
  %4489 = trunc i32 %4488 to i8
  %4490 = and i8 %4489, 1
  %4491 = xor i8 %4490, 1
  store i8 %4491, i8* %18, align 1
  %4492 = xor i64 %4476, %4478
  %4493 = trunc i64 %4492 to i32
  %4494 = xor i32 %4493, %4481
  %4495 = lshr i32 %4494, 4
  %4496 = trunc i32 %4495 to i8
  %4497 = and i8 %4496, 1
  store i8 %4497, i8* %19, align 1
  %4498 = icmp eq i32 %4481, 0
  %4499 = zext i1 %4498 to i8
  store i8 %4499, i8* %20, align 1
  %4500 = lshr i32 %4481, 31
  %4501 = trunc i32 %4500 to i8
  store i8 %4501, i8* %21, align 1
  %4502 = lshr i32 %4480, 31
  %4503 = lshr i64 %4476, 31
  %4504 = trunc i64 %4503 to i32
  %4505 = and i32 %4504, 1
  %4506 = xor i32 %4500, %4502
  %4507 = xor i32 %4500, %4505
  %4508 = add nuw nsw i32 %4506, %4507
  %4509 = icmp eq i32 %4508, 2
  %4510 = zext i1 %4509 to i8
  store i8 %4510, i8* %22, align 1
  %4511 = load i64, i64* %RBP.i, align 8
  %4512 = add i64 %4511, -360
  %4513 = add i64 %4425, 37
  store i64 %4513, i64* %3, align 8
  %4514 = inttoptr i64 %4512 to i32*
  store i32 %4481, i32* %4514, align 4
  %4515 = load i64, i64* %RBP.i, align 8
  %4516 = add i64 %4515, -344
  %4517 = load i64, i64* %3, align 8
  %4518 = add i64 %4517, 6
  store i64 %4518, i64* %3, align 8
  %4519 = inttoptr i64 %4516 to i32*
  %4520 = load i32, i32* %4519, align 4
  %4521 = zext i32 %4520 to i64
  store i64 %4521, i64* %RDI.i6998, align 8
  %4522 = add i64 %4515, -360
  %4523 = add i64 %4517, 12
  store i64 %4523, i64* %3, align 8
  %4524 = inttoptr i64 %4522 to i32*
  %4525 = load i32, i32* %4524, align 4
  %4526 = sub i32 %4520, %4525
  %4527 = zext i32 %4526 to i64
  store i64 %4527, i64* %RDI.i6998, align 8
  %4528 = icmp ult i32 %4520, %4525
  %4529 = zext i1 %4528 to i8
  store i8 %4529, i8* %17, align 1
  %4530 = and i32 %4526, 255
  %4531 = tail call i32 @llvm.ctpop.i32(i32 %4530)
  %4532 = trunc i32 %4531 to i8
  %4533 = and i8 %4532, 1
  %4534 = xor i8 %4533, 1
  store i8 %4534, i8* %18, align 1
  %4535 = xor i32 %4525, %4520
  %4536 = xor i32 %4535, %4526
  %4537 = lshr i32 %4536, 4
  %4538 = trunc i32 %4537 to i8
  %4539 = and i8 %4538, 1
  store i8 %4539, i8* %19, align 1
  %4540 = icmp eq i32 %4526, 0
  %4541 = zext i1 %4540 to i8
  store i8 %4541, i8* %20, align 1
  %4542 = lshr i32 %4526, 31
  %4543 = trunc i32 %4542 to i8
  store i8 %4543, i8* %21, align 1
  %4544 = lshr i32 %4520, 31
  %4545 = lshr i32 %4525, 31
  %4546 = xor i32 %4545, %4544
  %4547 = xor i32 %4542, %4544
  %4548 = add nuw nsw i32 %4547, %4546
  %4549 = icmp eq i32 %4548, 2
  %4550 = zext i1 %4549 to i8
  store i8 %4550, i8* %22, align 1
  %4551 = add i64 %4515, -44
  %4552 = add i64 %4517, 16
  store i64 %4552, i64* %3, align 8
  %4553 = inttoptr i64 %4551 to i32*
  %4554 = load i32, i32* %4553, align 4
  %4555 = sext i32 %4554 to i64
  %4556 = shl nsw i64 %4555, 6
  store i64 %4556, i64* %RDX.i1943, align 8
  %4557 = load i64, i64* %RCX.i1588, align 8
  %4558 = add i64 %4556, %4557
  store i64 %4558, i64* %RSI.i2015, align 8
  %4559 = icmp ult i64 %4558, %4557
  %4560 = icmp ult i64 %4558, %4556
  %4561 = or i1 %4559, %4560
  %4562 = zext i1 %4561 to i8
  store i8 %4562, i8* %17, align 1
  %4563 = trunc i64 %4558 to i32
  %4564 = and i32 %4563, 255
  %4565 = tail call i32 @llvm.ctpop.i32(i32 %4564)
  %4566 = trunc i32 %4565 to i8
  %4567 = and i8 %4566, 1
  %4568 = xor i8 %4567, 1
  store i8 %4568, i8* %18, align 1
  %4569 = xor i64 %4557, %4558
  %4570 = lshr i64 %4569, 4
  %4571 = trunc i64 %4570 to i8
  %4572 = and i8 %4571, 1
  store i8 %4572, i8* %19, align 1
  %4573 = icmp eq i64 %4558, 0
  %4574 = zext i1 %4573 to i8
  store i8 %4574, i8* %20, align 1
  %4575 = lshr i64 %4558, 63
  %4576 = trunc i64 %4575 to i8
  store i8 %4576, i8* %21, align 1
  %4577 = lshr i64 %4557, 63
  %4578 = lshr i64 %4555, 57
  %4579 = and i64 %4578, 1
  %4580 = xor i64 %4575, %4577
  %4581 = xor i64 %4575, %4579
  %4582 = add nuw nsw i64 %4580, %4581
  %4583 = icmp eq i64 %4582, 2
  %4584 = zext i1 %4583 to i8
  store i8 %4584, i8* %22, align 1
  %4585 = load i64, i64* %RBP.i, align 8
  %4586 = add i64 %4585, -48
  %4587 = add i64 %4517, 30
  store i64 %4587, i64* %3, align 8
  %4588 = inttoptr i64 %4586 to i32*
  %4589 = load i32, i32* %4588, align 4
  %4590 = sext i32 %4589 to i64
  store i64 %4590, i64* %RDX.i1943, align 8
  %4591 = shl nsw i64 %4590, 2
  %4592 = add i64 %4591, %4558
  %4593 = load i32, i32* %EDI.i1741, align 4
  %4594 = add i64 %4517, 33
  store i64 %4594, i64* %3, align 8
  %4595 = inttoptr i64 %4592 to i32*
  store i32 %4593, i32* %4595, align 4
  %4596 = load i64, i64* %RBP.i, align 8
  %4597 = add i64 %4596, -360
  %4598 = load i64, i64* %3, align 8
  %4599 = add i64 %4598, 6
  store i64 %4599, i64* %3, align 8
  %4600 = inttoptr i64 %4597 to i32*
  %4601 = load i32, i32* %4600, align 4
  %4602 = zext i32 %4601 to i64
  store i64 %4602, i64* %RDI.i6998, align 8
  %4603 = add i64 %4596, -44
  %4604 = add i64 %4598, 10
  store i64 %4604, i64* %3, align 8
  %4605 = inttoptr i64 %4603 to i32*
  %4606 = load i32, i32* %4605, align 4
  %4607 = sext i32 %4606 to i64
  %4608 = shl nsw i64 %4607, 6
  store i64 %4608, i64* %RDX.i1943, align 8
  %4609 = load i64, i64* %RCX.i1588, align 8
  %4610 = add i64 %4608, %4609
  store i64 %4610, i64* %RCX.i1588, align 8
  %4611 = icmp ult i64 %4610, %4609
  %4612 = icmp ult i64 %4610, %4608
  %4613 = or i1 %4611, %4612
  %4614 = zext i1 %4613 to i8
  store i8 %4614, i8* %17, align 1
  %4615 = trunc i64 %4610 to i32
  %4616 = and i32 %4615, 255
  %4617 = tail call i32 @llvm.ctpop.i32(i32 %4616)
  %4618 = trunc i32 %4617 to i8
  %4619 = and i8 %4618, 1
  %4620 = xor i8 %4619, 1
  store i8 %4620, i8* %18, align 1
  %4621 = xor i64 %4609, %4610
  %4622 = lshr i64 %4621, 4
  %4623 = trunc i64 %4622 to i8
  %4624 = and i8 %4623, 1
  store i8 %4624, i8* %19, align 1
  %4625 = icmp eq i64 %4610, 0
  %4626 = zext i1 %4625 to i8
  store i8 %4626, i8* %20, align 1
  %4627 = lshr i64 %4610, 63
  %4628 = trunc i64 %4627 to i8
  store i8 %4628, i8* %21, align 1
  %4629 = lshr i64 %4609, 63
  %4630 = lshr i64 %4607, 57
  %4631 = and i64 %4630, 1
  %4632 = xor i64 %4627, %4629
  %4633 = xor i64 %4627, %4631
  %4634 = add nuw nsw i64 %4632, %4633
  %4635 = icmp eq i64 %4634, 2
  %4636 = zext i1 %4635 to i8
  store i8 %4636, i8* %22, align 1
  %4637 = add i64 %4596, -48
  %4638 = add i64 %4598, 21
  store i64 %4638, i64* %3, align 8
  %4639 = inttoptr i64 %4637 to i32*
  %4640 = load i32, i32* %4639, align 4
  %4641 = sext i32 %4640 to i64
  store i64 %4641, i64* %RDX.i1943, align 8
  %4642 = shl nsw i64 %4641, 2
  %4643 = add i64 %4642, %4610
  %4644 = add i64 %4598, 25
  store i64 %4644, i64* %3, align 8
  %4645 = inttoptr i64 %4643 to i32*
  %4646 = load i32, i32* %4645, align 4
  %4647 = zext i32 %4646 to i64
  %4648 = shl nuw i64 %4647, 32
  %4649 = ashr i64 %4648, 33
  %4650 = and i64 %4649, 4294967295
  store i64 %4650, i64* %R9.i1633, align 8
  %4651 = load i64, i64* %RDI.i6998, align 8
  %4652 = trunc i64 %4649 to i32
  %4653 = trunc i64 %4651 to i32
  %4654 = add i32 %4652, %4653
  %4655 = zext i32 %4654 to i64
  store i64 %4655, i64* %RDI.i6998, align 8
  %4656 = icmp ult i32 %4654, %4653
  %4657 = icmp ult i32 %4654, %4652
  %4658 = or i1 %4656, %4657
  %4659 = zext i1 %4658 to i8
  store i8 %4659, i8* %17, align 1
  %4660 = and i32 %4654, 255
  %4661 = tail call i32 @llvm.ctpop.i32(i32 %4660)
  %4662 = trunc i32 %4661 to i8
  %4663 = and i8 %4662, 1
  %4664 = xor i8 %4663, 1
  store i8 %4664, i8* %18, align 1
  %4665 = xor i64 %4649, %4651
  %4666 = trunc i64 %4665 to i32
  %4667 = xor i32 %4666, %4654
  %4668 = lshr i32 %4667, 4
  %4669 = trunc i32 %4668 to i8
  %4670 = and i8 %4669, 1
  store i8 %4670, i8* %19, align 1
  %4671 = icmp eq i32 %4654, 0
  %4672 = zext i1 %4671 to i8
  store i8 %4672, i8* %20, align 1
  %4673 = lshr i32 %4654, 31
  %4674 = trunc i32 %4673 to i8
  store i8 %4674, i8* %21, align 1
  %4675 = lshr i32 %4653, 31
  %4676 = lshr i64 %4649, 31
  %4677 = trunc i64 %4676 to i32
  %4678 = and i32 %4677, 1
  %4679 = xor i32 %4673, %4675
  %4680 = xor i32 %4673, %4678
  %4681 = add nuw nsw i32 %4679, %4680
  %4682 = icmp eq i32 %4681, 2
  %4683 = zext i1 %4682 to i8
  store i8 %4683, i8* %22, align 1
  %4684 = load i64, i64* %RBP.i, align 8
  %4685 = add i64 %4684, -44
  %4686 = add i64 %4598, 35
  store i64 %4686, i64* %3, align 8
  %4687 = inttoptr i64 %4685 to i32*
  %4688 = load i32, i32* %4687, align 4
  %4689 = sext i32 %4688 to i64
  %4690 = shl nsw i64 %4689, 6
  store i64 %4690, i64* %RCX.i1588, align 8
  %4691 = load i64, i64* %RAX.i1659, align 8
  %4692 = add i64 %4690, %4691
  store i64 %4692, i64* %RAX.i1659, align 8
  %4693 = icmp ult i64 %4692, %4691
  %4694 = icmp ult i64 %4692, %4690
  %4695 = or i1 %4693, %4694
  %4696 = zext i1 %4695 to i8
  store i8 %4696, i8* %17, align 1
  %4697 = trunc i64 %4692 to i32
  %4698 = and i32 %4697, 255
  %4699 = tail call i32 @llvm.ctpop.i32(i32 %4698)
  %4700 = trunc i32 %4699 to i8
  %4701 = and i8 %4700, 1
  %4702 = xor i8 %4701, 1
  store i8 %4702, i8* %18, align 1
  %4703 = xor i64 %4691, %4692
  %4704 = lshr i64 %4703, 4
  %4705 = trunc i64 %4704 to i8
  %4706 = and i8 %4705, 1
  store i8 %4706, i8* %19, align 1
  %4707 = icmp eq i64 %4692, 0
  %4708 = zext i1 %4707 to i8
  store i8 %4708, i8* %20, align 1
  %4709 = lshr i64 %4692, 63
  %4710 = trunc i64 %4709 to i8
  store i8 %4710, i8* %21, align 1
  %4711 = lshr i64 %4691, 63
  %4712 = lshr i64 %4689, 57
  %4713 = and i64 %4712, 1
  %4714 = xor i64 %4709, %4711
  %4715 = xor i64 %4709, %4713
  %4716 = add nuw nsw i64 %4714, %4715
  %4717 = icmp eq i64 %4716, 2
  %4718 = zext i1 %4717 to i8
  store i8 %4718, i8* %22, align 1
  %4719 = add i64 %4684, -48
  %4720 = add i64 %4598, 46
  store i64 %4720, i64* %3, align 8
  %4721 = inttoptr i64 %4719 to i32*
  %4722 = load i32, i32* %4721, align 4
  %4723 = sext i32 %4722 to i64
  store i64 %4723, i64* %RCX.i1588, align 8
  %4724 = shl nsw i64 %4723, 2
  %4725 = add i64 %4724, %4692
  %4726 = load i32, i32* %EDI.i1741, align 4
  %4727 = add i64 %4598, 49
  store i64 %4727, i64* %3, align 8
  %4728 = inttoptr i64 %4725 to i32*
  store i32 %4726, i32* %4728, align 4
  %4729 = load i64, i64* %RBP.i, align 8
  %4730 = add i64 %4729, -44
  %4731 = load i64, i64* %3, align 8
  %4732 = add i64 %4731, 3
  store i64 %4732, i64* %3, align 8
  %4733 = inttoptr i64 %4730 to i32*
  %4734 = load i32, i32* %4733, align 4
  %4735 = add i32 %4734, 1
  %4736 = zext i32 %4735 to i64
  store i64 %4736, i64* %RAX.i1659, align 8
  %4737 = icmp eq i32 %4734, -1
  %4738 = icmp eq i32 %4735, 0
  %4739 = or i1 %4737, %4738
  %4740 = zext i1 %4739 to i8
  store i8 %4740, i8* %17, align 1
  %4741 = and i32 %4735, 255
  %4742 = tail call i32 @llvm.ctpop.i32(i32 %4741)
  %4743 = trunc i32 %4742 to i8
  %4744 = and i8 %4743, 1
  %4745 = xor i8 %4744, 1
  store i8 %4745, i8* %18, align 1
  %4746 = xor i32 %4735, %4734
  %4747 = lshr i32 %4746, 4
  %4748 = trunc i32 %4747 to i8
  %4749 = and i8 %4748, 1
  store i8 %4749, i8* %19, align 1
  %4750 = zext i1 %4738 to i8
  store i8 %4750, i8* %20, align 1
  %4751 = lshr i32 %4735, 31
  %4752 = trunc i32 %4751 to i8
  store i8 %4752, i8* %21, align 1
  %4753 = lshr i32 %4734, 31
  %4754 = xor i32 %4751, %4753
  %4755 = add nuw nsw i32 %4754, %4751
  %4756 = icmp eq i32 %4755, 2
  %4757 = zext i1 %4756 to i8
  store i8 %4757, i8* %22, align 1
  %4758 = add i64 %4731, 9
  store i64 %4758, i64* %3, align 8
  store i32 %4735, i32* %4733, align 4
  %4759 = load i64, i64* %3, align 8
  %4760 = add i64 %4759, -552
  store i64 %4760, i64* %3, align 8
  br label %block_.L_4842f9

block_.L_484526:                                  ; preds = %block_.L_4842f9
  %4761 = add i64 %3568, -48
  %4762 = add i64 %3596, 8
  store i64 %4762, i64* %3, align 8
  %4763 = inttoptr i64 %4761 to i32*
  %4764 = load i32, i32* %4763, align 4
  %4765 = add i32 %4764, 1
  %4766 = zext i32 %4765 to i64
  store i64 %4766, i64* %RAX.i1659, align 8
  %4767 = icmp eq i32 %4764, -1
  %4768 = icmp eq i32 %4765, 0
  %4769 = or i1 %4767, %4768
  %4770 = zext i1 %4769 to i8
  store i8 %4770, i8* %17, align 1
  %4771 = and i32 %4765, 255
  %4772 = tail call i32 @llvm.ctpop.i32(i32 %4771)
  %4773 = trunc i32 %4772 to i8
  %4774 = and i8 %4773, 1
  %4775 = xor i8 %4774, 1
  store i8 %4775, i8* %18, align 1
  %4776 = xor i32 %4765, %4764
  %4777 = lshr i32 %4776, 4
  %4778 = trunc i32 %4777 to i8
  %4779 = and i8 %4778, 1
  store i8 %4779, i8* %19, align 1
  %4780 = zext i1 %4768 to i8
  store i8 %4780, i8* %20, align 1
  %4781 = lshr i32 %4765, 31
  %4782 = trunc i32 %4781 to i8
  store i8 %4782, i8* %21, align 1
  %4783 = lshr i32 %4764, 31
  %4784 = xor i32 %4781, %4783
  %4785 = add nuw nsw i32 %4784, %4781
  %4786 = icmp eq i32 %4785, 2
  %4787 = zext i1 %4786 to i8
  store i8 %4787, i8* %22, align 1
  %4788 = add i64 %3596, 14
  store i64 %4788, i64* %3, align 8
  store i32 %4765, i32* %4763, align 4
  %4789 = load i64, i64* %3, align 8
  %4790 = add i64 %4789, -588
  store i64 %4790, i64* %3, align 8
  br label %block_.L_4842e8

block_.L_484539:                                  ; preds = %block_.L_4842e8
  %4791 = add i64 %3563, 7
  store i64 %4791, i64* %3, align 8
  store i32 0, i32* %3538, align 4
  %.pre583 = load i64, i64* %3, align 8
  br label %block_.L_484540

block_.L_484540:                                  ; preds = %block_.L_4845a5, %block_.L_484539
  %4792 = phi i64 [ %5024, %block_.L_4845a5 ], [ %.pre583, %block_.L_484539 ]
  %4793 = load i64, i64* %RBP.i, align 8
  %4794 = add i64 %4793, -48
  %4795 = add i64 %4792, 4
  store i64 %4795, i64* %3, align 8
  %4796 = inttoptr i64 %4794 to i32*
  %4797 = load i32, i32* %4796, align 4
  %4798 = add i32 %4797, -4
  %4799 = icmp ult i32 %4797, 4
  %4800 = zext i1 %4799 to i8
  store i8 %4800, i8* %17, align 1
  %4801 = and i32 %4798, 255
  %4802 = tail call i32 @llvm.ctpop.i32(i32 %4801)
  %4803 = trunc i32 %4802 to i8
  %4804 = and i8 %4803, 1
  %4805 = xor i8 %4804, 1
  store i8 %4805, i8* %18, align 1
  %4806 = xor i32 %4798, %4797
  %4807 = lshr i32 %4806, 4
  %4808 = trunc i32 %4807 to i8
  %4809 = and i8 %4808, 1
  store i8 %4809, i8* %19, align 1
  %4810 = icmp eq i32 %4798, 0
  %4811 = zext i1 %4810 to i8
  store i8 %4811, i8* %20, align 1
  %4812 = lshr i32 %4798, 31
  %4813 = trunc i32 %4812 to i8
  store i8 %4813, i8* %21, align 1
  %4814 = lshr i32 %4797, 31
  %4815 = xor i32 %4812, %4814
  %4816 = add nuw nsw i32 %4815, %4814
  %4817 = icmp eq i32 %4816, 2
  %4818 = zext i1 %4817 to i8
  store i8 %4818, i8* %22, align 1
  %4819 = icmp ne i8 %4813, 0
  %4820 = xor i1 %4819, %4817
  %.v739 = select i1 %4820, i64 10, i64 120
  %4821 = add i64 %4792, %.v739
  store i64 %4821, i64* %3, align 8
  br i1 %4820, label %block_48454a, label %block_.L_4845b8

block_48454a:                                     ; preds = %block_.L_484540
  %4822 = add i64 %4793, -44
  %4823 = add i64 %4821, 7
  store i64 %4823, i64* %3, align 8
  %4824 = inttoptr i64 %4822 to i32*
  store i32 0, i32* %4824, align 4
  %.pre653 = load i64, i64* %3, align 8
  br label %block_.L_484551

block_.L_484551:                                  ; preds = %block_48455b, %block_48454a
  %4825 = phi i64 [ %4994, %block_48455b ], [ %.pre653, %block_48454a ]
  %4826 = load i64, i64* %RBP.i, align 8
  %4827 = add i64 %4826, -44
  %4828 = add i64 %4825, 4
  store i64 %4828, i64* %3, align 8
  %4829 = inttoptr i64 %4827 to i32*
  %4830 = load i32, i32* %4829, align 4
  %4831 = add i32 %4830, -4
  %4832 = icmp ult i32 %4830, 4
  %4833 = zext i1 %4832 to i8
  store i8 %4833, i8* %17, align 1
  %4834 = and i32 %4831, 255
  %4835 = tail call i32 @llvm.ctpop.i32(i32 %4834)
  %4836 = trunc i32 %4835 to i8
  %4837 = and i8 %4836, 1
  %4838 = xor i8 %4837, 1
  store i8 %4838, i8* %18, align 1
  %4839 = xor i32 %4831, %4830
  %4840 = lshr i32 %4839, 4
  %4841 = trunc i32 %4840 to i8
  %4842 = and i8 %4841, 1
  store i8 %4842, i8* %19, align 1
  %4843 = icmp eq i32 %4831, 0
  %4844 = zext i1 %4843 to i8
  store i8 %4844, i8* %20, align 1
  %4845 = lshr i32 %4831, 31
  %4846 = trunc i32 %4845 to i8
  store i8 %4846, i8* %21, align 1
  %4847 = lshr i32 %4830, 31
  %4848 = xor i32 %4845, %4847
  %4849 = add nuw nsw i32 %4848, %4847
  %4850 = icmp eq i32 %4849, 2
  %4851 = zext i1 %4850 to i8
  store i8 %4851, i8* %22, align 1
  %4852 = icmp ne i8 %4846, 0
  %4853 = xor i1 %4852, %4850
  %.v692 = select i1 %4853, i64 10, i64 84
  %4854 = add i64 %4825, %.v692
  store i64 %4854, i64* %3, align 8
  br i1 %4853, label %block_48455b, label %block_.L_4845a5

block_48455b:                                     ; preds = %block_.L_484551
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX.i1659, align 8
  %4855 = add i64 %4854, 14
  store i64 %4855, i64* %3, align 8
  %4856 = load i32, i32* %4829, align 4
  %4857 = sext i32 %4856 to i64
  %4858 = shl nsw i64 %4857, 6
  store i64 %4858, i64* %RCX.i1588, align 8
  %4859 = add i64 %4858, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  store i64 %4859, i64* %RAX.i1659, align 8
  %4860 = icmp ult i64 %4859, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  %4861 = icmp ult i64 %4859, %4858
  %4862 = or i1 %4860, %4861
  %4863 = zext i1 %4862 to i8
  store i8 %4863, i8* %17, align 1
  %4864 = trunc i64 %4859 to i32
  %4865 = and i32 %4864, 248
  %4866 = tail call i32 @llvm.ctpop.i32(i32 %4865)
  %4867 = trunc i32 %4866 to i8
  %4868 = and i8 %4867, 1
  %4869 = xor i8 %4868, 1
  store i8 %4869, i8* %18, align 1
  %4870 = xor i64 %4859, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  %4871 = lshr i64 %4870, 4
  %4872 = trunc i64 %4871 to i8
  %4873 = and i8 %4872, 1
  store i8 %4873, i8* %19, align 1
  %4874 = icmp eq i64 %4859, 0
  %4875 = zext i1 %4874 to i8
  store i8 %4875, i8* %20, align 1
  %4876 = lshr i64 %4859, 63
  %4877 = trunc i64 %4876 to i8
  store i8 %4877, i8* %21, align 1
  %4878 = lshr i64 %4857, 57
  %4879 = and i64 %4878, 1
  %4880 = xor i64 %4876, lshr (i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64 63)
  %4881 = xor i64 %4876, %4879
  %4882 = add nuw nsw i64 %4880, %4881
  %4883 = icmp eq i64 %4882, 2
  %4884 = zext i1 %4883 to i8
  store i8 %4884, i8* %22, align 1
  %4885 = add i64 %4826, -48
  %4886 = add i64 %4854, 25
  store i64 %4886, i64* %3, align 8
  %4887 = inttoptr i64 %4885 to i32*
  %4888 = load i32, i32* %4887, align 4
  %4889 = sext i32 %4888 to i64
  store i64 %4889, i64* %RCX.i1588, align 8
  %4890 = shl nsw i64 %4889, 2
  %4891 = add i64 %4890, %4859
  %4892 = add i64 %4854, 28
  store i64 %4892, i64* %3, align 8
  %4893 = inttoptr i64 %4891 to i32*
  %4894 = load i32, i32* %4893, align 4
  %4895 = zext i32 %4894 to i64
  store i64 %4895, i64* %RDX.i1943, align 8
  %4896 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4897 = add i64 %4896, 13112
  store i64 %4897, i64* %RAX.i1659, align 8
  %4898 = icmp ugt i64 %4896, -13113
  %4899 = zext i1 %4898 to i8
  store i8 %4899, i8* %17, align 1
  %4900 = trunc i64 %4897 to i32
  %4901 = and i32 %4900, 255
  %4902 = tail call i32 @llvm.ctpop.i32(i32 %4901)
  %4903 = trunc i32 %4902 to i8
  %4904 = and i8 %4903, 1
  %4905 = xor i8 %4904, 1
  store i8 %4905, i8* %18, align 1
  %4906 = xor i64 %4896, 16
  %4907 = xor i64 %4906, %4897
  %4908 = lshr i64 %4907, 4
  %4909 = trunc i64 %4908 to i8
  %4910 = and i8 %4909, 1
  store i8 %4910, i8* %19, align 1
  %4911 = icmp eq i64 %4897, 0
  %4912 = zext i1 %4911 to i8
  store i8 %4912, i8* %20, align 1
  %4913 = lshr i64 %4897, 63
  %4914 = trunc i64 %4913 to i8
  store i8 %4914, i8* %21, align 1
  %4915 = lshr i64 %4896, 63
  %4916 = xor i64 %4913, %4915
  %4917 = add nuw nsw i64 %4916, %4913
  %4918 = icmp eq i64 %4917, 2
  %4919 = zext i1 %4918 to i8
  store i8 %4919, i8* %22, align 1
  %4920 = load i64, i64* %RBP.i, align 8
  %4921 = add i64 %4920, -44
  %4922 = add i64 %4854, 46
  store i64 %4922, i64* %3, align 8
  %4923 = inttoptr i64 %4921 to i32*
  %4924 = load i32, i32* %4923, align 4
  %4925 = sext i32 %4924 to i64
  %4926 = shl nsw i64 %4925, 6
  store i64 %4926, i64* %RCX.i1588, align 8
  %4927 = add i64 %4926, %4897
  store i64 %4927, i64* %RAX.i1659, align 8
  %4928 = icmp ult i64 %4927, %4897
  %4929 = icmp ult i64 %4927, %4926
  %4930 = or i1 %4928, %4929
  %4931 = zext i1 %4930 to i8
  store i8 %4931, i8* %17, align 1
  %4932 = trunc i64 %4927 to i32
  %4933 = and i32 %4932, 255
  %4934 = tail call i32 @llvm.ctpop.i32(i32 %4933)
  %4935 = trunc i32 %4934 to i8
  %4936 = and i8 %4935, 1
  %4937 = xor i8 %4936, 1
  store i8 %4937, i8* %18, align 1
  %4938 = xor i64 %4897, %4927
  %4939 = lshr i64 %4938, 4
  %4940 = trunc i64 %4939 to i8
  %4941 = and i8 %4940, 1
  store i8 %4941, i8* %19, align 1
  %4942 = icmp eq i64 %4927, 0
  %4943 = zext i1 %4942 to i8
  store i8 %4943, i8* %20, align 1
  %4944 = lshr i64 %4927, 63
  %4945 = trunc i64 %4944 to i8
  store i8 %4945, i8* %21, align 1
  %4946 = lshr i64 %4925, 57
  %4947 = and i64 %4946, 1
  %4948 = xor i64 %4944, %4913
  %4949 = xor i64 %4944, %4947
  %4950 = add nuw nsw i64 %4948, %4949
  %4951 = icmp eq i64 %4950, 2
  %4952 = zext i1 %4951 to i8
  store i8 %4952, i8* %22, align 1
  %4953 = add i64 %4920, -48
  %4954 = add i64 %4854, 57
  store i64 %4954, i64* %3, align 8
  %4955 = inttoptr i64 %4953 to i32*
  %4956 = load i32, i32* %4955, align 4
  %4957 = sext i32 %4956 to i64
  store i64 %4957, i64* %RCX.i1588, align 8
  %4958 = shl nsw i64 %4957, 2
  %4959 = add i64 %4958, %4927
  %4960 = load i32, i32* %108, align 4
  %4961 = add i64 %4854, 60
  store i64 %4961, i64* %3, align 8
  %4962 = inttoptr i64 %4959 to i32*
  store i32 %4960, i32* %4962, align 4
  %4963 = load i64, i64* %RBP.i, align 8
  %4964 = add i64 %4963, -44
  %4965 = load i64, i64* %3, align 8
  %4966 = add i64 %4965, 3
  store i64 %4966, i64* %3, align 8
  %4967 = inttoptr i64 %4964 to i32*
  %4968 = load i32, i32* %4967, align 4
  %4969 = add i32 %4968, 1
  %4970 = zext i32 %4969 to i64
  store i64 %4970, i64* %RAX.i1659, align 8
  %4971 = icmp eq i32 %4968, -1
  %4972 = icmp eq i32 %4969, 0
  %4973 = or i1 %4971, %4972
  %4974 = zext i1 %4973 to i8
  store i8 %4974, i8* %17, align 1
  %4975 = and i32 %4969, 255
  %4976 = tail call i32 @llvm.ctpop.i32(i32 %4975)
  %4977 = trunc i32 %4976 to i8
  %4978 = and i8 %4977, 1
  %4979 = xor i8 %4978, 1
  store i8 %4979, i8* %18, align 1
  %4980 = xor i32 %4969, %4968
  %4981 = lshr i32 %4980, 4
  %4982 = trunc i32 %4981 to i8
  %4983 = and i8 %4982, 1
  store i8 %4983, i8* %19, align 1
  %4984 = zext i1 %4972 to i8
  store i8 %4984, i8* %20, align 1
  %4985 = lshr i32 %4969, 31
  %4986 = trunc i32 %4985 to i8
  store i8 %4986, i8* %21, align 1
  %4987 = lshr i32 %4968, 31
  %4988 = xor i32 %4985, %4987
  %4989 = add nuw nsw i32 %4988, %4985
  %4990 = icmp eq i32 %4989, 2
  %4991 = zext i1 %4990 to i8
  store i8 %4991, i8* %22, align 1
  %4992 = add i64 %4965, 9
  store i64 %4992, i64* %3, align 8
  store i32 %4969, i32* %4967, align 4
  %4993 = load i64, i64* %3, align 8
  %4994 = add i64 %4993, -79
  store i64 %4994, i64* %3, align 8
  br label %block_.L_484551

block_.L_4845a5:                                  ; preds = %block_.L_484551
  %4995 = add i64 %4826, -48
  %4996 = add i64 %4854, 8
  store i64 %4996, i64* %3, align 8
  %4997 = inttoptr i64 %4995 to i32*
  %4998 = load i32, i32* %4997, align 4
  %4999 = add i32 %4998, 1
  %5000 = zext i32 %4999 to i64
  store i64 %5000, i64* %RAX.i1659, align 8
  %5001 = icmp eq i32 %4998, -1
  %5002 = icmp eq i32 %4999, 0
  %5003 = or i1 %5001, %5002
  %5004 = zext i1 %5003 to i8
  store i8 %5004, i8* %17, align 1
  %5005 = and i32 %4999, 255
  %5006 = tail call i32 @llvm.ctpop.i32(i32 %5005)
  %5007 = trunc i32 %5006 to i8
  %5008 = and i8 %5007, 1
  %5009 = xor i8 %5008, 1
  store i8 %5009, i8* %18, align 1
  %5010 = xor i32 %4999, %4998
  %5011 = lshr i32 %5010, 4
  %5012 = trunc i32 %5011 to i8
  %5013 = and i8 %5012, 1
  store i8 %5013, i8* %19, align 1
  %5014 = zext i1 %5002 to i8
  store i8 %5014, i8* %20, align 1
  %5015 = lshr i32 %4999, 31
  %5016 = trunc i32 %5015 to i8
  store i8 %5016, i8* %21, align 1
  %5017 = lshr i32 %4998, 31
  %5018 = xor i32 %5015, %5017
  %5019 = add nuw nsw i32 %5018, %5015
  %5020 = icmp eq i32 %5019, 2
  %5021 = zext i1 %5020 to i8
  store i8 %5021, i8* %22, align 1
  %5022 = add i64 %4854, 14
  store i64 %5022, i64* %3, align 8
  store i32 %4999, i32* %4997, align 4
  %5023 = load i64, i64* %3, align 8
  %5024 = add i64 %5023, -115
  store i64 %5024, i64* %3, align 8
  br label %block_.L_484540

block_.L_4845b8:                                  ; preds = %block_.L_484540
  %5025 = load i64, i64* bitcast (%G_0x6cc628_type* @G_0x6cc628 to i64*), align 8
  store i64 %5025, i64* %RDI.i6998, align 8
  %5026 = add i64 %4821, 103176
  %5027 = add i64 %4821, 13
  %5028 = load i64, i64* %6, align 8
  %5029 = add i64 %5028, -8
  %5030 = inttoptr i64 %5029 to i64*
  store i64 %5027, i64* %5030, align 8
  store i64 %5029, i64* %6, align 8
  store i64 %5026, i64* %3, align 8
  %call2_4845c0 = tail call %struct.Memory* @sub_49d8c0.store_coding_state(%struct.State* nonnull %0, i64 %5026, %struct.Memory* %MEMORY.8)
  %5031 = load i64, i64* %RBP.i, align 8
  %5032 = add i64 %5031, -72
  %5033 = load i64, i64* %3, align 8
  store i64 %5032, i64* %RDI.i6998, align 8
  %5034 = add i64 %5031, -12
  %5035 = add i64 %5033, 7
  store i64 %5035, i64* %3, align 8
  %5036 = inttoptr i64 %5034 to i32*
  %5037 = load i32, i32* %5036, align 4
  %5038 = zext i32 %5037 to i64
  store i64 %5038, i64* %RSI.i2015, align 8
  %5039 = add i64 %5031, -16
  %5040 = add i64 %5033, 10
  store i64 %5040, i64* %3, align 8
  %5041 = inttoptr i64 %5039 to i32*
  %5042 = load i32, i32* %5041, align 4
  %5043 = zext i32 %5042 to i64
  store i64 %5043, i64* %RDX.i1943, align 8
  %5044 = add i64 %5031, -36
  %5045 = add i64 %5033, 13
  store i64 %5045, i64* %3, align 8
  %5046 = inttoptr i64 %5044 to i32*
  %5047 = load i32, i32* %5046, align 4
  %5048 = zext i32 %5047 to i64
  store i64 %5048, i64* %RCX.i1588, align 8
  %5049 = add i64 %5031, -24
  %5050 = add i64 %5033, 18
  store i64 %5050, i64* %3, align 8
  %5051 = inttoptr i64 %5049 to i64*
  %5052 = load i64, i64* %5051, align 8
  store i64 %5052, i64* %69, align 1
  store double 0.000000e+00, double* %1190, align 1
  %5053 = add i64 %5031, -256
  %5054 = add i64 %5033, 26
  store i64 %5054, i64* %3, align 8
  %5055 = inttoptr i64 %5053 to i64*
  %5056 = load i64, i64* %5055, align 8
  store i64 %5056, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %5057 = add i64 %5031, -288
  %5058 = add i64 %5033, 33
  store i64 %5058, i64* %3, align 8
  %5059 = inttoptr i64 %5057 to i32*
  %5060 = load i32, i32* %5059, align 4
  %5061 = zext i32 %5060 to i64
  store i64 %5061, i64* %25, align 8
  %5062 = add i64 %5033, -5349
  %5063 = add i64 %5033, 38
  %5064 = load i64, i64* %6, align 8
  %5065 = add i64 %5064, -8
  %5066 = inttoptr i64 %5065 to i64*
  store i64 %5063, i64* %5066, align 8
  store i64 %5065, i64* %6, align 8
  store i64 %5062, i64* %3, align 8
  %call2_4845e6 = tail call %struct.Memory* @sub_4830e0.RDCost_for_4x4IntraBlocks(%struct.State* nonnull %0, i64 %5062, %struct.Memory* %MEMORY.8)
  %5067 = load i64, i64* %3, align 8
  %5068 = load double, double* %68, align 1
  %5069 = tail call double @llvm.trunc.f64(double %5068)
  %5070 = tail call double @llvm.fabs.f64(double %5069)
  %5071 = fcmp ogt double %5070, 0x41DFFFFFFFC00000
  %5072 = fptosi double %5069 to i32
  %5073 = zext i32 %5072 to i64
  %5074 = select i1 %5071, i64 2147483648, i64 %5073
  store i64 %5074, i64* %RCX.i1588, align 8
  %5075 = load i64, i64* %RBP.i, align 8
  %5076 = add i64 %5075, -352
  %5077 = trunc i64 %5074 to i32
  %5078 = add i64 %5067, 10
  store i64 %5078, i64* %3, align 8
  %5079 = inttoptr i64 %5076 to i32*
  store i32 %5077, i32* %5079, align 4
  %5080 = load i64, i64* %3, align 8
  %5081 = load i64, i64* bitcast (%G_0x6cc628_type* @G_0x6cc628 to i64*), align 8
  store i64 %5081, i64* %RDI.i6998, align 8
  %5082 = add i64 %5080, 103947
  %5083 = add i64 %5080, 13
  %5084 = load i64, i64* %6, align 8
  %5085 = add i64 %5084, -8
  %5086 = inttoptr i64 %5085 to i64*
  store i64 %5083, i64* %5086, align 8
  store i64 %5085, i64* %6, align 8
  store i64 %5082, i64* %3, align 8
  %call2_4845fd = tail call %struct.Memory* @sub_49dc00.reset_coding_state(%struct.State* nonnull %0, i64 %5082, %struct.Memory* %MEMORY.8)
  %5087 = load i64, i64* %RBP.i, align 8
  %5088 = add i64 %5087, -48
  %5089 = load i64, i64* %3, align 8
  %5090 = add i64 %5089, 7
  store i64 %5090, i64* %3, align 8
  %5091 = inttoptr i64 %5088 to i32*
  store i32 0, i32* %5091, align 4
  %.pre584 = load i64, i64* %3, align 8
  br label %block_.L_484609

block_.L_484609:                                  ; preds = %block_.L_4846ab, %block_.L_4845b8
  %5092 = phi i64 [ %5437, %block_.L_4846ab ], [ %.pre584, %block_.L_4845b8 ]
  %5093 = load i64, i64* %RBP.i, align 8
  %5094 = add i64 %5093, -48
  %5095 = add i64 %5092, 4
  store i64 %5095, i64* %3, align 8
  %5096 = inttoptr i64 %5094 to i32*
  %5097 = load i32, i32* %5096, align 4
  %5098 = add i32 %5097, -4
  %5099 = icmp ult i32 %5097, 4
  %5100 = zext i1 %5099 to i8
  store i8 %5100, i8* %17, align 1
  %5101 = and i32 %5098, 255
  %5102 = tail call i32 @llvm.ctpop.i32(i32 %5101)
  %5103 = trunc i32 %5102 to i8
  %5104 = and i8 %5103, 1
  %5105 = xor i8 %5104, 1
  store i8 %5105, i8* %18, align 1
  %5106 = xor i32 %5098, %5097
  %5107 = lshr i32 %5106, 4
  %5108 = trunc i32 %5107 to i8
  %5109 = and i8 %5108, 1
  store i8 %5109, i8* %19, align 1
  %5110 = icmp eq i32 %5098, 0
  %5111 = zext i1 %5110 to i8
  store i8 %5111, i8* %20, align 1
  %5112 = lshr i32 %5098, 31
  %5113 = trunc i32 %5112 to i8
  store i8 %5113, i8* %21, align 1
  %5114 = lshr i32 %5097, 31
  %5115 = xor i32 %5112, %5114
  %5116 = add nuw nsw i32 %5115, %5114
  %5117 = icmp eq i32 %5116, 2
  %5118 = zext i1 %5117 to i8
  store i8 %5118, i8* %22, align 1
  %5119 = icmp ne i8 %5113, 0
  %5120 = xor i1 %5119, %5117
  %.v740 = select i1 %5120, i64 10, i64 181
  %5121 = add i64 %5092, %.v740
  store i64 %5121, i64* %3, align 8
  br i1 %5120, label %block_484613, label %block_.L_4846be

block_484613:                                     ; preds = %block_.L_484609
  %5122 = add i64 %5093, -44
  %5123 = add i64 %5121, 7
  store i64 %5123, i64* %3, align 8
  %5124 = inttoptr i64 %5122 to i32*
  store i32 0, i32* %5124, align 4
  %.pre652 = load i64, i64* %3, align 8
  br label %block_.L_48461a

block_.L_48461a:                                  ; preds = %block_484624, %block_484613
  %5125 = phi i64 [ %5407, %block_484624 ], [ %.pre652, %block_484613 ]
  %5126 = load i64, i64* %RBP.i, align 8
  %5127 = add i64 %5126, -44
  %5128 = add i64 %5125, 4
  store i64 %5128, i64* %3, align 8
  %5129 = inttoptr i64 %5127 to i32*
  %5130 = load i32, i32* %5129, align 4
  %5131 = add i32 %5130, -4
  %5132 = icmp ult i32 %5130, 4
  %5133 = zext i1 %5132 to i8
  store i8 %5133, i8* %17, align 1
  %5134 = and i32 %5131, 255
  %5135 = tail call i32 @llvm.ctpop.i32(i32 %5134)
  %5136 = trunc i32 %5135 to i8
  %5137 = and i8 %5136, 1
  %5138 = xor i8 %5137, 1
  store i8 %5138, i8* %18, align 1
  %5139 = xor i32 %5131, %5130
  %5140 = lshr i32 %5139, 4
  %5141 = trunc i32 %5140 to i8
  %5142 = and i8 %5141, 1
  store i8 %5142, i8* %19, align 1
  %5143 = icmp eq i32 %5131, 0
  %5144 = zext i1 %5143 to i8
  store i8 %5144, i8* %20, align 1
  %5145 = lshr i32 %5131, 31
  %5146 = trunc i32 %5145 to i8
  store i8 %5146, i8* %21, align 1
  %5147 = lshr i32 %5130, 31
  %5148 = xor i32 %5145, %5147
  %5149 = add nuw nsw i32 %5148, %5147
  %5150 = icmp eq i32 %5149, 2
  %5151 = zext i1 %5150 to i8
  store i8 %5151, i8* %22, align 1
  %5152 = icmp ne i8 %5146, 0
  %5153 = xor i1 %5152, %5150
  %.v691 = select i1 %5153, i64 10, i64 145
  %5154 = add i64 %5125, %.v691
  store i64 %5154, i64* %3, align 8
  br i1 %5153, label %block_484624, label %block_.L_4846ab

block_484624:                                     ; preds = %block_.L_48461a
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RAX.i1659, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RCX.i1588, align 8
  %5155 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %5156 = add i64 %5155, 13112
  store i64 %5156, i64* %RDX.i1943, align 8
  %5157 = icmp ugt i64 %5155, -13113
  %5158 = zext i1 %5157 to i8
  store i8 %5158, i8* %17, align 1
  %5159 = trunc i64 %5156 to i32
  %5160 = and i32 %5159, 255
  %5161 = tail call i32 @llvm.ctpop.i32(i32 %5160)
  %5162 = trunc i32 %5161 to i8
  %5163 = and i8 %5162, 1
  %5164 = xor i8 %5163, 1
  store i8 %5164, i8* %18, align 1
  %5165 = xor i64 %5155, 16
  %5166 = xor i64 %5165, %5156
  %5167 = lshr i64 %5166, 4
  %5168 = trunc i64 %5167 to i8
  %5169 = and i8 %5168, 1
  store i8 %5169, i8* %19, align 1
  %5170 = icmp eq i64 %5156, 0
  %5171 = zext i1 %5170 to i8
  store i8 %5171, i8* %20, align 1
  %5172 = lshr i64 %5156, 63
  %5173 = trunc i64 %5172 to i8
  store i8 %5173, i8* %21, align 1
  %5174 = lshr i64 %5155, 63
  %5175 = xor i64 %5172, %5174
  %5176 = add nuw nsw i64 %5175, %5172
  %5177 = icmp eq i64 %5176, 2
  %5178 = zext i1 %5177 to i8
  store i8 %5178, i8* %22, align 1
  %5179 = add i64 %5154, 39
  store i64 %5179, i64* %3, align 8
  %5180 = load i32, i32* %5129, align 4
  %5181 = sext i32 %5180 to i64
  %5182 = shl nsw i64 %5181, 6
  store i64 %5182, i64* %RSI.i2015, align 8
  %5183 = add i64 %5182, %5156
  store i64 %5183, i64* %RDX.i1943, align 8
  %5184 = icmp ult i64 %5183, %5156
  %5185 = icmp ult i64 %5183, %5182
  %5186 = or i1 %5184, %5185
  %5187 = zext i1 %5186 to i8
  store i8 %5187, i8* %17, align 1
  %5188 = trunc i64 %5183 to i32
  %5189 = and i32 %5188, 255
  %5190 = tail call i32 @llvm.ctpop.i32(i32 %5189)
  %5191 = trunc i32 %5190 to i8
  %5192 = and i8 %5191, 1
  %5193 = xor i8 %5192, 1
  store i8 %5193, i8* %18, align 1
  %5194 = xor i64 %5156, %5183
  %5195 = lshr i64 %5194, 4
  %5196 = trunc i64 %5195 to i8
  %5197 = and i8 %5196, 1
  store i8 %5197, i8* %19, align 1
  %5198 = icmp eq i64 %5183, 0
  %5199 = zext i1 %5198 to i8
  store i8 %5199, i8* %20, align 1
  %5200 = lshr i64 %5183, 63
  %5201 = trunc i64 %5200 to i8
  store i8 %5201, i8* %21, align 1
  %5202 = lshr i64 %5181, 57
  %5203 = and i64 %5202, 1
  %5204 = xor i64 %5200, %5172
  %5205 = xor i64 %5200, %5203
  %5206 = add nuw nsw i64 %5204, %5205
  %5207 = icmp eq i64 %5206, 2
  %5208 = zext i1 %5207 to i8
  store i8 %5208, i8* %22, align 1
  %5209 = load i64, i64* %RBP.i, align 8
  %5210 = add i64 %5209, -48
  %5211 = add i64 %5154, 50
  store i64 %5211, i64* %3, align 8
  %5212 = inttoptr i64 %5210 to i32*
  %5213 = load i32, i32* %5212, align 4
  %5214 = sext i32 %5213 to i64
  store i64 %5214, i64* %RSI.i2015, align 8
  %5215 = shl nsw i64 %5214, 2
  %5216 = add i64 %5215, %5183
  %5217 = add i64 %5154, 53
  store i64 %5217, i64* %3, align 8
  %5218 = inttoptr i64 %5216 to i32*
  %5219 = load i32, i32* %5218, align 4
  %5220 = zext i32 %5219 to i64
  store i64 %5220, i64* %RDI.i6998, align 8
  %5221 = add i64 %5209, -44
  %5222 = add i64 %5154, 57
  store i64 %5222, i64* %3, align 8
  %5223 = inttoptr i64 %5221 to i32*
  %5224 = load i32, i32* %5223, align 4
  %5225 = sext i32 %5224 to i64
  %5226 = shl nsw i64 %5225, 6
  store i64 %5226, i64* %RDX.i1943, align 8
  %5227 = load i64, i64* %RCX.i1588, align 8
  %5228 = add i64 %5226, %5227
  store i64 %5228, i64* %RCX.i1588, align 8
  %5229 = icmp ult i64 %5228, %5227
  %5230 = icmp ult i64 %5228, %5226
  %5231 = or i1 %5229, %5230
  %5232 = zext i1 %5231 to i8
  store i8 %5232, i8* %17, align 1
  %5233 = trunc i64 %5228 to i32
  %5234 = and i32 %5233, 255
  %5235 = tail call i32 @llvm.ctpop.i32(i32 %5234)
  %5236 = trunc i32 %5235 to i8
  %5237 = and i8 %5236, 1
  %5238 = xor i8 %5237, 1
  store i8 %5238, i8* %18, align 1
  %5239 = xor i64 %5227, %5228
  %5240 = lshr i64 %5239, 4
  %5241 = trunc i64 %5240 to i8
  %5242 = and i8 %5241, 1
  store i8 %5242, i8* %19, align 1
  %5243 = icmp eq i64 %5228, 0
  %5244 = zext i1 %5243 to i8
  store i8 %5244, i8* %20, align 1
  %5245 = lshr i64 %5228, 63
  %5246 = trunc i64 %5245 to i8
  store i8 %5246, i8* %21, align 1
  %5247 = lshr i64 %5227, 63
  %5248 = lshr i64 %5225, 57
  %5249 = and i64 %5248, 1
  %5250 = xor i64 %5245, %5247
  %5251 = xor i64 %5245, %5249
  %5252 = add nuw nsw i64 %5250, %5251
  %5253 = icmp eq i64 %5252, 2
  %5254 = zext i1 %5253 to i8
  store i8 %5254, i8* %22, align 1
  %5255 = add i64 %5154, 68
  store i64 %5255, i64* %3, align 8
  %5256 = load i32, i32* %5212, align 4
  %5257 = sext i32 %5256 to i64
  store i64 %5257, i64* %RDX.i1943, align 8
  %5258 = shl nsw i64 %5257, 2
  %5259 = add i64 %5258, %5228
  %5260 = add i64 %5154, 71
  store i64 %5260, i64* %3, align 8
  %5261 = inttoptr i64 %5259 to i32*
  store i32 %5219, i32* %5261, align 4
  %5262 = load i64, i64* %RBP.i, align 8
  %5263 = add i64 %5262, -44
  %5264 = load i64, i64* %3, align 8
  %5265 = add i64 %5264, 4
  store i64 %5265, i64* %3, align 8
  %5266 = inttoptr i64 %5263 to i32*
  %5267 = load i32, i32* %5266, align 4
  %5268 = sext i32 %5267 to i64
  %5269 = shl nsw i64 %5268, 6
  store i64 %5269, i64* %RCX.i1588, align 8
  %5270 = load i64, i64* %RAX.i1659, align 8
  %5271 = add i64 %5269, %5270
  store i64 %5271, i64* %RAX.i1659, align 8
  %5272 = icmp ult i64 %5271, %5270
  %5273 = icmp ult i64 %5271, %5269
  %5274 = or i1 %5272, %5273
  %5275 = zext i1 %5274 to i8
  store i8 %5275, i8* %17, align 1
  %5276 = trunc i64 %5271 to i32
  %5277 = and i32 %5276, 255
  %5278 = tail call i32 @llvm.ctpop.i32(i32 %5277)
  %5279 = trunc i32 %5278 to i8
  %5280 = and i8 %5279, 1
  %5281 = xor i8 %5280, 1
  store i8 %5281, i8* %18, align 1
  %5282 = xor i64 %5270, %5271
  %5283 = lshr i64 %5282, 4
  %5284 = trunc i64 %5283 to i8
  %5285 = and i8 %5284, 1
  store i8 %5285, i8* %19, align 1
  %5286 = icmp eq i64 %5271, 0
  %5287 = zext i1 %5286 to i8
  store i8 %5287, i8* %20, align 1
  %5288 = lshr i64 %5271, 63
  %5289 = trunc i64 %5288 to i8
  store i8 %5289, i8* %21, align 1
  %5290 = lshr i64 %5270, 63
  %5291 = lshr i64 %5268, 57
  %5292 = and i64 %5291, 1
  %5293 = xor i64 %5288, %5290
  %5294 = xor i64 %5288, %5292
  %5295 = add nuw nsw i64 %5293, %5294
  %5296 = icmp eq i64 %5295, 2
  %5297 = zext i1 %5296 to i8
  store i8 %5297, i8* %22, align 1
  %5298 = add i64 %5262, -48
  %5299 = add i64 %5264, 15
  store i64 %5299, i64* %3, align 8
  %5300 = inttoptr i64 %5298 to i32*
  %5301 = load i32, i32* %5300, align 4
  %5302 = sext i32 %5301 to i64
  store i64 %5302, i64* %RCX.i1588, align 8
  %5303 = shl nsw i64 %5302, 2
  %5304 = add i64 %5303, %5271
  %5305 = add i64 %5264, 18
  store i64 %5305, i64* %3, align 8
  %5306 = inttoptr i64 %5304 to i32*
  %5307 = load i32, i32* %5306, align 4
  %5308 = zext i32 %5307 to i64
  store i64 %5308, i64* %RDI.i6998, align 8
  %5309 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %5310 = add i64 %5309, 13112
  store i64 %5310, i64* %RAX.i1659, align 8
  %5311 = icmp ugt i64 %5309, -13113
  %5312 = zext i1 %5311 to i8
  store i8 %5312, i8* %17, align 1
  %5313 = trunc i64 %5310 to i32
  %5314 = and i32 %5313, 255
  %5315 = tail call i32 @llvm.ctpop.i32(i32 %5314)
  %5316 = trunc i32 %5315 to i8
  %5317 = and i8 %5316, 1
  %5318 = xor i8 %5317, 1
  store i8 %5318, i8* %18, align 1
  %5319 = xor i64 %5309, 16
  %5320 = xor i64 %5319, %5310
  %5321 = lshr i64 %5320, 4
  %5322 = trunc i64 %5321 to i8
  %5323 = and i8 %5322, 1
  store i8 %5323, i8* %19, align 1
  %5324 = icmp eq i64 %5310, 0
  %5325 = zext i1 %5324 to i8
  store i8 %5325, i8* %20, align 1
  %5326 = lshr i64 %5310, 63
  %5327 = trunc i64 %5326 to i8
  store i8 %5327, i8* %21, align 1
  %5328 = lshr i64 %5309, 63
  %5329 = xor i64 %5326, %5328
  %5330 = add nuw nsw i64 %5329, %5326
  %5331 = icmp eq i64 %5330, 2
  %5332 = zext i1 %5331 to i8
  store i8 %5332, i8* %22, align 1
  %5333 = load i64, i64* %RBP.i, align 8
  %5334 = add i64 %5333, -44
  %5335 = add i64 %5264, 36
  store i64 %5335, i64* %3, align 8
  %5336 = inttoptr i64 %5334 to i32*
  %5337 = load i32, i32* %5336, align 4
  %5338 = sext i32 %5337 to i64
  %5339 = shl nsw i64 %5338, 6
  store i64 %5339, i64* %RCX.i1588, align 8
  %5340 = add i64 %5339, %5310
  store i64 %5340, i64* %RAX.i1659, align 8
  %5341 = icmp ult i64 %5340, %5310
  %5342 = icmp ult i64 %5340, %5339
  %5343 = or i1 %5341, %5342
  %5344 = zext i1 %5343 to i8
  store i8 %5344, i8* %17, align 1
  %5345 = trunc i64 %5340 to i32
  %5346 = and i32 %5345, 255
  %5347 = tail call i32 @llvm.ctpop.i32(i32 %5346)
  %5348 = trunc i32 %5347 to i8
  %5349 = and i8 %5348, 1
  %5350 = xor i8 %5349, 1
  store i8 %5350, i8* %18, align 1
  %5351 = xor i64 %5310, %5340
  %5352 = lshr i64 %5351, 4
  %5353 = trunc i64 %5352 to i8
  %5354 = and i8 %5353, 1
  store i8 %5354, i8* %19, align 1
  %5355 = icmp eq i64 %5340, 0
  %5356 = zext i1 %5355 to i8
  store i8 %5356, i8* %20, align 1
  %5357 = lshr i64 %5340, 63
  %5358 = trunc i64 %5357 to i8
  store i8 %5358, i8* %21, align 1
  %5359 = lshr i64 %5338, 57
  %5360 = and i64 %5359, 1
  %5361 = xor i64 %5357, %5326
  %5362 = xor i64 %5357, %5360
  %5363 = add nuw nsw i64 %5361, %5362
  %5364 = icmp eq i64 %5363, 2
  %5365 = zext i1 %5364 to i8
  store i8 %5365, i8* %22, align 1
  %5366 = add i64 %5333, -48
  %5367 = add i64 %5264, 47
  store i64 %5367, i64* %3, align 8
  %5368 = inttoptr i64 %5366 to i32*
  %5369 = load i32, i32* %5368, align 4
  %5370 = sext i32 %5369 to i64
  store i64 %5370, i64* %RCX.i1588, align 8
  %5371 = shl nsw i64 %5370, 2
  %5372 = add i64 %5371, %5340
  %5373 = load i32, i32* %EDI.i1741, align 4
  %5374 = add i64 %5264, 50
  store i64 %5374, i64* %3, align 8
  %5375 = inttoptr i64 %5372 to i32*
  store i32 %5373, i32* %5375, align 4
  %5376 = load i64, i64* %RBP.i, align 8
  %5377 = add i64 %5376, -44
  %5378 = load i64, i64* %3, align 8
  %5379 = add i64 %5378, 3
  store i64 %5379, i64* %3, align 8
  %5380 = inttoptr i64 %5377 to i32*
  %5381 = load i32, i32* %5380, align 4
  %5382 = add i32 %5381, 1
  %5383 = zext i32 %5382 to i64
  store i64 %5383, i64* %RAX.i1659, align 8
  %5384 = icmp eq i32 %5381, -1
  %5385 = icmp eq i32 %5382, 0
  %5386 = or i1 %5384, %5385
  %5387 = zext i1 %5386 to i8
  store i8 %5387, i8* %17, align 1
  %5388 = and i32 %5382, 255
  %5389 = tail call i32 @llvm.ctpop.i32(i32 %5388)
  %5390 = trunc i32 %5389 to i8
  %5391 = and i8 %5390, 1
  %5392 = xor i8 %5391, 1
  store i8 %5392, i8* %18, align 1
  %5393 = xor i32 %5382, %5381
  %5394 = lshr i32 %5393, 4
  %5395 = trunc i32 %5394 to i8
  %5396 = and i8 %5395, 1
  store i8 %5396, i8* %19, align 1
  %5397 = zext i1 %5385 to i8
  store i8 %5397, i8* %20, align 1
  %5398 = lshr i32 %5382, 31
  %5399 = trunc i32 %5398 to i8
  store i8 %5399, i8* %21, align 1
  %5400 = lshr i32 %5381, 31
  %5401 = xor i32 %5398, %5400
  %5402 = add nuw nsw i32 %5401, %5398
  %5403 = icmp eq i32 %5402, 2
  %5404 = zext i1 %5403 to i8
  store i8 %5404, i8* %22, align 1
  %5405 = add i64 %5378, 9
  store i64 %5405, i64* %3, align 8
  store i32 %5382, i32* %5380, align 4
  %5406 = load i64, i64* %3, align 8
  %5407 = add i64 %5406, -140
  store i64 %5407, i64* %3, align 8
  br label %block_.L_48461a

block_.L_4846ab:                                  ; preds = %block_.L_48461a
  %5408 = add i64 %5126, -48
  %5409 = add i64 %5154, 8
  store i64 %5409, i64* %3, align 8
  %5410 = inttoptr i64 %5408 to i32*
  %5411 = load i32, i32* %5410, align 4
  %5412 = add i32 %5411, 1
  %5413 = zext i32 %5412 to i64
  store i64 %5413, i64* %RAX.i1659, align 8
  %5414 = icmp eq i32 %5411, -1
  %5415 = icmp eq i32 %5412, 0
  %5416 = or i1 %5414, %5415
  %5417 = zext i1 %5416 to i8
  store i8 %5417, i8* %17, align 1
  %5418 = and i32 %5412, 255
  %5419 = tail call i32 @llvm.ctpop.i32(i32 %5418)
  %5420 = trunc i32 %5419 to i8
  %5421 = and i8 %5420, 1
  %5422 = xor i8 %5421, 1
  store i8 %5422, i8* %18, align 1
  %5423 = xor i32 %5412, %5411
  %5424 = lshr i32 %5423, 4
  %5425 = trunc i32 %5424 to i8
  %5426 = and i8 %5425, 1
  store i8 %5426, i8* %19, align 1
  %5427 = zext i1 %5415 to i8
  store i8 %5427, i8* %20, align 1
  %5428 = lshr i32 %5412, 31
  %5429 = trunc i32 %5428 to i8
  store i8 %5429, i8* %21, align 1
  %5430 = lshr i32 %5411, 31
  %5431 = xor i32 %5428, %5430
  %5432 = add nuw nsw i32 %5431, %5428
  %5433 = icmp eq i32 %5432, 2
  %5434 = zext i1 %5433 to i8
  store i8 %5434, i8* %22, align 1
  %5435 = add i64 %5154, 14
  store i64 %5435, i64* %3, align 8
  store i32 %5412, i32* %5410, align 4
  %5436 = load i64, i64* %3, align 8
  %5437 = add i64 %5436, -176
  store i64 %5437, i64* %3, align 8
  br label %block_.L_484609

block_.L_4846be:                                  ; preds = %block_.L_484609
  %5438 = load i64, i64* bitcast (%G_0x6cc628_type* @G_0x6cc628 to i64*), align 8
  store i64 %5438, i64* %RDI.i6998, align 8
  %5439 = add i64 %5121, 102914
  %5440 = add i64 %5121, 13
  %5441 = load i64, i64* %6, align 8
  %5442 = add i64 %5441, -8
  %5443 = inttoptr i64 %5442 to i64*
  store i64 %5440, i64* %5443, align 8
  store i64 %5442, i64* %6, align 8
  store i64 %5439, i64* %3, align 8
  %call2_4846c6 = tail call %struct.Memory* @sub_49d8c0.store_coding_state(%struct.State* nonnull %0, i64 %5439, %struct.Memory* %MEMORY.8)
  %5444 = load i64, i64* %3, align 8
  store i64 0, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %5445 = load i64, i64* %RBP.i, align 8
  %5446 = add i64 %5445, -12
  %5447 = add i64 %5444, 5
  store i64 %5447, i64* %3, align 8
  %5448 = inttoptr i64 %5446 to i32*
  %5449 = load i32, i32* %5448, align 4
  %5450 = add i32 %5449, 4
  %5451 = zext i32 %5450 to i64
  store i64 %5451, i64* %RAX.i1659, align 8
  %5452 = icmp ugt i32 %5449, -5
  %5453 = zext i1 %5452 to i8
  store i8 %5453, i8* %17, align 1
  %5454 = and i32 %5450, 255
  %5455 = tail call i32 @llvm.ctpop.i32(i32 %5454)
  %5456 = trunc i32 %5455 to i8
  %5457 = and i8 %5456, 1
  %5458 = xor i8 %5457, 1
  store i8 %5458, i8* %18, align 1
  %5459 = xor i32 %5450, %5449
  %5460 = lshr i32 %5459, 4
  %5461 = trunc i32 %5460 to i8
  %5462 = and i8 %5461, 1
  store i8 %5462, i8* %19, align 1
  %5463 = icmp eq i32 %5450, 0
  %5464 = zext i1 %5463 to i8
  store i8 %5464, i8* %20, align 1
  %5465 = lshr i32 %5450, 31
  %5466 = trunc i32 %5465 to i8
  store i8 %5466, i8* %21, align 1
  %5467 = lshr i32 %5449, 31
  %5468 = xor i32 %5465, %5467
  %5469 = add nuw nsw i32 %5468, %5465
  %5470 = icmp eq i32 %5469, 2
  %5471 = zext i1 %5470 to i8
  store i8 %5471, i8* %22, align 1
  %5472 = add i64 %5445, -16
  %5473 = add i64 %5444, 11
  store i64 %5473, i64* %3, align 8
  %5474 = inttoptr i64 %5472 to i32*
  %5475 = load i32, i32* %5474, align 4
  %5476 = zext i32 %5475 to i64
  store i64 %5476, i64* %RSI.i2015, align 8
  store i64 %5451, i64* %RDI.i6998, align 8
  %5477 = add i64 %5444, -4523
  %5478 = add i64 %5444, 18
  %5479 = load i64, i64* %6, align 8
  %5480 = add i64 %5479, -8
  %5481 = inttoptr i64 %5480 to i64*
  store i64 %5478, i64* %5481, align 8
  store i64 %5480, i64* %6, align 8
  store i64 %5477, i64* %3, align 8
  %call2_4846d8 = tail call %struct.Memory* @sub_483520.RDCost_for_4x4Blocks_Chroma(%struct.State* nonnull %0, i64 %5477, %struct.Memory* %MEMORY.8)
  %5482 = load i64, i64* %RAX.i1659, align 8
  %5483 = load i64, i64* %RBP.i, align 8
  %5484 = add i64 %5483, -352
  %5485 = load i64, i64* %3, align 8
  %5486 = add i64 %5485, 6
  store i64 %5486, i64* %3, align 8
  %5487 = trunc i64 %5482 to i32
  %5488 = inttoptr i64 %5484 to i32*
  %5489 = load i32, i32* %5488, align 4
  %5490 = add i32 %5489, %5487
  %5491 = zext i32 %5490 to i64
  store i64 %5491, i64* %RAX.i1659, align 8
  %5492 = icmp ult i32 %5490, %5487
  %5493 = icmp ult i32 %5490, %5489
  %5494 = or i1 %5492, %5493
  %5495 = zext i1 %5494 to i8
  store i8 %5495, i8* %17, align 1
  %5496 = and i32 %5490, 255
  %5497 = tail call i32 @llvm.ctpop.i32(i32 %5496)
  %5498 = trunc i32 %5497 to i8
  %5499 = and i8 %5498, 1
  %5500 = xor i8 %5499, 1
  store i8 %5500, i8* %18, align 1
  %5501 = xor i32 %5489, %5487
  %5502 = xor i32 %5501, %5490
  %5503 = lshr i32 %5502, 4
  %5504 = trunc i32 %5503 to i8
  %5505 = and i8 %5504, 1
  store i8 %5505, i8* %19, align 1
  %5506 = icmp eq i32 %5490, 0
  %5507 = zext i1 %5506 to i8
  store i8 %5507, i8* %20, align 1
  %5508 = lshr i32 %5490, 31
  %5509 = trunc i32 %5508 to i8
  store i8 %5509, i8* %21, align 1
  %5510 = lshr i32 %5487, 31
  %5511 = lshr i32 %5489, 31
  %5512 = xor i32 %5508, %5510
  %5513 = xor i32 %5508, %5511
  %5514 = add nuw nsw i32 %5512, %5513
  %5515 = icmp eq i32 %5514, 2
  %5516 = zext i1 %5515 to i8
  store i8 %5516, i8* %22, align 1
  %5517 = add i64 %5485, 12
  store i64 %5517, i64* %3, align 8
  store i32 %5490, i32* %5488, align 4
  %5518 = load i64, i64* %RBP.i, align 8
  %5519 = add i64 %5518, -48
  %5520 = load i64, i64* %3, align 8
  %5521 = add i64 %5520, 7
  store i64 %5521, i64* %3, align 8
  %5522 = inttoptr i64 %5519 to i32*
  store i32 0, i32* %5522, align 4
  %.pre585 = load i64, i64* %3, align 8
  br label %block_.L_4846f0

block_.L_4846f0:                                  ; preds = %block_.L_484792, %block_.L_4846be
  %5523 = phi i64 [ %5868, %block_.L_484792 ], [ %.pre585, %block_.L_4846be ]
  %5524 = load i64, i64* %RBP.i, align 8
  %5525 = add i64 %5524, -48
  %5526 = add i64 %5523, 4
  store i64 %5526, i64* %3, align 8
  %5527 = inttoptr i64 %5525 to i32*
  %5528 = load i32, i32* %5527, align 4
  %5529 = add i32 %5528, -4
  %5530 = icmp ult i32 %5528, 4
  %5531 = zext i1 %5530 to i8
  store i8 %5531, i8* %17, align 1
  %5532 = and i32 %5529, 255
  %5533 = tail call i32 @llvm.ctpop.i32(i32 %5532)
  %5534 = trunc i32 %5533 to i8
  %5535 = and i8 %5534, 1
  %5536 = xor i8 %5535, 1
  store i8 %5536, i8* %18, align 1
  %5537 = xor i32 %5529, %5528
  %5538 = lshr i32 %5537, 4
  %5539 = trunc i32 %5538 to i8
  %5540 = and i8 %5539, 1
  store i8 %5540, i8* %19, align 1
  %5541 = icmp eq i32 %5529, 0
  %5542 = zext i1 %5541 to i8
  store i8 %5542, i8* %20, align 1
  %5543 = lshr i32 %5529, 31
  %5544 = trunc i32 %5543 to i8
  store i8 %5544, i8* %21, align 1
  %5545 = lshr i32 %5528, 31
  %5546 = xor i32 %5543, %5545
  %5547 = add nuw nsw i32 %5546, %5545
  %5548 = icmp eq i32 %5547, 2
  %5549 = zext i1 %5548 to i8
  store i8 %5549, i8* %22, align 1
  %5550 = icmp ne i8 %5544, 0
  %5551 = xor i1 %5550, %5548
  %.v741 = select i1 %5551, i64 10, i64 181
  %5552 = add i64 %5523, %.v741
  store i64 %5552, i64* %3, align 8
  br i1 %5551, label %block_4846fa, label %block_.L_4847a5

block_4846fa:                                     ; preds = %block_.L_4846f0
  %5553 = add i64 %5524, -44
  %5554 = add i64 %5552, 7
  store i64 %5554, i64* %3, align 8
  %5555 = inttoptr i64 %5553 to i32*
  store i32 0, i32* %5555, align 4
  %.pre651 = load i64, i64* %3, align 8
  br label %block_.L_484701

block_.L_484701:                                  ; preds = %block_48470b, %block_4846fa
  %5556 = phi i64 [ %5838, %block_48470b ], [ %.pre651, %block_4846fa ]
  %5557 = load i64, i64* %RBP.i, align 8
  %5558 = add i64 %5557, -44
  %5559 = add i64 %5556, 4
  store i64 %5559, i64* %3, align 8
  %5560 = inttoptr i64 %5558 to i32*
  %5561 = load i32, i32* %5560, align 4
  %5562 = add i32 %5561, -4
  %5563 = icmp ult i32 %5561, 4
  %5564 = zext i1 %5563 to i8
  store i8 %5564, i8* %17, align 1
  %5565 = and i32 %5562, 255
  %5566 = tail call i32 @llvm.ctpop.i32(i32 %5565)
  %5567 = trunc i32 %5566 to i8
  %5568 = and i8 %5567, 1
  %5569 = xor i8 %5568, 1
  store i8 %5569, i8* %18, align 1
  %5570 = xor i32 %5562, %5561
  %5571 = lshr i32 %5570, 4
  %5572 = trunc i32 %5571 to i8
  %5573 = and i8 %5572, 1
  store i8 %5573, i8* %19, align 1
  %5574 = icmp eq i32 %5562, 0
  %5575 = zext i1 %5574 to i8
  store i8 %5575, i8* %20, align 1
  %5576 = lshr i32 %5562, 31
  %5577 = trunc i32 %5576 to i8
  store i8 %5577, i8* %21, align 1
  %5578 = lshr i32 %5561, 31
  %5579 = xor i32 %5576, %5578
  %5580 = add nuw nsw i32 %5579, %5578
  %5581 = icmp eq i32 %5580, 2
  %5582 = zext i1 %5581 to i8
  store i8 %5582, i8* %22, align 1
  %5583 = icmp ne i8 %5577, 0
  %5584 = xor i1 %5583, %5581
  %.v690 = select i1 %5584, i64 10, i64 145
  %5585 = add i64 %5556, %.v690
  store i64 %5585, i64* %3, align 8
  br i1 %5584, label %block_48470b, label %block_.L_484792

block_48470b:                                     ; preds = %block_.L_484701
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RAX.i1659, align 8
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX.i1588, align 8
  %5586 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %5587 = add i64 %5586, 13112
  store i64 %5587, i64* %RDX.i1943, align 8
  %5588 = icmp ugt i64 %5586, -13113
  %5589 = zext i1 %5588 to i8
  store i8 %5589, i8* %17, align 1
  %5590 = trunc i64 %5587 to i32
  %5591 = and i32 %5590, 255
  %5592 = tail call i32 @llvm.ctpop.i32(i32 %5591)
  %5593 = trunc i32 %5592 to i8
  %5594 = and i8 %5593, 1
  %5595 = xor i8 %5594, 1
  store i8 %5595, i8* %18, align 1
  %5596 = xor i64 %5586, 16
  %5597 = xor i64 %5596, %5587
  %5598 = lshr i64 %5597, 4
  %5599 = trunc i64 %5598 to i8
  %5600 = and i8 %5599, 1
  store i8 %5600, i8* %19, align 1
  %5601 = icmp eq i64 %5587, 0
  %5602 = zext i1 %5601 to i8
  store i8 %5602, i8* %20, align 1
  %5603 = lshr i64 %5587, 63
  %5604 = trunc i64 %5603 to i8
  store i8 %5604, i8* %21, align 1
  %5605 = lshr i64 %5586, 63
  %5606 = xor i64 %5603, %5605
  %5607 = add nuw nsw i64 %5606, %5603
  %5608 = icmp eq i64 %5607, 2
  %5609 = zext i1 %5608 to i8
  store i8 %5609, i8* %22, align 1
  %5610 = add i64 %5585, 39
  store i64 %5610, i64* %3, align 8
  %5611 = load i32, i32* %5560, align 4
  %5612 = sext i32 %5611 to i64
  %5613 = shl nsw i64 %5612, 6
  store i64 %5613, i64* %RSI.i2015, align 8
  %5614 = add i64 %5613, %5587
  store i64 %5614, i64* %RDX.i1943, align 8
  %5615 = icmp ult i64 %5614, %5587
  %5616 = icmp ult i64 %5614, %5613
  %5617 = or i1 %5615, %5616
  %5618 = zext i1 %5617 to i8
  store i8 %5618, i8* %17, align 1
  %5619 = trunc i64 %5614 to i32
  %5620 = and i32 %5619, 255
  %5621 = tail call i32 @llvm.ctpop.i32(i32 %5620)
  %5622 = trunc i32 %5621 to i8
  %5623 = and i8 %5622, 1
  %5624 = xor i8 %5623, 1
  store i8 %5624, i8* %18, align 1
  %5625 = xor i64 %5587, %5614
  %5626 = lshr i64 %5625, 4
  %5627 = trunc i64 %5626 to i8
  %5628 = and i8 %5627, 1
  store i8 %5628, i8* %19, align 1
  %5629 = icmp eq i64 %5614, 0
  %5630 = zext i1 %5629 to i8
  store i8 %5630, i8* %20, align 1
  %5631 = lshr i64 %5614, 63
  %5632 = trunc i64 %5631 to i8
  store i8 %5632, i8* %21, align 1
  %5633 = lshr i64 %5612, 57
  %5634 = and i64 %5633, 1
  %5635 = xor i64 %5631, %5603
  %5636 = xor i64 %5631, %5634
  %5637 = add nuw nsw i64 %5635, %5636
  %5638 = icmp eq i64 %5637, 2
  %5639 = zext i1 %5638 to i8
  store i8 %5639, i8* %22, align 1
  %5640 = load i64, i64* %RBP.i, align 8
  %5641 = add i64 %5640, -48
  %5642 = add i64 %5585, 50
  store i64 %5642, i64* %3, align 8
  %5643 = inttoptr i64 %5641 to i32*
  %5644 = load i32, i32* %5643, align 4
  %5645 = sext i32 %5644 to i64
  store i64 %5645, i64* %RSI.i2015, align 8
  %5646 = shl nsw i64 %5645, 2
  %5647 = add i64 %5646, %5614
  %5648 = add i64 %5585, 53
  store i64 %5648, i64* %3, align 8
  %5649 = inttoptr i64 %5647 to i32*
  %5650 = load i32, i32* %5649, align 4
  %5651 = zext i32 %5650 to i64
  store i64 %5651, i64* %RDI.i6998, align 8
  %5652 = add i64 %5640, -44
  %5653 = add i64 %5585, 57
  store i64 %5653, i64* %3, align 8
  %5654 = inttoptr i64 %5652 to i32*
  %5655 = load i32, i32* %5654, align 4
  %5656 = sext i32 %5655 to i64
  %5657 = shl nsw i64 %5656, 6
  store i64 %5657, i64* %RDX.i1943, align 8
  %5658 = load i64, i64* %RCX.i1588, align 8
  %5659 = add i64 %5657, %5658
  store i64 %5659, i64* %RCX.i1588, align 8
  %5660 = icmp ult i64 %5659, %5658
  %5661 = icmp ult i64 %5659, %5657
  %5662 = or i1 %5660, %5661
  %5663 = zext i1 %5662 to i8
  store i8 %5663, i8* %17, align 1
  %5664 = trunc i64 %5659 to i32
  %5665 = and i32 %5664, 255
  %5666 = tail call i32 @llvm.ctpop.i32(i32 %5665)
  %5667 = trunc i32 %5666 to i8
  %5668 = and i8 %5667, 1
  %5669 = xor i8 %5668, 1
  store i8 %5669, i8* %18, align 1
  %5670 = xor i64 %5658, %5659
  %5671 = lshr i64 %5670, 4
  %5672 = trunc i64 %5671 to i8
  %5673 = and i8 %5672, 1
  store i8 %5673, i8* %19, align 1
  %5674 = icmp eq i64 %5659, 0
  %5675 = zext i1 %5674 to i8
  store i8 %5675, i8* %20, align 1
  %5676 = lshr i64 %5659, 63
  %5677 = trunc i64 %5676 to i8
  store i8 %5677, i8* %21, align 1
  %5678 = lshr i64 %5658, 63
  %5679 = lshr i64 %5656, 57
  %5680 = and i64 %5679, 1
  %5681 = xor i64 %5676, %5678
  %5682 = xor i64 %5676, %5680
  %5683 = add nuw nsw i64 %5681, %5682
  %5684 = icmp eq i64 %5683, 2
  %5685 = zext i1 %5684 to i8
  store i8 %5685, i8* %22, align 1
  %5686 = add i64 %5585, 68
  store i64 %5686, i64* %3, align 8
  %5687 = load i32, i32* %5643, align 4
  %5688 = sext i32 %5687 to i64
  store i64 %5688, i64* %RDX.i1943, align 8
  %5689 = shl nsw i64 %5688, 2
  %5690 = add i64 %5689, %5659
  %5691 = add i64 %5585, 71
  store i64 %5691, i64* %3, align 8
  %5692 = inttoptr i64 %5690 to i32*
  store i32 %5650, i32* %5692, align 4
  %5693 = load i64, i64* %RBP.i, align 8
  %5694 = add i64 %5693, -44
  %5695 = load i64, i64* %3, align 8
  %5696 = add i64 %5695, 4
  store i64 %5696, i64* %3, align 8
  %5697 = inttoptr i64 %5694 to i32*
  %5698 = load i32, i32* %5697, align 4
  %5699 = sext i32 %5698 to i64
  %5700 = shl nsw i64 %5699, 6
  store i64 %5700, i64* %RCX.i1588, align 8
  %5701 = load i64, i64* %RAX.i1659, align 8
  %5702 = add i64 %5700, %5701
  store i64 %5702, i64* %RAX.i1659, align 8
  %5703 = icmp ult i64 %5702, %5701
  %5704 = icmp ult i64 %5702, %5700
  %5705 = or i1 %5703, %5704
  %5706 = zext i1 %5705 to i8
  store i8 %5706, i8* %17, align 1
  %5707 = trunc i64 %5702 to i32
  %5708 = and i32 %5707, 255
  %5709 = tail call i32 @llvm.ctpop.i32(i32 %5708)
  %5710 = trunc i32 %5709 to i8
  %5711 = and i8 %5710, 1
  %5712 = xor i8 %5711, 1
  store i8 %5712, i8* %18, align 1
  %5713 = xor i64 %5701, %5702
  %5714 = lshr i64 %5713, 4
  %5715 = trunc i64 %5714 to i8
  %5716 = and i8 %5715, 1
  store i8 %5716, i8* %19, align 1
  %5717 = icmp eq i64 %5702, 0
  %5718 = zext i1 %5717 to i8
  store i8 %5718, i8* %20, align 1
  %5719 = lshr i64 %5702, 63
  %5720 = trunc i64 %5719 to i8
  store i8 %5720, i8* %21, align 1
  %5721 = lshr i64 %5701, 63
  %5722 = lshr i64 %5699, 57
  %5723 = and i64 %5722, 1
  %5724 = xor i64 %5719, %5721
  %5725 = xor i64 %5719, %5723
  %5726 = add nuw nsw i64 %5724, %5725
  %5727 = icmp eq i64 %5726, 2
  %5728 = zext i1 %5727 to i8
  store i8 %5728, i8* %22, align 1
  %5729 = add i64 %5693, -48
  %5730 = add i64 %5695, 15
  store i64 %5730, i64* %3, align 8
  %5731 = inttoptr i64 %5729 to i32*
  %5732 = load i32, i32* %5731, align 4
  %5733 = sext i32 %5732 to i64
  store i64 %5733, i64* %RCX.i1588, align 8
  %5734 = shl nsw i64 %5733, 2
  %5735 = add i64 %5734, %5702
  %5736 = add i64 %5695, 18
  store i64 %5736, i64* %3, align 8
  %5737 = inttoptr i64 %5735 to i32*
  %5738 = load i32, i32* %5737, align 4
  %5739 = zext i32 %5738 to i64
  store i64 %5739, i64* %RDI.i6998, align 8
  %5740 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %5741 = add i64 %5740, 13112
  store i64 %5741, i64* %RAX.i1659, align 8
  %5742 = icmp ugt i64 %5740, -13113
  %5743 = zext i1 %5742 to i8
  store i8 %5743, i8* %17, align 1
  %5744 = trunc i64 %5741 to i32
  %5745 = and i32 %5744, 255
  %5746 = tail call i32 @llvm.ctpop.i32(i32 %5745)
  %5747 = trunc i32 %5746 to i8
  %5748 = and i8 %5747, 1
  %5749 = xor i8 %5748, 1
  store i8 %5749, i8* %18, align 1
  %5750 = xor i64 %5740, 16
  %5751 = xor i64 %5750, %5741
  %5752 = lshr i64 %5751, 4
  %5753 = trunc i64 %5752 to i8
  %5754 = and i8 %5753, 1
  store i8 %5754, i8* %19, align 1
  %5755 = icmp eq i64 %5741, 0
  %5756 = zext i1 %5755 to i8
  store i8 %5756, i8* %20, align 1
  %5757 = lshr i64 %5741, 63
  %5758 = trunc i64 %5757 to i8
  store i8 %5758, i8* %21, align 1
  %5759 = lshr i64 %5740, 63
  %5760 = xor i64 %5757, %5759
  %5761 = add nuw nsw i64 %5760, %5757
  %5762 = icmp eq i64 %5761, 2
  %5763 = zext i1 %5762 to i8
  store i8 %5763, i8* %22, align 1
  %5764 = load i64, i64* %RBP.i, align 8
  %5765 = add i64 %5764, -44
  %5766 = add i64 %5695, 36
  store i64 %5766, i64* %3, align 8
  %5767 = inttoptr i64 %5765 to i32*
  %5768 = load i32, i32* %5767, align 4
  %5769 = sext i32 %5768 to i64
  %5770 = shl nsw i64 %5769, 6
  store i64 %5770, i64* %RCX.i1588, align 8
  %5771 = add i64 %5770, %5741
  store i64 %5771, i64* %RAX.i1659, align 8
  %5772 = icmp ult i64 %5771, %5741
  %5773 = icmp ult i64 %5771, %5770
  %5774 = or i1 %5772, %5773
  %5775 = zext i1 %5774 to i8
  store i8 %5775, i8* %17, align 1
  %5776 = trunc i64 %5771 to i32
  %5777 = and i32 %5776, 255
  %5778 = tail call i32 @llvm.ctpop.i32(i32 %5777)
  %5779 = trunc i32 %5778 to i8
  %5780 = and i8 %5779, 1
  %5781 = xor i8 %5780, 1
  store i8 %5781, i8* %18, align 1
  %5782 = xor i64 %5741, %5771
  %5783 = lshr i64 %5782, 4
  %5784 = trunc i64 %5783 to i8
  %5785 = and i8 %5784, 1
  store i8 %5785, i8* %19, align 1
  %5786 = icmp eq i64 %5771, 0
  %5787 = zext i1 %5786 to i8
  store i8 %5787, i8* %20, align 1
  %5788 = lshr i64 %5771, 63
  %5789 = trunc i64 %5788 to i8
  store i8 %5789, i8* %21, align 1
  %5790 = lshr i64 %5769, 57
  %5791 = and i64 %5790, 1
  %5792 = xor i64 %5788, %5757
  %5793 = xor i64 %5788, %5791
  %5794 = add nuw nsw i64 %5792, %5793
  %5795 = icmp eq i64 %5794, 2
  %5796 = zext i1 %5795 to i8
  store i8 %5796, i8* %22, align 1
  %5797 = add i64 %5764, -48
  %5798 = add i64 %5695, 47
  store i64 %5798, i64* %3, align 8
  %5799 = inttoptr i64 %5797 to i32*
  %5800 = load i32, i32* %5799, align 4
  %5801 = sext i32 %5800 to i64
  store i64 %5801, i64* %RCX.i1588, align 8
  %5802 = shl nsw i64 %5801, 2
  %5803 = add i64 %5802, %5771
  %5804 = load i32, i32* %EDI.i1741, align 4
  %5805 = add i64 %5695, 50
  store i64 %5805, i64* %3, align 8
  %5806 = inttoptr i64 %5803 to i32*
  store i32 %5804, i32* %5806, align 4
  %5807 = load i64, i64* %RBP.i, align 8
  %5808 = add i64 %5807, -44
  %5809 = load i64, i64* %3, align 8
  %5810 = add i64 %5809, 3
  store i64 %5810, i64* %3, align 8
  %5811 = inttoptr i64 %5808 to i32*
  %5812 = load i32, i32* %5811, align 4
  %5813 = add i32 %5812, 1
  %5814 = zext i32 %5813 to i64
  store i64 %5814, i64* %RAX.i1659, align 8
  %5815 = icmp eq i32 %5812, -1
  %5816 = icmp eq i32 %5813, 0
  %5817 = or i1 %5815, %5816
  %5818 = zext i1 %5817 to i8
  store i8 %5818, i8* %17, align 1
  %5819 = and i32 %5813, 255
  %5820 = tail call i32 @llvm.ctpop.i32(i32 %5819)
  %5821 = trunc i32 %5820 to i8
  %5822 = and i8 %5821, 1
  %5823 = xor i8 %5822, 1
  store i8 %5823, i8* %18, align 1
  %5824 = xor i32 %5813, %5812
  %5825 = lshr i32 %5824, 4
  %5826 = trunc i32 %5825 to i8
  %5827 = and i8 %5826, 1
  store i8 %5827, i8* %19, align 1
  %5828 = zext i1 %5816 to i8
  store i8 %5828, i8* %20, align 1
  %5829 = lshr i32 %5813, 31
  %5830 = trunc i32 %5829 to i8
  store i8 %5830, i8* %21, align 1
  %5831 = lshr i32 %5812, 31
  %5832 = xor i32 %5829, %5831
  %5833 = add nuw nsw i32 %5832, %5829
  %5834 = icmp eq i32 %5833, 2
  %5835 = zext i1 %5834 to i8
  store i8 %5835, i8* %22, align 1
  %5836 = add i64 %5809, 9
  store i64 %5836, i64* %3, align 8
  store i32 %5813, i32* %5811, align 4
  %5837 = load i64, i64* %3, align 8
  %5838 = add i64 %5837, -140
  store i64 %5838, i64* %3, align 8
  br label %block_.L_484701

block_.L_484792:                                  ; preds = %block_.L_484701
  %5839 = add i64 %5557, -48
  %5840 = add i64 %5585, 8
  store i64 %5840, i64* %3, align 8
  %5841 = inttoptr i64 %5839 to i32*
  %5842 = load i32, i32* %5841, align 4
  %5843 = add i32 %5842, 1
  %5844 = zext i32 %5843 to i64
  store i64 %5844, i64* %RAX.i1659, align 8
  %5845 = icmp eq i32 %5842, -1
  %5846 = icmp eq i32 %5843, 0
  %5847 = or i1 %5845, %5846
  %5848 = zext i1 %5847 to i8
  store i8 %5848, i8* %17, align 1
  %5849 = and i32 %5843, 255
  %5850 = tail call i32 @llvm.ctpop.i32(i32 %5849)
  %5851 = trunc i32 %5850 to i8
  %5852 = and i8 %5851, 1
  %5853 = xor i8 %5852, 1
  store i8 %5853, i8* %18, align 1
  %5854 = xor i32 %5843, %5842
  %5855 = lshr i32 %5854, 4
  %5856 = trunc i32 %5855 to i8
  %5857 = and i8 %5856, 1
  store i8 %5857, i8* %19, align 1
  %5858 = zext i1 %5846 to i8
  store i8 %5858, i8* %20, align 1
  %5859 = lshr i32 %5843, 31
  %5860 = trunc i32 %5859 to i8
  store i8 %5860, i8* %21, align 1
  %5861 = lshr i32 %5842, 31
  %5862 = xor i32 %5859, %5861
  %5863 = add nuw nsw i32 %5862, %5859
  %5864 = icmp eq i32 %5863, 2
  %5865 = zext i1 %5864 to i8
  store i8 %5865, i8* %22, align 1
  %5866 = add i64 %5585, 14
  store i64 %5866, i64* %3, align 8
  store i32 %5843, i32* %5841, align 4
  %5867 = load i64, i64* %3, align 8
  %5868 = add i64 %5867, -176
  store i64 %5868, i64* %3, align 8
  br label %block_.L_4846f0

block_.L_4847a5:                                  ; preds = %block_.L_4846f0
  store i64 1, i64* %RDX.i1943, align 8
  %5869 = add i64 %5524, -12
  %5870 = add i64 %5552, 8
  store i64 %5870, i64* %3, align 8
  %5871 = inttoptr i64 %5869 to i32*
  %5872 = load i32, i32* %5871, align 4
  %5873 = add i32 %5872, 8
  %5874 = zext i32 %5873 to i64
  store i64 %5874, i64* %RAX.i1659, align 8
  %5875 = icmp ugt i32 %5872, -9
  %5876 = zext i1 %5875 to i8
  store i8 %5876, i8* %17, align 1
  %5877 = and i32 %5873, 255
  %5878 = tail call i32 @llvm.ctpop.i32(i32 %5877)
  %5879 = trunc i32 %5878 to i8
  %5880 = and i8 %5879, 1
  %5881 = xor i8 %5880, 1
  store i8 %5881, i8* %18, align 1
  %5882 = xor i32 %5873, %5872
  %5883 = lshr i32 %5882, 4
  %5884 = trunc i32 %5883 to i8
  %5885 = and i8 %5884, 1
  store i8 %5885, i8* %19, align 1
  %5886 = icmp eq i32 %5873, 0
  %5887 = zext i1 %5886 to i8
  store i8 %5887, i8* %20, align 1
  %5888 = lshr i32 %5873, 31
  %5889 = trunc i32 %5888 to i8
  store i8 %5889, i8* %21, align 1
  %5890 = lshr i32 %5872, 31
  %5891 = xor i32 %5888, %5890
  %5892 = add nuw nsw i32 %5891, %5888
  %5893 = icmp eq i32 %5892, 2
  %5894 = zext i1 %5893 to i8
  store i8 %5894, i8* %22, align 1
  %5895 = add i64 %5524, -16
  %5896 = add i64 %5552, 14
  store i64 %5896, i64* %3, align 8
  %5897 = inttoptr i64 %5895 to i32*
  %5898 = load i32, i32* %5897, align 4
  %5899 = zext i32 %5898 to i64
  store i64 %5899, i64* %RSI.i2015, align 8
  store i64 %5874, i64* %RDI.i6998, align 8
  %5900 = add i64 %5552, -4741
  %5901 = add i64 %5552, 21
  %5902 = load i64, i64* %6, align 8
  %5903 = add i64 %5902, -8
  %5904 = inttoptr i64 %5903 to i64*
  store i64 %5901, i64* %5904, align 8
  store i64 %5903, i64* %6, align 8
  store i64 %5900, i64* %3, align 8
  %call2_4847b5 = tail call %struct.Memory* @sub_483520.RDCost_for_4x4Blocks_Chroma(%struct.State* nonnull %0, i64 %5900, %struct.Memory* %MEMORY.8)
  %5905 = load i64, i64* %RAX.i1659, align 8
  %5906 = load i64, i64* %RBP.i, align 8
  %5907 = add i64 %5906, -352
  %5908 = load i64, i64* %3, align 8
  %5909 = add i64 %5908, 6
  store i64 %5909, i64* %3, align 8
  %5910 = trunc i64 %5905 to i32
  %5911 = inttoptr i64 %5907 to i32*
  %5912 = load i32, i32* %5911, align 4
  %5913 = add i32 %5912, %5910
  %5914 = zext i32 %5913 to i64
  store i64 %5914, i64* %RAX.i1659, align 8
  %5915 = icmp ult i32 %5913, %5910
  %5916 = icmp ult i32 %5913, %5912
  %5917 = or i1 %5915, %5916
  %5918 = zext i1 %5917 to i8
  store i8 %5918, i8* %17, align 1
  %5919 = and i32 %5913, 255
  %5920 = tail call i32 @llvm.ctpop.i32(i32 %5919)
  %5921 = trunc i32 %5920 to i8
  %5922 = and i8 %5921, 1
  %5923 = xor i8 %5922, 1
  store i8 %5923, i8* %18, align 1
  %5924 = xor i32 %5912, %5910
  %5925 = xor i32 %5924, %5913
  %5926 = lshr i32 %5925, 4
  %5927 = trunc i32 %5926 to i8
  %5928 = and i8 %5927, 1
  store i8 %5928, i8* %19, align 1
  %5929 = icmp eq i32 %5913, 0
  %5930 = zext i1 %5929 to i8
  store i8 %5930, i8* %20, align 1
  %5931 = lshr i32 %5913, 31
  %5932 = trunc i32 %5931 to i8
  store i8 %5932, i8* %21, align 1
  %5933 = lshr i32 %5910, 31
  %5934 = lshr i32 %5912, 31
  %5935 = xor i32 %5931, %5933
  %5936 = xor i32 %5931, %5934
  %5937 = add nuw nsw i32 %5935, %5936
  %5938 = icmp eq i32 %5937, 2
  %5939 = zext i1 %5938 to i8
  store i8 %5939, i8* %22, align 1
  %5940 = add i64 %5908, 12
  store i64 %5940, i64* %3, align 8
  store i32 %5913, i32* %5911, align 4
  %5941 = load i64, i64* %3, align 8
  %5942 = load i64, i64* bitcast (%G_0x6cc628_type* @G_0x6cc628 to i64*), align 8
  store i64 %5942, i64* %RDI.i6998, align 8
  %5943 = add i64 %5941, 103482
  %5944 = add i64 %5941, 13
  %5945 = load i64, i64* %6, align 8
  %5946 = add i64 %5945, -8
  %5947 = inttoptr i64 %5946 to i64*
  store i64 %5944, i64* %5947, align 8
  store i64 %5946, i64* %6, align 8
  store i64 %5943, i64* %3, align 8
  %call2_4847ce = tail call %struct.Memory* @sub_49dc00.reset_coding_state(%struct.State* nonnull %0, i64 %5943, %struct.Memory* %MEMORY.8)
  %5948 = load i64, i64* %RBP.i, align 8
  %5949 = add i64 %5948, -48
  %5950 = load i64, i64* %3, align 8
  %5951 = add i64 %5950, 7
  store i64 %5951, i64* %3, align 8
  %5952 = inttoptr i64 %5949 to i32*
  store i32 0, i32* %5952, align 4
  %.pre586 = load i64, i64* %3, align 8
  br label %block_.L_4847da

block_.L_4847da:                                  ; preds = %block_.L_484840, %block_.L_4847a5
  %5953 = phi i64 [ %6184, %block_.L_484840 ], [ %.pre586, %block_.L_4847a5 ]
  %5954 = load i64, i64* %RBP.i, align 8
  %5955 = add i64 %5954, -48
  %5956 = add i64 %5953, 4
  store i64 %5956, i64* %3, align 8
  %5957 = inttoptr i64 %5955 to i32*
  %5958 = load i32, i32* %5957, align 4
  %5959 = add i32 %5958, -4
  %5960 = icmp ult i32 %5958, 4
  %5961 = zext i1 %5960 to i8
  store i8 %5961, i8* %17, align 1
  %5962 = and i32 %5959, 255
  %5963 = tail call i32 @llvm.ctpop.i32(i32 %5962)
  %5964 = trunc i32 %5963 to i8
  %5965 = and i8 %5964, 1
  %5966 = xor i8 %5965, 1
  store i8 %5966, i8* %18, align 1
  %5967 = xor i32 %5959, %5958
  %5968 = lshr i32 %5967, 4
  %5969 = trunc i32 %5968 to i8
  %5970 = and i8 %5969, 1
  store i8 %5970, i8* %19, align 1
  %5971 = icmp eq i32 %5959, 0
  %5972 = zext i1 %5971 to i8
  store i8 %5972, i8* %20, align 1
  %5973 = lshr i32 %5959, 31
  %5974 = trunc i32 %5973 to i8
  store i8 %5974, i8* %21, align 1
  %5975 = lshr i32 %5958, 31
  %5976 = xor i32 %5973, %5975
  %5977 = add nuw nsw i32 %5976, %5975
  %5978 = icmp eq i32 %5977, 2
  %5979 = zext i1 %5978 to i8
  store i8 %5979, i8* %22, align 1
  %5980 = icmp ne i8 %5974, 0
  %5981 = xor i1 %5980, %5978
  %.v742 = select i1 %5981, i64 10, i64 121
  %5982 = add i64 %5953, %.v742
  store i64 %5982, i64* %3, align 8
  br i1 %5981, label %block_4847e4, label %block_.L_484853

block_4847e4:                                     ; preds = %block_.L_4847da
  %5983 = add i64 %5954, -44
  %5984 = add i64 %5982, 7
  store i64 %5984, i64* %3, align 8
  %5985 = inttoptr i64 %5983 to i32*
  store i32 0, i32* %5985, align 4
  %.pre650 = load i64, i64* %3, align 8
  br label %block_.L_4847eb

block_.L_4847eb:                                  ; preds = %block_4847f5, %block_4847e4
  %5986 = phi i64 [ %6154, %block_4847f5 ], [ %.pre650, %block_4847e4 ]
  %5987 = load i64, i64* %RBP.i, align 8
  %5988 = add i64 %5987, -44
  %5989 = add i64 %5986, 4
  store i64 %5989, i64* %3, align 8
  %5990 = inttoptr i64 %5988 to i32*
  %5991 = load i32, i32* %5990, align 4
  %5992 = add i32 %5991, -4
  %5993 = icmp ult i32 %5991, 4
  %5994 = zext i1 %5993 to i8
  store i8 %5994, i8* %17, align 1
  %5995 = and i32 %5992, 255
  %5996 = tail call i32 @llvm.ctpop.i32(i32 %5995)
  %5997 = trunc i32 %5996 to i8
  %5998 = and i8 %5997, 1
  %5999 = xor i8 %5998, 1
  store i8 %5999, i8* %18, align 1
  %6000 = xor i32 %5992, %5991
  %6001 = lshr i32 %6000, 4
  %6002 = trunc i32 %6001 to i8
  %6003 = and i8 %6002, 1
  store i8 %6003, i8* %19, align 1
  %6004 = icmp eq i32 %5992, 0
  %6005 = zext i1 %6004 to i8
  store i8 %6005, i8* %20, align 1
  %6006 = lshr i32 %5992, 31
  %6007 = trunc i32 %6006 to i8
  store i8 %6007, i8* %21, align 1
  %6008 = lshr i32 %5991, 31
  %6009 = xor i32 %6006, %6008
  %6010 = add nuw nsw i32 %6009, %6008
  %6011 = icmp eq i32 %6010, 2
  %6012 = zext i1 %6011 to i8
  store i8 %6012, i8* %22, align 1
  %6013 = icmp ne i8 %6007, 0
  %6014 = xor i1 %6013, %6011
  %.v689 = select i1 %6014, i64 10, i64 85
  %6015 = add i64 %5986, %.v689
  store i64 %6015, i64* %3, align 8
  br i1 %6014, label %block_4847f5, label %block_.L_484840

block_4847f5:                                     ; preds = %block_.L_4847eb
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RAX.i1659, align 8
  %6016 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %6017 = add i64 %6016, 13112
  store i64 %6017, i64* %RCX.i1588, align 8
  %6018 = icmp ugt i64 %6016, -13113
  %6019 = zext i1 %6018 to i8
  store i8 %6019, i8* %17, align 1
  %6020 = trunc i64 %6017 to i32
  %6021 = and i32 %6020, 255
  %6022 = tail call i32 @llvm.ctpop.i32(i32 %6021)
  %6023 = trunc i32 %6022 to i8
  %6024 = and i8 %6023, 1
  %6025 = xor i8 %6024, 1
  store i8 %6025, i8* %18, align 1
  %6026 = xor i64 %6016, 16
  %6027 = xor i64 %6026, %6017
  %6028 = lshr i64 %6027, 4
  %6029 = trunc i64 %6028 to i8
  %6030 = and i8 %6029, 1
  store i8 %6030, i8* %19, align 1
  %6031 = icmp eq i64 %6017, 0
  %6032 = zext i1 %6031 to i8
  store i8 %6032, i8* %20, align 1
  %6033 = lshr i64 %6017, 63
  %6034 = trunc i64 %6033 to i8
  store i8 %6034, i8* %21, align 1
  %6035 = lshr i64 %6016, 63
  %6036 = xor i64 %6033, %6035
  %6037 = add nuw nsw i64 %6036, %6033
  %6038 = icmp eq i64 %6037, 2
  %6039 = zext i1 %6038 to i8
  store i8 %6039, i8* %22, align 1
  %6040 = add i64 %6015, 29
  store i64 %6040, i64* %3, align 8
  %6041 = load i32, i32* %5990, align 4
  %6042 = sext i32 %6041 to i64
  %6043 = shl nsw i64 %6042, 6
  store i64 %6043, i64* %RDX.i1943, align 8
  %6044 = add i64 %6043, %6017
  store i64 %6044, i64* %RCX.i1588, align 8
  %6045 = icmp ult i64 %6044, %6017
  %6046 = icmp ult i64 %6044, %6043
  %6047 = or i1 %6045, %6046
  %6048 = zext i1 %6047 to i8
  store i8 %6048, i8* %17, align 1
  %6049 = trunc i64 %6044 to i32
  %6050 = and i32 %6049, 255
  %6051 = tail call i32 @llvm.ctpop.i32(i32 %6050)
  %6052 = trunc i32 %6051 to i8
  %6053 = and i8 %6052, 1
  %6054 = xor i8 %6053, 1
  store i8 %6054, i8* %18, align 1
  %6055 = xor i64 %6017, %6044
  %6056 = lshr i64 %6055, 4
  %6057 = trunc i64 %6056 to i8
  %6058 = and i8 %6057, 1
  store i8 %6058, i8* %19, align 1
  %6059 = icmp eq i64 %6044, 0
  %6060 = zext i1 %6059 to i8
  store i8 %6060, i8* %20, align 1
  %6061 = lshr i64 %6044, 63
  %6062 = trunc i64 %6061 to i8
  store i8 %6062, i8* %21, align 1
  %6063 = lshr i64 %6042, 57
  %6064 = and i64 %6063, 1
  %6065 = xor i64 %6061, %6033
  %6066 = xor i64 %6061, %6064
  %6067 = add nuw nsw i64 %6065, %6066
  %6068 = icmp eq i64 %6067, 2
  %6069 = zext i1 %6068 to i8
  store i8 %6069, i8* %22, align 1
  %6070 = load i64, i64* %RBP.i, align 8
  %6071 = add i64 %6070, -48
  %6072 = add i64 %6015, 40
  store i64 %6072, i64* %3, align 8
  %6073 = inttoptr i64 %6071 to i32*
  %6074 = load i32, i32* %6073, align 4
  %6075 = sext i32 %6074 to i64
  store i64 %6075, i64* %RDX.i1943, align 8
  %6076 = shl nsw i64 %6075, 2
  %6077 = add i64 %6076, %6044
  %6078 = add i64 %6015, 43
  store i64 %6078, i64* %3, align 8
  %6079 = inttoptr i64 %6077 to i32*
  %6080 = load i32, i32* %6079, align 4
  %6081 = zext i32 %6080 to i64
  store i64 %6081, i64* %RSI.i2015, align 8
  %6082 = add i64 %6070, -44
  %6083 = add i64 %6015, 47
  store i64 %6083, i64* %3, align 8
  %6084 = inttoptr i64 %6082 to i32*
  %6085 = load i32, i32* %6084, align 4
  %6086 = sext i32 %6085 to i64
  %6087 = shl nsw i64 %6086, 6
  store i64 %6087, i64* %RCX.i1588, align 8
  %6088 = load i64, i64* %RAX.i1659, align 8
  %6089 = add i64 %6087, %6088
  store i64 %6089, i64* %RAX.i1659, align 8
  %6090 = icmp ult i64 %6089, %6088
  %6091 = icmp ult i64 %6089, %6087
  %6092 = or i1 %6090, %6091
  %6093 = zext i1 %6092 to i8
  store i8 %6093, i8* %17, align 1
  %6094 = trunc i64 %6089 to i32
  %6095 = and i32 %6094, 255
  %6096 = tail call i32 @llvm.ctpop.i32(i32 %6095)
  %6097 = trunc i32 %6096 to i8
  %6098 = and i8 %6097, 1
  %6099 = xor i8 %6098, 1
  store i8 %6099, i8* %18, align 1
  %6100 = xor i64 %6088, %6089
  %6101 = lshr i64 %6100, 4
  %6102 = trunc i64 %6101 to i8
  %6103 = and i8 %6102, 1
  store i8 %6103, i8* %19, align 1
  %6104 = icmp eq i64 %6089, 0
  %6105 = zext i1 %6104 to i8
  store i8 %6105, i8* %20, align 1
  %6106 = lshr i64 %6089, 63
  %6107 = trunc i64 %6106 to i8
  store i8 %6107, i8* %21, align 1
  %6108 = lshr i64 %6088, 63
  %6109 = lshr i64 %6086, 57
  %6110 = and i64 %6109, 1
  %6111 = xor i64 %6106, %6108
  %6112 = xor i64 %6106, %6110
  %6113 = add nuw nsw i64 %6111, %6112
  %6114 = icmp eq i64 %6113, 2
  %6115 = zext i1 %6114 to i8
  store i8 %6115, i8* %22, align 1
  %6116 = add i64 %6015, 58
  store i64 %6116, i64* %3, align 8
  %6117 = load i32, i32* %6073, align 4
  %6118 = sext i32 %6117 to i64
  store i64 %6118, i64* %RCX.i1588, align 8
  %6119 = shl nsw i64 %6118, 2
  %6120 = add i64 %6119, %6089
  %6121 = add i64 %6015, 61
  store i64 %6121, i64* %3, align 8
  %6122 = inttoptr i64 %6120 to i32*
  store i32 %6080, i32* %6122, align 4
  %6123 = load i64, i64* %RBP.i, align 8
  %6124 = add i64 %6123, -44
  %6125 = load i64, i64* %3, align 8
  %6126 = add i64 %6125, 3
  store i64 %6126, i64* %3, align 8
  %6127 = inttoptr i64 %6124 to i32*
  %6128 = load i32, i32* %6127, align 4
  %6129 = add i32 %6128, 1
  %6130 = zext i32 %6129 to i64
  store i64 %6130, i64* %RAX.i1659, align 8
  %6131 = icmp eq i32 %6128, -1
  %6132 = icmp eq i32 %6129, 0
  %6133 = or i1 %6131, %6132
  %6134 = zext i1 %6133 to i8
  store i8 %6134, i8* %17, align 1
  %6135 = and i32 %6129, 255
  %6136 = tail call i32 @llvm.ctpop.i32(i32 %6135)
  %6137 = trunc i32 %6136 to i8
  %6138 = and i8 %6137, 1
  %6139 = xor i8 %6138, 1
  store i8 %6139, i8* %18, align 1
  %6140 = xor i32 %6129, %6128
  %6141 = lshr i32 %6140, 4
  %6142 = trunc i32 %6141 to i8
  %6143 = and i8 %6142, 1
  store i8 %6143, i8* %19, align 1
  %6144 = zext i1 %6132 to i8
  store i8 %6144, i8* %20, align 1
  %6145 = lshr i32 %6129, 31
  %6146 = trunc i32 %6145 to i8
  store i8 %6146, i8* %21, align 1
  %6147 = lshr i32 %6128, 31
  %6148 = xor i32 %6145, %6147
  %6149 = add nuw nsw i32 %6148, %6145
  %6150 = icmp eq i32 %6149, 2
  %6151 = zext i1 %6150 to i8
  store i8 %6151, i8* %22, align 1
  %6152 = add i64 %6125, 9
  store i64 %6152, i64* %3, align 8
  store i32 %6129, i32* %6127, align 4
  %6153 = load i64, i64* %3, align 8
  %6154 = add i64 %6153, -80
  store i64 %6154, i64* %3, align 8
  br label %block_.L_4847eb

block_.L_484840:                                  ; preds = %block_.L_4847eb
  %6155 = add i64 %5987, -48
  %6156 = add i64 %6015, 8
  store i64 %6156, i64* %3, align 8
  %6157 = inttoptr i64 %6155 to i32*
  %6158 = load i32, i32* %6157, align 4
  %6159 = add i32 %6158, 1
  %6160 = zext i32 %6159 to i64
  store i64 %6160, i64* %RAX.i1659, align 8
  %6161 = icmp eq i32 %6158, -1
  %6162 = icmp eq i32 %6159, 0
  %6163 = or i1 %6161, %6162
  %6164 = zext i1 %6163 to i8
  store i8 %6164, i8* %17, align 1
  %6165 = and i32 %6159, 255
  %6166 = tail call i32 @llvm.ctpop.i32(i32 %6165)
  %6167 = trunc i32 %6166 to i8
  %6168 = and i8 %6167, 1
  %6169 = xor i8 %6168, 1
  store i8 %6169, i8* %18, align 1
  %6170 = xor i32 %6159, %6158
  %6171 = lshr i32 %6170, 4
  %6172 = trunc i32 %6171 to i8
  %6173 = and i8 %6172, 1
  store i8 %6173, i8* %19, align 1
  %6174 = zext i1 %6162 to i8
  store i8 %6174, i8* %20, align 1
  %6175 = lshr i32 %6159, 31
  %6176 = trunc i32 %6175 to i8
  store i8 %6176, i8* %21, align 1
  %6177 = lshr i32 %6158, 31
  %6178 = xor i32 %6175, %6177
  %6179 = add nuw nsw i32 %6178, %6175
  %6180 = icmp eq i32 %6179, 2
  %6181 = zext i1 %6180 to i8
  store i8 %6181, i8* %22, align 1
  %6182 = add i64 %6015, 14
  store i64 %6182, i64* %3, align 8
  store i32 %6159, i32* %6157, align 4
  %6183 = load i64, i64* %3, align 8
  %6184 = add i64 %6183, -116
  store i64 %6184, i64* %3, align 8
  br label %block_.L_4847da

block_.L_484853:                                  ; preds = %block_.L_4847da
  %6185 = add i64 %5982, 7
  store i64 %6185, i64* %3, align 8
  store i32 0, i32* %5957, align 4
  %.pre587 = load i64, i64* %3, align 8
  br label %block_.L_48485a

block_.L_48485a:                                  ; preds = %block_.L_484ecf, %block_.L_484853
  %6186 = phi i64 [ %9258, %block_.L_484ecf ], [ %.pre587, %block_.L_484853 ]
  %6187 = load i64, i64* %RBP.i, align 8
  %6188 = add i64 %6187, -48
  %6189 = add i64 %6186, 4
  store i64 %6189, i64* %3, align 8
  %6190 = inttoptr i64 %6188 to i32*
  %6191 = load i32, i32* %6190, align 4
  %6192 = add i32 %6191, -4
  %6193 = icmp ult i32 %6191, 4
  %6194 = zext i1 %6193 to i8
  store i8 %6194, i8* %17, align 1
  %6195 = and i32 %6192, 255
  %6196 = tail call i32 @llvm.ctpop.i32(i32 %6195)
  %6197 = trunc i32 %6196 to i8
  %6198 = and i8 %6197, 1
  %6199 = xor i8 %6198, 1
  store i8 %6199, i8* %18, align 1
  %6200 = xor i32 %6192, %6191
  %6201 = lshr i32 %6200, 4
  %6202 = trunc i32 %6201 to i8
  %6203 = and i8 %6202, 1
  store i8 %6203, i8* %19, align 1
  %6204 = icmp eq i32 %6192, 0
  %6205 = zext i1 %6204 to i8
  store i8 %6205, i8* %20, align 1
  %6206 = lshr i32 %6192, 31
  %6207 = trunc i32 %6206 to i8
  store i8 %6207, i8* %21, align 1
  %6208 = lshr i32 %6191, 31
  %6209 = xor i32 %6206, %6208
  %6210 = add nuw nsw i32 %6209, %6208
  %6211 = icmp eq i32 %6210, 2
  %6212 = zext i1 %6211 to i8
  store i8 %6212, i8* %22, align 1
  %6213 = icmp ne i8 %6207, 0
  %6214 = xor i1 %6213, %6211
  %.v743 = select i1 %6214, i64 10, i64 1672
  %6215 = add i64 %6186, %.v743
  store i64 %6215, i64* %3, align 8
  br i1 %6214, label %block_484864, label %block_.L_484ee2

block_484864:                                     ; preds = %block_.L_48485a
  %6216 = add i64 %6187, -44
  %6217 = add i64 %6215, 7
  store i64 %6217, i64* %3, align 8
  %6218 = inttoptr i64 %6216 to i32*
  store i32 0, i32* %6218, align 4
  %.pre640 = load i64, i64* %3, align 8
  br label %block_.L_48486b

block_.L_48486b:                                  ; preds = %block_.L_484e85, %block_484864
  %6219 = phi i64 [ %9228, %block_.L_484e85 ], [ %.pre640, %block_484864 ]
  %6220 = load i64, i64* %RBP.i, align 8
  %6221 = add i64 %6220, -44
  %6222 = add i64 %6219, 4
  store i64 %6222, i64* %3, align 8
  %6223 = inttoptr i64 %6221 to i32*
  %6224 = load i32, i32* %6223, align 4
  %6225 = add i32 %6224, -4
  %6226 = icmp ult i32 %6224, 4
  %6227 = zext i1 %6226 to i8
  store i8 %6227, i8* %17, align 1
  %6228 = and i32 %6225, 255
  %6229 = tail call i32 @llvm.ctpop.i32(i32 %6228)
  %6230 = trunc i32 %6229 to i8
  %6231 = and i8 %6230, 1
  %6232 = xor i8 %6231, 1
  store i8 %6232, i8* %18, align 1
  %6233 = xor i32 %6225, %6224
  %6234 = lshr i32 %6233, 4
  %6235 = trunc i32 %6234 to i8
  %6236 = and i8 %6235, 1
  store i8 %6236, i8* %19, align 1
  %6237 = icmp eq i32 %6225, 0
  %6238 = zext i1 %6237 to i8
  store i8 %6238, i8* %20, align 1
  %6239 = lshr i32 %6225, 31
  %6240 = trunc i32 %6239 to i8
  store i8 %6240, i8* %21, align 1
  %6241 = lshr i32 %6224, 31
  %6242 = xor i32 %6239, %6241
  %6243 = add nuw nsw i32 %6242, %6241
  %6244 = icmp eq i32 %6243, 2
  %6245 = zext i1 %6244 to i8
  store i8 %6245, i8* %22, align 1
  %6246 = icmp ne i8 %6240, 0
  %6247 = xor i1 %6246, %6244
  %.v688 = select i1 %6247, i64 10, i64 1636
  %6248 = add i64 %6219, %.v688
  store i64 %6248, i64* %3, align 8
  br i1 %6247, label %block_484875, label %block_.L_484ecf

block_484875:                                     ; preds = %block_.L_48486b
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX.i1588, align 8
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RDX.i1943, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RSI.i2015, align 8
  %6249 = add i64 %6248, 36
  store i64 %6249, i64* %3, align 8
  %6250 = load i32, i32* %6223, align 4
  %6251 = sext i32 %6250 to i64
  %6252 = shl nsw i64 %6251, 6
  store i64 %6252, i64* %RDI.i6998, align 8
  %6253 = add i64 %6252, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  store i64 %6253, i64* %RSI.i2015, align 8
  %6254 = icmp ult i64 %6253, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  %6255 = icmp ult i64 %6253, %6252
  %6256 = or i1 %6254, %6255
  %6257 = zext i1 %6256 to i8
  store i8 %6257, i8* %17, align 1
  %6258 = trunc i64 %6253 to i32
  %6259 = and i32 %6258, 248
  %6260 = tail call i32 @llvm.ctpop.i32(i32 %6259)
  %6261 = trunc i32 %6260 to i8
  %6262 = and i8 %6261, 1
  %6263 = xor i8 %6262, 1
  store i8 %6263, i8* %18, align 1
  %6264 = xor i64 %6253, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  %6265 = lshr i64 %6264, 4
  %6266 = trunc i64 %6265 to i8
  %6267 = and i8 %6266, 1
  store i8 %6267, i8* %19, align 1
  %6268 = icmp eq i64 %6253, 0
  %6269 = zext i1 %6268 to i8
  store i8 %6269, i8* %20, align 1
  %6270 = lshr i64 %6253, 63
  %6271 = trunc i64 %6270 to i8
  store i8 %6271, i8* %21, align 1
  %6272 = lshr i64 %6251, 57
  %6273 = and i64 %6272, 1
  %6274 = xor i64 %6270, lshr (i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64 63)
  %6275 = xor i64 %6270, %6273
  %6276 = add nuw nsw i64 %6274, %6275
  %6277 = icmp eq i64 %6276, 2
  %6278 = zext i1 %6277 to i8
  store i8 %6278, i8* %22, align 1
  %6279 = add i64 %6220, -48
  %6280 = add i64 %6248, 47
  store i64 %6280, i64* %3, align 8
  %6281 = inttoptr i64 %6279 to i32*
  %6282 = load i32, i32* %6281, align 4
  %6283 = sext i32 %6282 to i64
  store i64 %6283, i64* %RDI.i6998, align 8
  %6284 = shl nsw i64 %6283, 2
  %6285 = add i64 %6284, %6253
  %6286 = add i64 %6248, 51
  store i64 %6286, i64* %3, align 8
  %6287 = inttoptr i64 %6285 to i32*
  %6288 = load i32, i32* %6287, align 4
  %6289 = zext i32 %6288 to i64
  store i64 %6289, i64* %25, align 8
  %6290 = load i64, i64* %RBP.i, align 8
  %6291 = add i64 %6290, -44
  %6292 = add i64 %6248, 55
  store i64 %6292, i64* %3, align 8
  %6293 = inttoptr i64 %6291 to i32*
  %6294 = load i32, i32* %6293, align 4
  %6295 = sext i32 %6294 to i64
  %6296 = shl nsw i64 %6295, 6
  store i64 %6296, i64* %RSI.i2015, align 8
  %6297 = load i64, i64* %RDX.i1943, align 8
  %6298 = add i64 %6296, %6297
  store i64 %6298, i64* %RDI.i6998, align 8
  %6299 = icmp ult i64 %6298, %6297
  %6300 = icmp ult i64 %6298, %6296
  %6301 = or i1 %6299, %6300
  %6302 = zext i1 %6301 to i8
  store i8 %6302, i8* %17, align 1
  %6303 = trunc i64 %6298 to i32
  %6304 = and i32 %6303, 255
  %6305 = tail call i32 @llvm.ctpop.i32(i32 %6304)
  %6306 = trunc i32 %6305 to i8
  %6307 = and i8 %6306, 1
  %6308 = xor i8 %6307, 1
  store i8 %6308, i8* %18, align 1
  %6309 = xor i64 %6297, %6298
  %6310 = lshr i64 %6309, 4
  %6311 = trunc i64 %6310 to i8
  %6312 = and i8 %6311, 1
  store i8 %6312, i8* %19, align 1
  %6313 = icmp eq i64 %6298, 0
  %6314 = zext i1 %6313 to i8
  store i8 %6314, i8* %20, align 1
  %6315 = lshr i64 %6298, 63
  %6316 = trunc i64 %6315 to i8
  store i8 %6316, i8* %21, align 1
  %6317 = lshr i64 %6297, 63
  %6318 = lshr i64 %6295, 57
  %6319 = and i64 %6318, 1
  %6320 = xor i64 %6315, %6317
  %6321 = xor i64 %6315, %6319
  %6322 = add nuw nsw i64 %6320, %6321
  %6323 = icmp eq i64 %6322, 2
  %6324 = zext i1 %6323 to i8
  store i8 %6324, i8* %22, align 1
  %6325 = add i64 %6290, -48
  %6326 = add i64 %6248, 69
  store i64 %6326, i64* %3, align 8
  %6327 = inttoptr i64 %6325 to i32*
  %6328 = load i32, i32* %6327, align 4
  %6329 = sext i32 %6328 to i64
  store i64 %6329, i64* %RSI.i2015, align 8
  %6330 = shl nsw i64 %6329, 2
  %6331 = add i64 %6330, %6298
  %6332 = add i64 %6248, 73
  store i64 %6332, i64* %3, align 8
  %6333 = inttoptr i64 %6331 to i32*
  %6334 = load i32, i32* %6333, align 4
  %6335 = zext i32 %6334 to i64
  %6336 = shl nuw i64 %6335, 32
  %6337 = ashr i64 %6336, 33
  %6338 = and i64 %6337, 4294967295
  store i64 %6338, i64* %R9.i1633, align 8
  %6339 = load i32, i32* %R8D.i1615, align 4
  %6340 = trunc i64 %6337 to i32
  %6341 = sub i32 %6339, %6340
  %6342 = zext i32 %6341 to i64
  store i64 %6342, i64* %25, align 8
  %6343 = icmp ult i32 %6339, %6340
  %6344 = zext i1 %6343 to i8
  store i8 %6344, i8* %17, align 1
  %6345 = and i32 %6341, 255
  %6346 = tail call i32 @llvm.ctpop.i32(i32 %6345)
  %6347 = trunc i32 %6346 to i8
  %6348 = and i8 %6347, 1
  %6349 = xor i8 %6348, 1
  store i8 %6349, i8* %18, align 1
  %6350 = xor i32 %6340, %6339
  %6351 = xor i32 %6350, %6341
  %6352 = lshr i32 %6351, 4
  %6353 = trunc i32 %6352 to i8
  %6354 = and i8 %6353, 1
  store i8 %6354, i8* %19, align 1
  %6355 = icmp eq i32 %6341, 0
  %6356 = zext i1 %6355 to i8
  store i8 %6356, i8* %20, align 1
  %6357 = lshr i32 %6341, 31
  %6358 = trunc i32 %6357 to i8
  store i8 %6358, i8* %21, align 1
  %6359 = lshr i32 %6339, 31
  %6360 = lshr i64 %6337, 31
  %6361 = trunc i64 %6360 to i32
  %6362 = and i32 %6361, 1
  %6363 = xor i32 %6362, %6359
  %6364 = xor i32 %6357, %6359
  %6365 = add nuw nsw i32 %6364, %6363
  %6366 = icmp eq i32 %6365, 2
  %6367 = zext i1 %6366 to i8
  store i8 %6367, i8* %22, align 1
  %6368 = load i64, i64* %RBP.i, align 8
  %6369 = add i64 %6368, -360
  %6370 = add i64 %6248, 86
  store i64 %6370, i64* %3, align 8
  %6371 = inttoptr i64 %6369 to i32*
  store i32 %6341, i32* %6371, align 4
  %6372 = load i64, i64* %RBP.i, align 8
  %6373 = add i64 %6372, -44
  %6374 = load i64, i64* %3, align 8
  %6375 = add i64 %6374, 4
  store i64 %6375, i64* %3, align 8
  %6376 = inttoptr i64 %6373 to i32*
  %6377 = load i32, i32* %6376, align 4
  %6378 = sext i32 %6377 to i64
  %6379 = shl nsw i64 %6378, 6
  store i64 %6379, i64* %RSI.i2015, align 8
  %6380 = load i64, i64* %RDX.i1943, align 8
  %6381 = add i64 %6379, %6380
  store i64 %6381, i64* %RDX.i1943, align 8
  %6382 = icmp ult i64 %6381, %6380
  %6383 = icmp ult i64 %6381, %6379
  %6384 = or i1 %6382, %6383
  %6385 = zext i1 %6384 to i8
  store i8 %6385, i8* %17, align 1
  %6386 = trunc i64 %6381 to i32
  %6387 = and i32 %6386, 255
  %6388 = tail call i32 @llvm.ctpop.i32(i32 %6387)
  %6389 = trunc i32 %6388 to i8
  %6390 = and i8 %6389, 1
  %6391 = xor i8 %6390, 1
  store i8 %6391, i8* %18, align 1
  %6392 = xor i64 %6380, %6381
  %6393 = lshr i64 %6392, 4
  %6394 = trunc i64 %6393 to i8
  %6395 = and i8 %6394, 1
  store i8 %6395, i8* %19, align 1
  %6396 = icmp eq i64 %6381, 0
  %6397 = zext i1 %6396 to i8
  store i8 %6397, i8* %20, align 1
  %6398 = lshr i64 %6381, 63
  %6399 = trunc i64 %6398 to i8
  store i8 %6399, i8* %21, align 1
  %6400 = lshr i64 %6380, 63
  %6401 = lshr i64 %6378, 57
  %6402 = and i64 %6401, 1
  %6403 = xor i64 %6398, %6400
  %6404 = xor i64 %6398, %6402
  %6405 = add nuw nsw i64 %6403, %6404
  %6406 = icmp eq i64 %6405, 2
  %6407 = zext i1 %6406 to i8
  store i8 %6407, i8* %22, align 1
  %6408 = add i64 %6372, -48
  %6409 = add i64 %6374, 15
  store i64 %6409, i64* %3, align 8
  %6410 = inttoptr i64 %6408 to i32*
  %6411 = load i32, i32* %6410, align 4
  %6412 = sext i32 %6411 to i64
  store i64 %6412, i64* %RSI.i2015, align 8
  %6413 = shl nsw i64 %6412, 2
  %6414 = add i64 %6413, %6381
  %6415 = add i64 %6374, 19
  store i64 %6415, i64* %3, align 8
  %6416 = inttoptr i64 %6414 to i32*
  %6417 = load i32, i32* %6416, align 4
  %6418 = zext i32 %6417 to i64
  store i64 %6418, i64* %25, align 8
  %6419 = add i64 %6372, -360
  %6420 = add i64 %6374, 26
  store i64 %6420, i64* %3, align 8
  %6421 = inttoptr i64 %6419 to i32*
  %6422 = load i32, i32* %6421, align 4
  %6423 = add i32 %6422, %6417
  %6424 = zext i32 %6423 to i64
  store i64 %6424, i64* %25, align 8
  %6425 = icmp ult i32 %6423, %6417
  %6426 = icmp ult i32 %6423, %6422
  %6427 = or i1 %6425, %6426
  %6428 = zext i1 %6427 to i8
  store i8 %6428, i8* %17, align 1
  %6429 = and i32 %6423, 255
  %6430 = tail call i32 @llvm.ctpop.i32(i32 %6429)
  %6431 = trunc i32 %6430 to i8
  %6432 = and i8 %6431, 1
  %6433 = xor i8 %6432, 1
  store i8 %6433, i8* %18, align 1
  %6434 = xor i32 %6422, %6417
  %6435 = xor i32 %6434, %6423
  %6436 = lshr i32 %6435, 4
  %6437 = trunc i32 %6436 to i8
  %6438 = and i8 %6437, 1
  store i8 %6438, i8* %19, align 1
  %6439 = icmp eq i32 %6423, 0
  %6440 = zext i1 %6439 to i8
  store i8 %6440, i8* %20, align 1
  %6441 = lshr i32 %6423, 31
  %6442 = trunc i32 %6441 to i8
  store i8 %6442, i8* %21, align 1
  %6443 = lshr i32 %6417, 31
  %6444 = lshr i32 %6422, 31
  %6445 = xor i32 %6441, %6443
  %6446 = xor i32 %6441, %6444
  %6447 = add nuw nsw i32 %6445, %6446
  %6448 = icmp eq i32 %6447, 2
  %6449 = zext i1 %6448 to i8
  store i8 %6449, i8* %22, align 1
  %6450 = load i64, i64* %RBP.i, align 8
  %6451 = add i64 %6450, -344
  %6452 = add i64 %6374, 33
  store i64 %6452, i64* %3, align 8
  %6453 = inttoptr i64 %6451 to i32*
  store i32 %6423, i32* %6453, align 4
  %6454 = load i64, i64* %RBP.i, align 8
  %6455 = add i64 %6454, -360
  %6456 = load i64, i64* %3, align 8
  %6457 = add i64 %6456, 7
  store i64 %6457, i64* %3, align 8
  %6458 = inttoptr i64 %6455 to i32*
  %6459 = load i32, i32* %6458, align 4
  %6460 = zext i32 %6459 to i64
  store i64 %6460, i64* %25, align 8
  %6461 = add i64 %6454, -44
  %6462 = add i64 %6456, 11
  store i64 %6462, i64* %3, align 8
  %6463 = inttoptr i64 %6461 to i32*
  %6464 = load i32, i32* %6463, align 4
  %6465 = sext i32 %6464 to i64
  %6466 = shl nsw i64 %6465, 6
  store i64 %6466, i64* %RDX.i1943, align 8
  %6467 = load i64, i64* %RCX.i1588, align 8
  %6468 = add i64 %6466, %6467
  store i64 %6468, i64* %RSI.i2015, align 8
  %6469 = icmp ult i64 %6468, %6467
  %6470 = icmp ult i64 %6468, %6466
  %6471 = or i1 %6469, %6470
  %6472 = zext i1 %6471 to i8
  store i8 %6472, i8* %17, align 1
  %6473 = trunc i64 %6468 to i32
  %6474 = and i32 %6473, 255
  %6475 = tail call i32 @llvm.ctpop.i32(i32 %6474)
  %6476 = trunc i32 %6475 to i8
  %6477 = and i8 %6476, 1
  %6478 = xor i8 %6477, 1
  store i8 %6478, i8* %18, align 1
  %6479 = xor i64 %6467, %6468
  %6480 = lshr i64 %6479, 4
  %6481 = trunc i64 %6480 to i8
  %6482 = and i8 %6481, 1
  store i8 %6482, i8* %19, align 1
  %6483 = icmp eq i64 %6468, 0
  %6484 = zext i1 %6483 to i8
  store i8 %6484, i8* %20, align 1
  %6485 = lshr i64 %6468, 63
  %6486 = trunc i64 %6485 to i8
  store i8 %6486, i8* %21, align 1
  %6487 = lshr i64 %6467, 63
  %6488 = lshr i64 %6465, 57
  %6489 = and i64 %6488, 1
  %6490 = xor i64 %6485, %6487
  %6491 = xor i64 %6485, %6489
  %6492 = add nuw nsw i64 %6490, %6491
  %6493 = icmp eq i64 %6492, 2
  %6494 = zext i1 %6493 to i8
  store i8 %6494, i8* %22, align 1
  %6495 = add i64 %6454, -48
  %6496 = add i64 %6456, 25
  store i64 %6496, i64* %3, align 8
  %6497 = inttoptr i64 %6495 to i32*
  %6498 = load i32, i32* %6497, align 4
  %6499 = sext i32 %6498 to i64
  store i64 %6499, i64* %RDX.i1943, align 8
  %6500 = shl nsw i64 %6499, 2
  %6501 = add i64 %6500, %6468
  %6502 = add i64 %6456, 29
  store i64 %6502, i64* %3, align 8
  %6503 = inttoptr i64 %6501 to i32*
  %6504 = load i32, i32* %6503, align 4
  %6505 = zext i32 %6504 to i64
  %6506 = shl nuw i64 %6505, 32
  %6507 = ashr i64 %6506, 33
  %6508 = and i64 %6507, 4294967295
  store i64 %6508, i64* %R9.i1633, align 8
  %6509 = load i32, i32* %R8D.i1615, align 4
  %6510 = trunc i64 %6507 to i32
  %6511 = sub i32 %6509, %6510
  %6512 = zext i32 %6511 to i64
  store i64 %6512, i64* %25, align 8
  %6513 = icmp ult i32 %6509, %6510
  %6514 = zext i1 %6513 to i8
  store i8 %6514, i8* %17, align 1
  %6515 = and i32 %6511, 255
  %6516 = tail call i32 @llvm.ctpop.i32(i32 %6515)
  %6517 = trunc i32 %6516 to i8
  %6518 = and i8 %6517, 1
  %6519 = xor i8 %6518, 1
  store i8 %6519, i8* %18, align 1
  %6520 = xor i32 %6510, %6509
  %6521 = xor i32 %6520, %6511
  %6522 = lshr i32 %6521, 4
  %6523 = trunc i32 %6522 to i8
  %6524 = and i8 %6523, 1
  store i8 %6524, i8* %19, align 1
  %6525 = icmp eq i32 %6511, 0
  %6526 = zext i1 %6525 to i8
  store i8 %6526, i8* %20, align 1
  %6527 = lshr i32 %6511, 31
  %6528 = trunc i32 %6527 to i8
  store i8 %6528, i8* %21, align 1
  %6529 = lshr i32 %6509, 31
  %6530 = lshr i64 %6507, 31
  %6531 = trunc i64 %6530 to i32
  %6532 = and i32 %6531, 1
  %6533 = xor i32 %6532, %6529
  %6534 = xor i32 %6527, %6529
  %6535 = add nuw nsw i32 %6534, %6533
  %6536 = icmp eq i32 %6535, 2
  %6537 = zext i1 %6536 to i8
  store i8 %6537, i8* %22, align 1
  %6538 = load i64, i64* %RBP.i, align 8
  %6539 = add i64 %6538, -348
  %6540 = add i64 %6456, 42
  store i64 %6540, i64* %3, align 8
  %6541 = inttoptr i64 %6539 to i32*
  store i32 %6511, i32* %6541, align 4
  %6542 = load i64, i64* %RBP.i, align 8
  %6543 = add i64 %6542, -348
  %6544 = load i64, i64* %3, align 8
  %6545 = add i64 %6544, 7
  store i64 %6545, i64* %3, align 8
  %6546 = inttoptr i64 %6543 to i32*
  %6547 = load i32, i32* %6546, align 4
  %6548 = zext i32 %6547 to i64
  store i64 %6548, i64* %25, align 8
  %6549 = add i64 %6542, -44
  %6550 = add i64 %6544, 11
  store i64 %6550, i64* %3, align 8
  %6551 = inttoptr i64 %6549 to i32*
  %6552 = load i32, i32* %6551, align 4
  %6553 = sext i32 %6552 to i64
  %6554 = shl nsw i64 %6553, 6
  store i64 %6554, i64* %RDX.i1943, align 8
  %6555 = load i64, i64* %RCX.i1588, align 8
  %6556 = add i64 %6554, %6555
  store i64 %6556, i64* %RCX.i1588, align 8
  %6557 = icmp ult i64 %6556, %6555
  %6558 = icmp ult i64 %6556, %6554
  %6559 = or i1 %6557, %6558
  %6560 = zext i1 %6559 to i8
  store i8 %6560, i8* %17, align 1
  %6561 = trunc i64 %6556 to i32
  %6562 = and i32 %6561, 255
  %6563 = tail call i32 @llvm.ctpop.i32(i32 %6562)
  %6564 = trunc i32 %6563 to i8
  %6565 = and i8 %6564, 1
  %6566 = xor i8 %6565, 1
  store i8 %6566, i8* %18, align 1
  %6567 = xor i64 %6555, %6556
  %6568 = lshr i64 %6567, 4
  %6569 = trunc i64 %6568 to i8
  %6570 = and i8 %6569, 1
  store i8 %6570, i8* %19, align 1
  %6571 = icmp eq i64 %6556, 0
  %6572 = zext i1 %6571 to i8
  store i8 %6572, i8* %20, align 1
  %6573 = lshr i64 %6556, 63
  %6574 = trunc i64 %6573 to i8
  store i8 %6574, i8* %21, align 1
  %6575 = lshr i64 %6555, 63
  %6576 = lshr i64 %6553, 57
  %6577 = and i64 %6576, 1
  %6578 = xor i64 %6573, %6575
  %6579 = xor i64 %6573, %6577
  %6580 = add nuw nsw i64 %6578, %6579
  %6581 = icmp eq i64 %6580, 2
  %6582 = zext i1 %6581 to i8
  store i8 %6582, i8* %22, align 1
  %6583 = add i64 %6542, -48
  %6584 = add i64 %6544, 22
  store i64 %6584, i64* %3, align 8
  %6585 = inttoptr i64 %6583 to i32*
  %6586 = load i32, i32* %6585, align 4
  %6587 = sext i32 %6586 to i64
  store i64 %6587, i64* %RDX.i1943, align 8
  %6588 = shl nsw i64 %6587, 2
  %6589 = add i64 %6556, %6588
  %6590 = add i64 %6544, 26
  store i64 %6590, i64* %3, align 8
  %6591 = inttoptr i64 %6589 to i32*
  %6592 = load i32, i32* %6591, align 4
  %6593 = add i32 %6592, %6547
  %6594 = zext i32 %6593 to i64
  store i64 %6594, i64* %25, align 8
  %6595 = icmp ult i32 %6593, %6547
  %6596 = icmp ult i32 %6593, %6592
  %6597 = or i1 %6595, %6596
  %6598 = zext i1 %6597 to i8
  store i8 %6598, i8* %17, align 1
  %6599 = and i32 %6593, 255
  %6600 = tail call i32 @llvm.ctpop.i32(i32 %6599)
  %6601 = trunc i32 %6600 to i8
  %6602 = and i8 %6601, 1
  %6603 = xor i8 %6602, 1
  store i8 %6603, i8* %18, align 1
  %6604 = xor i32 %6592, %6547
  %6605 = xor i32 %6604, %6593
  %6606 = lshr i32 %6605, 4
  %6607 = trunc i32 %6606 to i8
  %6608 = and i8 %6607, 1
  store i8 %6608, i8* %19, align 1
  %6609 = icmp eq i32 %6593, 0
  %6610 = zext i1 %6609 to i8
  store i8 %6610, i8* %20, align 1
  %6611 = lshr i32 %6593, 31
  %6612 = trunc i32 %6611 to i8
  store i8 %6612, i8* %21, align 1
  %6613 = lshr i32 %6547, 31
  %6614 = lshr i32 %6592, 31
  %6615 = xor i32 %6611, %6613
  %6616 = xor i32 %6611, %6614
  %6617 = add nuw nsw i32 %6615, %6616
  %6618 = icmp eq i32 %6617, 2
  %6619 = zext i1 %6618 to i8
  store i8 %6619, i8* %22, align 1
  %6620 = load i64, i64* %RBP.i, align 8
  %6621 = add i64 %6620, -340
  %6622 = add i64 %6544, 33
  store i64 %6622, i64* %3, align 8
  %6623 = inttoptr i64 %6621 to i32*
  store i32 %6593, i32* %6623, align 4
  %6624 = load i64, i64* %3, align 8
  %6625 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6625, i64* %RCX.i1588, align 8
  %6626 = add i64 %6625, 72688
  %6627 = add i64 %6624, 15
  store i64 %6627, i64* %3, align 8
  %6628 = inttoptr i64 %6626 to i32*
  %6629 = load i32, i32* %6628, align 4
  %6630 = zext i32 %6629 to i64
  store i64 %6630, i64* %25, align 8
  %6631 = load i64, i64* %RBP.i, align 8
  %6632 = add i64 %6631, -348
  %6633 = add i64 %6624, 22
  store i64 %6633, i64* %3, align 8
  %6634 = inttoptr i64 %6632 to i32*
  %6635 = load i32, i32* %6634, align 4
  %6636 = zext i32 %6635 to i64
  store i64 %6636, i64* %R9.i1633, align 8
  %6637 = add i64 %6625, 8504
  store i64 %6637, i64* %RCX.i1588, align 8
  %6638 = icmp ugt i64 %6625, -8505
  %6639 = zext i1 %6638 to i8
  store i8 %6639, i8* %17, align 1
  %6640 = trunc i64 %6637 to i32
  %6641 = and i32 %6640, 255
  %6642 = tail call i32 @llvm.ctpop.i32(i32 %6641)
  %6643 = trunc i32 %6642 to i8
  %6644 = and i8 %6643, 1
  %6645 = xor i8 %6644, 1
  store i8 %6645, i8* %18, align 1
  %6646 = xor i64 %6625, 16
  %6647 = xor i64 %6646, %6637
  %6648 = lshr i64 %6647, 4
  %6649 = trunc i64 %6648 to i8
  %6650 = and i8 %6649, 1
  store i8 %6650, i8* %19, align 1
  %6651 = icmp eq i64 %6637, 0
  %6652 = zext i1 %6651 to i8
  store i8 %6652, i8* %20, align 1
  %6653 = lshr i64 %6637, 63
  %6654 = trunc i64 %6653 to i8
  store i8 %6654, i8* %21, align 1
  %6655 = lshr i64 %6625, 63
  %6656 = xor i64 %6653, %6655
  %6657 = add nuw nsw i64 %6656, %6653
  %6658 = icmp eq i64 %6657, 2
  %6659 = zext i1 %6658 to i8
  store i8 %6659, i8* %22, align 1
  %6660 = add i64 %6631, -364
  %6661 = add i64 %6624, 44
  store i64 %6661, i64* %3, align 8
  %6662 = inttoptr i64 %6660 to i32*
  %6663 = load i32, i32* %6662, align 4
  %6664 = sext i32 %6663 to i64
  %6665 = shl nsw i64 %6664, 9
  store i64 %6665, i64* %RDX.i1943, align 8
  %6666 = add i64 %6665, %6637
  store i64 %6666, i64* %RCX.i1588, align 8
  %6667 = icmp ult i64 %6666, %6637
  %6668 = icmp ult i64 %6666, %6665
  %6669 = or i1 %6667, %6668
  %6670 = zext i1 %6669 to i8
  store i8 %6670, i8* %17, align 1
  %6671 = trunc i64 %6666 to i32
  %6672 = and i32 %6671, 255
  %6673 = tail call i32 @llvm.ctpop.i32(i32 %6672)
  %6674 = trunc i32 %6673 to i8
  %6675 = and i8 %6674, 1
  %6676 = xor i8 %6675, 1
  store i8 %6676, i8* %18, align 1
  %6677 = xor i64 %6637, %6666
  %6678 = lshr i64 %6677, 4
  %6679 = trunc i64 %6678 to i8
  %6680 = and i8 %6679, 1
  store i8 %6680, i8* %19, align 1
  %6681 = icmp eq i64 %6666, 0
  %6682 = zext i1 %6681 to i8
  store i8 %6682, i8* %20, align 1
  %6683 = lshr i64 %6666, 63
  %6684 = trunc i64 %6683 to i8
  store i8 %6684, i8* %21, align 1
  %6685 = lshr i64 %6664, 54
  %6686 = and i64 %6685, 1
  %6687 = xor i64 %6683, %6653
  %6688 = xor i64 %6683, %6686
  %6689 = add nuw nsw i64 %6687, %6688
  %6690 = icmp eq i64 %6689, 2
  %6691 = zext i1 %6690 to i8
  store i8 %6691, i8* %22, align 1
  %6692 = load i64, i64* %RBP.i, align 8
  %6693 = add i64 %6692, -220
  %6694 = add i64 %6624, 58
  store i64 %6694, i64* %3, align 8
  %6695 = inttoptr i64 %6693 to i32*
  %6696 = load i32, i32* %6695, align 4
  %6697 = zext i32 %6696 to i64
  store i64 %6697, i64* %50, align 8
  %6698 = add i64 %6692, -44
  %6699 = add i64 %6624, 62
  store i64 %6699, i64* %3, align 8
  %6700 = inttoptr i64 %6698 to i32*
  %6701 = load i32, i32* %6700, align 4
  %6702 = add i32 %6701, %6696
  %6703 = zext i32 %6702 to i64
  store i64 %6703, i64* %50, align 8
  %6704 = sext i32 %6702 to i64
  %6705 = shl nsw i64 %6704, 5
  store i64 %6705, i64* %RDX.i1943, align 8
  %6706 = load i64, i64* %RCX.i1588, align 8
  %6707 = add i64 %6705, %6706
  store i64 %6707, i64* %RCX.i1588, align 8
  %6708 = icmp ult i64 %6707, %6706
  %6709 = icmp ult i64 %6707, %6705
  %6710 = or i1 %6708, %6709
  %6711 = zext i1 %6710 to i8
  store i8 %6711, i8* %17, align 1
  %6712 = trunc i64 %6707 to i32
  %6713 = and i32 %6712, 255
  %6714 = tail call i32 @llvm.ctpop.i32(i32 %6713)
  %6715 = trunc i32 %6714 to i8
  %6716 = and i8 %6715, 1
  %6717 = xor i8 %6716, 1
  store i8 %6717, i8* %18, align 1
  %6718 = xor i64 %6706, %6707
  %6719 = lshr i64 %6718, 4
  %6720 = trunc i64 %6719 to i8
  %6721 = and i8 %6720, 1
  store i8 %6721, i8* %19, align 1
  %6722 = icmp eq i64 %6707, 0
  %6723 = zext i1 %6722 to i8
  store i8 %6723, i8* %20, align 1
  %6724 = lshr i64 %6707, 63
  %6725 = trunc i64 %6724 to i8
  store i8 %6725, i8* %21, align 1
  %6726 = lshr i64 %6706, 63
  %6727 = lshr i64 %6704, 58
  %6728 = and i64 %6727, 1
  %6729 = xor i64 %6724, %6726
  %6730 = xor i64 %6724, %6728
  %6731 = add nuw nsw i64 %6729, %6730
  %6732 = icmp eq i64 %6731, 2
  %6733 = zext i1 %6732 to i8
  store i8 %6733, i8* %22, align 1
  %6734 = load i64, i64* %RBP.i, align 8
  %6735 = add i64 %6734, -224
  %6736 = add i64 %6624, 79
  store i64 %6736, i64* %3, align 8
  %6737 = inttoptr i64 %6735 to i32*
  %6738 = load i32, i32* %6737, align 4
  %6739 = zext i32 %6738 to i64
  store i64 %6739, i64* %50, align 8
  %6740 = add i64 %6734, -48
  %6741 = add i64 %6624, 83
  store i64 %6741, i64* %3, align 8
  %6742 = inttoptr i64 %6740 to i32*
  %6743 = load i32, i32* %6742, align 4
  %6744 = add i32 %6743, %6738
  %6745 = zext i32 %6744 to i64
  store i64 %6745, i64* %50, align 8
  %6746 = icmp ult i32 %6744, %6738
  %6747 = icmp ult i32 %6744, %6743
  %6748 = or i1 %6746, %6747
  %6749 = zext i1 %6748 to i8
  store i8 %6749, i8* %17, align 1
  %6750 = and i32 %6744, 255
  %6751 = tail call i32 @llvm.ctpop.i32(i32 %6750)
  %6752 = trunc i32 %6751 to i8
  %6753 = and i8 %6752, 1
  %6754 = xor i8 %6753, 1
  store i8 %6754, i8* %18, align 1
  %6755 = xor i32 %6743, %6738
  %6756 = xor i32 %6755, %6744
  %6757 = lshr i32 %6756, 4
  %6758 = trunc i32 %6757 to i8
  %6759 = and i8 %6758, 1
  store i8 %6759, i8* %19, align 1
  %6760 = icmp eq i32 %6744, 0
  %6761 = zext i1 %6760 to i8
  store i8 %6761, i8* %20, align 1
  %6762 = lshr i32 %6744, 31
  %6763 = trunc i32 %6762 to i8
  store i8 %6763, i8* %21, align 1
  %6764 = lshr i32 %6738, 31
  %6765 = lshr i32 %6743, 31
  %6766 = xor i32 %6762, %6764
  %6767 = xor i32 %6762, %6765
  %6768 = add nuw nsw i32 %6766, %6767
  %6769 = icmp eq i32 %6768, 2
  %6770 = zext i1 %6769 to i8
  store i8 %6770, i8* %22, align 1
  %6771 = sext i32 %6744 to i64
  store i64 %6771, i64* %RDX.i1943, align 8
  %6772 = shl nsw i64 %6771, 1
  %6773 = add i64 %6707, %6772
  %6774 = add i64 %6624, 91
  store i64 %6774, i64* %3, align 8
  %6775 = inttoptr i64 %6773 to i16*
  %6776 = load i16, i16* %6775, align 2
  %6777 = zext i16 %6776 to i64
  store i64 %6777, i64* %50, align 8
  %6778 = load i32, i32* %R9D.i5956, align 4
  %6779 = zext i16 %6776 to i32
  %6780 = add i32 %6779, %6778
  %6781 = zext i32 %6780 to i64
  store i64 %6781, i64* %R9.i1633, align 8
  %6782 = lshr i32 %6780, 31
  %6783 = load i32, i32* %EAX.i2033, align 4
  %6784 = sub i32 %6783, %6780
  %6785 = icmp ult i32 %6783, %6780
  %6786 = zext i1 %6785 to i8
  store i8 %6786, i8* %17, align 1
  %6787 = and i32 %6784, 255
  %6788 = tail call i32 @llvm.ctpop.i32(i32 %6787)
  %6789 = trunc i32 %6788 to i8
  %6790 = and i8 %6789, 1
  %6791 = xor i8 %6790, 1
  store i8 %6791, i8* %18, align 1
  %6792 = xor i32 %6780, %6783
  %6793 = xor i32 %6792, %6784
  %6794 = lshr i32 %6793, 4
  %6795 = trunc i32 %6794 to i8
  %6796 = and i8 %6795, 1
  store i8 %6796, i8* %19, align 1
  %6797 = icmp eq i32 %6784, 0
  %6798 = zext i1 %6797 to i8
  store i8 %6798, i8* %20, align 1
  %6799 = lshr i32 %6784, 31
  %6800 = trunc i32 %6799 to i8
  store i8 %6800, i8* %21, align 1
  %6801 = lshr i32 %6783, 31
  %6802 = xor i32 %6782, %6801
  %6803 = xor i32 %6799, %6801
  %6804 = add nuw nsw i32 %6803, %6802
  %6805 = icmp eq i32 %6804, 2
  %6806 = zext i1 %6805 to i8
  store i8 %6806, i8* %22, align 1
  %6807 = load i64, i64* %RBP.i, align 8
  %6808 = add i64 %6807, -560
  %6809 = load i32, i32* %R8D.i1615, align 4
  %6810 = add i64 %6624, 104
  store i64 %6810, i64* %3, align 8
  %6811 = inttoptr i64 %6808 to i32*
  store i32 %6809, i32* %6811, align 4
  %6812 = load i64, i64* %3, align 8
  %6813 = load i8, i8* %20, align 1
  %6814 = icmp ne i8 %6813, 0
  %6815 = load i8, i8* %21, align 1
  %6816 = icmp ne i8 %6815, 0
  %6817 = load i8, i8* %22, align 1
  %6818 = icmp ne i8 %6817, 0
  %6819 = xor i1 %6816, %6818
  %6820 = or i1 %6814, %6819
  %.v879 = select i1 %6820, i64 19, i64 6
  %6821 = add i64 %6812, %.v879
  store i64 %6821, i64* %3, align 8
  br i1 %6820, label %block_.L_4849b4, label %block_4849a7

block_4849a7:                                     ; preds = %block_484875
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %6822 = load i64, i64* %RBP.i, align 8
  %6823 = add i64 %6822, -564
  %6824 = add i64 %6821, 8
  store i64 %6824, i64* %3, align 8
  %6825 = inttoptr i64 %6823 to i32*
  store i32 0, i32* %6825, align 4
  %6826 = load i64, i64* %3, align 8
  %6827 = add i64 %6826, 83
  store i64 %6827, i64* %3, align 8
  br label %block_.L_484a02

block_.L_4849b4:                                  ; preds = %block_484875
  %6828 = load i64, i64* %RBP.i, align 8
  %6829 = add i64 %6828, -348
  %6830 = add i64 %6821, 6
  store i64 %6830, i64* %3, align 8
  %6831 = inttoptr i64 %6829 to i32*
  %6832 = load i32, i32* %6831, align 4
  %6833 = zext i32 %6832 to i64
  store i64 %6833, i64* %RAX.i1659, align 8
  %6834 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %6835 = add i64 %6834, 8504
  store i64 %6835, i64* %RCX.i1588, align 8
  %6836 = icmp ugt i64 %6834, -8505
  %6837 = zext i1 %6836 to i8
  store i8 %6837, i8* %17, align 1
  %6838 = trunc i64 %6835 to i32
  %6839 = and i32 %6838, 255
  %6840 = tail call i32 @llvm.ctpop.i32(i32 %6839)
  %6841 = trunc i32 %6840 to i8
  %6842 = and i8 %6841, 1
  %6843 = xor i8 %6842, 1
  store i8 %6843, i8* %18, align 1
  %6844 = xor i64 %6834, 16
  %6845 = xor i64 %6844, %6835
  %6846 = lshr i64 %6845, 4
  %6847 = trunc i64 %6846 to i8
  %6848 = and i8 %6847, 1
  store i8 %6848, i8* %19, align 1
  %6849 = icmp eq i64 %6835, 0
  %6850 = zext i1 %6849 to i8
  store i8 %6850, i8* %20, align 1
  %6851 = lshr i64 %6835, 63
  %6852 = trunc i64 %6851 to i8
  store i8 %6852, i8* %21, align 1
  %6853 = lshr i64 %6834, 63
  %6854 = xor i64 %6851, %6853
  %6855 = add nuw nsw i64 %6854, %6851
  %6856 = icmp eq i64 %6855, 2
  %6857 = zext i1 %6856 to i8
  store i8 %6857, i8* %22, align 1
  %6858 = add i64 %6828, -364
  %6859 = add i64 %6821, 28
  store i64 %6859, i64* %3, align 8
  %6860 = inttoptr i64 %6858 to i32*
  %6861 = load i32, i32* %6860, align 4
  %6862 = sext i32 %6861 to i64
  %6863 = shl nsw i64 %6862, 9
  store i64 %6863, i64* %RDX.i1943, align 8
  %6864 = add i64 %6863, %6835
  store i64 %6864, i64* %RCX.i1588, align 8
  %6865 = icmp ult i64 %6864, %6835
  %6866 = icmp ult i64 %6864, %6863
  %6867 = or i1 %6865, %6866
  %6868 = zext i1 %6867 to i8
  store i8 %6868, i8* %17, align 1
  %6869 = trunc i64 %6864 to i32
  %6870 = and i32 %6869, 255
  %6871 = tail call i32 @llvm.ctpop.i32(i32 %6870)
  %6872 = trunc i32 %6871 to i8
  %6873 = and i8 %6872, 1
  %6874 = xor i8 %6873, 1
  store i8 %6874, i8* %18, align 1
  %6875 = xor i64 %6835, %6864
  %6876 = lshr i64 %6875, 4
  %6877 = trunc i64 %6876 to i8
  %6878 = and i8 %6877, 1
  store i8 %6878, i8* %19, align 1
  %6879 = icmp eq i64 %6864, 0
  %6880 = zext i1 %6879 to i8
  store i8 %6880, i8* %20, align 1
  %6881 = lshr i64 %6864, 63
  %6882 = trunc i64 %6881 to i8
  store i8 %6882, i8* %21, align 1
  %6883 = lshr i64 %6862, 54
  %6884 = and i64 %6883, 1
  %6885 = xor i64 %6881, %6851
  %6886 = xor i64 %6881, %6884
  %6887 = add nuw nsw i64 %6885, %6886
  %6888 = icmp eq i64 %6887, 2
  %6889 = zext i1 %6888 to i8
  store i8 %6889, i8* %22, align 1
  %6890 = load i64, i64* %RBP.i, align 8
  %6891 = add i64 %6890, -220
  %6892 = add i64 %6821, 41
  store i64 %6892, i64* %3, align 8
  %6893 = inttoptr i64 %6891 to i32*
  %6894 = load i32, i32* %6893, align 4
  %6895 = zext i32 %6894 to i64
  store i64 %6895, i64* %RSI.i2015, align 8
  %6896 = add i64 %6890, -44
  %6897 = add i64 %6821, 44
  store i64 %6897, i64* %3, align 8
  %6898 = inttoptr i64 %6896 to i32*
  %6899 = load i32, i32* %6898, align 4
  %6900 = add i32 %6899, %6894
  %6901 = zext i32 %6900 to i64
  store i64 %6901, i64* %RSI.i2015, align 8
  %6902 = sext i32 %6900 to i64
  %6903 = shl nsw i64 %6902, 5
  store i64 %6903, i64* %RDX.i1943, align 8
  %6904 = load i64, i64* %RCX.i1588, align 8
  %6905 = add i64 %6903, %6904
  store i64 %6905, i64* %RCX.i1588, align 8
  %6906 = icmp ult i64 %6905, %6904
  %6907 = icmp ult i64 %6905, %6903
  %6908 = or i1 %6906, %6907
  %6909 = zext i1 %6908 to i8
  store i8 %6909, i8* %17, align 1
  %6910 = trunc i64 %6905 to i32
  %6911 = and i32 %6910, 255
  %6912 = tail call i32 @llvm.ctpop.i32(i32 %6911)
  %6913 = trunc i32 %6912 to i8
  %6914 = and i8 %6913, 1
  %6915 = xor i8 %6914, 1
  store i8 %6915, i8* %18, align 1
  %6916 = xor i64 %6904, %6905
  %6917 = lshr i64 %6916, 4
  %6918 = trunc i64 %6917 to i8
  %6919 = and i8 %6918, 1
  store i8 %6919, i8* %19, align 1
  %6920 = icmp eq i64 %6905, 0
  %6921 = zext i1 %6920 to i8
  store i8 %6921, i8* %20, align 1
  %6922 = lshr i64 %6905, 63
  %6923 = trunc i64 %6922 to i8
  store i8 %6923, i8* %21, align 1
  %6924 = lshr i64 %6904, 63
  %6925 = lshr i64 %6902, 58
  %6926 = and i64 %6925, 1
  %6927 = xor i64 %6922, %6924
  %6928 = xor i64 %6922, %6926
  %6929 = add nuw nsw i64 %6927, %6928
  %6930 = icmp eq i64 %6929, 2
  %6931 = zext i1 %6930 to i8
  store i8 %6931, i8* %22, align 1
  %6932 = load i64, i64* %RBP.i, align 8
  %6933 = add i64 %6932, -224
  %6934 = add i64 %6821, 60
  store i64 %6934, i64* %3, align 8
  %6935 = inttoptr i64 %6933 to i32*
  %6936 = load i32, i32* %6935, align 4
  %6937 = zext i32 %6936 to i64
  store i64 %6937, i64* %RSI.i2015, align 8
  %6938 = add i64 %6932, -48
  %6939 = add i64 %6821, 63
  store i64 %6939, i64* %3, align 8
  %6940 = inttoptr i64 %6938 to i32*
  %6941 = load i32, i32* %6940, align 4
  %6942 = add i32 %6941, %6936
  %6943 = zext i32 %6942 to i64
  store i64 %6943, i64* %RSI.i2015, align 8
  %6944 = icmp ult i32 %6942, %6936
  %6945 = icmp ult i32 %6942, %6941
  %6946 = or i1 %6944, %6945
  %6947 = zext i1 %6946 to i8
  store i8 %6947, i8* %17, align 1
  %6948 = and i32 %6942, 255
  %6949 = tail call i32 @llvm.ctpop.i32(i32 %6948)
  %6950 = trunc i32 %6949 to i8
  %6951 = and i8 %6950, 1
  %6952 = xor i8 %6951, 1
  store i8 %6952, i8* %18, align 1
  %6953 = xor i32 %6941, %6936
  %6954 = xor i32 %6953, %6942
  %6955 = lshr i32 %6954, 4
  %6956 = trunc i32 %6955 to i8
  %6957 = and i8 %6956, 1
  store i8 %6957, i8* %19, align 1
  %6958 = icmp eq i32 %6942, 0
  %6959 = zext i1 %6958 to i8
  store i8 %6959, i8* %20, align 1
  %6960 = lshr i32 %6942, 31
  %6961 = trunc i32 %6960 to i8
  store i8 %6961, i8* %21, align 1
  %6962 = lshr i32 %6936, 31
  %6963 = lshr i32 %6941, 31
  %6964 = xor i32 %6960, %6962
  %6965 = xor i32 %6960, %6963
  %6966 = add nuw nsw i32 %6964, %6965
  %6967 = icmp eq i32 %6966, 2
  %6968 = zext i1 %6967 to i8
  store i8 %6968, i8* %22, align 1
  %6969 = sext i32 %6942 to i64
  store i64 %6969, i64* %RDX.i1943, align 8
  %6970 = shl nsw i64 %6969, 1
  %6971 = add i64 %6905, %6970
  %6972 = add i64 %6821, 70
  store i64 %6972, i64* %3, align 8
  %6973 = inttoptr i64 %6971 to i16*
  %6974 = load i16, i16* %6973, align 2
  %6975 = zext i16 %6974 to i64
  store i64 %6975, i64* %RSI.i2015, align 8
  %6976 = load i64, i64* %RAX.i1659, align 8
  %6977 = zext i16 %6974 to i32
  %6978 = zext i16 %6974 to i64
  %6979 = trunc i64 %6976 to i32
  %6980 = add i32 %6977, %6979
  %6981 = zext i32 %6980 to i64
  store i64 %6981, i64* %RAX.i1659, align 8
  %6982 = icmp ult i32 %6980, %6979
  %6983 = icmp ult i32 %6980, %6977
  %6984 = or i1 %6982, %6983
  %6985 = zext i1 %6984 to i8
  store i8 %6985, i8* %17, align 1
  %6986 = and i32 %6980, 255
  %6987 = tail call i32 @llvm.ctpop.i32(i32 %6986)
  %6988 = trunc i32 %6987 to i8
  %6989 = and i8 %6988, 1
  %6990 = xor i8 %6989, 1
  store i8 %6990, i8* %18, align 1
  %6991 = xor i64 %6978, %6976
  %6992 = trunc i64 %6991 to i32
  %6993 = xor i32 %6992, %6980
  %6994 = lshr i32 %6993, 4
  %6995 = trunc i32 %6994 to i8
  %6996 = and i8 %6995, 1
  store i8 %6996, i8* %19, align 1
  %6997 = icmp eq i32 %6980, 0
  %6998 = zext i1 %6997 to i8
  store i8 %6998, i8* %20, align 1
  %6999 = lshr i32 %6980, 31
  %7000 = trunc i32 %6999 to i8
  store i8 %7000, i8* %21, align 1
  %7001 = lshr i32 %6979, 31
  %7002 = xor i32 %6999, %7001
  %7003 = add nuw nsw i32 %7002, %6999
  %7004 = icmp eq i32 %7003, 2
  %7005 = zext i1 %7004 to i8
  store i8 %7005, i8* %22, align 1
  %7006 = add i64 %6932, -564
  %7007 = add i64 %6821, 78
  store i64 %7007, i64* %3, align 8
  %7008 = inttoptr i64 %7006 to i32*
  store i32 %6980, i32* %7008, align 4
  %.pre641 = load i64, i64* %3, align 8
  br label %block_.L_484a02

block_.L_484a02:                                  ; preds = %block_.L_4849b4, %block_4849a7
  %7009 = phi i64 [ %.pre641, %block_.L_4849b4 ], [ %6827, %block_4849a7 ]
  %7010 = load i64, i64* %RBP.i, align 8
  %7011 = add i64 %7010, -564
  %7012 = add i64 %7009, 6
  store i64 %7012, i64* %3, align 8
  %7013 = inttoptr i64 %7011 to i32*
  %7014 = load i32, i32* %7013, align 4
  %7015 = zext i32 %7014 to i64
  store i64 %7015, i64* %RAX.i1659, align 8
  %7016 = add i64 %7010, -560
  %7017 = add i64 %7009, 12
  store i64 %7017, i64* %3, align 8
  %7018 = inttoptr i64 %7016 to i32*
  %7019 = load i32, i32* %7018, align 4
  %7020 = zext i32 %7019 to i64
  store i64 %7020, i64* %RCX.i1588, align 8
  %7021 = sub i32 %7019, %7014
  %7022 = icmp ult i32 %7019, %7014
  %7023 = zext i1 %7022 to i8
  store i8 %7023, i8* %17, align 1
  %7024 = and i32 %7021, 255
  %7025 = tail call i32 @llvm.ctpop.i32(i32 %7024)
  %7026 = trunc i32 %7025 to i8
  %7027 = and i8 %7026, 1
  %7028 = xor i8 %7027, 1
  store i8 %7028, i8* %18, align 1
  %7029 = xor i32 %7014, %7019
  %7030 = xor i32 %7029, %7021
  %7031 = lshr i32 %7030, 4
  %7032 = trunc i32 %7031 to i8
  %7033 = and i8 %7032, 1
  store i8 %7033, i8* %19, align 1
  %7034 = icmp eq i32 %7021, 0
  %7035 = zext i1 %7034 to i8
  store i8 %7035, i8* %20, align 1
  %7036 = lshr i32 %7021, 31
  %7037 = trunc i32 %7036 to i8
  store i8 %7037, i8* %21, align 1
  %7038 = lshr i32 %7019, 31
  %7039 = lshr i32 %7014, 31
  %7040 = xor i32 %7039, %7038
  %7041 = xor i32 %7036, %7038
  %7042 = add nuw nsw i32 %7041, %7040
  %7043 = icmp eq i32 %7042, 2
  %7044 = zext i1 %7043 to i8
  store i8 %7044, i8* %22, align 1
  %7045 = icmp ne i8 %7037, 0
  %7046 = xor i1 %7045, %7043
  %.v749 = select i1 %7046, i64 20, i64 45
  %7047 = add i64 %7009, %.v749
  store i64 %7047, i64* %3, align 8
  br i1 %7046, label %block_484a16, label %block_.L_484a2f

block_484a16:                                     ; preds = %block_.L_484a02
  %7048 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7048, i64* %RAX.i1659, align 8
  %7049 = add i64 %7048, 72688
  %7050 = add i64 %7047, 14
  store i64 %7050, i64* %3, align 8
  %7051 = inttoptr i64 %7049 to i32*
  %7052 = load i32, i32* %7051, align 4
  %7053 = zext i32 %7052 to i64
  store i64 %7053, i64* %RCX.i1588, align 8
  %7054 = add i64 %7010, -568
  %7055 = add i64 %7047, 20
  store i64 %7055, i64* %3, align 8
  %7056 = inttoptr i64 %7054 to i32*
  store i32 %7052, i32* %7056, align 4
  %7057 = load i64, i64* %3, align 8
  %7058 = add i64 %7057, 190
  store i64 %7058, i64* %3, align 8
  br label %block_.L_484ae8

block_.L_484a2f:                                  ; preds = %block_.L_484a02
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %7059 = add i64 %7010, -348
  %7060 = add i64 %7047, 8
  store i64 %7060, i64* %3, align 8
  %7061 = inttoptr i64 %7059 to i32*
  %7062 = load i32, i32* %7061, align 4
  %7063 = zext i32 %7062 to i64
  store i64 %7063, i64* %RCX.i1588, align 8
  %7064 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %7065 = add i64 %7064, 8504
  store i64 %7065, i64* %RDX.i1943, align 8
  %7066 = icmp ugt i64 %7064, -8505
  %7067 = zext i1 %7066 to i8
  store i8 %7067, i8* %17, align 1
  %7068 = trunc i64 %7065 to i32
  %7069 = and i32 %7068, 255
  %7070 = tail call i32 @llvm.ctpop.i32(i32 %7069)
  %7071 = trunc i32 %7070 to i8
  %7072 = and i8 %7071, 1
  %7073 = xor i8 %7072, 1
  store i8 %7073, i8* %18, align 1
  %7074 = xor i64 %7064, 16
  %7075 = xor i64 %7074, %7065
  %7076 = lshr i64 %7075, 4
  %7077 = trunc i64 %7076 to i8
  %7078 = and i8 %7077, 1
  store i8 %7078, i8* %19, align 1
  %7079 = icmp eq i64 %7065, 0
  %7080 = zext i1 %7079 to i8
  store i8 %7080, i8* %20, align 1
  %7081 = lshr i64 %7065, 63
  %7082 = trunc i64 %7081 to i8
  store i8 %7082, i8* %21, align 1
  %7083 = lshr i64 %7064, 63
  %7084 = xor i64 %7081, %7083
  %7085 = add nuw nsw i64 %7084, %7081
  %7086 = icmp eq i64 %7085, 2
  %7087 = zext i1 %7086 to i8
  store i8 %7087, i8* %22, align 1
  %7088 = add i64 %7010, -364
  %7089 = add i64 %7047, 30
  store i64 %7089, i64* %3, align 8
  %7090 = inttoptr i64 %7088 to i32*
  %7091 = load i32, i32* %7090, align 4
  %7092 = sext i32 %7091 to i64
  %7093 = shl nsw i64 %7092, 9
  store i64 %7093, i64* %RSI.i2015, align 8
  %7094 = add i64 %7093, %7065
  store i64 %7094, i64* %RDX.i1943, align 8
  %7095 = icmp ult i64 %7094, %7065
  %7096 = icmp ult i64 %7094, %7093
  %7097 = or i1 %7095, %7096
  %7098 = zext i1 %7097 to i8
  store i8 %7098, i8* %17, align 1
  %7099 = trunc i64 %7094 to i32
  %7100 = and i32 %7099, 255
  %7101 = tail call i32 @llvm.ctpop.i32(i32 %7100)
  %7102 = trunc i32 %7101 to i8
  %7103 = and i8 %7102, 1
  %7104 = xor i8 %7103, 1
  store i8 %7104, i8* %18, align 1
  %7105 = xor i64 %7065, %7094
  %7106 = lshr i64 %7105, 4
  %7107 = trunc i64 %7106 to i8
  %7108 = and i8 %7107, 1
  store i8 %7108, i8* %19, align 1
  %7109 = icmp eq i64 %7094, 0
  %7110 = zext i1 %7109 to i8
  store i8 %7110, i8* %20, align 1
  %7111 = lshr i64 %7094, 63
  %7112 = trunc i64 %7111 to i8
  store i8 %7112, i8* %21, align 1
  %7113 = lshr i64 %7092, 54
  %7114 = and i64 %7113, 1
  %7115 = xor i64 %7111, %7081
  %7116 = xor i64 %7111, %7114
  %7117 = add nuw nsw i64 %7115, %7116
  %7118 = icmp eq i64 %7117, 2
  %7119 = zext i1 %7118 to i8
  store i8 %7119, i8* %22, align 1
  %7120 = load i64, i64* %RBP.i, align 8
  %7121 = add i64 %7120, -220
  %7122 = add i64 %7047, 43
  store i64 %7122, i64* %3, align 8
  %7123 = inttoptr i64 %7121 to i32*
  %7124 = load i32, i32* %7123, align 4
  %7125 = zext i32 %7124 to i64
  store i64 %7125, i64* %RDI.i6998, align 8
  %7126 = add i64 %7120, -44
  %7127 = add i64 %7047, 46
  store i64 %7127, i64* %3, align 8
  %7128 = inttoptr i64 %7126 to i32*
  %7129 = load i32, i32* %7128, align 4
  %7130 = add i32 %7129, %7124
  %7131 = zext i32 %7130 to i64
  store i64 %7131, i64* %RDI.i6998, align 8
  %7132 = sext i32 %7130 to i64
  %7133 = shl nsw i64 %7132, 5
  store i64 %7133, i64* %RSI.i2015, align 8
  %7134 = load i64, i64* %RDX.i1943, align 8
  %7135 = add i64 %7133, %7134
  store i64 %7135, i64* %RDX.i1943, align 8
  %7136 = icmp ult i64 %7135, %7134
  %7137 = icmp ult i64 %7135, %7133
  %7138 = or i1 %7136, %7137
  %7139 = zext i1 %7138 to i8
  store i8 %7139, i8* %17, align 1
  %7140 = trunc i64 %7135 to i32
  %7141 = and i32 %7140, 255
  %7142 = tail call i32 @llvm.ctpop.i32(i32 %7141)
  %7143 = trunc i32 %7142 to i8
  %7144 = and i8 %7143, 1
  %7145 = xor i8 %7144, 1
  store i8 %7145, i8* %18, align 1
  %7146 = xor i64 %7134, %7135
  %7147 = lshr i64 %7146, 4
  %7148 = trunc i64 %7147 to i8
  %7149 = and i8 %7148, 1
  store i8 %7149, i8* %19, align 1
  %7150 = icmp eq i64 %7135, 0
  %7151 = zext i1 %7150 to i8
  store i8 %7151, i8* %20, align 1
  %7152 = lshr i64 %7135, 63
  %7153 = trunc i64 %7152 to i8
  store i8 %7153, i8* %21, align 1
  %7154 = lshr i64 %7134, 63
  %7155 = lshr i64 %7132, 58
  %7156 = and i64 %7155, 1
  %7157 = xor i64 %7152, %7154
  %7158 = xor i64 %7152, %7156
  %7159 = add nuw nsw i64 %7157, %7158
  %7160 = icmp eq i64 %7159, 2
  %7161 = zext i1 %7160 to i8
  store i8 %7161, i8* %22, align 1
  %7162 = load i64, i64* %RBP.i, align 8
  %7163 = add i64 %7162, -224
  %7164 = add i64 %7047, 62
  store i64 %7164, i64* %3, align 8
  %7165 = inttoptr i64 %7163 to i32*
  %7166 = load i32, i32* %7165, align 4
  %7167 = zext i32 %7166 to i64
  store i64 %7167, i64* %RDI.i6998, align 8
  %7168 = add i64 %7162, -48
  %7169 = add i64 %7047, 65
  store i64 %7169, i64* %3, align 8
  %7170 = inttoptr i64 %7168 to i32*
  %7171 = load i32, i32* %7170, align 4
  %7172 = add i32 %7171, %7166
  %7173 = zext i32 %7172 to i64
  store i64 %7173, i64* %RDI.i6998, align 8
  %7174 = icmp ult i32 %7172, %7166
  %7175 = icmp ult i32 %7172, %7171
  %7176 = or i1 %7174, %7175
  %7177 = zext i1 %7176 to i8
  store i8 %7177, i8* %17, align 1
  %7178 = and i32 %7172, 255
  %7179 = tail call i32 @llvm.ctpop.i32(i32 %7178)
  %7180 = trunc i32 %7179 to i8
  %7181 = and i8 %7180, 1
  %7182 = xor i8 %7181, 1
  store i8 %7182, i8* %18, align 1
  %7183 = xor i32 %7171, %7166
  %7184 = xor i32 %7183, %7172
  %7185 = lshr i32 %7184, 4
  %7186 = trunc i32 %7185 to i8
  %7187 = and i8 %7186, 1
  store i8 %7187, i8* %19, align 1
  %7188 = icmp eq i32 %7172, 0
  %7189 = zext i1 %7188 to i8
  store i8 %7189, i8* %20, align 1
  %7190 = lshr i32 %7172, 31
  %7191 = trunc i32 %7190 to i8
  store i8 %7191, i8* %21, align 1
  %7192 = lshr i32 %7166, 31
  %7193 = lshr i32 %7171, 31
  %7194 = xor i32 %7190, %7192
  %7195 = xor i32 %7190, %7193
  %7196 = add nuw nsw i32 %7194, %7195
  %7197 = icmp eq i32 %7196, 2
  %7198 = zext i1 %7197 to i8
  store i8 %7198, i8* %22, align 1
  %7199 = sext i32 %7172 to i64
  store i64 %7199, i64* %RSI.i2015, align 8
  %7200 = shl nsw i64 %7199, 1
  %7201 = add i64 %7135, %7200
  %7202 = add i64 %7047, 72
  store i64 %7202, i64* %3, align 8
  %7203 = inttoptr i64 %7201 to i16*
  %7204 = load i16, i16* %7203, align 2
  %7205 = zext i16 %7204 to i64
  store i64 %7205, i64* %RDI.i6998, align 8
  %7206 = load i64, i64* %RCX.i1588, align 8
  %7207 = zext i16 %7204 to i32
  %7208 = trunc i64 %7206 to i32
  %7209 = add i32 %7207, %7208
  %7210 = zext i32 %7209 to i64
  store i64 %7210, i64* %RCX.i1588, align 8
  %7211 = lshr i32 %7209, 31
  %7212 = load i32, i32* %EAX.i2033, align 4
  %7213 = sub i32 %7212, %7209
  %7214 = icmp ult i32 %7212, %7209
  %7215 = zext i1 %7214 to i8
  store i8 %7215, i8* %17, align 1
  %7216 = and i32 %7213, 255
  %7217 = tail call i32 @llvm.ctpop.i32(i32 %7216)
  %7218 = trunc i32 %7217 to i8
  %7219 = and i8 %7218, 1
  %7220 = xor i8 %7219, 1
  store i8 %7220, i8* %18, align 1
  %7221 = xor i32 %7209, %7212
  %7222 = xor i32 %7221, %7213
  %7223 = lshr i32 %7222, 4
  %7224 = trunc i32 %7223 to i8
  %7225 = and i8 %7224, 1
  store i8 %7225, i8* %19, align 1
  %7226 = icmp eq i32 %7213, 0
  %7227 = zext i1 %7226 to i8
  store i8 %7227, i8* %20, align 1
  %7228 = lshr i32 %7213, 31
  %7229 = trunc i32 %7228 to i8
  store i8 %7229, i8* %21, align 1
  %7230 = lshr i32 %7212, 31
  %7231 = xor i32 %7211, %7230
  %7232 = xor i32 %7228, %7230
  %7233 = add nuw nsw i32 %7232, %7231
  %7234 = icmp eq i32 %7233, 2
  %7235 = zext i1 %7234 to i8
  store i8 %7235, i8* %22, align 1
  %7236 = icmp ne i8 %7229, 0
  %7237 = xor i1 %7236, %7234
  %7238 = or i1 %7226, %7237
  %.v750 = select i1 %7238, i64 95, i64 82
  %7239 = add i64 %7047, %.v750
  store i64 %7239, i64* %3, align 8
  br i1 %7238, label %block_.L_484a8e, label %block_484a81

block_484a81:                                     ; preds = %block_.L_484a2f
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %7240 = load i64, i64* %RBP.i, align 8
  %7241 = add i64 %7240, -572
  %7242 = add i64 %7239, 8
  store i64 %7242, i64* %3, align 8
  %7243 = inttoptr i64 %7241 to i32*
  store i32 0, i32* %7243, align 4
  %7244 = load i64, i64* %3, align 8
  %7245 = add i64 %7244, 83
  store i64 %7245, i64* %3, align 8
  br label %block_.L_484adc

block_.L_484a8e:                                  ; preds = %block_.L_484a2f
  %7246 = load i64, i64* %RBP.i, align 8
  %7247 = add i64 %7246, -348
  %7248 = add i64 %7239, 6
  store i64 %7248, i64* %3, align 8
  %7249 = inttoptr i64 %7247 to i32*
  %7250 = load i32, i32* %7249, align 4
  %7251 = zext i32 %7250 to i64
  store i64 %7251, i64* %RAX.i1659, align 8
  %7252 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %7253 = add i64 %7252, 8504
  store i64 %7253, i64* %RCX.i1588, align 8
  %7254 = icmp ugt i64 %7252, -8505
  %7255 = zext i1 %7254 to i8
  store i8 %7255, i8* %17, align 1
  %7256 = trunc i64 %7253 to i32
  %7257 = and i32 %7256, 255
  %7258 = tail call i32 @llvm.ctpop.i32(i32 %7257)
  %7259 = trunc i32 %7258 to i8
  %7260 = and i8 %7259, 1
  %7261 = xor i8 %7260, 1
  store i8 %7261, i8* %18, align 1
  %7262 = xor i64 %7252, 16
  %7263 = xor i64 %7262, %7253
  %7264 = lshr i64 %7263, 4
  %7265 = trunc i64 %7264 to i8
  %7266 = and i8 %7265, 1
  store i8 %7266, i8* %19, align 1
  %7267 = icmp eq i64 %7253, 0
  %7268 = zext i1 %7267 to i8
  store i8 %7268, i8* %20, align 1
  %7269 = lshr i64 %7253, 63
  %7270 = trunc i64 %7269 to i8
  store i8 %7270, i8* %21, align 1
  %7271 = lshr i64 %7252, 63
  %7272 = xor i64 %7269, %7271
  %7273 = add nuw nsw i64 %7272, %7269
  %7274 = icmp eq i64 %7273, 2
  %7275 = zext i1 %7274 to i8
  store i8 %7275, i8* %22, align 1
  %7276 = add i64 %7246, -364
  %7277 = add i64 %7239, 28
  store i64 %7277, i64* %3, align 8
  %7278 = inttoptr i64 %7276 to i32*
  %7279 = load i32, i32* %7278, align 4
  %7280 = sext i32 %7279 to i64
  %7281 = shl nsw i64 %7280, 9
  store i64 %7281, i64* %RDX.i1943, align 8
  %7282 = add i64 %7281, %7253
  store i64 %7282, i64* %RCX.i1588, align 8
  %7283 = icmp ult i64 %7282, %7253
  %7284 = icmp ult i64 %7282, %7281
  %7285 = or i1 %7283, %7284
  %7286 = zext i1 %7285 to i8
  store i8 %7286, i8* %17, align 1
  %7287 = trunc i64 %7282 to i32
  %7288 = and i32 %7287, 255
  %7289 = tail call i32 @llvm.ctpop.i32(i32 %7288)
  %7290 = trunc i32 %7289 to i8
  %7291 = and i8 %7290, 1
  %7292 = xor i8 %7291, 1
  store i8 %7292, i8* %18, align 1
  %7293 = xor i64 %7253, %7282
  %7294 = lshr i64 %7293, 4
  %7295 = trunc i64 %7294 to i8
  %7296 = and i8 %7295, 1
  store i8 %7296, i8* %19, align 1
  %7297 = icmp eq i64 %7282, 0
  %7298 = zext i1 %7297 to i8
  store i8 %7298, i8* %20, align 1
  %7299 = lshr i64 %7282, 63
  %7300 = trunc i64 %7299 to i8
  store i8 %7300, i8* %21, align 1
  %7301 = lshr i64 %7280, 54
  %7302 = and i64 %7301, 1
  %7303 = xor i64 %7299, %7269
  %7304 = xor i64 %7299, %7302
  %7305 = add nuw nsw i64 %7303, %7304
  %7306 = icmp eq i64 %7305, 2
  %7307 = zext i1 %7306 to i8
  store i8 %7307, i8* %22, align 1
  %7308 = load i64, i64* %RBP.i, align 8
  %7309 = add i64 %7308, -220
  %7310 = add i64 %7239, 41
  store i64 %7310, i64* %3, align 8
  %7311 = inttoptr i64 %7309 to i32*
  %7312 = load i32, i32* %7311, align 4
  %7313 = zext i32 %7312 to i64
  store i64 %7313, i64* %RSI.i2015, align 8
  %7314 = add i64 %7308, -44
  %7315 = add i64 %7239, 44
  store i64 %7315, i64* %3, align 8
  %7316 = inttoptr i64 %7314 to i32*
  %7317 = load i32, i32* %7316, align 4
  %7318 = add i32 %7317, %7312
  %7319 = zext i32 %7318 to i64
  store i64 %7319, i64* %RSI.i2015, align 8
  %7320 = sext i32 %7318 to i64
  %7321 = shl nsw i64 %7320, 5
  store i64 %7321, i64* %RDX.i1943, align 8
  %7322 = load i64, i64* %RCX.i1588, align 8
  %7323 = add i64 %7321, %7322
  store i64 %7323, i64* %RCX.i1588, align 8
  %7324 = icmp ult i64 %7323, %7322
  %7325 = icmp ult i64 %7323, %7321
  %7326 = or i1 %7324, %7325
  %7327 = zext i1 %7326 to i8
  store i8 %7327, i8* %17, align 1
  %7328 = trunc i64 %7323 to i32
  %7329 = and i32 %7328, 255
  %7330 = tail call i32 @llvm.ctpop.i32(i32 %7329)
  %7331 = trunc i32 %7330 to i8
  %7332 = and i8 %7331, 1
  %7333 = xor i8 %7332, 1
  store i8 %7333, i8* %18, align 1
  %7334 = xor i64 %7322, %7323
  %7335 = lshr i64 %7334, 4
  %7336 = trunc i64 %7335 to i8
  %7337 = and i8 %7336, 1
  store i8 %7337, i8* %19, align 1
  %7338 = icmp eq i64 %7323, 0
  %7339 = zext i1 %7338 to i8
  store i8 %7339, i8* %20, align 1
  %7340 = lshr i64 %7323, 63
  %7341 = trunc i64 %7340 to i8
  store i8 %7341, i8* %21, align 1
  %7342 = lshr i64 %7322, 63
  %7343 = lshr i64 %7320, 58
  %7344 = and i64 %7343, 1
  %7345 = xor i64 %7340, %7342
  %7346 = xor i64 %7340, %7344
  %7347 = add nuw nsw i64 %7345, %7346
  %7348 = icmp eq i64 %7347, 2
  %7349 = zext i1 %7348 to i8
  store i8 %7349, i8* %22, align 1
  %7350 = load i64, i64* %RBP.i, align 8
  %7351 = add i64 %7350, -224
  %7352 = add i64 %7239, 60
  store i64 %7352, i64* %3, align 8
  %7353 = inttoptr i64 %7351 to i32*
  %7354 = load i32, i32* %7353, align 4
  %7355 = zext i32 %7354 to i64
  store i64 %7355, i64* %RSI.i2015, align 8
  %7356 = add i64 %7350, -48
  %7357 = add i64 %7239, 63
  store i64 %7357, i64* %3, align 8
  %7358 = inttoptr i64 %7356 to i32*
  %7359 = load i32, i32* %7358, align 4
  %7360 = add i32 %7359, %7354
  %7361 = zext i32 %7360 to i64
  store i64 %7361, i64* %RSI.i2015, align 8
  %7362 = icmp ult i32 %7360, %7354
  %7363 = icmp ult i32 %7360, %7359
  %7364 = or i1 %7362, %7363
  %7365 = zext i1 %7364 to i8
  store i8 %7365, i8* %17, align 1
  %7366 = and i32 %7360, 255
  %7367 = tail call i32 @llvm.ctpop.i32(i32 %7366)
  %7368 = trunc i32 %7367 to i8
  %7369 = and i8 %7368, 1
  %7370 = xor i8 %7369, 1
  store i8 %7370, i8* %18, align 1
  %7371 = xor i32 %7359, %7354
  %7372 = xor i32 %7371, %7360
  %7373 = lshr i32 %7372, 4
  %7374 = trunc i32 %7373 to i8
  %7375 = and i8 %7374, 1
  store i8 %7375, i8* %19, align 1
  %7376 = icmp eq i32 %7360, 0
  %7377 = zext i1 %7376 to i8
  store i8 %7377, i8* %20, align 1
  %7378 = lshr i32 %7360, 31
  %7379 = trunc i32 %7378 to i8
  store i8 %7379, i8* %21, align 1
  %7380 = lshr i32 %7354, 31
  %7381 = lshr i32 %7359, 31
  %7382 = xor i32 %7378, %7380
  %7383 = xor i32 %7378, %7381
  %7384 = add nuw nsw i32 %7382, %7383
  %7385 = icmp eq i32 %7384, 2
  %7386 = zext i1 %7385 to i8
  store i8 %7386, i8* %22, align 1
  %7387 = sext i32 %7360 to i64
  store i64 %7387, i64* %RDX.i1943, align 8
  %7388 = shl nsw i64 %7387, 1
  %7389 = add i64 %7323, %7388
  %7390 = add i64 %7239, 70
  store i64 %7390, i64* %3, align 8
  %7391 = inttoptr i64 %7389 to i16*
  %7392 = load i16, i16* %7391, align 2
  %7393 = zext i16 %7392 to i64
  store i64 %7393, i64* %RSI.i2015, align 8
  %7394 = load i64, i64* %RAX.i1659, align 8
  %7395 = zext i16 %7392 to i32
  %7396 = zext i16 %7392 to i64
  %7397 = trunc i64 %7394 to i32
  %7398 = add i32 %7395, %7397
  %7399 = zext i32 %7398 to i64
  store i64 %7399, i64* %RAX.i1659, align 8
  %7400 = icmp ult i32 %7398, %7397
  %7401 = icmp ult i32 %7398, %7395
  %7402 = or i1 %7400, %7401
  %7403 = zext i1 %7402 to i8
  store i8 %7403, i8* %17, align 1
  %7404 = and i32 %7398, 255
  %7405 = tail call i32 @llvm.ctpop.i32(i32 %7404)
  %7406 = trunc i32 %7405 to i8
  %7407 = and i8 %7406, 1
  %7408 = xor i8 %7407, 1
  store i8 %7408, i8* %18, align 1
  %7409 = xor i64 %7396, %7394
  %7410 = trunc i64 %7409 to i32
  %7411 = xor i32 %7410, %7398
  %7412 = lshr i32 %7411, 4
  %7413 = trunc i32 %7412 to i8
  %7414 = and i8 %7413, 1
  store i8 %7414, i8* %19, align 1
  %7415 = icmp eq i32 %7398, 0
  %7416 = zext i1 %7415 to i8
  store i8 %7416, i8* %20, align 1
  %7417 = lshr i32 %7398, 31
  %7418 = trunc i32 %7417 to i8
  store i8 %7418, i8* %21, align 1
  %7419 = lshr i32 %7397, 31
  %7420 = xor i32 %7417, %7419
  %7421 = add nuw nsw i32 %7420, %7417
  %7422 = icmp eq i32 %7421, 2
  %7423 = zext i1 %7422 to i8
  store i8 %7423, i8* %22, align 1
  %7424 = add i64 %7350, -572
  %7425 = add i64 %7239, 78
  store i64 %7425, i64* %3, align 8
  %7426 = inttoptr i64 %7424 to i32*
  store i32 %7398, i32* %7426, align 4
  %.pre642 = load i64, i64* %3, align 8
  br label %block_.L_484adc

block_.L_484adc:                                  ; preds = %block_.L_484a8e, %block_484a81
  %7427 = phi i64 [ %.pre642, %block_.L_484a8e ], [ %7245, %block_484a81 ]
  %7428 = load i64, i64* %RBP.i, align 8
  %7429 = add i64 %7428, -572
  %7430 = add i64 %7427, 6
  store i64 %7430, i64* %3, align 8
  %7431 = inttoptr i64 %7429 to i32*
  %7432 = load i32, i32* %7431, align 4
  %7433 = zext i32 %7432 to i64
  store i64 %7433, i64* %RAX.i1659, align 8
  %7434 = add i64 %7428, -568
  %7435 = add i64 %7427, 12
  store i64 %7435, i64* %3, align 8
  %7436 = inttoptr i64 %7434 to i32*
  store i32 %7432, i32* %7436, align 4
  %.pre643 = load i64, i64* %3, align 8
  br label %block_.L_484ae8

block_.L_484ae8:                                  ; preds = %block_.L_484adc, %block_484a16
  %7437 = phi i64 [ %.pre643, %block_.L_484adc ], [ %7058, %block_484a16 ]
  %7438 = load i64, i64* %RBP.i, align 8
  %7439 = add i64 %7438, -568
  %7440 = add i64 %7437, 6
  store i64 %7440, i64* %3, align 8
  %7441 = inttoptr i64 %7439 to i32*
  %7442 = load i32, i32* %7441, align 4
  %7443 = zext i32 %7442 to i64
  store i64 %7443, i64* %RAX.i1659, align 8
  store i64 0, i64* %RCX.i1588, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %7444 = trunc i32 %7442 to i16
  store i16 %7444, i16* %DX.i4863, align 2
  %7445 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %7445, i64* %RSI.i2015, align 8
  %7446 = add i64 %7445, 6464
  %7447 = add i64 %7437, 26
  store i64 %7447, i64* %3, align 8
  %7448 = inttoptr i64 %7446 to i64*
  %7449 = load i64, i64* %7448, align 8
  store i64 %7449, i64* %RSI.i2015, align 8
  %7450 = add i64 %7437, 29
  store i64 %7450, i64* %3, align 8
  %7451 = inttoptr i64 %7449 to i64*
  %7452 = load i64, i64* %7451, align 8
  store i64 %7452, i64* %RSI.i2015, align 8
  %7453 = add i64 %7438, -232
  %7454 = add i64 %7437, 35
  store i64 %7454, i64* %3, align 8
  %7455 = inttoptr i64 %7453 to i32*
  %7456 = load i32, i32* %7455, align 4
  %7457 = zext i32 %7456 to i64
  store i64 %7457, i64* %RAX.i1659, align 8
  %7458 = add i64 %7438, -48
  %7459 = add i64 %7437, 38
  store i64 %7459, i64* %3, align 8
  %7460 = inttoptr i64 %7458 to i32*
  %7461 = load i32, i32* %7460, align 4
  %7462 = add i32 %7461, %7456
  %7463 = zext i32 %7462 to i64
  store i64 %7463, i64* %RAX.i1659, align 8
  %7464 = icmp ult i32 %7462, %7456
  %7465 = icmp ult i32 %7462, %7461
  %7466 = or i1 %7464, %7465
  %7467 = zext i1 %7466 to i8
  store i8 %7467, i8* %17, align 1
  %7468 = and i32 %7462, 255
  %7469 = tail call i32 @llvm.ctpop.i32(i32 %7468)
  %7470 = trunc i32 %7469 to i8
  %7471 = and i8 %7470, 1
  %7472 = xor i8 %7471, 1
  store i8 %7472, i8* %18, align 1
  %7473 = xor i32 %7461, %7456
  %7474 = xor i32 %7473, %7462
  %7475 = lshr i32 %7474, 4
  %7476 = trunc i32 %7475 to i8
  %7477 = and i8 %7476, 1
  store i8 %7477, i8* %19, align 1
  %7478 = icmp eq i32 %7462, 0
  %7479 = zext i1 %7478 to i8
  store i8 %7479, i8* %20, align 1
  %7480 = lshr i32 %7462, 31
  %7481 = trunc i32 %7480 to i8
  store i8 %7481, i8* %21, align 1
  %7482 = lshr i32 %7456, 31
  %7483 = lshr i32 %7461, 31
  %7484 = xor i32 %7480, %7482
  %7485 = xor i32 %7480, %7483
  %7486 = add nuw nsw i32 %7484, %7485
  %7487 = icmp eq i32 %7486, 2
  %7488 = zext i1 %7487 to i8
  store i8 %7488, i8* %22, align 1
  %7489 = sext i32 %7462 to i64
  store i64 %7489, i64* %RDI.i6998, align 8
  %7490 = shl nsw i64 %7489, 3
  %7491 = add i64 %7452, %7490
  %7492 = add i64 %7437, 45
  store i64 %7492, i64* %3, align 8
  %7493 = inttoptr i64 %7491 to i64*
  %7494 = load i64, i64* %7493, align 8
  store i64 %7494, i64* %RSI.i2015, align 8
  %7495 = load i64, i64* %RBP.i, align 8
  %7496 = add i64 %7495, -228
  %7497 = add i64 %7437, 51
  store i64 %7497, i64* %3, align 8
  %7498 = inttoptr i64 %7496 to i32*
  %7499 = load i32, i32* %7498, align 4
  %7500 = zext i32 %7499 to i64
  store i64 %7500, i64* %RAX.i1659, align 8
  %7501 = add i64 %7495, -44
  %7502 = add i64 %7437, 54
  store i64 %7502, i64* %3, align 8
  %7503 = inttoptr i64 %7501 to i32*
  %7504 = load i32, i32* %7503, align 4
  %7505 = add i32 %7504, %7499
  %7506 = zext i32 %7505 to i64
  store i64 %7506, i64* %RAX.i1659, align 8
  %7507 = icmp ult i32 %7505, %7499
  %7508 = icmp ult i32 %7505, %7504
  %7509 = or i1 %7507, %7508
  %7510 = zext i1 %7509 to i8
  store i8 %7510, i8* %17, align 1
  %7511 = and i32 %7505, 255
  %7512 = tail call i32 @llvm.ctpop.i32(i32 %7511)
  %7513 = trunc i32 %7512 to i8
  %7514 = and i8 %7513, 1
  %7515 = xor i8 %7514, 1
  store i8 %7515, i8* %18, align 1
  %7516 = xor i32 %7504, %7499
  %7517 = xor i32 %7516, %7505
  %7518 = lshr i32 %7517, 4
  %7519 = trunc i32 %7518 to i8
  %7520 = and i8 %7519, 1
  store i8 %7520, i8* %19, align 1
  %7521 = icmp eq i32 %7505, 0
  %7522 = zext i1 %7521 to i8
  store i8 %7522, i8* %20, align 1
  %7523 = lshr i32 %7505, 31
  %7524 = trunc i32 %7523 to i8
  store i8 %7524, i8* %21, align 1
  %7525 = lshr i32 %7499, 31
  %7526 = lshr i32 %7504, 31
  %7527 = xor i32 %7523, %7525
  %7528 = xor i32 %7523, %7526
  %7529 = add nuw nsw i32 %7527, %7528
  %7530 = icmp eq i32 %7529, 2
  %7531 = zext i1 %7530 to i8
  store i8 %7531, i8* %22, align 1
  %7532 = sext i32 %7505 to i64
  store i64 %7532, i64* %RDI.i6998, align 8
  %7533 = shl nsw i64 %7532, 1
  %7534 = add i64 %7494, %7533
  %7535 = load i16, i16* %DX.i4863, align 2
  %7536 = add i64 %7437, 61
  store i64 %7536, i64* %3, align 8
  %7537 = inttoptr i64 %7534 to i16*
  store i16 %7535, i16* %7537, align 2
  %7538 = load i64, i64* %3, align 8
  %7539 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7539, i64* %RSI.i2015, align 8
  %7540 = add i64 %7539, 72684
  %7541 = add i64 %7538, 14
  store i64 %7541, i64* %3, align 8
  %7542 = inttoptr i64 %7540 to i32*
  %7543 = load i32, i32* %7542, align 4
  %7544 = zext i32 %7543 to i64
  store i64 %7544, i64* %RAX.i1659, align 8
  %7545 = load i64, i64* %RBP.i, align 8
  %7546 = add i64 %7545, -344
  %7547 = add i64 %7538, 21
  store i64 %7547, i64* %3, align 8
  %7548 = inttoptr i64 %7546 to i32*
  %7549 = load i32, i32* %7548, align 4
  %7550 = zext i32 %7549 to i64
  store i64 %7550, i64* %25, align 8
  %7551 = add i64 %7539, 184
  store i64 %7551, i64* %RSI.i2015, align 8
  %7552 = icmp ugt i64 %7539, -185
  %7553 = zext i1 %7552 to i8
  store i8 %7553, i8* %17, align 1
  %7554 = trunc i64 %7551 to i32
  %7555 = and i32 %7554, 255
  %7556 = tail call i32 @llvm.ctpop.i32(i32 %7555)
  %7557 = trunc i32 %7556 to i8
  %7558 = and i8 %7557, 1
  %7559 = xor i8 %7558, 1
  store i8 %7559, i8* %18, align 1
  %7560 = xor i64 %7539, 16
  %7561 = xor i64 %7560, %7551
  %7562 = lshr i64 %7561, 4
  %7563 = trunc i64 %7562 to i8
  %7564 = and i8 %7563, 1
  store i8 %7564, i8* %19, align 1
  %7565 = icmp eq i64 %7551, 0
  %7566 = zext i1 %7565 to i8
  store i8 %7566, i8* %20, align 1
  %7567 = lshr i64 %7551, 63
  %7568 = trunc i64 %7567 to i8
  store i8 %7568, i8* %21, align 1
  %7569 = lshr i64 %7539, 63
  %7570 = xor i64 %7567, %7569
  %7571 = add nuw nsw i64 %7570, %7567
  %7572 = icmp eq i64 %7571, 2
  %7573 = zext i1 %7572 to i8
  store i8 %7573, i8* %22, align 1
  %7574 = add i64 %7545, -36
  %7575 = add i64 %7538, 40
  store i64 %7575, i64* %3, align 8
  %7576 = inttoptr i64 %7574 to i32*
  %7577 = load i32, i32* %7576, align 4
  %7578 = sext i32 %7577 to i64
  %7579 = shl nsw i64 %7578, 9
  store i64 %7579, i64* %RDI.i6998, align 8
  %7580 = add i64 %7579, %7551
  store i64 %7580, i64* %RSI.i2015, align 8
  %7581 = icmp ult i64 %7580, %7551
  %7582 = icmp ult i64 %7580, %7579
  %7583 = or i1 %7581, %7582
  %7584 = zext i1 %7583 to i8
  store i8 %7584, i8* %17, align 1
  %7585 = trunc i64 %7580 to i32
  %7586 = and i32 %7585, 255
  %7587 = tail call i32 @llvm.ctpop.i32(i32 %7586)
  %7588 = trunc i32 %7587 to i8
  %7589 = and i8 %7588, 1
  %7590 = xor i8 %7589, 1
  store i8 %7590, i8* %18, align 1
  %7591 = xor i64 %7551, %7580
  %7592 = lshr i64 %7591, 4
  %7593 = trunc i64 %7592 to i8
  %7594 = and i8 %7593, 1
  store i8 %7594, i8* %19, align 1
  %7595 = icmp eq i64 %7580, 0
  %7596 = zext i1 %7595 to i8
  store i8 %7596, i8* %20, align 1
  %7597 = lshr i64 %7580, 63
  %7598 = trunc i64 %7597 to i8
  store i8 %7598, i8* %21, align 1
  %7599 = lshr i64 %7578, 54
  %7600 = and i64 %7599, 1
  %7601 = xor i64 %7597, %7567
  %7602 = xor i64 %7597, %7600
  %7603 = add nuw nsw i64 %7601, %7602
  %7604 = icmp eq i64 %7603, 2
  %7605 = zext i1 %7604 to i8
  store i8 %7605, i8* %22, align 1
  %7606 = load i64, i64* %RBP.i, align 8
  %7607 = add i64 %7606, -48
  %7608 = add i64 %7538, 51
  store i64 %7608, i64* %3, align 8
  %7609 = inttoptr i64 %7607 to i32*
  %7610 = load i32, i32* %7609, align 4
  %7611 = sext i32 %7610 to i64
  %7612 = shl nsw i64 %7611, 5
  store i64 %7612, i64* %RDI.i6998, align 8
  %7613 = add i64 %7612, %7580
  store i64 %7613, i64* %RSI.i2015, align 8
  %7614 = icmp ult i64 %7613, %7580
  %7615 = icmp ult i64 %7613, %7612
  %7616 = or i1 %7614, %7615
  %7617 = zext i1 %7616 to i8
  store i8 %7617, i8* %17, align 1
  %7618 = trunc i64 %7613 to i32
  %7619 = and i32 %7618, 255
  %7620 = tail call i32 @llvm.ctpop.i32(i32 %7619)
  %7621 = trunc i32 %7620 to i8
  %7622 = and i8 %7621, 1
  %7623 = xor i8 %7622, 1
  store i8 %7623, i8* %18, align 1
  %7624 = xor i64 %7580, %7613
  %7625 = lshr i64 %7624, 4
  %7626 = trunc i64 %7625 to i8
  %7627 = and i8 %7626, 1
  store i8 %7627, i8* %19, align 1
  %7628 = icmp eq i64 %7613, 0
  %7629 = zext i1 %7628 to i8
  store i8 %7629, i8* %20, align 1
  %7630 = lshr i64 %7613, 63
  %7631 = trunc i64 %7630 to i8
  store i8 %7631, i8* %21, align 1
  %7632 = lshr i64 %7611, 58
  %7633 = and i64 %7632, 1
  %7634 = xor i64 %7630, %7597
  %7635 = xor i64 %7630, %7633
  %7636 = add nuw nsw i64 %7634, %7635
  %7637 = icmp eq i64 %7636, 2
  %7638 = zext i1 %7637 to i8
  store i8 %7638, i8* %22, align 1
  %7639 = add i64 %7606, -44
  %7640 = add i64 %7538, 62
  store i64 %7640, i64* %3, align 8
  %7641 = inttoptr i64 %7639 to i32*
  %7642 = load i32, i32* %7641, align 4
  %7643 = sext i32 %7642 to i64
  store i64 %7643, i64* %RDI.i6998, align 8
  %7644 = shl nsw i64 %7643, 1
  %7645 = add i64 %7644, %7613
  %7646 = add i64 %7538, 67
  store i64 %7646, i64* %3, align 8
  %7647 = inttoptr i64 %7645 to i16*
  %7648 = load i16, i16* %7647, align 2
  %7649 = zext i16 %7648 to i64
  store i64 %7649, i64* %R9.i1633, align 8
  %7650 = load i32, i32* %R8D.i1615, align 4
  %7651 = zext i16 %7648 to i32
  %7652 = add i32 %7651, %7650
  %7653 = zext i32 %7652 to i64
  store i64 %7653, i64* %25, align 8
  %7654 = lshr i32 %7652, 31
  %7655 = load i32, i32* %ECX.i6962, align 4
  %7656 = sub i32 %7655, %7652
  %7657 = icmp ult i32 %7655, %7652
  %7658 = zext i1 %7657 to i8
  store i8 %7658, i8* %17, align 1
  %7659 = and i32 %7656, 255
  %7660 = tail call i32 @llvm.ctpop.i32(i32 %7659)
  %7661 = trunc i32 %7660 to i8
  %7662 = and i8 %7661, 1
  %7663 = xor i8 %7662, 1
  store i8 %7663, i8* %18, align 1
  %7664 = xor i32 %7652, %7655
  %7665 = xor i32 %7664, %7656
  %7666 = lshr i32 %7665, 4
  %7667 = trunc i32 %7666 to i8
  %7668 = and i8 %7667, 1
  store i8 %7668, i8* %19, align 1
  %7669 = icmp eq i32 %7656, 0
  %7670 = zext i1 %7669 to i8
  store i8 %7670, i8* %20, align 1
  %7671 = lshr i32 %7656, 31
  %7672 = trunc i32 %7671 to i8
  store i8 %7672, i8* %21, align 1
  %7673 = lshr i32 %7655, 31
  %7674 = xor i32 %7654, %7673
  %7675 = xor i32 %7671, %7673
  %7676 = add nuw nsw i32 %7675, %7674
  %7677 = icmp eq i32 %7676, 2
  %7678 = zext i1 %7677 to i8
  store i8 %7678, i8* %22, align 1
  %7679 = load i64, i64* %RBP.i, align 8
  %7680 = add i64 %7679, -576
  %7681 = load i32, i32* %EAX.i2033, align 4
  %7682 = add i64 %7538, 79
  store i64 %7682, i64* %3, align 8
  %7683 = inttoptr i64 %7680 to i32*
  store i32 %7681, i32* %7683, align 4
  %7684 = load i64, i64* %3, align 8
  %7685 = load i8, i8* %20, align 1
  %7686 = icmp ne i8 %7685, 0
  %7687 = load i8, i8* %21, align 1
  %7688 = icmp ne i8 %7687, 0
  %7689 = load i8, i8* %22, align 1
  %7690 = icmp ne i8 %7689, 0
  %7691 = xor i1 %7688, %7690
  %7692 = or i1 %7686, %7691
  %.v880 = select i1 %7692, i64 19, i64 6
  %7693 = add i64 %7684, %.v880
  store i64 %7693, i64* %3, align 8
  br i1 %7692, label %block_.L_484b87, label %block_484b7a

block_484b7a:                                     ; preds = %block_.L_484ae8
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %7694 = load i64, i64* %RBP.i, align 8
  %7695 = add i64 %7694, -580
  %7696 = add i64 %7693, 8
  store i64 %7696, i64* %3, align 8
  %7697 = inttoptr i64 %7695 to i32*
  store i32 0, i32* %7697, align 4
  %7698 = load i64, i64* %3, align 8
  %7699 = add i64 %7698, 64
  store i64 %7699, i64* %3, align 8
  br label %block_.L_484bc2

block_.L_484b87:                                  ; preds = %block_.L_484ae8
  %7700 = load i64, i64* %RBP.i, align 8
  %7701 = add i64 %7700, -344
  %7702 = add i64 %7693, 6
  store i64 %7702, i64* %3, align 8
  %7703 = inttoptr i64 %7701 to i32*
  %7704 = load i32, i32* %7703, align 4
  %7705 = zext i32 %7704 to i64
  store i64 %7705, i64* %RAX.i1659, align 8
  %7706 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %7707 = add i64 %7706, 184
  store i64 %7707, i64* %RCX.i1588, align 8
  %7708 = icmp ugt i64 %7706, -185
  %7709 = zext i1 %7708 to i8
  store i8 %7709, i8* %17, align 1
  %7710 = trunc i64 %7707 to i32
  %7711 = and i32 %7710, 255
  %7712 = tail call i32 @llvm.ctpop.i32(i32 %7711)
  %7713 = trunc i32 %7712 to i8
  %7714 = and i8 %7713, 1
  %7715 = xor i8 %7714, 1
  store i8 %7715, i8* %18, align 1
  %7716 = xor i64 %7706, 16
  %7717 = xor i64 %7716, %7707
  %7718 = lshr i64 %7717, 4
  %7719 = trunc i64 %7718 to i8
  %7720 = and i8 %7719, 1
  store i8 %7720, i8* %19, align 1
  %7721 = icmp eq i64 %7707, 0
  %7722 = zext i1 %7721 to i8
  store i8 %7722, i8* %20, align 1
  %7723 = lshr i64 %7707, 63
  %7724 = trunc i64 %7723 to i8
  store i8 %7724, i8* %21, align 1
  %7725 = lshr i64 %7706, 63
  %7726 = xor i64 %7723, %7725
  %7727 = add nuw nsw i64 %7726, %7723
  %7728 = icmp eq i64 %7727, 2
  %7729 = zext i1 %7728 to i8
  store i8 %7729, i8* %22, align 1
  %7730 = add i64 %7700, -36
  %7731 = add i64 %7693, 25
  store i64 %7731, i64* %3, align 8
  %7732 = inttoptr i64 %7730 to i32*
  %7733 = load i32, i32* %7732, align 4
  %7734 = sext i32 %7733 to i64
  %7735 = shl nsw i64 %7734, 9
  store i64 %7735, i64* %RDX.i1943, align 8
  %7736 = add i64 %7735, %7707
  store i64 %7736, i64* %RCX.i1588, align 8
  %7737 = icmp ult i64 %7736, %7707
  %7738 = icmp ult i64 %7736, %7735
  %7739 = or i1 %7737, %7738
  %7740 = zext i1 %7739 to i8
  store i8 %7740, i8* %17, align 1
  %7741 = trunc i64 %7736 to i32
  %7742 = and i32 %7741, 255
  %7743 = tail call i32 @llvm.ctpop.i32(i32 %7742)
  %7744 = trunc i32 %7743 to i8
  %7745 = and i8 %7744, 1
  %7746 = xor i8 %7745, 1
  store i8 %7746, i8* %18, align 1
  %7747 = xor i64 %7707, %7736
  %7748 = lshr i64 %7747, 4
  %7749 = trunc i64 %7748 to i8
  %7750 = and i8 %7749, 1
  store i8 %7750, i8* %19, align 1
  %7751 = icmp eq i64 %7736, 0
  %7752 = zext i1 %7751 to i8
  store i8 %7752, i8* %20, align 1
  %7753 = lshr i64 %7736, 63
  %7754 = trunc i64 %7753 to i8
  store i8 %7754, i8* %21, align 1
  %7755 = lshr i64 %7734, 54
  %7756 = and i64 %7755, 1
  %7757 = xor i64 %7753, %7723
  %7758 = xor i64 %7753, %7756
  %7759 = add nuw nsw i64 %7757, %7758
  %7760 = icmp eq i64 %7759, 2
  %7761 = zext i1 %7760 to i8
  store i8 %7761, i8* %22, align 1
  %7762 = load i64, i64* %RBP.i, align 8
  %7763 = add i64 %7762, -48
  %7764 = add i64 %7693, 36
  store i64 %7764, i64* %3, align 8
  %7765 = inttoptr i64 %7763 to i32*
  %7766 = load i32, i32* %7765, align 4
  %7767 = sext i32 %7766 to i64
  %7768 = shl nsw i64 %7767, 5
  store i64 %7768, i64* %RDX.i1943, align 8
  %7769 = add i64 %7768, %7736
  store i64 %7769, i64* %RCX.i1588, align 8
  %7770 = icmp ult i64 %7769, %7736
  %7771 = icmp ult i64 %7769, %7768
  %7772 = or i1 %7770, %7771
  %7773 = zext i1 %7772 to i8
  store i8 %7773, i8* %17, align 1
  %7774 = trunc i64 %7769 to i32
  %7775 = and i32 %7774, 255
  %7776 = tail call i32 @llvm.ctpop.i32(i32 %7775)
  %7777 = trunc i32 %7776 to i8
  %7778 = and i8 %7777, 1
  %7779 = xor i8 %7778, 1
  store i8 %7779, i8* %18, align 1
  %7780 = xor i64 %7736, %7769
  %7781 = lshr i64 %7780, 4
  %7782 = trunc i64 %7781 to i8
  %7783 = and i8 %7782, 1
  store i8 %7783, i8* %19, align 1
  %7784 = icmp eq i64 %7769, 0
  %7785 = zext i1 %7784 to i8
  store i8 %7785, i8* %20, align 1
  %7786 = lshr i64 %7769, 63
  %7787 = trunc i64 %7786 to i8
  store i8 %7787, i8* %21, align 1
  %7788 = lshr i64 %7767, 58
  %7789 = and i64 %7788, 1
  %7790 = xor i64 %7786, %7753
  %7791 = xor i64 %7786, %7789
  %7792 = add nuw nsw i64 %7790, %7791
  %7793 = icmp eq i64 %7792, 2
  %7794 = zext i1 %7793 to i8
  store i8 %7794, i8* %22, align 1
  %7795 = add i64 %7762, -44
  %7796 = add i64 %7693, 47
  store i64 %7796, i64* %3, align 8
  %7797 = inttoptr i64 %7795 to i32*
  %7798 = load i32, i32* %7797, align 4
  %7799 = sext i32 %7798 to i64
  store i64 %7799, i64* %RDX.i1943, align 8
  %7800 = shl nsw i64 %7799, 1
  %7801 = add i64 %7800, %7769
  %7802 = add i64 %7693, 51
  store i64 %7802, i64* %3, align 8
  %7803 = inttoptr i64 %7801 to i16*
  %7804 = load i16, i16* %7803, align 2
  %7805 = zext i16 %7804 to i64
  store i64 %7805, i64* %RSI.i2015, align 8
  %7806 = load i64, i64* %RAX.i1659, align 8
  %7807 = zext i16 %7804 to i32
  %7808 = zext i16 %7804 to i64
  %7809 = trunc i64 %7806 to i32
  %7810 = add i32 %7807, %7809
  %7811 = zext i32 %7810 to i64
  store i64 %7811, i64* %RAX.i1659, align 8
  %7812 = icmp ult i32 %7810, %7809
  %7813 = icmp ult i32 %7810, %7807
  %7814 = or i1 %7812, %7813
  %7815 = zext i1 %7814 to i8
  store i8 %7815, i8* %17, align 1
  %7816 = and i32 %7810, 255
  %7817 = tail call i32 @llvm.ctpop.i32(i32 %7816)
  %7818 = trunc i32 %7817 to i8
  %7819 = and i8 %7818, 1
  %7820 = xor i8 %7819, 1
  store i8 %7820, i8* %18, align 1
  %7821 = xor i64 %7808, %7806
  %7822 = trunc i64 %7821 to i32
  %7823 = xor i32 %7822, %7810
  %7824 = lshr i32 %7823, 4
  %7825 = trunc i32 %7824 to i8
  %7826 = and i8 %7825, 1
  store i8 %7826, i8* %19, align 1
  %7827 = icmp eq i32 %7810, 0
  %7828 = zext i1 %7827 to i8
  store i8 %7828, i8* %20, align 1
  %7829 = lshr i32 %7810, 31
  %7830 = trunc i32 %7829 to i8
  store i8 %7830, i8* %21, align 1
  %7831 = lshr i32 %7809, 31
  %7832 = xor i32 %7829, %7831
  %7833 = add nuw nsw i32 %7832, %7829
  %7834 = icmp eq i32 %7833, 2
  %7835 = zext i1 %7834 to i8
  store i8 %7835, i8* %22, align 1
  %7836 = load i64, i64* %RBP.i, align 8
  %7837 = add i64 %7836, -580
  %7838 = add i64 %7693, 59
  store i64 %7838, i64* %3, align 8
  %7839 = inttoptr i64 %7837 to i32*
  store i32 %7810, i32* %7839, align 4
  %.pre644 = load i64, i64* %3, align 8
  br label %block_.L_484bc2

block_.L_484bc2:                                  ; preds = %block_.L_484b87, %block_484b7a
  %7840 = phi i64 [ %.pre644, %block_.L_484b87 ], [ %7699, %block_484b7a ]
  %7841 = load i64, i64* %RBP.i, align 8
  %7842 = add i64 %7841, -580
  %7843 = add i64 %7840, 6
  store i64 %7843, i64* %3, align 8
  %7844 = inttoptr i64 %7842 to i32*
  %7845 = load i32, i32* %7844, align 4
  %7846 = zext i32 %7845 to i64
  store i64 %7846, i64* %RAX.i1659, align 8
  %7847 = add i64 %7841, -576
  %7848 = add i64 %7840, 12
  store i64 %7848, i64* %3, align 8
  %7849 = inttoptr i64 %7847 to i32*
  %7850 = load i32, i32* %7849, align 4
  %7851 = zext i32 %7850 to i64
  store i64 %7851, i64* %RCX.i1588, align 8
  %7852 = sub i32 %7850, %7845
  %7853 = icmp ult i32 %7850, %7845
  %7854 = zext i1 %7853 to i8
  store i8 %7854, i8* %17, align 1
  %7855 = and i32 %7852, 255
  %7856 = tail call i32 @llvm.ctpop.i32(i32 %7855)
  %7857 = trunc i32 %7856 to i8
  %7858 = and i8 %7857, 1
  %7859 = xor i8 %7858, 1
  store i8 %7859, i8* %18, align 1
  %7860 = xor i32 %7845, %7850
  %7861 = xor i32 %7860, %7852
  %7862 = lshr i32 %7861, 4
  %7863 = trunc i32 %7862 to i8
  %7864 = and i8 %7863, 1
  store i8 %7864, i8* %19, align 1
  %7865 = icmp eq i32 %7852, 0
  %7866 = zext i1 %7865 to i8
  store i8 %7866, i8* %20, align 1
  %7867 = lshr i32 %7852, 31
  %7868 = trunc i32 %7867 to i8
  store i8 %7868, i8* %21, align 1
  %7869 = lshr i32 %7850, 31
  %7870 = lshr i32 %7845, 31
  %7871 = xor i32 %7870, %7869
  %7872 = xor i32 %7867, %7869
  %7873 = add nuw nsw i32 %7872, %7871
  %7874 = icmp eq i32 %7873, 2
  %7875 = zext i1 %7874 to i8
  store i8 %7875, i8* %22, align 1
  %7876 = icmp ne i8 %7868, 0
  %7877 = xor i1 %7876, %7874
  %.v751 = select i1 %7877, i64 20, i64 45
  %7878 = add i64 %7840, %.v751
  store i64 %7878, i64* %3, align 8
  br i1 %7877, label %block_484bd6, label %block_.L_484bef

block_484bd6:                                     ; preds = %block_.L_484bc2
  %7879 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7879, i64* %RAX.i1659, align 8
  %7880 = add i64 %7879, 72684
  %7881 = add i64 %7878, 14
  store i64 %7881, i64* %3, align 8
  %7882 = inttoptr i64 %7880 to i32*
  %7883 = load i32, i32* %7882, align 4
  %7884 = zext i32 %7883 to i64
  store i64 %7884, i64* %RCX.i1588, align 8
  %7885 = add i64 %7841, -584
  %7886 = add i64 %7878, 20
  store i64 %7886, i64* %3, align 8
  %7887 = inttoptr i64 %7885 to i32*
  store i32 %7883, i32* %7887, align 4
  %7888 = load i64, i64* %3, align 8
  %7889 = add i64 %7888, 152
  store i64 %7889, i64* %3, align 8
  br label %block_.L_484c82

block_.L_484bef:                                  ; preds = %block_.L_484bc2
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %7890 = add i64 %7841, -344
  %7891 = add i64 %7878, 8
  store i64 %7891, i64* %3, align 8
  %7892 = inttoptr i64 %7890 to i32*
  %7893 = load i32, i32* %7892, align 4
  %7894 = zext i32 %7893 to i64
  store i64 %7894, i64* %RCX.i1588, align 8
  %7895 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %7896 = add i64 %7895, 184
  store i64 %7896, i64* %RDX.i1943, align 8
  %7897 = icmp ugt i64 %7895, -185
  %7898 = zext i1 %7897 to i8
  store i8 %7898, i8* %17, align 1
  %7899 = trunc i64 %7896 to i32
  %7900 = and i32 %7899, 255
  %7901 = tail call i32 @llvm.ctpop.i32(i32 %7900)
  %7902 = trunc i32 %7901 to i8
  %7903 = and i8 %7902, 1
  %7904 = xor i8 %7903, 1
  store i8 %7904, i8* %18, align 1
  %7905 = xor i64 %7895, 16
  %7906 = xor i64 %7905, %7896
  %7907 = lshr i64 %7906, 4
  %7908 = trunc i64 %7907 to i8
  %7909 = and i8 %7908, 1
  store i8 %7909, i8* %19, align 1
  %7910 = icmp eq i64 %7896, 0
  %7911 = zext i1 %7910 to i8
  store i8 %7911, i8* %20, align 1
  %7912 = lshr i64 %7896, 63
  %7913 = trunc i64 %7912 to i8
  store i8 %7913, i8* %21, align 1
  %7914 = lshr i64 %7895, 63
  %7915 = xor i64 %7912, %7914
  %7916 = add nuw nsw i64 %7915, %7912
  %7917 = icmp eq i64 %7916, 2
  %7918 = zext i1 %7917 to i8
  store i8 %7918, i8* %22, align 1
  %7919 = add i64 %7841, -36
  %7920 = add i64 %7878, 27
  store i64 %7920, i64* %3, align 8
  %7921 = inttoptr i64 %7919 to i32*
  %7922 = load i32, i32* %7921, align 4
  %7923 = sext i32 %7922 to i64
  %7924 = shl nsw i64 %7923, 9
  store i64 %7924, i64* %RSI.i2015, align 8
  %7925 = add i64 %7924, %7896
  store i64 %7925, i64* %RDX.i1943, align 8
  %7926 = icmp ult i64 %7925, %7896
  %7927 = icmp ult i64 %7925, %7924
  %7928 = or i1 %7926, %7927
  %7929 = zext i1 %7928 to i8
  store i8 %7929, i8* %17, align 1
  %7930 = trunc i64 %7925 to i32
  %7931 = and i32 %7930, 255
  %7932 = tail call i32 @llvm.ctpop.i32(i32 %7931)
  %7933 = trunc i32 %7932 to i8
  %7934 = and i8 %7933, 1
  %7935 = xor i8 %7934, 1
  store i8 %7935, i8* %18, align 1
  %7936 = xor i64 %7896, %7925
  %7937 = lshr i64 %7936, 4
  %7938 = trunc i64 %7937 to i8
  %7939 = and i8 %7938, 1
  store i8 %7939, i8* %19, align 1
  %7940 = icmp eq i64 %7925, 0
  %7941 = zext i1 %7940 to i8
  store i8 %7941, i8* %20, align 1
  %7942 = lshr i64 %7925, 63
  %7943 = trunc i64 %7942 to i8
  store i8 %7943, i8* %21, align 1
  %7944 = lshr i64 %7923, 54
  %7945 = and i64 %7944, 1
  %7946 = xor i64 %7942, %7912
  %7947 = xor i64 %7942, %7945
  %7948 = add nuw nsw i64 %7946, %7947
  %7949 = icmp eq i64 %7948, 2
  %7950 = zext i1 %7949 to i8
  store i8 %7950, i8* %22, align 1
  %7951 = load i64, i64* %RBP.i, align 8
  %7952 = add i64 %7951, -48
  %7953 = add i64 %7878, 38
  store i64 %7953, i64* %3, align 8
  %7954 = inttoptr i64 %7952 to i32*
  %7955 = load i32, i32* %7954, align 4
  %7956 = sext i32 %7955 to i64
  %7957 = shl nsw i64 %7956, 5
  store i64 %7957, i64* %RSI.i2015, align 8
  %7958 = add i64 %7957, %7925
  store i64 %7958, i64* %RDX.i1943, align 8
  %7959 = icmp ult i64 %7958, %7925
  %7960 = icmp ult i64 %7958, %7957
  %7961 = or i1 %7959, %7960
  %7962 = zext i1 %7961 to i8
  store i8 %7962, i8* %17, align 1
  %7963 = trunc i64 %7958 to i32
  %7964 = and i32 %7963, 255
  %7965 = tail call i32 @llvm.ctpop.i32(i32 %7964)
  %7966 = trunc i32 %7965 to i8
  %7967 = and i8 %7966, 1
  %7968 = xor i8 %7967, 1
  store i8 %7968, i8* %18, align 1
  %7969 = xor i64 %7925, %7958
  %7970 = lshr i64 %7969, 4
  %7971 = trunc i64 %7970 to i8
  %7972 = and i8 %7971, 1
  store i8 %7972, i8* %19, align 1
  %7973 = icmp eq i64 %7958, 0
  %7974 = zext i1 %7973 to i8
  store i8 %7974, i8* %20, align 1
  %7975 = lshr i64 %7958, 63
  %7976 = trunc i64 %7975 to i8
  store i8 %7976, i8* %21, align 1
  %7977 = lshr i64 %7956, 58
  %7978 = and i64 %7977, 1
  %7979 = xor i64 %7975, %7942
  %7980 = xor i64 %7975, %7978
  %7981 = add nuw nsw i64 %7979, %7980
  %7982 = icmp eq i64 %7981, 2
  %7983 = zext i1 %7982 to i8
  store i8 %7983, i8* %22, align 1
  %7984 = add i64 %7951, -44
  %7985 = add i64 %7878, 49
  store i64 %7985, i64* %3, align 8
  %7986 = inttoptr i64 %7984 to i32*
  %7987 = load i32, i32* %7986, align 4
  %7988 = sext i32 %7987 to i64
  store i64 %7988, i64* %RSI.i2015, align 8
  %7989 = shl nsw i64 %7988, 1
  %7990 = add i64 %7989, %7958
  %7991 = add i64 %7878, 53
  store i64 %7991, i64* %3, align 8
  %7992 = inttoptr i64 %7990 to i16*
  %7993 = load i16, i16* %7992, align 2
  %7994 = zext i16 %7993 to i64
  store i64 %7994, i64* %RDI.i6998, align 8
  %7995 = load i64, i64* %RCX.i1588, align 8
  %7996 = zext i16 %7993 to i32
  %7997 = trunc i64 %7995 to i32
  %7998 = add i32 %7996, %7997
  %7999 = zext i32 %7998 to i64
  store i64 %7999, i64* %RCX.i1588, align 8
  %8000 = lshr i32 %7998, 31
  %8001 = load i32, i32* %EAX.i2033, align 4
  %8002 = sub i32 %8001, %7998
  %8003 = icmp ult i32 %8001, %7998
  %8004 = zext i1 %8003 to i8
  store i8 %8004, i8* %17, align 1
  %8005 = and i32 %8002, 255
  %8006 = tail call i32 @llvm.ctpop.i32(i32 %8005)
  %8007 = trunc i32 %8006 to i8
  %8008 = and i8 %8007, 1
  %8009 = xor i8 %8008, 1
  store i8 %8009, i8* %18, align 1
  %8010 = xor i32 %7998, %8001
  %8011 = xor i32 %8010, %8002
  %8012 = lshr i32 %8011, 4
  %8013 = trunc i32 %8012 to i8
  %8014 = and i8 %8013, 1
  store i8 %8014, i8* %19, align 1
  %8015 = icmp eq i32 %8002, 0
  %8016 = zext i1 %8015 to i8
  store i8 %8016, i8* %20, align 1
  %8017 = lshr i32 %8002, 31
  %8018 = trunc i32 %8017 to i8
  store i8 %8018, i8* %21, align 1
  %8019 = lshr i32 %8001, 31
  %8020 = xor i32 %8000, %8019
  %8021 = xor i32 %8017, %8019
  %8022 = add nuw nsw i32 %8021, %8020
  %8023 = icmp eq i32 %8022, 2
  %8024 = zext i1 %8023 to i8
  store i8 %8024, i8* %22, align 1
  %8025 = icmp ne i8 %8018, 0
  %8026 = xor i1 %8025, %8023
  %8027 = or i1 %8015, %8026
  %.v752 = select i1 %8027, i64 76, i64 63
  %8028 = add i64 %7878, %.v752
  store i64 %8028, i64* %3, align 8
  br i1 %8027, label %block_.L_484c3b, label %block_484c2e

block_484c2e:                                     ; preds = %block_.L_484bef
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %8029 = load i64, i64* %RBP.i, align 8
  %8030 = add i64 %8029, -588
  %8031 = add i64 %8028, 8
  store i64 %8031, i64* %3, align 8
  %8032 = inttoptr i64 %8030 to i32*
  store i32 0, i32* %8032, align 4
  %8033 = load i64, i64* %3, align 8
  %8034 = add i64 %8033, 64
  store i64 %8034, i64* %3, align 8
  br label %block_.L_484c76

block_.L_484c3b:                                  ; preds = %block_.L_484bef
  %8035 = load i64, i64* %RBP.i, align 8
  %8036 = add i64 %8035, -344
  %8037 = add i64 %8028, 6
  store i64 %8037, i64* %3, align 8
  %8038 = inttoptr i64 %8036 to i32*
  %8039 = load i32, i32* %8038, align 4
  %8040 = zext i32 %8039 to i64
  store i64 %8040, i64* %RAX.i1659, align 8
  %8041 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %8042 = add i64 %8041, 184
  store i64 %8042, i64* %RCX.i1588, align 8
  %8043 = icmp ugt i64 %8041, -185
  %8044 = zext i1 %8043 to i8
  store i8 %8044, i8* %17, align 1
  %8045 = trunc i64 %8042 to i32
  %8046 = and i32 %8045, 255
  %8047 = tail call i32 @llvm.ctpop.i32(i32 %8046)
  %8048 = trunc i32 %8047 to i8
  %8049 = and i8 %8048, 1
  %8050 = xor i8 %8049, 1
  store i8 %8050, i8* %18, align 1
  %8051 = xor i64 %8041, 16
  %8052 = xor i64 %8051, %8042
  %8053 = lshr i64 %8052, 4
  %8054 = trunc i64 %8053 to i8
  %8055 = and i8 %8054, 1
  store i8 %8055, i8* %19, align 1
  %8056 = icmp eq i64 %8042, 0
  %8057 = zext i1 %8056 to i8
  store i8 %8057, i8* %20, align 1
  %8058 = lshr i64 %8042, 63
  %8059 = trunc i64 %8058 to i8
  store i8 %8059, i8* %21, align 1
  %8060 = lshr i64 %8041, 63
  %8061 = xor i64 %8058, %8060
  %8062 = add nuw nsw i64 %8061, %8058
  %8063 = icmp eq i64 %8062, 2
  %8064 = zext i1 %8063 to i8
  store i8 %8064, i8* %22, align 1
  %8065 = add i64 %8035, -36
  %8066 = add i64 %8028, 25
  store i64 %8066, i64* %3, align 8
  %8067 = inttoptr i64 %8065 to i32*
  %8068 = load i32, i32* %8067, align 4
  %8069 = sext i32 %8068 to i64
  %8070 = shl nsw i64 %8069, 9
  store i64 %8070, i64* %RDX.i1943, align 8
  %8071 = add i64 %8070, %8042
  store i64 %8071, i64* %RCX.i1588, align 8
  %8072 = icmp ult i64 %8071, %8042
  %8073 = icmp ult i64 %8071, %8070
  %8074 = or i1 %8072, %8073
  %8075 = zext i1 %8074 to i8
  store i8 %8075, i8* %17, align 1
  %8076 = trunc i64 %8071 to i32
  %8077 = and i32 %8076, 255
  %8078 = tail call i32 @llvm.ctpop.i32(i32 %8077)
  %8079 = trunc i32 %8078 to i8
  %8080 = and i8 %8079, 1
  %8081 = xor i8 %8080, 1
  store i8 %8081, i8* %18, align 1
  %8082 = xor i64 %8042, %8071
  %8083 = lshr i64 %8082, 4
  %8084 = trunc i64 %8083 to i8
  %8085 = and i8 %8084, 1
  store i8 %8085, i8* %19, align 1
  %8086 = icmp eq i64 %8071, 0
  %8087 = zext i1 %8086 to i8
  store i8 %8087, i8* %20, align 1
  %8088 = lshr i64 %8071, 63
  %8089 = trunc i64 %8088 to i8
  store i8 %8089, i8* %21, align 1
  %8090 = lshr i64 %8069, 54
  %8091 = and i64 %8090, 1
  %8092 = xor i64 %8088, %8058
  %8093 = xor i64 %8088, %8091
  %8094 = add nuw nsw i64 %8092, %8093
  %8095 = icmp eq i64 %8094, 2
  %8096 = zext i1 %8095 to i8
  store i8 %8096, i8* %22, align 1
  %8097 = load i64, i64* %RBP.i, align 8
  %8098 = add i64 %8097, -48
  %8099 = add i64 %8028, 36
  store i64 %8099, i64* %3, align 8
  %8100 = inttoptr i64 %8098 to i32*
  %8101 = load i32, i32* %8100, align 4
  %8102 = sext i32 %8101 to i64
  %8103 = shl nsw i64 %8102, 5
  store i64 %8103, i64* %RDX.i1943, align 8
  %8104 = add i64 %8103, %8071
  store i64 %8104, i64* %RCX.i1588, align 8
  %8105 = icmp ult i64 %8104, %8071
  %8106 = icmp ult i64 %8104, %8103
  %8107 = or i1 %8105, %8106
  %8108 = zext i1 %8107 to i8
  store i8 %8108, i8* %17, align 1
  %8109 = trunc i64 %8104 to i32
  %8110 = and i32 %8109, 255
  %8111 = tail call i32 @llvm.ctpop.i32(i32 %8110)
  %8112 = trunc i32 %8111 to i8
  %8113 = and i8 %8112, 1
  %8114 = xor i8 %8113, 1
  store i8 %8114, i8* %18, align 1
  %8115 = xor i64 %8071, %8104
  %8116 = lshr i64 %8115, 4
  %8117 = trunc i64 %8116 to i8
  %8118 = and i8 %8117, 1
  store i8 %8118, i8* %19, align 1
  %8119 = icmp eq i64 %8104, 0
  %8120 = zext i1 %8119 to i8
  store i8 %8120, i8* %20, align 1
  %8121 = lshr i64 %8104, 63
  %8122 = trunc i64 %8121 to i8
  store i8 %8122, i8* %21, align 1
  %8123 = lshr i64 %8102, 58
  %8124 = and i64 %8123, 1
  %8125 = xor i64 %8121, %8088
  %8126 = xor i64 %8121, %8124
  %8127 = add nuw nsw i64 %8125, %8126
  %8128 = icmp eq i64 %8127, 2
  %8129 = zext i1 %8128 to i8
  store i8 %8129, i8* %22, align 1
  %8130 = add i64 %8097, -44
  %8131 = add i64 %8028, 47
  store i64 %8131, i64* %3, align 8
  %8132 = inttoptr i64 %8130 to i32*
  %8133 = load i32, i32* %8132, align 4
  %8134 = sext i32 %8133 to i64
  store i64 %8134, i64* %RDX.i1943, align 8
  %8135 = shl nsw i64 %8134, 1
  %8136 = add i64 %8135, %8104
  %8137 = add i64 %8028, 51
  store i64 %8137, i64* %3, align 8
  %8138 = inttoptr i64 %8136 to i16*
  %8139 = load i16, i16* %8138, align 2
  %8140 = zext i16 %8139 to i64
  store i64 %8140, i64* %RSI.i2015, align 8
  %8141 = load i64, i64* %RAX.i1659, align 8
  %8142 = zext i16 %8139 to i32
  %8143 = zext i16 %8139 to i64
  %8144 = trunc i64 %8141 to i32
  %8145 = add i32 %8142, %8144
  %8146 = zext i32 %8145 to i64
  store i64 %8146, i64* %RAX.i1659, align 8
  %8147 = icmp ult i32 %8145, %8144
  %8148 = icmp ult i32 %8145, %8142
  %8149 = or i1 %8147, %8148
  %8150 = zext i1 %8149 to i8
  store i8 %8150, i8* %17, align 1
  %8151 = and i32 %8145, 255
  %8152 = tail call i32 @llvm.ctpop.i32(i32 %8151)
  %8153 = trunc i32 %8152 to i8
  %8154 = and i8 %8153, 1
  %8155 = xor i8 %8154, 1
  store i8 %8155, i8* %18, align 1
  %8156 = xor i64 %8143, %8141
  %8157 = trunc i64 %8156 to i32
  %8158 = xor i32 %8157, %8145
  %8159 = lshr i32 %8158, 4
  %8160 = trunc i32 %8159 to i8
  %8161 = and i8 %8160, 1
  store i8 %8161, i8* %19, align 1
  %8162 = icmp eq i32 %8145, 0
  %8163 = zext i1 %8162 to i8
  store i8 %8163, i8* %20, align 1
  %8164 = lshr i32 %8145, 31
  %8165 = trunc i32 %8164 to i8
  store i8 %8165, i8* %21, align 1
  %8166 = lshr i32 %8144, 31
  %8167 = xor i32 %8164, %8166
  %8168 = add nuw nsw i32 %8167, %8164
  %8169 = icmp eq i32 %8168, 2
  %8170 = zext i1 %8169 to i8
  store i8 %8170, i8* %22, align 1
  %8171 = load i64, i64* %RBP.i, align 8
  %8172 = add i64 %8171, -588
  %8173 = add i64 %8028, 59
  store i64 %8173, i64* %3, align 8
  %8174 = inttoptr i64 %8172 to i32*
  store i32 %8145, i32* %8174, align 4
  %.pre645 = load i64, i64* %3, align 8
  br label %block_.L_484c76

block_.L_484c76:                                  ; preds = %block_.L_484c3b, %block_484c2e
  %8175 = phi i64 [ %.pre645, %block_.L_484c3b ], [ %8034, %block_484c2e ]
  %8176 = load i64, i64* %RBP.i, align 8
  %8177 = add i64 %8176, -588
  %8178 = add i64 %8175, 6
  store i64 %8178, i64* %3, align 8
  %8179 = inttoptr i64 %8177 to i32*
  %8180 = load i32, i32* %8179, align 4
  %8181 = zext i32 %8180 to i64
  store i64 %8181, i64* %RAX.i1659, align 8
  %8182 = add i64 %8176, -584
  %8183 = add i64 %8175, 12
  store i64 %8183, i64* %3, align 8
  %8184 = inttoptr i64 %8182 to i32*
  store i32 %8180, i32* %8184, align 4
  %.pre646 = load i64, i64* %3, align 8
  br label %block_.L_484c82

block_.L_484c82:                                  ; preds = %block_.L_484c76, %block_484bd6
  %8185 = phi i64 [ %.pre646, %block_.L_484c76 ], [ %7889, %block_484bd6 ]
  %8186 = load i64, i64* %RBP.i, align 8
  %8187 = add i64 %8186, -584
  %8188 = add i64 %8185, 6
  store i64 %8188, i64* %3, align 8
  %8189 = inttoptr i64 %8187 to i32*
  %8190 = load i32, i32* %8189, align 4
  %8191 = zext i32 %8190 to i64
  store i64 %8191, i64* %RAX.i1659, align 8
  store i64 0, i64* %RCX.i1588, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %8192 = trunc i32 %8190 to i16
  store i16 %8192, i16* %DX.i4863, align 2
  %8193 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %8193, i64* %RSI.i2015, align 8
  %8194 = add i64 %8193, 6424
  %8195 = add i64 %8185, 26
  store i64 %8195, i64* %3, align 8
  %8196 = inttoptr i64 %8194 to i64*
  %8197 = load i64, i64* %8196, align 8
  store i64 %8197, i64* %RSI.i2015, align 8
  %8198 = add i64 %8186, -232
  %8199 = add i64 %8185, 32
  store i64 %8199, i64* %3, align 8
  %8200 = inttoptr i64 %8198 to i32*
  %8201 = load i32, i32* %8200, align 4
  %8202 = zext i32 %8201 to i64
  store i64 %8202, i64* %RAX.i1659, align 8
  %8203 = add i64 %8186, -48
  %8204 = add i64 %8185, 35
  store i64 %8204, i64* %3, align 8
  %8205 = inttoptr i64 %8203 to i32*
  %8206 = load i32, i32* %8205, align 4
  %8207 = add i32 %8206, %8201
  %8208 = zext i32 %8207 to i64
  store i64 %8208, i64* %RAX.i1659, align 8
  %8209 = icmp ult i32 %8207, %8201
  %8210 = icmp ult i32 %8207, %8206
  %8211 = or i1 %8209, %8210
  %8212 = zext i1 %8211 to i8
  store i8 %8212, i8* %17, align 1
  %8213 = and i32 %8207, 255
  %8214 = tail call i32 @llvm.ctpop.i32(i32 %8213)
  %8215 = trunc i32 %8214 to i8
  %8216 = and i8 %8215, 1
  %8217 = xor i8 %8216, 1
  store i8 %8217, i8* %18, align 1
  %8218 = xor i32 %8206, %8201
  %8219 = xor i32 %8218, %8207
  %8220 = lshr i32 %8219, 4
  %8221 = trunc i32 %8220 to i8
  %8222 = and i8 %8221, 1
  store i8 %8222, i8* %19, align 1
  %8223 = icmp eq i32 %8207, 0
  %8224 = zext i1 %8223 to i8
  store i8 %8224, i8* %20, align 1
  %8225 = lshr i32 %8207, 31
  %8226 = trunc i32 %8225 to i8
  store i8 %8226, i8* %21, align 1
  %8227 = lshr i32 %8201, 31
  %8228 = lshr i32 %8206, 31
  %8229 = xor i32 %8225, %8227
  %8230 = xor i32 %8225, %8228
  %8231 = add nuw nsw i32 %8229, %8230
  %8232 = icmp eq i32 %8231, 2
  %8233 = zext i1 %8232 to i8
  store i8 %8233, i8* %22, align 1
  %8234 = sext i32 %8207 to i64
  store i64 %8234, i64* %RDI.i6998, align 8
  %8235 = shl nsw i64 %8234, 3
  %8236 = add i64 %8197, %8235
  %8237 = add i64 %8185, 42
  store i64 %8237, i64* %3, align 8
  %8238 = inttoptr i64 %8236 to i64*
  %8239 = load i64, i64* %8238, align 8
  store i64 %8239, i64* %RSI.i2015, align 8
  %8240 = load i64, i64* %RBP.i, align 8
  %8241 = add i64 %8240, -228
  %8242 = add i64 %8185, 48
  store i64 %8242, i64* %3, align 8
  %8243 = inttoptr i64 %8241 to i32*
  %8244 = load i32, i32* %8243, align 4
  %8245 = zext i32 %8244 to i64
  store i64 %8245, i64* %RAX.i1659, align 8
  %8246 = add i64 %8240, -44
  %8247 = add i64 %8185, 51
  store i64 %8247, i64* %3, align 8
  %8248 = inttoptr i64 %8246 to i32*
  %8249 = load i32, i32* %8248, align 4
  %8250 = add i32 %8249, %8244
  %8251 = zext i32 %8250 to i64
  store i64 %8251, i64* %RAX.i1659, align 8
  %8252 = icmp ult i32 %8250, %8244
  %8253 = icmp ult i32 %8250, %8249
  %8254 = or i1 %8252, %8253
  %8255 = zext i1 %8254 to i8
  store i8 %8255, i8* %17, align 1
  %8256 = and i32 %8250, 255
  %8257 = tail call i32 @llvm.ctpop.i32(i32 %8256)
  %8258 = trunc i32 %8257 to i8
  %8259 = and i8 %8258, 1
  %8260 = xor i8 %8259, 1
  store i8 %8260, i8* %18, align 1
  %8261 = xor i32 %8249, %8244
  %8262 = xor i32 %8261, %8250
  %8263 = lshr i32 %8262, 4
  %8264 = trunc i32 %8263 to i8
  %8265 = and i8 %8264, 1
  store i8 %8265, i8* %19, align 1
  %8266 = icmp eq i32 %8250, 0
  %8267 = zext i1 %8266 to i8
  store i8 %8267, i8* %20, align 1
  %8268 = lshr i32 %8250, 31
  %8269 = trunc i32 %8268 to i8
  store i8 %8269, i8* %21, align 1
  %8270 = lshr i32 %8244, 31
  %8271 = lshr i32 %8249, 31
  %8272 = xor i32 %8268, %8270
  %8273 = xor i32 %8268, %8271
  %8274 = add nuw nsw i32 %8272, %8273
  %8275 = icmp eq i32 %8274, 2
  %8276 = zext i1 %8275 to i8
  store i8 %8276, i8* %22, align 1
  %8277 = sext i32 %8250 to i64
  store i64 %8277, i64* %RDI.i6998, align 8
  %8278 = shl nsw i64 %8277, 1
  %8279 = add i64 %8239, %8278
  %8280 = load i16, i16* %DX.i4863, align 2
  %8281 = add i64 %8185, 58
  store i64 %8281, i64* %3, align 8
  %8282 = inttoptr i64 %8279 to i16*
  store i16 %8280, i16* %8282, align 2
  %8283 = load i64, i64* %3, align 8
  %8284 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8284, i64* %RSI.i2015, align 8
  %8285 = add i64 %8284, 72688
  %8286 = add i64 %8283, 14
  store i64 %8286, i64* %3, align 8
  %8287 = inttoptr i64 %8285 to i32*
  %8288 = load i32, i32* %8287, align 4
  %8289 = zext i32 %8288 to i64
  store i64 %8289, i64* %RAX.i1659, align 8
  %8290 = load i64, i64* %RBP.i, align 8
  %8291 = add i64 %8290, -340
  %8292 = add i64 %8283, 21
  store i64 %8292, i64* %3, align 8
  %8293 = inttoptr i64 %8291 to i32*
  %8294 = load i32, i32* %8293, align 4
  %8295 = zext i32 %8294 to i64
  store i64 %8295, i64* %25, align 8
  %8296 = add i64 %8284, 8504
  %8297 = lshr i64 %8296, 63
  %8298 = add i64 %8284, 10552
  store i64 %8298, i64* %RSI.i2015, align 8
  %8299 = icmp ugt i64 %8296, -2049
  %8300 = zext i1 %8299 to i8
  store i8 %8300, i8* %17, align 1
  %8301 = trunc i64 %8298 to i32
  %8302 = and i32 %8301, 255
  %8303 = tail call i32 @llvm.ctpop.i32(i32 %8302)
  %8304 = trunc i32 %8303 to i8
  %8305 = and i8 %8304, 1
  %8306 = xor i8 %8305, 1
  store i8 %8306, i8* %18, align 1
  %8307 = xor i64 %8298, %8296
  %8308 = lshr i64 %8307, 4
  %8309 = trunc i64 %8308 to i8
  %8310 = and i8 %8309, 1
  store i8 %8310, i8* %19, align 1
  %8311 = icmp eq i64 %8298, 0
  %8312 = zext i1 %8311 to i8
  store i8 %8312, i8* %20, align 1
  %8313 = lshr i64 %8298, 63
  %8314 = trunc i64 %8313 to i8
  store i8 %8314, i8* %21, align 1
  %8315 = xor i64 %8313, %8297
  %8316 = add nuw nsw i64 %8315, %8313
  %8317 = icmp eq i64 %8316, 2
  %8318 = zext i1 %8317 to i8
  store i8 %8318, i8* %22, align 1
  %8319 = add i64 %8290, -364
  %8320 = add i64 %8283, 50
  store i64 %8320, i64* %3, align 8
  %8321 = inttoptr i64 %8319 to i32*
  %8322 = load i32, i32* %8321, align 4
  %8323 = sext i32 %8322 to i64
  %8324 = shl nsw i64 %8323, 9
  store i64 %8324, i64* %RDI.i6998, align 8
  %8325 = add i64 %8324, %8298
  store i64 %8325, i64* %RSI.i2015, align 8
  %8326 = icmp ult i64 %8325, %8298
  %8327 = icmp ult i64 %8325, %8324
  %8328 = or i1 %8326, %8327
  %8329 = zext i1 %8328 to i8
  store i8 %8329, i8* %17, align 1
  %8330 = trunc i64 %8325 to i32
  %8331 = and i32 %8330, 255
  %8332 = tail call i32 @llvm.ctpop.i32(i32 %8331)
  %8333 = trunc i32 %8332 to i8
  %8334 = and i8 %8333, 1
  %8335 = xor i8 %8334, 1
  store i8 %8335, i8* %18, align 1
  %8336 = xor i64 %8298, %8325
  %8337 = lshr i64 %8336, 4
  %8338 = trunc i64 %8337 to i8
  %8339 = and i8 %8338, 1
  store i8 %8339, i8* %19, align 1
  %8340 = icmp eq i64 %8325, 0
  %8341 = zext i1 %8340 to i8
  store i8 %8341, i8* %20, align 1
  %8342 = lshr i64 %8325, 63
  %8343 = trunc i64 %8342 to i8
  store i8 %8343, i8* %21, align 1
  %8344 = lshr i64 %8323, 54
  %8345 = and i64 %8344, 1
  %8346 = xor i64 %8342, %8313
  %8347 = xor i64 %8342, %8345
  %8348 = add nuw nsw i64 %8346, %8347
  %8349 = icmp eq i64 %8348, 2
  %8350 = zext i1 %8349 to i8
  store i8 %8350, i8* %22, align 1
  %8351 = load i64, i64* %RBP.i, align 8
  %8352 = add i64 %8351, -220
  %8353 = add i64 %8283, 64
  store i64 %8353, i64* %3, align 8
  %8354 = inttoptr i64 %8352 to i32*
  %8355 = load i32, i32* %8354, align 4
  %8356 = zext i32 %8355 to i64
  store i64 %8356, i64* %R9.i1633, align 8
  %8357 = add i64 %8351, -44
  %8358 = add i64 %8283, 68
  store i64 %8358, i64* %3, align 8
  %8359 = inttoptr i64 %8357 to i32*
  %8360 = load i32, i32* %8359, align 4
  %8361 = add i32 %8360, %8355
  %8362 = zext i32 %8361 to i64
  store i64 %8362, i64* %R9.i1633, align 8
  %8363 = sext i32 %8361 to i64
  %8364 = shl nsw i64 %8363, 5
  store i64 %8364, i64* %RDI.i6998, align 8
  %8365 = load i64, i64* %RSI.i2015, align 8
  %8366 = add i64 %8364, %8365
  store i64 %8366, i64* %RSI.i2015, align 8
  %8367 = icmp ult i64 %8366, %8365
  %8368 = icmp ult i64 %8366, %8364
  %8369 = or i1 %8367, %8368
  %8370 = zext i1 %8369 to i8
  store i8 %8370, i8* %17, align 1
  %8371 = trunc i64 %8366 to i32
  %8372 = and i32 %8371, 255
  %8373 = tail call i32 @llvm.ctpop.i32(i32 %8372)
  %8374 = trunc i32 %8373 to i8
  %8375 = and i8 %8374, 1
  %8376 = xor i8 %8375, 1
  store i8 %8376, i8* %18, align 1
  %8377 = xor i64 %8365, %8366
  %8378 = lshr i64 %8377, 4
  %8379 = trunc i64 %8378 to i8
  %8380 = and i8 %8379, 1
  store i8 %8380, i8* %19, align 1
  %8381 = icmp eq i64 %8366, 0
  %8382 = zext i1 %8381 to i8
  store i8 %8382, i8* %20, align 1
  %8383 = lshr i64 %8366, 63
  %8384 = trunc i64 %8383 to i8
  store i8 %8384, i8* %21, align 1
  %8385 = lshr i64 %8365, 63
  %8386 = lshr i64 %8363, 58
  %8387 = and i64 %8386, 1
  %8388 = xor i64 %8383, %8385
  %8389 = xor i64 %8383, %8387
  %8390 = add nuw nsw i64 %8388, %8389
  %8391 = icmp eq i64 %8390, 2
  %8392 = zext i1 %8391 to i8
  store i8 %8392, i8* %22, align 1
  %8393 = load i64, i64* %RBP.i, align 8
  %8394 = add i64 %8393, -224
  %8395 = add i64 %8283, 85
  store i64 %8395, i64* %3, align 8
  %8396 = inttoptr i64 %8394 to i32*
  %8397 = load i32, i32* %8396, align 4
  %8398 = zext i32 %8397 to i64
  store i64 %8398, i64* %R9.i1633, align 8
  %8399 = add i64 %8393, -48
  %8400 = add i64 %8283, 89
  store i64 %8400, i64* %3, align 8
  %8401 = inttoptr i64 %8399 to i32*
  %8402 = load i32, i32* %8401, align 4
  %8403 = add i32 %8402, %8397
  %8404 = zext i32 %8403 to i64
  store i64 %8404, i64* %R9.i1633, align 8
  %8405 = icmp ult i32 %8403, %8397
  %8406 = icmp ult i32 %8403, %8402
  %8407 = or i1 %8405, %8406
  %8408 = zext i1 %8407 to i8
  store i8 %8408, i8* %17, align 1
  %8409 = and i32 %8403, 255
  %8410 = tail call i32 @llvm.ctpop.i32(i32 %8409)
  %8411 = trunc i32 %8410 to i8
  %8412 = and i8 %8411, 1
  %8413 = xor i8 %8412, 1
  store i8 %8413, i8* %18, align 1
  %8414 = xor i32 %8402, %8397
  %8415 = xor i32 %8414, %8403
  %8416 = lshr i32 %8415, 4
  %8417 = trunc i32 %8416 to i8
  %8418 = and i8 %8417, 1
  store i8 %8418, i8* %19, align 1
  %8419 = icmp eq i32 %8403, 0
  %8420 = zext i1 %8419 to i8
  store i8 %8420, i8* %20, align 1
  %8421 = lshr i32 %8403, 31
  %8422 = trunc i32 %8421 to i8
  store i8 %8422, i8* %21, align 1
  %8423 = lshr i32 %8397, 31
  %8424 = lshr i32 %8402, 31
  %8425 = xor i32 %8421, %8423
  %8426 = xor i32 %8421, %8424
  %8427 = add nuw nsw i32 %8425, %8426
  %8428 = icmp eq i32 %8427, 2
  %8429 = zext i1 %8428 to i8
  store i8 %8429, i8* %22, align 1
  %8430 = sext i32 %8403 to i64
  store i64 %8430, i64* %RDI.i6998, align 8
  %8431 = shl nsw i64 %8430, 1
  %8432 = add i64 %8366, %8431
  %8433 = add i64 %8283, 97
  store i64 %8433, i64* %3, align 8
  %8434 = inttoptr i64 %8432 to i16*
  %8435 = load i16, i16* %8434, align 2
  %8436 = zext i16 %8435 to i64
  store i64 %8436, i64* %R9.i1633, align 8
  %8437 = load i32, i32* %R8D.i1615, align 4
  %8438 = zext i16 %8435 to i32
  %8439 = add i32 %8438, %8437
  %8440 = zext i32 %8439 to i64
  store i64 %8440, i64* %25, align 8
  %8441 = lshr i32 %8439, 31
  %8442 = load i32, i32* %ECX.i6962, align 4
  %8443 = sub i32 %8442, %8439
  %8444 = icmp ult i32 %8442, %8439
  %8445 = zext i1 %8444 to i8
  store i8 %8445, i8* %17, align 1
  %8446 = and i32 %8443, 255
  %8447 = tail call i32 @llvm.ctpop.i32(i32 %8446)
  %8448 = trunc i32 %8447 to i8
  %8449 = and i8 %8448, 1
  %8450 = xor i8 %8449, 1
  store i8 %8450, i8* %18, align 1
  %8451 = xor i32 %8439, %8442
  %8452 = xor i32 %8451, %8443
  %8453 = lshr i32 %8452, 4
  %8454 = trunc i32 %8453 to i8
  %8455 = and i8 %8454, 1
  store i8 %8455, i8* %19, align 1
  %8456 = icmp eq i32 %8443, 0
  %8457 = zext i1 %8456 to i8
  store i8 %8457, i8* %20, align 1
  %8458 = lshr i32 %8443, 31
  %8459 = trunc i32 %8458 to i8
  store i8 %8459, i8* %21, align 1
  %8460 = lshr i32 %8442, 31
  %8461 = xor i32 %8441, %8460
  %8462 = xor i32 %8458, %8460
  %8463 = add nuw nsw i32 %8462, %8461
  %8464 = icmp eq i32 %8463, 2
  %8465 = zext i1 %8464 to i8
  store i8 %8465, i8* %22, align 1
  %8466 = load i64, i64* %RBP.i, align 8
  %8467 = add i64 %8466, -592
  %8468 = load i32, i32* %EAX.i2033, align 4
  %8469 = add i64 %8283, 109
  store i64 %8469, i64* %3, align 8
  %8470 = inttoptr i64 %8467 to i32*
  store i32 %8468, i32* %8470, align 4
  %8471 = load i64, i64* %3, align 8
  %8472 = load i8, i8* %20, align 1
  %8473 = icmp ne i8 %8472, 0
  %8474 = load i8, i8* %21, align 1
  %8475 = icmp ne i8 %8474, 0
  %8476 = load i8, i8* %22, align 1
  %8477 = icmp ne i8 %8476, 0
  %8478 = xor i1 %8475, %8477
  %8479 = or i1 %8473, %8478
  %.v881 = select i1 %8479, i64 19, i64 6
  %8480 = add i64 %8471, %.v881
  store i64 %8480, i64* %3, align 8
  br i1 %8479, label %block_.L_484d3c, label %block_484d2f

block_484d2f:                                     ; preds = %block_.L_484c82
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %8481 = load i64, i64* %RBP.i, align 8
  %8482 = add i64 %8481, -596
  %8483 = add i64 %8480, 8
  store i64 %8483, i64* %3, align 8
  %8484 = inttoptr i64 %8482 to i32*
  store i32 0, i32* %8484, align 4
  %8485 = load i64, i64* %3, align 8
  %8486 = add i64 %8485, 90
  store i64 %8486, i64* %3, align 8
  br label %block_.L_484d91

block_.L_484d3c:                                  ; preds = %block_.L_484c82
  %8487 = load i64, i64* %RBP.i, align 8
  %8488 = add i64 %8487, -340
  %8489 = add i64 %8480, 6
  store i64 %8489, i64* %3, align 8
  %8490 = inttoptr i64 %8488 to i32*
  %8491 = load i32, i32* %8490, align 4
  %8492 = zext i32 %8491 to i64
  store i64 %8492, i64* %RAX.i1659, align 8
  %8493 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %8494 = add i64 %8493, 8504
  %8495 = lshr i64 %8494, 63
  %8496 = add i64 %8493, 10552
  store i64 %8496, i64* %RCX.i1588, align 8
  %8497 = icmp ugt i64 %8494, -2049
  %8498 = zext i1 %8497 to i8
  store i8 %8498, i8* %17, align 1
  %8499 = trunc i64 %8496 to i32
  %8500 = and i32 %8499, 255
  %8501 = tail call i32 @llvm.ctpop.i32(i32 %8500)
  %8502 = trunc i32 %8501 to i8
  %8503 = and i8 %8502, 1
  %8504 = xor i8 %8503, 1
  store i8 %8504, i8* %18, align 1
  %8505 = xor i64 %8496, %8494
  %8506 = lshr i64 %8505, 4
  %8507 = trunc i64 %8506 to i8
  %8508 = and i8 %8507, 1
  store i8 %8508, i8* %19, align 1
  %8509 = icmp eq i64 %8496, 0
  %8510 = zext i1 %8509 to i8
  store i8 %8510, i8* %20, align 1
  %8511 = lshr i64 %8496, 63
  %8512 = trunc i64 %8511 to i8
  store i8 %8512, i8* %21, align 1
  %8513 = xor i64 %8511, %8495
  %8514 = add nuw nsw i64 %8513, %8511
  %8515 = icmp eq i64 %8514, 2
  %8516 = zext i1 %8515 to i8
  store i8 %8516, i8* %22, align 1
  %8517 = add i64 %8487, -364
  %8518 = add i64 %8480, 35
  store i64 %8518, i64* %3, align 8
  %8519 = inttoptr i64 %8517 to i32*
  %8520 = load i32, i32* %8519, align 4
  %8521 = sext i32 %8520 to i64
  %8522 = shl nsw i64 %8521, 9
  store i64 %8522, i64* %RDX.i1943, align 8
  %8523 = add i64 %8522, %8496
  store i64 %8523, i64* %RCX.i1588, align 8
  %8524 = icmp ult i64 %8523, %8496
  %8525 = icmp ult i64 %8523, %8522
  %8526 = or i1 %8524, %8525
  %8527 = zext i1 %8526 to i8
  store i8 %8527, i8* %17, align 1
  %8528 = trunc i64 %8523 to i32
  %8529 = and i32 %8528, 255
  %8530 = tail call i32 @llvm.ctpop.i32(i32 %8529)
  %8531 = trunc i32 %8530 to i8
  %8532 = and i8 %8531, 1
  %8533 = xor i8 %8532, 1
  store i8 %8533, i8* %18, align 1
  %8534 = xor i64 %8496, %8523
  %8535 = lshr i64 %8534, 4
  %8536 = trunc i64 %8535 to i8
  %8537 = and i8 %8536, 1
  store i8 %8537, i8* %19, align 1
  %8538 = icmp eq i64 %8523, 0
  %8539 = zext i1 %8538 to i8
  store i8 %8539, i8* %20, align 1
  %8540 = lshr i64 %8523, 63
  %8541 = trunc i64 %8540 to i8
  store i8 %8541, i8* %21, align 1
  %8542 = lshr i64 %8521, 54
  %8543 = and i64 %8542, 1
  %8544 = xor i64 %8540, %8511
  %8545 = xor i64 %8540, %8543
  %8546 = add nuw nsw i64 %8544, %8545
  %8547 = icmp eq i64 %8546, 2
  %8548 = zext i1 %8547 to i8
  store i8 %8548, i8* %22, align 1
  %8549 = load i64, i64* %RBP.i, align 8
  %8550 = add i64 %8549, -220
  %8551 = add i64 %8480, 48
  store i64 %8551, i64* %3, align 8
  %8552 = inttoptr i64 %8550 to i32*
  %8553 = load i32, i32* %8552, align 4
  %8554 = zext i32 %8553 to i64
  store i64 %8554, i64* %RSI.i2015, align 8
  %8555 = add i64 %8549, -44
  %8556 = add i64 %8480, 51
  store i64 %8556, i64* %3, align 8
  %8557 = inttoptr i64 %8555 to i32*
  %8558 = load i32, i32* %8557, align 4
  %8559 = add i32 %8558, %8553
  %8560 = zext i32 %8559 to i64
  store i64 %8560, i64* %RSI.i2015, align 8
  %8561 = sext i32 %8559 to i64
  %8562 = shl nsw i64 %8561, 5
  store i64 %8562, i64* %RDX.i1943, align 8
  %8563 = load i64, i64* %RCX.i1588, align 8
  %8564 = add i64 %8562, %8563
  store i64 %8564, i64* %RCX.i1588, align 8
  %8565 = icmp ult i64 %8564, %8563
  %8566 = icmp ult i64 %8564, %8562
  %8567 = or i1 %8565, %8566
  %8568 = zext i1 %8567 to i8
  store i8 %8568, i8* %17, align 1
  %8569 = trunc i64 %8564 to i32
  %8570 = and i32 %8569, 255
  %8571 = tail call i32 @llvm.ctpop.i32(i32 %8570)
  %8572 = trunc i32 %8571 to i8
  %8573 = and i8 %8572, 1
  %8574 = xor i8 %8573, 1
  store i8 %8574, i8* %18, align 1
  %8575 = xor i64 %8563, %8564
  %8576 = lshr i64 %8575, 4
  %8577 = trunc i64 %8576 to i8
  %8578 = and i8 %8577, 1
  store i8 %8578, i8* %19, align 1
  %8579 = icmp eq i64 %8564, 0
  %8580 = zext i1 %8579 to i8
  store i8 %8580, i8* %20, align 1
  %8581 = lshr i64 %8564, 63
  %8582 = trunc i64 %8581 to i8
  store i8 %8582, i8* %21, align 1
  %8583 = lshr i64 %8563, 63
  %8584 = lshr i64 %8561, 58
  %8585 = and i64 %8584, 1
  %8586 = xor i64 %8581, %8583
  %8587 = xor i64 %8581, %8585
  %8588 = add nuw nsw i64 %8586, %8587
  %8589 = icmp eq i64 %8588, 2
  %8590 = zext i1 %8589 to i8
  store i8 %8590, i8* %22, align 1
  %8591 = load i64, i64* %RBP.i, align 8
  %8592 = add i64 %8591, -224
  %8593 = add i64 %8480, 67
  store i64 %8593, i64* %3, align 8
  %8594 = inttoptr i64 %8592 to i32*
  %8595 = load i32, i32* %8594, align 4
  %8596 = zext i32 %8595 to i64
  store i64 %8596, i64* %RSI.i2015, align 8
  %8597 = add i64 %8591, -48
  %8598 = add i64 %8480, 70
  store i64 %8598, i64* %3, align 8
  %8599 = inttoptr i64 %8597 to i32*
  %8600 = load i32, i32* %8599, align 4
  %8601 = add i32 %8600, %8595
  %8602 = zext i32 %8601 to i64
  store i64 %8602, i64* %RSI.i2015, align 8
  %8603 = icmp ult i32 %8601, %8595
  %8604 = icmp ult i32 %8601, %8600
  %8605 = or i1 %8603, %8604
  %8606 = zext i1 %8605 to i8
  store i8 %8606, i8* %17, align 1
  %8607 = and i32 %8601, 255
  %8608 = tail call i32 @llvm.ctpop.i32(i32 %8607)
  %8609 = trunc i32 %8608 to i8
  %8610 = and i8 %8609, 1
  %8611 = xor i8 %8610, 1
  store i8 %8611, i8* %18, align 1
  %8612 = xor i32 %8600, %8595
  %8613 = xor i32 %8612, %8601
  %8614 = lshr i32 %8613, 4
  %8615 = trunc i32 %8614 to i8
  %8616 = and i8 %8615, 1
  store i8 %8616, i8* %19, align 1
  %8617 = icmp eq i32 %8601, 0
  %8618 = zext i1 %8617 to i8
  store i8 %8618, i8* %20, align 1
  %8619 = lshr i32 %8601, 31
  %8620 = trunc i32 %8619 to i8
  store i8 %8620, i8* %21, align 1
  %8621 = lshr i32 %8595, 31
  %8622 = lshr i32 %8600, 31
  %8623 = xor i32 %8619, %8621
  %8624 = xor i32 %8619, %8622
  %8625 = add nuw nsw i32 %8623, %8624
  %8626 = icmp eq i32 %8625, 2
  %8627 = zext i1 %8626 to i8
  store i8 %8627, i8* %22, align 1
  %8628 = sext i32 %8601 to i64
  store i64 %8628, i64* %RDX.i1943, align 8
  %8629 = shl nsw i64 %8628, 1
  %8630 = add i64 %8564, %8629
  %8631 = add i64 %8480, 77
  store i64 %8631, i64* %3, align 8
  %8632 = inttoptr i64 %8630 to i16*
  %8633 = load i16, i16* %8632, align 2
  %8634 = zext i16 %8633 to i64
  store i64 %8634, i64* %RSI.i2015, align 8
  %8635 = load i64, i64* %RAX.i1659, align 8
  %8636 = zext i16 %8633 to i32
  %8637 = zext i16 %8633 to i64
  %8638 = trunc i64 %8635 to i32
  %8639 = add i32 %8636, %8638
  %8640 = zext i32 %8639 to i64
  store i64 %8640, i64* %RAX.i1659, align 8
  %8641 = icmp ult i32 %8639, %8638
  %8642 = icmp ult i32 %8639, %8636
  %8643 = or i1 %8641, %8642
  %8644 = zext i1 %8643 to i8
  store i8 %8644, i8* %17, align 1
  %8645 = and i32 %8639, 255
  %8646 = tail call i32 @llvm.ctpop.i32(i32 %8645)
  %8647 = trunc i32 %8646 to i8
  %8648 = and i8 %8647, 1
  %8649 = xor i8 %8648, 1
  store i8 %8649, i8* %18, align 1
  %8650 = xor i64 %8637, %8635
  %8651 = trunc i64 %8650 to i32
  %8652 = xor i32 %8651, %8639
  %8653 = lshr i32 %8652, 4
  %8654 = trunc i32 %8653 to i8
  %8655 = and i8 %8654, 1
  store i8 %8655, i8* %19, align 1
  %8656 = icmp eq i32 %8639, 0
  %8657 = zext i1 %8656 to i8
  store i8 %8657, i8* %20, align 1
  %8658 = lshr i32 %8639, 31
  %8659 = trunc i32 %8658 to i8
  store i8 %8659, i8* %21, align 1
  %8660 = lshr i32 %8638, 31
  %8661 = xor i32 %8658, %8660
  %8662 = add nuw nsw i32 %8661, %8658
  %8663 = icmp eq i32 %8662, 2
  %8664 = zext i1 %8663 to i8
  store i8 %8664, i8* %22, align 1
  %8665 = add i64 %8591, -596
  %8666 = add i64 %8480, 85
  store i64 %8666, i64* %3, align 8
  %8667 = inttoptr i64 %8665 to i32*
  store i32 %8639, i32* %8667, align 4
  %.pre647 = load i64, i64* %3, align 8
  br label %block_.L_484d91

block_.L_484d91:                                  ; preds = %block_.L_484d3c, %block_484d2f
  %8668 = phi i64 [ %.pre647, %block_.L_484d3c ], [ %8486, %block_484d2f ]
  %8669 = load i64, i64* %RBP.i, align 8
  %8670 = add i64 %8669, -596
  %8671 = add i64 %8668, 6
  store i64 %8671, i64* %3, align 8
  %8672 = inttoptr i64 %8670 to i32*
  %8673 = load i32, i32* %8672, align 4
  %8674 = zext i32 %8673 to i64
  store i64 %8674, i64* %RAX.i1659, align 8
  %8675 = add i64 %8669, -592
  %8676 = add i64 %8668, 12
  store i64 %8676, i64* %3, align 8
  %8677 = inttoptr i64 %8675 to i32*
  %8678 = load i32, i32* %8677, align 4
  %8679 = zext i32 %8678 to i64
  store i64 %8679, i64* %RCX.i1588, align 8
  %8680 = sub i32 %8678, %8673
  %8681 = icmp ult i32 %8678, %8673
  %8682 = zext i1 %8681 to i8
  store i8 %8682, i8* %17, align 1
  %8683 = and i32 %8680, 255
  %8684 = tail call i32 @llvm.ctpop.i32(i32 %8683)
  %8685 = trunc i32 %8684 to i8
  %8686 = and i8 %8685, 1
  %8687 = xor i8 %8686, 1
  store i8 %8687, i8* %18, align 1
  %8688 = xor i32 %8673, %8678
  %8689 = xor i32 %8688, %8680
  %8690 = lshr i32 %8689, 4
  %8691 = trunc i32 %8690 to i8
  %8692 = and i8 %8691, 1
  store i8 %8692, i8* %19, align 1
  %8693 = icmp eq i32 %8680, 0
  %8694 = zext i1 %8693 to i8
  store i8 %8694, i8* %20, align 1
  %8695 = lshr i32 %8680, 31
  %8696 = trunc i32 %8695 to i8
  store i8 %8696, i8* %21, align 1
  %8697 = lshr i32 %8678, 31
  %8698 = lshr i32 %8673, 31
  %8699 = xor i32 %8698, %8697
  %8700 = xor i32 %8695, %8697
  %8701 = add nuw nsw i32 %8700, %8699
  %8702 = icmp eq i32 %8701, 2
  %8703 = zext i1 %8702 to i8
  store i8 %8703, i8* %22, align 1
  %8704 = icmp ne i8 %8696, 0
  %8705 = xor i1 %8704, %8702
  %.v753 = select i1 %8705, i64 20, i64 45
  %8706 = add i64 %8668, %.v753
  store i64 %8706, i64* %3, align 8
  br i1 %8705, label %block_484da5, label %block_.L_484dbe

block_484da5:                                     ; preds = %block_.L_484d91
  %8707 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8707, i64* %RAX.i1659, align 8
  %8708 = add i64 %8707, 72688
  %8709 = add i64 %8706, 14
  store i64 %8709, i64* %3, align 8
  %8710 = inttoptr i64 %8708 to i32*
  %8711 = load i32, i32* %8710, align 4
  %8712 = zext i32 %8711 to i64
  store i64 %8712, i64* %RCX.i1588, align 8
  %8713 = add i64 %8669, -600
  %8714 = add i64 %8706, 20
  store i64 %8714, i64* %3, align 8
  %8715 = inttoptr i64 %8713 to i32*
  store i32 %8711, i32* %8715, align 4
  %8716 = load i64, i64* %3, align 8
  %8717 = add i64 %8716, 204
  store i64 %8717, i64* %3, align 8
  br label %block_.L_484e85

block_.L_484dbe:                                  ; preds = %block_.L_484d91
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %8718 = add i64 %8669, -340
  %8719 = add i64 %8706, 8
  store i64 %8719, i64* %3, align 8
  %8720 = inttoptr i64 %8718 to i32*
  %8721 = load i32, i32* %8720, align 4
  %8722 = zext i32 %8721 to i64
  store i64 %8722, i64* %RCX.i1588, align 8
  %8723 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %8724 = add i64 %8723, 8504
  %8725 = lshr i64 %8724, 63
  %8726 = add i64 %8723, 10552
  store i64 %8726, i64* %RDX.i1943, align 8
  %8727 = icmp ugt i64 %8724, -2049
  %8728 = zext i1 %8727 to i8
  store i8 %8728, i8* %17, align 1
  %8729 = trunc i64 %8726 to i32
  %8730 = and i32 %8729, 255
  %8731 = tail call i32 @llvm.ctpop.i32(i32 %8730)
  %8732 = trunc i32 %8731 to i8
  %8733 = and i8 %8732, 1
  %8734 = xor i8 %8733, 1
  store i8 %8734, i8* %18, align 1
  %8735 = xor i64 %8726, %8724
  %8736 = lshr i64 %8735, 4
  %8737 = trunc i64 %8736 to i8
  %8738 = and i8 %8737, 1
  store i8 %8738, i8* %19, align 1
  %8739 = icmp eq i64 %8726, 0
  %8740 = zext i1 %8739 to i8
  store i8 %8740, i8* %20, align 1
  %8741 = lshr i64 %8726, 63
  %8742 = trunc i64 %8741 to i8
  store i8 %8742, i8* %21, align 1
  %8743 = xor i64 %8741, %8725
  %8744 = add nuw nsw i64 %8743, %8741
  %8745 = icmp eq i64 %8744, 2
  %8746 = zext i1 %8745 to i8
  store i8 %8746, i8* %22, align 1
  %8747 = add i64 %8669, -364
  %8748 = add i64 %8706, 37
  store i64 %8748, i64* %3, align 8
  %8749 = inttoptr i64 %8747 to i32*
  %8750 = load i32, i32* %8749, align 4
  %8751 = sext i32 %8750 to i64
  %8752 = shl nsw i64 %8751, 9
  store i64 %8752, i64* %RSI.i2015, align 8
  %8753 = add i64 %8752, %8726
  store i64 %8753, i64* %RDX.i1943, align 8
  %8754 = icmp ult i64 %8753, %8726
  %8755 = icmp ult i64 %8753, %8752
  %8756 = or i1 %8754, %8755
  %8757 = zext i1 %8756 to i8
  store i8 %8757, i8* %17, align 1
  %8758 = trunc i64 %8753 to i32
  %8759 = and i32 %8758, 255
  %8760 = tail call i32 @llvm.ctpop.i32(i32 %8759)
  %8761 = trunc i32 %8760 to i8
  %8762 = and i8 %8761, 1
  %8763 = xor i8 %8762, 1
  store i8 %8763, i8* %18, align 1
  %8764 = xor i64 %8726, %8753
  %8765 = lshr i64 %8764, 4
  %8766 = trunc i64 %8765 to i8
  %8767 = and i8 %8766, 1
  store i8 %8767, i8* %19, align 1
  %8768 = icmp eq i64 %8753, 0
  %8769 = zext i1 %8768 to i8
  store i8 %8769, i8* %20, align 1
  %8770 = lshr i64 %8753, 63
  %8771 = trunc i64 %8770 to i8
  store i8 %8771, i8* %21, align 1
  %8772 = lshr i64 %8751, 54
  %8773 = and i64 %8772, 1
  %8774 = xor i64 %8770, %8741
  %8775 = xor i64 %8770, %8773
  %8776 = add nuw nsw i64 %8774, %8775
  %8777 = icmp eq i64 %8776, 2
  %8778 = zext i1 %8777 to i8
  store i8 %8778, i8* %22, align 1
  %8779 = load i64, i64* %RBP.i, align 8
  %8780 = add i64 %8779, -220
  %8781 = add i64 %8706, 50
  store i64 %8781, i64* %3, align 8
  %8782 = inttoptr i64 %8780 to i32*
  %8783 = load i32, i32* %8782, align 4
  %8784 = zext i32 %8783 to i64
  store i64 %8784, i64* %RDI.i6998, align 8
  %8785 = add i64 %8779, -44
  %8786 = add i64 %8706, 53
  store i64 %8786, i64* %3, align 8
  %8787 = inttoptr i64 %8785 to i32*
  %8788 = load i32, i32* %8787, align 4
  %8789 = add i32 %8788, %8783
  %8790 = zext i32 %8789 to i64
  store i64 %8790, i64* %RDI.i6998, align 8
  %8791 = sext i32 %8789 to i64
  %8792 = shl nsw i64 %8791, 5
  store i64 %8792, i64* %RSI.i2015, align 8
  %8793 = load i64, i64* %RDX.i1943, align 8
  %8794 = add i64 %8792, %8793
  store i64 %8794, i64* %RDX.i1943, align 8
  %8795 = icmp ult i64 %8794, %8793
  %8796 = icmp ult i64 %8794, %8792
  %8797 = or i1 %8795, %8796
  %8798 = zext i1 %8797 to i8
  store i8 %8798, i8* %17, align 1
  %8799 = trunc i64 %8794 to i32
  %8800 = and i32 %8799, 255
  %8801 = tail call i32 @llvm.ctpop.i32(i32 %8800)
  %8802 = trunc i32 %8801 to i8
  %8803 = and i8 %8802, 1
  %8804 = xor i8 %8803, 1
  store i8 %8804, i8* %18, align 1
  %8805 = xor i64 %8793, %8794
  %8806 = lshr i64 %8805, 4
  %8807 = trunc i64 %8806 to i8
  %8808 = and i8 %8807, 1
  store i8 %8808, i8* %19, align 1
  %8809 = icmp eq i64 %8794, 0
  %8810 = zext i1 %8809 to i8
  store i8 %8810, i8* %20, align 1
  %8811 = lshr i64 %8794, 63
  %8812 = trunc i64 %8811 to i8
  store i8 %8812, i8* %21, align 1
  %8813 = lshr i64 %8793, 63
  %8814 = lshr i64 %8791, 58
  %8815 = and i64 %8814, 1
  %8816 = xor i64 %8811, %8813
  %8817 = xor i64 %8811, %8815
  %8818 = add nuw nsw i64 %8816, %8817
  %8819 = icmp eq i64 %8818, 2
  %8820 = zext i1 %8819 to i8
  store i8 %8820, i8* %22, align 1
  %8821 = load i64, i64* %RBP.i, align 8
  %8822 = add i64 %8821, -224
  %8823 = add i64 %8706, 69
  store i64 %8823, i64* %3, align 8
  %8824 = inttoptr i64 %8822 to i32*
  %8825 = load i32, i32* %8824, align 4
  %8826 = zext i32 %8825 to i64
  store i64 %8826, i64* %RDI.i6998, align 8
  %8827 = add i64 %8821, -48
  %8828 = add i64 %8706, 72
  store i64 %8828, i64* %3, align 8
  %8829 = inttoptr i64 %8827 to i32*
  %8830 = load i32, i32* %8829, align 4
  %8831 = add i32 %8830, %8825
  %8832 = zext i32 %8831 to i64
  store i64 %8832, i64* %RDI.i6998, align 8
  %8833 = icmp ult i32 %8831, %8825
  %8834 = icmp ult i32 %8831, %8830
  %8835 = or i1 %8833, %8834
  %8836 = zext i1 %8835 to i8
  store i8 %8836, i8* %17, align 1
  %8837 = and i32 %8831, 255
  %8838 = tail call i32 @llvm.ctpop.i32(i32 %8837)
  %8839 = trunc i32 %8838 to i8
  %8840 = and i8 %8839, 1
  %8841 = xor i8 %8840, 1
  store i8 %8841, i8* %18, align 1
  %8842 = xor i32 %8830, %8825
  %8843 = xor i32 %8842, %8831
  %8844 = lshr i32 %8843, 4
  %8845 = trunc i32 %8844 to i8
  %8846 = and i8 %8845, 1
  store i8 %8846, i8* %19, align 1
  %8847 = icmp eq i32 %8831, 0
  %8848 = zext i1 %8847 to i8
  store i8 %8848, i8* %20, align 1
  %8849 = lshr i32 %8831, 31
  %8850 = trunc i32 %8849 to i8
  store i8 %8850, i8* %21, align 1
  %8851 = lshr i32 %8825, 31
  %8852 = lshr i32 %8830, 31
  %8853 = xor i32 %8849, %8851
  %8854 = xor i32 %8849, %8852
  %8855 = add nuw nsw i32 %8853, %8854
  %8856 = icmp eq i32 %8855, 2
  %8857 = zext i1 %8856 to i8
  store i8 %8857, i8* %22, align 1
  %8858 = sext i32 %8831 to i64
  store i64 %8858, i64* %RSI.i2015, align 8
  %8859 = shl nsw i64 %8858, 1
  %8860 = add i64 %8794, %8859
  %8861 = add i64 %8706, 79
  store i64 %8861, i64* %3, align 8
  %8862 = inttoptr i64 %8860 to i16*
  %8863 = load i16, i16* %8862, align 2
  %8864 = zext i16 %8863 to i64
  store i64 %8864, i64* %RDI.i6998, align 8
  %8865 = load i64, i64* %RCX.i1588, align 8
  %8866 = zext i16 %8863 to i32
  %8867 = trunc i64 %8865 to i32
  %8868 = add i32 %8866, %8867
  %8869 = zext i32 %8868 to i64
  store i64 %8869, i64* %RCX.i1588, align 8
  %8870 = lshr i32 %8868, 31
  %8871 = load i32, i32* %EAX.i2033, align 4
  %8872 = sub i32 %8871, %8868
  %8873 = icmp ult i32 %8871, %8868
  %8874 = zext i1 %8873 to i8
  store i8 %8874, i8* %17, align 1
  %8875 = and i32 %8872, 255
  %8876 = tail call i32 @llvm.ctpop.i32(i32 %8875)
  %8877 = trunc i32 %8876 to i8
  %8878 = and i8 %8877, 1
  %8879 = xor i8 %8878, 1
  store i8 %8879, i8* %18, align 1
  %8880 = xor i32 %8868, %8871
  %8881 = xor i32 %8880, %8872
  %8882 = lshr i32 %8881, 4
  %8883 = trunc i32 %8882 to i8
  %8884 = and i8 %8883, 1
  store i8 %8884, i8* %19, align 1
  %8885 = icmp eq i32 %8872, 0
  %8886 = zext i1 %8885 to i8
  store i8 %8886, i8* %20, align 1
  %8887 = lshr i32 %8872, 31
  %8888 = trunc i32 %8887 to i8
  store i8 %8888, i8* %21, align 1
  %8889 = lshr i32 %8871, 31
  %8890 = xor i32 %8870, %8889
  %8891 = xor i32 %8887, %8889
  %8892 = add nuw nsw i32 %8891, %8890
  %8893 = icmp eq i32 %8892, 2
  %8894 = zext i1 %8893 to i8
  store i8 %8894, i8* %22, align 1
  %8895 = icmp ne i8 %8888, 0
  %8896 = xor i1 %8895, %8893
  %8897 = or i1 %8885, %8896
  %.v754 = select i1 %8897, i64 102, i64 89
  %8898 = add i64 %8706, %.v754
  store i64 %8898, i64* %3, align 8
  br i1 %8897, label %block_.L_484e24, label %block_484e17

block_484e17:                                     ; preds = %block_.L_484dbe
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %8899 = load i64, i64* %RBP.i, align 8
  %8900 = add i64 %8899, -604
  %8901 = add i64 %8898, 8
  store i64 %8901, i64* %3, align 8
  %8902 = inttoptr i64 %8900 to i32*
  store i32 0, i32* %8902, align 4
  %8903 = load i64, i64* %3, align 8
  %8904 = add i64 %8903, 90
  store i64 %8904, i64* %3, align 8
  br label %block_.L_484e79

block_.L_484e24:                                  ; preds = %block_.L_484dbe
  %8905 = load i64, i64* %RBP.i, align 8
  %8906 = add i64 %8905, -340
  %8907 = add i64 %8898, 6
  store i64 %8907, i64* %3, align 8
  %8908 = inttoptr i64 %8906 to i32*
  %8909 = load i32, i32* %8908, align 4
  %8910 = zext i32 %8909 to i64
  store i64 %8910, i64* %RAX.i1659, align 8
  %8911 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %8912 = add i64 %8911, 8504
  %8913 = lshr i64 %8912, 63
  %8914 = add i64 %8911, 10552
  store i64 %8914, i64* %RCX.i1588, align 8
  %8915 = icmp ugt i64 %8912, -2049
  %8916 = zext i1 %8915 to i8
  store i8 %8916, i8* %17, align 1
  %8917 = trunc i64 %8914 to i32
  %8918 = and i32 %8917, 255
  %8919 = tail call i32 @llvm.ctpop.i32(i32 %8918)
  %8920 = trunc i32 %8919 to i8
  %8921 = and i8 %8920, 1
  %8922 = xor i8 %8921, 1
  store i8 %8922, i8* %18, align 1
  %8923 = xor i64 %8914, %8912
  %8924 = lshr i64 %8923, 4
  %8925 = trunc i64 %8924 to i8
  %8926 = and i8 %8925, 1
  store i8 %8926, i8* %19, align 1
  %8927 = icmp eq i64 %8914, 0
  %8928 = zext i1 %8927 to i8
  store i8 %8928, i8* %20, align 1
  %8929 = lshr i64 %8914, 63
  %8930 = trunc i64 %8929 to i8
  store i8 %8930, i8* %21, align 1
  %8931 = xor i64 %8929, %8913
  %8932 = add nuw nsw i64 %8931, %8929
  %8933 = icmp eq i64 %8932, 2
  %8934 = zext i1 %8933 to i8
  store i8 %8934, i8* %22, align 1
  %8935 = add i64 %8905, -364
  %8936 = add i64 %8898, 35
  store i64 %8936, i64* %3, align 8
  %8937 = inttoptr i64 %8935 to i32*
  %8938 = load i32, i32* %8937, align 4
  %8939 = sext i32 %8938 to i64
  %8940 = shl nsw i64 %8939, 9
  store i64 %8940, i64* %RDX.i1943, align 8
  %8941 = add i64 %8940, %8914
  store i64 %8941, i64* %RCX.i1588, align 8
  %8942 = icmp ult i64 %8941, %8914
  %8943 = icmp ult i64 %8941, %8940
  %8944 = or i1 %8942, %8943
  %8945 = zext i1 %8944 to i8
  store i8 %8945, i8* %17, align 1
  %8946 = trunc i64 %8941 to i32
  %8947 = and i32 %8946, 255
  %8948 = tail call i32 @llvm.ctpop.i32(i32 %8947)
  %8949 = trunc i32 %8948 to i8
  %8950 = and i8 %8949, 1
  %8951 = xor i8 %8950, 1
  store i8 %8951, i8* %18, align 1
  %8952 = xor i64 %8914, %8941
  %8953 = lshr i64 %8952, 4
  %8954 = trunc i64 %8953 to i8
  %8955 = and i8 %8954, 1
  store i8 %8955, i8* %19, align 1
  %8956 = icmp eq i64 %8941, 0
  %8957 = zext i1 %8956 to i8
  store i8 %8957, i8* %20, align 1
  %8958 = lshr i64 %8941, 63
  %8959 = trunc i64 %8958 to i8
  store i8 %8959, i8* %21, align 1
  %8960 = lshr i64 %8939, 54
  %8961 = and i64 %8960, 1
  %8962 = xor i64 %8958, %8929
  %8963 = xor i64 %8958, %8961
  %8964 = add nuw nsw i64 %8962, %8963
  %8965 = icmp eq i64 %8964, 2
  %8966 = zext i1 %8965 to i8
  store i8 %8966, i8* %22, align 1
  %8967 = load i64, i64* %RBP.i, align 8
  %8968 = add i64 %8967, -220
  %8969 = add i64 %8898, 48
  store i64 %8969, i64* %3, align 8
  %8970 = inttoptr i64 %8968 to i32*
  %8971 = load i32, i32* %8970, align 4
  %8972 = zext i32 %8971 to i64
  store i64 %8972, i64* %RSI.i2015, align 8
  %8973 = add i64 %8967, -44
  %8974 = add i64 %8898, 51
  store i64 %8974, i64* %3, align 8
  %8975 = inttoptr i64 %8973 to i32*
  %8976 = load i32, i32* %8975, align 4
  %8977 = add i32 %8976, %8971
  %8978 = zext i32 %8977 to i64
  store i64 %8978, i64* %RSI.i2015, align 8
  %8979 = sext i32 %8977 to i64
  %8980 = shl nsw i64 %8979, 5
  store i64 %8980, i64* %RDX.i1943, align 8
  %8981 = load i64, i64* %RCX.i1588, align 8
  %8982 = add i64 %8980, %8981
  store i64 %8982, i64* %RCX.i1588, align 8
  %8983 = icmp ult i64 %8982, %8981
  %8984 = icmp ult i64 %8982, %8980
  %8985 = or i1 %8983, %8984
  %8986 = zext i1 %8985 to i8
  store i8 %8986, i8* %17, align 1
  %8987 = trunc i64 %8982 to i32
  %8988 = and i32 %8987, 255
  %8989 = tail call i32 @llvm.ctpop.i32(i32 %8988)
  %8990 = trunc i32 %8989 to i8
  %8991 = and i8 %8990, 1
  %8992 = xor i8 %8991, 1
  store i8 %8992, i8* %18, align 1
  %8993 = xor i64 %8981, %8982
  %8994 = lshr i64 %8993, 4
  %8995 = trunc i64 %8994 to i8
  %8996 = and i8 %8995, 1
  store i8 %8996, i8* %19, align 1
  %8997 = icmp eq i64 %8982, 0
  %8998 = zext i1 %8997 to i8
  store i8 %8998, i8* %20, align 1
  %8999 = lshr i64 %8982, 63
  %9000 = trunc i64 %8999 to i8
  store i8 %9000, i8* %21, align 1
  %9001 = lshr i64 %8981, 63
  %9002 = lshr i64 %8979, 58
  %9003 = and i64 %9002, 1
  %9004 = xor i64 %8999, %9001
  %9005 = xor i64 %8999, %9003
  %9006 = add nuw nsw i64 %9004, %9005
  %9007 = icmp eq i64 %9006, 2
  %9008 = zext i1 %9007 to i8
  store i8 %9008, i8* %22, align 1
  %9009 = load i64, i64* %RBP.i, align 8
  %9010 = add i64 %9009, -224
  %9011 = add i64 %8898, 67
  store i64 %9011, i64* %3, align 8
  %9012 = inttoptr i64 %9010 to i32*
  %9013 = load i32, i32* %9012, align 4
  %9014 = zext i32 %9013 to i64
  store i64 %9014, i64* %RSI.i2015, align 8
  %9015 = add i64 %9009, -48
  %9016 = add i64 %8898, 70
  store i64 %9016, i64* %3, align 8
  %9017 = inttoptr i64 %9015 to i32*
  %9018 = load i32, i32* %9017, align 4
  %9019 = add i32 %9018, %9013
  %9020 = zext i32 %9019 to i64
  store i64 %9020, i64* %RSI.i2015, align 8
  %9021 = icmp ult i32 %9019, %9013
  %9022 = icmp ult i32 %9019, %9018
  %9023 = or i1 %9021, %9022
  %9024 = zext i1 %9023 to i8
  store i8 %9024, i8* %17, align 1
  %9025 = and i32 %9019, 255
  %9026 = tail call i32 @llvm.ctpop.i32(i32 %9025)
  %9027 = trunc i32 %9026 to i8
  %9028 = and i8 %9027, 1
  %9029 = xor i8 %9028, 1
  store i8 %9029, i8* %18, align 1
  %9030 = xor i32 %9018, %9013
  %9031 = xor i32 %9030, %9019
  %9032 = lshr i32 %9031, 4
  %9033 = trunc i32 %9032 to i8
  %9034 = and i8 %9033, 1
  store i8 %9034, i8* %19, align 1
  %9035 = icmp eq i32 %9019, 0
  %9036 = zext i1 %9035 to i8
  store i8 %9036, i8* %20, align 1
  %9037 = lshr i32 %9019, 31
  %9038 = trunc i32 %9037 to i8
  store i8 %9038, i8* %21, align 1
  %9039 = lshr i32 %9013, 31
  %9040 = lshr i32 %9018, 31
  %9041 = xor i32 %9037, %9039
  %9042 = xor i32 %9037, %9040
  %9043 = add nuw nsw i32 %9041, %9042
  %9044 = icmp eq i32 %9043, 2
  %9045 = zext i1 %9044 to i8
  store i8 %9045, i8* %22, align 1
  %9046 = sext i32 %9019 to i64
  store i64 %9046, i64* %RDX.i1943, align 8
  %9047 = shl nsw i64 %9046, 1
  %9048 = add i64 %8982, %9047
  %9049 = add i64 %8898, 77
  store i64 %9049, i64* %3, align 8
  %9050 = inttoptr i64 %9048 to i16*
  %9051 = load i16, i16* %9050, align 2
  %9052 = zext i16 %9051 to i64
  store i64 %9052, i64* %RSI.i2015, align 8
  %9053 = load i64, i64* %RAX.i1659, align 8
  %9054 = zext i16 %9051 to i32
  %9055 = zext i16 %9051 to i64
  %9056 = trunc i64 %9053 to i32
  %9057 = add i32 %9054, %9056
  %9058 = zext i32 %9057 to i64
  store i64 %9058, i64* %RAX.i1659, align 8
  %9059 = icmp ult i32 %9057, %9056
  %9060 = icmp ult i32 %9057, %9054
  %9061 = or i1 %9059, %9060
  %9062 = zext i1 %9061 to i8
  store i8 %9062, i8* %17, align 1
  %9063 = and i32 %9057, 255
  %9064 = tail call i32 @llvm.ctpop.i32(i32 %9063)
  %9065 = trunc i32 %9064 to i8
  %9066 = and i8 %9065, 1
  %9067 = xor i8 %9066, 1
  store i8 %9067, i8* %18, align 1
  %9068 = xor i64 %9055, %9053
  %9069 = trunc i64 %9068 to i32
  %9070 = xor i32 %9069, %9057
  %9071 = lshr i32 %9070, 4
  %9072 = trunc i32 %9071 to i8
  %9073 = and i8 %9072, 1
  store i8 %9073, i8* %19, align 1
  %9074 = icmp eq i32 %9057, 0
  %9075 = zext i1 %9074 to i8
  store i8 %9075, i8* %20, align 1
  %9076 = lshr i32 %9057, 31
  %9077 = trunc i32 %9076 to i8
  store i8 %9077, i8* %21, align 1
  %9078 = lshr i32 %9056, 31
  %9079 = xor i32 %9076, %9078
  %9080 = add nuw nsw i32 %9079, %9076
  %9081 = icmp eq i32 %9080, 2
  %9082 = zext i1 %9081 to i8
  store i8 %9082, i8* %22, align 1
  %9083 = add i64 %9009, -604
  %9084 = add i64 %8898, 85
  store i64 %9084, i64* %3, align 8
  %9085 = inttoptr i64 %9083 to i32*
  store i32 %9057, i32* %9085, align 4
  %.pre648 = load i64, i64* %3, align 8
  br label %block_.L_484e79

block_.L_484e79:                                  ; preds = %block_.L_484e24, %block_484e17
  %9086 = phi i64 [ %.pre648, %block_.L_484e24 ], [ %8904, %block_484e17 ]
  %9087 = load i64, i64* %RBP.i, align 8
  %9088 = add i64 %9087, -604
  %9089 = add i64 %9086, 6
  store i64 %9089, i64* %3, align 8
  %9090 = inttoptr i64 %9088 to i32*
  %9091 = load i32, i32* %9090, align 4
  %9092 = zext i32 %9091 to i64
  store i64 %9092, i64* %RAX.i1659, align 8
  %9093 = add i64 %9087, -600
  %9094 = add i64 %9086, 12
  store i64 %9094, i64* %3, align 8
  %9095 = inttoptr i64 %9093 to i32*
  store i32 %9091, i32* %9095, align 4
  %.pre649 = load i64, i64* %3, align 8
  br label %block_.L_484e85

block_.L_484e85:                                  ; preds = %block_.L_484e79, %block_484da5
  %9096 = phi i64 [ %.pre649, %block_.L_484e79 ], [ %8717, %block_484da5 ]
  %9097 = load i64, i64* %RBP.i, align 8
  %9098 = add i64 %9097, -600
  %9099 = add i64 %9096, 6
  store i64 %9099, i64* %3, align 8
  %9100 = inttoptr i64 %9098 to i32*
  %9101 = load i32, i32* %9100, align 4
  %9102 = zext i32 %9101 to i64
  store i64 %9102, i64* %RAX.i1659, align 8
  %9103 = trunc i32 %9101 to i16
  store i16 %9103, i16* %CX.i4340, align 2
  %9104 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9104, i64* %RDX.i1943, align 8
  %9105 = add i64 %9104, 6464
  %9106 = add i64 %9096, 24
  store i64 %9106, i64* %3, align 8
  %9107 = inttoptr i64 %9105 to i64*
  %9108 = load i64, i64* %9107, align 8
  store i64 %9108, i64* %RDX.i1943, align 8
  %9109 = add i64 %9108, 8
  %9110 = add i64 %9096, 28
  store i64 %9110, i64* %3, align 8
  %9111 = inttoptr i64 %9109 to i64*
  %9112 = load i64, i64* %9111, align 8
  store i64 %9112, i64* %RDX.i1943, align 8
  %9113 = add i64 %9097, -232
  %9114 = add i64 %9096, 34
  store i64 %9114, i64* %3, align 8
  %9115 = inttoptr i64 %9113 to i32*
  %9116 = load i32, i32* %9115, align 4
  %9117 = zext i32 %9116 to i64
  store i64 %9117, i64* %RAX.i1659, align 8
  %9118 = add i64 %9097, -48
  %9119 = add i64 %9096, 37
  store i64 %9119, i64* %3, align 8
  %9120 = inttoptr i64 %9118 to i32*
  %9121 = load i32, i32* %9120, align 4
  %9122 = add i32 %9121, %9116
  %9123 = zext i32 %9122 to i64
  store i64 %9123, i64* %RAX.i1659, align 8
  %9124 = icmp ult i32 %9122, %9116
  %9125 = icmp ult i32 %9122, %9121
  %9126 = or i1 %9124, %9125
  %9127 = zext i1 %9126 to i8
  store i8 %9127, i8* %17, align 1
  %9128 = and i32 %9122, 255
  %9129 = tail call i32 @llvm.ctpop.i32(i32 %9128)
  %9130 = trunc i32 %9129 to i8
  %9131 = and i8 %9130, 1
  %9132 = xor i8 %9131, 1
  store i8 %9132, i8* %18, align 1
  %9133 = xor i32 %9121, %9116
  %9134 = xor i32 %9133, %9122
  %9135 = lshr i32 %9134, 4
  %9136 = trunc i32 %9135 to i8
  %9137 = and i8 %9136, 1
  store i8 %9137, i8* %19, align 1
  %9138 = icmp eq i32 %9122, 0
  %9139 = zext i1 %9138 to i8
  store i8 %9139, i8* %20, align 1
  %9140 = lshr i32 %9122, 31
  %9141 = trunc i32 %9140 to i8
  store i8 %9141, i8* %21, align 1
  %9142 = lshr i32 %9116, 31
  %9143 = lshr i32 %9121, 31
  %9144 = xor i32 %9140, %9142
  %9145 = xor i32 %9140, %9143
  %9146 = add nuw nsw i32 %9144, %9145
  %9147 = icmp eq i32 %9146, 2
  %9148 = zext i1 %9147 to i8
  store i8 %9148, i8* %22, align 1
  %9149 = sext i32 %9122 to i64
  store i64 %9149, i64* %RSI.i2015, align 8
  %9150 = shl nsw i64 %9149, 3
  %9151 = add i64 %9112, %9150
  %9152 = add i64 %9096, 44
  store i64 %9152, i64* %3, align 8
  %9153 = inttoptr i64 %9151 to i64*
  %9154 = load i64, i64* %9153, align 8
  store i64 %9154, i64* %RDX.i1943, align 8
  %9155 = add i64 %9097, -228
  %9156 = add i64 %9096, 50
  store i64 %9156, i64* %3, align 8
  %9157 = inttoptr i64 %9155 to i32*
  %9158 = load i32, i32* %9157, align 4
  %9159 = zext i32 %9158 to i64
  store i64 %9159, i64* %RAX.i1659, align 8
  %9160 = add i64 %9097, -44
  %9161 = add i64 %9096, 53
  store i64 %9161, i64* %3, align 8
  %9162 = inttoptr i64 %9160 to i32*
  %9163 = load i32, i32* %9162, align 4
  %9164 = add i32 %9163, %9158
  %9165 = zext i32 %9164 to i64
  store i64 %9165, i64* %RAX.i1659, align 8
  %9166 = icmp ult i32 %9164, %9158
  %9167 = icmp ult i32 %9164, %9163
  %9168 = or i1 %9166, %9167
  %9169 = zext i1 %9168 to i8
  store i8 %9169, i8* %17, align 1
  %9170 = and i32 %9164, 255
  %9171 = tail call i32 @llvm.ctpop.i32(i32 %9170)
  %9172 = trunc i32 %9171 to i8
  %9173 = and i8 %9172, 1
  %9174 = xor i8 %9173, 1
  store i8 %9174, i8* %18, align 1
  %9175 = xor i32 %9163, %9158
  %9176 = xor i32 %9175, %9164
  %9177 = lshr i32 %9176, 4
  %9178 = trunc i32 %9177 to i8
  %9179 = and i8 %9178, 1
  store i8 %9179, i8* %19, align 1
  %9180 = icmp eq i32 %9164, 0
  %9181 = zext i1 %9180 to i8
  store i8 %9181, i8* %20, align 1
  %9182 = lshr i32 %9164, 31
  %9183 = trunc i32 %9182 to i8
  store i8 %9183, i8* %21, align 1
  %9184 = lshr i32 %9158, 31
  %9185 = lshr i32 %9163, 31
  %9186 = xor i32 %9182, %9184
  %9187 = xor i32 %9182, %9185
  %9188 = add nuw nsw i32 %9186, %9187
  %9189 = icmp eq i32 %9188, 2
  %9190 = zext i1 %9189 to i8
  store i8 %9190, i8* %22, align 1
  %9191 = sext i32 %9164 to i64
  store i64 %9191, i64* %RSI.i2015, align 8
  %9192 = shl nsw i64 %9191, 1
  %9193 = add i64 %9154, %9192
  %9194 = load i16, i16* %CX.i4340, align 2
  %9195 = add i64 %9096, 60
  store i64 %9195, i64* %3, align 8
  %9196 = inttoptr i64 %9193 to i16*
  store i16 %9194, i16* %9196, align 2
  %9197 = load i64, i64* %RBP.i, align 8
  %9198 = add i64 %9197, -44
  %9199 = load i64, i64* %3, align 8
  %9200 = add i64 %9199, 3
  store i64 %9200, i64* %3, align 8
  %9201 = inttoptr i64 %9198 to i32*
  %9202 = load i32, i32* %9201, align 4
  %9203 = add i32 %9202, 1
  %9204 = zext i32 %9203 to i64
  store i64 %9204, i64* %RAX.i1659, align 8
  %9205 = icmp eq i32 %9202, -1
  %9206 = icmp eq i32 %9203, 0
  %9207 = or i1 %9205, %9206
  %9208 = zext i1 %9207 to i8
  store i8 %9208, i8* %17, align 1
  %9209 = and i32 %9203, 255
  %9210 = tail call i32 @llvm.ctpop.i32(i32 %9209)
  %9211 = trunc i32 %9210 to i8
  %9212 = and i8 %9211, 1
  %9213 = xor i8 %9212, 1
  store i8 %9213, i8* %18, align 1
  %9214 = xor i32 %9203, %9202
  %9215 = lshr i32 %9214, 4
  %9216 = trunc i32 %9215 to i8
  %9217 = and i8 %9216, 1
  store i8 %9217, i8* %19, align 1
  %9218 = zext i1 %9206 to i8
  store i8 %9218, i8* %20, align 1
  %9219 = lshr i32 %9203, 31
  %9220 = trunc i32 %9219 to i8
  store i8 %9220, i8* %21, align 1
  %9221 = lshr i32 %9202, 31
  %9222 = xor i32 %9219, %9221
  %9223 = add nuw nsw i32 %9222, %9219
  %9224 = icmp eq i32 %9223, 2
  %9225 = zext i1 %9224 to i8
  store i8 %9225, i8* %22, align 1
  %9226 = add i64 %9199, 9
  store i64 %9226, i64* %3, align 8
  store i32 %9203, i32* %9201, align 4
  %9227 = load i64, i64* %3, align 8
  %9228 = add i64 %9227, -1631
  store i64 %9228, i64* %3, align 8
  br label %block_.L_48486b

block_.L_484ecf:                                  ; preds = %block_.L_48486b
  %9229 = add i64 %6220, -48
  %9230 = add i64 %6248, 8
  store i64 %9230, i64* %3, align 8
  %9231 = inttoptr i64 %9229 to i32*
  %9232 = load i32, i32* %9231, align 4
  %9233 = add i32 %9232, 1
  %9234 = zext i32 %9233 to i64
  store i64 %9234, i64* %RAX.i1659, align 8
  %9235 = icmp eq i32 %9232, -1
  %9236 = icmp eq i32 %9233, 0
  %9237 = or i1 %9235, %9236
  %9238 = zext i1 %9237 to i8
  store i8 %9238, i8* %17, align 1
  %9239 = and i32 %9233, 255
  %9240 = tail call i32 @llvm.ctpop.i32(i32 %9239)
  %9241 = trunc i32 %9240 to i8
  %9242 = and i8 %9241, 1
  %9243 = xor i8 %9242, 1
  store i8 %9243, i8* %18, align 1
  %9244 = xor i32 %9233, %9232
  %9245 = lshr i32 %9244, 4
  %9246 = trunc i32 %9245 to i8
  %9247 = and i8 %9246, 1
  store i8 %9247, i8* %19, align 1
  %9248 = zext i1 %9236 to i8
  store i8 %9248, i8* %20, align 1
  %9249 = lshr i32 %9233, 31
  %9250 = trunc i32 %9249 to i8
  store i8 %9250, i8* %21, align 1
  %9251 = lshr i32 %9232, 31
  %9252 = xor i32 %9249, %9251
  %9253 = add nuw nsw i32 %9252, %9249
  %9254 = icmp eq i32 %9253, 2
  %9255 = zext i1 %9254 to i8
  store i8 %9255, i8* %22, align 1
  %9256 = add i64 %6248, 14
  store i64 %9256, i64* %3, align 8
  store i32 %9233, i32* %9231, align 4
  %9257 = load i64, i64* %3, align 8
  %9258 = add i64 %9257, -1667
  store i64 %9258, i64* %3, align 8
  br label %block_.L_48485a

block_.L_484ee2:                                  ; preds = %block_.L_48485a
  %9259 = add i64 %6187, -356
  %9260 = add i64 %6215, 10
  store i64 %9260, i64* %3, align 8
  %9261 = inttoptr i64 %9259 to i32*
  store i32 0, i32* %9261, align 4
  %9262 = load i64, i64* %RBP.i, align 8
  %9263 = add i64 %9262, -60
  %9264 = load i64, i64* %3, align 8
  %9265 = add i64 %9264, 7
  store i64 %9265, i64* %3, align 8
  %9266 = inttoptr i64 %9263 to i32*
  store i32 0, i32* %9266, align 4
  %.pre588 = load i64, i64* %3, align 8
  br label %block_.L_484ef3

block_.L_484ef3:                                  ; preds = %block_.L_485127, %block_.L_484ee2
  %9267 = phi i64 [ %10327, %block_.L_485127 ], [ %.pre588, %block_.L_484ee2 ]
  %9268 = load i64, i64* %RBP.i, align 8
  %9269 = add i64 %9268, -60
  %9270 = add i64 %9267, 4
  store i64 %9270, i64* %3, align 8
  %9271 = inttoptr i64 %9269 to i32*
  %9272 = load i32, i32* %9271, align 4
  %9273 = add i32 %9272, -4
  %9274 = icmp ult i32 %9272, 4
  %9275 = zext i1 %9274 to i8
  store i8 %9275, i8* %17, align 1
  %9276 = and i32 %9273, 255
  %9277 = tail call i32 @llvm.ctpop.i32(i32 %9276)
  %9278 = trunc i32 %9277 to i8
  %9279 = and i8 %9278, 1
  %9280 = xor i8 %9279, 1
  store i8 %9280, i8* %18, align 1
  %9281 = xor i32 %9273, %9272
  %9282 = lshr i32 %9281, 4
  %9283 = trunc i32 %9282 to i8
  %9284 = and i8 %9283, 1
  store i8 %9284, i8* %19, align 1
  %9285 = icmp eq i32 %9273, 0
  %9286 = zext i1 %9285 to i8
  store i8 %9286, i8* %20, align 1
  %9287 = lshr i32 %9273, 31
  %9288 = trunc i32 %9287 to i8
  store i8 %9288, i8* %21, align 1
  %9289 = lshr i32 %9272, 31
  %9290 = xor i32 %9287, %9289
  %9291 = add nuw nsw i32 %9290, %9289
  %9292 = icmp eq i32 %9291, 2
  %9293 = zext i1 %9292 to i8
  store i8 %9293, i8* %22, align 1
  %9294 = icmp ne i8 %9288, 0
  %9295 = xor i1 %9294, %9292
  %.v744 = select i1 %9295, i64 10, i64 583
  %9296 = add i64 %9267, %.v744
  store i64 %9296, i64* %3, align 8
  br i1 %9295, label %block_484efd, label %block_.L_48513a

block_484efd:                                     ; preds = %block_.L_484ef3
  %9297 = add i64 %9268, -228
  %9298 = add i64 %9296, 6
  store i64 %9298, i64* %3, align 8
  %9299 = inttoptr i64 %9297 to i32*
  %9300 = load i32, i32* %9299, align 4
  %9301 = zext i32 %9300 to i64
  store i64 %9301, i64* %RAX.i1659, align 8
  %9302 = add i64 %9268, -56
  %9303 = add i64 %9296, 9
  store i64 %9303, i64* %3, align 8
  %9304 = inttoptr i64 %9302 to i32*
  store i32 %9300, i32* %9304, align 4
  %.pre639 = load i64, i64* %3, align 8
  br label %block_.L_484f06

block_.L_484f06:                                  ; preds = %block_484f1a, %block_484efd
  %9305 = phi i64 [ %10297, %block_484f1a ], [ %.pre639, %block_484efd ]
  %9306 = load i64, i64* %RBP.i, align 8
  %9307 = add i64 %9306, -56
  %9308 = add i64 %9305, 3
  store i64 %9308, i64* %3, align 8
  %9309 = inttoptr i64 %9307 to i32*
  %9310 = load i32, i32* %9309, align 4
  %9311 = zext i32 %9310 to i64
  store i64 %9311, i64* %RAX.i1659, align 8
  %9312 = add i64 %9306, -228
  %9313 = add i64 %9305, 9
  store i64 %9313, i64* %3, align 8
  %9314 = inttoptr i64 %9312 to i32*
  %9315 = load i32, i32* %9314, align 4
  %9316 = add i32 %9315, 4
  %9317 = zext i32 %9316 to i64
  store i64 %9317, i64* %RCX.i1588, align 8
  %9318 = lshr i32 %9316, 31
  %9319 = sub i32 %9310, %9316
  %9320 = icmp ult i32 %9310, %9316
  %9321 = zext i1 %9320 to i8
  store i8 %9321, i8* %17, align 1
  %9322 = and i32 %9319, 255
  %9323 = tail call i32 @llvm.ctpop.i32(i32 %9322)
  %9324 = trunc i32 %9323 to i8
  %9325 = and i8 %9324, 1
  %9326 = xor i8 %9325, 1
  store i8 %9326, i8* %18, align 1
  %9327 = xor i32 %9316, %9310
  %9328 = xor i32 %9327, %9319
  %9329 = lshr i32 %9328, 4
  %9330 = trunc i32 %9329 to i8
  %9331 = and i8 %9330, 1
  store i8 %9331, i8* %19, align 1
  %9332 = icmp eq i32 %9319, 0
  %9333 = zext i1 %9332 to i8
  store i8 %9333, i8* %20, align 1
  %9334 = lshr i32 %9319, 31
  %9335 = trunc i32 %9334 to i8
  store i8 %9335, i8* %21, align 1
  %9336 = lshr i32 %9310, 31
  %9337 = xor i32 %9318, %9336
  %9338 = xor i32 %9334, %9336
  %9339 = add nuw nsw i32 %9338, %9337
  %9340 = icmp eq i32 %9339, 2
  %9341 = zext i1 %9340 to i8
  store i8 %9341, i8* %22, align 1
  %9342 = icmp ne i8 %9335, 0
  %9343 = xor i1 %9342, %9340
  %.v687 = select i1 %9343, i64 20, i64 545
  %9344 = add i64 %9305, %.v687
  store i64 %9344, i64* %3, align 8
  br i1 %9343, label %block_484f1a, label %block_.L_485127

block_484f1a:                                     ; preds = %block_.L_484f06
  %9345 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %9345, i64* %RAX.i1659, align 8
  %9346 = add i64 %9306, -232
  %9347 = add i64 %9344, 14
  store i64 %9347, i64* %3, align 8
  %9348 = inttoptr i64 %9346 to i32*
  %9349 = load i32, i32* %9348, align 4
  %9350 = zext i32 %9349 to i64
  store i64 %9350, i64* %RCX.i1588, align 8
  %9351 = add i64 %9306, -60
  %9352 = add i64 %9344, 17
  store i64 %9352, i64* %3, align 8
  %9353 = inttoptr i64 %9351 to i32*
  %9354 = load i32, i32* %9353, align 4
  %9355 = add i32 %9354, %9349
  %9356 = zext i32 %9355 to i64
  store i64 %9356, i64* %RCX.i1588, align 8
  %9357 = icmp ult i32 %9355, %9349
  %9358 = icmp ult i32 %9355, %9354
  %9359 = or i1 %9357, %9358
  %9360 = zext i1 %9359 to i8
  store i8 %9360, i8* %17, align 1
  %9361 = and i32 %9355, 255
  %9362 = tail call i32 @llvm.ctpop.i32(i32 %9361)
  %9363 = trunc i32 %9362 to i8
  %9364 = and i8 %9363, 1
  %9365 = xor i8 %9364, 1
  store i8 %9365, i8* %18, align 1
  %9366 = xor i32 %9354, %9349
  %9367 = xor i32 %9366, %9355
  %9368 = lshr i32 %9367, 4
  %9369 = trunc i32 %9368 to i8
  %9370 = and i8 %9369, 1
  store i8 %9370, i8* %19, align 1
  %9371 = icmp eq i32 %9355, 0
  %9372 = zext i1 %9371 to i8
  store i8 %9372, i8* %20, align 1
  %9373 = lshr i32 %9355, 31
  %9374 = trunc i32 %9373 to i8
  store i8 %9374, i8* %21, align 1
  %9375 = lshr i32 %9349, 31
  %9376 = lshr i32 %9354, 31
  %9377 = xor i32 %9373, %9375
  %9378 = xor i32 %9373, %9376
  %9379 = add nuw nsw i32 %9377, %9378
  %9380 = icmp eq i32 %9379, 2
  %9381 = zext i1 %9380 to i8
  store i8 %9381, i8* %22, align 1
  %9382 = sext i32 %9355 to i64
  store i64 %9382, i64* %RDX.i1943, align 8
  %9383 = shl nsw i64 %9382, 3
  %9384 = add i64 %9345, %9383
  %9385 = add i64 %9344, 24
  store i64 %9385, i64* %3, align 8
  %9386 = inttoptr i64 %9384 to i64*
  %9387 = load i64, i64* %9386, align 8
  store i64 %9387, i64* %RAX.i1659, align 8
  %9388 = add i64 %9344, 28
  store i64 %9388, i64* %3, align 8
  %9389 = load i32, i32* %9309, align 4
  %9390 = sext i32 %9389 to i64
  store i64 %9390, i64* %RDX.i1943, align 8
  %9391 = shl nsw i64 %9390, 1
  %9392 = add i64 %9391, %9387
  %9393 = add i64 %9344, 32
  store i64 %9393, i64* %3, align 8
  %9394 = inttoptr i64 %9392 to i16*
  %9395 = load i16, i16* %9394, align 2
  %9396 = zext i16 %9395 to i64
  store i64 %9396, i64* %RCX.i1588, align 8
  %9397 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9397, i64* %RAX.i1659, align 8
  %9398 = add i64 %9397, 6424
  %9399 = add i64 %9344, 47
  store i64 %9399, i64* %3, align 8
  %9400 = inttoptr i64 %9398 to i64*
  %9401 = load i64, i64* %9400, align 8
  store i64 %9401, i64* %RAX.i1659, align 8
  %9402 = add i64 %9344, 53
  store i64 %9402, i64* %3, align 8
  %9403 = load i32, i32* %9348, align 4
  %9404 = zext i32 %9403 to i64
  store i64 %9404, i64* %RSI.i2015, align 8
  %9405 = add i64 %9344, 56
  store i64 %9405, i64* %3, align 8
  %9406 = load i32, i32* %9353, align 4
  %9407 = add i32 %9406, %9403
  %9408 = zext i32 %9407 to i64
  store i64 %9408, i64* %RSI.i2015, align 8
  %9409 = icmp ult i32 %9407, %9403
  %9410 = icmp ult i32 %9407, %9406
  %9411 = or i1 %9409, %9410
  %9412 = zext i1 %9411 to i8
  store i8 %9412, i8* %17, align 1
  %9413 = and i32 %9407, 255
  %9414 = tail call i32 @llvm.ctpop.i32(i32 %9413)
  %9415 = trunc i32 %9414 to i8
  %9416 = and i8 %9415, 1
  %9417 = xor i8 %9416, 1
  store i8 %9417, i8* %18, align 1
  %9418 = xor i32 %9406, %9403
  %9419 = xor i32 %9418, %9407
  %9420 = lshr i32 %9419, 4
  %9421 = trunc i32 %9420 to i8
  %9422 = and i8 %9421, 1
  store i8 %9422, i8* %19, align 1
  %9423 = icmp eq i32 %9407, 0
  %9424 = zext i1 %9423 to i8
  store i8 %9424, i8* %20, align 1
  %9425 = lshr i32 %9407, 31
  %9426 = trunc i32 %9425 to i8
  store i8 %9426, i8* %21, align 1
  %9427 = lshr i32 %9403, 31
  %9428 = lshr i32 %9406, 31
  %9429 = xor i32 %9425, %9427
  %9430 = xor i32 %9425, %9428
  %9431 = add nuw nsw i32 %9429, %9430
  %9432 = icmp eq i32 %9431, 2
  %9433 = zext i1 %9432 to i8
  store i8 %9433, i8* %22, align 1
  %9434 = sext i32 %9407 to i64
  store i64 %9434, i64* %RDX.i1943, align 8
  %9435 = shl nsw i64 %9434, 3
  %9436 = add i64 %9401, %9435
  %9437 = add i64 %9344, 63
  store i64 %9437, i64* %3, align 8
  %9438 = inttoptr i64 %9436 to i64*
  %9439 = load i64, i64* %9438, align 8
  store i64 %9439, i64* %RAX.i1659, align 8
  %9440 = load i64, i64* %RBP.i, align 8
  %9441 = add i64 %9440, -56
  %9442 = add i64 %9344, 67
  store i64 %9442, i64* %3, align 8
  %9443 = inttoptr i64 %9441 to i32*
  %9444 = load i32, i32* %9443, align 4
  %9445 = sext i32 %9444 to i64
  store i64 %9445, i64* %RDX.i1943, align 8
  %9446 = shl nsw i64 %9445, 1
  %9447 = add i64 %9446, %9439
  %9448 = add i64 %9344, 71
  store i64 %9448, i64* %3, align 8
  %9449 = inttoptr i64 %9447 to i16*
  %9450 = load i16, i16* %9449, align 2
  %9451 = zext i16 %9450 to i64
  store i64 %9451, i64* %RSI.i2015, align 8
  %9452 = zext i16 %9450 to i32
  %9453 = zext i16 %9395 to i32
  %9454 = sub nsw i32 %9453, %9452
  %9455 = zext i32 %9454 to i64
  store i64 %9455, i64* %RCX.i1588, align 8
  %9456 = icmp ult i16 %9395, %9450
  %9457 = zext i1 %9456 to i8
  store i8 %9457, i8* %17, align 1
  %9458 = and i32 %9454, 255
  %9459 = tail call i32 @llvm.ctpop.i32(i32 %9458)
  %9460 = trunc i32 %9459 to i8
  %9461 = and i8 %9460, 1
  %9462 = xor i8 %9461, 1
  store i8 %9462, i8* %18, align 1
  %9463 = xor i16 %9450, %9395
  %9464 = zext i16 %9463 to i32
  %9465 = xor i32 %9464, %9454
  %9466 = lshr i32 %9465, 4
  %9467 = trunc i32 %9466 to i8
  %9468 = and i8 %9467, 1
  store i8 %9468, i8* %19, align 1
  %9469 = icmp eq i32 %9454, 0
  %9470 = zext i1 %9469 to i8
  store i8 %9470, i8* %20, align 1
  %9471 = lshr i32 %9454, 31
  %9472 = trunc i32 %9471 to i8
  store i8 %9472, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %9473 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %9473, i64* %RAX.i1659, align 8
  %9474 = add i64 %9440, -232
  %9475 = add i64 %9344, 87
  store i64 %9475, i64* %3, align 8
  %9476 = inttoptr i64 %9474 to i32*
  %9477 = load i32, i32* %9476, align 4
  %9478 = zext i32 %9477 to i64
  store i64 %9478, i64* %RSI.i2015, align 8
  %9479 = add i64 %9440, -60
  %9480 = add i64 %9344, 90
  store i64 %9480, i64* %3, align 8
  %9481 = inttoptr i64 %9479 to i32*
  %9482 = load i32, i32* %9481, align 4
  %9483 = add i32 %9482, %9477
  %9484 = zext i32 %9483 to i64
  store i64 %9484, i64* %RSI.i2015, align 8
  %9485 = icmp ult i32 %9483, %9477
  %9486 = icmp ult i32 %9483, %9482
  %9487 = or i1 %9485, %9486
  %9488 = zext i1 %9487 to i8
  store i8 %9488, i8* %17, align 1
  %9489 = and i32 %9483, 255
  %9490 = tail call i32 @llvm.ctpop.i32(i32 %9489)
  %9491 = trunc i32 %9490 to i8
  %9492 = and i8 %9491, 1
  %9493 = xor i8 %9492, 1
  store i8 %9493, i8* %18, align 1
  %9494 = xor i32 %9482, %9477
  %9495 = xor i32 %9494, %9483
  %9496 = lshr i32 %9495, 4
  %9497 = trunc i32 %9496 to i8
  %9498 = and i8 %9497, 1
  store i8 %9498, i8* %19, align 1
  %9499 = icmp eq i32 %9483, 0
  %9500 = zext i1 %9499 to i8
  store i8 %9500, i8* %20, align 1
  %9501 = lshr i32 %9483, 31
  %9502 = trunc i32 %9501 to i8
  store i8 %9502, i8* %21, align 1
  %9503 = lshr i32 %9477, 31
  %9504 = lshr i32 %9482, 31
  %9505 = xor i32 %9501, %9503
  %9506 = xor i32 %9501, %9504
  %9507 = add nuw nsw i32 %9505, %9506
  %9508 = icmp eq i32 %9507, 2
  %9509 = zext i1 %9508 to i8
  store i8 %9509, i8* %22, align 1
  %9510 = sext i32 %9483 to i64
  store i64 %9510, i64* %RDX.i1943, align 8
  %9511 = shl nsw i64 %9510, 3
  %9512 = add i64 %9473, %9511
  %9513 = add i64 %9344, 97
  store i64 %9513, i64* %3, align 8
  %9514 = inttoptr i64 %9512 to i64*
  %9515 = load i64, i64* %9514, align 8
  store i64 %9515, i64* %RAX.i1659, align 8
  %9516 = load i64, i64* %RBP.i, align 8
  %9517 = add i64 %9516, -56
  %9518 = add i64 %9344, 101
  store i64 %9518, i64* %3, align 8
  %9519 = inttoptr i64 %9517 to i32*
  %9520 = load i32, i32* %9519, align 4
  %9521 = sext i32 %9520 to i64
  store i64 %9521, i64* %RDX.i1943, align 8
  %9522 = shl nsw i64 %9521, 1
  %9523 = add i64 %9522, %9515
  %9524 = add i64 %9344, 105
  store i64 %9524, i64* %3, align 8
  %9525 = inttoptr i64 %9523 to i16*
  %9526 = load i16, i16* %9525, align 2
  %9527 = zext i16 %9526 to i64
  store i64 %9527, i64* %RSI.i2015, align 8
  %9528 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9528, i64* %RAX.i1659, align 8
  %9529 = add i64 %9528, 6424
  %9530 = add i64 %9344, 120
  store i64 %9530, i64* %3, align 8
  %9531 = inttoptr i64 %9529 to i64*
  %9532 = load i64, i64* %9531, align 8
  store i64 %9532, i64* %RAX.i1659, align 8
  %9533 = add i64 %9516, -232
  %9534 = add i64 %9344, 126
  store i64 %9534, i64* %3, align 8
  %9535 = inttoptr i64 %9533 to i32*
  %9536 = load i32, i32* %9535, align 4
  %9537 = zext i32 %9536 to i64
  store i64 %9537, i64* %RDI.i6998, align 8
  %9538 = add i64 %9516, -60
  %9539 = add i64 %9344, 129
  store i64 %9539, i64* %3, align 8
  %9540 = inttoptr i64 %9538 to i32*
  %9541 = load i32, i32* %9540, align 4
  %9542 = add i32 %9541, %9536
  %9543 = zext i32 %9542 to i64
  store i64 %9543, i64* %RDI.i6998, align 8
  %9544 = icmp ult i32 %9542, %9536
  %9545 = icmp ult i32 %9542, %9541
  %9546 = or i1 %9544, %9545
  %9547 = zext i1 %9546 to i8
  store i8 %9547, i8* %17, align 1
  %9548 = and i32 %9542, 255
  %9549 = tail call i32 @llvm.ctpop.i32(i32 %9548)
  %9550 = trunc i32 %9549 to i8
  %9551 = and i8 %9550, 1
  %9552 = xor i8 %9551, 1
  store i8 %9552, i8* %18, align 1
  %9553 = xor i32 %9541, %9536
  %9554 = xor i32 %9553, %9542
  %9555 = lshr i32 %9554, 4
  %9556 = trunc i32 %9555 to i8
  %9557 = and i8 %9556, 1
  store i8 %9557, i8* %19, align 1
  %9558 = icmp eq i32 %9542, 0
  %9559 = zext i1 %9558 to i8
  store i8 %9559, i8* %20, align 1
  %9560 = lshr i32 %9542, 31
  %9561 = trunc i32 %9560 to i8
  store i8 %9561, i8* %21, align 1
  %9562 = lshr i32 %9536, 31
  %9563 = lshr i32 %9541, 31
  %9564 = xor i32 %9560, %9562
  %9565 = xor i32 %9560, %9563
  %9566 = add nuw nsw i32 %9564, %9565
  %9567 = icmp eq i32 %9566, 2
  %9568 = zext i1 %9567 to i8
  store i8 %9568, i8* %22, align 1
  %9569 = sext i32 %9542 to i64
  store i64 %9569, i64* %RDX.i1943, align 8
  %9570 = shl nsw i64 %9569, 3
  %9571 = add i64 %9532, %9570
  %9572 = add i64 %9344, 136
  store i64 %9572, i64* %3, align 8
  %9573 = inttoptr i64 %9571 to i64*
  %9574 = load i64, i64* %9573, align 8
  store i64 %9574, i64* %RAX.i1659, align 8
  %9575 = add i64 %9344, 140
  store i64 %9575, i64* %3, align 8
  %9576 = load i32, i32* %9519, align 4
  %9577 = sext i32 %9576 to i64
  store i64 %9577, i64* %RDX.i1943, align 8
  %9578 = shl nsw i64 %9577, 1
  %9579 = add i64 %9578, %9574
  %9580 = add i64 %9344, 144
  store i64 %9580, i64* %3, align 8
  %9581 = inttoptr i64 %9579 to i16*
  %9582 = load i16, i16* %9581, align 2
  %9583 = zext i16 %9582 to i64
  store i64 %9583, i64* %RDI.i6998, align 8
  %9584 = zext i16 %9582 to i32
  %9585 = zext i16 %9526 to i32
  %9586 = sub nsw i32 %9585, %9584
  %9587 = zext i32 %9586 to i64
  store i64 %9587, i64* %RSI.i2015, align 8
  %9588 = load i64, i64* %RCX.i1588, align 8
  %9589 = shl i64 %9588, 32
  %9590 = ashr exact i64 %9589, 32
  %9591 = sext i32 %9586 to i64
  %9592 = mul nsw i64 %9591, %9590
  %9593 = trunc i64 %9592 to i32
  %9594 = and i64 %9592, 4294967295
  store i64 %9594, i64* %RCX.i1588, align 8
  %9595 = shl i64 %9592, 32
  %9596 = ashr exact i64 %9595, 32
  %9597 = icmp ne i64 %9596, %9592
  %9598 = zext i1 %9597 to i8
  store i8 %9598, i8* %17, align 1
  %9599 = and i32 %9593, 255
  %9600 = tail call i32 @llvm.ctpop.i32(i32 %9599)
  %9601 = trunc i32 %9600 to i8
  %9602 = and i8 %9601, 1
  %9603 = xor i8 %9602, 1
  store i8 %9603, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %9604 = lshr i32 %9593, 31
  %9605 = trunc i32 %9604 to i8
  store i8 %9605, i8* %21, align 1
  store i8 %9598, i8* %22, align 1
  %9606 = load i64, i64* %RBP.i, align 8
  %9607 = add i64 %9606, -356
  %9608 = add i64 %9344, 155
  store i64 %9608, i64* %3, align 8
  %9609 = trunc i64 %9592 to i32
  %9610 = inttoptr i64 %9607 to i32*
  %9611 = load i32, i32* %9610, align 4
  %9612 = add i32 %9611, %9609
  %9613 = zext i32 %9612 to i64
  store i64 %9613, i64* %RCX.i1588, align 8
  %9614 = icmp ult i32 %9612, %9609
  %9615 = icmp ult i32 %9612, %9611
  %9616 = or i1 %9614, %9615
  %9617 = zext i1 %9616 to i8
  store i8 %9617, i8* %17, align 1
  %9618 = and i32 %9612, 255
  %9619 = tail call i32 @llvm.ctpop.i32(i32 %9618)
  %9620 = trunc i32 %9619 to i8
  %9621 = and i8 %9620, 1
  %9622 = xor i8 %9621, 1
  store i8 %9622, i8* %18, align 1
  %9623 = xor i32 %9611, %9609
  %9624 = xor i32 %9623, %9612
  %9625 = lshr i32 %9624, 4
  %9626 = trunc i32 %9625 to i8
  %9627 = and i8 %9626, 1
  store i8 %9627, i8* %19, align 1
  %9628 = icmp eq i32 %9612, 0
  %9629 = zext i1 %9628 to i8
  store i8 %9629, i8* %20, align 1
  %9630 = lshr i32 %9612, 31
  %9631 = trunc i32 %9630 to i8
  store i8 %9631, i8* %21, align 1
  %9632 = lshr i32 %9609, 31
  %9633 = lshr i32 %9611, 31
  %9634 = xor i32 %9630, %9632
  %9635 = xor i32 %9630, %9633
  %9636 = add nuw nsw i32 %9634, %9635
  %9637 = icmp eq i32 %9636, 2
  %9638 = zext i1 %9637 to i8
  store i8 %9638, i8* %22, align 1
  %9639 = add i64 %9344, 161
  store i64 %9639, i64* %3, align 8
  store i32 %9612, i32* %9610, align 4
  %9640 = load i64, i64* %3, align 8
  %9641 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %9641, i64* %RAX.i1659, align 8
  %9642 = add i64 %9640, 11
  store i64 %9642, i64* %3, align 8
  %9643 = inttoptr i64 %9641 to i64*
  %9644 = load i64, i64* %9643, align 8
  store i64 %9644, i64* %RAX.i1659, align 8
  %9645 = load i64, i64* %RBP.i, align 8
  %9646 = add i64 %9645, -232
  %9647 = add i64 %9640, 17
  store i64 %9647, i64* %3, align 8
  %9648 = inttoptr i64 %9646 to i32*
  %9649 = load i32, i32* %9648, align 4
  %9650 = zext i32 %9649 to i64
  store i64 %9650, i64* %RCX.i1588, align 8
  %9651 = add i64 %9645, -60
  %9652 = add i64 %9640, 20
  store i64 %9652, i64* %3, align 8
  %9653 = inttoptr i64 %9651 to i32*
  %9654 = load i32, i32* %9653, align 4
  %9655 = add i32 %9654, %9649
  %9656 = zext i32 %9655 to i64
  store i64 %9656, i64* %RCX.i1588, align 8
  %9657 = icmp ult i32 %9655, %9649
  %9658 = icmp ult i32 %9655, %9654
  %9659 = or i1 %9657, %9658
  %9660 = zext i1 %9659 to i8
  store i8 %9660, i8* %17, align 1
  %9661 = and i32 %9655, 255
  %9662 = tail call i32 @llvm.ctpop.i32(i32 %9661)
  %9663 = trunc i32 %9662 to i8
  %9664 = and i8 %9663, 1
  %9665 = xor i8 %9664, 1
  store i8 %9665, i8* %18, align 1
  %9666 = xor i32 %9654, %9649
  %9667 = xor i32 %9666, %9655
  %9668 = lshr i32 %9667, 4
  %9669 = trunc i32 %9668 to i8
  %9670 = and i8 %9669, 1
  store i8 %9670, i8* %19, align 1
  %9671 = icmp eq i32 %9655, 0
  %9672 = zext i1 %9671 to i8
  store i8 %9672, i8* %20, align 1
  %9673 = lshr i32 %9655, 31
  %9674 = trunc i32 %9673 to i8
  store i8 %9674, i8* %21, align 1
  %9675 = lshr i32 %9649, 31
  %9676 = lshr i32 %9654, 31
  %9677 = xor i32 %9673, %9675
  %9678 = xor i32 %9673, %9676
  %9679 = add nuw nsw i32 %9677, %9678
  %9680 = icmp eq i32 %9679, 2
  %9681 = zext i1 %9680 to i8
  store i8 %9681, i8* %22, align 1
  %9682 = sext i32 %9655 to i64
  store i64 %9682, i64* %RDX.i1943, align 8
  %9683 = shl nsw i64 %9682, 3
  %9684 = add i64 %9644, %9683
  %9685 = add i64 %9640, 27
  store i64 %9685, i64* %3, align 8
  %9686 = inttoptr i64 %9684 to i64*
  %9687 = load i64, i64* %9686, align 8
  store i64 %9687, i64* %RAX.i1659, align 8
  %9688 = add i64 %9645, -56
  %9689 = add i64 %9640, 31
  store i64 %9689, i64* %3, align 8
  %9690 = inttoptr i64 %9688 to i32*
  %9691 = load i32, i32* %9690, align 4
  %9692 = sext i32 %9691 to i64
  store i64 %9692, i64* %RDX.i1943, align 8
  %9693 = shl nsw i64 %9692, 1
  %9694 = add i64 %9693, %9687
  %9695 = add i64 %9640, 35
  store i64 %9695, i64* %3, align 8
  %9696 = inttoptr i64 %9694 to i16*
  %9697 = load i16, i16* %9696, align 2
  %9698 = zext i16 %9697 to i64
  store i64 %9698, i64* %RCX.i1588, align 8
  %9699 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9699, i64* %RAX.i1659, align 8
  %9700 = add i64 %9699, 6464
  %9701 = add i64 %9640, 50
  store i64 %9701, i64* %3, align 8
  %9702 = inttoptr i64 %9700 to i64*
  %9703 = load i64, i64* %9702, align 8
  store i64 %9703, i64* %RAX.i1659, align 8
  %9704 = add i64 %9640, 53
  store i64 %9704, i64* %3, align 8
  %9705 = inttoptr i64 %9703 to i64*
  %9706 = load i64, i64* %9705, align 8
  store i64 %9706, i64* %RAX.i1659, align 8
  %9707 = add i64 %9640, 59
  store i64 %9707, i64* %3, align 8
  %9708 = load i32, i32* %9648, align 4
  %9709 = zext i32 %9708 to i64
  store i64 %9709, i64* %RSI.i2015, align 8
  %9710 = add i64 %9640, 62
  store i64 %9710, i64* %3, align 8
  %9711 = load i32, i32* %9653, align 4
  %9712 = add i32 %9711, %9708
  %9713 = zext i32 %9712 to i64
  store i64 %9713, i64* %RSI.i2015, align 8
  %9714 = icmp ult i32 %9712, %9708
  %9715 = icmp ult i32 %9712, %9711
  %9716 = or i1 %9714, %9715
  %9717 = zext i1 %9716 to i8
  store i8 %9717, i8* %17, align 1
  %9718 = and i32 %9712, 255
  %9719 = tail call i32 @llvm.ctpop.i32(i32 %9718)
  %9720 = trunc i32 %9719 to i8
  %9721 = and i8 %9720, 1
  %9722 = xor i8 %9721, 1
  store i8 %9722, i8* %18, align 1
  %9723 = xor i32 %9711, %9708
  %9724 = xor i32 %9723, %9712
  %9725 = lshr i32 %9724, 4
  %9726 = trunc i32 %9725 to i8
  %9727 = and i8 %9726, 1
  store i8 %9727, i8* %19, align 1
  %9728 = icmp eq i32 %9712, 0
  %9729 = zext i1 %9728 to i8
  store i8 %9729, i8* %20, align 1
  %9730 = lshr i32 %9712, 31
  %9731 = trunc i32 %9730 to i8
  store i8 %9731, i8* %21, align 1
  %9732 = lshr i32 %9708, 31
  %9733 = lshr i32 %9711, 31
  %9734 = xor i32 %9730, %9732
  %9735 = xor i32 %9730, %9733
  %9736 = add nuw nsw i32 %9734, %9735
  %9737 = icmp eq i32 %9736, 2
  %9738 = zext i1 %9737 to i8
  store i8 %9738, i8* %22, align 1
  %9739 = sext i32 %9712 to i64
  store i64 %9739, i64* %RDX.i1943, align 8
  %9740 = shl nsw i64 %9739, 3
  %9741 = add i64 %9706, %9740
  %9742 = add i64 %9640, 69
  store i64 %9742, i64* %3, align 8
  %9743 = inttoptr i64 %9741 to i64*
  %9744 = load i64, i64* %9743, align 8
  store i64 %9744, i64* %RAX.i1659, align 8
  %9745 = load i64, i64* %RBP.i, align 8
  %9746 = add i64 %9745, -56
  %9747 = add i64 %9640, 73
  store i64 %9747, i64* %3, align 8
  %9748 = inttoptr i64 %9746 to i32*
  %9749 = load i32, i32* %9748, align 4
  %9750 = sext i32 %9749 to i64
  store i64 %9750, i64* %RDX.i1943, align 8
  %9751 = shl nsw i64 %9750, 1
  %9752 = add i64 %9751, %9744
  %9753 = add i64 %9640, 77
  store i64 %9753, i64* %3, align 8
  %9754 = inttoptr i64 %9752 to i16*
  %9755 = load i16, i16* %9754, align 2
  %9756 = zext i16 %9755 to i64
  store i64 %9756, i64* %RSI.i2015, align 8
  %9757 = zext i16 %9755 to i32
  %9758 = zext i16 %9697 to i32
  %9759 = sub nsw i32 %9758, %9757
  %9760 = zext i32 %9759 to i64
  store i64 %9760, i64* %RCX.i1588, align 8
  %9761 = icmp ult i16 %9697, %9755
  %9762 = zext i1 %9761 to i8
  store i8 %9762, i8* %17, align 1
  %9763 = and i32 %9759, 255
  %9764 = tail call i32 @llvm.ctpop.i32(i32 %9763)
  %9765 = trunc i32 %9764 to i8
  %9766 = and i8 %9765, 1
  %9767 = xor i8 %9766, 1
  store i8 %9767, i8* %18, align 1
  %9768 = xor i16 %9755, %9697
  %9769 = zext i16 %9768 to i32
  %9770 = xor i32 %9769, %9759
  %9771 = lshr i32 %9770, 4
  %9772 = trunc i32 %9771 to i8
  %9773 = and i8 %9772, 1
  store i8 %9773, i8* %19, align 1
  %9774 = icmp eq i32 %9759, 0
  %9775 = zext i1 %9774 to i8
  store i8 %9775, i8* %20, align 1
  %9776 = lshr i32 %9759, 31
  %9777 = trunc i32 %9776 to i8
  store i8 %9777, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %9778 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %9778, i64* %RAX.i1659, align 8
  %9779 = add i64 %9640, 90
  store i64 %9779, i64* %3, align 8
  %9780 = inttoptr i64 %9778 to i64*
  %9781 = load i64, i64* %9780, align 8
  store i64 %9781, i64* %RAX.i1659, align 8
  %9782 = add i64 %9745, -232
  %9783 = add i64 %9640, 96
  store i64 %9783, i64* %3, align 8
  %9784 = inttoptr i64 %9782 to i32*
  %9785 = load i32, i32* %9784, align 4
  %9786 = zext i32 %9785 to i64
  store i64 %9786, i64* %RSI.i2015, align 8
  %9787 = add i64 %9745, -60
  %9788 = add i64 %9640, 99
  store i64 %9788, i64* %3, align 8
  %9789 = inttoptr i64 %9787 to i32*
  %9790 = load i32, i32* %9789, align 4
  %9791 = add i32 %9790, %9785
  %9792 = zext i32 %9791 to i64
  store i64 %9792, i64* %RSI.i2015, align 8
  %9793 = icmp ult i32 %9791, %9785
  %9794 = icmp ult i32 %9791, %9790
  %9795 = or i1 %9793, %9794
  %9796 = zext i1 %9795 to i8
  store i8 %9796, i8* %17, align 1
  %9797 = and i32 %9791, 255
  %9798 = tail call i32 @llvm.ctpop.i32(i32 %9797)
  %9799 = trunc i32 %9798 to i8
  %9800 = and i8 %9799, 1
  %9801 = xor i8 %9800, 1
  store i8 %9801, i8* %18, align 1
  %9802 = xor i32 %9790, %9785
  %9803 = xor i32 %9802, %9791
  %9804 = lshr i32 %9803, 4
  %9805 = trunc i32 %9804 to i8
  %9806 = and i8 %9805, 1
  store i8 %9806, i8* %19, align 1
  %9807 = icmp eq i32 %9791, 0
  %9808 = zext i1 %9807 to i8
  store i8 %9808, i8* %20, align 1
  %9809 = lshr i32 %9791, 31
  %9810 = trunc i32 %9809 to i8
  store i8 %9810, i8* %21, align 1
  %9811 = lshr i32 %9785, 31
  %9812 = lshr i32 %9790, 31
  %9813 = xor i32 %9809, %9811
  %9814 = xor i32 %9809, %9812
  %9815 = add nuw nsw i32 %9813, %9814
  %9816 = icmp eq i32 %9815, 2
  %9817 = zext i1 %9816 to i8
  store i8 %9817, i8* %22, align 1
  %9818 = sext i32 %9791 to i64
  store i64 %9818, i64* %RDX.i1943, align 8
  %9819 = shl nsw i64 %9818, 3
  %9820 = add i64 %9781, %9819
  %9821 = add i64 %9640, 106
  store i64 %9821, i64* %3, align 8
  %9822 = inttoptr i64 %9820 to i64*
  %9823 = load i64, i64* %9822, align 8
  store i64 %9823, i64* %RAX.i1659, align 8
  %9824 = load i64, i64* %RBP.i, align 8
  %9825 = add i64 %9824, -56
  %9826 = add i64 %9640, 110
  store i64 %9826, i64* %3, align 8
  %9827 = inttoptr i64 %9825 to i32*
  %9828 = load i32, i32* %9827, align 4
  %9829 = sext i32 %9828 to i64
  store i64 %9829, i64* %RDX.i1943, align 8
  %9830 = shl nsw i64 %9829, 1
  %9831 = add i64 %9830, %9823
  %9832 = add i64 %9640, 114
  store i64 %9832, i64* %3, align 8
  %9833 = inttoptr i64 %9831 to i16*
  %9834 = load i16, i16* %9833, align 2
  %9835 = zext i16 %9834 to i64
  store i64 %9835, i64* %RSI.i2015, align 8
  %9836 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9836, i64* %RAX.i1659, align 8
  %9837 = add i64 %9836, 6464
  %9838 = add i64 %9640, 129
  store i64 %9838, i64* %3, align 8
  %9839 = inttoptr i64 %9837 to i64*
  %9840 = load i64, i64* %9839, align 8
  store i64 %9840, i64* %RAX.i1659, align 8
  %9841 = add i64 %9640, 132
  store i64 %9841, i64* %3, align 8
  %9842 = inttoptr i64 %9840 to i64*
  %9843 = load i64, i64* %9842, align 8
  store i64 %9843, i64* %RAX.i1659, align 8
  %9844 = add i64 %9824, -232
  %9845 = add i64 %9640, 138
  store i64 %9845, i64* %3, align 8
  %9846 = inttoptr i64 %9844 to i32*
  %9847 = load i32, i32* %9846, align 4
  %9848 = zext i32 %9847 to i64
  store i64 %9848, i64* %RDI.i6998, align 8
  %9849 = add i64 %9824, -60
  %9850 = add i64 %9640, 141
  store i64 %9850, i64* %3, align 8
  %9851 = inttoptr i64 %9849 to i32*
  %9852 = load i32, i32* %9851, align 4
  %9853 = add i32 %9852, %9847
  %9854 = zext i32 %9853 to i64
  store i64 %9854, i64* %RDI.i6998, align 8
  %9855 = icmp ult i32 %9853, %9847
  %9856 = icmp ult i32 %9853, %9852
  %9857 = or i1 %9855, %9856
  %9858 = zext i1 %9857 to i8
  store i8 %9858, i8* %17, align 1
  %9859 = and i32 %9853, 255
  %9860 = tail call i32 @llvm.ctpop.i32(i32 %9859)
  %9861 = trunc i32 %9860 to i8
  %9862 = and i8 %9861, 1
  %9863 = xor i8 %9862, 1
  store i8 %9863, i8* %18, align 1
  %9864 = xor i32 %9852, %9847
  %9865 = xor i32 %9864, %9853
  %9866 = lshr i32 %9865, 4
  %9867 = trunc i32 %9866 to i8
  %9868 = and i8 %9867, 1
  store i8 %9868, i8* %19, align 1
  %9869 = icmp eq i32 %9853, 0
  %9870 = zext i1 %9869 to i8
  store i8 %9870, i8* %20, align 1
  %9871 = lshr i32 %9853, 31
  %9872 = trunc i32 %9871 to i8
  store i8 %9872, i8* %21, align 1
  %9873 = lshr i32 %9847, 31
  %9874 = lshr i32 %9852, 31
  %9875 = xor i32 %9871, %9873
  %9876 = xor i32 %9871, %9874
  %9877 = add nuw nsw i32 %9875, %9876
  %9878 = icmp eq i32 %9877, 2
  %9879 = zext i1 %9878 to i8
  store i8 %9879, i8* %22, align 1
  %9880 = sext i32 %9853 to i64
  store i64 %9880, i64* %RDX.i1943, align 8
  %9881 = shl nsw i64 %9880, 3
  %9882 = add i64 %9843, %9881
  %9883 = add i64 %9640, 148
  store i64 %9883, i64* %3, align 8
  %9884 = inttoptr i64 %9882 to i64*
  %9885 = load i64, i64* %9884, align 8
  store i64 %9885, i64* %RAX.i1659, align 8
  %9886 = add i64 %9640, 152
  store i64 %9886, i64* %3, align 8
  %9887 = load i32, i32* %9827, align 4
  %9888 = sext i32 %9887 to i64
  store i64 %9888, i64* %RDX.i1943, align 8
  %9889 = shl nsw i64 %9888, 1
  %9890 = add i64 %9889, %9885
  %9891 = add i64 %9640, 156
  store i64 %9891, i64* %3, align 8
  %9892 = inttoptr i64 %9890 to i16*
  %9893 = load i16, i16* %9892, align 2
  %9894 = zext i16 %9893 to i64
  store i64 %9894, i64* %RDI.i6998, align 8
  %9895 = zext i16 %9893 to i32
  %9896 = zext i16 %9834 to i32
  %9897 = sub nsw i32 %9896, %9895
  %9898 = zext i32 %9897 to i64
  store i64 %9898, i64* %RSI.i2015, align 8
  %9899 = load i64, i64* %RCX.i1588, align 8
  %9900 = shl i64 %9899, 32
  %9901 = ashr exact i64 %9900, 32
  %9902 = sext i32 %9897 to i64
  %9903 = mul nsw i64 %9902, %9901
  %9904 = trunc i64 %9903 to i32
  %9905 = and i64 %9903, 4294967295
  store i64 %9905, i64* %RCX.i1588, align 8
  %9906 = shl i64 %9903, 32
  %9907 = ashr exact i64 %9906, 32
  %9908 = icmp ne i64 %9907, %9903
  %9909 = zext i1 %9908 to i8
  store i8 %9909, i8* %17, align 1
  %9910 = and i32 %9904, 255
  %9911 = tail call i32 @llvm.ctpop.i32(i32 %9910)
  %9912 = trunc i32 %9911 to i8
  %9913 = and i8 %9912, 1
  %9914 = xor i8 %9913, 1
  store i8 %9914, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %9915 = lshr i32 %9904, 31
  %9916 = trunc i32 %9915 to i8
  store i8 %9916, i8* %21, align 1
  store i8 %9909, i8* %22, align 1
  %9917 = load i64, i64* %RBP.i, align 8
  %9918 = add i64 %9917, -356
  %9919 = add i64 %9640, 167
  store i64 %9919, i64* %3, align 8
  %9920 = trunc i64 %9903 to i32
  %9921 = inttoptr i64 %9918 to i32*
  %9922 = load i32, i32* %9921, align 4
  %9923 = add i32 %9922, %9920
  %9924 = zext i32 %9923 to i64
  store i64 %9924, i64* %RCX.i1588, align 8
  %9925 = icmp ult i32 %9923, %9920
  %9926 = icmp ult i32 %9923, %9922
  %9927 = or i1 %9925, %9926
  %9928 = zext i1 %9927 to i8
  store i8 %9928, i8* %17, align 1
  %9929 = and i32 %9923, 255
  %9930 = tail call i32 @llvm.ctpop.i32(i32 %9929)
  %9931 = trunc i32 %9930 to i8
  %9932 = and i8 %9931, 1
  %9933 = xor i8 %9932, 1
  store i8 %9933, i8* %18, align 1
  %9934 = xor i32 %9922, %9920
  %9935 = xor i32 %9934, %9923
  %9936 = lshr i32 %9935, 4
  %9937 = trunc i32 %9936 to i8
  %9938 = and i8 %9937, 1
  store i8 %9938, i8* %19, align 1
  %9939 = icmp eq i32 %9923, 0
  %9940 = zext i1 %9939 to i8
  store i8 %9940, i8* %20, align 1
  %9941 = lshr i32 %9923, 31
  %9942 = trunc i32 %9941 to i8
  store i8 %9942, i8* %21, align 1
  %9943 = lshr i32 %9920, 31
  %9944 = lshr i32 %9922, 31
  %9945 = xor i32 %9941, %9943
  %9946 = xor i32 %9941, %9944
  %9947 = add nuw nsw i32 %9945, %9946
  %9948 = icmp eq i32 %9947, 2
  %9949 = zext i1 %9948 to i8
  store i8 %9949, i8* %22, align 1
  %9950 = add i64 %9640, 173
  store i64 %9950, i64* %3, align 8
  store i32 %9923, i32* %9921, align 4
  %9951 = load i64, i64* %3, align 8
  %9952 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %9952, i64* %RAX.i1659, align 8
  %9953 = add i64 %9952, 8
  %9954 = add i64 %9951, 12
  store i64 %9954, i64* %3, align 8
  %9955 = inttoptr i64 %9953 to i64*
  %9956 = load i64, i64* %9955, align 8
  store i64 %9956, i64* %RAX.i1659, align 8
  %9957 = load i64, i64* %RBP.i, align 8
  %9958 = add i64 %9957, -232
  %9959 = add i64 %9951, 18
  store i64 %9959, i64* %3, align 8
  %9960 = inttoptr i64 %9958 to i32*
  %9961 = load i32, i32* %9960, align 4
  %9962 = zext i32 %9961 to i64
  store i64 %9962, i64* %RCX.i1588, align 8
  %9963 = add i64 %9957, -60
  %9964 = add i64 %9951, 21
  store i64 %9964, i64* %3, align 8
  %9965 = inttoptr i64 %9963 to i32*
  %9966 = load i32, i32* %9965, align 4
  %9967 = add i32 %9966, %9961
  %9968 = zext i32 %9967 to i64
  store i64 %9968, i64* %RCX.i1588, align 8
  %9969 = icmp ult i32 %9967, %9961
  %9970 = icmp ult i32 %9967, %9966
  %9971 = or i1 %9969, %9970
  %9972 = zext i1 %9971 to i8
  store i8 %9972, i8* %17, align 1
  %9973 = and i32 %9967, 255
  %9974 = tail call i32 @llvm.ctpop.i32(i32 %9973)
  %9975 = trunc i32 %9974 to i8
  %9976 = and i8 %9975, 1
  %9977 = xor i8 %9976, 1
  store i8 %9977, i8* %18, align 1
  %9978 = xor i32 %9966, %9961
  %9979 = xor i32 %9978, %9967
  %9980 = lshr i32 %9979, 4
  %9981 = trunc i32 %9980 to i8
  %9982 = and i8 %9981, 1
  store i8 %9982, i8* %19, align 1
  %9983 = icmp eq i32 %9967, 0
  %9984 = zext i1 %9983 to i8
  store i8 %9984, i8* %20, align 1
  %9985 = lshr i32 %9967, 31
  %9986 = trunc i32 %9985 to i8
  store i8 %9986, i8* %21, align 1
  %9987 = lshr i32 %9961, 31
  %9988 = lshr i32 %9966, 31
  %9989 = xor i32 %9985, %9987
  %9990 = xor i32 %9985, %9988
  %9991 = add nuw nsw i32 %9989, %9990
  %9992 = icmp eq i32 %9991, 2
  %9993 = zext i1 %9992 to i8
  store i8 %9993, i8* %22, align 1
  %9994 = sext i32 %9967 to i64
  store i64 %9994, i64* %RDX.i1943, align 8
  %9995 = shl nsw i64 %9994, 3
  %9996 = add i64 %9956, %9995
  %9997 = add i64 %9951, 28
  store i64 %9997, i64* %3, align 8
  %9998 = inttoptr i64 %9996 to i64*
  %9999 = load i64, i64* %9998, align 8
  store i64 %9999, i64* %RAX.i1659, align 8
  %10000 = add i64 %9957, -56
  %10001 = add i64 %9951, 32
  store i64 %10001, i64* %3, align 8
  %10002 = inttoptr i64 %10000 to i32*
  %10003 = load i32, i32* %10002, align 4
  %10004 = sext i32 %10003 to i64
  store i64 %10004, i64* %RDX.i1943, align 8
  %10005 = shl nsw i64 %10004, 1
  %10006 = add i64 %10005, %9999
  %10007 = add i64 %9951, 36
  store i64 %10007, i64* %3, align 8
  %10008 = inttoptr i64 %10006 to i16*
  %10009 = load i16, i16* %10008, align 2
  %10010 = zext i16 %10009 to i64
  store i64 %10010, i64* %RCX.i1588, align 8
  %10011 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %10011, i64* %RAX.i1659, align 8
  %10012 = add i64 %10011, 6464
  %10013 = add i64 %9951, 51
  store i64 %10013, i64* %3, align 8
  %10014 = inttoptr i64 %10012 to i64*
  %10015 = load i64, i64* %10014, align 8
  store i64 %10015, i64* %RAX.i1659, align 8
  %10016 = add i64 %10015, 8
  %10017 = add i64 %9951, 55
  store i64 %10017, i64* %3, align 8
  %10018 = inttoptr i64 %10016 to i64*
  %10019 = load i64, i64* %10018, align 8
  store i64 %10019, i64* %RAX.i1659, align 8
  %10020 = add i64 %9951, 61
  store i64 %10020, i64* %3, align 8
  %10021 = load i32, i32* %9960, align 4
  %10022 = zext i32 %10021 to i64
  store i64 %10022, i64* %RSI.i2015, align 8
  %10023 = add i64 %9951, 64
  store i64 %10023, i64* %3, align 8
  %10024 = load i32, i32* %9965, align 4
  %10025 = add i32 %10024, %10021
  %10026 = zext i32 %10025 to i64
  store i64 %10026, i64* %RSI.i2015, align 8
  %10027 = icmp ult i32 %10025, %10021
  %10028 = icmp ult i32 %10025, %10024
  %10029 = or i1 %10027, %10028
  %10030 = zext i1 %10029 to i8
  store i8 %10030, i8* %17, align 1
  %10031 = and i32 %10025, 255
  %10032 = tail call i32 @llvm.ctpop.i32(i32 %10031)
  %10033 = trunc i32 %10032 to i8
  %10034 = and i8 %10033, 1
  %10035 = xor i8 %10034, 1
  store i8 %10035, i8* %18, align 1
  %10036 = xor i32 %10024, %10021
  %10037 = xor i32 %10036, %10025
  %10038 = lshr i32 %10037, 4
  %10039 = trunc i32 %10038 to i8
  %10040 = and i8 %10039, 1
  store i8 %10040, i8* %19, align 1
  %10041 = icmp eq i32 %10025, 0
  %10042 = zext i1 %10041 to i8
  store i8 %10042, i8* %20, align 1
  %10043 = lshr i32 %10025, 31
  %10044 = trunc i32 %10043 to i8
  store i8 %10044, i8* %21, align 1
  %10045 = lshr i32 %10021, 31
  %10046 = lshr i32 %10024, 31
  %10047 = xor i32 %10043, %10045
  %10048 = xor i32 %10043, %10046
  %10049 = add nuw nsw i32 %10047, %10048
  %10050 = icmp eq i32 %10049, 2
  %10051 = zext i1 %10050 to i8
  store i8 %10051, i8* %22, align 1
  %10052 = sext i32 %10025 to i64
  store i64 %10052, i64* %RDX.i1943, align 8
  %10053 = shl nsw i64 %10052, 3
  %10054 = add i64 %10019, %10053
  %10055 = add i64 %9951, 71
  store i64 %10055, i64* %3, align 8
  %10056 = inttoptr i64 %10054 to i64*
  %10057 = load i64, i64* %10056, align 8
  store i64 %10057, i64* %RAX.i1659, align 8
  %10058 = load i64, i64* %RBP.i, align 8
  %10059 = add i64 %10058, -56
  %10060 = add i64 %9951, 75
  store i64 %10060, i64* %3, align 8
  %10061 = inttoptr i64 %10059 to i32*
  %10062 = load i32, i32* %10061, align 4
  %10063 = sext i32 %10062 to i64
  store i64 %10063, i64* %RDX.i1943, align 8
  %10064 = shl nsw i64 %10063, 1
  %10065 = add i64 %10064, %10057
  %10066 = add i64 %9951, 79
  store i64 %10066, i64* %3, align 8
  %10067 = inttoptr i64 %10065 to i16*
  %10068 = load i16, i16* %10067, align 2
  %10069 = zext i16 %10068 to i64
  store i64 %10069, i64* %RSI.i2015, align 8
  %10070 = zext i16 %10068 to i32
  %10071 = zext i16 %10009 to i32
  %10072 = sub nsw i32 %10071, %10070
  %10073 = zext i32 %10072 to i64
  store i64 %10073, i64* %RCX.i1588, align 8
  %10074 = icmp ult i16 %10009, %10068
  %10075 = zext i1 %10074 to i8
  store i8 %10075, i8* %17, align 1
  %10076 = and i32 %10072, 255
  %10077 = tail call i32 @llvm.ctpop.i32(i32 %10076)
  %10078 = trunc i32 %10077 to i8
  %10079 = and i8 %10078, 1
  %10080 = xor i8 %10079, 1
  store i8 %10080, i8* %18, align 1
  %10081 = xor i16 %10068, %10009
  %10082 = zext i16 %10081 to i32
  %10083 = xor i32 %10082, %10072
  %10084 = lshr i32 %10083, 4
  %10085 = trunc i32 %10084 to i8
  %10086 = and i8 %10085, 1
  store i8 %10086, i8* %19, align 1
  %10087 = icmp eq i32 %10072, 0
  %10088 = zext i1 %10087 to i8
  store i8 %10088, i8* %20, align 1
  %10089 = lshr i32 %10072, 31
  %10090 = trunc i32 %10089 to i8
  store i8 %10090, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %10091 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %10091, i64* %RAX.i1659, align 8
  %10092 = add i64 %10091, 8
  %10093 = add i64 %9951, 93
  store i64 %10093, i64* %3, align 8
  %10094 = inttoptr i64 %10092 to i64*
  %10095 = load i64, i64* %10094, align 8
  store i64 %10095, i64* %RAX.i1659, align 8
  %10096 = add i64 %10058, -232
  %10097 = add i64 %9951, 99
  store i64 %10097, i64* %3, align 8
  %10098 = inttoptr i64 %10096 to i32*
  %10099 = load i32, i32* %10098, align 4
  %10100 = zext i32 %10099 to i64
  store i64 %10100, i64* %RSI.i2015, align 8
  %10101 = add i64 %10058, -60
  %10102 = add i64 %9951, 102
  store i64 %10102, i64* %3, align 8
  %10103 = inttoptr i64 %10101 to i32*
  %10104 = load i32, i32* %10103, align 4
  %10105 = add i32 %10104, %10099
  %10106 = zext i32 %10105 to i64
  store i64 %10106, i64* %RSI.i2015, align 8
  %10107 = icmp ult i32 %10105, %10099
  %10108 = icmp ult i32 %10105, %10104
  %10109 = or i1 %10107, %10108
  %10110 = zext i1 %10109 to i8
  store i8 %10110, i8* %17, align 1
  %10111 = and i32 %10105, 255
  %10112 = tail call i32 @llvm.ctpop.i32(i32 %10111)
  %10113 = trunc i32 %10112 to i8
  %10114 = and i8 %10113, 1
  %10115 = xor i8 %10114, 1
  store i8 %10115, i8* %18, align 1
  %10116 = xor i32 %10104, %10099
  %10117 = xor i32 %10116, %10105
  %10118 = lshr i32 %10117, 4
  %10119 = trunc i32 %10118 to i8
  %10120 = and i8 %10119, 1
  store i8 %10120, i8* %19, align 1
  %10121 = icmp eq i32 %10105, 0
  %10122 = zext i1 %10121 to i8
  store i8 %10122, i8* %20, align 1
  %10123 = lshr i32 %10105, 31
  %10124 = trunc i32 %10123 to i8
  store i8 %10124, i8* %21, align 1
  %10125 = lshr i32 %10099, 31
  %10126 = lshr i32 %10104, 31
  %10127 = xor i32 %10123, %10125
  %10128 = xor i32 %10123, %10126
  %10129 = add nuw nsw i32 %10127, %10128
  %10130 = icmp eq i32 %10129, 2
  %10131 = zext i1 %10130 to i8
  store i8 %10131, i8* %22, align 1
  %10132 = sext i32 %10105 to i64
  store i64 %10132, i64* %RDX.i1943, align 8
  %10133 = shl nsw i64 %10132, 3
  %10134 = add i64 %10095, %10133
  %10135 = add i64 %9951, 109
  store i64 %10135, i64* %3, align 8
  %10136 = inttoptr i64 %10134 to i64*
  %10137 = load i64, i64* %10136, align 8
  store i64 %10137, i64* %RAX.i1659, align 8
  %10138 = load i64, i64* %RBP.i, align 8
  %10139 = add i64 %10138, -56
  %10140 = add i64 %9951, 113
  store i64 %10140, i64* %3, align 8
  %10141 = inttoptr i64 %10139 to i32*
  %10142 = load i32, i32* %10141, align 4
  %10143 = sext i32 %10142 to i64
  store i64 %10143, i64* %RDX.i1943, align 8
  %10144 = shl nsw i64 %10143, 1
  %10145 = add i64 %10144, %10137
  %10146 = add i64 %9951, 117
  store i64 %10146, i64* %3, align 8
  %10147 = inttoptr i64 %10145 to i16*
  %10148 = load i16, i16* %10147, align 2
  %10149 = zext i16 %10148 to i64
  store i64 %10149, i64* %RSI.i2015, align 8
  %10150 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %10150, i64* %RAX.i1659, align 8
  %10151 = add i64 %10150, 6464
  %10152 = add i64 %9951, 132
  store i64 %10152, i64* %3, align 8
  %10153 = inttoptr i64 %10151 to i64*
  %10154 = load i64, i64* %10153, align 8
  store i64 %10154, i64* %RAX.i1659, align 8
  %10155 = add i64 %10154, 8
  %10156 = add i64 %9951, 136
  store i64 %10156, i64* %3, align 8
  %10157 = inttoptr i64 %10155 to i64*
  %10158 = load i64, i64* %10157, align 8
  store i64 %10158, i64* %RAX.i1659, align 8
  %10159 = add i64 %10138, -232
  %10160 = add i64 %9951, 142
  store i64 %10160, i64* %3, align 8
  %10161 = inttoptr i64 %10159 to i32*
  %10162 = load i32, i32* %10161, align 4
  %10163 = zext i32 %10162 to i64
  store i64 %10163, i64* %RDI.i6998, align 8
  %10164 = add i64 %10138, -60
  %10165 = add i64 %9951, 145
  store i64 %10165, i64* %3, align 8
  %10166 = inttoptr i64 %10164 to i32*
  %10167 = load i32, i32* %10166, align 4
  %10168 = add i32 %10167, %10162
  %10169 = zext i32 %10168 to i64
  store i64 %10169, i64* %RDI.i6998, align 8
  %10170 = icmp ult i32 %10168, %10162
  %10171 = icmp ult i32 %10168, %10167
  %10172 = or i1 %10170, %10171
  %10173 = zext i1 %10172 to i8
  store i8 %10173, i8* %17, align 1
  %10174 = and i32 %10168, 255
  %10175 = tail call i32 @llvm.ctpop.i32(i32 %10174)
  %10176 = trunc i32 %10175 to i8
  %10177 = and i8 %10176, 1
  %10178 = xor i8 %10177, 1
  store i8 %10178, i8* %18, align 1
  %10179 = xor i32 %10167, %10162
  %10180 = xor i32 %10179, %10168
  %10181 = lshr i32 %10180, 4
  %10182 = trunc i32 %10181 to i8
  %10183 = and i8 %10182, 1
  store i8 %10183, i8* %19, align 1
  %10184 = icmp eq i32 %10168, 0
  %10185 = zext i1 %10184 to i8
  store i8 %10185, i8* %20, align 1
  %10186 = lshr i32 %10168, 31
  %10187 = trunc i32 %10186 to i8
  store i8 %10187, i8* %21, align 1
  %10188 = lshr i32 %10162, 31
  %10189 = lshr i32 %10167, 31
  %10190 = xor i32 %10186, %10188
  %10191 = xor i32 %10186, %10189
  %10192 = add nuw nsw i32 %10190, %10191
  %10193 = icmp eq i32 %10192, 2
  %10194 = zext i1 %10193 to i8
  store i8 %10194, i8* %22, align 1
  %10195 = sext i32 %10168 to i64
  store i64 %10195, i64* %RDX.i1943, align 8
  %10196 = shl nsw i64 %10195, 3
  %10197 = add i64 %10158, %10196
  %10198 = add i64 %9951, 152
  store i64 %10198, i64* %3, align 8
  %10199 = inttoptr i64 %10197 to i64*
  %10200 = load i64, i64* %10199, align 8
  store i64 %10200, i64* %RAX.i1659, align 8
  %10201 = add i64 %9951, 156
  store i64 %10201, i64* %3, align 8
  %10202 = load i32, i32* %10141, align 4
  %10203 = sext i32 %10202 to i64
  store i64 %10203, i64* %RDX.i1943, align 8
  %10204 = shl nsw i64 %10203, 1
  %10205 = add i64 %10204, %10200
  %10206 = add i64 %9951, 160
  store i64 %10206, i64* %3, align 8
  %10207 = inttoptr i64 %10205 to i16*
  %10208 = load i16, i16* %10207, align 2
  %10209 = zext i16 %10208 to i64
  store i64 %10209, i64* %RDI.i6998, align 8
  %10210 = zext i16 %10208 to i32
  %10211 = zext i16 %10148 to i32
  %10212 = sub nsw i32 %10211, %10210
  %10213 = zext i32 %10212 to i64
  store i64 %10213, i64* %RSI.i2015, align 8
  %10214 = load i64, i64* %RCX.i1588, align 8
  %10215 = shl i64 %10214, 32
  %10216 = ashr exact i64 %10215, 32
  %10217 = sext i32 %10212 to i64
  %10218 = mul nsw i64 %10217, %10216
  %10219 = trunc i64 %10218 to i32
  %10220 = and i64 %10218, 4294967295
  store i64 %10220, i64* %RCX.i1588, align 8
  %10221 = shl i64 %10218, 32
  %10222 = ashr exact i64 %10221, 32
  %10223 = icmp ne i64 %10222, %10218
  %10224 = zext i1 %10223 to i8
  store i8 %10224, i8* %17, align 1
  %10225 = and i32 %10219, 255
  %10226 = tail call i32 @llvm.ctpop.i32(i32 %10225)
  %10227 = trunc i32 %10226 to i8
  %10228 = and i8 %10227, 1
  %10229 = xor i8 %10228, 1
  store i8 %10229, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  %10230 = lshr i32 %10219, 31
  %10231 = trunc i32 %10230 to i8
  store i8 %10231, i8* %21, align 1
  store i8 %10224, i8* %22, align 1
  %10232 = load i64, i64* %RBP.i, align 8
  %10233 = add i64 %10232, -356
  %10234 = add i64 %9951, 171
  store i64 %10234, i64* %3, align 8
  %10235 = trunc i64 %10218 to i32
  %10236 = inttoptr i64 %10233 to i32*
  %10237 = load i32, i32* %10236, align 4
  %10238 = add i32 %10237, %10235
  %10239 = zext i32 %10238 to i64
  store i64 %10239, i64* %RCX.i1588, align 8
  %10240 = icmp ult i32 %10238, %10235
  %10241 = icmp ult i32 %10238, %10237
  %10242 = or i1 %10240, %10241
  %10243 = zext i1 %10242 to i8
  store i8 %10243, i8* %17, align 1
  %10244 = and i32 %10238, 255
  %10245 = tail call i32 @llvm.ctpop.i32(i32 %10244)
  %10246 = trunc i32 %10245 to i8
  %10247 = and i8 %10246, 1
  %10248 = xor i8 %10247, 1
  store i8 %10248, i8* %18, align 1
  %10249 = xor i32 %10237, %10235
  %10250 = xor i32 %10249, %10238
  %10251 = lshr i32 %10250, 4
  %10252 = trunc i32 %10251 to i8
  %10253 = and i8 %10252, 1
  store i8 %10253, i8* %19, align 1
  %10254 = icmp eq i32 %10238, 0
  %10255 = zext i1 %10254 to i8
  store i8 %10255, i8* %20, align 1
  %10256 = lshr i32 %10238, 31
  %10257 = trunc i32 %10256 to i8
  store i8 %10257, i8* %21, align 1
  %10258 = lshr i32 %10235, 31
  %10259 = lshr i32 %10237, 31
  %10260 = xor i32 %10256, %10258
  %10261 = xor i32 %10256, %10259
  %10262 = add nuw nsw i32 %10260, %10261
  %10263 = icmp eq i32 %10262, 2
  %10264 = zext i1 %10263 to i8
  store i8 %10264, i8* %22, align 1
  %10265 = add i64 %9951, 177
  store i64 %10265, i64* %3, align 8
  store i32 %10238, i32* %10236, align 4
  %10266 = load i64, i64* %RBP.i, align 8
  %10267 = add i64 %10266, -56
  %10268 = load i64, i64* %3, align 8
  %10269 = add i64 %10268, 3
  store i64 %10269, i64* %3, align 8
  %10270 = inttoptr i64 %10267 to i32*
  %10271 = load i32, i32* %10270, align 4
  %10272 = add i32 %10271, 1
  %10273 = zext i32 %10272 to i64
  store i64 %10273, i64* %RAX.i1659, align 8
  %10274 = icmp eq i32 %10271, -1
  %10275 = icmp eq i32 %10272, 0
  %10276 = or i1 %10274, %10275
  %10277 = zext i1 %10276 to i8
  store i8 %10277, i8* %17, align 1
  %10278 = and i32 %10272, 255
  %10279 = tail call i32 @llvm.ctpop.i32(i32 %10278)
  %10280 = trunc i32 %10279 to i8
  %10281 = and i8 %10280, 1
  %10282 = xor i8 %10281, 1
  store i8 %10282, i8* %18, align 1
  %10283 = xor i32 %10272, %10271
  %10284 = lshr i32 %10283, 4
  %10285 = trunc i32 %10284 to i8
  %10286 = and i8 %10285, 1
  store i8 %10286, i8* %19, align 1
  %10287 = zext i1 %10275 to i8
  store i8 %10287, i8* %20, align 1
  %10288 = lshr i32 %10272, 31
  %10289 = trunc i32 %10288 to i8
  store i8 %10289, i8* %21, align 1
  %10290 = lshr i32 %10271, 31
  %10291 = xor i32 %10288, %10290
  %10292 = add nuw nsw i32 %10291, %10288
  %10293 = icmp eq i32 %10292, 2
  %10294 = zext i1 %10293 to i8
  store i8 %10294, i8* %22, align 1
  %10295 = add i64 %10268, 9
  store i64 %10295, i64* %3, align 8
  store i32 %10272, i32* %10270, align 4
  %10296 = load i64, i64* %3, align 8
  %10297 = add i64 %10296, -540
  store i64 %10297, i64* %3, align 8
  br label %block_.L_484f06

block_.L_485127:                                  ; preds = %block_.L_484f06
  %10298 = add i64 %9306, -60
  %10299 = add i64 %9344, 8
  store i64 %10299, i64* %3, align 8
  %10300 = inttoptr i64 %10298 to i32*
  %10301 = load i32, i32* %10300, align 4
  %10302 = add i32 %10301, 1
  %10303 = zext i32 %10302 to i64
  store i64 %10303, i64* %RAX.i1659, align 8
  %10304 = icmp eq i32 %10301, -1
  %10305 = icmp eq i32 %10302, 0
  %10306 = or i1 %10304, %10305
  %10307 = zext i1 %10306 to i8
  store i8 %10307, i8* %17, align 1
  %10308 = and i32 %10302, 255
  %10309 = tail call i32 @llvm.ctpop.i32(i32 %10308)
  %10310 = trunc i32 %10309 to i8
  %10311 = and i8 %10310, 1
  %10312 = xor i8 %10311, 1
  store i8 %10312, i8* %18, align 1
  %10313 = xor i32 %10302, %10301
  %10314 = lshr i32 %10313, 4
  %10315 = trunc i32 %10314 to i8
  %10316 = and i8 %10315, 1
  store i8 %10316, i8* %19, align 1
  %10317 = zext i1 %10305 to i8
  store i8 %10317, i8* %20, align 1
  %10318 = lshr i32 %10302, 31
  %10319 = trunc i32 %10318 to i8
  store i8 %10319, i8* %21, align 1
  %10320 = lshr i32 %10301, 31
  %10321 = xor i32 %10318, %10320
  %10322 = add nuw nsw i32 %10321, %10318
  %10323 = icmp eq i32 %10322, 2
  %10324 = zext i1 %10323 to i8
  store i8 %10324, i8* %22, align 1
  %10325 = add i64 %9344, 14
  store i64 %10325, i64* %3, align 8
  store i32 %10302, i32* %10300, align 4
  %10326 = load i64, i64* %3, align 8
  %10327 = add i64 %10326, -578
  store i64 %10327, i64* %3, align 8
  br label %block_.L_484ef3

block_.L_48513a:                                  ; preds = %block_.L_484ef3
  %10328 = add i64 %9268, -356
  %10329 = add i64 %9296, 8
  store i64 %10329, i64* %3, align 8
  %10330 = inttoptr i64 %10328 to i32*
  %10331 = load i32, i32* %10330, align 4
  %10332 = sitofp i32 %10331 to double
  store double %10332, double* %68, align 1
  %10333 = add i64 %9268, -24
  %10334 = add i64 %9296, 13
  store i64 %10334, i64* %3, align 8
  %10335 = inttoptr i64 %10333 to i64*
  %10336 = load i64, i64* %10335, align 8
  store i64 %10336, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %10337 = add i64 %9268, -352
  %10338 = add i64 %9296, 21
  store i64 %10338, i64* %3, align 8
  %10339 = inttoptr i64 %10337 to i32*
  %10340 = load i32, i32* %10339, align 4
  %10341 = sitofp i32 %10340 to double
  store double %10341, double* %45, align 1
  %10342 = bitcast i64 %10336 to double
  %10343 = fmul double %10341, %10342
  store double %10343, double* %36, align 1
  store i64 0, i64* %38, align 1
  %10344 = fadd double %10343, %10332
  store double %10344, double* %68, align 1
  %10345 = add i64 %9268, -216
  %10346 = add i64 %9296, 37
  store i64 %10346, i64* %3, align 8
  %10347 = inttoptr i64 %10345 to double*
  store double %10344, double* %10347, align 8
  %10348 = load i64, i64* %RBP.i, align 8
  %10349 = add i64 %10348, -216
  %10350 = load i64, i64* %3, align 8
  %10351 = add i64 %10350, 8
  store i64 %10351, i64* %3, align 8
  %10352 = inttoptr i64 %10349 to i64*
  %10353 = load i64, i64* %10352, align 8
  store i64 %10353, i64* %69, align 1
  store double 0.000000e+00, double* %1190, align 1
  %10354 = add i64 %10348, -256
  %10355 = add i64 %10350, 16
  store i64 %10355, i64* %3, align 8
  %10356 = inttoptr i64 %10354 to i64*
  %10357 = load i64, i64* %10356, align 8
  store i64 %10357, i64* %37, align 1
  store double 0.000000e+00, double* %39, align 1
  %10358 = add i64 %10350, 20
  store i64 %10358, i64* %3, align 8
  %.cast189 = bitcast i64 %10357 to double
  %10359 = bitcast i64 %10353 to double
  %10360 = fcmp uno double %.cast189, %10359
  br i1 %10360, label %10361, label %10371

; <label>:10361:                                  ; preds = %block_.L_48513a
  %10362 = fadd double %.cast189, %10359
  %10363 = bitcast double %10362 to i64
  %10364 = and i64 %10363, 9221120237041090560
  %10365 = icmp eq i64 %10364, 9218868437227405312
  %10366 = and i64 %10363, 2251799813685247
  %10367 = icmp ne i64 %10366, 0
  %10368 = and i1 %10365, %10367
  br i1 %10368, label %10369, label %10377

; <label>:10369:                                  ; preds = %10361
  %10370 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %10358, %struct.Memory* %MEMORY.8)
  %.pre589 = load i64, i64* %3, align 8
  br label %routine_ucomisd__xmm0___xmm1.exit

; <label>:10371:                                  ; preds = %block_.L_48513a
  %10372 = fcmp ogt double %.cast189, %10359
  br i1 %10372, label %10377, label %10373

; <label>:10373:                                  ; preds = %10371
  %10374 = fcmp olt double %.cast189, %10359
  br i1 %10374, label %10377, label %10375

; <label>:10375:                                  ; preds = %10373
  %10376 = fcmp oeq double %.cast189, %10359
  br i1 %10376, label %10377, label %10381

; <label>:10377:                                  ; preds = %10375, %10373, %10371, %10361
  %10378 = phi i8 [ 0, %10371 ], [ 0, %10373 ], [ 1, %10375 ], [ 1, %10361 ]
  %10379 = phi i8 [ 0, %10371 ], [ 0, %10373 ], [ 0, %10375 ], [ 1, %10361 ]
  %10380 = phi i8 [ 0, %10371 ], [ 1, %10373 ], [ 0, %10375 ], [ 1, %10361 ]
  store i8 %10378, i8* %20, align 1
  store i8 %10379, i8* %18, align 1
  store i8 %10380, i8* %17, align 1
  br label %10381

; <label>:10381:                                  ; preds = %10377, %10375
  store i8 0, i8* %22, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %19, align 1
  br label %routine_ucomisd__xmm0___xmm1.exit

routine_ucomisd__xmm0___xmm1.exit:                ; preds = %10381, %10369
  %10382 = phi i64 [ %.pre589, %10369 ], [ %10358, %10381 ]
  %10383 = phi %struct.Memory* [ %10370, %10369 ], [ %MEMORY.8, %10381 ]
  %10384 = add i64 %10382, 1322
  %10385 = add i64 %10382, 6
  %10386 = load i8, i8* %17, align 1
  %10387 = load i8, i8* %20, align 1
  %10388 = or i8 %10387, %10386
  %10389 = icmp ne i8 %10388, 0
  %10390 = select i1 %10389, i64 %10384, i64 %10385
  store i64 %10390, i64* %3, align 8
  br i1 %10389, label %block_.L_48569d, label %block_485179

block_485179:                                     ; preds = %routine_ucomisd__xmm0___xmm1.exit
  %10391 = load i64, i64* %RBP.i, align 8
  %10392 = add i64 %10391, -48
  %10393 = add i64 %10390, 7
  store i64 %10393, i64* %3, align 8
  %10394 = inttoptr i64 %10392 to i32*
  store i32 0, i32* %10394, align 4
  %.pre590 = load i64, i64* %3, align 8
  br label %block_.L_485180

block_.L_485180:                                  ; preds = %block_.L_4851ee, %block_485179
  %10395 = phi i64 [ %10580, %block_.L_4851ee ], [ %.pre590, %block_485179 ]
  %10396 = load i64, i64* %RBP.i, align 8
  %10397 = add i64 %10396, -48
  %10398 = add i64 %10395, 4
  store i64 %10398, i64* %3, align 8
  %10399 = inttoptr i64 %10397 to i32*
  %10400 = load i32, i32* %10399, align 4
  %10401 = add i32 %10400, -2
  %10402 = icmp ult i32 %10400, 2
  %10403 = zext i1 %10402 to i8
  store i8 %10403, i8* %17, align 1
  %10404 = and i32 %10401, 255
  %10405 = tail call i32 @llvm.ctpop.i32(i32 %10404)
  %10406 = trunc i32 %10405 to i8
  %10407 = and i8 %10406, 1
  %10408 = xor i8 %10407, 1
  store i8 %10408, i8* %18, align 1
  %10409 = xor i32 %10401, %10400
  %10410 = lshr i32 %10409, 4
  %10411 = trunc i32 %10410 to i8
  %10412 = and i8 %10411, 1
  store i8 %10412, i8* %19, align 1
  %10413 = icmp eq i32 %10401, 0
  %10414 = zext i1 %10413 to i8
  store i8 %10414, i8* %20, align 1
  %10415 = lshr i32 %10401, 31
  %10416 = trunc i32 %10415 to i8
  store i8 %10416, i8* %21, align 1
  %10417 = lshr i32 %10400, 31
  %10418 = xor i32 %10415, %10417
  %10419 = add nuw nsw i32 %10418, %10417
  %10420 = icmp eq i32 %10419, 2
  %10421 = zext i1 %10420 to i8
  store i8 %10421, i8* %22, align 1
  %10422 = icmp ne i8 %10416, 0
  %10423 = xor i1 %10422, %10420
  %.v745 = select i1 %10423, i64 10, i64 129
  %10424 = add i64 %10395, %.v745
  store i64 %10424, i64* %3, align 8
  br i1 %10423, label %block_48518a, label %block_.L_485201

block_48518a:                                     ; preds = %block_.L_485180
  %10425 = add i64 %10396, -44
  %10426 = add i64 %10424, 7
  store i64 %10426, i64* %3, align 8
  %10427 = inttoptr i64 %10425 to i32*
  store i32 0, i32* %10427, align 4
  %.pre637 = load i64, i64* %3, align 8
  br label %block_.L_485191

block_.L_485191:                                  ; preds = %block_48519b, %block_48518a
  %10428 = phi i64 [ %10550, %block_48519b ], [ %.pre637, %block_48518a ]
  %10429 = load i64, i64* %RBP.i, align 8
  %10430 = add i64 %10429, -44
  %10431 = add i64 %10428, 4
  store i64 %10431, i64* %3, align 8
  %10432 = inttoptr i64 %10430 to i32*
  %10433 = load i32, i32* %10432, align 4
  %10434 = add i32 %10433, -18
  %10435 = icmp ult i32 %10433, 18
  %10436 = zext i1 %10435 to i8
  store i8 %10436, i8* %17, align 1
  %10437 = and i32 %10434, 255
  %10438 = tail call i32 @llvm.ctpop.i32(i32 %10437)
  %10439 = trunc i32 %10438 to i8
  %10440 = and i8 %10439, 1
  %10441 = xor i8 %10440, 1
  store i8 %10441, i8* %18, align 1
  %10442 = xor i32 %10433, 16
  %10443 = xor i32 %10442, %10434
  %10444 = lshr i32 %10443, 4
  %10445 = trunc i32 %10444 to i8
  %10446 = and i8 %10445, 1
  store i8 %10446, i8* %19, align 1
  %10447 = icmp eq i32 %10434, 0
  %10448 = zext i1 %10447 to i8
  store i8 %10448, i8* %20, align 1
  %10449 = lshr i32 %10434, 31
  %10450 = trunc i32 %10449 to i8
  store i8 %10450, i8* %21, align 1
  %10451 = lshr i32 %10433, 31
  %10452 = xor i32 %10449, %10451
  %10453 = add nuw nsw i32 %10452, %10451
  %10454 = icmp eq i32 %10453, 2
  %10455 = zext i1 %10454 to i8
  store i8 %10455, i8* %22, align 1
  %10456 = icmp ne i8 %10450, 0
  %10457 = xor i1 %10456, %10454
  %.v686 = select i1 %10457, i64 10, i64 93
  %10458 = add i64 %10428, %.v686
  store i64 %10458, i64* %3, align 8
  br i1 %10457, label %block_48519b, label %block_.L_4851ee

block_48519b:                                     ; preds = %block_.L_485191
  %10459 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10459, i64* %RAX.i1659, align 8
  %10460 = add i64 %10459, 14136
  %10461 = add i64 %10458, 15
  store i64 %10461, i64* %3, align 8
  %10462 = inttoptr i64 %10460 to i64*
  %10463 = load i64, i64* %10462, align 8
  store i64 %10463, i64* %RAX.i1659, align 8
  %10464 = add i64 %10429, -12
  %10465 = add i64 %10458, 19
  store i64 %10465, i64* %3, align 8
  %10466 = inttoptr i64 %10464 to i32*
  %10467 = load i32, i32* %10466, align 4
  %10468 = sext i32 %10467 to i64
  store i64 %10468, i64* %RCX.i1588, align 8
  %10469 = shl nsw i64 %10468, 3
  %10470 = add i64 %10469, %10463
  %10471 = add i64 %10458, 23
  store i64 %10471, i64* %3, align 8
  %10472 = inttoptr i64 %10470 to i64*
  %10473 = load i64, i64* %10472, align 8
  store i64 %10473, i64* %RAX.i1659, align 8
  %10474 = add i64 %10429, -16
  %10475 = add i64 %10458, 27
  store i64 %10475, i64* %3, align 8
  %10476 = inttoptr i64 %10474 to i32*
  %10477 = load i32, i32* %10476, align 4
  %10478 = sext i32 %10477 to i64
  store i64 %10478, i64* %RCX.i1588, align 8
  %10479 = shl nsw i64 %10478, 3
  %10480 = add i64 %10479, %10473
  %10481 = add i64 %10458, 31
  store i64 %10481, i64* %3, align 8
  %10482 = inttoptr i64 %10480 to i64*
  %10483 = load i64, i64* %10482, align 8
  store i64 %10483, i64* %RAX.i1659, align 8
  %10484 = add i64 %10429, -48
  %10485 = add i64 %10458, 35
  store i64 %10485, i64* %3, align 8
  %10486 = inttoptr i64 %10484 to i32*
  %10487 = load i32, i32* %10486, align 4
  %10488 = sext i32 %10487 to i64
  store i64 %10488, i64* %RCX.i1588, align 8
  %10489 = shl nsw i64 %10488, 3
  %10490 = add i64 %10489, %10483
  %10491 = add i64 %10458, 39
  store i64 %10491, i64* %3, align 8
  %10492 = inttoptr i64 %10490 to i64*
  %10493 = load i64, i64* %10492, align 8
  store i64 %10493, i64* %RAX.i1659, align 8
  %10494 = add i64 %10458, 43
  store i64 %10494, i64* %3, align 8
  %10495 = load i32, i32* %10432, align 4
  %10496 = sext i32 %10495 to i64
  store i64 %10496, i64* %RCX.i1588, align 8
  %10497 = shl nsw i64 %10496, 2
  %10498 = add i64 %10497, %10493
  %10499 = add i64 %10458, 46
  store i64 %10499, i64* %3, align 8
  %10500 = inttoptr i64 %10498 to i32*
  %10501 = load i32, i32* %10500, align 4
  %10502 = zext i32 %10501 to i64
  store i64 %10502, i64* %RDX.i1943, align 8
  %10503 = load i64, i64* bitcast (%G_0x6cc608_type* @G_0x6cc608 to i64*), align 8
  store i64 %10503, i64* %RAX.i1659, align 8
  %10504 = add i64 %10458, 58
  store i64 %10504, i64* %3, align 8
  %10505 = load i32, i32* %10486, align 4
  %10506 = sext i32 %10505 to i64
  store i64 %10506, i64* %RCX.i1588, align 8
  %10507 = shl nsw i64 %10506, 3
  %10508 = add i64 %10507, %10503
  %10509 = add i64 %10458, 62
  store i64 %10509, i64* %3, align 8
  %10510 = inttoptr i64 %10508 to i64*
  %10511 = load i64, i64* %10510, align 8
  store i64 %10511, i64* %RAX.i1659, align 8
  %10512 = add i64 %10458, 66
  store i64 %10512, i64* %3, align 8
  %10513 = load i32, i32* %10432, align 4
  %10514 = sext i32 %10513 to i64
  store i64 %10514, i64* %RCX.i1588, align 8
  %10515 = shl nsw i64 %10514, 2
  %10516 = add i64 %10515, %10511
  %10517 = add i64 %10458, 69
  store i64 %10517, i64* %3, align 8
  %10518 = inttoptr i64 %10516 to i32*
  store i32 %10501, i32* %10518, align 4
  %10519 = load i64, i64* %RBP.i, align 8
  %10520 = add i64 %10519, -44
  %10521 = load i64, i64* %3, align 8
  %10522 = add i64 %10521, 3
  store i64 %10522, i64* %3, align 8
  %10523 = inttoptr i64 %10520 to i32*
  %10524 = load i32, i32* %10523, align 4
  %10525 = add i32 %10524, 1
  %10526 = zext i32 %10525 to i64
  store i64 %10526, i64* %RAX.i1659, align 8
  %10527 = icmp eq i32 %10524, -1
  %10528 = icmp eq i32 %10525, 0
  %10529 = or i1 %10527, %10528
  %10530 = zext i1 %10529 to i8
  store i8 %10530, i8* %17, align 1
  %10531 = and i32 %10525, 255
  %10532 = tail call i32 @llvm.ctpop.i32(i32 %10531)
  %10533 = trunc i32 %10532 to i8
  %10534 = and i8 %10533, 1
  %10535 = xor i8 %10534, 1
  store i8 %10535, i8* %18, align 1
  %10536 = xor i32 %10525, %10524
  %10537 = lshr i32 %10536, 4
  %10538 = trunc i32 %10537 to i8
  %10539 = and i8 %10538, 1
  store i8 %10539, i8* %19, align 1
  %10540 = zext i1 %10528 to i8
  store i8 %10540, i8* %20, align 1
  %10541 = lshr i32 %10525, 31
  %10542 = trunc i32 %10541 to i8
  store i8 %10542, i8* %21, align 1
  %10543 = lshr i32 %10524, 31
  %10544 = xor i32 %10541, %10543
  %10545 = add nuw nsw i32 %10544, %10541
  %10546 = icmp eq i32 %10545, 2
  %10547 = zext i1 %10546 to i8
  store i8 %10547, i8* %22, align 1
  %10548 = add i64 %10521, 9
  store i64 %10548, i64* %3, align 8
  store i32 %10525, i32* %10523, align 4
  %10549 = load i64, i64* %3, align 8
  %10550 = add i64 %10549, -88
  store i64 %10550, i64* %3, align 8
  br label %block_.L_485191

block_.L_4851ee:                                  ; preds = %block_.L_485191
  %10551 = add i64 %10429, -48
  %10552 = add i64 %10458, 8
  store i64 %10552, i64* %3, align 8
  %10553 = inttoptr i64 %10551 to i32*
  %10554 = load i32, i32* %10553, align 4
  %10555 = add i32 %10554, 1
  %10556 = zext i32 %10555 to i64
  store i64 %10556, i64* %RAX.i1659, align 8
  %10557 = icmp eq i32 %10554, -1
  %10558 = icmp eq i32 %10555, 0
  %10559 = or i1 %10557, %10558
  %10560 = zext i1 %10559 to i8
  store i8 %10560, i8* %17, align 1
  %10561 = and i32 %10555, 255
  %10562 = tail call i32 @llvm.ctpop.i32(i32 %10561)
  %10563 = trunc i32 %10562 to i8
  %10564 = and i8 %10563, 1
  %10565 = xor i8 %10564, 1
  store i8 %10565, i8* %18, align 1
  %10566 = xor i32 %10555, %10554
  %10567 = lshr i32 %10566, 4
  %10568 = trunc i32 %10567 to i8
  %10569 = and i8 %10568, 1
  store i8 %10569, i8* %19, align 1
  %10570 = zext i1 %10558 to i8
  store i8 %10570, i8* %20, align 1
  %10571 = lshr i32 %10555, 31
  %10572 = trunc i32 %10571 to i8
  store i8 %10572, i8* %21, align 1
  %10573 = lshr i32 %10554, 31
  %10574 = xor i32 %10571, %10573
  %10575 = add nuw nsw i32 %10574, %10571
  %10576 = icmp eq i32 %10575, 2
  %10577 = zext i1 %10576 to i8
  store i8 %10577, i8* %22, align 1
  %10578 = add i64 %10458, 14
  store i64 %10578, i64* %3, align 8
  store i32 %10555, i32* %10553, align 4
  %10579 = load i64, i64* %3, align 8
  %10580 = add i64 %10579, -124
  store i64 %10580, i64* %3, align 8
  br label %block_.L_485180

block_.L_485201:                                  ; preds = %block_.L_485180
  %10581 = add i64 %10424, 7
  store i64 %10581, i64* %3, align 8
  store i32 0, i32* %10399, align 4
  %.pre591 = load i64, i64* %3, align 8
  br label %block_.L_485208

block_.L_485208:                                  ; preds = %block_.L_485280, %block_.L_485201
  %10582 = phi i64 [ %10817, %block_.L_485280 ], [ %.pre591, %block_.L_485201 ]
  %10583 = load i64, i64* %RBP.i, align 8
  %10584 = add i64 %10583, -48
  %10585 = add i64 %10582, 4
  store i64 %10585, i64* %3, align 8
  %10586 = inttoptr i64 %10584 to i32*
  %10587 = load i32, i32* %10586, align 4
  %10588 = add i32 %10587, -2
  %10589 = icmp ult i32 %10587, 2
  %10590 = zext i1 %10589 to i8
  store i8 %10590, i8* %17, align 1
  %10591 = and i32 %10588, 255
  %10592 = tail call i32 @llvm.ctpop.i32(i32 %10591)
  %10593 = trunc i32 %10592 to i8
  %10594 = and i8 %10593, 1
  %10595 = xor i8 %10594, 1
  store i8 %10595, i8* %18, align 1
  %10596 = xor i32 %10588, %10587
  %10597 = lshr i32 %10596, 4
  %10598 = trunc i32 %10597 to i8
  %10599 = and i8 %10598, 1
  store i8 %10599, i8* %19, align 1
  %10600 = icmp eq i32 %10588, 0
  %10601 = zext i1 %10600 to i8
  store i8 %10601, i8* %20, align 1
  %10602 = lshr i32 %10588, 31
  %10603 = trunc i32 %10602 to i8
  store i8 %10603, i8* %21, align 1
  %10604 = lshr i32 %10587, 31
  %10605 = xor i32 %10602, %10604
  %10606 = add nuw nsw i32 %10605, %10604
  %10607 = icmp eq i32 %10606, 2
  %10608 = zext i1 %10607 to i8
  store i8 %10608, i8* %22, align 1
  %10609 = icmp ne i8 %10603, 0
  %10610 = xor i1 %10609, %10607
  %.v746 = select i1 %10610, i64 10, i64 139
  %10611 = add i64 %10582, %.v746
  store i64 %10611, i64* %3, align 8
  br i1 %10610, label %block_485212, label %block_.L_485293

block_485212:                                     ; preds = %block_.L_485208
  %10612 = add i64 %10583, -44
  %10613 = add i64 %10611, 7
  store i64 %10613, i64* %3, align 8
  %10614 = inttoptr i64 %10612 to i32*
  store i32 0, i32* %10614, align 4
  %.pre636 = load i64, i64* %3, align 8
  br label %block_.L_485219

block_.L_485219:                                  ; preds = %block_485223, %block_485212
  %10615 = phi i64 [ %10787, %block_485223 ], [ %.pre636, %block_485212 ]
  %10616 = load i64, i64* %RBP.i, align 8
  %10617 = add i64 %10616, -44
  %10618 = add i64 %10615, 4
  store i64 %10618, i64* %3, align 8
  %10619 = inttoptr i64 %10617 to i32*
  %10620 = load i32, i32* %10619, align 4
  %10621 = add i32 %10620, -18
  %10622 = icmp ult i32 %10620, 18
  %10623 = zext i1 %10622 to i8
  store i8 %10623, i8* %17, align 1
  %10624 = and i32 %10621, 255
  %10625 = tail call i32 @llvm.ctpop.i32(i32 %10624)
  %10626 = trunc i32 %10625 to i8
  %10627 = and i8 %10626, 1
  %10628 = xor i8 %10627, 1
  store i8 %10628, i8* %18, align 1
  %10629 = xor i32 %10620, 16
  %10630 = xor i32 %10629, %10621
  %10631 = lshr i32 %10630, 4
  %10632 = trunc i32 %10631 to i8
  %10633 = and i8 %10632, 1
  store i8 %10633, i8* %19, align 1
  %10634 = icmp eq i32 %10621, 0
  %10635 = zext i1 %10634 to i8
  store i8 %10635, i8* %20, align 1
  %10636 = lshr i32 %10621, 31
  %10637 = trunc i32 %10636 to i8
  store i8 %10637, i8* %21, align 1
  %10638 = lshr i32 %10620, 31
  %10639 = xor i32 %10636, %10638
  %10640 = add nuw nsw i32 %10639, %10638
  %10641 = icmp eq i32 %10640, 2
  %10642 = zext i1 %10641 to i8
  store i8 %10642, i8* %22, align 1
  %10643 = icmp ne i8 %10637, 0
  %10644 = xor i1 %10643, %10641
  %.v685 = select i1 %10644, i64 10, i64 103
  %10645 = add i64 %10615, %.v685
  store i64 %10645, i64* %3, align 8
  br i1 %10644, label %block_485223, label %block_.L_485280

block_485223:                                     ; preds = %block_.L_485219
  store i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64* %RAX.i1659, align 8
  %10646 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10646, i64* %RCX.i1588, align 8
  %10647 = add i64 %10646, 14136
  %10648 = add i64 %10645, 25
  store i64 %10648, i64* %3, align 8
  %10649 = inttoptr i64 %10647 to i64*
  %10650 = load i64, i64* %10649, align 8
  store i64 %10650, i64* %RCX.i1588, align 8
  %10651 = add i64 %10616, -12
  %10652 = add i64 %10645, 28
  store i64 %10652, i64* %3, align 8
  %10653 = inttoptr i64 %10651 to i32*
  %10654 = load i32, i32* %10653, align 4
  %10655 = add i32 %10654, 4
  %10656 = zext i32 %10655 to i64
  store i64 %10656, i64* %RDX.i1943, align 8
  %10657 = icmp ugt i32 %10654, -5
  %10658 = zext i1 %10657 to i8
  store i8 %10658, i8* %17, align 1
  %10659 = and i32 %10655, 255
  %10660 = tail call i32 @llvm.ctpop.i32(i32 %10659)
  %10661 = trunc i32 %10660 to i8
  %10662 = and i8 %10661, 1
  %10663 = xor i8 %10662, 1
  store i8 %10663, i8* %18, align 1
  %10664 = xor i32 %10655, %10654
  %10665 = lshr i32 %10664, 4
  %10666 = trunc i32 %10665 to i8
  %10667 = and i8 %10666, 1
  store i8 %10667, i8* %19, align 1
  %10668 = icmp eq i32 %10655, 0
  %10669 = zext i1 %10668 to i8
  store i8 %10669, i8* %20, align 1
  %10670 = lshr i32 %10655, 31
  %10671 = trunc i32 %10670 to i8
  store i8 %10671, i8* %21, align 1
  %10672 = lshr i32 %10654, 31
  %10673 = xor i32 %10670, %10672
  %10674 = add nuw nsw i32 %10673, %10670
  %10675 = icmp eq i32 %10674, 2
  %10676 = zext i1 %10675 to i8
  store i8 %10676, i8* %22, align 1
  %10677 = sext i32 %10655 to i64
  store i64 %10677, i64* %RSI.i2015, align 8
  %10678 = shl nsw i64 %10677, 3
  %10679 = add i64 %10650, %10678
  %10680 = add i64 %10645, 38
  store i64 %10680, i64* %3, align 8
  %10681 = inttoptr i64 %10679 to i64*
  %10682 = load i64, i64* %10681, align 8
  store i64 %10682, i64* %RCX.i1588, align 8
  %10683 = add i64 %10616, -16
  %10684 = add i64 %10645, 42
  store i64 %10684, i64* %3, align 8
  %10685 = inttoptr i64 %10683 to i32*
  %10686 = load i32, i32* %10685, align 4
  %10687 = sext i32 %10686 to i64
  store i64 %10687, i64* %RSI.i2015, align 8
  %10688 = shl nsw i64 %10687, 3
  %10689 = add i64 %10688, %10682
  %10690 = add i64 %10645, 46
  store i64 %10690, i64* %3, align 8
  %10691 = inttoptr i64 %10689 to i64*
  %10692 = load i64, i64* %10691, align 8
  store i64 %10692, i64* %RCX.i1588, align 8
  %10693 = add i64 %10616, -48
  %10694 = add i64 %10645, 50
  store i64 %10694, i64* %3, align 8
  %10695 = inttoptr i64 %10693 to i32*
  %10696 = load i32, i32* %10695, align 4
  %10697 = sext i32 %10696 to i64
  store i64 %10697, i64* %RSI.i2015, align 8
  %10698 = shl nsw i64 %10697, 3
  %10699 = add i64 %10698, %10692
  %10700 = add i64 %10645, 54
  store i64 %10700, i64* %3, align 8
  %10701 = inttoptr i64 %10699 to i64*
  %10702 = load i64, i64* %10701, align 8
  store i64 %10702, i64* %RCX.i1588, align 8
  %10703 = add i64 %10645, 58
  store i64 %10703, i64* %3, align 8
  %10704 = load i32, i32* %10619, align 4
  %10705 = sext i32 %10704 to i64
  store i64 %10705, i64* %RSI.i2015, align 8
  %10706 = shl nsw i64 %10705, 2
  %10707 = add i64 %10706, %10702
  %10708 = add i64 %10645, 61
  store i64 %10708, i64* %3, align 8
  %10709 = inttoptr i64 %10707 to i32*
  %10710 = load i32, i32* %10709, align 4
  %10711 = zext i32 %10710 to i64
  store i64 %10711, i64* %RDX.i1943, align 8
  %10712 = load i64, i64* %RBP.i, align 8
  %10713 = add i64 %10712, -48
  %10714 = add i64 %10645, 65
  store i64 %10714, i64* %3, align 8
  %10715 = inttoptr i64 %10713 to i32*
  %10716 = load i32, i32* %10715, align 4
  %10717 = sext i32 %10716 to i64
  %10718 = mul nsw i64 %10717, 72
  store i64 %10718, i64* %RCX.i1588, align 8
  %10719 = lshr i64 %10718, 63
  %10720 = load i64, i64* %RAX.i1659, align 8
  %10721 = add i64 %10718, %10720
  store i64 %10721, i64* %RAX.i1659, align 8
  %10722 = icmp ult i64 %10721, %10720
  %10723 = icmp ult i64 %10721, %10718
  %10724 = or i1 %10722, %10723
  %10725 = zext i1 %10724 to i8
  store i8 %10725, i8* %17, align 1
  %10726 = trunc i64 %10721 to i32
  %10727 = and i32 %10726, 255
  %10728 = tail call i32 @llvm.ctpop.i32(i32 %10727)
  %10729 = trunc i32 %10728 to i8
  %10730 = and i8 %10729, 1
  %10731 = xor i8 %10730, 1
  store i8 %10731, i8* %18, align 1
  %10732 = xor i64 %10718, %10720
  %10733 = xor i64 %10732, %10721
  %10734 = lshr i64 %10733, 4
  %10735 = trunc i64 %10734 to i8
  %10736 = and i8 %10735, 1
  store i8 %10736, i8* %19, align 1
  %10737 = icmp eq i64 %10721, 0
  %10738 = zext i1 %10737 to i8
  store i8 %10738, i8* %20, align 1
  %10739 = lshr i64 %10721, 63
  %10740 = trunc i64 %10739 to i8
  store i8 %10740, i8* %21, align 1
  %10741 = lshr i64 %10720, 63
  %10742 = xor i64 %10739, %10741
  %10743 = xor i64 %10739, %10719
  %10744 = add nuw nsw i64 %10742, %10743
  %10745 = icmp eq i64 %10744, 2
  %10746 = zext i1 %10745 to i8
  store i8 %10746, i8* %22, align 1
  %10747 = add i64 %10712, -44
  %10748 = add i64 %10645, 76
  store i64 %10748, i64* %3, align 8
  %10749 = inttoptr i64 %10747 to i32*
  %10750 = load i32, i32* %10749, align 4
  %10751 = sext i32 %10750 to i64
  store i64 %10751, i64* %RCX.i1588, align 8
  %10752 = shl nsw i64 %10751, 2
  %10753 = add i64 %10752, %10721
  %10754 = add i64 %10645, 79
  store i64 %10754, i64* %3, align 8
  %10755 = inttoptr i64 %10753 to i32*
  store i32 %10710, i32* %10755, align 4
  %10756 = load i64, i64* %RBP.i, align 8
  %10757 = add i64 %10756, -44
  %10758 = load i64, i64* %3, align 8
  %10759 = add i64 %10758, 3
  store i64 %10759, i64* %3, align 8
  %10760 = inttoptr i64 %10757 to i32*
  %10761 = load i32, i32* %10760, align 4
  %10762 = add i32 %10761, 1
  %10763 = zext i32 %10762 to i64
  store i64 %10763, i64* %RAX.i1659, align 8
  %10764 = icmp eq i32 %10761, -1
  %10765 = icmp eq i32 %10762, 0
  %10766 = or i1 %10764, %10765
  %10767 = zext i1 %10766 to i8
  store i8 %10767, i8* %17, align 1
  %10768 = and i32 %10762, 255
  %10769 = tail call i32 @llvm.ctpop.i32(i32 %10768)
  %10770 = trunc i32 %10769 to i8
  %10771 = and i8 %10770, 1
  %10772 = xor i8 %10771, 1
  store i8 %10772, i8* %18, align 1
  %10773 = xor i32 %10762, %10761
  %10774 = lshr i32 %10773, 4
  %10775 = trunc i32 %10774 to i8
  %10776 = and i8 %10775, 1
  store i8 %10776, i8* %19, align 1
  %10777 = zext i1 %10765 to i8
  store i8 %10777, i8* %20, align 1
  %10778 = lshr i32 %10762, 31
  %10779 = trunc i32 %10778 to i8
  store i8 %10779, i8* %21, align 1
  %10780 = lshr i32 %10761, 31
  %10781 = xor i32 %10778, %10780
  %10782 = add nuw nsw i32 %10781, %10778
  %10783 = icmp eq i32 %10782, 2
  %10784 = zext i1 %10783 to i8
  store i8 %10784, i8* %22, align 1
  %10785 = add i64 %10758, 9
  store i64 %10785, i64* %3, align 8
  store i32 %10762, i32* %10760, align 4
  %10786 = load i64, i64* %3, align 8
  %10787 = add i64 %10786, -98
  store i64 %10787, i64* %3, align 8
  br label %block_.L_485219

block_.L_485280:                                  ; preds = %block_.L_485219
  %10788 = add i64 %10616, -48
  %10789 = add i64 %10645, 8
  store i64 %10789, i64* %3, align 8
  %10790 = inttoptr i64 %10788 to i32*
  %10791 = load i32, i32* %10790, align 4
  %10792 = add i32 %10791, 1
  %10793 = zext i32 %10792 to i64
  store i64 %10793, i64* %RAX.i1659, align 8
  %10794 = icmp eq i32 %10791, -1
  %10795 = icmp eq i32 %10792, 0
  %10796 = or i1 %10794, %10795
  %10797 = zext i1 %10796 to i8
  store i8 %10797, i8* %17, align 1
  %10798 = and i32 %10792, 255
  %10799 = tail call i32 @llvm.ctpop.i32(i32 %10798)
  %10800 = trunc i32 %10799 to i8
  %10801 = and i8 %10800, 1
  %10802 = xor i8 %10801, 1
  store i8 %10802, i8* %18, align 1
  %10803 = xor i32 %10792, %10791
  %10804 = lshr i32 %10803, 4
  %10805 = trunc i32 %10804 to i8
  %10806 = and i8 %10805, 1
  store i8 %10806, i8* %19, align 1
  %10807 = zext i1 %10795 to i8
  store i8 %10807, i8* %20, align 1
  %10808 = lshr i32 %10792, 31
  %10809 = trunc i32 %10808 to i8
  store i8 %10809, i8* %21, align 1
  %10810 = lshr i32 %10791, 31
  %10811 = xor i32 %10808, %10810
  %10812 = add nuw nsw i32 %10811, %10808
  %10813 = icmp eq i32 %10812, 2
  %10814 = zext i1 %10813 to i8
  store i8 %10814, i8* %22, align 1
  %10815 = add i64 %10645, 14
  store i64 %10815, i64* %3, align 8
  store i32 %10792, i32* %10790, align 4
  %10816 = load i64, i64* %3, align 8
  %10817 = add i64 %10816, -134
  store i64 %10817, i64* %3, align 8
  br label %block_.L_485208

block_.L_485293:                                  ; preds = %block_.L_485208
  %10818 = add i64 %10611, 7
  store i64 %10818, i64* %3, align 8
  store i32 0, i32* %10586, align 4
  %.pre592 = load i64, i64* %3, align 8
  br label %block_.L_48529a

block_.L_48529a:                                  ; preds = %block_.L_485318, %block_.L_485293
  %10819 = phi i64 [ %11054, %block_.L_485318 ], [ %.pre592, %block_.L_485293 ]
  %10820 = load i64, i64* %RBP.i, align 8
  %10821 = add i64 %10820, -48
  %10822 = add i64 %10819, 4
  store i64 %10822, i64* %3, align 8
  %10823 = inttoptr i64 %10821 to i32*
  %10824 = load i32, i32* %10823, align 4
  %10825 = add i32 %10824, -2
  %10826 = icmp ult i32 %10824, 2
  %10827 = zext i1 %10826 to i8
  store i8 %10827, i8* %17, align 1
  %10828 = and i32 %10825, 255
  %10829 = tail call i32 @llvm.ctpop.i32(i32 %10828)
  %10830 = trunc i32 %10829 to i8
  %10831 = and i8 %10830, 1
  %10832 = xor i8 %10831, 1
  store i8 %10832, i8* %18, align 1
  %10833 = xor i32 %10825, %10824
  %10834 = lshr i32 %10833, 4
  %10835 = trunc i32 %10834 to i8
  %10836 = and i8 %10835, 1
  store i8 %10836, i8* %19, align 1
  %10837 = icmp eq i32 %10825, 0
  %10838 = zext i1 %10837 to i8
  store i8 %10838, i8* %20, align 1
  %10839 = lshr i32 %10825, 31
  %10840 = trunc i32 %10839 to i8
  store i8 %10840, i8* %21, align 1
  %10841 = lshr i32 %10824, 31
  %10842 = xor i32 %10839, %10841
  %10843 = add nuw nsw i32 %10842, %10841
  %10844 = icmp eq i32 %10843, 2
  %10845 = zext i1 %10844 to i8
  store i8 %10845, i8* %22, align 1
  %10846 = icmp ne i8 %10840, 0
  %10847 = xor i1 %10846, %10844
  %.v680 = select i1 %10847, i64 10, i64 145
  %10848 = add i64 %10819, %.v680
  %10849 = add i64 %10820, -44
  %10850 = add i64 %10848, 7
  store i64 %10850, i64* %3, align 8
  %10851 = inttoptr i64 %10849 to i32*
  store i32 0, i32* %10851, align 4
  %.pre635 = load i64, i64* %3, align 8
  br i1 %10847, label %block_.L_4852ab.preheader, label %block_.L_485332.preheader

block_.L_485332.preheader:                        ; preds = %block_.L_48529a
  br label %block_.L_485332

block_.L_4852ab.preheader:                        ; preds = %block_.L_48529a
  br label %block_.L_4852ab

block_.L_4852ab:                                  ; preds = %block_.L_4852ab.preheader, %block_4852b5
  %10852 = phi i64 [ %11024, %block_4852b5 ], [ %.pre635, %block_.L_4852ab.preheader ]
  %10853 = load i64, i64* %RBP.i, align 8
  %10854 = add i64 %10853, -44
  %10855 = add i64 %10852, 4
  store i64 %10855, i64* %3, align 8
  %10856 = inttoptr i64 %10854 to i32*
  %10857 = load i32, i32* %10856, align 4
  %10858 = add i32 %10857, -18
  %10859 = icmp ult i32 %10857, 18
  %10860 = zext i1 %10859 to i8
  store i8 %10860, i8* %17, align 1
  %10861 = and i32 %10858, 255
  %10862 = tail call i32 @llvm.ctpop.i32(i32 %10861)
  %10863 = trunc i32 %10862 to i8
  %10864 = and i8 %10863, 1
  %10865 = xor i8 %10864, 1
  store i8 %10865, i8* %18, align 1
  %10866 = xor i32 %10857, 16
  %10867 = xor i32 %10866, %10858
  %10868 = lshr i32 %10867, 4
  %10869 = trunc i32 %10868 to i8
  %10870 = and i8 %10869, 1
  store i8 %10870, i8* %19, align 1
  %10871 = icmp eq i32 %10858, 0
  %10872 = zext i1 %10871 to i8
  store i8 %10872, i8* %20, align 1
  %10873 = lshr i32 %10858, 31
  %10874 = trunc i32 %10873 to i8
  store i8 %10874, i8* %21, align 1
  %10875 = lshr i32 %10857, 31
  %10876 = xor i32 %10873, %10875
  %10877 = add nuw nsw i32 %10876, %10875
  %10878 = icmp eq i32 %10877, 2
  %10879 = zext i1 %10878 to i8
  store i8 %10879, i8* %22, align 1
  %10880 = icmp ne i8 %10874, 0
  %10881 = xor i1 %10880, %10878
  %.v684 = select i1 %10881, i64 10, i64 109
  %10882 = add i64 %10852, %.v684
  store i64 %10882, i64* %3, align 8
  br i1 %10881, label %block_4852b5, label %block_.L_485318

block_4852b5:                                     ; preds = %block_.L_4852ab
  store i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64* %RAX.i1659, align 8
  store i8 zext (i1 or (i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64)), i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 144)) to i8), i8* %17, align 1
  store i8 %1194, i8* %18, align 1
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144)), i64 4) to i8), i8 1), i8* %19, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 0) to i8), i8* %20, align 1
  store i8 trunc (i64 lshr (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 63) to i8), i8* %21, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 63), i64 lshr (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 63)), i64 lshr (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 63)), i64 2) to i8), i8* %22, align 1
  %10883 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10883, i64* %RCX.i1588, align 8
  %10884 = add i64 %10883, 14136
  %10885 = add i64 %10882, 31
  store i64 %10885, i64* %3, align 8
  %10886 = inttoptr i64 %10884 to i64*
  %10887 = load i64, i64* %10886, align 8
  store i64 %10887, i64* %RCX.i1588, align 8
  %10888 = add i64 %10853, -12
  %10889 = add i64 %10882, 34
  store i64 %10889, i64* %3, align 8
  %10890 = inttoptr i64 %10888 to i32*
  %10891 = load i32, i32* %10890, align 4
  %10892 = add i32 %10891, 8
  %10893 = zext i32 %10892 to i64
  store i64 %10893, i64* %RDX.i1943, align 8
  %10894 = icmp ugt i32 %10891, -9
  %10895 = zext i1 %10894 to i8
  store i8 %10895, i8* %17, align 1
  %10896 = and i32 %10892, 255
  %10897 = tail call i32 @llvm.ctpop.i32(i32 %10896)
  %10898 = trunc i32 %10897 to i8
  %10899 = and i8 %10898, 1
  %10900 = xor i8 %10899, 1
  store i8 %10900, i8* %18, align 1
  %10901 = xor i32 %10892, %10891
  %10902 = lshr i32 %10901, 4
  %10903 = trunc i32 %10902 to i8
  %10904 = and i8 %10903, 1
  store i8 %10904, i8* %19, align 1
  %10905 = icmp eq i32 %10892, 0
  %10906 = zext i1 %10905 to i8
  store i8 %10906, i8* %20, align 1
  %10907 = lshr i32 %10892, 31
  %10908 = trunc i32 %10907 to i8
  store i8 %10908, i8* %21, align 1
  %10909 = lshr i32 %10891, 31
  %10910 = xor i32 %10907, %10909
  %10911 = add nuw nsw i32 %10910, %10907
  %10912 = icmp eq i32 %10911, 2
  %10913 = zext i1 %10912 to i8
  store i8 %10913, i8* %22, align 1
  %10914 = sext i32 %10892 to i64
  store i64 %10914, i64* %RSI.i2015, align 8
  %10915 = shl nsw i64 %10914, 3
  %10916 = add i64 %10887, %10915
  %10917 = add i64 %10882, 44
  store i64 %10917, i64* %3, align 8
  %10918 = inttoptr i64 %10916 to i64*
  %10919 = load i64, i64* %10918, align 8
  store i64 %10919, i64* %RCX.i1588, align 8
  %10920 = add i64 %10853, -16
  %10921 = add i64 %10882, 48
  store i64 %10921, i64* %3, align 8
  %10922 = inttoptr i64 %10920 to i32*
  %10923 = load i32, i32* %10922, align 4
  %10924 = sext i32 %10923 to i64
  store i64 %10924, i64* %RSI.i2015, align 8
  %10925 = shl nsw i64 %10924, 3
  %10926 = add i64 %10925, %10919
  %10927 = add i64 %10882, 52
  store i64 %10927, i64* %3, align 8
  %10928 = inttoptr i64 %10926 to i64*
  %10929 = load i64, i64* %10928, align 8
  store i64 %10929, i64* %RCX.i1588, align 8
  %10930 = add i64 %10853, -48
  %10931 = add i64 %10882, 56
  store i64 %10931, i64* %3, align 8
  %10932 = inttoptr i64 %10930 to i32*
  %10933 = load i32, i32* %10932, align 4
  %10934 = sext i32 %10933 to i64
  store i64 %10934, i64* %RSI.i2015, align 8
  %10935 = shl nsw i64 %10934, 3
  %10936 = add i64 %10935, %10929
  %10937 = add i64 %10882, 60
  store i64 %10937, i64* %3, align 8
  %10938 = inttoptr i64 %10936 to i64*
  %10939 = load i64, i64* %10938, align 8
  store i64 %10939, i64* %RCX.i1588, align 8
  %10940 = load i64, i64* %RBP.i, align 8
  %10941 = add i64 %10940, -44
  %10942 = add i64 %10882, 64
  store i64 %10942, i64* %3, align 8
  %10943 = inttoptr i64 %10941 to i32*
  %10944 = load i32, i32* %10943, align 4
  %10945 = sext i32 %10944 to i64
  store i64 %10945, i64* %RSI.i2015, align 8
  %10946 = shl nsw i64 %10945, 2
  %10947 = add i64 %10946, %10939
  %10948 = add i64 %10882, 67
  store i64 %10948, i64* %3, align 8
  %10949 = inttoptr i64 %10947 to i32*
  %10950 = load i32, i32* %10949, align 4
  %10951 = zext i32 %10950 to i64
  store i64 %10951, i64* %RDX.i1943, align 8
  %10952 = add i64 %10940, -48
  %10953 = add i64 %10882, 71
  store i64 %10953, i64* %3, align 8
  %10954 = inttoptr i64 %10952 to i32*
  %10955 = load i32, i32* %10954, align 4
  %10956 = sext i32 %10955 to i64
  %10957 = mul nsw i64 %10956, 72
  store i64 %10957, i64* %RCX.i1588, align 8
  %10958 = lshr i64 %10957, 63
  %10959 = load i64, i64* %RAX.i1659, align 8
  %10960 = add i64 %10957, %10959
  store i64 %10960, i64* %RAX.i1659, align 8
  %10961 = icmp ult i64 %10960, %10959
  %10962 = icmp ult i64 %10960, %10957
  %10963 = or i1 %10961, %10962
  %10964 = zext i1 %10963 to i8
  store i8 %10964, i8* %17, align 1
  %10965 = trunc i64 %10960 to i32
  %10966 = and i32 %10965, 255
  %10967 = tail call i32 @llvm.ctpop.i32(i32 %10966)
  %10968 = trunc i32 %10967 to i8
  %10969 = and i8 %10968, 1
  %10970 = xor i8 %10969, 1
  store i8 %10970, i8* %18, align 1
  %10971 = xor i64 %10957, %10959
  %10972 = xor i64 %10971, %10960
  %10973 = lshr i64 %10972, 4
  %10974 = trunc i64 %10973 to i8
  %10975 = and i8 %10974, 1
  store i8 %10975, i8* %19, align 1
  %10976 = icmp eq i64 %10960, 0
  %10977 = zext i1 %10976 to i8
  store i8 %10977, i8* %20, align 1
  %10978 = lshr i64 %10960, 63
  %10979 = trunc i64 %10978 to i8
  store i8 %10979, i8* %21, align 1
  %10980 = lshr i64 %10959, 63
  %10981 = xor i64 %10978, %10980
  %10982 = xor i64 %10978, %10958
  %10983 = add nuw nsw i64 %10981, %10982
  %10984 = icmp eq i64 %10983, 2
  %10985 = zext i1 %10984 to i8
  store i8 %10985, i8* %22, align 1
  %10986 = add i64 %10882, 82
  store i64 %10986, i64* %3, align 8
  %10987 = load i32, i32* %10943, align 4
  %10988 = sext i32 %10987 to i64
  store i64 %10988, i64* %RCX.i1588, align 8
  %10989 = shl nsw i64 %10988, 2
  %10990 = add i64 %10989, %10960
  %10991 = add i64 %10882, 85
  store i64 %10991, i64* %3, align 8
  %10992 = inttoptr i64 %10990 to i32*
  store i32 %10950, i32* %10992, align 4
  %10993 = load i64, i64* %RBP.i, align 8
  %10994 = add i64 %10993, -44
  %10995 = load i64, i64* %3, align 8
  %10996 = add i64 %10995, 3
  store i64 %10996, i64* %3, align 8
  %10997 = inttoptr i64 %10994 to i32*
  %10998 = load i32, i32* %10997, align 4
  %10999 = add i32 %10998, 1
  %11000 = zext i32 %10999 to i64
  store i64 %11000, i64* %RAX.i1659, align 8
  %11001 = icmp eq i32 %10998, -1
  %11002 = icmp eq i32 %10999, 0
  %11003 = or i1 %11001, %11002
  %11004 = zext i1 %11003 to i8
  store i8 %11004, i8* %17, align 1
  %11005 = and i32 %10999, 255
  %11006 = tail call i32 @llvm.ctpop.i32(i32 %11005)
  %11007 = trunc i32 %11006 to i8
  %11008 = and i8 %11007, 1
  %11009 = xor i8 %11008, 1
  store i8 %11009, i8* %18, align 1
  %11010 = xor i32 %10999, %10998
  %11011 = lshr i32 %11010, 4
  %11012 = trunc i32 %11011 to i8
  %11013 = and i8 %11012, 1
  store i8 %11013, i8* %19, align 1
  %11014 = zext i1 %11002 to i8
  store i8 %11014, i8* %20, align 1
  %11015 = lshr i32 %10999, 31
  %11016 = trunc i32 %11015 to i8
  store i8 %11016, i8* %21, align 1
  %11017 = lshr i32 %10998, 31
  %11018 = xor i32 %11015, %11017
  %11019 = add nuw nsw i32 %11018, %11015
  %11020 = icmp eq i32 %11019, 2
  %11021 = zext i1 %11020 to i8
  store i8 %11021, i8* %22, align 1
  %11022 = add i64 %10995, 9
  store i64 %11022, i64* %3, align 8
  store i32 %10999, i32* %10997, align 4
  %11023 = load i64, i64* %3, align 8
  %11024 = add i64 %11023, -104
  store i64 %11024, i64* %3, align 8
  br label %block_.L_4852ab

block_.L_485318:                                  ; preds = %block_.L_4852ab
  %11025 = add i64 %10853, -48
  %11026 = add i64 %10882, 8
  store i64 %11026, i64* %3, align 8
  %11027 = inttoptr i64 %11025 to i32*
  %11028 = load i32, i32* %11027, align 4
  %11029 = add i32 %11028, 1
  %11030 = zext i32 %11029 to i64
  store i64 %11030, i64* %RAX.i1659, align 8
  %11031 = icmp eq i32 %11028, -1
  %11032 = icmp eq i32 %11029, 0
  %11033 = or i1 %11031, %11032
  %11034 = zext i1 %11033 to i8
  store i8 %11034, i8* %17, align 1
  %11035 = and i32 %11029, 255
  %11036 = tail call i32 @llvm.ctpop.i32(i32 %11035)
  %11037 = trunc i32 %11036 to i8
  %11038 = and i8 %11037, 1
  %11039 = xor i8 %11038, 1
  store i8 %11039, i8* %18, align 1
  %11040 = xor i32 %11029, %11028
  %11041 = lshr i32 %11040, 4
  %11042 = trunc i32 %11041 to i8
  %11043 = and i8 %11042, 1
  store i8 %11043, i8* %19, align 1
  %11044 = zext i1 %11032 to i8
  store i8 %11044, i8* %20, align 1
  %11045 = lshr i32 %11029, 31
  %11046 = trunc i32 %11045 to i8
  store i8 %11046, i8* %21, align 1
  %11047 = lshr i32 %11028, 31
  %11048 = xor i32 %11045, %11047
  %11049 = add nuw nsw i32 %11048, %11045
  %11050 = icmp eq i32 %11049, 2
  %11051 = zext i1 %11050 to i8
  store i8 %11051, i8* %22, align 1
  %11052 = add i64 %10882, 14
  store i64 %11052, i64* %3, align 8
  store i32 %11029, i32* %11027, align 4
  %11053 = load i64, i64* %3, align 8
  %11054 = add i64 %11053, -140
  store i64 %11054, i64* %3, align 8
  br label %block_.L_48529a

block_.L_485332:                                  ; preds = %block_.L_485332.preheader, %block_.L_4855e3
  %11055 = phi i64 [ %12534, %block_.L_4855e3 ], [ %.pre635, %block_.L_485332.preheader ]
  %MEMORY.61 = phi %struct.Memory* [ %12153, %block_.L_4855e3 ], [ %10383, %block_.L_485332.preheader ]
  %11056 = load i64, i64* %RBP.i, align 8
  %11057 = add i64 %11056, -44
  %11058 = add i64 %11055, 4
  store i64 %11058, i64* %3, align 8
  %11059 = inttoptr i64 %11057 to i32*
  %11060 = load i32, i32* %11059, align 4
  %11061 = add i32 %11060, -2
  %11062 = icmp ult i32 %11060, 2
  %11063 = zext i1 %11062 to i8
  store i8 %11063, i8* %17, align 1
  %11064 = and i32 %11061, 255
  %11065 = tail call i32 @llvm.ctpop.i32(i32 %11064)
  %11066 = trunc i32 %11065 to i8
  %11067 = and i8 %11066, 1
  %11068 = xor i8 %11067, 1
  store i8 %11068, i8* %18, align 1
  %11069 = xor i32 %11061, %11060
  %11070 = lshr i32 %11069, 4
  %11071 = trunc i32 %11070 to i8
  %11072 = and i8 %11071, 1
  store i8 %11072, i8* %19, align 1
  %11073 = icmp eq i32 %11061, 0
  %11074 = zext i1 %11073 to i8
  store i8 %11074, i8* %20, align 1
  %11075 = lshr i32 %11061, 31
  %11076 = trunc i32 %11075 to i8
  store i8 %11076, i8* %21, align 1
  %11077 = lshr i32 %11060, 31
  %11078 = xor i32 %11075, %11077
  %11079 = add nuw nsw i32 %11078, %11077
  %11080 = icmp eq i32 %11079, 2
  %11081 = zext i1 %11080 to i8
  store i8 %11081, i8* %22, align 1
  %11082 = icmp ne i8 %11076, 0
  %11083 = xor i1 %11082, %11080
  %.v747 = select i1 %11083, i64 10, i64 708
  %11084 = add i64 %11055, %.v747
  store i64 %11084, i64* %3, align 8
  br i1 %11083, label %block_48533c, label %block_.L_4855f6

block_48533c:                                     ; preds = %block_.L_485332
  store i64 2, i64* %RAX.i1659, align 8
  store i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64* %RCX.i1588, align 8
  store i64 ptrtoint (%G__0x6cd4f0_type* @G__0x6cd4f0 to i64), i64* %RDX.i1943, align 8
  store i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64* %RSI.i2015, align 8
  store i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64* %RDI.i6998, align 8
  %11085 = add i64 %11084, 49
  store i64 %11085, i64* %3, align 8
  %11086 = load i32, i32* %11059, align 4
  %11087 = sext i32 %11086 to i64
  %11088 = shl nsw i64 %11087, 6
  store i64 %11088, i64* %25, align 8
  %11089 = add i64 %11088, ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64)
  store i64 %11089, i64* %RDI.i6998, align 8
  %11090 = icmp ult i64 %11089, ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64)
  %11091 = icmp ult i64 %11089, %11088
  %11092 = or i1 %11090, %11091
  %11093 = zext i1 %11092 to i8
  store i8 %11093, i8* %17, align 1
  %11094 = trunc i64 %11089 to i32
  %11095 = and i32 %11094, 248
  %11096 = tail call i32 @llvm.ctpop.i32(i32 %11095)
  %11097 = trunc i32 %11096 to i8
  %11098 = and i8 %11097, 1
  %11099 = xor i8 %11098, 1
  store i8 %11099, i8* %18, align 1
  %11100 = xor i64 %11089, ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64)
  %11101 = lshr i64 %11100, 4
  %11102 = trunc i64 %11101 to i8
  %11103 = and i8 %11102, 1
  store i8 %11103, i8* %19, align 1
  %11104 = icmp eq i64 %11089, 0
  %11105 = zext i1 %11104 to i8
  store i8 %11105, i8* %20, align 1
  %11106 = lshr i64 %11089, 63
  %11107 = trunc i64 %11106 to i8
  store i8 %11107, i8* %21, align 1
  %11108 = lshr i64 %11087, 57
  %11109 = and i64 %11108, 1
  %11110 = xor i64 %11106, lshr (i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64 63)
  %11111 = xor i64 %11106, %11109
  %11112 = add nuw nsw i64 %11110, %11111
  %11113 = icmp eq i64 %11112, 2
  %11114 = zext i1 %11113 to i8
  store i8 %11114, i8* %22, align 1
  %11115 = add i64 %11056, -12
  %11116 = add i64 %11084, 60
  store i64 %11116, i64* %3, align 8
  %11117 = inttoptr i64 %11115 to i32*
  %11118 = load i32, i32* %11117, align 4
  %11119 = zext i32 %11118 to i64
  store i64 %11119, i64* %R9.i1633, align 8
  %11120 = add i64 %11056, -608
  %11121 = add i64 %11084, 66
  store i64 %11121, i64* %3, align 8
  %11122 = inttoptr i64 %11120 to i32*
  store i32 2, i32* %11122, align 4
  %11123 = load i32, i32* %R9D.i5956, align 4
  %11124 = zext i32 %11123 to i64
  %11125 = load i64, i64* %3, align 8
  store i64 %11124, i64* %RAX.i1659, align 8
  %11126 = load i64, i64* %RBP.i, align 8
  %11127 = add i64 %11126, -616
  %11128 = load i64, i64* %RDX.i1943, align 8
  %11129 = add i64 %11125, 10
  store i64 %11129, i64* %3, align 8
  %11130 = inttoptr i64 %11127 to i64*
  store i64 %11128, i64* %11130, align 8
  %11131 = load i64, i64* %3, align 8
  %11132 = load i32, i32* %EAX.i2033, align 8
  %11133 = sext i32 %11132 to i64
  %11134 = lshr i64 %11133, 32
  store i64 %11134, i64* %103, align 8
  %11135 = load i64, i64* %RBP.i, align 8
  %11136 = add i64 %11135, -608
  %11137 = add i64 %11131, 8
  store i64 %11137, i64* %3, align 8
  %11138 = inttoptr i64 %11136 to i32*
  %11139 = load i32, i32* %11138, align 4
  %11140 = zext i32 %11139 to i64
  store i64 %11140, i64* %R9.i1633, align 8
  %11141 = add i64 %11131, 11
  store i64 %11141, i64* %3, align 8
  %11142 = zext i32 %11132 to i64
  %11143 = sext i32 %11139 to i64
  %11144 = shl nuw i64 %11134, 32
  %11145 = or i64 %11144, %11142
  %11146 = sdiv i64 %11145, %11143
  %11147 = shl i64 %11146, 32
  %11148 = ashr exact i64 %11147, 32
  %11149 = icmp eq i64 %11146, %11148
  br i1 %11149, label %11152, label %11150

; <label>:11150:                                  ; preds = %block_48533c
  %11151 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11141, %struct.Memory* %MEMORY.61)
  %.pre596 = load i64, i64* %RDX.i1943, align 8
  %.pre597 = load i64, i64* %3, align 8
  %.pre598 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3612

; <label>:11152:                                  ; preds = %block_48533c
  %11153 = srem i64 %11145, %11143
  %11154 = and i64 %11146, 4294967295
  store i64 %11154, i64* %RAX.i1659, align 8
  %11155 = and i64 %11153, 4294967295
  store i64 %11155, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r9d.exit3612

routine_idivl__r9d.exit3612:                      ; preds = %11152, %11150
  %11156 = phi i64 [ %.pre598, %11150 ], [ %11135, %11152 ]
  %11157 = phi i64 [ %.pre597, %11150 ], [ %11141, %11152 ]
  %11158 = phi i64 [ %.pre596, %11150 ], [ %11155, %11152 ]
  %11159 = phi %struct.Memory* [ %11151, %11150 ], [ %MEMORY.61, %11152 ]
  %11160 = trunc i64 %11158 to i32
  %11161 = shl i32 %11160, 1
  %11162 = icmp slt i32 %11160, 0
  %11163 = icmp slt i32 %11161, 0
  %11164 = xor i1 %11162, %11163
  %11165 = zext i32 %11161 to i64
  store i64 %11165, i64* %RDX.i1943, align 8
  %.lobit191 = lshr i32 %11160, 31
  %11166 = trunc i32 %.lobit191 to i8
  store i8 %11166, i8* %17, align 1
  %11167 = and i32 %11161, 254
  %11168 = tail call i32 @llvm.ctpop.i32(i32 %11167)
  %11169 = trunc i32 %11168 to i8
  %11170 = and i8 %11169, 1
  %11171 = xor i8 %11170, 1
  store i8 %11171, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %11172 = icmp eq i32 %11161, 0
  %11173 = zext i1 %11172 to i8
  store i8 %11173, i8* %20, align 1
  %11174 = lshr i32 %11160, 30
  %11175 = trunc i32 %11174 to i8
  %11176 = and i8 %11175, 1
  store i8 %11176, i8* %21, align 1
  %11177 = zext i1 %11164 to i8
  store i8 %11177, i8* %22, align 1
  %11178 = add i64 %11156, -16
  %11179 = add i64 %11157, 6
  store i64 %11179, i64* %3, align 8
  %11180 = inttoptr i64 %11178 to i32*
  %11181 = load i32, i32* %11180, align 4
  %11182 = zext i32 %11181 to i64
  store i64 %11182, i64* %50, align 8
  store i64 %11182, i64* %RAX.i1659, align 8
  %11183 = add i64 %11156, -620
  %11184 = add i64 %11157, 15
  store i64 %11184, i64* %3, align 8
  %11185 = inttoptr i64 %11183 to i32*
  store i32 %11161, i32* %11185, align 4
  %11186 = load i64, i64* %3, align 8
  %11187 = load i32, i32* %EAX.i2033, align 8
  %11188 = sext i32 %11187 to i64
  %11189 = lshr i64 %11188, 32
  store i64 %11189, i64* %103, align 8
  %11190 = load i32, i32* %R9D.i5956, align 4
  %11191 = add i64 %11186, 4
  store i64 %11191, i64* %3, align 8
  %11192 = zext i32 %11187 to i64
  %11193 = sext i32 %11190 to i64
  %11194 = shl nuw i64 %11189, 32
  %11195 = or i64 %11194, %11192
  %11196 = sdiv i64 %11195, %11193
  %11197 = shl i64 %11196, 32
  %11198 = ashr exact i64 %11197, 32
  %11199 = icmp eq i64 %11196, %11198
  br i1 %11199, label %11202, label %11200

; <label>:11200:                                  ; preds = %routine_idivl__r9d.exit3612
  %11201 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11191, %struct.Memory* %11159)
  %.pre599 = load i64, i64* %3, align 8
  %.pre600 = load i32, i32* %108, align 4
  br label %routine_idivl__r9d.exit3594

; <label>:11202:                                  ; preds = %routine_idivl__r9d.exit3612
  %11203 = srem i64 %11195, %11193
  %11204 = and i64 %11196, 4294967295
  store i64 %11204, i64* %RAX.i1659, align 8
  %11205 = and i64 %11203, 4294967295
  store i64 %11205, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %11206 = trunc i64 %11203 to i32
  br label %routine_idivl__r9d.exit3594

routine_idivl__r9d.exit3594:                      ; preds = %11202, %11200
  %11207 = phi i32 [ %.pre600, %11200 ], [ %11206, %11202 ]
  %11208 = phi i64 [ %.pre599, %11200 ], [ %11191, %11202 ]
  %11209 = phi %struct.Memory* [ %11201, %11200 ], [ %11159, %11202 ]
  %11210 = load i64, i64* %RBP.i, align 8
  %11211 = add i64 %11210, -620
  %11212 = add i64 %11208, 7
  store i64 %11212, i64* %3, align 8
  %11213 = inttoptr i64 %11211 to i32*
  %11214 = load i32, i32* %11213, align 4
  %11215 = add i32 %11207, %11214
  %11216 = zext i32 %11215 to i64
  store i64 %11216, i64* %50, align 8
  %11217 = sext i32 %11215 to i64
  %11218 = shl nsw i64 %11217, 4
  store i64 %11218, i64* %25, align 8
  %11219 = load i64, i64* %RDI.i6998, align 8
  %11220 = add i64 %11218, %11219
  store i64 %11220, i64* %RDI.i6998, align 8
  %11221 = icmp ult i64 %11220, %11219
  %11222 = icmp ult i64 %11220, %11218
  %11223 = or i1 %11221, %11222
  %11224 = zext i1 %11223 to i8
  store i8 %11224, i8* %17, align 1
  %11225 = trunc i64 %11220 to i32
  %11226 = and i32 %11225, 255
  %11227 = tail call i32 @llvm.ctpop.i32(i32 %11226)
  %11228 = trunc i32 %11227 to i8
  %11229 = and i8 %11228, 1
  %11230 = xor i8 %11229, 1
  store i8 %11230, i8* %18, align 1
  %11231 = xor i64 %11218, %11219
  %11232 = xor i64 %11231, %11220
  %11233 = lshr i64 %11232, 4
  %11234 = trunc i64 %11233 to i8
  %11235 = and i8 %11234, 1
  store i8 %11235, i8* %19, align 1
  %11236 = icmp eq i64 %11220, 0
  %11237 = zext i1 %11236 to i8
  store i8 %11237, i8* %20, align 1
  %11238 = lshr i64 %11220, 63
  %11239 = trunc i64 %11238 to i8
  store i8 %11239, i8* %21, align 1
  %11240 = lshr i64 %11219, 63
  %11241 = lshr i64 %11217, 59
  %11242 = and i64 %11241, 1
  %11243 = xor i64 %11238, %11240
  %11244 = xor i64 %11238, %11242
  %11245 = add nuw nsw i64 %11243, %11244
  %11246 = icmp eq i64 %11245, 2
  %11247 = zext i1 %11246 to i8
  store i8 %11247, i8* %22, align 1
  %11248 = load i64, i64* %RBP.i, align 8
  %11249 = add i64 %11248, -12
  %11250 = add i64 %11208, 23
  store i64 %11250, i64* %3, align 8
  %11251 = inttoptr i64 %11249 to i32*
  %11252 = load i32, i32* %11251, align 4
  %11253 = zext i32 %11252 to i64
  store i64 %11253, i64* %RAX.i1659, align 8
  %11254 = sext i32 %11252 to i64
  %11255 = lshr i64 %11254, 32
  store i64 %11255, i64* %103, align 8
  %11256 = load i32, i32* %R9D.i5956, align 4
  %11257 = add i64 %11208, 29
  store i64 %11257, i64* %3, align 8
  %11258 = sext i32 %11256 to i64
  %11259 = shl nuw i64 %11255, 32
  %11260 = or i64 %11259, %11253
  %11261 = sdiv i64 %11260, %11258
  %11262 = shl i64 %11261, 32
  %11263 = ashr exact i64 %11262, 32
  %11264 = icmp eq i64 %11261, %11263
  br i1 %11264, label %11267, label %11265

; <label>:11265:                                  ; preds = %routine_idivl__r9d.exit3594
  %11266 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11257, %struct.Memory* %11209)
  %.pre601 = load i64, i64* %RAX.i1659, align 8
  %.pre602 = load i64, i64* %3, align 8
  %.pre603 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3565

; <label>:11267:                                  ; preds = %routine_idivl__r9d.exit3594
  %11268 = srem i64 %11260, %11258
  %11269 = and i64 %11261, 4294967295
  store i64 %11269, i64* %RAX.i1659, align 8
  %11270 = and i64 %11268, 4294967295
  store i64 %11270, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r9d.exit3565

routine_idivl__r9d.exit3565:                      ; preds = %11267, %11265
  %11271 = phi i64 [ %.pre603, %11265 ], [ %11248, %11267 ]
  %11272 = phi i64 [ %.pre602, %11265 ], [ %11257, %11267 ]
  %11273 = phi i64 [ %.pre601, %11265 ], [ %11269, %11267 ]
  %11274 = phi %struct.Memory* [ %11266, %11265 ], [ %11209, %11267 ]
  %11275 = trunc i64 %11273 to i32
  %11276 = shl i32 %11275, 1
  %11277 = icmp slt i32 %11275, 0
  %11278 = icmp slt i32 %11276, 0
  %11279 = xor i1 %11277, %11278
  %11280 = zext i32 %11276 to i64
  store i64 %11280, i64* %RAX.i1659, align 8
  %.lobit193 = lshr i32 %11275, 31
  %11281 = trunc i32 %.lobit193 to i8
  store i8 %11281, i8* %17, align 1
  %11282 = and i32 %11276, 254
  %11283 = tail call i32 @llvm.ctpop.i32(i32 %11282)
  %11284 = trunc i32 %11283 to i8
  %11285 = and i8 %11284, 1
  %11286 = xor i8 %11285, 1
  store i8 %11286, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %11287 = icmp eq i32 %11276, 0
  %11288 = zext i1 %11287 to i8
  store i8 %11288, i8* %20, align 1
  %11289 = lshr i32 %11275, 30
  %11290 = trunc i32 %11289 to i8
  %11291 = and i8 %11290, 1
  store i8 %11291, i8* %21, align 1
  %11292 = zext i1 %11279 to i8
  store i8 %11292, i8* %22, align 1
  %11293 = add i64 %11271, -16
  %11294 = add i64 %11272, 6
  store i64 %11294, i64* %3, align 8
  %11295 = inttoptr i64 %11293 to i32*
  %11296 = load i32, i32* %11295, align 4
  %11297 = zext i32 %11296 to i64
  store i64 %11297, i64* %50, align 8
  %11298 = add i64 %11271, -624
  %11299 = add i64 %11272, 12
  store i64 %11299, i64* %3, align 8
  %11300 = inttoptr i64 %11298 to i32*
  store i32 %11276, i32* %11300, align 4
  %11301 = load i32, i32* %R10D.i1715, align 4
  %11302 = zext i32 %11301 to i64
  %11303 = load i64, i64* %3, align 8
  store i64 %11302, i64* %RAX.i1659, align 8
  %11304 = sext i32 %11301 to i64
  %11305 = lshr i64 %11304, 32
  store i64 %11305, i64* %103, align 8
  %11306 = load i32, i32* %R9D.i5956, align 4
  %11307 = add i64 %11303, 7
  store i64 %11307, i64* %3, align 8
  %11308 = sext i32 %11306 to i64
  %11309 = shl nuw i64 %11305, 32
  %11310 = or i64 %11309, %11302
  %11311 = sdiv i64 %11310, %11308
  %11312 = shl i64 %11311, 32
  %11313 = ashr exact i64 %11312, 32
  %11314 = icmp eq i64 %11311, %11313
  br i1 %11314, label %11317, label %11315

; <label>:11315:                                  ; preds = %routine_idivl__r9d.exit3565
  %11316 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11307, %struct.Memory* %11274)
  %.pre604 = load i64, i64* %3, align 8
  %.pre605 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__r9d.exit3549

; <label>:11317:                                  ; preds = %routine_idivl__r9d.exit3565
  %11318 = srem i64 %11310, %11308
  %11319 = and i64 %11311, 4294967295
  store i64 %11319, i64* %RAX.i1659, align 8
  %11320 = and i64 %11318, 4294967295
  store i64 %11320, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %11321 = trunc i64 %11311 to i32
  br label %routine_idivl__r9d.exit3549

routine_idivl__r9d.exit3549:                      ; preds = %11317, %11315
  %11322 = phi i32 [ %.pre605, %11315 ], [ %11321, %11317 ]
  %11323 = phi i64 [ %.pre604, %11315 ], [ %11307, %11317 ]
  %11324 = phi %struct.Memory* [ %11316, %11315 ], [ %11274, %11317 ]
  %11325 = load i64, i64* %RBP.i, align 8
  %11326 = add i64 %11325, -624
  %11327 = add i64 %11323, 7
  store i64 %11327, i64* %3, align 8
  %11328 = inttoptr i64 %11326 to i32*
  %11329 = load i32, i32* %11328, align 4
  %11330 = add i32 %11322, %11329
  %11331 = zext i32 %11330 to i64
  store i64 %11331, i64* %50, align 8
  %11332 = icmp ult i32 %11330, %11329
  %11333 = icmp ult i32 %11330, %11322
  %11334 = or i1 %11332, %11333
  %11335 = zext i1 %11334 to i8
  store i8 %11335, i8* %17, align 1
  %11336 = and i32 %11330, 255
  %11337 = tail call i32 @llvm.ctpop.i32(i32 %11336)
  %11338 = trunc i32 %11337 to i8
  %11339 = and i8 %11338, 1
  %11340 = xor i8 %11339, 1
  store i8 %11340, i8* %18, align 1
  %11341 = xor i32 %11322, %11329
  %11342 = xor i32 %11341, %11330
  %11343 = lshr i32 %11342, 4
  %11344 = trunc i32 %11343 to i8
  %11345 = and i8 %11344, 1
  store i8 %11345, i8* %19, align 1
  %11346 = icmp eq i32 %11330, 0
  %11347 = zext i1 %11346 to i8
  store i8 %11347, i8* %20, align 1
  %11348 = lshr i32 %11330, 31
  %11349 = trunc i32 %11348 to i8
  store i8 %11349, i8* %21, align 1
  %11350 = lshr i32 %11329, 31
  %11351 = lshr i32 %11322, 31
  %11352 = xor i32 %11348, %11350
  %11353 = xor i32 %11348, %11351
  %11354 = add nuw nsw i32 %11352, %11353
  %11355 = icmp eq i32 %11354, 2
  %11356 = zext i1 %11355 to i8
  store i8 %11356, i8* %22, align 1
  %11357 = sext i32 %11330 to i64
  store i64 %11357, i64* %25, align 8
  %11358 = load i64, i64* %RDI.i6998, align 8
  %11359 = shl nsw i64 %11357, 2
  %11360 = add i64 %11358, %11359
  %11361 = add i64 %11323, 17
  store i64 %11361, i64* %3, align 8
  %11362 = inttoptr i64 %11360 to i32*
  %11363 = load i32, i32* %11362, align 4
  %11364 = zext i32 %11363 to i64
  store i64 %11364, i64* %RAX.i1659, align 8
  %11365 = add i64 %11325, -44
  %11366 = add i64 %11323, 21
  store i64 %11366, i64* %3, align 8
  %11367 = inttoptr i64 %11365 to i32*
  %11368 = load i32, i32* %11367, align 4
  %11369 = sext i32 %11368 to i64
  %11370 = shl nsw i64 %11369, 6
  store i64 %11370, i64* %RDI.i6998, align 8
  %11371 = load i64, i64* %RSI.i2015, align 8
  %11372 = add i64 %11370, %11371
  store i64 %11372, i64* %RSI.i2015, align 8
  %11373 = icmp ult i64 %11372, %11371
  %11374 = icmp ult i64 %11372, %11370
  %11375 = or i1 %11373, %11374
  %11376 = zext i1 %11375 to i8
  store i8 %11376, i8* %17, align 1
  %11377 = trunc i64 %11372 to i32
  %11378 = and i32 %11377, 255
  %11379 = tail call i32 @llvm.ctpop.i32(i32 %11378)
  %11380 = trunc i32 %11379 to i8
  %11381 = and i8 %11380, 1
  %11382 = xor i8 %11381, 1
  store i8 %11382, i8* %18, align 1
  %11383 = xor i64 %11371, %11372
  %11384 = lshr i64 %11383, 4
  %11385 = trunc i64 %11384 to i8
  %11386 = and i8 %11385, 1
  store i8 %11386, i8* %19, align 1
  %11387 = icmp eq i64 %11372, 0
  %11388 = zext i1 %11387 to i8
  store i8 %11388, i8* %20, align 1
  %11389 = lshr i64 %11372, 63
  %11390 = trunc i64 %11389 to i8
  store i8 %11390, i8* %21, align 1
  %11391 = lshr i64 %11371, 63
  %11392 = lshr i64 %11369, 57
  %11393 = and i64 %11392, 1
  %11394 = xor i64 %11389, %11391
  %11395 = xor i64 %11389, %11393
  %11396 = add nuw nsw i64 %11394, %11395
  %11397 = icmp eq i64 %11396, 2
  %11398 = zext i1 %11397 to i8
  store i8 %11398, i8* %22, align 1
  %11399 = load i64, i64* %RBP.i, align 8
  %11400 = add i64 %11399, -12
  %11401 = add i64 %11323, 32
  store i64 %11401, i64* %3, align 8
  %11402 = inttoptr i64 %11400 to i32*
  %11403 = load i32, i32* %11402, align 4
  %11404 = zext i32 %11403 to i64
  store i64 %11404, i64* %50, align 8
  %11405 = add i64 %11399, -628
  %11406 = add i64 %11323, 38
  store i64 %11406, i64* %3, align 8
  %11407 = inttoptr i64 %11405 to i32*
  store i32 %11363, i32* %11407, align 4
  %11408 = load i32, i32* %R10D.i1715, align 4
  %11409 = zext i32 %11408 to i64
  %11410 = load i64, i64* %3, align 8
  store i64 %11409, i64* %RAX.i1659, align 8
  %11411 = sext i32 %11408 to i64
  %11412 = lshr i64 %11411, 32
  store i64 %11412, i64* %103, align 8
  %11413 = load i32, i32* %R9D.i5956, align 4
  %11414 = add i64 %11410, 7
  store i64 %11414, i64* %3, align 8
  %11415 = sext i32 %11413 to i64
  %11416 = shl nuw i64 %11412, 32
  %11417 = or i64 %11416, %11409
  %11418 = sdiv i64 %11417, %11415
  %11419 = shl i64 %11418, 32
  %11420 = ashr exact i64 %11419, 32
  %11421 = icmp eq i64 %11418, %11420
  br i1 %11421, label %11424, label %11422

; <label>:11422:                                  ; preds = %routine_idivl__r9d.exit3549
  %11423 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11414, %struct.Memory* %11324)
  %.pre606 = load i64, i64* %RDX.i1943, align 8
  %.pre607 = load i64, i64* %3, align 8
  br label %routine_idivl__r9d.exit3512

; <label>:11424:                                  ; preds = %routine_idivl__r9d.exit3549
  %11425 = srem i64 %11417, %11415
  %11426 = and i64 %11418, 4294967295
  store i64 %11426, i64* %RAX.i1659, align 8
  %11427 = and i64 %11425, 4294967295
  store i64 %11427, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r9d.exit3512

routine_idivl__r9d.exit3512:                      ; preds = %11424, %11422
  %11428 = phi i64 [ %.pre607, %11422 ], [ %11414, %11424 ]
  %11429 = phi i64 [ %.pre606, %11422 ], [ %11427, %11424 ]
  %11430 = phi %struct.Memory* [ %11423, %11422 ], [ %11324, %11424 ]
  %11431 = trunc i64 %11429 to i32
  %11432 = shl i32 %11431, 1
  %11433 = icmp slt i32 %11431, 0
  %11434 = icmp slt i32 %11432, 0
  %11435 = xor i1 %11433, %11434
  %11436 = zext i32 %11432 to i64
  store i64 %11436, i64* %RDX.i1943, align 8
  %.lobit195 = lshr i32 %11431, 31
  %11437 = trunc i32 %.lobit195 to i8
  store i8 %11437, i8* %17, align 1
  %11438 = and i32 %11432, 254
  %11439 = tail call i32 @llvm.ctpop.i32(i32 %11438)
  %11440 = trunc i32 %11439 to i8
  %11441 = and i8 %11440, 1
  %11442 = xor i8 %11441, 1
  store i8 %11442, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %11443 = icmp eq i32 %11432, 0
  %11444 = zext i1 %11443 to i8
  store i8 %11444, i8* %20, align 1
  %11445 = lshr i32 %11431, 30
  %11446 = trunc i32 %11445 to i8
  %11447 = and i8 %11446, 1
  store i8 %11447, i8* %21, align 1
  %11448 = zext i1 %11435 to i8
  store i8 %11448, i8* %22, align 1
  %11449 = load i64, i64* %RBP.i, align 8
  %11450 = add i64 %11449, -16
  %11451 = add i64 %11428, 6
  store i64 %11451, i64* %3, align 8
  %11452 = inttoptr i64 %11450 to i32*
  %11453 = load i32, i32* %11452, align 4
  %11454 = zext i32 %11453 to i64
  store i64 %11454, i64* %50, align 8
  store i64 %11454, i64* %RAX.i1659, align 8
  %11455 = add i64 %11449, -632
  %11456 = add i64 %11428, 15
  store i64 %11456, i64* %3, align 8
  %11457 = inttoptr i64 %11455 to i32*
  store i32 %11432, i32* %11457, align 4
  %11458 = load i64, i64* %3, align 8
  %11459 = load i32, i32* %EAX.i2033, align 8
  %11460 = sext i32 %11459 to i64
  %11461 = lshr i64 %11460, 32
  store i64 %11461, i64* %103, align 8
  %11462 = load i32, i32* %R9D.i5956, align 4
  %11463 = add i64 %11458, 4
  store i64 %11463, i64* %3, align 8
  %11464 = zext i32 %11459 to i64
  %11465 = sext i32 %11462 to i64
  %11466 = shl nuw i64 %11461, 32
  %11467 = or i64 %11466, %11464
  %11468 = sdiv i64 %11467, %11465
  %11469 = shl i64 %11468, 32
  %11470 = ashr exact i64 %11469, 32
  %11471 = icmp eq i64 %11468, %11470
  br i1 %11471, label %11474, label %11472

; <label>:11472:                                  ; preds = %routine_idivl__r9d.exit3512
  %11473 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11463, %struct.Memory* %11430)
  %.pre608 = load i64, i64* %3, align 8
  %.pre609 = load i32, i32* %108, align 4
  br label %routine_idivl__r9d.exit3494

; <label>:11474:                                  ; preds = %routine_idivl__r9d.exit3512
  %11475 = srem i64 %11467, %11465
  %11476 = and i64 %11468, 4294967295
  store i64 %11476, i64* %RAX.i1659, align 8
  %11477 = and i64 %11475, 4294967295
  store i64 %11477, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %11478 = trunc i64 %11475 to i32
  br label %routine_idivl__r9d.exit3494

routine_idivl__r9d.exit3494:                      ; preds = %11474, %11472
  %11479 = phi i32 [ %.pre609, %11472 ], [ %11478, %11474 ]
  %11480 = phi i64 [ %.pre608, %11472 ], [ %11463, %11474 ]
  %11481 = phi %struct.Memory* [ %11473, %11472 ], [ %11430, %11474 ]
  %11482 = load i64, i64* %RBP.i, align 8
  %11483 = add i64 %11482, -632
  %11484 = add i64 %11480, 7
  store i64 %11484, i64* %3, align 8
  %11485 = inttoptr i64 %11483 to i32*
  %11486 = load i32, i32* %11485, align 4
  %11487 = add i32 %11479, %11486
  %11488 = zext i32 %11487 to i64
  store i64 %11488, i64* %50, align 8
  %11489 = sext i32 %11487 to i64
  %11490 = shl nsw i64 %11489, 4
  store i64 %11490, i64* %RDI.i6998, align 8
  %11491 = load i64, i64* %RSI.i2015, align 8
  %11492 = add i64 %11490, %11491
  store i64 %11492, i64* %RSI.i2015, align 8
  %11493 = icmp ult i64 %11492, %11491
  %11494 = icmp ult i64 %11492, %11490
  %11495 = or i1 %11493, %11494
  %11496 = zext i1 %11495 to i8
  store i8 %11496, i8* %17, align 1
  %11497 = trunc i64 %11492 to i32
  %11498 = and i32 %11497, 255
  %11499 = tail call i32 @llvm.ctpop.i32(i32 %11498)
  %11500 = trunc i32 %11499 to i8
  %11501 = and i8 %11500, 1
  %11502 = xor i8 %11501, 1
  store i8 %11502, i8* %18, align 1
  %11503 = xor i64 %11490, %11491
  %11504 = xor i64 %11503, %11492
  %11505 = lshr i64 %11504, 4
  %11506 = trunc i64 %11505 to i8
  %11507 = and i8 %11506, 1
  store i8 %11507, i8* %19, align 1
  %11508 = icmp eq i64 %11492, 0
  %11509 = zext i1 %11508 to i8
  store i8 %11509, i8* %20, align 1
  %11510 = lshr i64 %11492, 63
  %11511 = trunc i64 %11510 to i8
  store i8 %11511, i8* %21, align 1
  %11512 = lshr i64 %11491, 63
  %11513 = lshr i64 %11489, 59
  %11514 = and i64 %11513, 1
  %11515 = xor i64 %11510, %11512
  %11516 = xor i64 %11510, %11514
  %11517 = add nuw nsw i64 %11515, %11516
  %11518 = icmp eq i64 %11517, 2
  %11519 = zext i1 %11518 to i8
  store i8 %11519, i8* %22, align 1
  %11520 = load i64, i64* %RBP.i, align 8
  %11521 = add i64 %11520, -12
  %11522 = add i64 %11480, 23
  store i64 %11522, i64* %3, align 8
  %11523 = inttoptr i64 %11521 to i32*
  %11524 = load i32, i32* %11523, align 4
  %11525 = zext i32 %11524 to i64
  store i64 %11525, i64* %RAX.i1659, align 8
  %11526 = sext i32 %11524 to i64
  %11527 = lshr i64 %11526, 32
  store i64 %11527, i64* %103, align 8
  %11528 = load i32, i32* %R9D.i5956, align 4
  %11529 = add i64 %11480, 29
  store i64 %11529, i64* %3, align 8
  %11530 = sext i32 %11528 to i64
  %11531 = shl nuw i64 %11527, 32
  %11532 = or i64 %11531, %11525
  %11533 = sdiv i64 %11532, %11530
  %11534 = shl i64 %11533, 32
  %11535 = ashr exact i64 %11534, 32
  %11536 = icmp eq i64 %11533, %11535
  br i1 %11536, label %11539, label %11537

; <label>:11537:                                  ; preds = %routine_idivl__r9d.exit3494
  %11538 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11529, %struct.Memory* %11481)
  %.pre610 = load i64, i64* %RAX.i1659, align 8
  %.pre611 = load i64, i64* %3, align 8
  %.pre612 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3467

; <label>:11539:                                  ; preds = %routine_idivl__r9d.exit3494
  %11540 = srem i64 %11532, %11530
  %11541 = and i64 %11533, 4294967295
  store i64 %11541, i64* %RAX.i1659, align 8
  %11542 = and i64 %11540, 4294967295
  store i64 %11542, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r9d.exit3467

routine_idivl__r9d.exit3467:                      ; preds = %11539, %11537
  %11543 = phi i64 [ %.pre612, %11537 ], [ %11520, %11539 ]
  %11544 = phi i64 [ %.pre611, %11537 ], [ %11529, %11539 ]
  %11545 = phi i64 [ %.pre610, %11537 ], [ %11541, %11539 ]
  %11546 = phi %struct.Memory* [ %11538, %11537 ], [ %11481, %11539 ]
  %11547 = trunc i64 %11545 to i32
  %11548 = shl i32 %11547, 1
  %11549 = icmp slt i32 %11547, 0
  %11550 = icmp slt i32 %11548, 0
  %11551 = xor i1 %11549, %11550
  %11552 = zext i32 %11548 to i64
  store i64 %11552, i64* %RAX.i1659, align 8
  %.lobit197 = lshr i32 %11547, 31
  %11553 = trunc i32 %.lobit197 to i8
  store i8 %11553, i8* %17, align 1
  %11554 = and i32 %11548, 254
  %11555 = tail call i32 @llvm.ctpop.i32(i32 %11554)
  %11556 = trunc i32 %11555 to i8
  %11557 = and i8 %11556, 1
  %11558 = xor i8 %11557, 1
  store i8 %11558, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %11559 = icmp eq i32 %11548, 0
  %11560 = zext i1 %11559 to i8
  store i8 %11560, i8* %20, align 1
  %11561 = lshr i32 %11547, 30
  %11562 = trunc i32 %11561 to i8
  %11563 = and i8 %11562, 1
  store i8 %11563, i8* %21, align 1
  %11564 = zext i1 %11551 to i8
  store i8 %11564, i8* %22, align 1
  %11565 = add i64 %11543, -16
  %11566 = add i64 %11544, 6
  store i64 %11566, i64* %3, align 8
  %11567 = inttoptr i64 %11565 to i32*
  %11568 = load i32, i32* %11567, align 4
  %11569 = zext i32 %11568 to i64
  store i64 %11569, i64* %50, align 8
  %11570 = add i64 %11543, -636
  %11571 = add i64 %11544, 12
  store i64 %11571, i64* %3, align 8
  %11572 = inttoptr i64 %11570 to i32*
  store i32 %11548, i32* %11572, align 4
  %11573 = load i32, i32* %R10D.i1715, align 4
  %11574 = zext i32 %11573 to i64
  %11575 = load i64, i64* %3, align 8
  store i64 %11574, i64* %RAX.i1659, align 8
  %11576 = sext i32 %11573 to i64
  %11577 = lshr i64 %11576, 32
  store i64 %11577, i64* %103, align 8
  %11578 = load i32, i32* %R9D.i5956, align 4
  %11579 = add i64 %11575, 7
  store i64 %11579, i64* %3, align 8
  %11580 = sext i32 %11578 to i64
  %11581 = shl nuw i64 %11577, 32
  %11582 = or i64 %11581, %11574
  %11583 = sdiv i64 %11582, %11580
  %11584 = shl i64 %11583, 32
  %11585 = ashr exact i64 %11584, 32
  %11586 = icmp eq i64 %11583, %11585
  br i1 %11586, label %11589, label %11587

; <label>:11587:                                  ; preds = %routine_idivl__r9d.exit3467
  %11588 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11579, %struct.Memory* %11546)
  %.pre613 = load i64, i64* %3, align 8
  %.pre614 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__r9d.exit3447

; <label>:11589:                                  ; preds = %routine_idivl__r9d.exit3467
  %11590 = srem i64 %11582, %11580
  %11591 = and i64 %11583, 4294967295
  store i64 %11591, i64* %RAX.i1659, align 8
  %11592 = and i64 %11590, 4294967295
  store i64 %11592, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %11593 = trunc i64 %11583 to i32
  br label %routine_idivl__r9d.exit3447

routine_idivl__r9d.exit3447:                      ; preds = %11589, %11587
  %11594 = phi i32 [ %.pre614, %11587 ], [ %11593, %11589 ]
  %11595 = phi i64 [ %.pre613, %11587 ], [ %11579, %11589 ]
  %11596 = phi %struct.Memory* [ %11588, %11587 ], [ %11546, %11589 ]
  %11597 = load i64, i64* %RBP.i, align 8
  %11598 = add i64 %11597, -636
  %11599 = add i64 %11595, 7
  store i64 %11599, i64* %3, align 8
  %11600 = inttoptr i64 %11598 to i32*
  %11601 = load i32, i32* %11600, align 4
  %11602 = add i32 %11594, %11601
  %11603 = zext i32 %11602 to i64
  store i64 %11603, i64* %50, align 8
  %11604 = icmp ult i32 %11602, %11601
  %11605 = icmp ult i32 %11602, %11594
  %11606 = or i1 %11604, %11605
  %11607 = zext i1 %11606 to i8
  store i8 %11607, i8* %17, align 1
  %11608 = and i32 %11602, 255
  %11609 = tail call i32 @llvm.ctpop.i32(i32 %11608)
  %11610 = trunc i32 %11609 to i8
  %11611 = and i8 %11610, 1
  %11612 = xor i8 %11611, 1
  store i8 %11612, i8* %18, align 1
  %11613 = xor i32 %11594, %11601
  %11614 = xor i32 %11613, %11602
  %11615 = lshr i32 %11614, 4
  %11616 = trunc i32 %11615 to i8
  %11617 = and i8 %11616, 1
  store i8 %11617, i8* %19, align 1
  %11618 = icmp eq i32 %11602, 0
  %11619 = zext i1 %11618 to i8
  store i8 %11619, i8* %20, align 1
  %11620 = lshr i32 %11602, 31
  %11621 = trunc i32 %11620 to i8
  store i8 %11621, i8* %21, align 1
  %11622 = lshr i32 %11601, 31
  %11623 = lshr i32 %11594, 31
  %11624 = xor i32 %11620, %11622
  %11625 = xor i32 %11620, %11623
  %11626 = add nuw nsw i32 %11624, %11625
  %11627 = icmp eq i32 %11626, 2
  %11628 = zext i1 %11627 to i8
  store i8 %11628, i8* %22, align 1
  %11629 = sext i32 %11602 to i64
  store i64 %11629, i64* %RDI.i6998, align 8
  %11630 = add i64 %11597, -628
  %11631 = add i64 %11595, 19
  store i64 %11631, i64* %3, align 8
  %11632 = inttoptr i64 %11630 to i32*
  %11633 = load i32, i32* %11632, align 4
  %11634 = zext i32 %11633 to i64
  store i64 %11634, i64* %RAX.i1659, align 8
  %11635 = load i64, i64* %RSI.i2015, align 8
  %11636 = shl nsw i64 %11629, 2
  %11637 = add i64 %11636, %11635
  %11638 = add i64 %11595, 22
  store i64 %11638, i64* %3, align 8
  %11639 = inttoptr i64 %11637 to i32*
  store i32 %11633, i32* %11639, align 4
  %11640 = load i64, i64* %RBP.i, align 8
  %11641 = add i64 %11640, -44
  %11642 = load i64, i64* %3, align 8
  %11643 = add i64 %11642, 4
  store i64 %11643, i64* %3, align 8
  %11644 = inttoptr i64 %11641 to i32*
  %11645 = load i32, i32* %11644, align 4
  %11646 = sext i32 %11645 to i64
  %11647 = shl nsw i64 %11646, 6
  store i64 %11647, i64* %RSI.i2015, align 8
  %.lobit198 = lshr i32 %11645, 31
  %11648 = trunc i32 %.lobit198 to i8
  store i8 %11648, i8* %17, align 1
  %11649 = trunc i64 %11647 to i32
  %11650 = and i32 %11649, 192
  %11651 = tail call i32 @llvm.ctpop.i32(i32 %11650)
  %11652 = trunc i32 %11651 to i8
  %11653 = and i8 %11652, 1
  %11654 = xor i8 %11653, 1
  store i8 %11654, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %11655 = icmp eq i32 %11645, 0
  %11656 = zext i1 %11655 to i8
  store i8 %11656, i8* %20, align 1
  %11657 = lshr i64 %11646, 57
  %11658 = trunc i64 %11657 to i8
  %11659 = and i8 %11658, 1
  store i8 %11659, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %11660 = add i64 %11640, -616
  %11661 = add i64 %11642, 15
  store i64 %11661, i64* %3, align 8
  %11662 = inttoptr i64 %11660 to i64*
  %11663 = load i64, i64* %11662, align 8
  %11664 = add i64 %11647, %11663
  store i64 %11664, i64* %RDI.i6998, align 8
  %11665 = icmp ult i64 %11664, %11663
  %11666 = icmp ult i64 %11664, %11647
  %11667 = or i1 %11665, %11666
  %11668 = zext i1 %11667 to i8
  store i8 %11668, i8* %17, align 1
  %11669 = trunc i64 %11664 to i32
  %11670 = and i32 %11669, 255
  %11671 = tail call i32 @llvm.ctpop.i32(i32 %11670)
  %11672 = trunc i32 %11671 to i8
  %11673 = and i8 %11672, 1
  %11674 = xor i8 %11673, 1
  store i8 %11674, i8* %18, align 1
  %11675 = xor i64 %11663, %11664
  %11676 = lshr i64 %11675, 4
  %11677 = trunc i64 %11676 to i8
  %11678 = and i8 %11677, 1
  store i8 %11678, i8* %19, align 1
  %11679 = icmp eq i64 %11664, 0
  %11680 = zext i1 %11679 to i8
  store i8 %11680, i8* %20, align 1
  %11681 = lshr i64 %11664, 63
  %11682 = trunc i64 %11681 to i8
  store i8 %11682, i8* %21, align 1
  %11683 = lshr i64 %11663, 63
  %11684 = lshr i64 %11646, 57
  %11685 = and i64 %11684, 1
  %11686 = xor i64 %11681, %11683
  %11687 = xor i64 %11681, %11685
  %11688 = add nuw nsw i64 %11686, %11687
  %11689 = icmp eq i64 %11688, 2
  %11690 = zext i1 %11689 to i8
  store i8 %11690, i8* %22, align 1
  %11691 = add i64 %11640, -12
  %11692 = add i64 %11642, 21
  store i64 %11692, i64* %3, align 8
  %11693 = inttoptr i64 %11691 to i32*
  %11694 = load i32, i32* %11693, align 4
  %11695 = zext i32 %11694 to i64
  store i64 %11695, i64* %RAX.i1659, align 8
  %11696 = sext i32 %11694 to i64
  %11697 = lshr i64 %11696, 32
  store i64 %11697, i64* %103, align 8
  %11698 = load i32, i32* %R9D.i5956, align 4
  %11699 = add i64 %11642, 25
  store i64 %11699, i64* %3, align 8
  %11700 = sext i32 %11698 to i64
  %11701 = shl nuw i64 %11697, 32
  %11702 = or i64 %11701, %11695
  %11703 = sdiv i64 %11702, %11700
  %11704 = shl i64 %11703, 32
  %11705 = ashr exact i64 %11704, 32
  %11706 = icmp eq i64 %11703, %11705
  br i1 %11706, label %11709, label %11707

; <label>:11707:                                  ; preds = %routine_idivl__r9d.exit3447
  %11708 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11699, %struct.Memory* %11596)
  %.pre615 = load i64, i64* %RDX.i1943, align 8
  %.pre616 = load i64, i64* %3, align 8
  %.pre657 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3412

; <label>:11709:                                  ; preds = %routine_idivl__r9d.exit3447
  %11710 = srem i64 %11702, %11700
  %11711 = and i64 %11703, 4294967295
  store i64 %11711, i64* %RAX.i1659, align 8
  %11712 = and i64 %11710, 4294967295
  store i64 %11712, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r9d.exit3412

routine_idivl__r9d.exit3412:                      ; preds = %11709, %11707
  %11713 = phi i64 [ %.pre657, %11707 ], [ %11640, %11709 ]
  %11714 = phi i64 [ %.pre616, %11707 ], [ %11699, %11709 ]
  %11715 = phi i64 [ %.pre615, %11707 ], [ %11712, %11709 ]
  %11716 = phi %struct.Memory* [ %11708, %11707 ], [ %11596, %11709 ]
  %11717 = trunc i64 %11715 to i32
  %11718 = shl i32 %11717, 1
  %11719 = icmp slt i32 %11717, 0
  %11720 = icmp slt i32 %11718, 0
  %11721 = xor i1 %11719, %11720
  %11722 = zext i32 %11718 to i64
  store i64 %11722, i64* %RDX.i1943, align 8
  %.lobit199 = lshr i32 %11717, 31
  %11723 = trunc i32 %.lobit199 to i8
  store i8 %11723, i8* %17, align 1
  %11724 = and i32 %11718, 254
  %11725 = tail call i32 @llvm.ctpop.i32(i32 %11724)
  %11726 = trunc i32 %11725 to i8
  %11727 = and i8 %11726, 1
  %11728 = xor i8 %11727, 1
  store i8 %11728, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %11729 = icmp eq i32 %11718, 0
  %11730 = zext i1 %11729 to i8
  store i8 %11730, i8* %20, align 1
  %11731 = lshr i32 %11717, 30
  %11732 = trunc i32 %11731 to i8
  %11733 = and i8 %11732, 1
  store i8 %11733, i8* %21, align 1
  %11734 = zext i1 %11721 to i8
  store i8 %11734, i8* %22, align 1
  %11735 = add i64 %11713, -16
  %11736 = add i64 %11714, 6
  store i64 %11736, i64* %3, align 8
  %11737 = inttoptr i64 %11735 to i32*
  %11738 = load i32, i32* %11737, align 4
  %11739 = zext i32 %11738 to i64
  store i64 %11739, i64* %50, align 8
  store i64 %11739, i64* %RAX.i1659, align 8
  %11740 = add i64 %11713, -640
  %11741 = add i64 %11714, 15
  store i64 %11741, i64* %3, align 8
  %11742 = inttoptr i64 %11740 to i32*
  store i32 %11718, i32* %11742, align 4
  %11743 = load i64, i64* %3, align 8
  %11744 = load i32, i32* %EAX.i2033, align 8
  %11745 = sext i32 %11744 to i64
  %11746 = lshr i64 %11745, 32
  store i64 %11746, i64* %103, align 8
  %11747 = load i32, i32* %R9D.i5956, align 4
  %11748 = add i64 %11743, 4
  store i64 %11748, i64* %3, align 8
  %11749 = zext i32 %11744 to i64
  %11750 = sext i32 %11747 to i64
  %11751 = shl nuw i64 %11746, 32
  %11752 = or i64 %11751, %11749
  %11753 = sdiv i64 %11752, %11750
  %11754 = shl i64 %11753, 32
  %11755 = ashr exact i64 %11754, 32
  %11756 = icmp eq i64 %11753, %11755
  br i1 %11756, label %11759, label %11757

; <label>:11757:                                  ; preds = %routine_idivl__r9d.exit3412
  %11758 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11748, %struct.Memory* %11716)
  %.pre617 = load i64, i64* %3, align 8
  %.pre618 = load i32, i32* %108, align 4
  br label %routine_idivl__r9d.exit3394

; <label>:11759:                                  ; preds = %routine_idivl__r9d.exit3412
  %11760 = srem i64 %11752, %11750
  %11761 = and i64 %11753, 4294967295
  store i64 %11761, i64* %RAX.i1659, align 8
  %11762 = and i64 %11760, 4294967295
  store i64 %11762, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %11763 = trunc i64 %11760 to i32
  br label %routine_idivl__r9d.exit3394

routine_idivl__r9d.exit3394:                      ; preds = %11759, %11757
  %11764 = phi i32 [ %.pre618, %11757 ], [ %11763, %11759 ]
  %11765 = phi i64 [ %.pre617, %11757 ], [ %11748, %11759 ]
  %11766 = phi %struct.Memory* [ %11758, %11757 ], [ %11716, %11759 ]
  %11767 = load i64, i64* %RBP.i, align 8
  %11768 = add i64 %11767, -640
  %11769 = add i64 %11765, 7
  store i64 %11769, i64* %3, align 8
  %11770 = inttoptr i64 %11768 to i32*
  %11771 = load i32, i32* %11770, align 4
  %11772 = add i32 %11764, %11771
  %11773 = zext i32 %11772 to i64
  store i64 %11773, i64* %50, align 8
  %11774 = sext i32 %11772 to i64
  %11775 = shl nsw i64 %11774, 4
  store i64 %11775, i64* %RSI.i2015, align 8
  %11776 = load i64, i64* %RDI.i6998, align 8
  %11777 = add i64 %11775, %11776
  store i64 %11777, i64* %RDI.i6998, align 8
  %11778 = icmp ult i64 %11777, %11776
  %11779 = icmp ult i64 %11777, %11775
  %11780 = or i1 %11778, %11779
  %11781 = zext i1 %11780 to i8
  store i8 %11781, i8* %17, align 1
  %11782 = trunc i64 %11777 to i32
  %11783 = and i32 %11782, 255
  %11784 = tail call i32 @llvm.ctpop.i32(i32 %11783)
  %11785 = trunc i32 %11784 to i8
  %11786 = and i8 %11785, 1
  %11787 = xor i8 %11786, 1
  store i8 %11787, i8* %18, align 1
  %11788 = xor i64 %11775, %11776
  %11789 = xor i64 %11788, %11777
  %11790 = lshr i64 %11789, 4
  %11791 = trunc i64 %11790 to i8
  %11792 = and i8 %11791, 1
  store i8 %11792, i8* %19, align 1
  %11793 = icmp eq i64 %11777, 0
  %11794 = zext i1 %11793 to i8
  store i8 %11794, i8* %20, align 1
  %11795 = lshr i64 %11777, 63
  %11796 = trunc i64 %11795 to i8
  store i8 %11796, i8* %21, align 1
  %11797 = lshr i64 %11776, 63
  %11798 = lshr i64 %11774, 59
  %11799 = and i64 %11798, 1
  %11800 = xor i64 %11795, %11797
  %11801 = xor i64 %11795, %11799
  %11802 = add nuw nsw i64 %11800, %11801
  %11803 = icmp eq i64 %11802, 2
  %11804 = zext i1 %11803 to i8
  store i8 %11804, i8* %22, align 1
  %11805 = load i64, i64* %RBP.i, align 8
  %11806 = add i64 %11805, -12
  %11807 = add i64 %11765, 23
  store i64 %11807, i64* %3, align 8
  %11808 = inttoptr i64 %11806 to i32*
  %11809 = load i32, i32* %11808, align 4
  %11810 = zext i32 %11809 to i64
  store i64 %11810, i64* %RAX.i1659, align 8
  %11811 = sext i32 %11809 to i64
  %11812 = lshr i64 %11811, 32
  store i64 %11812, i64* %103, align 8
  %11813 = load i32, i32* %R9D.i5956, align 4
  %11814 = add i64 %11765, 29
  store i64 %11814, i64* %3, align 8
  %11815 = sext i32 %11813 to i64
  %11816 = shl nuw i64 %11812, 32
  %11817 = or i64 %11816, %11810
  %11818 = sdiv i64 %11817, %11815
  %11819 = shl i64 %11818, 32
  %11820 = ashr exact i64 %11819, 32
  %11821 = icmp eq i64 %11818, %11820
  br i1 %11821, label %11824, label %11822

; <label>:11822:                                  ; preds = %routine_idivl__r9d.exit3394
  %11823 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11814, %struct.Memory* %11766)
  %.pre619 = load i64, i64* %RAX.i1659, align 8
  %.pre620 = load i64, i64* %3, align 8
  %.pre621 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3367

; <label>:11824:                                  ; preds = %routine_idivl__r9d.exit3394
  %11825 = srem i64 %11817, %11815
  %11826 = and i64 %11818, 4294967295
  store i64 %11826, i64* %RAX.i1659, align 8
  %11827 = and i64 %11825, 4294967295
  store i64 %11827, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r9d.exit3367

routine_idivl__r9d.exit3367:                      ; preds = %11824, %11822
  %11828 = phi i64 [ %.pre621, %11822 ], [ %11805, %11824 ]
  %11829 = phi i64 [ %.pre620, %11822 ], [ %11814, %11824 ]
  %11830 = phi i64 [ %.pre619, %11822 ], [ %11826, %11824 ]
  %11831 = phi %struct.Memory* [ %11823, %11822 ], [ %11766, %11824 ]
  %11832 = trunc i64 %11830 to i32
  %11833 = shl i32 %11832, 1
  %11834 = icmp slt i32 %11832, 0
  %11835 = icmp slt i32 %11833, 0
  %11836 = xor i1 %11834, %11835
  %11837 = zext i32 %11833 to i64
  store i64 %11837, i64* %RAX.i1659, align 8
  %.lobit201 = lshr i32 %11832, 31
  %11838 = trunc i32 %.lobit201 to i8
  store i8 %11838, i8* %17, align 1
  %11839 = and i32 %11833, 254
  %11840 = tail call i32 @llvm.ctpop.i32(i32 %11839)
  %11841 = trunc i32 %11840 to i8
  %11842 = and i8 %11841, 1
  %11843 = xor i8 %11842, 1
  store i8 %11843, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %11844 = icmp eq i32 %11833, 0
  %11845 = zext i1 %11844 to i8
  store i8 %11845, i8* %20, align 1
  %11846 = lshr i32 %11832, 30
  %11847 = trunc i32 %11846 to i8
  %11848 = and i8 %11847, 1
  store i8 %11848, i8* %21, align 1
  %11849 = zext i1 %11836 to i8
  store i8 %11849, i8* %22, align 1
  %11850 = add i64 %11828, -16
  %11851 = add i64 %11829, 6
  store i64 %11851, i64* %3, align 8
  %11852 = inttoptr i64 %11850 to i32*
  %11853 = load i32, i32* %11852, align 4
  %11854 = zext i32 %11853 to i64
  store i64 %11854, i64* %50, align 8
  %11855 = add i64 %11828, -644
  %11856 = add i64 %11829, 12
  store i64 %11856, i64* %3, align 8
  %11857 = inttoptr i64 %11855 to i32*
  store i32 %11833, i32* %11857, align 4
  %11858 = load i32, i32* %R10D.i1715, align 4
  %11859 = zext i32 %11858 to i64
  %11860 = load i64, i64* %3, align 8
  store i64 %11859, i64* %RAX.i1659, align 8
  %11861 = sext i32 %11858 to i64
  %11862 = lshr i64 %11861, 32
  store i64 %11862, i64* %103, align 8
  %11863 = load i32, i32* %R9D.i5956, align 4
  %11864 = add i64 %11860, 7
  store i64 %11864, i64* %3, align 8
  %11865 = sext i32 %11863 to i64
  %11866 = shl nuw i64 %11862, 32
  %11867 = or i64 %11866, %11859
  %11868 = sdiv i64 %11867, %11865
  %11869 = shl i64 %11868, 32
  %11870 = ashr exact i64 %11869, 32
  %11871 = icmp eq i64 %11868, %11870
  br i1 %11871, label %11874, label %11872

; <label>:11872:                                  ; preds = %routine_idivl__r9d.exit3367
  %11873 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11864, %struct.Memory* %11831)
  %.pre622 = load i64, i64* %3, align 8
  %.pre623 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__r9d.exit3349

; <label>:11874:                                  ; preds = %routine_idivl__r9d.exit3367
  %11875 = srem i64 %11867, %11865
  %11876 = and i64 %11868, 4294967295
  store i64 %11876, i64* %RAX.i1659, align 8
  %11877 = and i64 %11875, 4294967295
  store i64 %11877, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %11878 = trunc i64 %11868 to i32
  br label %routine_idivl__r9d.exit3349

routine_idivl__r9d.exit3349:                      ; preds = %11874, %11872
  %11879 = phi i32 [ %.pre623, %11872 ], [ %11878, %11874 ]
  %11880 = phi i64 [ %.pre622, %11872 ], [ %11864, %11874 ]
  %11881 = phi %struct.Memory* [ %11873, %11872 ], [ %11831, %11874 ]
  %11882 = load i64, i64* %RBP.i, align 8
  %11883 = add i64 %11882, -644
  %11884 = add i64 %11880, 7
  store i64 %11884, i64* %3, align 8
  %11885 = inttoptr i64 %11883 to i32*
  %11886 = load i32, i32* %11885, align 4
  %11887 = add i32 %11879, %11886
  %11888 = zext i32 %11887 to i64
  store i64 %11888, i64* %50, align 8
  %11889 = icmp ult i32 %11887, %11886
  %11890 = icmp ult i32 %11887, %11879
  %11891 = or i1 %11889, %11890
  %11892 = zext i1 %11891 to i8
  store i8 %11892, i8* %17, align 1
  %11893 = and i32 %11887, 255
  %11894 = tail call i32 @llvm.ctpop.i32(i32 %11893)
  %11895 = trunc i32 %11894 to i8
  %11896 = and i8 %11895, 1
  %11897 = xor i8 %11896, 1
  store i8 %11897, i8* %18, align 1
  %11898 = xor i32 %11879, %11886
  %11899 = xor i32 %11898, %11887
  %11900 = lshr i32 %11899, 4
  %11901 = trunc i32 %11900 to i8
  %11902 = and i8 %11901, 1
  store i8 %11902, i8* %19, align 1
  %11903 = icmp eq i32 %11887, 0
  %11904 = zext i1 %11903 to i8
  store i8 %11904, i8* %20, align 1
  %11905 = lshr i32 %11887, 31
  %11906 = trunc i32 %11905 to i8
  store i8 %11906, i8* %21, align 1
  %11907 = lshr i32 %11886, 31
  %11908 = lshr i32 %11879, 31
  %11909 = xor i32 %11905, %11907
  %11910 = xor i32 %11905, %11908
  %11911 = add nuw nsw i32 %11909, %11910
  %11912 = icmp eq i32 %11911, 2
  %11913 = zext i1 %11912 to i8
  store i8 %11913, i8* %22, align 1
  %11914 = sext i32 %11887 to i64
  store i64 %11914, i64* %RSI.i2015, align 8
  %11915 = load i64, i64* %RDI.i6998, align 8
  %11916 = shl nsw i64 %11914, 2
  %11917 = add i64 %11915, %11916
  %11918 = add i64 %11880, 16
  store i64 %11918, i64* %3, align 8
  %11919 = inttoptr i64 %11917 to i32*
  %11920 = load i32, i32* %11919, align 4
  %11921 = zext i32 %11920 to i64
  store i64 %11921, i64* %RAX.i1659, align 8
  %11922 = add i64 %11882, -44
  %11923 = add i64 %11880, 20
  store i64 %11923, i64* %3, align 8
  %11924 = inttoptr i64 %11922 to i32*
  %11925 = load i32, i32* %11924, align 4
  %11926 = sext i32 %11925 to i64
  %11927 = shl nsw i64 %11926, 6
  store i64 %11927, i64* %RSI.i2015, align 8
  %11928 = load i64, i64* %RCX.i1588, align 8
  %11929 = add i64 %11927, %11928
  store i64 %11929, i64* %RCX.i1588, align 8
  %11930 = icmp ult i64 %11929, %11928
  %11931 = icmp ult i64 %11929, %11927
  %11932 = or i1 %11930, %11931
  %11933 = zext i1 %11932 to i8
  store i8 %11933, i8* %17, align 1
  %11934 = trunc i64 %11929 to i32
  %11935 = and i32 %11934, 255
  %11936 = tail call i32 @llvm.ctpop.i32(i32 %11935)
  %11937 = trunc i32 %11936 to i8
  %11938 = and i8 %11937, 1
  %11939 = xor i8 %11938, 1
  store i8 %11939, i8* %18, align 1
  %11940 = xor i64 %11928, %11929
  %11941 = lshr i64 %11940, 4
  %11942 = trunc i64 %11941 to i8
  %11943 = and i8 %11942, 1
  store i8 %11943, i8* %19, align 1
  %11944 = icmp eq i64 %11929, 0
  %11945 = zext i1 %11944 to i8
  store i8 %11945, i8* %20, align 1
  %11946 = lshr i64 %11929, 63
  %11947 = trunc i64 %11946 to i8
  store i8 %11947, i8* %21, align 1
  %11948 = lshr i64 %11928, 63
  %11949 = lshr i64 %11926, 57
  %11950 = and i64 %11949, 1
  %11951 = xor i64 %11946, %11948
  %11952 = xor i64 %11946, %11950
  %11953 = add nuw nsw i64 %11951, %11952
  %11954 = icmp eq i64 %11953, 2
  %11955 = zext i1 %11954 to i8
  store i8 %11955, i8* %22, align 1
  %11956 = load i64, i64* %RBP.i, align 8
  %11957 = add i64 %11956, -12
  %11958 = add i64 %11880, 31
  store i64 %11958, i64* %3, align 8
  %11959 = inttoptr i64 %11957 to i32*
  %11960 = load i32, i32* %11959, align 4
  %11961 = zext i32 %11960 to i64
  store i64 %11961, i64* %50, align 8
  %11962 = add i64 %11956, -648
  %11963 = add i64 %11880, 37
  store i64 %11963, i64* %3, align 8
  %11964 = inttoptr i64 %11962 to i32*
  store i32 %11920, i32* %11964, align 4
  %11965 = load i32, i32* %R10D.i1715, align 4
  %11966 = zext i32 %11965 to i64
  %11967 = load i64, i64* %3, align 8
  store i64 %11966, i64* %RAX.i1659, align 8
  %11968 = sext i32 %11965 to i64
  %11969 = lshr i64 %11968, 32
  store i64 %11969, i64* %103, align 8
  %11970 = load i32, i32* %R9D.i5956, align 4
  %11971 = add i64 %11967, 7
  store i64 %11971, i64* %3, align 8
  %11972 = sext i32 %11970 to i64
  %11973 = shl nuw i64 %11969, 32
  %11974 = or i64 %11973, %11966
  %11975 = sdiv i64 %11974, %11972
  %11976 = shl i64 %11975, 32
  %11977 = ashr exact i64 %11976, 32
  %11978 = icmp eq i64 %11975, %11977
  br i1 %11978, label %11981, label %11979

; <label>:11979:                                  ; preds = %routine_idivl__r9d.exit3349
  %11980 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %11971, %struct.Memory* %11881)
  %.pre624 = load i64, i64* %RDX.i1943, align 8
  %.pre625 = load i64, i64* %3, align 8
  br label %routine_idivl__r9d.exit3312

; <label>:11981:                                  ; preds = %routine_idivl__r9d.exit3349
  %11982 = srem i64 %11974, %11972
  %11983 = and i64 %11975, 4294967295
  store i64 %11983, i64* %RAX.i1659, align 8
  %11984 = and i64 %11982, 4294967295
  store i64 %11984, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r9d.exit3312

routine_idivl__r9d.exit3312:                      ; preds = %11981, %11979
  %11985 = phi i64 [ %.pre625, %11979 ], [ %11971, %11981 ]
  %11986 = phi i64 [ %.pre624, %11979 ], [ %11984, %11981 ]
  %11987 = phi %struct.Memory* [ %11980, %11979 ], [ %11881, %11981 ]
  %11988 = trunc i64 %11986 to i32
  %11989 = shl i32 %11988, 1
  %11990 = icmp slt i32 %11988, 0
  %11991 = icmp slt i32 %11989, 0
  %11992 = xor i1 %11990, %11991
  %11993 = zext i32 %11989 to i64
  store i64 %11993, i64* %RDX.i1943, align 8
  %.lobit203 = lshr i32 %11988, 31
  %11994 = trunc i32 %.lobit203 to i8
  store i8 %11994, i8* %17, align 1
  %11995 = and i32 %11989, 254
  %11996 = tail call i32 @llvm.ctpop.i32(i32 %11995)
  %11997 = trunc i32 %11996 to i8
  %11998 = and i8 %11997, 1
  %11999 = xor i8 %11998, 1
  store i8 %11999, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %12000 = icmp eq i32 %11989, 0
  %12001 = zext i1 %12000 to i8
  store i8 %12001, i8* %20, align 1
  %12002 = lshr i32 %11988, 30
  %12003 = trunc i32 %12002 to i8
  %12004 = and i8 %12003, 1
  store i8 %12004, i8* %21, align 1
  %12005 = zext i1 %11992 to i8
  store i8 %12005, i8* %22, align 1
  %12006 = load i64, i64* %RBP.i, align 8
  %12007 = add i64 %12006, -16
  %12008 = add i64 %11985, 6
  store i64 %12008, i64* %3, align 8
  %12009 = inttoptr i64 %12007 to i32*
  %12010 = load i32, i32* %12009, align 4
  %12011 = zext i32 %12010 to i64
  store i64 %12011, i64* %50, align 8
  store i64 %12011, i64* %RAX.i1659, align 8
  %12012 = add i64 %12006, -652
  %12013 = add i64 %11985, 15
  store i64 %12013, i64* %3, align 8
  %12014 = inttoptr i64 %12012 to i32*
  store i32 %11989, i32* %12014, align 4
  %12015 = load i64, i64* %3, align 8
  %12016 = load i32, i32* %EAX.i2033, align 8
  %12017 = sext i32 %12016 to i64
  %12018 = lshr i64 %12017, 32
  store i64 %12018, i64* %103, align 8
  %12019 = load i32, i32* %R9D.i5956, align 4
  %12020 = add i64 %12015, 4
  store i64 %12020, i64* %3, align 8
  %12021 = zext i32 %12016 to i64
  %12022 = sext i32 %12019 to i64
  %12023 = shl nuw i64 %12018, 32
  %12024 = or i64 %12023, %12021
  %12025 = sdiv i64 %12024, %12022
  %12026 = shl i64 %12025, 32
  %12027 = ashr exact i64 %12026, 32
  %12028 = icmp eq i64 %12025, %12027
  br i1 %12028, label %12031, label %12029

; <label>:12029:                                  ; preds = %routine_idivl__r9d.exit3312
  %12030 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12020, %struct.Memory* %11987)
  %.pre626 = load i64, i64* %3, align 8
  %.pre627 = load i32, i32* %108, align 4
  br label %routine_idivl__r9d.exit3294

; <label>:12031:                                  ; preds = %routine_idivl__r9d.exit3312
  %12032 = srem i64 %12024, %12022
  %12033 = and i64 %12025, 4294967295
  store i64 %12033, i64* %RAX.i1659, align 8
  %12034 = and i64 %12032, 4294967295
  store i64 %12034, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %12035 = trunc i64 %12032 to i32
  br label %routine_idivl__r9d.exit3294

routine_idivl__r9d.exit3294:                      ; preds = %12031, %12029
  %12036 = phi i32 [ %.pre627, %12029 ], [ %12035, %12031 ]
  %12037 = phi i64 [ %.pre626, %12029 ], [ %12020, %12031 ]
  %12038 = phi %struct.Memory* [ %12030, %12029 ], [ %11987, %12031 ]
  %12039 = load i64, i64* %RBP.i, align 8
  %12040 = add i64 %12039, -652
  %12041 = add i64 %12037, 7
  store i64 %12041, i64* %3, align 8
  %12042 = inttoptr i64 %12040 to i32*
  %12043 = load i32, i32* %12042, align 4
  %12044 = add i32 %12036, %12043
  %12045 = zext i32 %12044 to i64
  store i64 %12045, i64* %50, align 8
  %12046 = sext i32 %12044 to i64
  %12047 = shl nsw i64 %12046, 4
  store i64 %12047, i64* %RSI.i2015, align 8
  %12048 = load i64, i64* %RCX.i1588, align 8
  %12049 = add i64 %12047, %12048
  store i64 %12049, i64* %RCX.i1588, align 8
  %12050 = icmp ult i64 %12049, %12048
  %12051 = icmp ult i64 %12049, %12047
  %12052 = or i1 %12050, %12051
  %12053 = zext i1 %12052 to i8
  store i8 %12053, i8* %17, align 1
  %12054 = trunc i64 %12049 to i32
  %12055 = and i32 %12054, 255
  %12056 = tail call i32 @llvm.ctpop.i32(i32 %12055)
  %12057 = trunc i32 %12056 to i8
  %12058 = and i8 %12057, 1
  %12059 = xor i8 %12058, 1
  store i8 %12059, i8* %18, align 1
  %12060 = xor i64 %12047, %12048
  %12061 = xor i64 %12060, %12049
  %12062 = lshr i64 %12061, 4
  %12063 = trunc i64 %12062 to i8
  %12064 = and i8 %12063, 1
  store i8 %12064, i8* %19, align 1
  %12065 = icmp eq i64 %12049, 0
  %12066 = zext i1 %12065 to i8
  store i8 %12066, i8* %20, align 1
  %12067 = lshr i64 %12049, 63
  %12068 = trunc i64 %12067 to i8
  store i8 %12068, i8* %21, align 1
  %12069 = lshr i64 %12048, 63
  %12070 = lshr i64 %12046, 59
  %12071 = and i64 %12070, 1
  %12072 = xor i64 %12067, %12069
  %12073 = xor i64 %12067, %12071
  %12074 = add nuw nsw i64 %12072, %12073
  %12075 = icmp eq i64 %12074, 2
  %12076 = zext i1 %12075 to i8
  store i8 %12076, i8* %22, align 1
  %12077 = load i64, i64* %RBP.i, align 8
  %12078 = add i64 %12077, -12
  %12079 = add i64 %12037, 23
  store i64 %12079, i64* %3, align 8
  %12080 = inttoptr i64 %12078 to i32*
  %12081 = load i32, i32* %12080, align 4
  %12082 = zext i32 %12081 to i64
  store i64 %12082, i64* %RAX.i1659, align 8
  %12083 = sext i32 %12081 to i64
  %12084 = lshr i64 %12083, 32
  store i64 %12084, i64* %103, align 8
  %12085 = load i32, i32* %R9D.i5956, align 4
  %12086 = add i64 %12037, 29
  store i64 %12086, i64* %3, align 8
  %12087 = sext i32 %12085 to i64
  %12088 = shl nuw i64 %12084, 32
  %12089 = or i64 %12088, %12082
  %12090 = sdiv i64 %12089, %12087
  %12091 = shl i64 %12090, 32
  %12092 = ashr exact i64 %12091, 32
  %12093 = icmp eq i64 %12090, %12092
  br i1 %12093, label %12096, label %12094

; <label>:12094:                                  ; preds = %routine_idivl__r9d.exit3294
  %12095 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12086, %struct.Memory* %12038)
  %.pre628 = load i64, i64* %RAX.i1659, align 8
  %.pre629 = load i64, i64* %3, align 8
  %.pre630 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__r9d.exit3265

; <label>:12096:                                  ; preds = %routine_idivl__r9d.exit3294
  %12097 = srem i64 %12089, %12087
  %12098 = and i64 %12090, 4294967295
  store i64 %12098, i64* %RAX.i1659, align 8
  %12099 = and i64 %12097, 4294967295
  store i64 %12099, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__r9d.exit3265

routine_idivl__r9d.exit3265:                      ; preds = %12096, %12094
  %12100 = phi i64 [ %.pre630, %12094 ], [ %12077, %12096 ]
  %12101 = phi i64 [ %.pre629, %12094 ], [ %12086, %12096 ]
  %12102 = phi i64 [ %.pre628, %12094 ], [ %12098, %12096 ]
  %12103 = phi %struct.Memory* [ %12095, %12094 ], [ %12038, %12096 ]
  %12104 = trunc i64 %12102 to i32
  %12105 = shl i32 %12104, 1
  %12106 = icmp slt i32 %12104, 0
  %12107 = icmp slt i32 %12105, 0
  %12108 = xor i1 %12106, %12107
  %12109 = zext i32 %12105 to i64
  store i64 %12109, i64* %RAX.i1659, align 8
  %.lobit205 = lshr i32 %12104, 31
  %12110 = trunc i32 %.lobit205 to i8
  store i8 %12110, i8* %17, align 1
  %12111 = and i32 %12105, 254
  %12112 = tail call i32 @llvm.ctpop.i32(i32 %12111)
  %12113 = trunc i32 %12112 to i8
  %12114 = and i8 %12113, 1
  %12115 = xor i8 %12114, 1
  store i8 %12115, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %12116 = icmp eq i32 %12105, 0
  %12117 = zext i1 %12116 to i8
  store i8 %12117, i8* %20, align 1
  %12118 = lshr i32 %12104, 30
  %12119 = trunc i32 %12118 to i8
  %12120 = and i8 %12119, 1
  store i8 %12120, i8* %21, align 1
  %12121 = zext i1 %12108 to i8
  store i8 %12121, i8* %22, align 1
  %12122 = add i64 %12100, -16
  %12123 = add i64 %12101, 6
  store i64 %12123, i64* %3, align 8
  %12124 = inttoptr i64 %12122 to i32*
  %12125 = load i32, i32* %12124, align 4
  %12126 = zext i32 %12125 to i64
  store i64 %12126, i64* %50, align 8
  %12127 = add i64 %12100, -656
  %12128 = add i64 %12101, 12
  store i64 %12128, i64* %3, align 8
  %12129 = inttoptr i64 %12127 to i32*
  store i32 %12105, i32* %12129, align 4
  %12130 = load i32, i32* %R10D.i1715, align 4
  %12131 = zext i32 %12130 to i64
  %12132 = load i64, i64* %3, align 8
  store i64 %12131, i64* %RAX.i1659, align 8
  %12133 = sext i32 %12130 to i64
  %12134 = lshr i64 %12133, 32
  store i64 %12134, i64* %103, align 8
  %12135 = load i32, i32* %R9D.i5956, align 4
  %12136 = add i64 %12132, 7
  store i64 %12136, i64* %3, align 8
  %12137 = sext i32 %12135 to i64
  %12138 = shl nuw i64 %12134, 32
  %12139 = or i64 %12138, %12131
  %12140 = sdiv i64 %12139, %12137
  %12141 = shl i64 %12140, 32
  %12142 = ashr exact i64 %12141, 32
  %12143 = icmp eq i64 %12140, %12142
  br i1 %12143, label %12146, label %12144

; <label>:12144:                                  ; preds = %routine_idivl__r9d.exit3265
  %12145 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %12136, %struct.Memory* %12103)
  %.pre631 = load i64, i64* %3, align 8
  %.pre632 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__r9d.exit

; <label>:12146:                                  ; preds = %routine_idivl__r9d.exit3265
  %12147 = srem i64 %12139, %12137
  %12148 = and i64 %12140, 4294967295
  store i64 %12148, i64* %RAX.i1659, align 8
  %12149 = and i64 %12147, 4294967295
  store i64 %12149, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %12150 = trunc i64 %12140 to i32
  br label %routine_idivl__r9d.exit

routine_idivl__r9d.exit:                          ; preds = %12146, %12144
  %12151 = phi i32 [ %.pre632, %12144 ], [ %12150, %12146 ]
  %12152 = phi i64 [ %.pre631, %12144 ], [ %12136, %12146 ]
  %12153 = phi %struct.Memory* [ %12145, %12144 ], [ %12103, %12146 ]
  %12154 = load i64, i64* %RBP.i, align 8
  %12155 = add i64 %12154, -656
  %12156 = add i64 %12152, 7
  store i64 %12156, i64* %3, align 8
  %12157 = inttoptr i64 %12155 to i32*
  %12158 = load i32, i32* %12157, align 4
  %12159 = add i32 %12151, %12158
  %12160 = zext i32 %12159 to i64
  store i64 %12160, i64* %50, align 8
  %12161 = icmp ult i32 %12159, %12158
  %12162 = icmp ult i32 %12159, %12151
  %12163 = or i1 %12161, %12162
  %12164 = zext i1 %12163 to i8
  store i8 %12164, i8* %17, align 1
  %12165 = and i32 %12159, 255
  %12166 = tail call i32 @llvm.ctpop.i32(i32 %12165)
  %12167 = trunc i32 %12166 to i8
  %12168 = and i8 %12167, 1
  %12169 = xor i8 %12168, 1
  store i8 %12169, i8* %18, align 1
  %12170 = xor i32 %12151, %12158
  %12171 = xor i32 %12170, %12159
  %12172 = lshr i32 %12171, 4
  %12173 = trunc i32 %12172 to i8
  %12174 = and i8 %12173, 1
  store i8 %12174, i8* %19, align 1
  %12175 = icmp eq i32 %12159, 0
  %12176 = zext i1 %12175 to i8
  store i8 %12176, i8* %20, align 1
  %12177 = lshr i32 %12159, 31
  %12178 = trunc i32 %12177 to i8
  store i8 %12178, i8* %21, align 1
  %12179 = lshr i32 %12158, 31
  %12180 = lshr i32 %12151, 31
  %12181 = xor i32 %12177, %12179
  %12182 = xor i32 %12177, %12180
  %12183 = add nuw nsw i32 %12181, %12182
  %12184 = icmp eq i32 %12183, 2
  %12185 = zext i1 %12184 to i8
  store i8 %12185, i8* %22, align 1
  %12186 = sext i32 %12159 to i64
  store i64 %12186, i64* %RSI.i2015, align 8
  %12187 = add i64 %12154, -648
  %12188 = add i64 %12152, 19
  store i64 %12188, i64* %3, align 8
  %12189 = inttoptr i64 %12187 to i32*
  %12190 = load i32, i32* %12189, align 4
  %12191 = zext i32 %12190 to i64
  store i64 %12191, i64* %RAX.i1659, align 8
  %12192 = load i64, i64* %RCX.i1588, align 8
  %12193 = shl nsw i64 %12186, 2
  %12194 = add i64 %12193, %12192
  %12195 = add i64 %12152, 22
  store i64 %12195, i64* %3, align 8
  %12196 = inttoptr i64 %12194 to i32*
  store i32 %12190, i32* %12196, align 4
  %12197 = load i64, i64* %RBP.i, align 8
  %12198 = add i64 %12197, -60
  %12199 = load i64, i64* %3, align 8
  %12200 = add i64 %12199, 7
  store i64 %12200, i64* %3, align 8
  %12201 = inttoptr i64 %12198 to i32*
  store i32 0, i32* %12201, align 4
  %.pre633 = load i64, i64* %3, align 8
  br label %block_.L_48554c

block_.L_48554c:                                  ; preds = %block_.L_4855d0, %routine_idivl__r9d.exit
  %12202 = phi i64 [ %12504, %block_.L_4855d0 ], [ %.pre633, %routine_idivl__r9d.exit ]
  %12203 = load i64, i64* %RBP.i, align 8
  %12204 = add i64 %12203, -60
  %12205 = add i64 %12202, 4
  store i64 %12205, i64* %3, align 8
  %12206 = inttoptr i64 %12204 to i32*
  %12207 = load i32, i32* %12206, align 4
  %12208 = add i32 %12207, -4
  %12209 = icmp ult i32 %12207, 4
  %12210 = zext i1 %12209 to i8
  store i8 %12210, i8* %17, align 1
  %12211 = and i32 %12208, 255
  %12212 = tail call i32 @llvm.ctpop.i32(i32 %12211)
  %12213 = trunc i32 %12212 to i8
  %12214 = and i8 %12213, 1
  %12215 = xor i8 %12214, 1
  store i8 %12215, i8* %18, align 1
  %12216 = xor i32 %12208, %12207
  %12217 = lshr i32 %12216, 4
  %12218 = trunc i32 %12217 to i8
  %12219 = and i8 %12218, 1
  store i8 %12219, i8* %19, align 1
  %12220 = icmp eq i32 %12208, 0
  %12221 = zext i1 %12220 to i8
  store i8 %12221, i8* %20, align 1
  %12222 = lshr i32 %12208, 31
  %12223 = trunc i32 %12222 to i8
  store i8 %12223, i8* %21, align 1
  %12224 = lshr i32 %12207, 31
  %12225 = xor i32 %12222, %12224
  %12226 = add nuw nsw i32 %12225, %12224
  %12227 = icmp eq i32 %12226, 2
  %12228 = zext i1 %12227 to i8
  store i8 %12228, i8* %22, align 1
  %12229 = icmp ne i8 %12223, 0
  %12230 = xor i1 %12229, %12227
  %.v682 = select i1 %12230, i64 10, i64 151
  %12231 = add i64 %12202, %.v682
  store i64 %12231, i64* %3, align 8
  br i1 %12230, label %block_485556, label %block_.L_4855e3

block_485556:                                     ; preds = %block_.L_48554c
  %12232 = add i64 %12203, -56
  %12233 = add i64 %12231, 7
  store i64 %12233, i64* %3, align 8
  %12234 = inttoptr i64 %12232 to i32*
  store i32 0, i32* %12234, align 4
  %.pre634 = load i64, i64* %3, align 8
  br label %block_.L_48555d

block_.L_48555d:                                  ; preds = %block_485567, %block_485556
  %12235 = phi i64 [ %12474, %block_485567 ], [ %.pre634, %block_485556 ]
  %12236 = load i64, i64* %RBP.i, align 8
  %12237 = add i64 %12236, -56
  %12238 = add i64 %12235, 4
  store i64 %12238, i64* %3, align 8
  %12239 = inttoptr i64 %12237 to i32*
  %12240 = load i32, i32* %12239, align 4
  %12241 = add i32 %12240, -4
  %12242 = icmp ult i32 %12240, 4
  %12243 = zext i1 %12242 to i8
  store i8 %12243, i8* %17, align 1
  %12244 = and i32 %12241, 255
  %12245 = tail call i32 @llvm.ctpop.i32(i32 %12244)
  %12246 = trunc i32 %12245 to i8
  %12247 = and i8 %12246, 1
  %12248 = xor i8 %12247, 1
  store i8 %12248, i8* %18, align 1
  %12249 = xor i32 %12241, %12240
  %12250 = lshr i32 %12249, 4
  %12251 = trunc i32 %12250 to i8
  %12252 = and i8 %12251, 1
  store i8 %12252, i8* %19, align 1
  %12253 = icmp eq i32 %12241, 0
  %12254 = zext i1 %12253 to i8
  store i8 %12254, i8* %20, align 1
  %12255 = lshr i32 %12241, 31
  %12256 = trunc i32 %12255 to i8
  store i8 %12256, i8* %21, align 1
  %12257 = lshr i32 %12240, 31
  %12258 = xor i32 %12255, %12257
  %12259 = add nuw nsw i32 %12258, %12257
  %12260 = icmp eq i32 %12259, 2
  %12261 = zext i1 %12260 to i8
  store i8 %12261, i8* %22, align 1
  %12262 = icmp ne i8 %12256, 0
  %12263 = xor i1 %12262, %12260
  %.v683 = select i1 %12263, i64 10, i64 115
  %12264 = add i64 %12235, %.v683
  store i64 %12264, i64* %3, align 8
  br i1 %12263, label %block_485567, label %block_.L_4855d0

block_485567:                                     ; preds = %block_.L_48555d
  %12265 = add i64 %12236, -496
  store i64 %12265, i64* %RAX.i1659, align 8
  %12266 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %12266, i64* %RCX.i1588, align 8
  %12267 = add i64 %12266, 6464
  %12268 = add i64 %12264, 22
  store i64 %12268, i64* %3, align 8
  %12269 = inttoptr i64 %12267 to i64*
  %12270 = load i64, i64* %12269, align 8
  store i64 %12270, i64* %RCX.i1588, align 8
  %12271 = add i64 %12236, -44
  %12272 = add i64 %12264, 26
  store i64 %12272, i64* %3, align 8
  %12273 = inttoptr i64 %12271 to i32*
  %12274 = load i32, i32* %12273, align 4
  %12275 = sext i32 %12274 to i64
  store i64 %12275, i64* %RDX.i1943, align 8
  %12276 = shl nsw i64 %12275, 3
  %12277 = add i64 %12276, %12270
  %12278 = add i64 %12264, 30
  store i64 %12278, i64* %3, align 8
  %12279 = inttoptr i64 %12277 to i64*
  %12280 = load i64, i64* %12279, align 8
  store i64 %12280, i64* %RCX.i1588, align 8
  %12281 = add i64 %12236, -232
  %12282 = add i64 %12264, 36
  store i64 %12282, i64* %3, align 8
  %12283 = inttoptr i64 %12281 to i32*
  %12284 = load i32, i32* %12283, align 4
  %12285 = zext i32 %12284 to i64
  store i64 %12285, i64* %RSI.i2015, align 8
  %12286 = add i64 %12236, -60
  %12287 = add i64 %12264, 39
  store i64 %12287, i64* %3, align 8
  %12288 = inttoptr i64 %12286 to i32*
  %12289 = load i32, i32* %12288, align 4
  %12290 = add i32 %12289, %12284
  %12291 = zext i32 %12290 to i64
  store i64 %12291, i64* %RSI.i2015, align 8
  %12292 = icmp ult i32 %12290, %12284
  %12293 = icmp ult i32 %12290, %12289
  %12294 = or i1 %12292, %12293
  %12295 = zext i1 %12294 to i8
  store i8 %12295, i8* %17, align 1
  %12296 = and i32 %12290, 255
  %12297 = tail call i32 @llvm.ctpop.i32(i32 %12296)
  %12298 = trunc i32 %12297 to i8
  %12299 = and i8 %12298, 1
  %12300 = xor i8 %12299, 1
  store i8 %12300, i8* %18, align 1
  %12301 = xor i32 %12289, %12284
  %12302 = xor i32 %12301, %12290
  %12303 = lshr i32 %12302, 4
  %12304 = trunc i32 %12303 to i8
  %12305 = and i8 %12304, 1
  store i8 %12305, i8* %19, align 1
  %12306 = icmp eq i32 %12290, 0
  %12307 = zext i1 %12306 to i8
  store i8 %12307, i8* %20, align 1
  %12308 = lshr i32 %12290, 31
  %12309 = trunc i32 %12308 to i8
  store i8 %12309, i8* %21, align 1
  %12310 = lshr i32 %12284, 31
  %12311 = lshr i32 %12289, 31
  %12312 = xor i32 %12308, %12310
  %12313 = xor i32 %12308, %12311
  %12314 = add nuw nsw i32 %12312, %12313
  %12315 = icmp eq i32 %12314, 2
  %12316 = zext i1 %12315 to i8
  store i8 %12316, i8* %22, align 1
  %12317 = sext i32 %12290 to i64
  store i64 %12317, i64* %RDX.i1943, align 8
  %12318 = shl nsw i64 %12317, 3
  %12319 = add i64 %12280, %12318
  %12320 = add i64 %12264, 46
  store i64 %12320, i64* %3, align 8
  %12321 = inttoptr i64 %12319 to i64*
  %12322 = load i64, i64* %12321, align 8
  store i64 %12322, i64* %RCX.i1588, align 8
  %12323 = add i64 %12236, -228
  %12324 = add i64 %12264, 52
  store i64 %12324, i64* %3, align 8
  %12325 = inttoptr i64 %12323 to i32*
  %12326 = load i32, i32* %12325, align 4
  %12327 = zext i32 %12326 to i64
  store i64 %12327, i64* %RSI.i2015, align 8
  %12328 = add i64 %12264, 55
  store i64 %12328, i64* %3, align 8
  %12329 = load i32, i32* %12239, align 4
  %12330 = add i32 %12329, %12326
  %12331 = zext i32 %12330 to i64
  store i64 %12331, i64* %RSI.i2015, align 8
  %12332 = icmp ult i32 %12330, %12326
  %12333 = icmp ult i32 %12330, %12329
  %12334 = or i1 %12332, %12333
  %12335 = zext i1 %12334 to i8
  store i8 %12335, i8* %17, align 1
  %12336 = and i32 %12330, 255
  %12337 = tail call i32 @llvm.ctpop.i32(i32 %12336)
  %12338 = trunc i32 %12337 to i8
  %12339 = and i8 %12338, 1
  %12340 = xor i8 %12339, 1
  store i8 %12340, i8* %18, align 1
  %12341 = xor i32 %12329, %12326
  %12342 = xor i32 %12341, %12330
  %12343 = lshr i32 %12342, 4
  %12344 = trunc i32 %12343 to i8
  %12345 = and i8 %12344, 1
  store i8 %12345, i8* %19, align 1
  %12346 = icmp eq i32 %12330, 0
  %12347 = zext i1 %12346 to i8
  store i8 %12347, i8* %20, align 1
  %12348 = lshr i32 %12330, 31
  %12349 = trunc i32 %12348 to i8
  store i8 %12349, i8* %21, align 1
  %12350 = lshr i32 %12326, 31
  %12351 = lshr i32 %12329, 31
  %12352 = xor i32 %12348, %12350
  %12353 = xor i32 %12348, %12351
  %12354 = add nuw nsw i32 %12352, %12353
  %12355 = icmp eq i32 %12354, 2
  %12356 = zext i1 %12355 to i8
  store i8 %12356, i8* %22, align 1
  %12357 = sext i32 %12330 to i64
  store i64 %12357, i64* %RDX.i1943, align 8
  %12358 = shl nsw i64 %12357, 1
  %12359 = add i64 %12322, %12358
  %12360 = add i64 %12264, 62
  store i64 %12360, i64* %3, align 8
  %12361 = inttoptr i64 %12359 to i16*
  %12362 = load i16, i16* %12361, align 2
  %12363 = zext i16 %12362 to i64
  store i64 %12363, i64* %RSI.i2015, align 8
  %12364 = load i64, i64* %RBP.i, align 8
  %12365 = add i64 %12364, -44
  %12366 = add i64 %12264, 66
  store i64 %12366, i64* %3, align 8
  %12367 = inttoptr i64 %12365 to i32*
  %12368 = load i32, i32* %12367, align 4
  %12369 = sext i32 %12368 to i64
  %12370 = shl nsw i64 %12369, 6
  store i64 %12370, i64* %RCX.i1588, align 8
  %12371 = load i64, i64* %RAX.i1659, align 8
  %12372 = add i64 %12370, %12371
  store i64 %12372, i64* %RAX.i1659, align 8
  %12373 = icmp ult i64 %12372, %12371
  %12374 = icmp ult i64 %12372, %12370
  %12375 = or i1 %12373, %12374
  %12376 = zext i1 %12375 to i8
  store i8 %12376, i8* %17, align 1
  %12377 = trunc i64 %12372 to i32
  %12378 = and i32 %12377, 255
  %12379 = tail call i32 @llvm.ctpop.i32(i32 %12378)
  %12380 = trunc i32 %12379 to i8
  %12381 = and i8 %12380, 1
  %12382 = xor i8 %12381, 1
  store i8 %12382, i8* %18, align 1
  %12383 = xor i64 %12371, %12372
  %12384 = lshr i64 %12383, 4
  %12385 = trunc i64 %12384 to i8
  %12386 = and i8 %12385, 1
  store i8 %12386, i8* %19, align 1
  %12387 = icmp eq i64 %12372, 0
  %12388 = zext i1 %12387 to i8
  store i8 %12388, i8* %20, align 1
  %12389 = lshr i64 %12372, 63
  %12390 = trunc i64 %12389 to i8
  store i8 %12390, i8* %21, align 1
  %12391 = lshr i64 %12371, 63
  %12392 = lshr i64 %12369, 57
  %12393 = and i64 %12392, 1
  %12394 = xor i64 %12389, %12391
  %12395 = xor i64 %12389, %12393
  %12396 = add nuw nsw i64 %12394, %12395
  %12397 = icmp eq i64 %12396, 2
  %12398 = zext i1 %12397 to i8
  store i8 %12398, i8* %22, align 1
  %12399 = add i64 %12364, -60
  %12400 = add i64 %12264, 77
  store i64 %12400, i64* %3, align 8
  %12401 = inttoptr i64 %12399 to i32*
  %12402 = load i32, i32* %12401, align 4
  %12403 = sext i32 %12402 to i64
  %12404 = shl nsw i64 %12403, 4
  store i64 %12404, i64* %RCX.i1588, align 8
  %12405 = add i64 %12404, %12372
  store i64 %12405, i64* %RAX.i1659, align 8
  %12406 = icmp ult i64 %12405, %12372
  %12407 = icmp ult i64 %12405, %12404
  %12408 = or i1 %12406, %12407
  %12409 = zext i1 %12408 to i8
  store i8 %12409, i8* %17, align 1
  %12410 = trunc i64 %12405 to i32
  %12411 = and i32 %12410, 255
  %12412 = tail call i32 @llvm.ctpop.i32(i32 %12411)
  %12413 = trunc i32 %12412 to i8
  %12414 = and i8 %12413, 1
  %12415 = xor i8 %12414, 1
  store i8 %12415, i8* %18, align 1
  %12416 = xor i64 %12404, %12372
  %12417 = xor i64 %12416, %12405
  %12418 = lshr i64 %12417, 4
  %12419 = trunc i64 %12418 to i8
  %12420 = and i8 %12419, 1
  store i8 %12420, i8* %19, align 1
  %12421 = icmp eq i64 %12405, 0
  %12422 = zext i1 %12421 to i8
  store i8 %12422, i8* %20, align 1
  %12423 = lshr i64 %12405, 63
  %12424 = trunc i64 %12423 to i8
  store i8 %12424, i8* %21, align 1
  %12425 = lshr i64 %12403, 59
  %12426 = and i64 %12425, 1
  %12427 = xor i64 %12423, %12389
  %12428 = xor i64 %12423, %12426
  %12429 = add nuw nsw i64 %12427, %12428
  %12430 = icmp eq i64 %12429, 2
  %12431 = zext i1 %12430 to i8
  store i8 %12431, i8* %22, align 1
  %12432 = load i64, i64* %RBP.i, align 8
  %12433 = add i64 %12432, -56
  %12434 = add i64 %12264, 88
  store i64 %12434, i64* %3, align 8
  %12435 = inttoptr i64 %12433 to i32*
  %12436 = load i32, i32* %12435, align 4
  %12437 = sext i32 %12436 to i64
  store i64 %12437, i64* %RCX.i1588, align 8
  %12438 = shl nsw i64 %12437, 2
  %12439 = add i64 %12438, %12405
  %12440 = load i32, i32* %ESI.i1759, align 4
  %12441 = add i64 %12264, 91
  store i64 %12441, i64* %3, align 8
  %12442 = inttoptr i64 %12439 to i32*
  store i32 %12440, i32* %12442, align 4
  %12443 = load i64, i64* %RBP.i, align 8
  %12444 = add i64 %12443, -56
  %12445 = load i64, i64* %3, align 8
  %12446 = add i64 %12445, 3
  store i64 %12446, i64* %3, align 8
  %12447 = inttoptr i64 %12444 to i32*
  %12448 = load i32, i32* %12447, align 4
  %12449 = add i32 %12448, 1
  %12450 = zext i32 %12449 to i64
  store i64 %12450, i64* %RAX.i1659, align 8
  %12451 = icmp eq i32 %12448, -1
  %12452 = icmp eq i32 %12449, 0
  %12453 = or i1 %12451, %12452
  %12454 = zext i1 %12453 to i8
  store i8 %12454, i8* %17, align 1
  %12455 = and i32 %12449, 255
  %12456 = tail call i32 @llvm.ctpop.i32(i32 %12455)
  %12457 = trunc i32 %12456 to i8
  %12458 = and i8 %12457, 1
  %12459 = xor i8 %12458, 1
  store i8 %12459, i8* %18, align 1
  %12460 = xor i32 %12449, %12448
  %12461 = lshr i32 %12460, 4
  %12462 = trunc i32 %12461 to i8
  %12463 = and i8 %12462, 1
  store i8 %12463, i8* %19, align 1
  %12464 = zext i1 %12452 to i8
  store i8 %12464, i8* %20, align 1
  %12465 = lshr i32 %12449, 31
  %12466 = trunc i32 %12465 to i8
  store i8 %12466, i8* %21, align 1
  %12467 = lshr i32 %12448, 31
  %12468 = xor i32 %12465, %12467
  %12469 = add nuw nsw i32 %12468, %12465
  %12470 = icmp eq i32 %12469, 2
  %12471 = zext i1 %12470 to i8
  store i8 %12471, i8* %22, align 1
  %12472 = add i64 %12445, 9
  store i64 %12472, i64* %3, align 8
  store i32 %12449, i32* %12447, align 4
  %12473 = load i64, i64* %3, align 8
  %12474 = add i64 %12473, -110
  store i64 %12474, i64* %3, align 8
  br label %block_.L_48555d

block_.L_4855d0:                                  ; preds = %block_.L_48555d
  %12475 = add i64 %12236, -60
  %12476 = add i64 %12264, 8
  store i64 %12476, i64* %3, align 8
  %12477 = inttoptr i64 %12475 to i32*
  %12478 = load i32, i32* %12477, align 4
  %12479 = add i32 %12478, 1
  %12480 = zext i32 %12479 to i64
  store i64 %12480, i64* %RAX.i1659, align 8
  %12481 = icmp eq i32 %12478, -1
  %12482 = icmp eq i32 %12479, 0
  %12483 = or i1 %12481, %12482
  %12484 = zext i1 %12483 to i8
  store i8 %12484, i8* %17, align 1
  %12485 = and i32 %12479, 255
  %12486 = tail call i32 @llvm.ctpop.i32(i32 %12485)
  %12487 = trunc i32 %12486 to i8
  %12488 = and i8 %12487, 1
  %12489 = xor i8 %12488, 1
  store i8 %12489, i8* %18, align 1
  %12490 = xor i32 %12479, %12478
  %12491 = lshr i32 %12490, 4
  %12492 = trunc i32 %12491 to i8
  %12493 = and i8 %12492, 1
  store i8 %12493, i8* %19, align 1
  %12494 = zext i1 %12482 to i8
  store i8 %12494, i8* %20, align 1
  %12495 = lshr i32 %12479, 31
  %12496 = trunc i32 %12495 to i8
  store i8 %12496, i8* %21, align 1
  %12497 = lshr i32 %12478, 31
  %12498 = xor i32 %12495, %12497
  %12499 = add nuw nsw i32 %12498, %12495
  %12500 = icmp eq i32 %12499, 2
  %12501 = zext i1 %12500 to i8
  store i8 %12501, i8* %22, align 1
  %12502 = add i64 %12264, 14
  store i64 %12502, i64* %3, align 8
  store i32 %12479, i32* %12477, align 4
  %12503 = load i64, i64* %3, align 8
  %12504 = add i64 %12503, -146
  store i64 %12504, i64* %3, align 8
  br label %block_.L_48554c

block_.L_4855e3:                                  ; preds = %block_.L_48554c
  %12505 = add i64 %12203, -44
  %12506 = add i64 %12231, 8
  store i64 %12506, i64* %3, align 8
  %12507 = inttoptr i64 %12505 to i32*
  %12508 = load i32, i32* %12507, align 4
  %12509 = add i32 %12508, 1
  %12510 = zext i32 %12509 to i64
  store i64 %12510, i64* %RAX.i1659, align 8
  %12511 = icmp eq i32 %12508, -1
  %12512 = icmp eq i32 %12509, 0
  %12513 = or i1 %12511, %12512
  %12514 = zext i1 %12513 to i8
  store i8 %12514, i8* %17, align 1
  %12515 = and i32 %12509, 255
  %12516 = tail call i32 @llvm.ctpop.i32(i32 %12515)
  %12517 = trunc i32 %12516 to i8
  %12518 = and i8 %12517, 1
  %12519 = xor i8 %12518, 1
  store i8 %12519, i8* %18, align 1
  %12520 = xor i32 %12509, %12508
  %12521 = lshr i32 %12520, 4
  %12522 = trunc i32 %12521 to i8
  %12523 = and i8 %12522, 1
  store i8 %12523, i8* %19, align 1
  %12524 = zext i1 %12512 to i8
  store i8 %12524, i8* %20, align 1
  %12525 = lshr i32 %12509, 31
  %12526 = trunc i32 %12525 to i8
  store i8 %12526, i8* %21, align 1
  %12527 = lshr i32 %12508, 31
  %12528 = xor i32 %12525, %12527
  %12529 = add nuw nsw i32 %12528, %12525
  %12530 = icmp eq i32 %12529, 2
  %12531 = zext i1 %12530 to i8
  store i8 %12531, i8* %22, align 1
  %12532 = add i64 %12231, 14
  store i64 %12532, i64* %3, align 8
  store i32 %12509, i32* %12507, align 4
  %12533 = load i64, i64* %3, align 8
  %12534 = add i64 %12533, -703
  store i64 %12534, i64* %3, align 8
  br label %block_.L_485332

block_.L_4855f6:                                  ; preds = %block_.L_485332
  %12535 = add i64 %11056, -60
  %12536 = add i64 %11084, 7
  store i64 %12536, i64* %3, align 8
  %12537 = inttoptr i64 %12535 to i32*
  store i32 0, i32* %12537, align 4
  %.pre594 = load i64, i64* %3, align 8
  br label %block_.L_4855fd

block_.L_4855fd:                                  ; preds = %block_.L_48566e, %block_.L_4855f6
  %12538 = phi i64 [ %12797, %block_.L_48566e ], [ %.pre594, %block_.L_4855f6 ]
  %12539 = load i64, i64* %RBP.i, align 8
  %12540 = add i64 %12539, -60
  %12541 = add i64 %12538, 4
  store i64 %12541, i64* %3, align 8
  %12542 = inttoptr i64 %12540 to i32*
  %12543 = load i32, i32* %12542, align 4
  %12544 = add i32 %12543, -4
  %12545 = icmp ult i32 %12543, 4
  %12546 = zext i1 %12545 to i8
  store i8 %12546, i8* %17, align 1
  %12547 = and i32 %12544, 255
  %12548 = tail call i32 @llvm.ctpop.i32(i32 %12547)
  %12549 = trunc i32 %12548 to i8
  %12550 = and i8 %12549, 1
  %12551 = xor i8 %12550, 1
  store i8 %12551, i8* %18, align 1
  %12552 = xor i32 %12544, %12543
  %12553 = lshr i32 %12552, 4
  %12554 = trunc i32 %12553 to i8
  %12555 = and i8 %12554, 1
  store i8 %12555, i8* %19, align 1
  %12556 = icmp eq i32 %12544, 0
  %12557 = zext i1 %12556 to i8
  store i8 %12557, i8* %20, align 1
  %12558 = lshr i32 %12544, 31
  %12559 = trunc i32 %12558 to i8
  store i8 %12559, i8* %21, align 1
  %12560 = lshr i32 %12543, 31
  %12561 = xor i32 %12558, %12560
  %12562 = add nuw nsw i32 %12561, %12560
  %12563 = icmp eq i32 %12562, 2
  %12564 = zext i1 %12563 to i8
  store i8 %12564, i8* %22, align 1
  %12565 = icmp ne i8 %12559, 0
  %12566 = xor i1 %12565, %12563
  %.v748 = select i1 %12566, i64 10, i64 132
  %12567 = add i64 %12538, %.v748
  store i64 %12567, i64* %3, align 8
  br i1 %12566, label %block_485607, label %block_.L_485681

block_485607:                                     ; preds = %block_.L_4855fd
  %12568 = add i64 %12539, -56
  %12569 = add i64 %12567, 7
  store i64 %12569, i64* %3, align 8
  %12570 = inttoptr i64 %12568 to i32*
  store i32 0, i32* %12570, align 4
  %.pre595 = load i64, i64* %3, align 8
  br label %block_.L_48560e

block_.L_48560e:                                  ; preds = %block_485618, %block_485607
  %12571 = phi i64 [ %12767, %block_485618 ], [ %.pre595, %block_485607 ]
  %12572 = load i64, i64* %RBP.i, align 8
  %12573 = add i64 %12572, -56
  %12574 = add i64 %12571, 4
  store i64 %12574, i64* %3, align 8
  %12575 = inttoptr i64 %12573 to i32*
  %12576 = load i32, i32* %12575, align 4
  %12577 = add i32 %12576, -4
  %12578 = icmp ult i32 %12576, 4
  %12579 = zext i1 %12578 to i8
  store i8 %12579, i8* %17, align 1
  %12580 = and i32 %12577, 255
  %12581 = tail call i32 @llvm.ctpop.i32(i32 %12580)
  %12582 = trunc i32 %12581 to i8
  %12583 = and i8 %12582, 1
  %12584 = xor i8 %12583, 1
  store i8 %12584, i8* %18, align 1
  %12585 = xor i32 %12577, %12576
  %12586 = lshr i32 %12585, 4
  %12587 = trunc i32 %12586 to i8
  %12588 = and i8 %12587, 1
  store i8 %12588, i8* %19, align 1
  %12589 = icmp eq i32 %12577, 0
  %12590 = zext i1 %12589 to i8
  store i8 %12590, i8* %20, align 1
  %12591 = lshr i32 %12577, 31
  %12592 = trunc i32 %12591 to i8
  store i8 %12592, i8* %21, align 1
  %12593 = lshr i32 %12576, 31
  %12594 = xor i32 %12591, %12593
  %12595 = add nuw nsw i32 %12594, %12593
  %12596 = icmp eq i32 %12595, 2
  %12597 = zext i1 %12596 to i8
  store i8 %12597, i8* %22, align 1
  %12598 = icmp ne i8 %12592, 0
  %12599 = xor i1 %12598, %12596
  %.v681 = select i1 %12599, i64 10, i64 96
  %12600 = add i64 %12571, %.v681
  store i64 %12600, i64* %3, align 8
  br i1 %12599, label %block_485618, label %block_.L_48566e

block_485618:                                     ; preds = %block_.L_48560e
  %12601 = add i64 %12572, -144
  store i64 %12601, i64* %RAX.i1659, align 8
  %12602 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %12602, i64* %RCX.i1588, align 8
  %12603 = add i64 %12602, 6424
  %12604 = add i64 %12600, 22
  store i64 %12604, i64* %3, align 8
  %12605 = inttoptr i64 %12603 to i64*
  %12606 = load i64, i64* %12605, align 8
  store i64 %12606, i64* %RCX.i1588, align 8
  %12607 = add i64 %12572, -232
  %12608 = add i64 %12600, 28
  store i64 %12608, i64* %3, align 8
  %12609 = inttoptr i64 %12607 to i32*
  %12610 = load i32, i32* %12609, align 4
  %12611 = zext i32 %12610 to i64
  store i64 %12611, i64* %RDX.i1943, align 8
  %12612 = add i64 %12572, -60
  %12613 = add i64 %12600, 31
  store i64 %12613, i64* %3, align 8
  %12614 = inttoptr i64 %12612 to i32*
  %12615 = load i32, i32* %12614, align 4
  %12616 = add i32 %12615, %12610
  %12617 = zext i32 %12616 to i64
  store i64 %12617, i64* %RDX.i1943, align 8
  %12618 = icmp ult i32 %12616, %12610
  %12619 = icmp ult i32 %12616, %12615
  %12620 = or i1 %12618, %12619
  %12621 = zext i1 %12620 to i8
  store i8 %12621, i8* %17, align 1
  %12622 = and i32 %12616, 255
  %12623 = tail call i32 @llvm.ctpop.i32(i32 %12622)
  %12624 = trunc i32 %12623 to i8
  %12625 = and i8 %12624, 1
  %12626 = xor i8 %12625, 1
  store i8 %12626, i8* %18, align 1
  %12627 = xor i32 %12615, %12610
  %12628 = xor i32 %12627, %12616
  %12629 = lshr i32 %12628, 4
  %12630 = trunc i32 %12629 to i8
  %12631 = and i8 %12630, 1
  store i8 %12631, i8* %19, align 1
  %12632 = icmp eq i32 %12616, 0
  %12633 = zext i1 %12632 to i8
  store i8 %12633, i8* %20, align 1
  %12634 = lshr i32 %12616, 31
  %12635 = trunc i32 %12634 to i8
  store i8 %12635, i8* %21, align 1
  %12636 = lshr i32 %12610, 31
  %12637 = lshr i32 %12615, 31
  %12638 = xor i32 %12634, %12636
  %12639 = xor i32 %12634, %12637
  %12640 = add nuw nsw i32 %12638, %12639
  %12641 = icmp eq i32 %12640, 2
  %12642 = zext i1 %12641 to i8
  store i8 %12642, i8* %22, align 1
  %12643 = sext i32 %12616 to i64
  store i64 %12643, i64* %RSI.i2015, align 8
  %12644 = shl nsw i64 %12643, 3
  %12645 = add i64 %12606, %12644
  %12646 = add i64 %12600, 38
  store i64 %12646, i64* %3, align 8
  %12647 = inttoptr i64 %12645 to i64*
  %12648 = load i64, i64* %12647, align 8
  store i64 %12648, i64* %RCX.i1588, align 8
  %12649 = add i64 %12572, -228
  %12650 = add i64 %12600, 44
  store i64 %12650, i64* %3, align 8
  %12651 = inttoptr i64 %12649 to i32*
  %12652 = load i32, i32* %12651, align 4
  %12653 = zext i32 %12652 to i64
  store i64 %12653, i64* %RDX.i1943, align 8
  %12654 = add i64 %12600, 47
  store i64 %12654, i64* %3, align 8
  %12655 = load i32, i32* %12575, align 4
  %12656 = add i32 %12655, %12652
  %12657 = zext i32 %12656 to i64
  store i64 %12657, i64* %RDX.i1943, align 8
  %12658 = icmp ult i32 %12656, %12652
  %12659 = icmp ult i32 %12656, %12655
  %12660 = or i1 %12658, %12659
  %12661 = zext i1 %12660 to i8
  store i8 %12661, i8* %17, align 1
  %12662 = and i32 %12656, 255
  %12663 = tail call i32 @llvm.ctpop.i32(i32 %12662)
  %12664 = trunc i32 %12663 to i8
  %12665 = and i8 %12664, 1
  %12666 = xor i8 %12665, 1
  store i8 %12666, i8* %18, align 1
  %12667 = xor i32 %12655, %12652
  %12668 = xor i32 %12667, %12656
  %12669 = lshr i32 %12668, 4
  %12670 = trunc i32 %12669 to i8
  %12671 = and i8 %12670, 1
  store i8 %12671, i8* %19, align 1
  %12672 = icmp eq i32 %12656, 0
  %12673 = zext i1 %12672 to i8
  store i8 %12673, i8* %20, align 1
  %12674 = lshr i32 %12656, 31
  %12675 = trunc i32 %12674 to i8
  store i8 %12675, i8* %21, align 1
  %12676 = lshr i32 %12652, 31
  %12677 = lshr i32 %12655, 31
  %12678 = xor i32 %12674, %12676
  %12679 = xor i32 %12674, %12677
  %12680 = add nuw nsw i32 %12678, %12679
  %12681 = icmp eq i32 %12680, 2
  %12682 = zext i1 %12681 to i8
  store i8 %12682, i8* %22, align 1
  %12683 = sext i32 %12656 to i64
  store i64 %12683, i64* %RSI.i2015, align 8
  %12684 = shl nsw i64 %12683, 1
  %12685 = add i64 %12648, %12684
  %12686 = add i64 %12600, 54
  store i64 %12686, i64* %3, align 8
  %12687 = inttoptr i64 %12685 to i16*
  %12688 = load i16, i16* %12687, align 2
  %12689 = zext i16 %12688 to i64
  store i64 %12689, i64* %RDX.i1943, align 8
  %12690 = load i64, i64* %RBP.i, align 8
  %12691 = add i64 %12690, -60
  %12692 = add i64 %12600, 58
  store i64 %12692, i64* %3, align 8
  %12693 = inttoptr i64 %12691 to i32*
  %12694 = load i32, i32* %12693, align 4
  %12695 = sext i32 %12694 to i64
  %12696 = shl nsw i64 %12695, 4
  store i64 %12696, i64* %RCX.i1588, align 8
  %12697 = load i64, i64* %RAX.i1659, align 8
  %12698 = add i64 %12696, %12697
  store i64 %12698, i64* %RAX.i1659, align 8
  %12699 = icmp ult i64 %12698, %12697
  %12700 = icmp ult i64 %12698, %12696
  %12701 = or i1 %12699, %12700
  %12702 = zext i1 %12701 to i8
  store i8 %12702, i8* %17, align 1
  %12703 = trunc i64 %12698 to i32
  %12704 = and i32 %12703, 255
  %12705 = tail call i32 @llvm.ctpop.i32(i32 %12704)
  %12706 = trunc i32 %12705 to i8
  %12707 = and i8 %12706, 1
  %12708 = xor i8 %12707, 1
  store i8 %12708, i8* %18, align 1
  %12709 = xor i64 %12696, %12697
  %12710 = xor i64 %12709, %12698
  %12711 = lshr i64 %12710, 4
  %12712 = trunc i64 %12711 to i8
  %12713 = and i8 %12712, 1
  store i8 %12713, i8* %19, align 1
  %12714 = icmp eq i64 %12698, 0
  %12715 = zext i1 %12714 to i8
  store i8 %12715, i8* %20, align 1
  %12716 = lshr i64 %12698, 63
  %12717 = trunc i64 %12716 to i8
  store i8 %12717, i8* %21, align 1
  %12718 = lshr i64 %12697, 63
  %12719 = lshr i64 %12695, 59
  %12720 = and i64 %12719, 1
  %12721 = xor i64 %12716, %12718
  %12722 = xor i64 %12716, %12720
  %12723 = add nuw nsw i64 %12721, %12722
  %12724 = icmp eq i64 %12723, 2
  %12725 = zext i1 %12724 to i8
  store i8 %12725, i8* %22, align 1
  %12726 = add i64 %12690, -56
  %12727 = add i64 %12600, 69
  store i64 %12727, i64* %3, align 8
  %12728 = inttoptr i64 %12726 to i32*
  %12729 = load i32, i32* %12728, align 4
  %12730 = sext i32 %12729 to i64
  store i64 %12730, i64* %RCX.i1588, align 8
  %12731 = shl nsw i64 %12730, 2
  %12732 = add i64 %12731, %12698
  %12733 = zext i16 %12688 to i32
  %12734 = add i64 %12600, 72
  store i64 %12734, i64* %3, align 8
  %12735 = inttoptr i64 %12732 to i32*
  store i32 %12733, i32* %12735, align 4
  %12736 = load i64, i64* %RBP.i, align 8
  %12737 = add i64 %12736, -56
  %12738 = load i64, i64* %3, align 8
  %12739 = add i64 %12738, 3
  store i64 %12739, i64* %3, align 8
  %12740 = inttoptr i64 %12737 to i32*
  %12741 = load i32, i32* %12740, align 4
  %12742 = add i32 %12741, 1
  %12743 = zext i32 %12742 to i64
  store i64 %12743, i64* %RAX.i1659, align 8
  %12744 = icmp eq i32 %12741, -1
  %12745 = icmp eq i32 %12742, 0
  %12746 = or i1 %12744, %12745
  %12747 = zext i1 %12746 to i8
  store i8 %12747, i8* %17, align 1
  %12748 = and i32 %12742, 255
  %12749 = tail call i32 @llvm.ctpop.i32(i32 %12748)
  %12750 = trunc i32 %12749 to i8
  %12751 = and i8 %12750, 1
  %12752 = xor i8 %12751, 1
  store i8 %12752, i8* %18, align 1
  %12753 = xor i32 %12742, %12741
  %12754 = lshr i32 %12753, 4
  %12755 = trunc i32 %12754 to i8
  %12756 = and i8 %12755, 1
  store i8 %12756, i8* %19, align 1
  %12757 = zext i1 %12745 to i8
  store i8 %12757, i8* %20, align 1
  %12758 = lshr i32 %12742, 31
  %12759 = trunc i32 %12758 to i8
  store i8 %12759, i8* %21, align 1
  %12760 = lshr i32 %12741, 31
  %12761 = xor i32 %12758, %12760
  %12762 = add nuw nsw i32 %12761, %12758
  %12763 = icmp eq i32 %12762, 2
  %12764 = zext i1 %12763 to i8
  store i8 %12764, i8* %22, align 1
  %12765 = add i64 %12738, 9
  store i64 %12765, i64* %3, align 8
  store i32 %12742, i32* %12740, align 4
  %12766 = load i64, i64* %3, align 8
  %12767 = add i64 %12766, -91
  store i64 %12767, i64* %3, align 8
  br label %block_.L_48560e

block_.L_48566e:                                  ; preds = %block_.L_48560e
  %12768 = add i64 %12572, -60
  %12769 = add i64 %12600, 8
  store i64 %12769, i64* %3, align 8
  %12770 = inttoptr i64 %12768 to i32*
  %12771 = load i32, i32* %12770, align 4
  %12772 = add i32 %12771, 1
  %12773 = zext i32 %12772 to i64
  store i64 %12773, i64* %RAX.i1659, align 8
  %12774 = icmp eq i32 %12771, -1
  %12775 = icmp eq i32 %12772, 0
  %12776 = or i1 %12774, %12775
  %12777 = zext i1 %12776 to i8
  store i8 %12777, i8* %17, align 1
  %12778 = and i32 %12772, 255
  %12779 = tail call i32 @llvm.ctpop.i32(i32 %12778)
  %12780 = trunc i32 %12779 to i8
  %12781 = and i8 %12780, 1
  %12782 = xor i8 %12781, 1
  store i8 %12782, i8* %18, align 1
  %12783 = xor i32 %12772, %12771
  %12784 = lshr i32 %12783, 4
  %12785 = trunc i32 %12784 to i8
  %12786 = and i8 %12785, 1
  store i8 %12786, i8* %19, align 1
  %12787 = zext i1 %12775 to i8
  store i8 %12787, i8* %20, align 1
  %12788 = lshr i32 %12772, 31
  %12789 = trunc i32 %12788 to i8
  store i8 %12789, i8* %21, align 1
  %12790 = lshr i32 %12771, 31
  %12791 = xor i32 %12788, %12790
  %12792 = add nuw nsw i32 %12791, %12788
  %12793 = icmp eq i32 %12792, 2
  %12794 = zext i1 %12793 to i8
  store i8 %12794, i8* %22, align 1
  %12795 = add i64 %12600, 14
  store i64 %12795, i64* %3, align 8
  store i32 %12772, i32* %12770, align 4
  %12796 = load i64, i64* %3, align 8
  %12797 = add i64 %12796, -127
  store i64 %12797, i64* %3, align 8
  br label %block_.L_4855fd

block_.L_485681:                                  ; preds = %block_.L_4855fd
  %12798 = add i64 %12539, -72
  %12799 = add i64 %12567, 3
  store i64 %12799, i64* %3, align 8
  %12800 = inttoptr i64 %12798 to i32*
  %12801 = load i32, i32* %12800, align 4
  %12802 = zext i32 %12801 to i64
  store i64 %12802, i64* %RAX.i1659, align 8
  %12803 = add i64 %12539, -76
  %12804 = add i64 %12567, 6
  store i64 %12804, i64* %3, align 8
  %12805 = inttoptr i64 %12803 to i32*
  store i32 %12801, i32* %12805, align 4
  %12806 = load i64, i64* %RBP.i, align 8
  %12807 = add i64 %12806, -216
  %12808 = load i64, i64* %3, align 8
  %12809 = add i64 %12808, 8
  store i64 %12809, i64* %3, align 8
  %12810 = inttoptr i64 %12807 to i64*
  %12811 = load i64, i64* %12810, align 8
  store i64 %12811, i64* %69, align 1
  store double 0.000000e+00, double* %1190, align 1
  %12812 = add i64 %12806, -256
  %12813 = add i64 %12808, 16
  store i64 %12813, i64* %3, align 8
  %12814 = inttoptr i64 %12812 to i64*
  store i64 %12811, i64* %12814, align 8
  %12815 = load i64, i64* %RBP.i, align 8
  %12816 = add i64 %12815, -36
  %12817 = load i64, i64* %3, align 8
  %12818 = add i64 %12817, 3
  store i64 %12818, i64* %3, align 8
  %12819 = inttoptr i64 %12816 to i32*
  %12820 = load i32, i32* %12819, align 4
  %12821 = zext i32 %12820 to i64
  store i64 %12821, i64* %RAX.i1659, align 8
  %12822 = add i64 %12815, -40
  %12823 = add i64 %12817, 6
  store i64 %12823, i64* %3, align 8
  %12824 = inttoptr i64 %12822 to i32*
  store i32 %12820, i32* %12824, align 4
  %.pre638 = load i64, i64* %3, align 8
  br label %block_.L_48569d

block_.L_48569d:                                  ; preds = %block_.L_485681, %routine_ucomisd__xmm0___xmm1.exit
  %12825 = phi i64 [ %10384, %routine_ucomisd__xmm0___xmm1.exit ], [ %.pre638, %block_.L_485681 ]
  %MEMORY.66 = phi %struct.Memory* [ %10383, %routine_ucomisd__xmm0___xmm1.exit ], [ %MEMORY.61, %block_.L_485681 ]
  %12826 = add i64 %12825, 5
  store i64 %12826, i64* %3, align 8
  br label %block_.L_4856a2

block_.L_4856a2:                                  ; preds = %block_.L_48569d, %block_.L_4842cf
  %storemerge136 = phi i64 [ %3533, %block_.L_4842cf ], [ %12826, %block_.L_48569d ]
  %MEMORY.67 = phi %struct.Memory* [ %call2_4842d7, %block_.L_4842cf ], [ %MEMORY.66, %block_.L_48569d ]
  %12827 = add i64 %storemerge136, 5
  store i64 %12827, i64* %3, align 8
  br label %block_.L_4856a7

block_.L_4856a7:                                  ; preds = %block_.L_4856a2, %block_.L_483ff2
  %storemerge128 = phi i64 [ %2281, %block_.L_483ff2 ], [ %12827, %block_.L_4856a2 ]
  %MEMORY.68 = phi %struct.Memory* [ %call2_483fc9, %block_.L_483ff2 ], [ %MEMORY.67, %block_.L_4856a2 ]
  %12828 = add i64 %storemerge128, 5
  store i64 %12828, i64* %3, align 8
  %.pre655 = load i64, i64* %RBP.i, align 8
  br label %block_.L_4856b1

block_.L_4856b1:                                  ; preds = %block_483e68, %block_483e3a, %block_483e30, %block_.L_483ea0, %block_.L_4856a7, %block_483e8c, %block_483e5e
  %12829 = phi i64 [ %1578, %block_483e68 ], [ %1578, %block_483e5e ], [ %1644, %block_483e8c ], [ %.pre655, %block_.L_4856a7 ], [ %1676, %block_.L_483ea0 ], [ %1524, %block_483e3a ], [ %1524, %block_483e30 ]
  %12830 = phi i64 [ %1628, %block_483e68 ], [ %1604, %block_483e5e ], [ %1672, %block_483e8c ], [ %12828, %block_.L_4856a7 ], [ %1690, %block_.L_483ea0 ], [ %1562, %block_483e3a ], [ %1538, %block_483e30 ]
  %.sink296 = phi i64 [ 6207, %block_483e68 ], [ 6207, %block_483e5e ], [ 6171, %block_483e8c ], [ 5, %block_.L_4856a7 ], [ 5, %block_.L_483ea0 ], [ 6253, %block_483e3a ], [ 6253, %block_483e30 ]
  %MEMORY.70 = phi %struct.Memory* [ %MEMORY.8, %block_483e68 ], [ %MEMORY.8, %block_483e5e ], [ %MEMORY.8, %block_483e8c ], [ %MEMORY.68, %block_.L_4856a7 ], [ %MEMORY.8, %block_.L_483ea0 ], [ %MEMORY.8, %block_483e3a ], [ %MEMORY.8, %block_483e30 ]
  %12831 = add i64 %12830, %.sink296
  %12832 = add i64 %12829, -36
  %12833 = add i64 %12831, 3
  store i64 %12833, i64* %3, align 8
  %12834 = inttoptr i64 %12832 to i32*
  %12835 = load i32, i32* %12834, align 4
  %12836 = add i32 %12835, 1
  %12837 = zext i32 %12836 to i64
  store i64 %12837, i64* %RAX.i1659, align 8
  %12838 = icmp eq i32 %12835, -1
  %12839 = icmp eq i32 %12836, 0
  %12840 = or i1 %12838, %12839
  %12841 = zext i1 %12840 to i8
  store i8 %12841, i8* %17, align 1
  %12842 = and i32 %12836, 255
  %12843 = tail call i32 @llvm.ctpop.i32(i32 %12842)
  %12844 = trunc i32 %12843 to i8
  %12845 = and i8 %12844, 1
  %12846 = xor i8 %12845, 1
  store i8 %12846, i8* %18, align 1
  %12847 = xor i32 %12836, %12835
  %12848 = lshr i32 %12847, 4
  %12849 = trunc i32 %12848 to i8
  %12850 = and i8 %12849, 1
  store i8 %12850, i8* %19, align 1
  %12851 = zext i1 %12839 to i8
  store i8 %12851, i8* %20, align 1
  %12852 = lshr i32 %12836, 31
  %12853 = trunc i32 %12852 to i8
  store i8 %12853, i8* %21, align 1
  %12854 = lshr i32 %12835, 31
  %12855 = xor i32 %12852, %12854
  %12856 = add nuw nsw i32 %12855, %12852
  %12857 = icmp eq i32 %12856, 2
  %12858 = zext i1 %12857 to i8
  store i8 %12858, i8* %22, align 1
  %12859 = add i64 %12831, 9
  store i64 %12859, i64* %3, align 8
  store i32 %12836, i32* %12834, align 4
  %12860 = load i64, i64* %3, align 8
  %12861 = add i64 %12860, -6495
  store i64 %12861, i64* %3, align 8
  br label %block_.L_483d5b

block_.L_4856bf:                                  ; preds = %block_.L_483d5b
  %12862 = add i64 %1209, -40
  %12863 = add i64 %1237, 3
  store i64 %12863, i64* %3, align 8
  %12864 = inttoptr i64 %12862 to i32*
  %12865 = load i32, i32* %12864, align 4
  %12866 = zext i32 %12865 to i64
  store i64 %12866, i64* %RAX.i1659, align 8
  %12867 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %12867, i64* %RCX.i1588, align 8
  %12868 = add i64 %12867, 104
  %12869 = add i64 %1237, 15
  store i64 %12869, i64* %3, align 8
  %12870 = inttoptr i64 %12868 to i64*
  %12871 = load i64, i64* %12870, align 8
  store i64 %12871, i64* %RCX.i1588, align 8
  %12872 = add i64 %1209, -244
  %12873 = add i64 %1237, 22
  store i64 %12873, i64* %3, align 8
  %12874 = inttoptr i64 %12872 to i32*
  %12875 = load i32, i32* %12874, align 4
  %12876 = sext i32 %12875 to i64
  store i64 %12876, i64* %RDX.i1943, align 8
  %12877 = shl nsw i64 %12876, 3
  %12878 = add i64 %12877, %12871
  %12879 = add i64 %1237, 26
  store i64 %12879, i64* %3, align 8
  %12880 = inttoptr i64 %12878 to i64*
  %12881 = load i64, i64* %12880, align 8
  store i64 %12881, i64* %RCX.i1588, align 8
  %12882 = add i64 %1209, -248
  %12883 = add i64 %1237, 33
  store i64 %12883, i64* %3, align 8
  %12884 = inttoptr i64 %12882 to i32*
  %12885 = load i32, i32* %12884, align 4
  %12886 = sext i32 %12885 to i64
  store i64 %12886, i64* %RDX.i1943, align 8
  %12887 = shl nsw i64 %12886, 2
  %12888 = add i64 %12887, %12881
  %12889 = add i64 %1237, 36
  store i64 %12889, i64* %3, align 8
  %12890 = inttoptr i64 %12888 to i32*
  store i32 %12865, i32* %12890, align 4
  %12891 = load i64, i64* %RBP.i, align 8
  %12892 = add i64 %12891, -288
  %12893 = load i64, i64* %3, align 8
  %12894 = add i64 %12893, 6
  store i64 %12894, i64* %3, align 8
  %12895 = inttoptr i64 %12892 to i32*
  %12896 = load i32, i32* %12895, align 4
  %12897 = zext i32 %12896 to i64
  store i64 %12897, i64* %RAX.i1659, align 8
  %12898 = add i64 %12891, -40
  %12899 = add i64 %12893, 9
  store i64 %12899, i64* %3, align 8
  %12900 = inttoptr i64 %12898 to i32*
  %12901 = load i32, i32* %12900, align 4
  %12902 = sub i32 %12896, %12901
  %12903 = icmp ult i32 %12896, %12901
  %12904 = zext i1 %12903 to i8
  store i8 %12904, i8* %17, align 1
  %12905 = and i32 %12902, 255
  %12906 = tail call i32 @llvm.ctpop.i32(i32 %12905)
  %12907 = trunc i32 %12906 to i8
  %12908 = and i8 %12907, 1
  %12909 = xor i8 %12908, 1
  store i8 %12909, i8* %18, align 1
  %12910 = xor i32 %12901, %12896
  %12911 = xor i32 %12910, %12902
  %12912 = lshr i32 %12911, 4
  %12913 = trunc i32 %12912 to i8
  %12914 = and i8 %12913, 1
  store i8 %12914, i8* %19, align 1
  %12915 = icmp eq i32 %12902, 0
  %12916 = zext i1 %12915 to i8
  store i8 %12916, i8* %20, align 1
  %12917 = lshr i32 %12902, 31
  %12918 = trunc i32 %12917 to i8
  store i8 %12918, i8* %21, align 1
  %12919 = lshr i32 %12896, 31
  %12920 = lshr i32 %12901, 31
  %12921 = xor i32 %12920, %12919
  %12922 = xor i32 %12917, %12919
  %12923 = add nuw nsw i32 %12922, %12921
  %12924 = icmp eq i32 %12923, 2
  %12925 = zext i1 %12924 to i8
  store i8 %12925, i8* %22, align 1
  %.v672 = select i1 %12915, i64 15, i64 31
  %12926 = add i64 %12893, %.v672
  store i64 %12926, i64* %3, align 8
  br i1 %12915, label %block_4856f2, label %block_.L_485702

block_4856f2:                                     ; preds = %block_.L_4856bf
  store i64 4294967295, i64* %RAX.i1659, align 8
  %12927 = add i64 %12891, -660
  %12928 = add i64 %12926, 11
  store i64 %12928, i64* %3, align 8
  %12929 = inttoptr i64 %12927 to i32*
  store i32 -1, i32* %12929, align 4
  %12930 = load i64, i64* %3, align 8
  %12931 = add i64 %12930, 58
  store i64 %12931, i64* %3, align 8
  br label %block_.L_485737

block_.L_485702:                                  ; preds = %block_.L_4856bf
  %12932 = add i64 %12926, 3
  store i64 %12932, i64* %3, align 8
  %12933 = load i32, i32* %12900, align 4
  %12934 = zext i32 %12933 to i64
  store i64 %12934, i64* %RAX.i1659, align 8
  %12935 = add i64 %12926, 9
  store i64 %12935, i64* %3, align 8
  %12936 = load i32, i32* %12895, align 4
  %12937 = sub i32 %12933, %12936
  %12938 = icmp ult i32 %12933, %12936
  %12939 = zext i1 %12938 to i8
  store i8 %12939, i8* %17, align 1
  %12940 = and i32 %12937, 255
  %12941 = tail call i32 @llvm.ctpop.i32(i32 %12940)
  %12942 = trunc i32 %12941 to i8
  %12943 = and i8 %12942, 1
  %12944 = xor i8 %12943, 1
  store i8 %12944, i8* %18, align 1
  %12945 = xor i32 %12936, %12933
  %12946 = xor i32 %12945, %12937
  %12947 = lshr i32 %12946, 4
  %12948 = trunc i32 %12947 to i8
  %12949 = and i8 %12948, 1
  store i8 %12949, i8* %19, align 1
  %12950 = icmp eq i32 %12937, 0
  %12951 = zext i1 %12950 to i8
  store i8 %12951, i8* %20, align 1
  %12952 = lshr i32 %12937, 31
  %12953 = trunc i32 %12952 to i8
  store i8 %12953, i8* %21, align 1
  %12954 = lshr i32 %12933, 31
  %12955 = lshr i32 %12936, 31
  %12956 = xor i32 %12955, %12954
  %12957 = xor i32 %12952, %12954
  %12958 = add nuw nsw i32 %12957, %12956
  %12959 = icmp eq i32 %12958, 2
  %12960 = zext i1 %12959 to i8
  store i8 %12960, i8* %22, align 1
  %12961 = icmp ne i8 %12953, 0
  %12962 = xor i1 %12961, %12959
  %.v671 = select i1 %12962, i64 15, i64 29
  %12963 = add i64 %12926, %.v671
  %12964 = add i64 %12963, 3
  store i64 %12964, i64* %3, align 8
  %12965 = load i32, i32* %12900, align 4
  %12966 = zext i32 %12965 to i64
  store i64 %12966, i64* %RAX.i1659, align 8
  br i1 %12962, label %block_485711, label %block_.L_48571f

block_485711:                                     ; preds = %block_.L_485702
  %12967 = add i64 %12891, -664
  %12968 = add i64 %12963, 9
  store i64 %12968, i64* %3, align 8
  %12969 = inttoptr i64 %12967 to i32*
  store i32 %12965, i32* %12969, align 4
  %12970 = load i64, i64* %3, align 8
  %12971 = add i64 %12970, 17
  store i64 %12971, i64* %3, align 8
  br label %block_.L_48572b

block_.L_48571f:                                  ; preds = %block_.L_485702
  %12972 = add i32 %12965, -1
  %12973 = zext i32 %12972 to i64
  store i64 %12973, i64* %RAX.i1659, align 8
  %12974 = icmp eq i32 %12965, 0
  %12975 = zext i1 %12974 to i8
  store i8 %12975, i8* %17, align 1
  %12976 = and i32 %12972, 255
  %12977 = tail call i32 @llvm.ctpop.i32(i32 %12976)
  %12978 = trunc i32 %12977 to i8
  %12979 = and i8 %12978, 1
  %12980 = xor i8 %12979, 1
  store i8 %12980, i8* %18, align 1
  %12981 = xor i32 %12972, %12965
  %12982 = lshr i32 %12981, 4
  %12983 = trunc i32 %12982 to i8
  %12984 = and i8 %12983, 1
  store i8 %12984, i8* %19, align 1
  %12985 = icmp eq i32 %12972, 0
  %12986 = zext i1 %12985 to i8
  store i8 %12986, i8* %20, align 1
  %12987 = lshr i32 %12972, 31
  %12988 = trunc i32 %12987 to i8
  store i8 %12988, i8* %21, align 1
  %12989 = lshr i32 %12965, 31
  %12990 = xor i32 %12987, %12989
  %12991 = add nuw nsw i32 %12990, %12989
  %12992 = icmp eq i32 %12991, 2
  %12993 = zext i1 %12992 to i8
  store i8 %12993, i8* %22, align 1
  %12994 = add i64 %12891, -664
  %12995 = add i64 %12963, 12
  store i64 %12995, i64* %3, align 8
  %12996 = inttoptr i64 %12994 to i32*
  store i32 %12972, i32* %12996, align 4
  %.pre469 = load i64, i64* %3, align 8
  br label %block_.L_48572b

block_.L_48572b:                                  ; preds = %block_.L_48571f, %block_485711
  %12997 = phi i64 [ %.pre469, %block_.L_48571f ], [ %12971, %block_485711 ]
  %12998 = load i64, i64* %RBP.i, align 8
  %12999 = add i64 %12998, -664
  %13000 = add i64 %12997, 6
  store i64 %13000, i64* %3, align 8
  %13001 = inttoptr i64 %12999 to i32*
  %13002 = load i32, i32* %13001, align 4
  %13003 = zext i32 %13002 to i64
  store i64 %13003, i64* %RAX.i1659, align 8
  %13004 = add i64 %12998, -660
  %13005 = add i64 %12997, 12
  store i64 %13005, i64* %3, align 8
  %13006 = inttoptr i64 %13004 to i32*
  store i32 %13002, i32* %13006, align 4
  %.pre470 = load i64, i64* %3, align 8
  br label %block_.L_485737

block_.L_485737:                                  ; preds = %block_.L_48572b, %block_4856f2
  %13007 = phi i64 [ %.pre470, %block_.L_48572b ], [ %12931, %block_4856f2 ]
  %13008 = load i64, i64* %RBP.i, align 8
  %13009 = add i64 %13008, -660
  %13010 = add i64 %13007, 6
  store i64 %13010, i64* %3, align 8
  %13011 = inttoptr i64 %13009 to i32*
  %13012 = load i32, i32* %13011, align 4
  %13013 = zext i32 %13012 to i64
  store i64 %13013, i64* %RAX.i1659, align 8
  %13014 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %13014, i64* %RCX.i1588, align 8
  %13015 = add i64 %13014, 14168
  %13016 = add i64 %13007, 21
  store i64 %13016, i64* %3, align 8
  %13017 = inttoptr i64 %13015 to i64*
  %13018 = load i64, i64* %13017, align 8
  store i64 %13018, i64* %RCX.i1588, align 8
  store i64 %13014, i64* %RDX.i1943, align 8
  %13019 = add i64 %13014, 12
  %13020 = add i64 %13007, 33
  store i64 %13020, i64* %3, align 8
  %13021 = inttoptr i64 %13019 to i32*
  %13022 = load i32, i32* %13021, align 4
  %13023 = sext i32 %13022 to i64
  %13024 = mul nsw i64 %13023, 632
  store i64 %13024, i64* %RDX.i1943, align 8
  %13025 = lshr i64 %13024, 63
  %13026 = add i64 %13024, %13018
  store i64 %13026, i64* %RCX.i1588, align 8
  %13027 = icmp ult i64 %13026, %13018
  %13028 = icmp ult i64 %13026, %13024
  %13029 = or i1 %13027, %13028
  %13030 = zext i1 %13029 to i8
  store i8 %13030, i8* %17, align 1
  %13031 = trunc i64 %13026 to i32
  %13032 = and i32 %13031, 255
  %13033 = tail call i32 @llvm.ctpop.i32(i32 %13032)
  %13034 = trunc i32 %13033 to i8
  %13035 = and i8 %13034, 1
  %13036 = xor i8 %13035, 1
  store i8 %13036, i8* %18, align 1
  %13037 = xor i64 %13024, %13018
  %13038 = xor i64 %13037, %13026
  %13039 = lshr i64 %13038, 4
  %13040 = trunc i64 %13039 to i8
  %13041 = and i8 %13040, 1
  store i8 %13041, i8* %19, align 1
  %13042 = icmp eq i64 %13026, 0
  %13043 = zext i1 %13042 to i8
  store i8 %13043, i8* %20, align 1
  %13044 = lshr i64 %13026, 63
  %13045 = trunc i64 %13044 to i8
  store i8 %13045, i8* %21, align 1
  %13046 = lshr i64 %13018, 63
  %13047 = xor i64 %13044, %13046
  %13048 = xor i64 %13044, %13025
  %13049 = add nuw nsw i64 %13047, %13048
  %13050 = icmp eq i64 %13049, 2
  %13051 = zext i1 %13050 to i8
  store i8 %13051, i8* %22, align 1
  %13052 = add i64 %13008, -12
  %13053 = add i64 %13007, 46
  store i64 %13053, i64* %3, align 8
  %13054 = inttoptr i64 %13052 to i32*
  %13055 = load i32, i32* %13054, align 4
  %13056 = shl i32 %13055, 2
  %13057 = zext i32 %13056 to i64
  store i64 %13057, i64* %RSI.i2015, align 8
  %13058 = lshr i32 %13055, 30
  %13059 = trunc i32 %13058 to i8
  %13060 = and i8 %13059, 1
  store i8 %13060, i8* %17, align 1
  %13061 = and i32 %13056, 252
  %13062 = tail call i32 @llvm.ctpop.i32(i32 %13061)
  %13063 = trunc i32 %13062 to i8
  %13064 = and i8 %13063, 1
  %13065 = xor i8 %13064, 1
  store i8 %13065, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %13066 = icmp eq i32 %13056, 0
  %13067 = zext i1 %13066 to i8
  store i8 %13067, i8* %20, align 1
  %13068 = lshr i32 %13055, 29
  %13069 = trunc i32 %13068 to i8
  %13070 = and i8 %13069, 1
  store i8 %13070, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %13071 = load i64, i64* %RBP.i, align 8
  %13072 = add i64 %13071, -16
  %13073 = add i64 %13007, 52
  store i64 %13073, i64* %3, align 8
  %13074 = inttoptr i64 %13072 to i32*
  %13075 = load i32, i32* %13074, align 4
  %13076 = add i32 %13075, %13056
  %13077 = zext i32 %13076 to i64
  store i64 %13077, i64* %RSI.i2015, align 8
  %13078 = icmp ult i32 %13076, %13056
  %13079 = icmp ult i32 %13076, %13075
  %13080 = or i1 %13078, %13079
  %13081 = zext i1 %13080 to i8
  store i8 %13081, i8* %17, align 1
  %13082 = and i32 %13076, 255
  %13083 = tail call i32 @llvm.ctpop.i32(i32 %13082)
  %13084 = trunc i32 %13083 to i8
  %13085 = and i8 %13084, 1
  %13086 = xor i8 %13085, 1
  store i8 %13086, i8* %18, align 1
  %13087 = xor i32 %13075, %13056
  %13088 = xor i32 %13087, %13076
  %13089 = lshr i32 %13088, 4
  %13090 = trunc i32 %13089 to i8
  %13091 = and i8 %13090, 1
  store i8 %13091, i8* %19, align 1
  %13092 = icmp eq i32 %13076, 0
  %13093 = zext i1 %13092 to i8
  store i8 %13093, i8* %20, align 1
  %13094 = lshr i32 %13076, 31
  %13095 = trunc i32 %13094 to i8
  store i8 %13095, i8* %21, align 1
  %13096 = lshr i32 %13055, 29
  %13097 = and i32 %13096, 1
  %13098 = lshr i32 %13075, 31
  %13099 = xor i32 %13094, %13097
  %13100 = xor i32 %13094, %13098
  %13101 = add nuw nsw i32 %13099, %13100
  %13102 = icmp eq i32 %13101, 2
  %13103 = zext i1 %13102 to i8
  store i8 %13103, i8* %22, align 1
  %13104 = sext i32 %13076 to i64
  store i64 %13104, i64* %RDX.i1943, align 8
  %13105 = load i64, i64* %RCX.i1588, align 8
  %13106 = shl nsw i64 %13104, 2
  %13107 = add nsw i64 %13106, 332
  %13108 = add i64 %13107, %13105
  %13109 = load i32, i32* %EAX.i2033, align 4
  %13110 = add i64 %13007, 62
  store i64 %13110, i64* %3, align 8
  %13111 = inttoptr i64 %13108 to i32*
  store i32 %13109, i32* %13111, align 4
  %13112 = load i64, i64* %3, align 8
  %13113 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %13113, i64* %RCX.i1588, align 8
  %13114 = add i64 %13113, 2464
  %13115 = add i64 %13112, 15
  store i64 %13115, i64* %3, align 8
  %13116 = inttoptr i64 %13114 to i32*
  %13117 = load i32, i32* %13116, align 4
  store i8 0, i8* %17, align 1
  %13118 = and i32 %13117, 255
  %13119 = tail call i32 @llvm.ctpop.i32(i32 %13118)
  %13120 = trunc i32 %13119 to i8
  %13121 = and i8 %13120, 1
  %13122 = xor i8 %13121, 1
  store i8 %13122, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %13123 = icmp eq i32 %13117, 0
  %13124 = zext i1 %13123 to i8
  store i8 %13124, i8* %20, align 1
  %13125 = lshr i32 %13117, 31
  %13126 = trunc i32 %13125 to i8
  store i8 %13126, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v701 = select i1 %13123, i64 21, i64 3990
  %13127 = add i64 %13112, %.v701
  store i64 %13127, i64* %3, align 8
  br i1 %13123, label %block_48578a, label %block_.L_48670b

block_48578a:                                     ; preds = %block_.L_485737
  %13128 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %13128, i64* %RAX.i1659, align 8
  %13129 = add i64 %13128, 72724
  %13130 = add i64 %13127, 15
  store i64 %13130, i64* %3, align 8
  %13131 = inttoptr i64 %13129 to i32*
  %13132 = load i32, i32* %13131, align 4
  store i8 0, i8* %17, align 1
  %13133 = and i32 %13132, 255
  %13134 = tail call i32 @llvm.ctpop.i32(i32 %13133)
  %13135 = trunc i32 %13134 to i8
  %13136 = and i8 %13135, 1
  %13137 = xor i8 %13136, 1
  store i8 %13137, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %13138 = icmp eq i32 %13132, 0
  %13139 = zext i1 %13138 to i8
  store i8 %13139, i8* %20, align 1
  %13140 = lshr i32 %13132, 31
  %13141 = trunc i32 %13140 to i8
  store i8 %13141, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v709 = select i1 %13138, i64 21, i64 333
  %13142 = add i64 %13127, %.v709
  %13143 = load i64, i64* %RBP.i, align 8
  %13144 = add i64 %13143, -48
  %13145 = add i64 %13142, 7
  store i64 %13145, i64* %3, align 8
  %13146 = inttoptr i64 %13144 to i32*
  store i32 0, i32* %13146, align 4
  %.pre471 = load i64, i64* %3, align 8
  br i1 %13138, label %block_.L_4857a6.preheader, label %block_.L_4858de.preheader

block_.L_4858de.preheader:                        ; preds = %block_48578a
  br label %block_.L_4858de

block_.L_4857a6.preheader:                        ; preds = %block_48578a
  br label %block_.L_4857a6

block_.L_4857a6:                                  ; preds = %block_.L_4857a6.preheader, %block_.L_4858a2
  %13147 = phi i64 [ %13734, %block_.L_4858a2 ], [ %.pre471, %block_.L_4857a6.preheader ]
  %13148 = load i64, i64* %RBP.i, align 8
  %13149 = add i64 %13148, -48
  %13150 = add i64 %13147, 4
  store i64 %13150, i64* %3, align 8
  %13151 = inttoptr i64 %13149 to i32*
  %13152 = load i32, i32* %13151, align 4
  %13153 = add i32 %13152, -4
  %13154 = icmp ult i32 %13152, 4
  %13155 = zext i1 %13154 to i8
  store i8 %13155, i8* %17, align 1
  %13156 = and i32 %13153, 255
  %13157 = tail call i32 @llvm.ctpop.i32(i32 %13156)
  %13158 = trunc i32 %13157 to i8
  %13159 = and i8 %13158, 1
  %13160 = xor i8 %13159, 1
  store i8 %13160, i8* %18, align 1
  %13161 = xor i32 %13153, %13152
  %13162 = lshr i32 %13161, 4
  %13163 = trunc i32 %13162 to i8
  %13164 = and i8 %13163, 1
  store i8 %13164, i8* %19, align 1
  %13165 = icmp eq i32 %13153, 0
  %13166 = zext i1 %13165 to i8
  store i8 %13166, i8* %20, align 1
  %13167 = lshr i32 %13153, 31
  %13168 = trunc i32 %13167 to i8
  store i8 %13168, i8* %21, align 1
  %13169 = lshr i32 %13152, 31
  %13170 = xor i32 %13167, %13169
  %13171 = add nuw nsw i32 %13170, %13169
  %13172 = icmp eq i32 %13171, 2
  %13173 = zext i1 %13172 to i8
  store i8 %13173, i8* %22, align 1
  %13174 = icmp ne i8 %13168, 0
  %13175 = xor i1 %13174, %13172
  %.v722 = select i1 %13175, i64 10, i64 271
  %13176 = add i64 %13147, %.v722
  store i64 %13176, i64* %3, align 8
  br i1 %13175, label %block_4857b0, label %block_.L_4858b5

block_4857b0:                                     ; preds = %block_.L_4857a6
  %13177 = add i64 %13148, -44
  %13178 = add i64 %13176, 7
  store i64 %13178, i64* %3, align 8
  %13179 = inttoptr i64 %13177 to i32*
  store i32 0, i32* %13179, align 4
  %.pre472 = load i64, i64* %3, align 8
  br label %block_.L_4857b7

block_.L_4857b7:                                  ; preds = %block_4857c1, %block_4857b0
  %13180 = phi i64 [ %13704, %block_4857c1 ], [ %.pre472, %block_4857b0 ]
  %13181 = load i64, i64* %RBP.i, align 8
  %13182 = add i64 %13181, -44
  %13183 = add i64 %13180, 4
  store i64 %13183, i64* %3, align 8
  %13184 = inttoptr i64 %13182 to i32*
  %13185 = load i32, i32* %13184, align 4
  %13186 = add i32 %13185, -4
  %13187 = icmp ult i32 %13185, 4
  %13188 = zext i1 %13187 to i8
  store i8 %13188, i8* %17, align 1
  %13189 = and i32 %13186, 255
  %13190 = tail call i32 @llvm.ctpop.i32(i32 %13189)
  %13191 = trunc i32 %13190 to i8
  %13192 = and i8 %13191, 1
  %13193 = xor i8 %13192, 1
  store i8 %13193, i8* %18, align 1
  %13194 = xor i32 %13186, %13185
  %13195 = lshr i32 %13194, 4
  %13196 = trunc i32 %13195 to i8
  %13197 = and i8 %13196, 1
  store i8 %13197, i8* %19, align 1
  %13198 = icmp eq i32 %13186, 0
  %13199 = zext i1 %13198 to i8
  store i8 %13199, i8* %20, align 1
  %13200 = lshr i32 %13186, 31
  %13201 = trunc i32 %13200 to i8
  store i8 %13201, i8* %21, align 1
  %13202 = lshr i32 %13185, 31
  %13203 = xor i32 %13200, %13202
  %13204 = add nuw nsw i32 %13203, %13202
  %13205 = icmp eq i32 %13204, 2
  %13206 = zext i1 %13205 to i8
  store i8 %13206, i8* %22, align 1
  %13207 = icmp ne i8 %13201, 0
  %13208 = xor i1 %13207, %13205
  %.v658 = select i1 %13208, i64 10, i64 235
  %13209 = add i64 %13180, %.v658
  store i64 %13209, i64* %3, align 8
  br i1 %13208, label %block_4857c1, label %block_.L_4858a2

block_4857c1:                                     ; preds = %block_.L_4857b7
  %13210 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %13211 = add i64 %13210, 184
  store i64 %13211, i64* %RAX.i1659, align 8
  %13212 = icmp ugt i64 %13210, -185
  %13213 = zext i1 %13212 to i8
  store i8 %13213, i8* %17, align 1
  %13214 = trunc i64 %13211 to i32
  %13215 = and i32 %13214, 255
  %13216 = tail call i32 @llvm.ctpop.i32(i32 %13215)
  %13217 = trunc i32 %13216 to i8
  %13218 = and i8 %13217, 1
  %13219 = xor i8 %13218, 1
  store i8 %13219, i8* %18, align 1
  %13220 = xor i64 %13210, 16
  %13221 = xor i64 %13220, %13211
  %13222 = lshr i64 %13221, 4
  %13223 = trunc i64 %13222 to i8
  %13224 = and i8 %13223, 1
  store i8 %13224, i8* %19, align 1
  %13225 = icmp eq i64 %13211, 0
  %13226 = zext i1 %13225 to i8
  store i8 %13226, i8* %20, align 1
  %13227 = lshr i64 %13211, 63
  %13228 = trunc i64 %13227 to i8
  store i8 %13228, i8* %21, align 1
  %13229 = lshr i64 %13210, 63
  %13230 = xor i64 %13227, %13229
  %13231 = add nuw nsw i64 %13230, %13227
  %13232 = icmp eq i64 %13231, 2
  %13233 = zext i1 %13232 to i8
  store i8 %13233, i8* %22, align 1
  %13234 = add i64 %13181, -40
  %13235 = add i64 %13209, 18
  store i64 %13235, i64* %3, align 8
  %13236 = inttoptr i64 %13234 to i32*
  %13237 = load i32, i32* %13236, align 4
  %13238 = sext i32 %13237 to i64
  %13239 = shl nsw i64 %13238, 9
  store i64 %13239, i64* %RCX.i1588, align 8
  %13240 = add i64 %13239, %13211
  store i64 %13240, i64* %RAX.i1659, align 8
  %13241 = icmp ult i64 %13240, %13211
  %13242 = icmp ult i64 %13240, %13239
  %13243 = or i1 %13241, %13242
  %13244 = zext i1 %13243 to i8
  store i8 %13244, i8* %17, align 1
  %13245 = trunc i64 %13240 to i32
  %13246 = and i32 %13245, 255
  %13247 = tail call i32 @llvm.ctpop.i32(i32 %13246)
  %13248 = trunc i32 %13247 to i8
  %13249 = and i8 %13248, 1
  %13250 = xor i8 %13249, 1
  store i8 %13250, i8* %18, align 1
  %13251 = xor i64 %13211, %13240
  %13252 = lshr i64 %13251, 4
  %13253 = trunc i64 %13252 to i8
  %13254 = and i8 %13253, 1
  store i8 %13254, i8* %19, align 1
  %13255 = icmp eq i64 %13240, 0
  %13256 = zext i1 %13255 to i8
  store i8 %13256, i8* %20, align 1
  %13257 = lshr i64 %13240, 63
  %13258 = trunc i64 %13257 to i8
  store i8 %13258, i8* %21, align 1
  %13259 = lshr i64 %13238, 54
  %13260 = and i64 %13259, 1
  %13261 = xor i64 %13257, %13227
  %13262 = xor i64 %13257, %13260
  %13263 = add nuw nsw i64 %13261, %13262
  %13264 = icmp eq i64 %13263, 2
  %13265 = zext i1 %13264 to i8
  store i8 %13265, i8* %22, align 1
  %13266 = add i64 %13181, -48
  %13267 = add i64 %13209, 29
  store i64 %13267, i64* %3, align 8
  %13268 = inttoptr i64 %13266 to i32*
  %13269 = load i32, i32* %13268, align 4
  %13270 = sext i32 %13269 to i64
  %13271 = shl nsw i64 %13270, 5
  store i64 %13271, i64* %RCX.i1588, align 8
  %13272 = add i64 %13271, %13240
  store i64 %13272, i64* %RAX.i1659, align 8
  %13273 = icmp ult i64 %13272, %13240
  %13274 = icmp ult i64 %13272, %13271
  %13275 = or i1 %13273, %13274
  %13276 = zext i1 %13275 to i8
  store i8 %13276, i8* %17, align 1
  %13277 = trunc i64 %13272 to i32
  %13278 = and i32 %13277, 255
  %13279 = tail call i32 @llvm.ctpop.i32(i32 %13278)
  %13280 = trunc i32 %13279 to i8
  %13281 = and i8 %13280, 1
  %13282 = xor i8 %13281, 1
  store i8 %13282, i8* %18, align 1
  %13283 = xor i64 %13240, %13272
  %13284 = lshr i64 %13283, 4
  %13285 = trunc i64 %13284 to i8
  %13286 = and i8 %13285, 1
  store i8 %13286, i8* %19, align 1
  %13287 = icmp eq i64 %13272, 0
  %13288 = zext i1 %13287 to i8
  store i8 %13288, i8* %20, align 1
  %13289 = lshr i64 %13272, 63
  %13290 = trunc i64 %13289 to i8
  store i8 %13290, i8* %21, align 1
  %13291 = lshr i64 %13270, 58
  %13292 = and i64 %13291, 1
  %13293 = xor i64 %13289, %13257
  %13294 = xor i64 %13289, %13292
  %13295 = add nuw nsw i64 %13293, %13294
  %13296 = icmp eq i64 %13295, 2
  %13297 = zext i1 %13296 to i8
  store i8 %13297, i8* %22, align 1
  %13298 = load i64, i64* %RBP.i, align 8
  %13299 = add i64 %13298, -44
  %13300 = add i64 %13209, 40
  store i64 %13300, i64* %3, align 8
  %13301 = inttoptr i64 %13299 to i32*
  %13302 = load i32, i32* %13301, align 4
  %13303 = sext i32 %13302 to i64
  store i64 %13303, i64* %RCX.i1588, align 8
  %13304 = shl nsw i64 %13303, 1
  %13305 = add i64 %13304, %13272
  %13306 = add i64 %13209, 44
  store i64 %13306, i64* %3, align 8
  %13307 = inttoptr i64 %13305 to i16*
  %13308 = load i16, i16* %13307, align 2
  store i16 %13308, i16* %DX.i4863, align 2
  %13309 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %13310 = add i64 %13309, 12600
  store i64 %13310, i64* %RAX.i1659, align 8
  %13311 = icmp ugt i64 %13309, -12601
  %13312 = zext i1 %13311 to i8
  store i8 %13312, i8* %17, align 1
  %13313 = trunc i64 %13310 to i32
  %13314 = and i32 %13313, 255
  %13315 = tail call i32 @llvm.ctpop.i32(i32 %13314)
  %13316 = trunc i32 %13315 to i8
  %13317 = and i8 %13316, 1
  %13318 = xor i8 %13317, 1
  store i8 %13318, i8* %18, align 1
  %13319 = xor i64 %13309, 16
  %13320 = xor i64 %13319, %13310
  %13321 = lshr i64 %13320, 4
  %13322 = trunc i64 %13321 to i8
  %13323 = and i8 %13322, 1
  store i8 %13323, i8* %19, align 1
  %13324 = icmp eq i64 %13310, 0
  %13325 = zext i1 %13324 to i8
  store i8 %13325, i8* %20, align 1
  %13326 = lshr i64 %13310, 63
  %13327 = trunc i64 %13326 to i8
  store i8 %13327, i8* %21, align 1
  %13328 = lshr i64 %13309, 63
  %13329 = xor i64 %13326, %13328
  %13330 = add nuw nsw i64 %13329, %13326
  %13331 = icmp eq i64 %13330, 2
  %13332 = zext i1 %13331 to i8
  store i8 %13332, i8* %22, align 1
  %13333 = add i64 %13298, -220
  %13334 = add i64 %13209, 64
  store i64 %13334, i64* %3, align 8
  %13335 = inttoptr i64 %13333 to i32*
  %13336 = load i32, i32* %13335, align 4
  %13337 = zext i32 %13336 to i64
  store i64 %13337, i64* %RSI.i2015, align 8
  %13338 = add i64 %13209, 67
  store i64 %13338, i64* %3, align 8
  %13339 = load i32, i32* %13301, align 4
  %13340 = add i32 %13339, %13336
  %13341 = zext i32 %13340 to i64
  store i64 %13341, i64* %RSI.i2015, align 8
  %13342 = sext i32 %13340 to i64
  %13343 = shl nsw i64 %13342, 5
  store i64 %13343, i64* %RCX.i1588, align 8
  %13344 = load i64, i64* %RAX.i1659, align 8
  %13345 = add i64 %13343, %13344
  store i64 %13345, i64* %RAX.i1659, align 8
  %13346 = icmp ult i64 %13345, %13344
  %13347 = icmp ult i64 %13345, %13343
  %13348 = or i1 %13346, %13347
  %13349 = zext i1 %13348 to i8
  store i8 %13349, i8* %17, align 1
  %13350 = trunc i64 %13345 to i32
  %13351 = and i32 %13350, 255
  %13352 = tail call i32 @llvm.ctpop.i32(i32 %13351)
  %13353 = trunc i32 %13352 to i8
  %13354 = and i8 %13353, 1
  %13355 = xor i8 %13354, 1
  store i8 %13355, i8* %18, align 1
  %13356 = xor i64 %13344, %13345
  %13357 = lshr i64 %13356, 4
  %13358 = trunc i64 %13357 to i8
  %13359 = and i8 %13358, 1
  store i8 %13359, i8* %19, align 1
  %13360 = icmp eq i64 %13345, 0
  %13361 = zext i1 %13360 to i8
  store i8 %13361, i8* %20, align 1
  %13362 = lshr i64 %13345, 63
  %13363 = trunc i64 %13362 to i8
  store i8 %13363, i8* %21, align 1
  %13364 = lshr i64 %13344, 63
  %13365 = lshr i64 %13342, 58
  %13366 = and i64 %13365, 1
  %13367 = xor i64 %13362, %13364
  %13368 = xor i64 %13362, %13366
  %13369 = add nuw nsw i64 %13367, %13368
  %13370 = icmp eq i64 %13369, 2
  %13371 = zext i1 %13370 to i8
  store i8 %13371, i8* %22, align 1
  %13372 = load i64, i64* %RBP.i, align 8
  %13373 = add i64 %13372, -224
  %13374 = add i64 %13209, 83
  store i64 %13374, i64* %3, align 8
  %13375 = inttoptr i64 %13373 to i32*
  %13376 = load i32, i32* %13375, align 4
  %13377 = zext i32 %13376 to i64
  store i64 %13377, i64* %RSI.i2015, align 8
  %13378 = add i64 %13372, -48
  %13379 = add i64 %13209, 86
  store i64 %13379, i64* %3, align 8
  %13380 = inttoptr i64 %13378 to i32*
  %13381 = load i32, i32* %13380, align 4
  %13382 = add i32 %13381, %13376
  %13383 = zext i32 %13382 to i64
  store i64 %13383, i64* %RSI.i2015, align 8
  %13384 = icmp ult i32 %13382, %13376
  %13385 = icmp ult i32 %13382, %13381
  %13386 = or i1 %13384, %13385
  %13387 = zext i1 %13386 to i8
  store i8 %13387, i8* %17, align 1
  %13388 = and i32 %13382, 255
  %13389 = tail call i32 @llvm.ctpop.i32(i32 %13388)
  %13390 = trunc i32 %13389 to i8
  %13391 = and i8 %13390, 1
  %13392 = xor i8 %13391, 1
  store i8 %13392, i8* %18, align 1
  %13393 = xor i32 %13381, %13376
  %13394 = xor i32 %13393, %13382
  %13395 = lshr i32 %13394, 4
  %13396 = trunc i32 %13395 to i8
  %13397 = and i8 %13396, 1
  store i8 %13397, i8* %19, align 1
  %13398 = icmp eq i32 %13382, 0
  %13399 = zext i1 %13398 to i8
  store i8 %13399, i8* %20, align 1
  %13400 = lshr i32 %13382, 31
  %13401 = trunc i32 %13400 to i8
  store i8 %13401, i8* %21, align 1
  %13402 = lshr i32 %13376, 31
  %13403 = lshr i32 %13381, 31
  %13404 = xor i32 %13400, %13402
  %13405 = xor i32 %13400, %13403
  %13406 = add nuw nsw i32 %13404, %13405
  %13407 = icmp eq i32 %13406, 2
  %13408 = zext i1 %13407 to i8
  store i8 %13408, i8* %22, align 1
  %13409 = sext i32 %13382 to i64
  store i64 %13409, i64* %RCX.i1588, align 8
  %13410 = shl nsw i64 %13409, 1
  %13411 = add i64 %13345, %13410
  %13412 = load i16, i16* %DX.i4863, align 2
  %13413 = add i64 %13209, 93
  store i64 %13413, i64* %3, align 8
  %13414 = inttoptr i64 %13411 to i16*
  store i16 %13412, i16* %13414, align 2
  %13415 = load i64, i64* %3, align 8
  %13416 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %13416, i64* %RAX.i1659, align 8
  %13417 = load i64, i64* %RBP.i, align 8
  %13418 = add i64 %13417, -240
  %13419 = add i64 %13415, 14
  store i64 %13419, i64* %3, align 8
  %13420 = inttoptr i64 %13418 to i32*
  %13421 = load i32, i32* %13420, align 4
  %13422 = zext i32 %13421 to i64
  store i64 %13422, i64* %RSI.i2015, align 8
  %13423 = add i64 %13417, -48
  %13424 = add i64 %13415, 17
  store i64 %13424, i64* %3, align 8
  %13425 = inttoptr i64 %13423 to i32*
  %13426 = load i32, i32* %13425, align 4
  %13427 = add i32 %13426, %13421
  %13428 = zext i32 %13427 to i64
  store i64 %13428, i64* %RSI.i2015, align 8
  %13429 = icmp ult i32 %13427, %13421
  %13430 = icmp ult i32 %13427, %13426
  %13431 = or i1 %13429, %13430
  %13432 = zext i1 %13431 to i8
  store i8 %13432, i8* %17, align 1
  %13433 = and i32 %13427, 255
  %13434 = tail call i32 @llvm.ctpop.i32(i32 %13433)
  %13435 = trunc i32 %13434 to i8
  %13436 = and i8 %13435, 1
  %13437 = xor i8 %13436, 1
  store i8 %13437, i8* %18, align 1
  %13438 = xor i32 %13426, %13421
  %13439 = xor i32 %13438, %13427
  %13440 = lshr i32 %13439, 4
  %13441 = trunc i32 %13440 to i8
  %13442 = and i8 %13441, 1
  store i8 %13442, i8* %19, align 1
  %13443 = icmp eq i32 %13427, 0
  %13444 = zext i1 %13443 to i8
  store i8 %13444, i8* %20, align 1
  %13445 = lshr i32 %13427, 31
  %13446 = trunc i32 %13445 to i8
  store i8 %13446, i8* %21, align 1
  %13447 = lshr i32 %13421, 31
  %13448 = lshr i32 %13426, 31
  %13449 = xor i32 %13445, %13447
  %13450 = xor i32 %13445, %13448
  %13451 = add nuw nsw i32 %13449, %13450
  %13452 = icmp eq i32 %13451, 2
  %13453 = zext i1 %13452 to i8
  store i8 %13453, i8* %22, align 1
  %13454 = sext i32 %13427 to i64
  store i64 %13454, i64* %RCX.i1588, align 8
  %13455 = shl nsw i64 %13454, 3
  %13456 = add i64 %13416, %13455
  %13457 = add i64 %13415, 24
  store i64 %13457, i64* %3, align 8
  %13458 = inttoptr i64 %13456 to i64*
  %13459 = load i64, i64* %13458, align 8
  store i64 %13459, i64* %RAX.i1659, align 8
  %13460 = add i64 %13417, -236
  %13461 = add i64 %13415, 30
  store i64 %13461, i64* %3, align 8
  %13462 = inttoptr i64 %13460 to i32*
  %13463 = load i32, i32* %13462, align 4
  %13464 = zext i32 %13463 to i64
  store i64 %13464, i64* %RSI.i2015, align 8
  %13465 = add i64 %13417, -44
  %13466 = add i64 %13415, 33
  store i64 %13466, i64* %3, align 8
  %13467 = inttoptr i64 %13465 to i32*
  %13468 = load i32, i32* %13467, align 4
  %13469 = add i32 %13468, %13463
  %13470 = zext i32 %13469 to i64
  store i64 %13470, i64* %RSI.i2015, align 8
  %13471 = icmp ult i32 %13469, %13463
  %13472 = icmp ult i32 %13469, %13468
  %13473 = or i1 %13471, %13472
  %13474 = zext i1 %13473 to i8
  store i8 %13474, i8* %17, align 1
  %13475 = and i32 %13469, 255
  %13476 = tail call i32 @llvm.ctpop.i32(i32 %13475)
  %13477 = trunc i32 %13476 to i8
  %13478 = and i8 %13477, 1
  %13479 = xor i8 %13478, 1
  store i8 %13479, i8* %18, align 1
  %13480 = xor i32 %13468, %13463
  %13481 = xor i32 %13480, %13469
  %13482 = lshr i32 %13481, 4
  %13483 = trunc i32 %13482 to i8
  %13484 = and i8 %13483, 1
  store i8 %13484, i8* %19, align 1
  %13485 = icmp eq i32 %13469, 0
  %13486 = zext i1 %13485 to i8
  store i8 %13486, i8* %20, align 1
  %13487 = lshr i32 %13469, 31
  %13488 = trunc i32 %13487 to i8
  store i8 %13488, i8* %21, align 1
  %13489 = lshr i32 %13463, 31
  %13490 = lshr i32 %13468, 31
  %13491 = xor i32 %13487, %13489
  %13492 = xor i32 %13487, %13490
  %13493 = add nuw nsw i32 %13491, %13492
  %13494 = icmp eq i32 %13493, 2
  %13495 = zext i1 %13494 to i8
  store i8 %13495, i8* %22, align 1
  %13496 = sext i32 %13469 to i64
  store i64 %13496, i64* %RCX.i1588, align 8
  %13497 = shl nsw i64 %13496, 1
  %13498 = add i64 %13459, %13497
  %13499 = add i64 %13415, 40
  store i64 %13499, i64* %3, align 8
  %13500 = inttoptr i64 %13498 to i16*
  %13501 = load i16, i16* %13500, align 2
  %13502 = zext i16 %13501 to i64
  store i64 %13502, i64* %RSI.i2015, align 8
  %13503 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %13504 = add i64 %13503, 184
  store i64 %13504, i64* %RAX.i1659, align 8
  %13505 = icmp ugt i64 %13503, -185
  %13506 = zext i1 %13505 to i8
  store i8 %13506, i8* %17, align 1
  %13507 = trunc i64 %13504 to i32
  %13508 = and i32 %13507, 255
  %13509 = tail call i32 @llvm.ctpop.i32(i32 %13508)
  %13510 = trunc i32 %13509 to i8
  %13511 = and i8 %13510, 1
  %13512 = xor i8 %13511, 1
  store i8 %13512, i8* %18, align 1
  %13513 = xor i64 %13503, 16
  %13514 = xor i64 %13513, %13504
  %13515 = lshr i64 %13514, 4
  %13516 = trunc i64 %13515 to i8
  %13517 = and i8 %13516, 1
  store i8 %13517, i8* %19, align 1
  %13518 = icmp eq i64 %13504, 0
  %13519 = zext i1 %13518 to i8
  store i8 %13519, i8* %20, align 1
  %13520 = lshr i64 %13504, 63
  %13521 = trunc i64 %13520 to i8
  store i8 %13521, i8* %21, align 1
  %13522 = lshr i64 %13503, 63
  %13523 = xor i64 %13520, %13522
  %13524 = add nuw nsw i64 %13523, %13520
  %13525 = icmp eq i64 %13524, 2
  %13526 = zext i1 %13525 to i8
  store i8 %13526, i8* %22, align 1
  %13527 = load i64, i64* %RBP.i, align 8
  %13528 = add i64 %13527, -40
  %13529 = add i64 %13415, 58
  store i64 %13529, i64* %3, align 8
  %13530 = inttoptr i64 %13528 to i32*
  %13531 = load i32, i32* %13530, align 4
  %13532 = sext i32 %13531 to i64
  %13533 = shl nsw i64 %13532, 9
  store i64 %13533, i64* %RCX.i1588, align 8
  %13534 = add i64 %13533, %13504
  store i64 %13534, i64* %RAX.i1659, align 8
  %13535 = icmp ult i64 %13534, %13504
  %13536 = icmp ult i64 %13534, %13533
  %13537 = or i1 %13535, %13536
  %13538 = zext i1 %13537 to i8
  store i8 %13538, i8* %17, align 1
  %13539 = trunc i64 %13534 to i32
  %13540 = and i32 %13539, 255
  %13541 = tail call i32 @llvm.ctpop.i32(i32 %13540)
  %13542 = trunc i32 %13541 to i8
  %13543 = and i8 %13542, 1
  %13544 = xor i8 %13543, 1
  store i8 %13544, i8* %18, align 1
  %13545 = xor i64 %13504, %13534
  %13546 = lshr i64 %13545, 4
  %13547 = trunc i64 %13546 to i8
  %13548 = and i8 %13547, 1
  store i8 %13548, i8* %19, align 1
  %13549 = icmp eq i64 %13534, 0
  %13550 = zext i1 %13549 to i8
  store i8 %13550, i8* %20, align 1
  %13551 = lshr i64 %13534, 63
  %13552 = trunc i64 %13551 to i8
  store i8 %13552, i8* %21, align 1
  %13553 = lshr i64 %13532, 54
  %13554 = and i64 %13553, 1
  %13555 = xor i64 %13551, %13520
  %13556 = xor i64 %13551, %13554
  %13557 = add nuw nsw i64 %13555, %13556
  %13558 = icmp eq i64 %13557, 2
  %13559 = zext i1 %13558 to i8
  store i8 %13559, i8* %22, align 1
  %13560 = add i64 %13527, -48
  %13561 = add i64 %13415, 69
  store i64 %13561, i64* %3, align 8
  %13562 = inttoptr i64 %13560 to i32*
  %13563 = load i32, i32* %13562, align 4
  %13564 = sext i32 %13563 to i64
  %13565 = shl nsw i64 %13564, 5
  store i64 %13565, i64* %RCX.i1588, align 8
  %13566 = add i64 %13565, %13534
  store i64 %13566, i64* %RAX.i1659, align 8
  %13567 = icmp ult i64 %13566, %13534
  %13568 = icmp ult i64 %13566, %13565
  %13569 = or i1 %13567, %13568
  %13570 = zext i1 %13569 to i8
  store i8 %13570, i8* %17, align 1
  %13571 = trunc i64 %13566 to i32
  %13572 = and i32 %13571, 255
  %13573 = tail call i32 @llvm.ctpop.i32(i32 %13572)
  %13574 = trunc i32 %13573 to i8
  %13575 = and i8 %13574, 1
  %13576 = xor i8 %13575, 1
  store i8 %13576, i8* %18, align 1
  %13577 = xor i64 %13534, %13566
  %13578 = lshr i64 %13577, 4
  %13579 = trunc i64 %13578 to i8
  %13580 = and i8 %13579, 1
  store i8 %13580, i8* %19, align 1
  %13581 = icmp eq i64 %13566, 0
  %13582 = zext i1 %13581 to i8
  store i8 %13582, i8* %20, align 1
  %13583 = lshr i64 %13566, 63
  %13584 = trunc i64 %13583 to i8
  store i8 %13584, i8* %21, align 1
  %13585 = lshr i64 %13564, 58
  %13586 = and i64 %13585, 1
  %13587 = xor i64 %13583, %13551
  %13588 = xor i64 %13583, %13586
  %13589 = add nuw nsw i64 %13587, %13588
  %13590 = icmp eq i64 %13589, 2
  %13591 = zext i1 %13590 to i8
  store i8 %13591, i8* %22, align 1
  %13592 = load i64, i64* %RBP.i, align 8
  %13593 = add i64 %13592, -44
  %13594 = add i64 %13415, 80
  store i64 %13594, i64* %3, align 8
  %13595 = inttoptr i64 %13593 to i32*
  %13596 = load i32, i32* %13595, align 4
  %13597 = sext i32 %13596 to i64
  store i64 %13597, i64* %RCX.i1588, align 8
  %13598 = shl nsw i64 %13597, 1
  %13599 = add i64 %13598, %13566
  %13600 = add i64 %13415, 84
  store i64 %13600, i64* %3, align 8
  %13601 = inttoptr i64 %13599 to i16*
  %13602 = load i16, i16* %13601, align 2
  %13603 = zext i16 %13602 to i64
  store i64 %13603, i64* %RDI.i6998, align 8
  %13604 = load i64, i64* %RSI.i2015, align 8
  %13605 = zext i16 %13602 to i64
  %13606 = sub i64 %13604, %13605
  %13607 = and i64 %13606, 4294967295
  store i64 %13607, i64* %RSI.i2015, align 8
  %13608 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %13609 = add i64 %13608, 13112
  store i64 %13609, i64* %RAX.i1659, align 8
  %13610 = icmp ugt i64 %13608, -13113
  %13611 = zext i1 %13610 to i8
  store i8 %13611, i8* %17, align 1
  %13612 = trunc i64 %13609 to i32
  %13613 = and i32 %13612, 255
  %13614 = tail call i32 @llvm.ctpop.i32(i32 %13613)
  %13615 = trunc i32 %13614 to i8
  %13616 = and i8 %13615, 1
  %13617 = xor i8 %13616, 1
  store i8 %13617, i8* %18, align 1
  %13618 = xor i64 %13608, 16
  %13619 = xor i64 %13618, %13609
  %13620 = lshr i64 %13619, 4
  %13621 = trunc i64 %13620 to i8
  %13622 = and i8 %13621, 1
  store i8 %13622, i8* %19, align 1
  %13623 = icmp eq i64 %13609, 0
  %13624 = zext i1 %13623 to i8
  store i8 %13624, i8* %20, align 1
  %13625 = lshr i64 %13609, 63
  %13626 = trunc i64 %13625 to i8
  store i8 %13626, i8* %21, align 1
  %13627 = lshr i64 %13608, 63
  %13628 = xor i64 %13625, %13627
  %13629 = add nuw nsw i64 %13628, %13625
  %13630 = icmp eq i64 %13629, 2
  %13631 = zext i1 %13630 to i8
  store i8 %13631, i8* %22, align 1
  %13632 = add i64 %13415, 104
  store i64 %13632, i64* %3, align 8
  %13633 = load i32, i32* %13595, align 4
  %13634 = sext i32 %13633 to i64
  %13635 = shl nsw i64 %13634, 6
  store i64 %13635, i64* %RCX.i1588, align 8
  %13636 = add i64 %13635, %13609
  store i64 %13636, i64* %RAX.i1659, align 8
  %13637 = icmp ult i64 %13636, %13609
  %13638 = icmp ult i64 %13636, %13635
  %13639 = or i1 %13637, %13638
  %13640 = zext i1 %13639 to i8
  store i8 %13640, i8* %17, align 1
  %13641 = trunc i64 %13636 to i32
  %13642 = and i32 %13641, 255
  %13643 = tail call i32 @llvm.ctpop.i32(i32 %13642)
  %13644 = trunc i32 %13643 to i8
  %13645 = and i8 %13644, 1
  %13646 = xor i8 %13645, 1
  store i8 %13646, i8* %18, align 1
  %13647 = xor i64 %13609, %13636
  %13648 = lshr i64 %13647, 4
  %13649 = trunc i64 %13648 to i8
  %13650 = and i8 %13649, 1
  store i8 %13650, i8* %19, align 1
  %13651 = icmp eq i64 %13636, 0
  %13652 = zext i1 %13651 to i8
  store i8 %13652, i8* %20, align 1
  %13653 = lshr i64 %13636, 63
  %13654 = trunc i64 %13653 to i8
  store i8 %13654, i8* %21, align 1
  %13655 = lshr i64 %13634, 57
  %13656 = and i64 %13655, 1
  %13657 = xor i64 %13653, %13625
  %13658 = xor i64 %13653, %13656
  %13659 = add nuw nsw i64 %13657, %13658
  %13660 = icmp eq i64 %13659, 2
  %13661 = zext i1 %13660 to i8
  store i8 %13661, i8* %22, align 1
  %13662 = load i64, i64* %RBP.i, align 8
  %13663 = add i64 %13662, -48
  %13664 = add i64 %13415, 115
  store i64 %13664, i64* %3, align 8
  %13665 = inttoptr i64 %13663 to i32*
  %13666 = load i32, i32* %13665, align 4
  %13667 = sext i32 %13666 to i64
  store i64 %13667, i64* %RCX.i1588, align 8
  %13668 = shl nsw i64 %13667, 2
  %13669 = add i64 %13668, %13636
  %13670 = load i32, i32* %ESI.i1759, align 4
  %13671 = add i64 %13415, 118
  store i64 %13671, i64* %3, align 8
  %13672 = inttoptr i64 %13669 to i32*
  store i32 %13670, i32* %13672, align 4
  %13673 = load i64, i64* %RBP.i, align 8
  %13674 = add i64 %13673, -44
  %13675 = load i64, i64* %3, align 8
  %13676 = add i64 %13675, 3
  store i64 %13676, i64* %3, align 8
  %13677 = inttoptr i64 %13674 to i32*
  %13678 = load i32, i32* %13677, align 4
  %13679 = add i32 %13678, 1
  %13680 = zext i32 %13679 to i64
  store i64 %13680, i64* %RAX.i1659, align 8
  %13681 = icmp eq i32 %13678, -1
  %13682 = icmp eq i32 %13679, 0
  %13683 = or i1 %13681, %13682
  %13684 = zext i1 %13683 to i8
  store i8 %13684, i8* %17, align 1
  %13685 = and i32 %13679, 255
  %13686 = tail call i32 @llvm.ctpop.i32(i32 %13685)
  %13687 = trunc i32 %13686 to i8
  %13688 = and i8 %13687, 1
  %13689 = xor i8 %13688, 1
  store i8 %13689, i8* %18, align 1
  %13690 = xor i32 %13679, %13678
  %13691 = lshr i32 %13690, 4
  %13692 = trunc i32 %13691 to i8
  %13693 = and i8 %13692, 1
  store i8 %13693, i8* %19, align 1
  %13694 = zext i1 %13682 to i8
  store i8 %13694, i8* %20, align 1
  %13695 = lshr i32 %13679, 31
  %13696 = trunc i32 %13695 to i8
  store i8 %13696, i8* %21, align 1
  %13697 = lshr i32 %13678, 31
  %13698 = xor i32 %13695, %13697
  %13699 = add nuw nsw i32 %13698, %13695
  %13700 = icmp eq i32 %13699, 2
  %13701 = zext i1 %13700 to i8
  store i8 %13701, i8* %22, align 1
  %13702 = add i64 %13675, 9
  store i64 %13702, i64* %3, align 8
  store i32 %13679, i32* %13677, align 4
  %13703 = load i64, i64* %3, align 8
  %13704 = add i64 %13703, -230
  store i64 %13704, i64* %3, align 8
  br label %block_.L_4857b7

block_.L_4858a2:                                  ; preds = %block_.L_4857b7
  %13705 = add i64 %13181, -48
  %13706 = add i64 %13209, 8
  store i64 %13706, i64* %3, align 8
  %13707 = inttoptr i64 %13705 to i32*
  %13708 = load i32, i32* %13707, align 4
  %13709 = add i32 %13708, 1
  %13710 = zext i32 %13709 to i64
  store i64 %13710, i64* %RAX.i1659, align 8
  %13711 = icmp eq i32 %13708, -1
  %13712 = icmp eq i32 %13709, 0
  %13713 = or i1 %13711, %13712
  %13714 = zext i1 %13713 to i8
  store i8 %13714, i8* %17, align 1
  %13715 = and i32 %13709, 255
  %13716 = tail call i32 @llvm.ctpop.i32(i32 %13715)
  %13717 = trunc i32 %13716 to i8
  %13718 = and i8 %13717, 1
  %13719 = xor i8 %13718, 1
  store i8 %13719, i8* %18, align 1
  %13720 = xor i32 %13709, %13708
  %13721 = lshr i32 %13720, 4
  %13722 = trunc i32 %13721 to i8
  %13723 = and i8 %13722, 1
  store i8 %13723, i8* %19, align 1
  %13724 = zext i1 %13712 to i8
  store i8 %13724, i8* %20, align 1
  %13725 = lshr i32 %13709, 31
  %13726 = trunc i32 %13725 to i8
  store i8 %13726, i8* %21, align 1
  %13727 = lshr i32 %13708, 31
  %13728 = xor i32 %13725, %13727
  %13729 = add nuw nsw i32 %13728, %13725
  %13730 = icmp eq i32 %13729, 2
  %13731 = zext i1 %13730 to i8
  store i8 %13731, i8* %22, align 1
  %13732 = add i64 %13209, 14
  store i64 %13732, i64* %3, align 8
  store i32 %13709, i32* %13707, align 4
  %13733 = load i64, i64* %3, align 8
  %13734 = add i64 %13733, -266
  store i64 %13734, i64* %3, align 8
  br label %block_.L_4857a6

block_.L_4858b5:                                  ; preds = %block_.L_4857a6
  %13735 = add i64 %13148, -68
  store i64 %13735, i64* %RDX.i1943, align 8
  store i64 1, i64* %RCX.i1588, align 8
  %13736 = add i64 %13148, -220
  %13737 = add i64 %13176, 15
  store i64 %13737, i64* %3, align 8
  %13738 = inttoptr i64 %13736 to i32*
  %13739 = load i32, i32* %13738, align 4
  %13740 = zext i32 %13739 to i64
  store i64 %13740, i64* %RDI.i6998, align 8
  %13741 = add i64 %13148, -224
  %13742 = add i64 %13176, 21
  store i64 %13742, i64* %3, align 8
  %13743 = inttoptr i64 %13741 to i32*
  %13744 = load i32, i32* %13743, align 4
  %13745 = zext i32 %13744 to i64
  store i64 %13745, i64* %RSI.i2015, align 8
  %13746 = add i64 %13176, -521829
  %13747 = add i64 %13176, 26
  %13748 = load i64, i64* %6, align 8
  %13749 = add i64 %13748, -8
  %13750 = inttoptr i64 %13749 to i64*
  store i64 %13747, i64* %13750, align 8
  store i64 %13749, i64* %6, align 8
  store i64 %13746, i64* %3, align 8
  %call2_4858ca = tail call %struct.Memory* @sub_406250.dct_luma(%struct.State* nonnull %0, i64 %13746, %struct.Memory* %MEMORY.8)
  %13751 = load i64, i64* %RBP.i, align 8
  %13752 = add i64 %13751, -76
  %13753 = load i32, i32* %EAX.i2033, align 4
  %13754 = load i64, i64* %3, align 8
  %13755 = add i64 %13754, 3
  store i64 %13755, i64* %3, align 8
  %13756 = inttoptr i64 %13752 to i32*
  store i32 %13753, i32* %13756, align 4
  %13757 = load i64, i64* %3, align 8
  %13758 = add i64 %13757, 3636
  %.pre561.pre = load i64, i64* %RBP.i, align 8
  br label %block_.L_486706

block_.L_4858de:                                  ; preds = %block_.L_4858de.preheader, %block_.L_485b1c
  %13759 = phi i64 [ %15015, %block_.L_485b1c ], [ %.pre471, %block_.L_4858de.preheader ]
  %13760 = load i64, i64* %RBP.i, align 8
  %13761 = add i64 %13760, -48
  %13762 = add i64 %13759, 4
  store i64 %13762, i64* %3, align 8
  %13763 = inttoptr i64 %13761 to i32*
  %13764 = load i32, i32* %13763, align 4
  %13765 = add i32 %13764, -4
  %13766 = icmp ult i32 %13764, 4
  %13767 = zext i1 %13766 to i8
  store i8 %13767, i8* %17, align 1
  %13768 = and i32 %13765, 255
  %13769 = tail call i32 @llvm.ctpop.i32(i32 %13768)
  %13770 = trunc i32 %13769 to i8
  %13771 = and i8 %13770, 1
  %13772 = xor i8 %13771, 1
  store i8 %13772, i8* %18, align 1
  %13773 = xor i32 %13765, %13764
  %13774 = lshr i32 %13773, 4
  %13775 = trunc i32 %13774 to i8
  %13776 = and i8 %13775, 1
  store i8 %13776, i8* %19, align 1
  %13777 = icmp eq i32 %13765, 0
  %13778 = zext i1 %13777 to i8
  store i8 %13778, i8* %20, align 1
  %13779 = lshr i32 %13765, 31
  %13780 = trunc i32 %13779 to i8
  store i8 %13780, i8* %21, align 1
  %13781 = lshr i32 %13764, 31
  %13782 = xor i32 %13779, %13781
  %13783 = add nuw nsw i32 %13782, %13781
  %13784 = icmp eq i32 %13783, 2
  %13785 = zext i1 %13784 to i8
  store i8 %13785, i8* %22, align 1
  %13786 = icmp ne i8 %13780, 0
  %13787 = xor i1 %13786, %13784
  %.v710 = select i1 %13787, i64 10, i64 593
  %13788 = add i64 %13759, %.v710
  store i64 %13788, i64* %3, align 8
  br i1 %13787, label %block_4858e8, label %block_.L_485b2f

block_4858e8:                                     ; preds = %block_.L_4858de
  %13789 = add i64 %13760, -44
  %13790 = add i64 %13788, 7
  store i64 %13790, i64* %3, align 8
  %13791 = inttoptr i64 %13789 to i32*
  store i32 0, i32* %13791, align 4
  %.pre551 = load i64, i64* %3, align 8
  br label %block_.L_4858ef

block_.L_4858ef:                                  ; preds = %block_4858f9, %block_4858e8
  %13792 = phi i64 [ %14985, %block_4858f9 ], [ %.pre551, %block_4858e8 ]
  %13793 = load i64, i64* %RBP.i, align 8
  %13794 = add i64 %13793, -44
  %13795 = add i64 %13792, 4
  store i64 %13795, i64* %3, align 8
  %13796 = inttoptr i64 %13794 to i32*
  %13797 = load i32, i32* %13796, align 4
  %13798 = add i32 %13797, -4
  %13799 = icmp ult i32 %13797, 4
  %13800 = zext i1 %13799 to i8
  store i8 %13800, i8* %17, align 1
  %13801 = and i32 %13798, 255
  %13802 = tail call i32 @llvm.ctpop.i32(i32 %13801)
  %13803 = trunc i32 %13802 to i8
  %13804 = and i8 %13803, 1
  %13805 = xor i8 %13804, 1
  store i8 %13805, i8* %18, align 1
  %13806 = xor i32 %13798, %13797
  %13807 = lshr i32 %13806, 4
  %13808 = trunc i32 %13807 to i8
  %13809 = and i8 %13808, 1
  store i8 %13809, i8* %19, align 1
  %13810 = icmp eq i32 %13798, 0
  %13811 = zext i1 %13810 to i8
  store i8 %13811, i8* %20, align 1
  %13812 = lshr i32 %13798, 31
  %13813 = trunc i32 %13812 to i8
  store i8 %13813, i8* %21, align 1
  %13814 = lshr i32 %13797, 31
  %13815 = xor i32 %13812, %13814
  %13816 = add nuw nsw i32 %13815, %13814
  %13817 = icmp eq i32 %13816, 2
  %13818 = zext i1 %13817 to i8
  store i8 %13818, i8* %22, align 1
  %13819 = icmp ne i8 %13813, 0
  %13820 = xor i1 %13819, %13817
  %.v664 = select i1 %13820, i64 10, i64 557
  %13821 = add i64 %13792, %.v664
  store i64 %13821, i64* %3, align 8
  br i1 %13820, label %block_4858f9, label %block_.L_485b1c

block_4858f9:                                     ; preds = %block_.L_4858ef
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX.i1659, align 8
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RCX.i1588, align 8
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RDX.i1943, align 8
  %13822 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %13822, i64* %RSI.i2015, align 8
  %13823 = add i64 %13821, 41
  store i64 %13823, i64* %3, align 8
  %13824 = inttoptr i64 %13822 to i64*
  %13825 = load i64, i64* %13824, align 8
  store i64 %13825, i64* %RSI.i2015, align 8
  %13826 = add i64 %13793, -240
  %13827 = add i64 %13821, 47
  store i64 %13827, i64* %3, align 8
  %13828 = inttoptr i64 %13826 to i32*
  %13829 = load i32, i32* %13828, align 4
  %13830 = zext i32 %13829 to i64
  store i64 %13830, i64* %RDI.i6998, align 8
  %13831 = add i64 %13793, -48
  %13832 = add i64 %13821, 50
  store i64 %13832, i64* %3, align 8
  %13833 = inttoptr i64 %13831 to i32*
  %13834 = load i32, i32* %13833, align 4
  %13835 = add i32 %13834, %13829
  %13836 = zext i32 %13835 to i64
  store i64 %13836, i64* %RDI.i6998, align 8
  %13837 = icmp ult i32 %13835, %13829
  %13838 = icmp ult i32 %13835, %13834
  %13839 = or i1 %13837, %13838
  %13840 = zext i1 %13839 to i8
  store i8 %13840, i8* %17, align 1
  %13841 = and i32 %13835, 255
  %13842 = tail call i32 @llvm.ctpop.i32(i32 %13841)
  %13843 = trunc i32 %13842 to i8
  %13844 = and i8 %13843, 1
  %13845 = xor i8 %13844, 1
  store i8 %13845, i8* %18, align 1
  %13846 = xor i32 %13834, %13829
  %13847 = xor i32 %13846, %13835
  %13848 = lshr i32 %13847, 4
  %13849 = trunc i32 %13848 to i8
  %13850 = and i8 %13849, 1
  store i8 %13850, i8* %19, align 1
  %13851 = icmp eq i32 %13835, 0
  %13852 = zext i1 %13851 to i8
  store i8 %13852, i8* %20, align 1
  %13853 = lshr i32 %13835, 31
  %13854 = trunc i32 %13853 to i8
  store i8 %13854, i8* %21, align 1
  %13855 = lshr i32 %13829, 31
  %13856 = lshr i32 %13834, 31
  %13857 = xor i32 %13853, %13855
  %13858 = xor i32 %13853, %13856
  %13859 = add nuw nsw i32 %13857, %13858
  %13860 = icmp eq i32 %13859, 2
  %13861 = zext i1 %13860 to i8
  store i8 %13861, i8* %22, align 1
  %13862 = sext i32 %13835 to i64
  store i64 %13862, i64* %25, align 8
  %13863 = shl nsw i64 %13862, 3
  %13864 = add i64 %13825, %13863
  %13865 = add i64 %13821, 57
  store i64 %13865, i64* %3, align 8
  %13866 = inttoptr i64 %13864 to i64*
  %13867 = load i64, i64* %13866, align 8
  store i64 %13867, i64* %RSI.i2015, align 8
  %13868 = add i64 %13793, -236
  %13869 = add i64 %13821, 63
  store i64 %13869, i64* %3, align 8
  %13870 = inttoptr i64 %13868 to i32*
  %13871 = load i32, i32* %13870, align 4
  %13872 = zext i32 %13871 to i64
  store i64 %13872, i64* %RDI.i6998, align 8
  %13873 = add i64 %13821, 66
  store i64 %13873, i64* %3, align 8
  %13874 = load i32, i32* %13796, align 4
  %13875 = add i32 %13874, %13871
  %13876 = zext i32 %13875 to i64
  store i64 %13876, i64* %RDI.i6998, align 8
  %13877 = icmp ult i32 %13875, %13871
  %13878 = icmp ult i32 %13875, %13874
  %13879 = or i1 %13877, %13878
  %13880 = zext i1 %13879 to i8
  store i8 %13880, i8* %17, align 1
  %13881 = and i32 %13875, 255
  %13882 = tail call i32 @llvm.ctpop.i32(i32 %13881)
  %13883 = trunc i32 %13882 to i8
  %13884 = and i8 %13883, 1
  %13885 = xor i8 %13884, 1
  store i8 %13885, i8* %18, align 1
  %13886 = xor i32 %13874, %13871
  %13887 = xor i32 %13886, %13875
  %13888 = lshr i32 %13887, 4
  %13889 = trunc i32 %13888 to i8
  %13890 = and i8 %13889, 1
  store i8 %13890, i8* %19, align 1
  %13891 = icmp eq i32 %13875, 0
  %13892 = zext i1 %13891 to i8
  store i8 %13892, i8* %20, align 1
  %13893 = lshr i32 %13875, 31
  %13894 = trunc i32 %13893 to i8
  store i8 %13894, i8* %21, align 1
  %13895 = lshr i32 %13871, 31
  %13896 = lshr i32 %13874, 31
  %13897 = xor i32 %13893, %13895
  %13898 = xor i32 %13893, %13896
  %13899 = add nuw nsw i32 %13897, %13898
  %13900 = icmp eq i32 %13899, 2
  %13901 = zext i1 %13900 to i8
  store i8 %13901, i8* %22, align 1
  %13902 = sext i32 %13875 to i64
  store i64 %13902, i64* %25, align 8
  %13903 = shl nsw i64 %13902, 1
  %13904 = add i64 %13867, %13903
  %13905 = add i64 %13821, 74
  store i64 %13905, i64* %3, align 8
  %13906 = inttoptr i64 %13904 to i16*
  %13907 = load i16, i16* %13906, align 2
  %13908 = zext i16 %13907 to i64
  store i64 %13908, i64* %RDI.i6998, align 8
  %13909 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %13910 = add i64 %13909, 8504
  store i64 %13910, i64* %RSI.i2015, align 8
  %13911 = icmp ugt i64 %13909, -8505
  %13912 = zext i1 %13911 to i8
  store i8 %13912, i8* %17, align 1
  %13913 = trunc i64 %13910 to i32
  %13914 = and i32 %13913, 255
  %13915 = tail call i32 @llvm.ctpop.i32(i32 %13914)
  %13916 = trunc i32 %13915 to i8
  %13917 = and i8 %13916, 1
  %13918 = xor i8 %13917, 1
  store i8 %13918, i8* %18, align 1
  %13919 = xor i64 %13909, 16
  %13920 = xor i64 %13919, %13910
  %13921 = lshr i64 %13920, 4
  %13922 = trunc i64 %13921 to i8
  %13923 = and i8 %13922, 1
  store i8 %13923, i8* %19, align 1
  %13924 = icmp eq i64 %13910, 0
  %13925 = zext i1 %13924 to i8
  store i8 %13925, i8* %20, align 1
  %13926 = lshr i64 %13910, 63
  %13927 = trunc i64 %13926 to i8
  store i8 %13927, i8* %21, align 1
  %13928 = lshr i64 %13909, 63
  %13929 = xor i64 %13926, %13928
  %13930 = add nuw nsw i64 %13929, %13926
  %13931 = icmp eq i64 %13930, 2
  %13932 = zext i1 %13931 to i8
  store i8 %13932, i8* %22, align 1
  %13933 = load i64, i64* %RBP.i, align 8
  %13934 = add i64 %13933, -364
  %13935 = add i64 %13821, 96
  store i64 %13935, i64* %3, align 8
  %13936 = inttoptr i64 %13934 to i32*
  %13937 = load i32, i32* %13936, align 4
  %13938 = sext i32 %13937 to i64
  %13939 = shl nsw i64 %13938, 9
  store i64 %13939, i64* %25, align 8
  %13940 = add i64 %13939, %13910
  store i64 %13940, i64* %RSI.i2015, align 8
  %13941 = icmp ult i64 %13940, %13910
  %13942 = icmp ult i64 %13940, %13939
  %13943 = or i1 %13941, %13942
  %13944 = zext i1 %13943 to i8
  store i8 %13944, i8* %17, align 1
  %13945 = trunc i64 %13940 to i32
  %13946 = and i32 %13945, 255
  %13947 = tail call i32 @llvm.ctpop.i32(i32 %13946)
  %13948 = trunc i32 %13947 to i8
  %13949 = and i8 %13948, 1
  %13950 = xor i8 %13949, 1
  store i8 %13950, i8* %18, align 1
  %13951 = xor i64 %13910, %13940
  %13952 = lshr i64 %13951, 4
  %13953 = trunc i64 %13952 to i8
  %13954 = and i8 %13953, 1
  store i8 %13954, i8* %19, align 1
  %13955 = icmp eq i64 %13940, 0
  %13956 = zext i1 %13955 to i8
  store i8 %13956, i8* %20, align 1
  %13957 = lshr i64 %13940, 63
  %13958 = trunc i64 %13957 to i8
  store i8 %13958, i8* %21, align 1
  %13959 = lshr i64 %13938, 54
  %13960 = and i64 %13959, 1
  %13961 = xor i64 %13957, %13926
  %13962 = xor i64 %13957, %13960
  %13963 = add nuw nsw i64 %13961, %13962
  %13964 = icmp eq i64 %13963, 2
  %13965 = zext i1 %13964 to i8
  store i8 %13965, i8* %22, align 1
  %13966 = add i64 %13933, -220
  %13967 = add i64 %13821, 110
  store i64 %13967, i64* %3, align 8
  %13968 = inttoptr i64 %13966 to i32*
  %13969 = load i32, i32* %13968, align 4
  %13970 = zext i32 %13969 to i64
  store i64 %13970, i64* %R9.i1633, align 8
  %13971 = add i64 %13933, -44
  %13972 = add i64 %13821, 114
  store i64 %13972, i64* %3, align 8
  %13973 = inttoptr i64 %13971 to i32*
  %13974 = load i32, i32* %13973, align 4
  %13975 = add i32 %13974, %13969
  %13976 = zext i32 %13975 to i64
  store i64 %13976, i64* %R9.i1633, align 8
  %13977 = sext i32 %13975 to i64
  %13978 = shl nsw i64 %13977, 5
  store i64 %13978, i64* %25, align 8
  %13979 = load i64, i64* %RSI.i2015, align 8
  %13980 = add i64 %13978, %13979
  store i64 %13980, i64* %RSI.i2015, align 8
  %13981 = icmp ult i64 %13980, %13979
  %13982 = icmp ult i64 %13980, %13978
  %13983 = or i1 %13981, %13982
  %13984 = zext i1 %13983 to i8
  store i8 %13984, i8* %17, align 1
  %13985 = trunc i64 %13980 to i32
  %13986 = and i32 %13985, 255
  %13987 = tail call i32 @llvm.ctpop.i32(i32 %13986)
  %13988 = trunc i32 %13987 to i8
  %13989 = and i8 %13988, 1
  %13990 = xor i8 %13989, 1
  store i8 %13990, i8* %18, align 1
  %13991 = xor i64 %13979, %13980
  %13992 = lshr i64 %13991, 4
  %13993 = trunc i64 %13992 to i8
  %13994 = and i8 %13993, 1
  store i8 %13994, i8* %19, align 1
  %13995 = icmp eq i64 %13980, 0
  %13996 = zext i1 %13995 to i8
  store i8 %13996, i8* %20, align 1
  %13997 = lshr i64 %13980, 63
  %13998 = trunc i64 %13997 to i8
  store i8 %13998, i8* %21, align 1
  %13999 = lshr i64 %13979, 63
  %14000 = lshr i64 %13977, 58
  %14001 = and i64 %14000, 1
  %14002 = xor i64 %13997, %13999
  %14003 = xor i64 %13997, %14001
  %14004 = add nuw nsw i64 %14002, %14003
  %14005 = icmp eq i64 %14004, 2
  %14006 = zext i1 %14005 to i8
  store i8 %14006, i8* %22, align 1
  %14007 = load i64, i64* %RBP.i, align 8
  %14008 = add i64 %14007, -224
  %14009 = add i64 %13821, 131
  store i64 %14009, i64* %3, align 8
  %14010 = inttoptr i64 %14008 to i32*
  %14011 = load i32, i32* %14010, align 4
  %14012 = zext i32 %14011 to i64
  store i64 %14012, i64* %R9.i1633, align 8
  %14013 = add i64 %14007, -48
  %14014 = add i64 %13821, 135
  store i64 %14014, i64* %3, align 8
  %14015 = inttoptr i64 %14013 to i32*
  %14016 = load i32, i32* %14015, align 4
  %14017 = add i32 %14016, %14011
  %14018 = zext i32 %14017 to i64
  store i64 %14018, i64* %R9.i1633, align 8
  %14019 = icmp ult i32 %14017, %14011
  %14020 = icmp ult i32 %14017, %14016
  %14021 = or i1 %14019, %14020
  %14022 = zext i1 %14021 to i8
  store i8 %14022, i8* %17, align 1
  %14023 = and i32 %14017, 255
  %14024 = tail call i32 @llvm.ctpop.i32(i32 %14023)
  %14025 = trunc i32 %14024 to i8
  %14026 = and i8 %14025, 1
  %14027 = xor i8 %14026, 1
  store i8 %14027, i8* %18, align 1
  %14028 = xor i32 %14016, %14011
  %14029 = xor i32 %14028, %14017
  %14030 = lshr i32 %14029, 4
  %14031 = trunc i32 %14030 to i8
  %14032 = and i8 %14031, 1
  store i8 %14032, i8* %19, align 1
  %14033 = icmp eq i32 %14017, 0
  %14034 = zext i1 %14033 to i8
  store i8 %14034, i8* %20, align 1
  %14035 = lshr i32 %14017, 31
  %14036 = trunc i32 %14035 to i8
  store i8 %14036, i8* %21, align 1
  %14037 = lshr i32 %14011, 31
  %14038 = lshr i32 %14016, 31
  %14039 = xor i32 %14035, %14037
  %14040 = xor i32 %14035, %14038
  %14041 = add nuw nsw i32 %14039, %14040
  %14042 = icmp eq i32 %14041, 2
  %14043 = zext i1 %14042 to i8
  store i8 %14043, i8* %22, align 1
  %14044 = sext i32 %14017 to i64
  store i64 %14044, i64* %25, align 8
  %14045 = shl nsw i64 %14044, 1
  %14046 = add i64 %13980, %14045
  %14047 = add i64 %13821, 143
  store i64 %14047, i64* %3, align 8
  %14048 = inttoptr i64 %14046 to i16*
  %14049 = load i16, i16* %14048, align 2
  %14050 = zext i16 %14049 to i64
  store i64 %14050, i64* %R9.i1633, align 8
  %14051 = load i64, i64* %RDI.i6998, align 8
  %14052 = zext i16 %14049 to i32
  %14053 = zext i16 %14049 to i64
  %14054 = trunc i64 %14051 to i32
  %14055 = sub i32 %14054, %14052
  %14056 = zext i32 %14055 to i64
  store i64 %14056, i64* %RDI.i6998, align 8
  %14057 = icmp ult i32 %14054, %14052
  %14058 = zext i1 %14057 to i8
  store i8 %14058, i8* %17, align 1
  %14059 = and i32 %14055, 255
  %14060 = tail call i32 @llvm.ctpop.i32(i32 %14059)
  %14061 = trunc i32 %14060 to i8
  %14062 = and i8 %14061, 1
  %14063 = xor i8 %14062, 1
  store i8 %14063, i8* %18, align 1
  %14064 = xor i64 %14053, %14051
  %14065 = trunc i64 %14064 to i32
  %14066 = xor i32 %14065, %14055
  %14067 = lshr i32 %14066, 4
  %14068 = trunc i32 %14067 to i8
  %14069 = and i8 %14068, 1
  store i8 %14069, i8* %19, align 1
  %14070 = icmp eq i32 %14055, 0
  %14071 = zext i1 %14070 to i8
  store i8 %14071, i8* %20, align 1
  %14072 = lshr i32 %14055, 31
  %14073 = trunc i32 %14072 to i8
  store i8 %14073, i8* %21, align 1
  %14074 = lshr i32 %14054, 31
  %14075 = xor i32 %14072, %14074
  %14076 = add nuw nsw i32 %14075, %14074
  %14077 = icmp eq i32 %14076, 2
  %14078 = zext i1 %14077 to i8
  store i8 %14078, i8* %22, align 1
  %14079 = add i64 %14007, -348
  %14080 = add i64 %13821, 152
  store i64 %14080, i64* %3, align 8
  %14081 = inttoptr i64 %14079 to i32*
  store i32 %14055, i32* %14081, align 4
  %14082 = load i64, i64* %3, align 8
  %14083 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %14083, i64* %RSI.i2015, align 8
  %14084 = load i64, i64* %RBP.i, align 8
  %14085 = add i64 %14084, -240
  %14086 = add i64 %14082, 14
  store i64 %14086, i64* %3, align 8
  %14087 = inttoptr i64 %14085 to i32*
  %14088 = load i32, i32* %14087, align 4
  %14089 = zext i32 %14088 to i64
  store i64 %14089, i64* %RDI.i6998, align 8
  %14090 = add i64 %14084, -48
  %14091 = add i64 %14082, 17
  store i64 %14091, i64* %3, align 8
  %14092 = inttoptr i64 %14090 to i32*
  %14093 = load i32, i32* %14092, align 4
  %14094 = add i32 %14093, %14088
  %14095 = zext i32 %14094 to i64
  store i64 %14095, i64* %RDI.i6998, align 8
  %14096 = icmp ult i32 %14094, %14088
  %14097 = icmp ult i32 %14094, %14093
  %14098 = or i1 %14096, %14097
  %14099 = zext i1 %14098 to i8
  store i8 %14099, i8* %17, align 1
  %14100 = and i32 %14094, 255
  %14101 = tail call i32 @llvm.ctpop.i32(i32 %14100)
  %14102 = trunc i32 %14101 to i8
  %14103 = and i8 %14102, 1
  %14104 = xor i8 %14103, 1
  store i8 %14104, i8* %18, align 1
  %14105 = xor i32 %14093, %14088
  %14106 = xor i32 %14105, %14094
  %14107 = lshr i32 %14106, 4
  %14108 = trunc i32 %14107 to i8
  %14109 = and i8 %14108, 1
  store i8 %14109, i8* %19, align 1
  %14110 = icmp eq i32 %14094, 0
  %14111 = zext i1 %14110 to i8
  store i8 %14111, i8* %20, align 1
  %14112 = lshr i32 %14094, 31
  %14113 = trunc i32 %14112 to i8
  store i8 %14113, i8* %21, align 1
  %14114 = lshr i32 %14088, 31
  %14115 = lshr i32 %14093, 31
  %14116 = xor i32 %14112, %14114
  %14117 = xor i32 %14112, %14115
  %14118 = add nuw nsw i32 %14116, %14117
  %14119 = icmp eq i32 %14118, 2
  %14120 = zext i1 %14119 to i8
  store i8 %14120, i8* %22, align 1
  %14121 = sext i32 %14094 to i64
  store i64 %14121, i64* %25, align 8
  %14122 = shl nsw i64 %14121, 3
  %14123 = add i64 %14083, %14122
  %14124 = add i64 %14082, 24
  store i64 %14124, i64* %3, align 8
  %14125 = inttoptr i64 %14123 to i64*
  %14126 = load i64, i64* %14125, align 8
  store i64 %14126, i64* %RSI.i2015, align 8
  %14127 = add i64 %14084, -236
  %14128 = add i64 %14082, 30
  store i64 %14128, i64* %3, align 8
  %14129 = inttoptr i64 %14127 to i32*
  %14130 = load i32, i32* %14129, align 4
  %14131 = zext i32 %14130 to i64
  store i64 %14131, i64* %RDI.i6998, align 8
  %14132 = add i64 %14084, -44
  %14133 = add i64 %14082, 33
  store i64 %14133, i64* %3, align 8
  %14134 = inttoptr i64 %14132 to i32*
  %14135 = load i32, i32* %14134, align 4
  %14136 = add i32 %14135, %14130
  %14137 = zext i32 %14136 to i64
  store i64 %14137, i64* %RDI.i6998, align 8
  %14138 = icmp ult i32 %14136, %14130
  %14139 = icmp ult i32 %14136, %14135
  %14140 = or i1 %14138, %14139
  %14141 = zext i1 %14140 to i8
  store i8 %14141, i8* %17, align 1
  %14142 = and i32 %14136, 255
  %14143 = tail call i32 @llvm.ctpop.i32(i32 %14142)
  %14144 = trunc i32 %14143 to i8
  %14145 = and i8 %14144, 1
  %14146 = xor i8 %14145, 1
  store i8 %14146, i8* %18, align 1
  %14147 = xor i32 %14135, %14130
  %14148 = xor i32 %14147, %14136
  %14149 = lshr i32 %14148, 4
  %14150 = trunc i32 %14149 to i8
  %14151 = and i8 %14150, 1
  store i8 %14151, i8* %19, align 1
  %14152 = icmp eq i32 %14136, 0
  %14153 = zext i1 %14152 to i8
  store i8 %14153, i8* %20, align 1
  %14154 = lshr i32 %14136, 31
  %14155 = trunc i32 %14154 to i8
  store i8 %14155, i8* %21, align 1
  %14156 = lshr i32 %14130, 31
  %14157 = lshr i32 %14135, 31
  %14158 = xor i32 %14154, %14156
  %14159 = xor i32 %14154, %14157
  %14160 = add nuw nsw i32 %14158, %14159
  %14161 = icmp eq i32 %14160, 2
  %14162 = zext i1 %14161 to i8
  store i8 %14162, i8* %22, align 1
  %14163 = sext i32 %14136 to i64
  store i64 %14163, i64* %25, align 8
  %14164 = shl nsw i64 %14163, 1
  %14165 = add i64 %14126, %14164
  %14166 = add i64 %14082, 41
  store i64 %14166, i64* %3, align 8
  %14167 = inttoptr i64 %14165 to i16*
  %14168 = load i16, i16* %14167, align 2
  %14169 = zext i16 %14168 to i64
  store i64 %14169, i64* %RDI.i6998, align 8
  %14170 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %14171 = add i64 %14170, 184
  store i64 %14171, i64* %RSI.i2015, align 8
  %14172 = icmp ugt i64 %14170, -185
  %14173 = zext i1 %14172 to i8
  store i8 %14173, i8* %17, align 1
  %14174 = trunc i64 %14171 to i32
  %14175 = and i32 %14174, 255
  %14176 = tail call i32 @llvm.ctpop.i32(i32 %14175)
  %14177 = trunc i32 %14176 to i8
  %14178 = and i8 %14177, 1
  %14179 = xor i8 %14178, 1
  store i8 %14179, i8* %18, align 1
  %14180 = xor i64 %14170, 16
  %14181 = xor i64 %14180, %14171
  %14182 = lshr i64 %14181, 4
  %14183 = trunc i64 %14182 to i8
  %14184 = and i8 %14183, 1
  store i8 %14184, i8* %19, align 1
  %14185 = icmp eq i64 %14171, 0
  %14186 = zext i1 %14185 to i8
  store i8 %14186, i8* %20, align 1
  %14187 = lshr i64 %14171, 63
  %14188 = trunc i64 %14187 to i8
  store i8 %14188, i8* %21, align 1
  %14189 = lshr i64 %14170, 63
  %14190 = xor i64 %14187, %14189
  %14191 = add nuw nsw i64 %14190, %14187
  %14192 = icmp eq i64 %14191, 2
  %14193 = zext i1 %14192 to i8
  store i8 %14193, i8* %22, align 1
  %14194 = load i64, i64* %RBP.i, align 8
  %14195 = add i64 %14194, -40
  %14196 = add i64 %14082, 60
  store i64 %14196, i64* %3, align 8
  %14197 = inttoptr i64 %14195 to i32*
  %14198 = load i32, i32* %14197, align 4
  %14199 = sext i32 %14198 to i64
  %14200 = shl nsw i64 %14199, 9
  store i64 %14200, i64* %25, align 8
  %14201 = add i64 %14200, %14171
  store i64 %14201, i64* %RSI.i2015, align 8
  %14202 = icmp ult i64 %14201, %14171
  %14203 = icmp ult i64 %14201, %14200
  %14204 = or i1 %14202, %14203
  %14205 = zext i1 %14204 to i8
  store i8 %14205, i8* %17, align 1
  %14206 = trunc i64 %14201 to i32
  %14207 = and i32 %14206, 255
  %14208 = tail call i32 @llvm.ctpop.i32(i32 %14207)
  %14209 = trunc i32 %14208 to i8
  %14210 = and i8 %14209, 1
  %14211 = xor i8 %14210, 1
  store i8 %14211, i8* %18, align 1
  %14212 = xor i64 %14171, %14201
  %14213 = lshr i64 %14212, 4
  %14214 = trunc i64 %14213 to i8
  %14215 = and i8 %14214, 1
  store i8 %14215, i8* %19, align 1
  %14216 = icmp eq i64 %14201, 0
  %14217 = zext i1 %14216 to i8
  store i8 %14217, i8* %20, align 1
  %14218 = lshr i64 %14201, 63
  %14219 = trunc i64 %14218 to i8
  store i8 %14219, i8* %21, align 1
  %14220 = lshr i64 %14199, 54
  %14221 = and i64 %14220, 1
  %14222 = xor i64 %14218, %14187
  %14223 = xor i64 %14218, %14221
  %14224 = add nuw nsw i64 %14222, %14223
  %14225 = icmp eq i64 %14224, 2
  %14226 = zext i1 %14225 to i8
  store i8 %14226, i8* %22, align 1
  %14227 = add i64 %14194, -48
  %14228 = add i64 %14082, 71
  store i64 %14228, i64* %3, align 8
  %14229 = inttoptr i64 %14227 to i32*
  %14230 = load i32, i32* %14229, align 4
  %14231 = sext i32 %14230 to i64
  %14232 = shl nsw i64 %14231, 5
  store i64 %14232, i64* %25, align 8
  %14233 = add i64 %14232, %14201
  store i64 %14233, i64* %RSI.i2015, align 8
  %14234 = icmp ult i64 %14233, %14201
  %14235 = icmp ult i64 %14233, %14232
  %14236 = or i1 %14234, %14235
  %14237 = zext i1 %14236 to i8
  store i8 %14237, i8* %17, align 1
  %14238 = trunc i64 %14233 to i32
  %14239 = and i32 %14238, 255
  %14240 = tail call i32 @llvm.ctpop.i32(i32 %14239)
  %14241 = trunc i32 %14240 to i8
  %14242 = and i8 %14241, 1
  %14243 = xor i8 %14242, 1
  store i8 %14243, i8* %18, align 1
  %14244 = xor i64 %14201, %14233
  %14245 = lshr i64 %14244, 4
  %14246 = trunc i64 %14245 to i8
  %14247 = and i8 %14246, 1
  store i8 %14247, i8* %19, align 1
  %14248 = icmp eq i64 %14233, 0
  %14249 = zext i1 %14248 to i8
  store i8 %14249, i8* %20, align 1
  %14250 = lshr i64 %14233, 63
  %14251 = trunc i64 %14250 to i8
  store i8 %14251, i8* %21, align 1
  %14252 = lshr i64 %14231, 58
  %14253 = and i64 %14252, 1
  %14254 = xor i64 %14250, %14218
  %14255 = xor i64 %14250, %14253
  %14256 = add nuw nsw i64 %14254, %14255
  %14257 = icmp eq i64 %14256, 2
  %14258 = zext i1 %14257 to i8
  store i8 %14258, i8* %22, align 1
  %14259 = load i64, i64* %RBP.i, align 8
  %14260 = add i64 %14259, -44
  %14261 = add i64 %14082, 82
  store i64 %14261, i64* %3, align 8
  %14262 = inttoptr i64 %14260 to i32*
  %14263 = load i32, i32* %14262, align 4
  %14264 = sext i32 %14263 to i64
  store i64 %14264, i64* %25, align 8
  %14265 = shl nsw i64 %14264, 1
  %14266 = add i64 %14265, %14233
  %14267 = add i64 %14082, 87
  store i64 %14267, i64* %3, align 8
  %14268 = inttoptr i64 %14266 to i16*
  %14269 = load i16, i16* %14268, align 2
  %14270 = zext i16 %14269 to i64
  store i64 %14270, i64* %R9.i1633, align 8
  %14271 = load i64, i64* %RDI.i6998, align 8
  %14272 = zext i16 %14269 to i32
  %14273 = zext i16 %14269 to i64
  %14274 = trunc i64 %14271 to i32
  %14275 = sub i32 %14274, %14272
  %14276 = zext i32 %14275 to i64
  store i64 %14276, i64* %RDI.i6998, align 8
  %14277 = icmp ult i32 %14274, %14272
  %14278 = zext i1 %14277 to i8
  store i8 %14278, i8* %17, align 1
  %14279 = and i32 %14275, 255
  %14280 = tail call i32 @llvm.ctpop.i32(i32 %14279)
  %14281 = trunc i32 %14280 to i8
  %14282 = and i8 %14281, 1
  %14283 = xor i8 %14282, 1
  store i8 %14283, i8* %18, align 1
  %14284 = xor i64 %14273, %14271
  %14285 = trunc i64 %14284 to i32
  %14286 = xor i32 %14285, %14275
  %14287 = lshr i32 %14286, 4
  %14288 = trunc i32 %14287 to i8
  %14289 = and i8 %14288, 1
  store i8 %14289, i8* %19, align 1
  %14290 = icmp eq i32 %14275, 0
  %14291 = zext i1 %14290 to i8
  store i8 %14291, i8* %20, align 1
  %14292 = lshr i32 %14275, 31
  %14293 = trunc i32 %14292 to i8
  store i8 %14293, i8* %21, align 1
  %14294 = lshr i32 %14274, 31
  %14295 = xor i32 %14292, %14294
  %14296 = add nuw nsw i32 %14295, %14294
  %14297 = icmp eq i32 %14296, 2
  %14298 = zext i1 %14297 to i8
  store i8 %14298, i8* %22, align 1
  %14299 = add i64 %14259, -344
  %14300 = add i64 %14082, 96
  store i64 %14300, i64* %3, align 8
  %14301 = inttoptr i64 %14299 to i32*
  store i32 %14275, i32* %14301, align 4
  %14302 = load i64, i64* %3, align 8
  %14303 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %14303, i64* %RSI.i2015, align 8
  %14304 = add i64 %14303, 8
  %14305 = add i64 %14302, 12
  store i64 %14305, i64* %3, align 8
  %14306 = inttoptr i64 %14304 to i64*
  %14307 = load i64, i64* %14306, align 8
  store i64 %14307, i64* %RSI.i2015, align 8
  %14308 = load i64, i64* %RBP.i, align 8
  %14309 = add i64 %14308, -240
  %14310 = add i64 %14302, 18
  store i64 %14310, i64* %3, align 8
  %14311 = inttoptr i64 %14309 to i32*
  %14312 = load i32, i32* %14311, align 4
  %14313 = zext i32 %14312 to i64
  store i64 %14313, i64* %RDI.i6998, align 8
  %14314 = add i64 %14308, -48
  %14315 = add i64 %14302, 21
  store i64 %14315, i64* %3, align 8
  %14316 = inttoptr i64 %14314 to i32*
  %14317 = load i32, i32* %14316, align 4
  %14318 = add i32 %14317, %14312
  %14319 = zext i32 %14318 to i64
  store i64 %14319, i64* %RDI.i6998, align 8
  %14320 = icmp ult i32 %14318, %14312
  %14321 = icmp ult i32 %14318, %14317
  %14322 = or i1 %14320, %14321
  %14323 = zext i1 %14322 to i8
  store i8 %14323, i8* %17, align 1
  %14324 = and i32 %14318, 255
  %14325 = tail call i32 @llvm.ctpop.i32(i32 %14324)
  %14326 = trunc i32 %14325 to i8
  %14327 = and i8 %14326, 1
  %14328 = xor i8 %14327, 1
  store i8 %14328, i8* %18, align 1
  %14329 = xor i32 %14317, %14312
  %14330 = xor i32 %14329, %14318
  %14331 = lshr i32 %14330, 4
  %14332 = trunc i32 %14331 to i8
  %14333 = and i8 %14332, 1
  store i8 %14333, i8* %19, align 1
  %14334 = icmp eq i32 %14318, 0
  %14335 = zext i1 %14334 to i8
  store i8 %14335, i8* %20, align 1
  %14336 = lshr i32 %14318, 31
  %14337 = trunc i32 %14336 to i8
  store i8 %14337, i8* %21, align 1
  %14338 = lshr i32 %14312, 31
  %14339 = lshr i32 %14317, 31
  %14340 = xor i32 %14336, %14338
  %14341 = xor i32 %14336, %14339
  %14342 = add nuw nsw i32 %14340, %14341
  %14343 = icmp eq i32 %14342, 2
  %14344 = zext i1 %14343 to i8
  store i8 %14344, i8* %22, align 1
  %14345 = sext i32 %14318 to i64
  store i64 %14345, i64* %25, align 8
  %14346 = shl nsw i64 %14345, 3
  %14347 = add i64 %14307, %14346
  %14348 = add i64 %14302, 28
  store i64 %14348, i64* %3, align 8
  %14349 = inttoptr i64 %14347 to i64*
  %14350 = load i64, i64* %14349, align 8
  store i64 %14350, i64* %RSI.i2015, align 8
  %14351 = add i64 %14308, -236
  %14352 = add i64 %14302, 34
  store i64 %14352, i64* %3, align 8
  %14353 = inttoptr i64 %14351 to i32*
  %14354 = load i32, i32* %14353, align 4
  %14355 = zext i32 %14354 to i64
  store i64 %14355, i64* %RDI.i6998, align 8
  %14356 = add i64 %14308, -44
  %14357 = add i64 %14302, 37
  store i64 %14357, i64* %3, align 8
  %14358 = inttoptr i64 %14356 to i32*
  %14359 = load i32, i32* %14358, align 4
  %14360 = add i32 %14359, %14354
  %14361 = zext i32 %14360 to i64
  store i64 %14361, i64* %RDI.i6998, align 8
  %14362 = icmp ult i32 %14360, %14354
  %14363 = icmp ult i32 %14360, %14359
  %14364 = or i1 %14362, %14363
  %14365 = zext i1 %14364 to i8
  store i8 %14365, i8* %17, align 1
  %14366 = and i32 %14360, 255
  %14367 = tail call i32 @llvm.ctpop.i32(i32 %14366)
  %14368 = trunc i32 %14367 to i8
  %14369 = and i8 %14368, 1
  %14370 = xor i8 %14369, 1
  store i8 %14370, i8* %18, align 1
  %14371 = xor i32 %14359, %14354
  %14372 = xor i32 %14371, %14360
  %14373 = lshr i32 %14372, 4
  %14374 = trunc i32 %14373 to i8
  %14375 = and i8 %14374, 1
  store i8 %14375, i8* %19, align 1
  %14376 = icmp eq i32 %14360, 0
  %14377 = zext i1 %14376 to i8
  store i8 %14377, i8* %20, align 1
  %14378 = lshr i32 %14360, 31
  %14379 = trunc i32 %14378 to i8
  store i8 %14379, i8* %21, align 1
  %14380 = lshr i32 %14354, 31
  %14381 = lshr i32 %14359, 31
  %14382 = xor i32 %14378, %14380
  %14383 = xor i32 %14378, %14381
  %14384 = add nuw nsw i32 %14382, %14383
  %14385 = icmp eq i32 %14384, 2
  %14386 = zext i1 %14385 to i8
  store i8 %14386, i8* %22, align 1
  %14387 = sext i32 %14360 to i64
  store i64 %14387, i64* %25, align 8
  %14388 = shl nsw i64 %14387, 1
  %14389 = add i64 %14350, %14388
  %14390 = add i64 %14302, 45
  store i64 %14390, i64* %3, align 8
  %14391 = inttoptr i64 %14389 to i16*
  %14392 = load i16, i16* %14391, align 2
  %14393 = zext i16 %14392 to i64
  store i64 %14393, i64* %RDI.i6998, align 8
  %14394 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %14395 = add i64 %14394, 8504
  %14396 = lshr i64 %14395, 63
  %14397 = add i64 %14394, 10552
  store i64 %14397, i64* %RSI.i2015, align 8
  %14398 = icmp ugt i64 %14395, -2049
  %14399 = zext i1 %14398 to i8
  store i8 %14399, i8* %17, align 1
  %14400 = trunc i64 %14397 to i32
  %14401 = and i32 %14400, 255
  %14402 = tail call i32 @llvm.ctpop.i32(i32 %14401)
  %14403 = trunc i32 %14402 to i8
  %14404 = and i8 %14403, 1
  %14405 = xor i8 %14404, 1
  store i8 %14405, i8* %18, align 1
  %14406 = xor i64 %14397, %14395
  %14407 = lshr i64 %14406, 4
  %14408 = trunc i64 %14407 to i8
  %14409 = and i8 %14408, 1
  store i8 %14409, i8* %19, align 1
  %14410 = icmp eq i64 %14397, 0
  %14411 = zext i1 %14410 to i8
  store i8 %14411, i8* %20, align 1
  %14412 = lshr i64 %14397, 63
  %14413 = trunc i64 %14412 to i8
  store i8 %14413, i8* %21, align 1
  %14414 = xor i64 %14412, %14396
  %14415 = add nuw nsw i64 %14414, %14412
  %14416 = icmp eq i64 %14415, 2
  %14417 = zext i1 %14416 to i8
  store i8 %14417, i8* %22, align 1
  %14418 = load i64, i64* %RBP.i, align 8
  %14419 = add i64 %14418, -364
  %14420 = add i64 %14302, 74
  store i64 %14420, i64* %3, align 8
  %14421 = inttoptr i64 %14419 to i32*
  %14422 = load i32, i32* %14421, align 4
  %14423 = sext i32 %14422 to i64
  %14424 = shl nsw i64 %14423, 9
  store i64 %14424, i64* %25, align 8
  %14425 = add i64 %14424, %14397
  store i64 %14425, i64* %RSI.i2015, align 8
  %14426 = icmp ult i64 %14425, %14397
  %14427 = icmp ult i64 %14425, %14424
  %14428 = or i1 %14426, %14427
  %14429 = zext i1 %14428 to i8
  store i8 %14429, i8* %17, align 1
  %14430 = trunc i64 %14425 to i32
  %14431 = and i32 %14430, 255
  %14432 = tail call i32 @llvm.ctpop.i32(i32 %14431)
  %14433 = trunc i32 %14432 to i8
  %14434 = and i8 %14433, 1
  %14435 = xor i8 %14434, 1
  store i8 %14435, i8* %18, align 1
  %14436 = xor i64 %14397, %14425
  %14437 = lshr i64 %14436, 4
  %14438 = trunc i64 %14437 to i8
  %14439 = and i8 %14438, 1
  store i8 %14439, i8* %19, align 1
  %14440 = icmp eq i64 %14425, 0
  %14441 = zext i1 %14440 to i8
  store i8 %14441, i8* %20, align 1
  %14442 = lshr i64 %14425, 63
  %14443 = trunc i64 %14442 to i8
  store i8 %14443, i8* %21, align 1
  %14444 = lshr i64 %14423, 54
  %14445 = and i64 %14444, 1
  %14446 = xor i64 %14442, %14412
  %14447 = xor i64 %14442, %14445
  %14448 = add nuw nsw i64 %14446, %14447
  %14449 = icmp eq i64 %14448, 2
  %14450 = zext i1 %14449 to i8
  store i8 %14450, i8* %22, align 1
  %14451 = add i64 %14418, -220
  %14452 = add i64 %14302, 88
  store i64 %14452, i64* %3, align 8
  %14453 = inttoptr i64 %14451 to i32*
  %14454 = load i32, i32* %14453, align 4
  %14455 = zext i32 %14454 to i64
  store i64 %14455, i64* %R9.i1633, align 8
  %14456 = add i64 %14418, -44
  %14457 = add i64 %14302, 92
  store i64 %14457, i64* %3, align 8
  %14458 = inttoptr i64 %14456 to i32*
  %14459 = load i32, i32* %14458, align 4
  %14460 = add i32 %14459, %14454
  %14461 = zext i32 %14460 to i64
  store i64 %14461, i64* %R9.i1633, align 8
  %14462 = sext i32 %14460 to i64
  %14463 = shl nsw i64 %14462, 5
  store i64 %14463, i64* %25, align 8
  %14464 = load i64, i64* %RSI.i2015, align 8
  %14465 = add i64 %14463, %14464
  store i64 %14465, i64* %RSI.i2015, align 8
  %14466 = icmp ult i64 %14465, %14464
  %14467 = icmp ult i64 %14465, %14463
  %14468 = or i1 %14466, %14467
  %14469 = zext i1 %14468 to i8
  store i8 %14469, i8* %17, align 1
  %14470 = trunc i64 %14465 to i32
  %14471 = and i32 %14470, 255
  %14472 = tail call i32 @llvm.ctpop.i32(i32 %14471)
  %14473 = trunc i32 %14472 to i8
  %14474 = and i8 %14473, 1
  %14475 = xor i8 %14474, 1
  store i8 %14475, i8* %18, align 1
  %14476 = xor i64 %14464, %14465
  %14477 = lshr i64 %14476, 4
  %14478 = trunc i64 %14477 to i8
  %14479 = and i8 %14478, 1
  store i8 %14479, i8* %19, align 1
  %14480 = icmp eq i64 %14465, 0
  %14481 = zext i1 %14480 to i8
  store i8 %14481, i8* %20, align 1
  %14482 = lshr i64 %14465, 63
  %14483 = trunc i64 %14482 to i8
  store i8 %14483, i8* %21, align 1
  %14484 = lshr i64 %14464, 63
  %14485 = lshr i64 %14462, 58
  %14486 = and i64 %14485, 1
  %14487 = xor i64 %14482, %14484
  %14488 = xor i64 %14482, %14486
  %14489 = add nuw nsw i64 %14487, %14488
  %14490 = icmp eq i64 %14489, 2
  %14491 = zext i1 %14490 to i8
  store i8 %14491, i8* %22, align 1
  %14492 = load i64, i64* %RBP.i, align 8
  %14493 = add i64 %14492, -224
  %14494 = add i64 %14302, 109
  store i64 %14494, i64* %3, align 8
  %14495 = inttoptr i64 %14493 to i32*
  %14496 = load i32, i32* %14495, align 4
  %14497 = zext i32 %14496 to i64
  store i64 %14497, i64* %R9.i1633, align 8
  %14498 = add i64 %14492, -48
  %14499 = add i64 %14302, 113
  store i64 %14499, i64* %3, align 8
  %14500 = inttoptr i64 %14498 to i32*
  %14501 = load i32, i32* %14500, align 4
  %14502 = add i32 %14501, %14496
  %14503 = zext i32 %14502 to i64
  store i64 %14503, i64* %R9.i1633, align 8
  %14504 = icmp ult i32 %14502, %14496
  %14505 = icmp ult i32 %14502, %14501
  %14506 = or i1 %14504, %14505
  %14507 = zext i1 %14506 to i8
  store i8 %14507, i8* %17, align 1
  %14508 = and i32 %14502, 255
  %14509 = tail call i32 @llvm.ctpop.i32(i32 %14508)
  %14510 = trunc i32 %14509 to i8
  %14511 = and i8 %14510, 1
  %14512 = xor i8 %14511, 1
  store i8 %14512, i8* %18, align 1
  %14513 = xor i32 %14501, %14496
  %14514 = xor i32 %14513, %14502
  %14515 = lshr i32 %14514, 4
  %14516 = trunc i32 %14515 to i8
  %14517 = and i8 %14516, 1
  store i8 %14517, i8* %19, align 1
  %14518 = icmp eq i32 %14502, 0
  %14519 = zext i1 %14518 to i8
  store i8 %14519, i8* %20, align 1
  %14520 = lshr i32 %14502, 31
  %14521 = trunc i32 %14520 to i8
  store i8 %14521, i8* %21, align 1
  %14522 = lshr i32 %14496, 31
  %14523 = lshr i32 %14501, 31
  %14524 = xor i32 %14520, %14522
  %14525 = xor i32 %14520, %14523
  %14526 = add nuw nsw i32 %14524, %14525
  %14527 = icmp eq i32 %14526, 2
  %14528 = zext i1 %14527 to i8
  store i8 %14528, i8* %22, align 1
  %14529 = sext i32 %14502 to i64
  store i64 %14529, i64* %25, align 8
  %14530 = shl nsw i64 %14529, 1
  %14531 = add i64 %14465, %14530
  %14532 = add i64 %14302, 121
  store i64 %14532, i64* %3, align 8
  %14533 = inttoptr i64 %14531 to i16*
  %14534 = load i16, i16* %14533, align 2
  %14535 = zext i16 %14534 to i64
  store i64 %14535, i64* %R9.i1633, align 8
  %14536 = load i64, i64* %RDI.i6998, align 8
  %14537 = zext i16 %14534 to i32
  %14538 = zext i16 %14534 to i64
  %14539 = trunc i64 %14536 to i32
  %14540 = sub i32 %14539, %14537
  %14541 = zext i32 %14540 to i64
  store i64 %14541, i64* %RDI.i6998, align 8
  %14542 = icmp ult i32 %14539, %14537
  %14543 = zext i1 %14542 to i8
  store i8 %14543, i8* %17, align 1
  %14544 = and i32 %14540, 255
  %14545 = tail call i32 @llvm.ctpop.i32(i32 %14544)
  %14546 = trunc i32 %14545 to i8
  %14547 = and i8 %14546, 1
  %14548 = xor i8 %14547, 1
  store i8 %14548, i8* %18, align 1
  %14549 = xor i64 %14538, %14536
  %14550 = trunc i64 %14549 to i32
  %14551 = xor i32 %14550, %14540
  %14552 = lshr i32 %14551, 4
  %14553 = trunc i32 %14552 to i8
  %14554 = and i8 %14553, 1
  store i8 %14554, i8* %19, align 1
  %14555 = icmp eq i32 %14540, 0
  %14556 = zext i1 %14555 to i8
  store i8 %14556, i8* %20, align 1
  %14557 = lshr i32 %14540, 31
  %14558 = trunc i32 %14557 to i8
  store i8 %14558, i8* %21, align 1
  %14559 = lshr i32 %14539, 31
  %14560 = xor i32 %14557, %14559
  %14561 = add nuw nsw i32 %14560, %14559
  %14562 = icmp eq i32 %14561, 2
  %14563 = zext i1 %14562 to i8
  store i8 %14563, i8* %22, align 1
  %14564 = add i64 %14492, -340
  %14565 = add i64 %14302, 130
  store i64 %14565, i64* %3, align 8
  %14566 = inttoptr i64 %14564 to i32*
  store i32 %14540, i32* %14566, align 4
  %14567 = load i64, i64* %RBP.i, align 8
  %14568 = add i64 %14567, -340
  %14569 = load i64, i64* %3, align 8
  %14570 = add i64 %14569, 6
  store i64 %14570, i64* %3, align 8
  %14571 = inttoptr i64 %14568 to i32*
  %14572 = load i32, i32* %14571, align 4
  %14573 = zext i32 %14572 to i64
  store i64 %14573, i64* %RDI.i6998, align 8
  %14574 = add i64 %14567, -348
  %14575 = add i64 %14569, 12
  store i64 %14575, i64* %3, align 8
  %14576 = inttoptr i64 %14574 to i32*
  %14577 = load i32, i32* %14576, align 4
  %14578 = sub i32 %14572, %14577
  %14579 = zext i32 %14578 to i64
  store i64 %14579, i64* %RDI.i6998, align 8
  %14580 = icmp ult i32 %14572, %14577
  %14581 = zext i1 %14580 to i8
  store i8 %14581, i8* %17, align 1
  %14582 = and i32 %14578, 255
  %14583 = tail call i32 @llvm.ctpop.i32(i32 %14582)
  %14584 = trunc i32 %14583 to i8
  %14585 = and i8 %14584, 1
  %14586 = xor i8 %14585, 1
  store i8 %14586, i8* %18, align 1
  %14587 = xor i32 %14577, %14572
  %14588 = xor i32 %14587, %14578
  %14589 = lshr i32 %14588, 4
  %14590 = trunc i32 %14589 to i8
  %14591 = and i8 %14590, 1
  store i8 %14591, i8* %19, align 1
  %14592 = icmp eq i32 %14578, 0
  %14593 = zext i1 %14592 to i8
  store i8 %14593, i8* %20, align 1
  %14594 = lshr i32 %14578, 31
  %14595 = trunc i32 %14594 to i8
  store i8 %14595, i8* %21, align 1
  %14596 = lshr i32 %14572, 31
  %14597 = lshr i32 %14577, 31
  %14598 = xor i32 %14597, %14596
  %14599 = xor i32 %14594, %14596
  %14600 = add nuw nsw i32 %14599, %14598
  %14601 = icmp eq i32 %14600, 2
  %14602 = zext i1 %14601 to i8
  store i8 %14602, i8* %22, align 1
  %14603 = add i64 %14567, -44
  %14604 = add i64 %14569, 16
  store i64 %14604, i64* %3, align 8
  %14605 = inttoptr i64 %14603 to i32*
  %14606 = load i32, i32* %14605, align 4
  %14607 = sext i32 %14606 to i64
  %14608 = shl nsw i64 %14607, 6
  store i64 %14608, i64* %RSI.i2015, align 8
  %14609 = load i64, i64* %RDX.i1943, align 8
  %14610 = add i64 %14608, %14609
  store i64 %14610, i64* %25, align 8
  %14611 = icmp ult i64 %14610, %14609
  %14612 = icmp ult i64 %14610, %14608
  %14613 = or i1 %14611, %14612
  %14614 = zext i1 %14613 to i8
  store i8 %14614, i8* %17, align 1
  %14615 = trunc i64 %14610 to i32
  %14616 = and i32 %14615, 255
  %14617 = tail call i32 @llvm.ctpop.i32(i32 %14616)
  %14618 = trunc i32 %14617 to i8
  %14619 = and i8 %14618, 1
  %14620 = xor i8 %14619, 1
  store i8 %14620, i8* %18, align 1
  %14621 = xor i64 %14609, %14610
  %14622 = lshr i64 %14621, 4
  %14623 = trunc i64 %14622 to i8
  %14624 = and i8 %14623, 1
  store i8 %14624, i8* %19, align 1
  %14625 = icmp eq i64 %14610, 0
  %14626 = zext i1 %14625 to i8
  store i8 %14626, i8* %20, align 1
  %14627 = lshr i64 %14610, 63
  %14628 = trunc i64 %14627 to i8
  store i8 %14628, i8* %21, align 1
  %14629 = lshr i64 %14609, 63
  %14630 = lshr i64 %14607, 57
  %14631 = and i64 %14630, 1
  %14632 = xor i64 %14627, %14629
  %14633 = xor i64 %14627, %14631
  %14634 = add nuw nsw i64 %14632, %14633
  %14635 = icmp eq i64 %14634, 2
  %14636 = zext i1 %14635 to i8
  store i8 %14636, i8* %22, align 1
  %14637 = load i64, i64* %RBP.i, align 8
  %14638 = add i64 %14637, -48
  %14639 = add i64 %14569, 30
  store i64 %14639, i64* %3, align 8
  %14640 = inttoptr i64 %14638 to i32*
  %14641 = load i32, i32* %14640, align 4
  %14642 = sext i32 %14641 to i64
  store i64 %14642, i64* %RSI.i2015, align 8
  %14643 = shl nsw i64 %14642, 2
  %14644 = add i64 %14643, %14610
  %14645 = load i32, i32* %EDI.i1741, align 4
  %14646 = add i64 %14569, 34
  store i64 %14646, i64* %3, align 8
  %14647 = inttoptr i64 %14644 to i32*
  store i32 %14645, i32* %14647, align 4
  %14648 = load i64, i64* %RBP.i, align 8
  %14649 = add i64 %14648, -348
  %14650 = load i64, i64* %3, align 8
  %14651 = add i64 %14650, 6
  store i64 %14651, i64* %3, align 8
  %14652 = inttoptr i64 %14649 to i32*
  %14653 = load i32, i32* %14652, align 4
  %14654 = zext i32 %14653 to i64
  store i64 %14654, i64* %RDI.i6998, align 8
  %14655 = add i64 %14648, -44
  %14656 = add i64 %14650, 10
  store i64 %14656, i64* %3, align 8
  %14657 = inttoptr i64 %14655 to i32*
  %14658 = load i32, i32* %14657, align 4
  %14659 = sext i32 %14658 to i64
  %14660 = shl nsw i64 %14659, 6
  store i64 %14660, i64* %RSI.i2015, align 8
  %14661 = load i64, i64* %RDX.i1943, align 8
  %14662 = add i64 %14660, %14661
  store i64 %14662, i64* %RDX.i1943, align 8
  %14663 = icmp ult i64 %14662, %14661
  %14664 = icmp ult i64 %14662, %14660
  %14665 = or i1 %14663, %14664
  %14666 = zext i1 %14665 to i8
  store i8 %14666, i8* %17, align 1
  %14667 = trunc i64 %14662 to i32
  %14668 = and i32 %14667, 255
  %14669 = tail call i32 @llvm.ctpop.i32(i32 %14668)
  %14670 = trunc i32 %14669 to i8
  %14671 = and i8 %14670, 1
  %14672 = xor i8 %14671, 1
  store i8 %14672, i8* %18, align 1
  %14673 = xor i64 %14661, %14662
  %14674 = lshr i64 %14673, 4
  %14675 = trunc i64 %14674 to i8
  %14676 = and i8 %14675, 1
  store i8 %14676, i8* %19, align 1
  %14677 = icmp eq i64 %14662, 0
  %14678 = zext i1 %14677 to i8
  store i8 %14678, i8* %20, align 1
  %14679 = lshr i64 %14662, 63
  %14680 = trunc i64 %14679 to i8
  store i8 %14680, i8* %21, align 1
  %14681 = lshr i64 %14661, 63
  %14682 = lshr i64 %14659, 57
  %14683 = and i64 %14682, 1
  %14684 = xor i64 %14679, %14681
  %14685 = xor i64 %14679, %14683
  %14686 = add nuw nsw i64 %14684, %14685
  %14687 = icmp eq i64 %14686, 2
  %14688 = zext i1 %14687 to i8
  store i8 %14688, i8* %22, align 1
  %14689 = add i64 %14648, -48
  %14690 = add i64 %14650, 21
  store i64 %14690, i64* %3, align 8
  %14691 = inttoptr i64 %14689 to i32*
  %14692 = load i32, i32* %14691, align 4
  %14693 = sext i32 %14692 to i64
  store i64 %14693, i64* %RSI.i2015, align 8
  %14694 = shl nsw i64 %14693, 2
  %14695 = add i64 %14694, %14662
  %14696 = add i64 %14650, 25
  store i64 %14696, i64* %3, align 8
  %14697 = inttoptr i64 %14695 to i32*
  %14698 = load i32, i32* %14697, align 4
  %14699 = zext i32 %14698 to i64
  %14700 = shl nuw i64 %14699, 32
  %14701 = ashr i64 %14700, 33
  %14702 = and i64 %14701, 4294967295
  store i64 %14702, i64* %R9.i1633, align 8
  %14703 = load i64, i64* %RDI.i6998, align 8
  %14704 = trunc i64 %14701 to i32
  %14705 = trunc i64 %14703 to i32
  %14706 = add i32 %14704, %14705
  %14707 = zext i32 %14706 to i64
  store i64 %14707, i64* %RDI.i6998, align 8
  %14708 = icmp ult i32 %14706, %14705
  %14709 = icmp ult i32 %14706, %14704
  %14710 = or i1 %14708, %14709
  %14711 = zext i1 %14710 to i8
  store i8 %14711, i8* %17, align 1
  %14712 = and i32 %14706, 255
  %14713 = tail call i32 @llvm.ctpop.i32(i32 %14712)
  %14714 = trunc i32 %14713 to i8
  %14715 = and i8 %14714, 1
  %14716 = xor i8 %14715, 1
  store i8 %14716, i8* %18, align 1
  %14717 = xor i64 %14701, %14703
  %14718 = trunc i64 %14717 to i32
  %14719 = xor i32 %14718, %14706
  %14720 = lshr i32 %14719, 4
  %14721 = trunc i32 %14720 to i8
  %14722 = and i8 %14721, 1
  store i8 %14722, i8* %19, align 1
  %14723 = icmp eq i32 %14706, 0
  %14724 = zext i1 %14723 to i8
  store i8 %14724, i8* %20, align 1
  %14725 = lshr i32 %14706, 31
  %14726 = trunc i32 %14725 to i8
  store i8 %14726, i8* %21, align 1
  %14727 = lshr i32 %14705, 31
  %14728 = lshr i64 %14701, 31
  %14729 = trunc i64 %14728 to i32
  %14730 = and i32 %14729, 1
  %14731 = xor i32 %14725, %14727
  %14732 = xor i32 %14725, %14730
  %14733 = add nuw nsw i32 %14731, %14732
  %14734 = icmp eq i32 %14733, 2
  %14735 = zext i1 %14734 to i8
  store i8 %14735, i8* %22, align 1
  %14736 = load i64, i64* %RBP.i, align 8
  %14737 = add i64 %14736, -360
  %14738 = add i64 %14650, 37
  store i64 %14738, i64* %3, align 8
  %14739 = inttoptr i64 %14737 to i32*
  store i32 %14706, i32* %14739, align 4
  %14740 = load i64, i64* %RBP.i, align 8
  %14741 = add i64 %14740, -344
  %14742 = load i64, i64* %3, align 8
  %14743 = add i64 %14742, 6
  store i64 %14743, i64* %3, align 8
  %14744 = inttoptr i64 %14741 to i32*
  %14745 = load i32, i32* %14744, align 4
  %14746 = zext i32 %14745 to i64
  store i64 %14746, i64* %RDI.i6998, align 8
  %14747 = add i64 %14740, -360
  %14748 = add i64 %14742, 12
  store i64 %14748, i64* %3, align 8
  %14749 = inttoptr i64 %14747 to i32*
  %14750 = load i32, i32* %14749, align 4
  %14751 = sub i32 %14745, %14750
  %14752 = zext i32 %14751 to i64
  store i64 %14752, i64* %RDI.i6998, align 8
  %14753 = icmp ult i32 %14745, %14750
  %14754 = zext i1 %14753 to i8
  store i8 %14754, i8* %17, align 1
  %14755 = and i32 %14751, 255
  %14756 = tail call i32 @llvm.ctpop.i32(i32 %14755)
  %14757 = trunc i32 %14756 to i8
  %14758 = and i8 %14757, 1
  %14759 = xor i8 %14758, 1
  store i8 %14759, i8* %18, align 1
  %14760 = xor i32 %14750, %14745
  %14761 = xor i32 %14760, %14751
  %14762 = lshr i32 %14761, 4
  %14763 = trunc i32 %14762 to i8
  %14764 = and i8 %14763, 1
  store i8 %14764, i8* %19, align 1
  %14765 = icmp eq i32 %14751, 0
  %14766 = zext i1 %14765 to i8
  store i8 %14766, i8* %20, align 1
  %14767 = lshr i32 %14751, 31
  %14768 = trunc i32 %14767 to i8
  store i8 %14768, i8* %21, align 1
  %14769 = lshr i32 %14745, 31
  %14770 = lshr i32 %14750, 31
  %14771 = xor i32 %14770, %14769
  %14772 = xor i32 %14767, %14769
  %14773 = add nuw nsw i32 %14772, %14771
  %14774 = icmp eq i32 %14773, 2
  %14775 = zext i1 %14774 to i8
  store i8 %14775, i8* %22, align 1
  %14776 = add i64 %14740, -44
  %14777 = add i64 %14742, 16
  store i64 %14777, i64* %3, align 8
  %14778 = inttoptr i64 %14776 to i32*
  %14779 = load i32, i32* %14778, align 4
  %14780 = sext i32 %14779 to i64
  %14781 = shl nsw i64 %14780, 6
  store i64 %14781, i64* %RDX.i1943, align 8
  %14782 = load i64, i64* %RCX.i1588, align 8
  %14783 = add i64 %14781, %14782
  store i64 %14783, i64* %RSI.i2015, align 8
  %14784 = icmp ult i64 %14783, %14782
  %14785 = icmp ult i64 %14783, %14781
  %14786 = or i1 %14784, %14785
  %14787 = zext i1 %14786 to i8
  store i8 %14787, i8* %17, align 1
  %14788 = trunc i64 %14783 to i32
  %14789 = and i32 %14788, 255
  %14790 = tail call i32 @llvm.ctpop.i32(i32 %14789)
  %14791 = trunc i32 %14790 to i8
  %14792 = and i8 %14791, 1
  %14793 = xor i8 %14792, 1
  store i8 %14793, i8* %18, align 1
  %14794 = xor i64 %14782, %14783
  %14795 = lshr i64 %14794, 4
  %14796 = trunc i64 %14795 to i8
  %14797 = and i8 %14796, 1
  store i8 %14797, i8* %19, align 1
  %14798 = icmp eq i64 %14783, 0
  %14799 = zext i1 %14798 to i8
  store i8 %14799, i8* %20, align 1
  %14800 = lshr i64 %14783, 63
  %14801 = trunc i64 %14800 to i8
  store i8 %14801, i8* %21, align 1
  %14802 = lshr i64 %14782, 63
  %14803 = lshr i64 %14780, 57
  %14804 = and i64 %14803, 1
  %14805 = xor i64 %14800, %14802
  %14806 = xor i64 %14800, %14804
  %14807 = add nuw nsw i64 %14805, %14806
  %14808 = icmp eq i64 %14807, 2
  %14809 = zext i1 %14808 to i8
  store i8 %14809, i8* %22, align 1
  %14810 = load i64, i64* %RBP.i, align 8
  %14811 = add i64 %14810, -48
  %14812 = add i64 %14742, 30
  store i64 %14812, i64* %3, align 8
  %14813 = inttoptr i64 %14811 to i32*
  %14814 = load i32, i32* %14813, align 4
  %14815 = sext i32 %14814 to i64
  store i64 %14815, i64* %RDX.i1943, align 8
  %14816 = shl nsw i64 %14815, 2
  %14817 = add i64 %14816, %14783
  %14818 = load i32, i32* %EDI.i1741, align 4
  %14819 = add i64 %14742, 33
  store i64 %14819, i64* %3, align 8
  %14820 = inttoptr i64 %14817 to i32*
  store i32 %14818, i32* %14820, align 4
  %14821 = load i64, i64* %RBP.i, align 8
  %14822 = add i64 %14821, -360
  %14823 = load i64, i64* %3, align 8
  %14824 = add i64 %14823, 6
  store i64 %14824, i64* %3, align 8
  %14825 = inttoptr i64 %14822 to i32*
  %14826 = load i32, i32* %14825, align 4
  %14827 = zext i32 %14826 to i64
  store i64 %14827, i64* %RDI.i6998, align 8
  %14828 = add i64 %14821, -44
  %14829 = add i64 %14823, 10
  store i64 %14829, i64* %3, align 8
  %14830 = inttoptr i64 %14828 to i32*
  %14831 = load i32, i32* %14830, align 4
  %14832 = sext i32 %14831 to i64
  %14833 = shl nsw i64 %14832, 6
  store i64 %14833, i64* %RDX.i1943, align 8
  %14834 = load i64, i64* %RCX.i1588, align 8
  %14835 = add i64 %14833, %14834
  store i64 %14835, i64* %RCX.i1588, align 8
  %14836 = icmp ult i64 %14835, %14834
  %14837 = icmp ult i64 %14835, %14833
  %14838 = or i1 %14836, %14837
  %14839 = zext i1 %14838 to i8
  store i8 %14839, i8* %17, align 1
  %14840 = trunc i64 %14835 to i32
  %14841 = and i32 %14840, 255
  %14842 = tail call i32 @llvm.ctpop.i32(i32 %14841)
  %14843 = trunc i32 %14842 to i8
  %14844 = and i8 %14843, 1
  %14845 = xor i8 %14844, 1
  store i8 %14845, i8* %18, align 1
  %14846 = xor i64 %14834, %14835
  %14847 = lshr i64 %14846, 4
  %14848 = trunc i64 %14847 to i8
  %14849 = and i8 %14848, 1
  store i8 %14849, i8* %19, align 1
  %14850 = icmp eq i64 %14835, 0
  %14851 = zext i1 %14850 to i8
  store i8 %14851, i8* %20, align 1
  %14852 = lshr i64 %14835, 63
  %14853 = trunc i64 %14852 to i8
  store i8 %14853, i8* %21, align 1
  %14854 = lshr i64 %14834, 63
  %14855 = lshr i64 %14832, 57
  %14856 = and i64 %14855, 1
  %14857 = xor i64 %14852, %14854
  %14858 = xor i64 %14852, %14856
  %14859 = add nuw nsw i64 %14857, %14858
  %14860 = icmp eq i64 %14859, 2
  %14861 = zext i1 %14860 to i8
  store i8 %14861, i8* %22, align 1
  %14862 = add i64 %14821, -48
  %14863 = add i64 %14823, 21
  store i64 %14863, i64* %3, align 8
  %14864 = inttoptr i64 %14862 to i32*
  %14865 = load i32, i32* %14864, align 4
  %14866 = sext i32 %14865 to i64
  store i64 %14866, i64* %RDX.i1943, align 8
  %14867 = shl nsw i64 %14866, 2
  %14868 = add i64 %14867, %14835
  %14869 = add i64 %14823, 25
  store i64 %14869, i64* %3, align 8
  %14870 = inttoptr i64 %14868 to i32*
  %14871 = load i32, i32* %14870, align 4
  %14872 = zext i32 %14871 to i64
  %14873 = shl nuw i64 %14872, 32
  %14874 = ashr i64 %14873, 33
  %14875 = and i64 %14874, 4294967295
  store i64 %14875, i64* %R9.i1633, align 8
  %14876 = load i64, i64* %RDI.i6998, align 8
  %14877 = trunc i64 %14874 to i32
  %14878 = trunc i64 %14876 to i32
  %14879 = add i32 %14877, %14878
  %14880 = zext i32 %14879 to i64
  store i64 %14880, i64* %RDI.i6998, align 8
  %14881 = icmp ult i32 %14879, %14878
  %14882 = icmp ult i32 %14879, %14877
  %14883 = or i1 %14881, %14882
  %14884 = zext i1 %14883 to i8
  store i8 %14884, i8* %17, align 1
  %14885 = and i32 %14879, 255
  %14886 = tail call i32 @llvm.ctpop.i32(i32 %14885)
  %14887 = trunc i32 %14886 to i8
  %14888 = and i8 %14887, 1
  %14889 = xor i8 %14888, 1
  store i8 %14889, i8* %18, align 1
  %14890 = xor i64 %14874, %14876
  %14891 = trunc i64 %14890 to i32
  %14892 = xor i32 %14891, %14879
  %14893 = lshr i32 %14892, 4
  %14894 = trunc i32 %14893 to i8
  %14895 = and i8 %14894, 1
  store i8 %14895, i8* %19, align 1
  %14896 = icmp eq i32 %14879, 0
  %14897 = zext i1 %14896 to i8
  store i8 %14897, i8* %20, align 1
  %14898 = lshr i32 %14879, 31
  %14899 = trunc i32 %14898 to i8
  store i8 %14899, i8* %21, align 1
  %14900 = lshr i32 %14878, 31
  %14901 = lshr i64 %14874, 31
  %14902 = trunc i64 %14901 to i32
  %14903 = and i32 %14902, 1
  %14904 = xor i32 %14898, %14900
  %14905 = xor i32 %14898, %14903
  %14906 = add nuw nsw i32 %14904, %14905
  %14907 = icmp eq i32 %14906, 2
  %14908 = zext i1 %14907 to i8
  store i8 %14908, i8* %22, align 1
  %14909 = load i64, i64* %RBP.i, align 8
  %14910 = add i64 %14909, -44
  %14911 = add i64 %14823, 35
  store i64 %14911, i64* %3, align 8
  %14912 = inttoptr i64 %14910 to i32*
  %14913 = load i32, i32* %14912, align 4
  %14914 = sext i32 %14913 to i64
  %14915 = shl nsw i64 %14914, 6
  store i64 %14915, i64* %RCX.i1588, align 8
  %14916 = load i64, i64* %RAX.i1659, align 8
  %14917 = add i64 %14915, %14916
  store i64 %14917, i64* %RAX.i1659, align 8
  %14918 = icmp ult i64 %14917, %14916
  %14919 = icmp ult i64 %14917, %14915
  %14920 = or i1 %14918, %14919
  %14921 = zext i1 %14920 to i8
  store i8 %14921, i8* %17, align 1
  %14922 = trunc i64 %14917 to i32
  %14923 = and i32 %14922, 255
  %14924 = tail call i32 @llvm.ctpop.i32(i32 %14923)
  %14925 = trunc i32 %14924 to i8
  %14926 = and i8 %14925, 1
  %14927 = xor i8 %14926, 1
  store i8 %14927, i8* %18, align 1
  %14928 = xor i64 %14916, %14917
  %14929 = lshr i64 %14928, 4
  %14930 = trunc i64 %14929 to i8
  %14931 = and i8 %14930, 1
  store i8 %14931, i8* %19, align 1
  %14932 = icmp eq i64 %14917, 0
  %14933 = zext i1 %14932 to i8
  store i8 %14933, i8* %20, align 1
  %14934 = lshr i64 %14917, 63
  %14935 = trunc i64 %14934 to i8
  store i8 %14935, i8* %21, align 1
  %14936 = lshr i64 %14916, 63
  %14937 = lshr i64 %14914, 57
  %14938 = and i64 %14937, 1
  %14939 = xor i64 %14934, %14936
  %14940 = xor i64 %14934, %14938
  %14941 = add nuw nsw i64 %14939, %14940
  %14942 = icmp eq i64 %14941, 2
  %14943 = zext i1 %14942 to i8
  store i8 %14943, i8* %22, align 1
  %14944 = add i64 %14909, -48
  %14945 = add i64 %14823, 46
  store i64 %14945, i64* %3, align 8
  %14946 = inttoptr i64 %14944 to i32*
  %14947 = load i32, i32* %14946, align 4
  %14948 = sext i32 %14947 to i64
  store i64 %14948, i64* %RCX.i1588, align 8
  %14949 = shl nsw i64 %14948, 2
  %14950 = add i64 %14949, %14917
  %14951 = load i32, i32* %EDI.i1741, align 4
  %14952 = add i64 %14823, 49
  store i64 %14952, i64* %3, align 8
  %14953 = inttoptr i64 %14950 to i32*
  store i32 %14951, i32* %14953, align 4
  %14954 = load i64, i64* %RBP.i, align 8
  %14955 = add i64 %14954, -44
  %14956 = load i64, i64* %3, align 8
  %14957 = add i64 %14956, 3
  store i64 %14957, i64* %3, align 8
  %14958 = inttoptr i64 %14955 to i32*
  %14959 = load i32, i32* %14958, align 4
  %14960 = add i32 %14959, 1
  %14961 = zext i32 %14960 to i64
  store i64 %14961, i64* %RAX.i1659, align 8
  %14962 = icmp eq i32 %14959, -1
  %14963 = icmp eq i32 %14960, 0
  %14964 = or i1 %14962, %14963
  %14965 = zext i1 %14964 to i8
  store i8 %14965, i8* %17, align 1
  %14966 = and i32 %14960, 255
  %14967 = tail call i32 @llvm.ctpop.i32(i32 %14966)
  %14968 = trunc i32 %14967 to i8
  %14969 = and i8 %14968, 1
  %14970 = xor i8 %14969, 1
  store i8 %14970, i8* %18, align 1
  %14971 = xor i32 %14960, %14959
  %14972 = lshr i32 %14971, 4
  %14973 = trunc i32 %14972 to i8
  %14974 = and i8 %14973, 1
  store i8 %14974, i8* %19, align 1
  %14975 = zext i1 %14963 to i8
  store i8 %14975, i8* %20, align 1
  %14976 = lshr i32 %14960, 31
  %14977 = trunc i32 %14976 to i8
  store i8 %14977, i8* %21, align 1
  %14978 = lshr i32 %14959, 31
  %14979 = xor i32 %14976, %14978
  %14980 = add nuw nsw i32 %14979, %14976
  %14981 = icmp eq i32 %14980, 2
  %14982 = zext i1 %14981 to i8
  store i8 %14982, i8* %22, align 1
  %14983 = add i64 %14956, 9
  store i64 %14983, i64* %3, align 8
  store i32 %14960, i32* %14958, align 4
  %14984 = load i64, i64* %3, align 8
  %14985 = add i64 %14984, -552
  store i64 %14985, i64* %3, align 8
  br label %block_.L_4858ef

block_.L_485b1c:                                  ; preds = %block_.L_4858ef
  %14986 = add i64 %13793, -48
  %14987 = add i64 %13821, 8
  store i64 %14987, i64* %3, align 8
  %14988 = inttoptr i64 %14986 to i32*
  %14989 = load i32, i32* %14988, align 4
  %14990 = add i32 %14989, 1
  %14991 = zext i32 %14990 to i64
  store i64 %14991, i64* %RAX.i1659, align 8
  %14992 = icmp eq i32 %14989, -1
  %14993 = icmp eq i32 %14990, 0
  %14994 = or i1 %14992, %14993
  %14995 = zext i1 %14994 to i8
  store i8 %14995, i8* %17, align 1
  %14996 = and i32 %14990, 255
  %14997 = tail call i32 @llvm.ctpop.i32(i32 %14996)
  %14998 = trunc i32 %14997 to i8
  %14999 = and i8 %14998, 1
  %15000 = xor i8 %14999, 1
  store i8 %15000, i8* %18, align 1
  %15001 = xor i32 %14990, %14989
  %15002 = lshr i32 %15001, 4
  %15003 = trunc i32 %15002 to i8
  %15004 = and i8 %15003, 1
  store i8 %15004, i8* %19, align 1
  %15005 = zext i1 %14993 to i8
  store i8 %15005, i8* %20, align 1
  %15006 = lshr i32 %14990, 31
  %15007 = trunc i32 %15006 to i8
  store i8 %15007, i8* %21, align 1
  %15008 = lshr i32 %14989, 31
  %15009 = xor i32 %15006, %15008
  %15010 = add nuw nsw i32 %15009, %15006
  %15011 = icmp eq i32 %15010, 2
  %15012 = zext i1 %15011 to i8
  store i8 %15012, i8* %22, align 1
  %15013 = add i64 %13821, 14
  store i64 %15013, i64* %3, align 8
  store i32 %14990, i32* %14988, align 4
  %15014 = load i64, i64* %3, align 8
  %15015 = add i64 %15014, -588
  store i64 %15015, i64* %3, align 8
  br label %block_.L_4858de

block_.L_485b2f:                                  ; preds = %block_.L_4858de
  %15016 = add i64 %13788, 7
  store i64 %15016, i64* %3, align 8
  store i32 0, i32* %13763, align 4
  %.pre474 = load i64, i64* %3, align 8
  br label %block_.L_485b36

block_.L_485b36:                                  ; preds = %block_.L_485b9b, %block_.L_485b2f
  %15017 = phi i64 [ %15249, %block_.L_485b9b ], [ %.pre474, %block_.L_485b2f ]
  %15018 = load i64, i64* %RBP.i, align 8
  %15019 = add i64 %15018, -48
  %15020 = add i64 %15017, 4
  store i64 %15020, i64* %3, align 8
  %15021 = inttoptr i64 %15019 to i32*
  %15022 = load i32, i32* %15021, align 4
  %15023 = add i32 %15022, -4
  %15024 = icmp ult i32 %15022, 4
  %15025 = zext i1 %15024 to i8
  store i8 %15025, i8* %17, align 1
  %15026 = and i32 %15023, 255
  %15027 = tail call i32 @llvm.ctpop.i32(i32 %15026)
  %15028 = trunc i32 %15027 to i8
  %15029 = and i8 %15028, 1
  %15030 = xor i8 %15029, 1
  store i8 %15030, i8* %18, align 1
  %15031 = xor i32 %15023, %15022
  %15032 = lshr i32 %15031, 4
  %15033 = trunc i32 %15032 to i8
  %15034 = and i8 %15033, 1
  store i8 %15034, i8* %19, align 1
  %15035 = icmp eq i32 %15023, 0
  %15036 = zext i1 %15035 to i8
  store i8 %15036, i8* %20, align 1
  %15037 = lshr i32 %15023, 31
  %15038 = trunc i32 %15037 to i8
  store i8 %15038, i8* %21, align 1
  %15039 = lshr i32 %15022, 31
  %15040 = xor i32 %15037, %15039
  %15041 = add nuw nsw i32 %15040, %15039
  %15042 = icmp eq i32 %15041, 2
  %15043 = zext i1 %15042 to i8
  store i8 %15043, i8* %22, align 1
  %15044 = icmp ne i8 %15038, 0
  %15045 = xor i1 %15044, %15042
  %.v711 = select i1 %15045, i64 10, i64 120
  %15046 = add i64 %15017, %.v711
  store i64 %15046, i64* %3, align 8
  br i1 %15045, label %block_485b40, label %block_.L_485bae

block_485b40:                                     ; preds = %block_.L_485b36
  %15047 = add i64 %15018, -44
  %15048 = add i64 %15046, 7
  store i64 %15048, i64* %3, align 8
  %15049 = inttoptr i64 %15047 to i32*
  store i32 0, i32* %15049, align 4
  %.pre550 = load i64, i64* %3, align 8
  br label %block_.L_485b47

block_.L_485b47:                                  ; preds = %block_485b51, %block_485b40
  %15050 = phi i64 [ %15219, %block_485b51 ], [ %.pre550, %block_485b40 ]
  %15051 = load i64, i64* %RBP.i, align 8
  %15052 = add i64 %15051, -44
  %15053 = add i64 %15050, 4
  store i64 %15053, i64* %3, align 8
  %15054 = inttoptr i64 %15052 to i32*
  %15055 = load i32, i32* %15054, align 4
  %15056 = add i32 %15055, -4
  %15057 = icmp ult i32 %15055, 4
  %15058 = zext i1 %15057 to i8
  store i8 %15058, i8* %17, align 1
  %15059 = and i32 %15056, 255
  %15060 = tail call i32 @llvm.ctpop.i32(i32 %15059)
  %15061 = trunc i32 %15060 to i8
  %15062 = and i8 %15061, 1
  %15063 = xor i8 %15062, 1
  store i8 %15063, i8* %18, align 1
  %15064 = xor i32 %15056, %15055
  %15065 = lshr i32 %15064, 4
  %15066 = trunc i32 %15065 to i8
  %15067 = and i8 %15066, 1
  store i8 %15067, i8* %19, align 1
  %15068 = icmp eq i32 %15056, 0
  %15069 = zext i1 %15068 to i8
  store i8 %15069, i8* %20, align 1
  %15070 = lshr i32 %15056, 31
  %15071 = trunc i32 %15070 to i8
  store i8 %15071, i8* %21, align 1
  %15072 = lshr i32 %15055, 31
  %15073 = xor i32 %15070, %15072
  %15074 = add nuw nsw i32 %15073, %15072
  %15075 = icmp eq i32 %15074, 2
  %15076 = zext i1 %15075 to i8
  store i8 %15076, i8* %22, align 1
  %15077 = icmp ne i8 %15071, 0
  %15078 = xor i1 %15077, %15075
  %.v663 = select i1 %15078, i64 10, i64 84
  %15079 = add i64 %15050, %.v663
  store i64 %15079, i64* %3, align 8
  br i1 %15078, label %block_485b51, label %block_.L_485b9b

block_485b51:                                     ; preds = %block_.L_485b47
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX.i1659, align 8
  %15080 = add i64 %15079, 14
  store i64 %15080, i64* %3, align 8
  %15081 = load i32, i32* %15054, align 4
  %15082 = sext i32 %15081 to i64
  %15083 = shl nsw i64 %15082, 6
  store i64 %15083, i64* %RCX.i1588, align 8
  %15084 = add i64 %15083, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  store i64 %15084, i64* %RAX.i1659, align 8
  %15085 = icmp ult i64 %15084, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  %15086 = icmp ult i64 %15084, %15083
  %15087 = or i1 %15085, %15086
  %15088 = zext i1 %15087 to i8
  store i8 %15088, i8* %17, align 1
  %15089 = trunc i64 %15084 to i32
  %15090 = and i32 %15089, 248
  %15091 = tail call i32 @llvm.ctpop.i32(i32 %15090)
  %15092 = trunc i32 %15091 to i8
  %15093 = and i8 %15092, 1
  %15094 = xor i8 %15093, 1
  store i8 %15094, i8* %18, align 1
  %15095 = xor i64 %15084, ptrtoint (%G__0x723720_type* @G__0x723720 to i64)
  %15096 = lshr i64 %15095, 4
  %15097 = trunc i64 %15096 to i8
  %15098 = and i8 %15097, 1
  store i8 %15098, i8* %19, align 1
  %15099 = icmp eq i64 %15084, 0
  %15100 = zext i1 %15099 to i8
  store i8 %15100, i8* %20, align 1
  %15101 = lshr i64 %15084, 63
  %15102 = trunc i64 %15101 to i8
  store i8 %15102, i8* %21, align 1
  %15103 = lshr i64 %15082, 57
  %15104 = and i64 %15103, 1
  %15105 = xor i64 %15101, lshr (i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64 63)
  %15106 = xor i64 %15101, %15104
  %15107 = add nuw nsw i64 %15105, %15106
  %15108 = icmp eq i64 %15107, 2
  %15109 = zext i1 %15108 to i8
  store i8 %15109, i8* %22, align 1
  %15110 = add i64 %15051, -48
  %15111 = add i64 %15079, 25
  store i64 %15111, i64* %3, align 8
  %15112 = inttoptr i64 %15110 to i32*
  %15113 = load i32, i32* %15112, align 4
  %15114 = sext i32 %15113 to i64
  store i64 %15114, i64* %RCX.i1588, align 8
  %15115 = shl nsw i64 %15114, 2
  %15116 = add i64 %15115, %15084
  %15117 = add i64 %15079, 28
  store i64 %15117, i64* %3, align 8
  %15118 = inttoptr i64 %15116 to i32*
  %15119 = load i32, i32* %15118, align 4
  %15120 = zext i32 %15119 to i64
  store i64 %15120, i64* %RDX.i1943, align 8
  %15121 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %15122 = add i64 %15121, 13112
  store i64 %15122, i64* %RAX.i1659, align 8
  %15123 = icmp ugt i64 %15121, -13113
  %15124 = zext i1 %15123 to i8
  store i8 %15124, i8* %17, align 1
  %15125 = trunc i64 %15122 to i32
  %15126 = and i32 %15125, 255
  %15127 = tail call i32 @llvm.ctpop.i32(i32 %15126)
  %15128 = trunc i32 %15127 to i8
  %15129 = and i8 %15128, 1
  %15130 = xor i8 %15129, 1
  store i8 %15130, i8* %18, align 1
  %15131 = xor i64 %15121, 16
  %15132 = xor i64 %15131, %15122
  %15133 = lshr i64 %15132, 4
  %15134 = trunc i64 %15133 to i8
  %15135 = and i8 %15134, 1
  store i8 %15135, i8* %19, align 1
  %15136 = icmp eq i64 %15122, 0
  %15137 = zext i1 %15136 to i8
  store i8 %15137, i8* %20, align 1
  %15138 = lshr i64 %15122, 63
  %15139 = trunc i64 %15138 to i8
  store i8 %15139, i8* %21, align 1
  %15140 = lshr i64 %15121, 63
  %15141 = xor i64 %15138, %15140
  %15142 = add nuw nsw i64 %15141, %15138
  %15143 = icmp eq i64 %15142, 2
  %15144 = zext i1 %15143 to i8
  store i8 %15144, i8* %22, align 1
  %15145 = load i64, i64* %RBP.i, align 8
  %15146 = add i64 %15145, -44
  %15147 = add i64 %15079, 46
  store i64 %15147, i64* %3, align 8
  %15148 = inttoptr i64 %15146 to i32*
  %15149 = load i32, i32* %15148, align 4
  %15150 = sext i32 %15149 to i64
  %15151 = shl nsw i64 %15150, 6
  store i64 %15151, i64* %RCX.i1588, align 8
  %15152 = add i64 %15151, %15122
  store i64 %15152, i64* %RAX.i1659, align 8
  %15153 = icmp ult i64 %15152, %15122
  %15154 = icmp ult i64 %15152, %15151
  %15155 = or i1 %15153, %15154
  %15156 = zext i1 %15155 to i8
  store i8 %15156, i8* %17, align 1
  %15157 = trunc i64 %15152 to i32
  %15158 = and i32 %15157, 255
  %15159 = tail call i32 @llvm.ctpop.i32(i32 %15158)
  %15160 = trunc i32 %15159 to i8
  %15161 = and i8 %15160, 1
  %15162 = xor i8 %15161, 1
  store i8 %15162, i8* %18, align 1
  %15163 = xor i64 %15122, %15152
  %15164 = lshr i64 %15163, 4
  %15165 = trunc i64 %15164 to i8
  %15166 = and i8 %15165, 1
  store i8 %15166, i8* %19, align 1
  %15167 = icmp eq i64 %15152, 0
  %15168 = zext i1 %15167 to i8
  store i8 %15168, i8* %20, align 1
  %15169 = lshr i64 %15152, 63
  %15170 = trunc i64 %15169 to i8
  store i8 %15170, i8* %21, align 1
  %15171 = lshr i64 %15150, 57
  %15172 = and i64 %15171, 1
  %15173 = xor i64 %15169, %15138
  %15174 = xor i64 %15169, %15172
  %15175 = add nuw nsw i64 %15173, %15174
  %15176 = icmp eq i64 %15175, 2
  %15177 = zext i1 %15176 to i8
  store i8 %15177, i8* %22, align 1
  %15178 = add i64 %15145, -48
  %15179 = add i64 %15079, 57
  store i64 %15179, i64* %3, align 8
  %15180 = inttoptr i64 %15178 to i32*
  %15181 = load i32, i32* %15180, align 4
  %15182 = sext i32 %15181 to i64
  store i64 %15182, i64* %RCX.i1588, align 8
  %15183 = shl nsw i64 %15182, 2
  %15184 = add i64 %15183, %15152
  %15185 = load i32, i32* %108, align 4
  %15186 = add i64 %15079, 60
  store i64 %15186, i64* %3, align 8
  %15187 = inttoptr i64 %15184 to i32*
  store i32 %15185, i32* %15187, align 4
  %15188 = load i64, i64* %RBP.i, align 8
  %15189 = add i64 %15188, -44
  %15190 = load i64, i64* %3, align 8
  %15191 = add i64 %15190, 3
  store i64 %15191, i64* %3, align 8
  %15192 = inttoptr i64 %15189 to i32*
  %15193 = load i32, i32* %15192, align 4
  %15194 = add i32 %15193, 1
  %15195 = zext i32 %15194 to i64
  store i64 %15195, i64* %RAX.i1659, align 8
  %15196 = icmp eq i32 %15193, -1
  %15197 = icmp eq i32 %15194, 0
  %15198 = or i1 %15196, %15197
  %15199 = zext i1 %15198 to i8
  store i8 %15199, i8* %17, align 1
  %15200 = and i32 %15194, 255
  %15201 = tail call i32 @llvm.ctpop.i32(i32 %15200)
  %15202 = trunc i32 %15201 to i8
  %15203 = and i8 %15202, 1
  %15204 = xor i8 %15203, 1
  store i8 %15204, i8* %18, align 1
  %15205 = xor i32 %15194, %15193
  %15206 = lshr i32 %15205, 4
  %15207 = trunc i32 %15206 to i8
  %15208 = and i8 %15207, 1
  store i8 %15208, i8* %19, align 1
  %15209 = zext i1 %15197 to i8
  store i8 %15209, i8* %20, align 1
  %15210 = lshr i32 %15194, 31
  %15211 = trunc i32 %15210 to i8
  store i8 %15211, i8* %21, align 1
  %15212 = lshr i32 %15193, 31
  %15213 = xor i32 %15210, %15212
  %15214 = add nuw nsw i32 %15213, %15210
  %15215 = icmp eq i32 %15214, 2
  %15216 = zext i1 %15215 to i8
  store i8 %15216, i8* %22, align 1
  %15217 = add i64 %15190, 9
  store i64 %15217, i64* %3, align 8
  store i32 %15194, i32* %15192, align 4
  %15218 = load i64, i64* %3, align 8
  %15219 = add i64 %15218, -79
  store i64 %15219, i64* %3, align 8
  br label %block_.L_485b47

block_.L_485b9b:                                  ; preds = %block_.L_485b47
  %15220 = add i64 %15051, -48
  %15221 = add i64 %15079, 8
  store i64 %15221, i64* %3, align 8
  %15222 = inttoptr i64 %15220 to i32*
  %15223 = load i32, i32* %15222, align 4
  %15224 = add i32 %15223, 1
  %15225 = zext i32 %15224 to i64
  store i64 %15225, i64* %RAX.i1659, align 8
  %15226 = icmp eq i32 %15223, -1
  %15227 = icmp eq i32 %15224, 0
  %15228 = or i1 %15226, %15227
  %15229 = zext i1 %15228 to i8
  store i8 %15229, i8* %17, align 1
  %15230 = and i32 %15224, 255
  %15231 = tail call i32 @llvm.ctpop.i32(i32 %15230)
  %15232 = trunc i32 %15231 to i8
  %15233 = and i8 %15232, 1
  %15234 = xor i8 %15233, 1
  store i8 %15234, i8* %18, align 1
  %15235 = xor i32 %15224, %15223
  %15236 = lshr i32 %15235, 4
  %15237 = trunc i32 %15236 to i8
  %15238 = and i8 %15237, 1
  store i8 %15238, i8* %19, align 1
  %15239 = zext i1 %15227 to i8
  store i8 %15239, i8* %20, align 1
  %15240 = lshr i32 %15224, 31
  %15241 = trunc i32 %15240 to i8
  store i8 %15241, i8* %21, align 1
  %15242 = lshr i32 %15223, 31
  %15243 = xor i32 %15240, %15242
  %15244 = add nuw nsw i32 %15243, %15240
  %15245 = icmp eq i32 %15244, 2
  %15246 = zext i1 %15245 to i8
  store i8 %15246, i8* %22, align 1
  %15247 = add i64 %15079, 14
  store i64 %15247, i64* %3, align 8
  store i32 %15224, i32* %15222, align 4
  %15248 = load i64, i64* %3, align 8
  %15249 = add i64 %15248, -115
  store i64 %15249, i64* %3, align 8
  br label %block_.L_485b36

block_.L_485bae:                                  ; preds = %block_.L_485b36
  %15250 = add i64 %15018, -68
  store i64 %15250, i64* %RDX.i1943, align 8
  store i64 1, i64* %RCX.i1588, align 8
  %15251 = add i64 %15018, -220
  %15252 = add i64 %15046, 15
  store i64 %15252, i64* %3, align 8
  %15253 = inttoptr i64 %15251 to i32*
  %15254 = load i32, i32* %15253, align 4
  %15255 = zext i32 %15254 to i64
  store i64 %15255, i64* %RDI.i6998, align 8
  %15256 = add i64 %15018, -224
  %15257 = add i64 %15046, 21
  store i64 %15257, i64* %3, align 8
  %15258 = inttoptr i64 %15256 to i32*
  %15259 = load i32, i32* %15258, align 4
  %15260 = zext i32 %15259 to i64
  store i64 %15260, i64* %RSI.i2015, align 8
  %15261 = add i64 %15046, -522590
  %15262 = add i64 %15046, 26
  %15263 = load i64, i64* %6, align 8
  %15264 = add i64 %15263, -8
  %15265 = inttoptr i64 %15264 to i64*
  store i64 %15262, i64* %15265, align 8
  store i64 %15264, i64* %6, align 8
  store i64 %15261, i64* %3, align 8
  %call2_485bc3 = tail call %struct.Memory* @sub_406250.dct_luma(%struct.State* nonnull %0, i64 %15261, %struct.Memory* %MEMORY.8)
  %15266 = load i64, i64* %RBP.i, align 8
  %15267 = add i64 %15266, -76
  %15268 = load i32, i32* %EAX.i2033, align 4
  %15269 = load i64, i64* %3, align 8
  %15270 = add i64 %15269, 3
  store i64 %15270, i64* %3, align 8
  %15271 = inttoptr i64 %15267 to i32*
  store i32 %15268, i32* %15271, align 4
  %15272 = load i64, i64* %RBP.i, align 8
  %15273 = add i64 %15272, -48
  %15274 = load i64, i64* %3, align 8
  %15275 = add i64 %15274, 7
  store i64 %15275, i64* %3, align 8
  %15276 = inttoptr i64 %15273 to i32*
  store i32 0, i32* %15276, align 4
  %.pre475 = load i64, i64* %3, align 8
  br label %block_.L_485bd2

block_.L_485bd2:                                  ; preds = %block_.L_485c74, %block_.L_485bae
  %15277 = phi i64 [ %15622, %block_.L_485c74 ], [ %.pre475, %block_.L_485bae ]
  %15278 = load i64, i64* %RBP.i, align 8
  %15279 = add i64 %15278, -48
  %15280 = add i64 %15277, 4
  store i64 %15280, i64* %3, align 8
  %15281 = inttoptr i64 %15279 to i32*
  %15282 = load i32, i32* %15281, align 4
  %15283 = add i32 %15282, -4
  %15284 = icmp ult i32 %15282, 4
  %15285 = zext i1 %15284 to i8
  store i8 %15285, i8* %17, align 1
  %15286 = and i32 %15283, 255
  %15287 = tail call i32 @llvm.ctpop.i32(i32 %15286)
  %15288 = trunc i32 %15287 to i8
  %15289 = and i8 %15288, 1
  %15290 = xor i8 %15289, 1
  store i8 %15290, i8* %18, align 1
  %15291 = xor i32 %15283, %15282
  %15292 = lshr i32 %15291, 4
  %15293 = trunc i32 %15292 to i8
  %15294 = and i8 %15293, 1
  store i8 %15294, i8* %19, align 1
  %15295 = icmp eq i32 %15283, 0
  %15296 = zext i1 %15295 to i8
  store i8 %15296, i8* %20, align 1
  %15297 = lshr i32 %15283, 31
  %15298 = trunc i32 %15297 to i8
  store i8 %15298, i8* %21, align 1
  %15299 = lshr i32 %15282, 31
  %15300 = xor i32 %15297, %15299
  %15301 = add nuw nsw i32 %15300, %15299
  %15302 = icmp eq i32 %15301, 2
  %15303 = zext i1 %15302 to i8
  store i8 %15303, i8* %22, align 1
  %15304 = icmp ne i8 %15298, 0
  %15305 = xor i1 %15304, %15302
  %.v712 = select i1 %15305, i64 10, i64 181
  %15306 = add i64 %15277, %.v712
  store i64 %15306, i64* %3, align 8
  br i1 %15305, label %block_485bdc, label %block_.L_485c87

block_485bdc:                                     ; preds = %block_.L_485bd2
  %15307 = add i64 %15278, -44
  %15308 = add i64 %15306, 7
  store i64 %15308, i64* %3, align 8
  %15309 = inttoptr i64 %15307 to i32*
  store i32 0, i32* %15309, align 4
  %.pre549 = load i64, i64* %3, align 8
  br label %block_.L_485be3

block_.L_485be3:                                  ; preds = %block_485bed, %block_485bdc
  %15310 = phi i64 [ %15592, %block_485bed ], [ %.pre549, %block_485bdc ]
  %15311 = load i64, i64* %RBP.i, align 8
  %15312 = add i64 %15311, -44
  %15313 = add i64 %15310, 4
  store i64 %15313, i64* %3, align 8
  %15314 = inttoptr i64 %15312 to i32*
  %15315 = load i32, i32* %15314, align 4
  %15316 = add i32 %15315, -4
  %15317 = icmp ult i32 %15315, 4
  %15318 = zext i1 %15317 to i8
  store i8 %15318, i8* %17, align 1
  %15319 = and i32 %15316, 255
  %15320 = tail call i32 @llvm.ctpop.i32(i32 %15319)
  %15321 = trunc i32 %15320 to i8
  %15322 = and i8 %15321, 1
  %15323 = xor i8 %15322, 1
  store i8 %15323, i8* %18, align 1
  %15324 = xor i32 %15316, %15315
  %15325 = lshr i32 %15324, 4
  %15326 = trunc i32 %15325 to i8
  %15327 = and i8 %15326, 1
  store i8 %15327, i8* %19, align 1
  %15328 = icmp eq i32 %15316, 0
  %15329 = zext i1 %15328 to i8
  store i8 %15329, i8* %20, align 1
  %15330 = lshr i32 %15316, 31
  %15331 = trunc i32 %15330 to i8
  store i8 %15331, i8* %21, align 1
  %15332 = lshr i32 %15315, 31
  %15333 = xor i32 %15330, %15332
  %15334 = add nuw nsw i32 %15333, %15332
  %15335 = icmp eq i32 %15334, 2
  %15336 = zext i1 %15335 to i8
  store i8 %15336, i8* %22, align 1
  %15337 = icmp ne i8 %15331, 0
  %15338 = xor i1 %15337, %15335
  %.v662 = select i1 %15338, i64 10, i64 145
  %15339 = add i64 %15310, %.v662
  store i64 %15339, i64* %3, align 8
  br i1 %15338, label %block_485bed, label %block_.L_485c74

block_485bed:                                     ; preds = %block_.L_485be3
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RAX.i1659, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RCX.i1588, align 8
  %15340 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %15341 = add i64 %15340, 13112
  store i64 %15341, i64* %RDX.i1943, align 8
  %15342 = icmp ugt i64 %15340, -13113
  %15343 = zext i1 %15342 to i8
  store i8 %15343, i8* %17, align 1
  %15344 = trunc i64 %15341 to i32
  %15345 = and i32 %15344, 255
  %15346 = tail call i32 @llvm.ctpop.i32(i32 %15345)
  %15347 = trunc i32 %15346 to i8
  %15348 = and i8 %15347, 1
  %15349 = xor i8 %15348, 1
  store i8 %15349, i8* %18, align 1
  %15350 = xor i64 %15340, 16
  %15351 = xor i64 %15350, %15341
  %15352 = lshr i64 %15351, 4
  %15353 = trunc i64 %15352 to i8
  %15354 = and i8 %15353, 1
  store i8 %15354, i8* %19, align 1
  %15355 = icmp eq i64 %15341, 0
  %15356 = zext i1 %15355 to i8
  store i8 %15356, i8* %20, align 1
  %15357 = lshr i64 %15341, 63
  %15358 = trunc i64 %15357 to i8
  store i8 %15358, i8* %21, align 1
  %15359 = lshr i64 %15340, 63
  %15360 = xor i64 %15357, %15359
  %15361 = add nuw nsw i64 %15360, %15357
  %15362 = icmp eq i64 %15361, 2
  %15363 = zext i1 %15362 to i8
  store i8 %15363, i8* %22, align 1
  %15364 = add i64 %15339, 39
  store i64 %15364, i64* %3, align 8
  %15365 = load i32, i32* %15314, align 4
  %15366 = sext i32 %15365 to i64
  %15367 = shl nsw i64 %15366, 6
  store i64 %15367, i64* %RSI.i2015, align 8
  %15368 = add i64 %15367, %15341
  store i64 %15368, i64* %RDX.i1943, align 8
  %15369 = icmp ult i64 %15368, %15341
  %15370 = icmp ult i64 %15368, %15367
  %15371 = or i1 %15369, %15370
  %15372 = zext i1 %15371 to i8
  store i8 %15372, i8* %17, align 1
  %15373 = trunc i64 %15368 to i32
  %15374 = and i32 %15373, 255
  %15375 = tail call i32 @llvm.ctpop.i32(i32 %15374)
  %15376 = trunc i32 %15375 to i8
  %15377 = and i8 %15376, 1
  %15378 = xor i8 %15377, 1
  store i8 %15378, i8* %18, align 1
  %15379 = xor i64 %15341, %15368
  %15380 = lshr i64 %15379, 4
  %15381 = trunc i64 %15380 to i8
  %15382 = and i8 %15381, 1
  store i8 %15382, i8* %19, align 1
  %15383 = icmp eq i64 %15368, 0
  %15384 = zext i1 %15383 to i8
  store i8 %15384, i8* %20, align 1
  %15385 = lshr i64 %15368, 63
  %15386 = trunc i64 %15385 to i8
  store i8 %15386, i8* %21, align 1
  %15387 = lshr i64 %15366, 57
  %15388 = and i64 %15387, 1
  %15389 = xor i64 %15385, %15357
  %15390 = xor i64 %15385, %15388
  %15391 = add nuw nsw i64 %15389, %15390
  %15392 = icmp eq i64 %15391, 2
  %15393 = zext i1 %15392 to i8
  store i8 %15393, i8* %22, align 1
  %15394 = load i64, i64* %RBP.i, align 8
  %15395 = add i64 %15394, -48
  %15396 = add i64 %15339, 50
  store i64 %15396, i64* %3, align 8
  %15397 = inttoptr i64 %15395 to i32*
  %15398 = load i32, i32* %15397, align 4
  %15399 = sext i32 %15398 to i64
  store i64 %15399, i64* %RSI.i2015, align 8
  %15400 = shl nsw i64 %15399, 2
  %15401 = add i64 %15400, %15368
  %15402 = add i64 %15339, 53
  store i64 %15402, i64* %3, align 8
  %15403 = inttoptr i64 %15401 to i32*
  %15404 = load i32, i32* %15403, align 4
  %15405 = zext i32 %15404 to i64
  store i64 %15405, i64* %RDI.i6998, align 8
  %15406 = add i64 %15394, -44
  %15407 = add i64 %15339, 57
  store i64 %15407, i64* %3, align 8
  %15408 = inttoptr i64 %15406 to i32*
  %15409 = load i32, i32* %15408, align 4
  %15410 = sext i32 %15409 to i64
  %15411 = shl nsw i64 %15410, 6
  store i64 %15411, i64* %RDX.i1943, align 8
  %15412 = load i64, i64* %RCX.i1588, align 8
  %15413 = add i64 %15411, %15412
  store i64 %15413, i64* %RCX.i1588, align 8
  %15414 = icmp ult i64 %15413, %15412
  %15415 = icmp ult i64 %15413, %15411
  %15416 = or i1 %15414, %15415
  %15417 = zext i1 %15416 to i8
  store i8 %15417, i8* %17, align 1
  %15418 = trunc i64 %15413 to i32
  %15419 = and i32 %15418, 255
  %15420 = tail call i32 @llvm.ctpop.i32(i32 %15419)
  %15421 = trunc i32 %15420 to i8
  %15422 = and i8 %15421, 1
  %15423 = xor i8 %15422, 1
  store i8 %15423, i8* %18, align 1
  %15424 = xor i64 %15412, %15413
  %15425 = lshr i64 %15424, 4
  %15426 = trunc i64 %15425 to i8
  %15427 = and i8 %15426, 1
  store i8 %15427, i8* %19, align 1
  %15428 = icmp eq i64 %15413, 0
  %15429 = zext i1 %15428 to i8
  store i8 %15429, i8* %20, align 1
  %15430 = lshr i64 %15413, 63
  %15431 = trunc i64 %15430 to i8
  store i8 %15431, i8* %21, align 1
  %15432 = lshr i64 %15412, 63
  %15433 = lshr i64 %15410, 57
  %15434 = and i64 %15433, 1
  %15435 = xor i64 %15430, %15432
  %15436 = xor i64 %15430, %15434
  %15437 = add nuw nsw i64 %15435, %15436
  %15438 = icmp eq i64 %15437, 2
  %15439 = zext i1 %15438 to i8
  store i8 %15439, i8* %22, align 1
  %15440 = add i64 %15339, 68
  store i64 %15440, i64* %3, align 8
  %15441 = load i32, i32* %15397, align 4
  %15442 = sext i32 %15441 to i64
  store i64 %15442, i64* %RDX.i1943, align 8
  %15443 = shl nsw i64 %15442, 2
  %15444 = add i64 %15443, %15413
  %15445 = add i64 %15339, 71
  store i64 %15445, i64* %3, align 8
  %15446 = inttoptr i64 %15444 to i32*
  store i32 %15404, i32* %15446, align 4
  %15447 = load i64, i64* %RBP.i, align 8
  %15448 = add i64 %15447, -44
  %15449 = load i64, i64* %3, align 8
  %15450 = add i64 %15449, 4
  store i64 %15450, i64* %3, align 8
  %15451 = inttoptr i64 %15448 to i32*
  %15452 = load i32, i32* %15451, align 4
  %15453 = sext i32 %15452 to i64
  %15454 = shl nsw i64 %15453, 6
  store i64 %15454, i64* %RCX.i1588, align 8
  %15455 = load i64, i64* %RAX.i1659, align 8
  %15456 = add i64 %15454, %15455
  store i64 %15456, i64* %RAX.i1659, align 8
  %15457 = icmp ult i64 %15456, %15455
  %15458 = icmp ult i64 %15456, %15454
  %15459 = or i1 %15457, %15458
  %15460 = zext i1 %15459 to i8
  store i8 %15460, i8* %17, align 1
  %15461 = trunc i64 %15456 to i32
  %15462 = and i32 %15461, 255
  %15463 = tail call i32 @llvm.ctpop.i32(i32 %15462)
  %15464 = trunc i32 %15463 to i8
  %15465 = and i8 %15464, 1
  %15466 = xor i8 %15465, 1
  store i8 %15466, i8* %18, align 1
  %15467 = xor i64 %15455, %15456
  %15468 = lshr i64 %15467, 4
  %15469 = trunc i64 %15468 to i8
  %15470 = and i8 %15469, 1
  store i8 %15470, i8* %19, align 1
  %15471 = icmp eq i64 %15456, 0
  %15472 = zext i1 %15471 to i8
  store i8 %15472, i8* %20, align 1
  %15473 = lshr i64 %15456, 63
  %15474 = trunc i64 %15473 to i8
  store i8 %15474, i8* %21, align 1
  %15475 = lshr i64 %15455, 63
  %15476 = lshr i64 %15453, 57
  %15477 = and i64 %15476, 1
  %15478 = xor i64 %15473, %15475
  %15479 = xor i64 %15473, %15477
  %15480 = add nuw nsw i64 %15478, %15479
  %15481 = icmp eq i64 %15480, 2
  %15482 = zext i1 %15481 to i8
  store i8 %15482, i8* %22, align 1
  %15483 = add i64 %15447, -48
  %15484 = add i64 %15449, 15
  store i64 %15484, i64* %3, align 8
  %15485 = inttoptr i64 %15483 to i32*
  %15486 = load i32, i32* %15485, align 4
  %15487 = sext i32 %15486 to i64
  store i64 %15487, i64* %RCX.i1588, align 8
  %15488 = shl nsw i64 %15487, 2
  %15489 = add i64 %15488, %15456
  %15490 = add i64 %15449, 18
  store i64 %15490, i64* %3, align 8
  %15491 = inttoptr i64 %15489 to i32*
  %15492 = load i32, i32* %15491, align 4
  %15493 = zext i32 %15492 to i64
  store i64 %15493, i64* %RDI.i6998, align 8
  %15494 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %15495 = add i64 %15494, 13112
  store i64 %15495, i64* %RAX.i1659, align 8
  %15496 = icmp ugt i64 %15494, -13113
  %15497 = zext i1 %15496 to i8
  store i8 %15497, i8* %17, align 1
  %15498 = trunc i64 %15495 to i32
  %15499 = and i32 %15498, 255
  %15500 = tail call i32 @llvm.ctpop.i32(i32 %15499)
  %15501 = trunc i32 %15500 to i8
  %15502 = and i8 %15501, 1
  %15503 = xor i8 %15502, 1
  store i8 %15503, i8* %18, align 1
  %15504 = xor i64 %15494, 16
  %15505 = xor i64 %15504, %15495
  %15506 = lshr i64 %15505, 4
  %15507 = trunc i64 %15506 to i8
  %15508 = and i8 %15507, 1
  store i8 %15508, i8* %19, align 1
  %15509 = icmp eq i64 %15495, 0
  %15510 = zext i1 %15509 to i8
  store i8 %15510, i8* %20, align 1
  %15511 = lshr i64 %15495, 63
  %15512 = trunc i64 %15511 to i8
  store i8 %15512, i8* %21, align 1
  %15513 = lshr i64 %15494, 63
  %15514 = xor i64 %15511, %15513
  %15515 = add nuw nsw i64 %15514, %15511
  %15516 = icmp eq i64 %15515, 2
  %15517 = zext i1 %15516 to i8
  store i8 %15517, i8* %22, align 1
  %15518 = load i64, i64* %RBP.i, align 8
  %15519 = add i64 %15518, -44
  %15520 = add i64 %15449, 36
  store i64 %15520, i64* %3, align 8
  %15521 = inttoptr i64 %15519 to i32*
  %15522 = load i32, i32* %15521, align 4
  %15523 = sext i32 %15522 to i64
  %15524 = shl nsw i64 %15523, 6
  store i64 %15524, i64* %RCX.i1588, align 8
  %15525 = add i64 %15524, %15495
  store i64 %15525, i64* %RAX.i1659, align 8
  %15526 = icmp ult i64 %15525, %15495
  %15527 = icmp ult i64 %15525, %15524
  %15528 = or i1 %15526, %15527
  %15529 = zext i1 %15528 to i8
  store i8 %15529, i8* %17, align 1
  %15530 = trunc i64 %15525 to i32
  %15531 = and i32 %15530, 255
  %15532 = tail call i32 @llvm.ctpop.i32(i32 %15531)
  %15533 = trunc i32 %15532 to i8
  %15534 = and i8 %15533, 1
  %15535 = xor i8 %15534, 1
  store i8 %15535, i8* %18, align 1
  %15536 = xor i64 %15495, %15525
  %15537 = lshr i64 %15536, 4
  %15538 = trunc i64 %15537 to i8
  %15539 = and i8 %15538, 1
  store i8 %15539, i8* %19, align 1
  %15540 = icmp eq i64 %15525, 0
  %15541 = zext i1 %15540 to i8
  store i8 %15541, i8* %20, align 1
  %15542 = lshr i64 %15525, 63
  %15543 = trunc i64 %15542 to i8
  store i8 %15543, i8* %21, align 1
  %15544 = lshr i64 %15523, 57
  %15545 = and i64 %15544, 1
  %15546 = xor i64 %15542, %15511
  %15547 = xor i64 %15542, %15545
  %15548 = add nuw nsw i64 %15546, %15547
  %15549 = icmp eq i64 %15548, 2
  %15550 = zext i1 %15549 to i8
  store i8 %15550, i8* %22, align 1
  %15551 = add i64 %15518, -48
  %15552 = add i64 %15449, 47
  store i64 %15552, i64* %3, align 8
  %15553 = inttoptr i64 %15551 to i32*
  %15554 = load i32, i32* %15553, align 4
  %15555 = sext i32 %15554 to i64
  store i64 %15555, i64* %RCX.i1588, align 8
  %15556 = shl nsw i64 %15555, 2
  %15557 = add i64 %15556, %15525
  %15558 = load i32, i32* %EDI.i1741, align 4
  %15559 = add i64 %15449, 50
  store i64 %15559, i64* %3, align 8
  %15560 = inttoptr i64 %15557 to i32*
  store i32 %15558, i32* %15560, align 4
  %15561 = load i64, i64* %RBP.i, align 8
  %15562 = add i64 %15561, -44
  %15563 = load i64, i64* %3, align 8
  %15564 = add i64 %15563, 3
  store i64 %15564, i64* %3, align 8
  %15565 = inttoptr i64 %15562 to i32*
  %15566 = load i32, i32* %15565, align 4
  %15567 = add i32 %15566, 1
  %15568 = zext i32 %15567 to i64
  store i64 %15568, i64* %RAX.i1659, align 8
  %15569 = icmp eq i32 %15566, -1
  %15570 = icmp eq i32 %15567, 0
  %15571 = or i1 %15569, %15570
  %15572 = zext i1 %15571 to i8
  store i8 %15572, i8* %17, align 1
  %15573 = and i32 %15567, 255
  %15574 = tail call i32 @llvm.ctpop.i32(i32 %15573)
  %15575 = trunc i32 %15574 to i8
  %15576 = and i8 %15575, 1
  %15577 = xor i8 %15576, 1
  store i8 %15577, i8* %18, align 1
  %15578 = xor i32 %15567, %15566
  %15579 = lshr i32 %15578, 4
  %15580 = trunc i32 %15579 to i8
  %15581 = and i8 %15580, 1
  store i8 %15581, i8* %19, align 1
  %15582 = zext i1 %15570 to i8
  store i8 %15582, i8* %20, align 1
  %15583 = lshr i32 %15567, 31
  %15584 = trunc i32 %15583 to i8
  store i8 %15584, i8* %21, align 1
  %15585 = lshr i32 %15566, 31
  %15586 = xor i32 %15583, %15585
  %15587 = add nuw nsw i32 %15586, %15583
  %15588 = icmp eq i32 %15587, 2
  %15589 = zext i1 %15588 to i8
  store i8 %15589, i8* %22, align 1
  %15590 = add i64 %15563, 9
  store i64 %15590, i64* %3, align 8
  store i32 %15567, i32* %15565, align 4
  %15591 = load i64, i64* %3, align 8
  %15592 = add i64 %15591, -140
  store i64 %15592, i64* %3, align 8
  br label %block_.L_485be3

block_.L_485c74:                                  ; preds = %block_.L_485be3
  %15593 = add i64 %15311, -48
  %15594 = add i64 %15339, 8
  store i64 %15594, i64* %3, align 8
  %15595 = inttoptr i64 %15593 to i32*
  %15596 = load i32, i32* %15595, align 4
  %15597 = add i32 %15596, 1
  %15598 = zext i32 %15597 to i64
  store i64 %15598, i64* %RAX.i1659, align 8
  %15599 = icmp eq i32 %15596, -1
  %15600 = icmp eq i32 %15597, 0
  %15601 = or i1 %15599, %15600
  %15602 = zext i1 %15601 to i8
  store i8 %15602, i8* %17, align 1
  %15603 = and i32 %15597, 255
  %15604 = tail call i32 @llvm.ctpop.i32(i32 %15603)
  %15605 = trunc i32 %15604 to i8
  %15606 = and i8 %15605, 1
  %15607 = xor i8 %15606, 1
  store i8 %15607, i8* %18, align 1
  %15608 = xor i32 %15597, %15596
  %15609 = lshr i32 %15608, 4
  %15610 = trunc i32 %15609 to i8
  %15611 = and i8 %15610, 1
  store i8 %15611, i8* %19, align 1
  %15612 = zext i1 %15600 to i8
  store i8 %15612, i8* %20, align 1
  %15613 = lshr i32 %15597, 31
  %15614 = trunc i32 %15613 to i8
  store i8 %15614, i8* %21, align 1
  %15615 = lshr i32 %15596, 31
  %15616 = xor i32 %15613, %15615
  %15617 = add nuw nsw i32 %15616, %15613
  %15618 = icmp eq i32 %15617, 2
  %15619 = zext i1 %15618 to i8
  store i8 %15619, i8* %22, align 1
  %15620 = add i64 %15339, 14
  store i64 %15620, i64* %3, align 8
  store i32 %15597, i32* %15595, align 4
  %15621 = load i64, i64* %3, align 8
  %15622 = add i64 %15621, -176
  store i64 %15622, i64* %3, align 8
  br label %block_.L_485bd2

block_.L_485c87:                                  ; preds = %block_.L_485bd2
  store i64 0, i64* %RDI.i6998, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %15623 = add i64 %15278, -12
  %15624 = add i64 %15306, 5
  store i64 %15624, i64* %3, align 8
  %15625 = inttoptr i64 %15623 to i32*
  %15626 = load i32, i32* %15625, align 4
  %15627 = add i32 %15626, 4
  %15628 = zext i32 %15627 to i64
  store i64 %15628, i64* %RAX.i1659, align 8
  %15629 = icmp ugt i32 %15626, -5
  %15630 = zext i1 %15629 to i8
  store i8 %15630, i8* %17, align 1
  %15631 = and i32 %15627, 255
  %15632 = tail call i32 @llvm.ctpop.i32(i32 %15631)
  %15633 = trunc i32 %15632 to i8
  %15634 = and i8 %15633, 1
  %15635 = xor i8 %15634, 1
  store i8 %15635, i8* %18, align 1
  %15636 = xor i32 %15627, %15626
  %15637 = lshr i32 %15636, 4
  %15638 = trunc i32 %15637 to i8
  %15639 = and i8 %15638, 1
  store i8 %15639, i8* %19, align 1
  %15640 = icmp eq i32 %15627, 0
  %15641 = zext i1 %15640 to i8
  store i8 %15641, i8* %20, align 1
  %15642 = lshr i32 %15627, 31
  %15643 = trunc i32 %15642 to i8
  store i8 %15643, i8* %21, align 1
  %15644 = lshr i32 %15626, 31
  %15645 = xor i32 %15642, %15644
  %15646 = add nuw nsw i32 %15645, %15642
  %15647 = icmp eq i32 %15646, 2
  %15648 = zext i1 %15647 to i8
  store i8 %15648, i8* %22, align 1
  %15649 = add i64 %15278, -16
  %15650 = add i64 %15306, 11
  store i64 %15650, i64* %3, align 8
  %15651 = inttoptr i64 %15649 to i32*
  %15652 = load i32, i32* %15651, align 4
  %15653 = zext i32 %15652 to i64
  store i64 %15653, i64* %RDX.i1943, align 8
  store i64 %15628, i64* %RSI.i2015, align 8
  %15654 = add i64 %15306, -503751
  %15655 = add i64 %15306, 18
  %15656 = load i64, i64* %6, align 8
  %15657 = add i64 %15656, -8
  %15658 = inttoptr i64 %15657 to i64*
  store i64 %15655, i64* %15658, align 8
  store i64 %15657, i64* %6, align 8
  store i64 %15654, i64* %3, align 8
  %call2_485c94 = tail call %struct.Memory* @sub_40acc0.dct_chroma4x4(%struct.State* nonnull %0, i64 %15654, %struct.Memory* %call2_485bc3)
  %15659 = load i64, i64* %3, align 8
  store i64 2, i64* %RDX.i1943, align 8
  store i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64* %RCX.i1588, align 8
  store i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64* %25, align 8
  store i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64* %R9.i1633, align 8
  %15660 = load i64, i64* %RBP.i, align 8
  %15661 = add i64 %15660, -12
  %15662 = add i64 %15659, 38
  store i64 %15662, i64* %3, align 8
  %15663 = inttoptr i64 %15661 to i32*
  %15664 = load i32, i32* %15663, align 4
  %15665 = zext i32 %15664 to i64
  store i64 %15665, i64* %RSI.i2015, align 8
  %15666 = add i64 %15660, -668
  %15667 = load i32, i32* %EAX.i2033, align 4
  %15668 = add i64 %15659, 44
  store i64 %15668, i64* %3, align 8
  %15669 = inttoptr i64 %15666 to i32*
  store i32 %15667, i32* %15669, align 4
  %15670 = load i32, i32* %ESI.i1759, align 4
  %15671 = zext i32 %15670 to i64
  %15672 = load i64, i64* %3, align 8
  store i64 %15671, i64* %RAX.i1659, align 8
  %15673 = load i64, i64* %RBP.i, align 8
  %15674 = add i64 %15673, -672
  %15675 = load i32, i32* %108, align 4
  %15676 = add i64 %15672, 8
  store i64 %15676, i64* %3, align 8
  %15677 = inttoptr i64 %15674 to i32*
  store i32 %15675, i32* %15677, align 4
  %15678 = load i64, i64* %3, align 8
  %15679 = load i32, i32* %EAX.i2033, align 8
  %15680 = sext i32 %15679 to i64
  %15681 = lshr i64 %15680, 32
  store i64 %15681, i64* %103, align 8
  %15682 = load i64, i64* %RBP.i, align 8
  %15683 = add i64 %15682, -672
  %15684 = add i64 %15678, 7
  store i64 %15684, i64* %3, align 8
  %15685 = inttoptr i64 %15683 to i32*
  %15686 = load i32, i32* %15685, align 4
  %15687 = zext i32 %15686 to i64
  store i64 %15687, i64* %RSI.i2015, align 8
  %15688 = add i64 %15678, 9
  store i64 %15688, i64* %3, align 8
  %15689 = zext i32 %15679 to i64
  %15690 = sext i32 %15686 to i64
  %15691 = shl nuw i64 %15681, 32
  %15692 = or i64 %15691, %15689
  %15693 = sdiv i64 %15692, %15690
  %15694 = shl i64 %15693, 32
  %15695 = ashr exact i64 %15694, 32
  %15696 = icmp eq i64 %15693, %15695
  br i1 %15696, label %15699, label %15697

; <label>:15697:                                  ; preds = %block_.L_485c87
  %15698 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %15688, %struct.Memory* %call2_485c94)
  %.pre476 = load i64, i64* %RDX.i1943, align 8
  %.pre477 = load i64, i64* %3, align 8
  %.pre478 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2164

; <label>:15699:                                  ; preds = %block_.L_485c87
  %15700 = srem i64 %15692, %15690
  %15701 = and i64 %15693, 4294967295
  store i64 %15701, i64* %RAX.i1659, align 8
  %15702 = and i64 %15700, 4294967295
  store i64 %15702, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit2164

routine_idivl__esi.exit2164:                      ; preds = %15699, %15697
  %15703 = phi i64 [ %.pre478, %15697 ], [ %15682, %15699 ]
  %15704 = phi i64 [ %.pre477, %15697 ], [ %15688, %15699 ]
  %15705 = phi i64 [ %.pre476, %15697 ], [ %15702, %15699 ]
  %15706 = phi %struct.Memory* [ %15698, %15697 ], [ %call2_485c94, %15699 ]
  %15707 = trunc i64 %15705 to i32
  %15708 = shl i32 %15707, 1
  %15709 = icmp slt i32 %15707, 0
  %15710 = icmp slt i32 %15708, 0
  %15711 = xor i1 %15709, %15710
  %15712 = zext i32 %15708 to i64
  store i64 %15712, i64* %RDX.i1943, align 8
  %.lobit235 = lshr i32 %15707, 31
  %15713 = trunc i32 %.lobit235 to i8
  store i8 %15713, i8* %17, align 1
  %15714 = and i32 %15708, 254
  %15715 = tail call i32 @llvm.ctpop.i32(i32 %15714)
  %15716 = trunc i32 %15715 to i8
  %15717 = and i8 %15716, 1
  %15718 = xor i8 %15717, 1
  store i8 %15718, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %15719 = icmp eq i32 %15708, 0
  %15720 = zext i1 %15719 to i8
  store i8 %15720, i8* %20, align 1
  %15721 = lshr i32 %15707, 30
  %15722 = trunc i32 %15721 to i8
  %15723 = and i8 %15722, 1
  store i8 %15723, i8* %21, align 1
  %15724 = zext i1 %15711 to i8
  store i8 %15724, i8* %22, align 1
  %15725 = add i64 %15703, -16
  %15726 = add i64 %15704, 5
  store i64 %15726, i64* %3, align 8
  %15727 = inttoptr i64 %15725 to i32*
  %15728 = load i32, i32* %15727, align 4
  %15729 = zext i32 %15728 to i64
  store i64 %15729, i64* %RDI.i6998, align 8
  store i64 %15729, i64* %RAX.i1659, align 8
  %15730 = add i64 %15703, -676
  %15731 = add i64 %15704, 13
  store i64 %15731, i64* %3, align 8
  %15732 = inttoptr i64 %15730 to i32*
  store i32 %15708, i32* %15732, align 4
  %15733 = load i64, i64* %3, align 8
  %15734 = load i32, i32* %EAX.i2033, align 8
  %15735 = sext i32 %15734 to i64
  %15736 = lshr i64 %15735, 32
  store i64 %15736, i64* %103, align 8
  %15737 = load i32, i32* %ESI.i1759, align 4
  %15738 = add i64 %15733, 3
  store i64 %15738, i64* %3, align 8
  %15739 = zext i32 %15734 to i64
  %15740 = sext i32 %15737 to i64
  %15741 = shl nuw i64 %15736, 32
  %15742 = or i64 %15741, %15739
  %15743 = sdiv i64 %15742, %15740
  %15744 = shl i64 %15743, 32
  %15745 = ashr exact i64 %15744, 32
  %15746 = icmp eq i64 %15743, %15745
  br i1 %15746, label %15749, label %15747

; <label>:15747:                                  ; preds = %routine_idivl__esi.exit2164
  %15748 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %15738, %struct.Memory* %15706)
  %.pre479 = load i64, i64* %3, align 8
  %.pre480 = load i32, i32* %108, align 4
  br label %routine_idivl__esi.exit2146

; <label>:15749:                                  ; preds = %routine_idivl__esi.exit2164
  %15750 = srem i64 %15742, %15740
  %15751 = and i64 %15743, 4294967295
  store i64 %15751, i64* %RAX.i1659, align 8
  %15752 = and i64 %15750, 4294967295
  store i64 %15752, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %15753 = trunc i64 %15750 to i32
  br label %routine_idivl__esi.exit2146

routine_idivl__esi.exit2146:                      ; preds = %15749, %15747
  %15754 = phi i32 [ %.pre480, %15747 ], [ %15753, %15749 ]
  %15755 = phi i64 [ %.pre479, %15747 ], [ %15738, %15749 ]
  %15756 = phi %struct.Memory* [ %15748, %15747 ], [ %15706, %15749 ]
  %15757 = load i64, i64* %RBP.i, align 8
  %15758 = add i64 %15757, -676
  %15759 = add i64 %15755, 6
  store i64 %15759, i64* %3, align 8
  %15760 = inttoptr i64 %15758 to i32*
  %15761 = load i32, i32* %15760, align 4
  %15762 = add i32 %15754, %15761
  %15763 = zext i32 %15762 to i64
  store i64 %15763, i64* %RDI.i6998, align 8
  %15764 = sext i32 %15762 to i64
  %15765 = shl nsw i64 %15764, 4
  store i64 %15765, i64* %50, align 8
  %15766 = load i64, i64* %R9.i1633, align 8
  %15767 = add i64 %15765, %15766
  store i64 %15767, i64* %R9.i1633, align 8
  %15768 = icmp ult i64 %15767, %15766
  %15769 = icmp ult i64 %15767, %15765
  %15770 = or i1 %15768, %15769
  %15771 = zext i1 %15770 to i8
  store i8 %15771, i8* %17, align 1
  %15772 = trunc i64 %15767 to i32
  %15773 = and i32 %15772, 255
  %15774 = tail call i32 @llvm.ctpop.i32(i32 %15773)
  %15775 = trunc i32 %15774 to i8
  %15776 = and i8 %15775, 1
  %15777 = xor i8 %15776, 1
  store i8 %15777, i8* %18, align 1
  %15778 = xor i64 %15765, %15766
  %15779 = xor i64 %15778, %15767
  %15780 = lshr i64 %15779, 4
  %15781 = trunc i64 %15780 to i8
  %15782 = and i8 %15781, 1
  store i8 %15782, i8* %19, align 1
  %15783 = icmp eq i64 %15767, 0
  %15784 = zext i1 %15783 to i8
  store i8 %15784, i8* %20, align 1
  %15785 = lshr i64 %15767, 63
  %15786 = trunc i64 %15785 to i8
  store i8 %15786, i8* %21, align 1
  %15787 = lshr i64 %15766, 63
  %15788 = lshr i64 %15764, 59
  %15789 = and i64 %15788, 1
  %15790 = xor i64 %15785, %15787
  %15791 = xor i64 %15785, %15789
  %15792 = add nuw nsw i64 %15790, %15791
  %15793 = icmp eq i64 %15792, 2
  %15794 = zext i1 %15793 to i8
  store i8 %15794, i8* %22, align 1
  %15795 = load i64, i64* %RBP.i, align 8
  %15796 = add i64 %15795, -12
  %15797 = add i64 %15755, 21
  store i64 %15797, i64* %3, align 8
  %15798 = inttoptr i64 %15796 to i32*
  %15799 = load i32, i32* %15798, align 4
  %15800 = zext i32 %15799 to i64
  store i64 %15800, i64* %RAX.i1659, align 8
  %15801 = sext i32 %15799 to i64
  %15802 = lshr i64 %15801, 32
  store i64 %15802, i64* %103, align 8
  %15803 = load i32, i32* %ESI.i1759, align 4
  %15804 = add i64 %15755, 26
  store i64 %15804, i64* %3, align 8
  %15805 = sext i32 %15803 to i64
  %15806 = shl nuw i64 %15802, 32
  %15807 = or i64 %15806, %15800
  %15808 = sdiv i64 %15807, %15805
  %15809 = shl i64 %15808, 32
  %15810 = ashr exact i64 %15809, 32
  %15811 = icmp eq i64 %15808, %15810
  br i1 %15811, label %15814, label %15812

; <label>:15812:                                  ; preds = %routine_idivl__esi.exit2146
  %15813 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %15804, %struct.Memory* %15756)
  %.pre481 = load i64, i64* %RAX.i1659, align 8
  %.pre482 = load i64, i64* %3, align 8
  %.pre483 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2119

; <label>:15814:                                  ; preds = %routine_idivl__esi.exit2146
  %15815 = srem i64 %15807, %15805
  %15816 = and i64 %15808, 4294967295
  store i64 %15816, i64* %RAX.i1659, align 8
  %15817 = and i64 %15815, 4294967295
  store i64 %15817, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit2119

routine_idivl__esi.exit2119:                      ; preds = %15814, %15812
  %15818 = phi i64 [ %.pre483, %15812 ], [ %15795, %15814 ]
  %15819 = phi i64 [ %.pre482, %15812 ], [ %15804, %15814 ]
  %15820 = phi i64 [ %.pre481, %15812 ], [ %15816, %15814 ]
  %15821 = phi %struct.Memory* [ %15813, %15812 ], [ %15756, %15814 ]
  %15822 = trunc i64 %15820 to i32
  %15823 = shl i32 %15822, 1
  %15824 = icmp slt i32 %15822, 0
  %15825 = icmp slt i32 %15823, 0
  %15826 = xor i1 %15824, %15825
  %15827 = zext i32 %15823 to i64
  store i64 %15827, i64* %RAX.i1659, align 8
  %.lobit237 = lshr i32 %15822, 31
  %15828 = trunc i32 %.lobit237 to i8
  store i8 %15828, i8* %17, align 1
  %15829 = and i32 %15823, 254
  %15830 = tail call i32 @llvm.ctpop.i32(i32 %15829)
  %15831 = trunc i32 %15830 to i8
  %15832 = and i8 %15831, 1
  %15833 = xor i8 %15832, 1
  store i8 %15833, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %15834 = icmp eq i32 %15823, 0
  %15835 = zext i1 %15834 to i8
  store i8 %15835, i8* %20, align 1
  %15836 = lshr i32 %15822, 30
  %15837 = trunc i32 %15836 to i8
  %15838 = and i8 %15837, 1
  store i8 %15838, i8* %21, align 1
  %15839 = zext i1 %15826 to i8
  store i8 %15839, i8* %22, align 1
  %15840 = add i64 %15818, -16
  %15841 = add i64 %15819, 5
  store i64 %15841, i64* %3, align 8
  %15842 = inttoptr i64 %15840 to i32*
  %15843 = load i32, i32* %15842, align 4
  %15844 = zext i32 %15843 to i64
  store i64 %15844, i64* %RDI.i6998, align 8
  %15845 = add i64 %15818, -680
  %15846 = add i64 %15819, 11
  store i64 %15846, i64* %3, align 8
  %15847 = inttoptr i64 %15845 to i32*
  store i32 %15823, i32* %15847, align 4
  %15848 = load i32, i32* %EDI.i1741, align 4
  %15849 = zext i32 %15848 to i64
  %15850 = load i64, i64* %3, align 8
  store i64 %15849, i64* %RAX.i1659, align 8
  %15851 = sext i32 %15848 to i64
  %15852 = lshr i64 %15851, 32
  store i64 %15852, i64* %103, align 8
  %15853 = load i32, i32* %ESI.i1759, align 4
  %15854 = add i64 %15850, 5
  store i64 %15854, i64* %3, align 8
  %15855 = sext i32 %15853 to i64
  %15856 = shl nuw i64 %15852, 32
  %15857 = or i64 %15856, %15849
  %15858 = sdiv i64 %15857, %15855
  %15859 = shl i64 %15858, 32
  %15860 = ashr exact i64 %15859, 32
  %15861 = icmp eq i64 %15858, %15860
  br i1 %15861, label %15864, label %15862

; <label>:15862:                                  ; preds = %routine_idivl__esi.exit2119
  %15863 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %15854, %struct.Memory* %15821)
  %.pre484 = load i64, i64* %3, align 8
  %.pre485 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit2100

; <label>:15864:                                  ; preds = %routine_idivl__esi.exit2119
  %15865 = srem i64 %15857, %15855
  %15866 = and i64 %15858, 4294967295
  store i64 %15866, i64* %RAX.i1659, align 8
  %15867 = and i64 %15865, 4294967295
  store i64 %15867, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %15868 = trunc i64 %15858 to i32
  br label %routine_idivl__esi.exit2100

routine_idivl__esi.exit2100:                      ; preds = %15864, %15862
  %15869 = phi i32 [ %.pre485, %15862 ], [ %15868, %15864 ]
  %15870 = phi i64 [ %.pre484, %15862 ], [ %15854, %15864 ]
  %15871 = phi %struct.Memory* [ %15863, %15862 ], [ %15821, %15864 ]
  %15872 = load i64, i64* %RBP.i, align 8
  %15873 = add i64 %15872, -680
  %15874 = add i64 %15870, 6
  store i64 %15874, i64* %3, align 8
  %15875 = inttoptr i64 %15873 to i32*
  %15876 = load i32, i32* %15875, align 4
  %15877 = add i32 %15869, %15876
  %15878 = zext i32 %15877 to i64
  store i64 %15878, i64* %RDI.i6998, align 8
  %15879 = icmp ult i32 %15877, %15876
  %15880 = icmp ult i32 %15877, %15869
  %15881 = or i1 %15879, %15880
  %15882 = zext i1 %15881 to i8
  store i8 %15882, i8* %17, align 1
  %15883 = and i32 %15877, 255
  %15884 = tail call i32 @llvm.ctpop.i32(i32 %15883)
  %15885 = trunc i32 %15884 to i8
  %15886 = and i8 %15885, 1
  %15887 = xor i8 %15886, 1
  store i8 %15887, i8* %18, align 1
  %15888 = xor i32 %15869, %15876
  %15889 = xor i32 %15888, %15877
  %15890 = lshr i32 %15889, 4
  %15891 = trunc i32 %15890 to i8
  %15892 = and i8 %15891, 1
  store i8 %15892, i8* %19, align 1
  %15893 = icmp eq i32 %15877, 0
  %15894 = zext i1 %15893 to i8
  store i8 %15894, i8* %20, align 1
  %15895 = lshr i32 %15877, 31
  %15896 = trunc i32 %15895 to i8
  store i8 %15896, i8* %21, align 1
  %15897 = lshr i32 %15876, 31
  %15898 = lshr i32 %15869, 31
  %15899 = xor i32 %15895, %15897
  %15900 = xor i32 %15895, %15898
  %15901 = add nuw nsw i32 %15899, %15900
  %15902 = icmp eq i32 %15901, 2
  %15903 = zext i1 %15902 to i8
  store i8 %15903, i8* %22, align 1
  %15904 = sext i32 %15877 to i64
  store i64 %15904, i64* %50, align 8
  %15905 = add i64 %15872, -668
  %15906 = add i64 %15870, 17
  store i64 %15906, i64* %3, align 8
  %15907 = inttoptr i64 %15905 to i32*
  %15908 = load i32, i32* %15907, align 4
  %15909 = zext i32 %15908 to i64
  store i64 %15909, i64* %RAX.i1659, align 8
  %15910 = load i64, i64* %R9.i1633, align 8
  %15911 = shl nsw i64 %15904, 2
  %15912 = add i64 %15911, %15910
  %15913 = add i64 %15870, 21
  store i64 %15913, i64* %3, align 8
  %15914 = inttoptr i64 %15912 to i32*
  store i32 %15908, i32* %15914, align 4
  %15915 = load i64, i64* %RBP.i, align 8
  %15916 = add i64 %15915, -12
  %15917 = load i64, i64* %3, align 8
  %15918 = add i64 %15917, 3
  store i64 %15918, i64* %3, align 8
  %15919 = inttoptr i64 %15916 to i32*
  %15920 = load i32, i32* %15919, align 4
  %15921 = zext i32 %15920 to i64
  store i64 %15921, i64* %RAX.i1659, align 8
  %15922 = sext i32 %15920 to i64
  %15923 = lshr i64 %15922, 32
  store i64 %15923, i64* %103, align 8
  %15924 = load i32, i32* %ESI.i1759, align 4
  %15925 = add i64 %15917, 6
  store i64 %15925, i64* %3, align 8
  %15926 = sext i32 %15924 to i64
  %15927 = shl nuw i64 %15923, 32
  %15928 = or i64 %15927, %15921
  %15929 = sdiv i64 %15928, %15926
  %15930 = shl i64 %15929, 32
  %15931 = ashr exact i64 %15930, 32
  %15932 = icmp eq i64 %15929, %15931
  br i1 %15932, label %15935, label %15933

; <label>:15933:                                  ; preds = %routine_idivl__esi.exit2100
  %15934 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %15925, %struct.Memory* %15871)
  %.pre486 = load i64, i64* %RDX.i1943, align 8
  %.pre487 = load i64, i64* %3, align 8
  %.pre488 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2076

; <label>:15935:                                  ; preds = %routine_idivl__esi.exit2100
  %15936 = srem i64 %15928, %15926
  %15937 = and i64 %15929, 4294967295
  store i64 %15937, i64* %RAX.i1659, align 8
  %15938 = and i64 %15936, 4294967295
  store i64 %15938, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit2076

routine_idivl__esi.exit2076:                      ; preds = %15935, %15933
  %15939 = phi i64 [ %.pre488, %15933 ], [ %15915, %15935 ]
  %15940 = phi i64 [ %.pre487, %15933 ], [ %15925, %15935 ]
  %15941 = phi i64 [ %.pre486, %15933 ], [ %15938, %15935 ]
  %15942 = phi %struct.Memory* [ %15934, %15933 ], [ %15871, %15935 ]
  %15943 = trunc i64 %15941 to i32
  %15944 = shl i32 %15943, 1
  %15945 = icmp slt i32 %15943, 0
  %15946 = icmp slt i32 %15944, 0
  %15947 = xor i1 %15945, %15946
  %15948 = zext i32 %15944 to i64
  store i64 %15948, i64* %RDX.i1943, align 8
  %.lobit238 = lshr i32 %15943, 31
  %15949 = trunc i32 %.lobit238 to i8
  store i8 %15949, i8* %17, align 1
  %15950 = and i32 %15944, 254
  %15951 = tail call i32 @llvm.ctpop.i32(i32 %15950)
  %15952 = trunc i32 %15951 to i8
  %15953 = and i8 %15952, 1
  %15954 = xor i8 %15953, 1
  store i8 %15954, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %15955 = icmp eq i32 %15944, 0
  %15956 = zext i1 %15955 to i8
  store i8 %15956, i8* %20, align 1
  %15957 = lshr i32 %15943, 30
  %15958 = trunc i32 %15957 to i8
  %15959 = and i8 %15958, 1
  store i8 %15959, i8* %21, align 1
  %15960 = zext i1 %15947 to i8
  store i8 %15960, i8* %22, align 1
  %15961 = add i64 %15939, -16
  %15962 = add i64 %15940, 5
  store i64 %15962, i64* %3, align 8
  %15963 = inttoptr i64 %15961 to i32*
  %15964 = load i32, i32* %15963, align 4
  %15965 = zext i32 %15964 to i64
  store i64 %15965, i64* %RDI.i6998, align 8
  store i64 %15965, i64* %RAX.i1659, align 8
  %15966 = add i64 %15939, -684
  %15967 = add i64 %15940, 13
  store i64 %15967, i64* %3, align 8
  %15968 = inttoptr i64 %15966 to i32*
  store i32 %15944, i32* %15968, align 4
  %15969 = load i64, i64* %3, align 8
  %15970 = load i32, i32* %EAX.i2033, align 8
  %15971 = sext i32 %15970 to i64
  %15972 = lshr i64 %15971, 32
  store i64 %15972, i64* %103, align 8
  %15973 = load i32, i32* %ESI.i1759, align 4
  %15974 = add i64 %15969, 3
  store i64 %15974, i64* %3, align 8
  %15975 = zext i32 %15970 to i64
  %15976 = sext i32 %15973 to i64
  %15977 = shl nuw i64 %15972, 32
  %15978 = or i64 %15977, %15975
  %15979 = sdiv i64 %15978, %15976
  %15980 = shl i64 %15979, 32
  %15981 = ashr exact i64 %15980, 32
  %15982 = icmp eq i64 %15979, %15981
  br i1 %15982, label %15985, label %15983

; <label>:15983:                                  ; preds = %routine_idivl__esi.exit2076
  %15984 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %15974, %struct.Memory* %15942)
  %.pre489 = load i64, i64* %3, align 8
  %.pre490 = load i32, i32* %108, align 4
  br label %routine_idivl__esi.exit2058

; <label>:15985:                                  ; preds = %routine_idivl__esi.exit2076
  %15986 = srem i64 %15978, %15976
  %15987 = and i64 %15979, 4294967295
  store i64 %15987, i64* %RAX.i1659, align 8
  %15988 = and i64 %15986, 4294967295
  store i64 %15988, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %15989 = trunc i64 %15986 to i32
  br label %routine_idivl__esi.exit2058

routine_idivl__esi.exit2058:                      ; preds = %15985, %15983
  %15990 = phi i32 [ %.pre490, %15983 ], [ %15989, %15985 ]
  %15991 = phi i64 [ %.pre489, %15983 ], [ %15974, %15985 ]
  %15992 = phi %struct.Memory* [ %15984, %15983 ], [ %15942, %15985 ]
  %15993 = load i64, i64* %RBP.i, align 8
  %15994 = add i64 %15993, -684
  %15995 = add i64 %15991, 6
  store i64 %15995, i64* %3, align 8
  %15996 = inttoptr i64 %15994 to i32*
  %15997 = load i32, i32* %15996, align 4
  %15998 = add i32 %15990, %15997
  %15999 = zext i32 %15998 to i64
  store i64 %15999, i64* %RDI.i6998, align 8
  %16000 = sext i32 %15998 to i64
  %16001 = shl nsw i64 %16000, 4
  store i64 %16001, i64* %R9.i1633, align 8
  %16002 = load i64, i64* %25, align 8
  %16003 = add i64 %16001, %16002
  store i64 %16003, i64* %25, align 8
  %16004 = icmp ult i64 %16003, %16002
  %16005 = icmp ult i64 %16003, %16001
  %16006 = or i1 %16004, %16005
  %16007 = zext i1 %16006 to i8
  store i8 %16007, i8* %17, align 1
  %16008 = trunc i64 %16003 to i32
  %16009 = and i32 %16008, 255
  %16010 = tail call i32 @llvm.ctpop.i32(i32 %16009)
  %16011 = trunc i32 %16010 to i8
  %16012 = and i8 %16011, 1
  %16013 = xor i8 %16012, 1
  store i8 %16013, i8* %18, align 1
  %16014 = xor i64 %16001, %16002
  %16015 = xor i64 %16014, %16003
  %16016 = lshr i64 %16015, 4
  %16017 = trunc i64 %16016 to i8
  %16018 = and i8 %16017, 1
  store i8 %16018, i8* %19, align 1
  %16019 = icmp eq i64 %16003, 0
  %16020 = zext i1 %16019 to i8
  store i8 %16020, i8* %20, align 1
  %16021 = lshr i64 %16003, 63
  %16022 = trunc i64 %16021 to i8
  store i8 %16022, i8* %21, align 1
  %16023 = lshr i64 %16002, 63
  %16024 = lshr i64 %16000, 59
  %16025 = and i64 %16024, 1
  %16026 = xor i64 %16021, %16023
  %16027 = xor i64 %16021, %16025
  %16028 = add nuw nsw i64 %16026, %16027
  %16029 = icmp eq i64 %16028, 2
  %16030 = zext i1 %16029 to i8
  store i8 %16030, i8* %22, align 1
  %16031 = load i64, i64* %RBP.i, align 8
  %16032 = add i64 %16031, -12
  %16033 = add i64 %15991, 21
  store i64 %16033, i64* %3, align 8
  %16034 = inttoptr i64 %16032 to i32*
  %16035 = load i32, i32* %16034, align 4
  %16036 = zext i32 %16035 to i64
  store i64 %16036, i64* %RAX.i1659, align 8
  %16037 = sext i32 %16035 to i64
  %16038 = lshr i64 %16037, 32
  store i64 %16038, i64* %103, align 8
  %16039 = load i32, i32* %ESI.i1759, align 4
  %16040 = add i64 %15991, 26
  store i64 %16040, i64* %3, align 8
  %16041 = sext i32 %16039 to i64
  %16042 = shl nuw i64 %16038, 32
  %16043 = or i64 %16042, %16036
  %16044 = sdiv i64 %16043, %16041
  %16045 = shl i64 %16044, 32
  %16046 = ashr exact i64 %16045, 32
  %16047 = icmp eq i64 %16044, %16046
  br i1 %16047, label %16050, label %16048

; <label>:16048:                                  ; preds = %routine_idivl__esi.exit2058
  %16049 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16040, %struct.Memory* %15992)
  %.pre491 = load i64, i64* %RAX.i1659, align 8
  %.pre492 = load i64, i64* %3, align 8
  %.pre493 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit2031

; <label>:16050:                                  ; preds = %routine_idivl__esi.exit2058
  %16051 = srem i64 %16043, %16041
  %16052 = and i64 %16044, 4294967295
  store i64 %16052, i64* %RAX.i1659, align 8
  %16053 = and i64 %16051, 4294967295
  store i64 %16053, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit2031

routine_idivl__esi.exit2031:                      ; preds = %16050, %16048
  %16054 = phi i64 [ %.pre493, %16048 ], [ %16031, %16050 ]
  %16055 = phi i64 [ %.pre492, %16048 ], [ %16040, %16050 ]
  %16056 = phi i64 [ %.pre491, %16048 ], [ %16052, %16050 ]
  %16057 = phi %struct.Memory* [ %16049, %16048 ], [ %15992, %16050 ]
  %16058 = trunc i64 %16056 to i32
  %16059 = shl i32 %16058, 1
  %16060 = icmp slt i32 %16058, 0
  %16061 = icmp slt i32 %16059, 0
  %16062 = xor i1 %16060, %16061
  %16063 = zext i32 %16059 to i64
  store i64 %16063, i64* %RAX.i1659, align 8
  %.lobit240 = lshr i32 %16058, 31
  %16064 = trunc i32 %.lobit240 to i8
  store i8 %16064, i8* %17, align 1
  %16065 = and i32 %16059, 254
  %16066 = tail call i32 @llvm.ctpop.i32(i32 %16065)
  %16067 = trunc i32 %16066 to i8
  %16068 = and i8 %16067, 1
  %16069 = xor i8 %16068, 1
  store i8 %16069, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %16070 = icmp eq i32 %16059, 0
  %16071 = zext i1 %16070 to i8
  store i8 %16071, i8* %20, align 1
  %16072 = lshr i32 %16058, 30
  %16073 = trunc i32 %16072 to i8
  %16074 = and i8 %16073, 1
  store i8 %16074, i8* %21, align 1
  %16075 = zext i1 %16062 to i8
  store i8 %16075, i8* %22, align 1
  %16076 = add i64 %16054, -16
  %16077 = add i64 %16055, 5
  store i64 %16077, i64* %3, align 8
  %16078 = inttoptr i64 %16076 to i32*
  %16079 = load i32, i32* %16078, align 4
  %16080 = zext i32 %16079 to i64
  store i64 %16080, i64* %RDI.i6998, align 8
  %16081 = add i64 %16054, -688
  %16082 = add i64 %16055, 11
  store i64 %16082, i64* %3, align 8
  %16083 = inttoptr i64 %16081 to i32*
  store i32 %16059, i32* %16083, align 4
  %16084 = load i32, i32* %EDI.i1741, align 4
  %16085 = zext i32 %16084 to i64
  %16086 = load i64, i64* %3, align 8
  store i64 %16085, i64* %RAX.i1659, align 8
  %16087 = sext i32 %16084 to i64
  %16088 = lshr i64 %16087, 32
  store i64 %16088, i64* %103, align 8
  %16089 = load i32, i32* %ESI.i1759, align 4
  %16090 = add i64 %16086, 5
  store i64 %16090, i64* %3, align 8
  %16091 = sext i32 %16089 to i64
  %16092 = shl nuw i64 %16088, 32
  %16093 = or i64 %16092, %16085
  %16094 = sdiv i64 %16093, %16091
  %16095 = shl i64 %16094, 32
  %16096 = ashr exact i64 %16095, 32
  %16097 = icmp eq i64 %16094, %16096
  br i1 %16097, label %16100, label %16098

; <label>:16098:                                  ; preds = %routine_idivl__esi.exit2031
  %16099 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16090, %struct.Memory* %16057)
  %.pre494 = load i64, i64* %3, align 8
  %.pre495 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit2013

; <label>:16100:                                  ; preds = %routine_idivl__esi.exit2031
  %16101 = srem i64 %16093, %16091
  %16102 = and i64 %16094, 4294967295
  store i64 %16102, i64* %RAX.i1659, align 8
  %16103 = and i64 %16101, 4294967295
  store i64 %16103, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %16104 = trunc i64 %16094 to i32
  br label %routine_idivl__esi.exit2013

routine_idivl__esi.exit2013:                      ; preds = %16100, %16098
  %16105 = phi i32 [ %.pre495, %16098 ], [ %16104, %16100 ]
  %16106 = phi i64 [ %.pre494, %16098 ], [ %16090, %16100 ]
  %16107 = phi %struct.Memory* [ %16099, %16098 ], [ %16057, %16100 ]
  %16108 = load i64, i64* %RBP.i, align 8
  %16109 = add i64 %16108, -688
  %16110 = add i64 %16106, 6
  store i64 %16110, i64* %3, align 8
  %16111 = inttoptr i64 %16109 to i32*
  %16112 = load i32, i32* %16111, align 4
  %16113 = add i32 %16105, %16112
  %16114 = zext i32 %16113 to i64
  store i64 %16114, i64* %RDI.i6998, align 8
  %16115 = icmp ult i32 %16113, %16112
  %16116 = icmp ult i32 %16113, %16105
  %16117 = or i1 %16115, %16116
  %16118 = zext i1 %16117 to i8
  store i8 %16118, i8* %17, align 1
  %16119 = and i32 %16113, 255
  %16120 = tail call i32 @llvm.ctpop.i32(i32 %16119)
  %16121 = trunc i32 %16120 to i8
  %16122 = and i8 %16121, 1
  %16123 = xor i8 %16122, 1
  store i8 %16123, i8* %18, align 1
  %16124 = xor i32 %16105, %16112
  %16125 = xor i32 %16124, %16113
  %16126 = lshr i32 %16125, 4
  %16127 = trunc i32 %16126 to i8
  %16128 = and i8 %16127, 1
  store i8 %16128, i8* %19, align 1
  %16129 = icmp eq i32 %16113, 0
  %16130 = zext i1 %16129 to i8
  store i8 %16130, i8* %20, align 1
  %16131 = lshr i32 %16113, 31
  %16132 = trunc i32 %16131 to i8
  store i8 %16132, i8* %21, align 1
  %16133 = lshr i32 %16112, 31
  %16134 = lshr i32 %16105, 31
  %16135 = xor i32 %16131, %16133
  %16136 = xor i32 %16131, %16134
  %16137 = add nuw nsw i32 %16135, %16136
  %16138 = icmp eq i32 %16137, 2
  %16139 = zext i1 %16138 to i8
  store i8 %16139, i8* %22, align 1
  %16140 = sext i32 %16113 to i64
  store i64 %16140, i64* %R9.i1633, align 8
  %16141 = load i64, i64* %25, align 8
  %16142 = shl nsw i64 %16140, 2
  %16143 = add i64 %16141, %16142
  %16144 = add i64 %16106, 15
  store i64 %16144, i64* %3, align 8
  %16145 = inttoptr i64 %16143 to i32*
  %16146 = load i32, i32* %16145, align 4
  %16147 = zext i32 %16146 to i64
  store i64 %16147, i64* %RAX.i1659, align 8
  %16148 = add i64 %16108, -12
  %16149 = add i64 %16106, 18
  store i64 %16149, i64* %3, align 8
  %16150 = inttoptr i64 %16148 to i32*
  %16151 = load i32, i32* %16150, align 4
  %16152 = zext i32 %16151 to i64
  store i64 %16152, i64* %RDI.i6998, align 8
  %16153 = add i64 %16108, -692
  %16154 = add i64 %16106, 24
  store i64 %16154, i64* %3, align 8
  %16155 = inttoptr i64 %16153 to i32*
  store i32 %16146, i32* %16155, align 4
  %16156 = load i32, i32* %EDI.i1741, align 4
  %16157 = zext i32 %16156 to i64
  %16158 = load i64, i64* %3, align 8
  store i64 %16157, i64* %RAX.i1659, align 8
  %16159 = sext i32 %16156 to i64
  %16160 = lshr i64 %16159, 32
  store i64 %16160, i64* %103, align 8
  %16161 = load i32, i32* %ESI.i1759, align 4
  %16162 = add i64 %16158, 5
  store i64 %16162, i64* %3, align 8
  %16163 = sext i32 %16161 to i64
  %16164 = shl nuw i64 %16160, 32
  %16165 = or i64 %16164, %16157
  %16166 = sdiv i64 %16165, %16163
  %16167 = shl i64 %16166, 32
  %16168 = ashr exact i64 %16167, 32
  %16169 = icmp eq i64 %16166, %16168
  br i1 %16169, label %16172, label %16170

; <label>:16170:                                  ; preds = %routine_idivl__esi.exit2013
  %16171 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16162, %struct.Memory* %16107)
  %.pre496 = load i64, i64* %RDX.i1943, align 8
  %.pre497 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit1985

; <label>:16172:                                  ; preds = %routine_idivl__esi.exit2013
  %16173 = srem i64 %16165, %16163
  %16174 = and i64 %16166, 4294967295
  store i64 %16174, i64* %RAX.i1659, align 8
  %16175 = and i64 %16173, 4294967295
  store i64 %16175, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit1985

routine_idivl__esi.exit1985:                      ; preds = %16172, %16170
  %16176 = phi i64 [ %.pre497, %16170 ], [ %16162, %16172 ]
  %16177 = phi i64 [ %.pre496, %16170 ], [ %16175, %16172 ]
  %16178 = phi %struct.Memory* [ %16171, %16170 ], [ %16107, %16172 ]
  %16179 = trunc i64 %16177 to i32
  %16180 = shl i32 %16179, 1
  %16181 = icmp slt i32 %16179, 0
  %16182 = icmp slt i32 %16180, 0
  %16183 = xor i1 %16181, %16182
  %16184 = zext i32 %16180 to i64
  store i64 %16184, i64* %RDX.i1943, align 8
  %.lobit241 = lshr i32 %16179, 31
  %16185 = trunc i32 %.lobit241 to i8
  store i8 %16185, i8* %17, align 1
  %16186 = and i32 %16180, 254
  %16187 = tail call i32 @llvm.ctpop.i32(i32 %16186)
  %16188 = trunc i32 %16187 to i8
  %16189 = and i8 %16188, 1
  %16190 = xor i8 %16189, 1
  store i8 %16190, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %16191 = icmp eq i32 %16180, 0
  %16192 = zext i1 %16191 to i8
  store i8 %16192, i8* %20, align 1
  %16193 = lshr i32 %16179, 30
  %16194 = trunc i32 %16193 to i8
  %16195 = and i8 %16194, 1
  store i8 %16195, i8* %21, align 1
  %16196 = zext i1 %16183 to i8
  store i8 %16196, i8* %22, align 1
  %16197 = load i64, i64* %RBP.i, align 8
  %16198 = add i64 %16197, -16
  %16199 = add i64 %16176, 5
  store i64 %16199, i64* %3, align 8
  %16200 = inttoptr i64 %16198 to i32*
  %16201 = load i32, i32* %16200, align 4
  %16202 = zext i32 %16201 to i64
  store i64 %16202, i64* %RDI.i6998, align 8
  store i64 %16202, i64* %RAX.i1659, align 8
  %16203 = add i64 %16197, -696
  %16204 = add i64 %16176, 13
  store i64 %16204, i64* %3, align 8
  %16205 = inttoptr i64 %16203 to i32*
  store i32 %16180, i32* %16205, align 4
  %16206 = load i64, i64* %3, align 8
  %16207 = load i32, i32* %EAX.i2033, align 8
  %16208 = sext i32 %16207 to i64
  %16209 = lshr i64 %16208, 32
  store i64 %16209, i64* %103, align 8
  %16210 = load i32, i32* %ESI.i1759, align 4
  %16211 = add i64 %16206, 3
  store i64 %16211, i64* %3, align 8
  %16212 = zext i32 %16207 to i64
  %16213 = sext i32 %16210 to i64
  %16214 = shl nuw i64 %16209, 32
  %16215 = or i64 %16214, %16212
  %16216 = sdiv i64 %16215, %16213
  %16217 = shl i64 %16216, 32
  %16218 = ashr exact i64 %16217, 32
  %16219 = icmp eq i64 %16216, %16218
  br i1 %16219, label %16222, label %16220

; <label>:16220:                                  ; preds = %routine_idivl__esi.exit1985
  %16221 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16211, %struct.Memory* %16178)
  %.pre498 = load i64, i64* %3, align 8
  %.pre499 = load i32, i32* %108, align 4
  br label %routine_idivl__esi.exit1968

; <label>:16222:                                  ; preds = %routine_idivl__esi.exit1985
  %16223 = srem i64 %16215, %16213
  %16224 = and i64 %16216, 4294967295
  store i64 %16224, i64* %RAX.i1659, align 8
  %16225 = and i64 %16223, 4294967295
  store i64 %16225, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %16226 = trunc i64 %16223 to i32
  br label %routine_idivl__esi.exit1968

routine_idivl__esi.exit1968:                      ; preds = %16222, %16220
  %16227 = phi i32 [ %.pre499, %16220 ], [ %16226, %16222 ]
  %16228 = phi i64 [ %.pre498, %16220 ], [ %16211, %16222 ]
  %16229 = phi %struct.Memory* [ %16221, %16220 ], [ %16178, %16222 ]
  %16230 = load i64, i64* %RBP.i, align 8
  %16231 = add i64 %16230, -696
  %16232 = add i64 %16228, 6
  store i64 %16232, i64* %3, align 8
  %16233 = inttoptr i64 %16231 to i32*
  %16234 = load i32, i32* %16233, align 4
  %16235 = add i32 %16227, %16234
  %16236 = zext i32 %16235 to i64
  store i64 %16236, i64* %RDI.i6998, align 8
  %16237 = sext i32 %16235 to i64
  %16238 = shl nsw i64 %16237, 4
  store i64 %16238, i64* %25, align 8
  %16239 = load i64, i64* %RCX.i1588, align 8
  %16240 = add i64 %16238, %16239
  store i64 %16240, i64* %RCX.i1588, align 8
  %16241 = icmp ult i64 %16240, %16239
  %16242 = icmp ult i64 %16240, %16238
  %16243 = or i1 %16241, %16242
  %16244 = zext i1 %16243 to i8
  store i8 %16244, i8* %17, align 1
  %16245 = trunc i64 %16240 to i32
  %16246 = and i32 %16245, 255
  %16247 = tail call i32 @llvm.ctpop.i32(i32 %16246)
  %16248 = trunc i32 %16247 to i8
  %16249 = and i8 %16248, 1
  %16250 = xor i8 %16249, 1
  store i8 %16250, i8* %18, align 1
  %16251 = xor i64 %16238, %16239
  %16252 = xor i64 %16251, %16240
  %16253 = lshr i64 %16252, 4
  %16254 = trunc i64 %16253 to i8
  %16255 = and i8 %16254, 1
  store i8 %16255, i8* %19, align 1
  %16256 = icmp eq i64 %16240, 0
  %16257 = zext i1 %16256 to i8
  store i8 %16257, i8* %20, align 1
  %16258 = lshr i64 %16240, 63
  %16259 = trunc i64 %16258 to i8
  store i8 %16259, i8* %21, align 1
  %16260 = lshr i64 %16239, 63
  %16261 = lshr i64 %16237, 59
  %16262 = and i64 %16261, 1
  %16263 = xor i64 %16258, %16260
  %16264 = xor i64 %16258, %16262
  %16265 = add nuw nsw i64 %16263, %16264
  %16266 = icmp eq i64 %16265, 2
  %16267 = zext i1 %16266 to i8
  store i8 %16267, i8* %22, align 1
  %16268 = load i64, i64* %RBP.i, align 8
  %16269 = add i64 %16268, -12
  %16270 = add i64 %16228, 21
  store i64 %16270, i64* %3, align 8
  %16271 = inttoptr i64 %16269 to i32*
  %16272 = load i32, i32* %16271, align 4
  %16273 = zext i32 %16272 to i64
  store i64 %16273, i64* %RAX.i1659, align 8
  %16274 = sext i32 %16272 to i64
  %16275 = lshr i64 %16274, 32
  store i64 %16275, i64* %103, align 8
  %16276 = load i32, i32* %ESI.i1759, align 4
  %16277 = add i64 %16228, 26
  store i64 %16277, i64* %3, align 8
  %16278 = sext i32 %16276 to i64
  %16279 = shl nuw i64 %16275, 32
  %16280 = or i64 %16279, %16273
  %16281 = sdiv i64 %16280, %16278
  %16282 = shl i64 %16281, 32
  %16283 = ashr exact i64 %16282, 32
  %16284 = icmp eq i64 %16281, %16283
  br i1 %16284, label %16287, label %16285

; <label>:16285:                                  ; preds = %routine_idivl__esi.exit1968
  %16286 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16277, %struct.Memory* %16229)
  %.pre500 = load i64, i64* %RAX.i1659, align 8
  %.pre501 = load i64, i64* %3, align 8
  %.pre502 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1941

; <label>:16287:                                  ; preds = %routine_idivl__esi.exit1968
  %16288 = srem i64 %16280, %16278
  %16289 = and i64 %16281, 4294967295
  store i64 %16289, i64* %RAX.i1659, align 8
  %16290 = and i64 %16288, 4294967295
  store i64 %16290, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit1941

routine_idivl__esi.exit1941:                      ; preds = %16287, %16285
  %16291 = phi i64 [ %.pre502, %16285 ], [ %16268, %16287 ]
  %16292 = phi i64 [ %.pre501, %16285 ], [ %16277, %16287 ]
  %16293 = phi i64 [ %.pre500, %16285 ], [ %16289, %16287 ]
  %16294 = phi %struct.Memory* [ %16286, %16285 ], [ %16229, %16287 ]
  %16295 = trunc i64 %16293 to i32
  %16296 = shl i32 %16295, 1
  %16297 = icmp slt i32 %16295, 0
  %16298 = icmp slt i32 %16296, 0
  %16299 = xor i1 %16297, %16298
  %16300 = zext i32 %16296 to i64
  store i64 %16300, i64* %RAX.i1659, align 8
  %.lobit243 = lshr i32 %16295, 31
  %16301 = trunc i32 %.lobit243 to i8
  store i8 %16301, i8* %17, align 1
  %16302 = and i32 %16296, 254
  %16303 = tail call i32 @llvm.ctpop.i32(i32 %16302)
  %16304 = trunc i32 %16303 to i8
  %16305 = and i8 %16304, 1
  %16306 = xor i8 %16305, 1
  store i8 %16306, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %16307 = icmp eq i32 %16296, 0
  %16308 = zext i1 %16307 to i8
  store i8 %16308, i8* %20, align 1
  %16309 = lshr i32 %16295, 30
  %16310 = trunc i32 %16309 to i8
  %16311 = and i8 %16310, 1
  store i8 %16311, i8* %21, align 1
  %16312 = zext i1 %16299 to i8
  store i8 %16312, i8* %22, align 1
  %16313 = add i64 %16291, -16
  %16314 = add i64 %16292, 5
  store i64 %16314, i64* %3, align 8
  %16315 = inttoptr i64 %16313 to i32*
  %16316 = load i32, i32* %16315, align 4
  %16317 = zext i32 %16316 to i64
  store i64 %16317, i64* %RDI.i6998, align 8
  %16318 = add i64 %16291, -700
  %16319 = add i64 %16292, 11
  store i64 %16319, i64* %3, align 8
  %16320 = inttoptr i64 %16318 to i32*
  store i32 %16296, i32* %16320, align 4
  %16321 = load i32, i32* %EDI.i1741, align 4
  %16322 = zext i32 %16321 to i64
  %16323 = load i64, i64* %3, align 8
  store i64 %16322, i64* %RAX.i1659, align 8
  %16324 = sext i32 %16321 to i64
  %16325 = lshr i64 %16324, 32
  store i64 %16325, i64* %103, align 8
  %16326 = load i32, i32* %ESI.i1759, align 4
  %16327 = add i64 %16323, 5
  store i64 %16327, i64* %3, align 8
  %16328 = sext i32 %16326 to i64
  %16329 = shl nuw i64 %16325, 32
  %16330 = or i64 %16329, %16322
  %16331 = sdiv i64 %16330, %16328
  %16332 = shl i64 %16331, 32
  %16333 = ashr exact i64 %16332, 32
  %16334 = icmp eq i64 %16331, %16333
  br i1 %16334, label %16337, label %16335

; <label>:16335:                                  ; preds = %routine_idivl__esi.exit1941
  %16336 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16327, %struct.Memory* %16294)
  %.pre503 = load i64, i64* %3, align 8
  %.pre504 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit1924

; <label>:16337:                                  ; preds = %routine_idivl__esi.exit1941
  %16338 = srem i64 %16330, %16328
  %16339 = and i64 %16331, 4294967295
  store i64 %16339, i64* %RAX.i1659, align 8
  %16340 = and i64 %16338, 4294967295
  store i64 %16340, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %16341 = trunc i64 %16331 to i32
  br label %routine_idivl__esi.exit1924

routine_idivl__esi.exit1924:                      ; preds = %16337, %16335
  %16342 = phi i32 [ %.pre504, %16335 ], [ %16341, %16337 ]
  %16343 = phi i64 [ %.pre503, %16335 ], [ %16327, %16337 ]
  %16344 = phi %struct.Memory* [ %16336, %16335 ], [ %16294, %16337 ]
  %16345 = load i64, i64* %RBP.i, align 8
  %16346 = add i64 %16345, -700
  %16347 = add i64 %16343, 6
  store i64 %16347, i64* %3, align 8
  %16348 = inttoptr i64 %16346 to i32*
  %16349 = load i32, i32* %16348, align 4
  %16350 = add i32 %16342, %16349
  %16351 = zext i32 %16350 to i64
  store i64 %16351, i64* %RDI.i6998, align 8
  %16352 = icmp ult i32 %16350, %16349
  %16353 = icmp ult i32 %16350, %16342
  %16354 = or i1 %16352, %16353
  %16355 = zext i1 %16354 to i8
  store i8 %16355, i8* %17, align 1
  %16356 = and i32 %16350, 255
  %16357 = tail call i32 @llvm.ctpop.i32(i32 %16356)
  %16358 = trunc i32 %16357 to i8
  %16359 = and i8 %16358, 1
  %16360 = xor i8 %16359, 1
  store i8 %16360, i8* %18, align 1
  %16361 = xor i32 %16342, %16349
  %16362 = xor i32 %16361, %16350
  %16363 = lshr i32 %16362, 4
  %16364 = trunc i32 %16363 to i8
  %16365 = and i8 %16364, 1
  store i8 %16365, i8* %19, align 1
  %16366 = icmp eq i32 %16350, 0
  %16367 = zext i1 %16366 to i8
  store i8 %16367, i8* %20, align 1
  %16368 = lshr i32 %16350, 31
  %16369 = trunc i32 %16368 to i8
  store i8 %16369, i8* %21, align 1
  %16370 = lshr i32 %16349, 31
  %16371 = lshr i32 %16342, 31
  %16372 = xor i32 %16368, %16370
  %16373 = xor i32 %16368, %16371
  %16374 = add nuw nsw i32 %16372, %16373
  %16375 = icmp eq i32 %16374, 2
  %16376 = zext i1 %16375 to i8
  store i8 %16376, i8* %22, align 1
  %16377 = sext i32 %16350 to i64
  store i64 %16377, i64* %25, align 8
  %16378 = add i64 %16345, -692
  %16379 = add i64 %16343, 17
  store i64 %16379, i64* %3, align 8
  %16380 = inttoptr i64 %16378 to i32*
  %16381 = load i32, i32* %16380, align 4
  %16382 = zext i32 %16381 to i64
  store i64 %16382, i64* %RAX.i1659, align 8
  %16383 = load i64, i64* %RCX.i1588, align 8
  %16384 = shl nsw i64 %16377, 2
  %16385 = add i64 %16384, %16383
  %16386 = add i64 %16343, 21
  store i64 %16386, i64* %3, align 8
  %16387 = inttoptr i64 %16385 to i32*
  store i32 %16381, i32* %16387, align 4
  %16388 = load i64, i64* %RBP.i, align 8
  %16389 = add i64 %16388, -48
  %16390 = load i64, i64* %3, align 8
  %16391 = add i64 %16390, 7
  store i64 %16391, i64* %3, align 8
  %16392 = inttoptr i64 %16389 to i32*
  store i32 0, i32* %16392, align 4
  %.pre505 = load i64, i64* %3, align 8
  br label %block_.L_485dde

block_.L_485dde:                                  ; preds = %block_.L_485e80, %routine_idivl__esi.exit1924
  %16393 = phi i64 [ %16738, %block_.L_485e80 ], [ %.pre505, %routine_idivl__esi.exit1924 ]
  %16394 = load i64, i64* %RBP.i, align 8
  %16395 = add i64 %16394, -48
  %16396 = add i64 %16393, 4
  store i64 %16396, i64* %3, align 8
  %16397 = inttoptr i64 %16395 to i32*
  %16398 = load i32, i32* %16397, align 4
  %16399 = add i32 %16398, -4
  %16400 = icmp ult i32 %16398, 4
  %16401 = zext i1 %16400 to i8
  store i8 %16401, i8* %17, align 1
  %16402 = and i32 %16399, 255
  %16403 = tail call i32 @llvm.ctpop.i32(i32 %16402)
  %16404 = trunc i32 %16403 to i8
  %16405 = and i8 %16404, 1
  %16406 = xor i8 %16405, 1
  store i8 %16406, i8* %18, align 1
  %16407 = xor i32 %16399, %16398
  %16408 = lshr i32 %16407, 4
  %16409 = trunc i32 %16408 to i8
  %16410 = and i8 %16409, 1
  store i8 %16410, i8* %19, align 1
  %16411 = icmp eq i32 %16399, 0
  %16412 = zext i1 %16411 to i8
  store i8 %16412, i8* %20, align 1
  %16413 = lshr i32 %16399, 31
  %16414 = trunc i32 %16413 to i8
  store i8 %16414, i8* %21, align 1
  %16415 = lshr i32 %16398, 31
  %16416 = xor i32 %16413, %16415
  %16417 = add nuw nsw i32 %16416, %16415
  %16418 = icmp eq i32 %16417, 2
  %16419 = zext i1 %16418 to i8
  store i8 %16419, i8* %22, align 1
  %16420 = icmp ne i8 %16414, 0
  %16421 = xor i1 %16420, %16418
  %.v713 = select i1 %16421, i64 10, i64 181
  %16422 = add i64 %16393, %.v713
  store i64 %16422, i64* %3, align 8
  br i1 %16421, label %block_485de8, label %block_.L_485e93

block_485de8:                                     ; preds = %block_.L_485dde
  %16423 = add i64 %16394, -44
  %16424 = add i64 %16422, 7
  store i64 %16424, i64* %3, align 8
  %16425 = inttoptr i64 %16423 to i32*
  store i32 0, i32* %16425, align 4
  %.pre548 = load i64, i64* %3, align 8
  br label %block_.L_485def

block_.L_485def:                                  ; preds = %block_485df9, %block_485de8
  %16426 = phi i64 [ %16708, %block_485df9 ], [ %.pre548, %block_485de8 ]
  %16427 = load i64, i64* %RBP.i, align 8
  %16428 = add i64 %16427, -44
  %16429 = add i64 %16426, 4
  store i64 %16429, i64* %3, align 8
  %16430 = inttoptr i64 %16428 to i32*
  %16431 = load i32, i32* %16430, align 4
  %16432 = add i32 %16431, -4
  %16433 = icmp ult i32 %16431, 4
  %16434 = zext i1 %16433 to i8
  store i8 %16434, i8* %17, align 1
  %16435 = and i32 %16432, 255
  %16436 = tail call i32 @llvm.ctpop.i32(i32 %16435)
  %16437 = trunc i32 %16436 to i8
  %16438 = and i8 %16437, 1
  %16439 = xor i8 %16438, 1
  store i8 %16439, i8* %18, align 1
  %16440 = xor i32 %16432, %16431
  %16441 = lshr i32 %16440, 4
  %16442 = trunc i32 %16441 to i8
  %16443 = and i8 %16442, 1
  store i8 %16443, i8* %19, align 1
  %16444 = icmp eq i32 %16432, 0
  %16445 = zext i1 %16444 to i8
  store i8 %16445, i8* %20, align 1
  %16446 = lshr i32 %16432, 31
  %16447 = trunc i32 %16446 to i8
  store i8 %16447, i8* %21, align 1
  %16448 = lshr i32 %16431, 31
  %16449 = xor i32 %16446, %16448
  %16450 = add nuw nsw i32 %16449, %16448
  %16451 = icmp eq i32 %16450, 2
  %16452 = zext i1 %16451 to i8
  store i8 %16452, i8* %22, align 1
  %16453 = icmp ne i8 %16447, 0
  %16454 = xor i1 %16453, %16451
  %.v661 = select i1 %16454, i64 10, i64 145
  %16455 = add i64 %16426, %.v661
  store i64 %16455, i64* %3, align 8
  br i1 %16454, label %block_485df9, label %block_.L_485e80

block_485df9:                                     ; preds = %block_.L_485def
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RAX.i1659, align 8
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX.i1588, align 8
  %16456 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %16457 = add i64 %16456, 13112
  store i64 %16457, i64* %RDX.i1943, align 8
  %16458 = icmp ugt i64 %16456, -13113
  %16459 = zext i1 %16458 to i8
  store i8 %16459, i8* %17, align 1
  %16460 = trunc i64 %16457 to i32
  %16461 = and i32 %16460, 255
  %16462 = tail call i32 @llvm.ctpop.i32(i32 %16461)
  %16463 = trunc i32 %16462 to i8
  %16464 = and i8 %16463, 1
  %16465 = xor i8 %16464, 1
  store i8 %16465, i8* %18, align 1
  %16466 = xor i64 %16456, 16
  %16467 = xor i64 %16466, %16457
  %16468 = lshr i64 %16467, 4
  %16469 = trunc i64 %16468 to i8
  %16470 = and i8 %16469, 1
  store i8 %16470, i8* %19, align 1
  %16471 = icmp eq i64 %16457, 0
  %16472 = zext i1 %16471 to i8
  store i8 %16472, i8* %20, align 1
  %16473 = lshr i64 %16457, 63
  %16474 = trunc i64 %16473 to i8
  store i8 %16474, i8* %21, align 1
  %16475 = lshr i64 %16456, 63
  %16476 = xor i64 %16473, %16475
  %16477 = add nuw nsw i64 %16476, %16473
  %16478 = icmp eq i64 %16477, 2
  %16479 = zext i1 %16478 to i8
  store i8 %16479, i8* %22, align 1
  %16480 = add i64 %16455, 39
  store i64 %16480, i64* %3, align 8
  %16481 = load i32, i32* %16430, align 4
  %16482 = sext i32 %16481 to i64
  %16483 = shl nsw i64 %16482, 6
  store i64 %16483, i64* %RSI.i2015, align 8
  %16484 = add i64 %16483, %16457
  store i64 %16484, i64* %RDX.i1943, align 8
  %16485 = icmp ult i64 %16484, %16457
  %16486 = icmp ult i64 %16484, %16483
  %16487 = or i1 %16485, %16486
  %16488 = zext i1 %16487 to i8
  store i8 %16488, i8* %17, align 1
  %16489 = trunc i64 %16484 to i32
  %16490 = and i32 %16489, 255
  %16491 = tail call i32 @llvm.ctpop.i32(i32 %16490)
  %16492 = trunc i32 %16491 to i8
  %16493 = and i8 %16492, 1
  %16494 = xor i8 %16493, 1
  store i8 %16494, i8* %18, align 1
  %16495 = xor i64 %16457, %16484
  %16496 = lshr i64 %16495, 4
  %16497 = trunc i64 %16496 to i8
  %16498 = and i8 %16497, 1
  store i8 %16498, i8* %19, align 1
  %16499 = icmp eq i64 %16484, 0
  %16500 = zext i1 %16499 to i8
  store i8 %16500, i8* %20, align 1
  %16501 = lshr i64 %16484, 63
  %16502 = trunc i64 %16501 to i8
  store i8 %16502, i8* %21, align 1
  %16503 = lshr i64 %16482, 57
  %16504 = and i64 %16503, 1
  %16505 = xor i64 %16501, %16473
  %16506 = xor i64 %16501, %16504
  %16507 = add nuw nsw i64 %16505, %16506
  %16508 = icmp eq i64 %16507, 2
  %16509 = zext i1 %16508 to i8
  store i8 %16509, i8* %22, align 1
  %16510 = load i64, i64* %RBP.i, align 8
  %16511 = add i64 %16510, -48
  %16512 = add i64 %16455, 50
  store i64 %16512, i64* %3, align 8
  %16513 = inttoptr i64 %16511 to i32*
  %16514 = load i32, i32* %16513, align 4
  %16515 = sext i32 %16514 to i64
  store i64 %16515, i64* %RSI.i2015, align 8
  %16516 = shl nsw i64 %16515, 2
  %16517 = add i64 %16516, %16484
  %16518 = add i64 %16455, 53
  store i64 %16518, i64* %3, align 8
  %16519 = inttoptr i64 %16517 to i32*
  %16520 = load i32, i32* %16519, align 4
  %16521 = zext i32 %16520 to i64
  store i64 %16521, i64* %RDI.i6998, align 8
  %16522 = add i64 %16510, -44
  %16523 = add i64 %16455, 57
  store i64 %16523, i64* %3, align 8
  %16524 = inttoptr i64 %16522 to i32*
  %16525 = load i32, i32* %16524, align 4
  %16526 = sext i32 %16525 to i64
  %16527 = shl nsw i64 %16526, 6
  store i64 %16527, i64* %RDX.i1943, align 8
  %16528 = load i64, i64* %RCX.i1588, align 8
  %16529 = add i64 %16527, %16528
  store i64 %16529, i64* %RCX.i1588, align 8
  %16530 = icmp ult i64 %16529, %16528
  %16531 = icmp ult i64 %16529, %16527
  %16532 = or i1 %16530, %16531
  %16533 = zext i1 %16532 to i8
  store i8 %16533, i8* %17, align 1
  %16534 = trunc i64 %16529 to i32
  %16535 = and i32 %16534, 255
  %16536 = tail call i32 @llvm.ctpop.i32(i32 %16535)
  %16537 = trunc i32 %16536 to i8
  %16538 = and i8 %16537, 1
  %16539 = xor i8 %16538, 1
  store i8 %16539, i8* %18, align 1
  %16540 = xor i64 %16528, %16529
  %16541 = lshr i64 %16540, 4
  %16542 = trunc i64 %16541 to i8
  %16543 = and i8 %16542, 1
  store i8 %16543, i8* %19, align 1
  %16544 = icmp eq i64 %16529, 0
  %16545 = zext i1 %16544 to i8
  store i8 %16545, i8* %20, align 1
  %16546 = lshr i64 %16529, 63
  %16547 = trunc i64 %16546 to i8
  store i8 %16547, i8* %21, align 1
  %16548 = lshr i64 %16528, 63
  %16549 = lshr i64 %16526, 57
  %16550 = and i64 %16549, 1
  %16551 = xor i64 %16546, %16548
  %16552 = xor i64 %16546, %16550
  %16553 = add nuw nsw i64 %16551, %16552
  %16554 = icmp eq i64 %16553, 2
  %16555 = zext i1 %16554 to i8
  store i8 %16555, i8* %22, align 1
  %16556 = add i64 %16455, 68
  store i64 %16556, i64* %3, align 8
  %16557 = load i32, i32* %16513, align 4
  %16558 = sext i32 %16557 to i64
  store i64 %16558, i64* %RDX.i1943, align 8
  %16559 = shl nsw i64 %16558, 2
  %16560 = add i64 %16559, %16529
  %16561 = add i64 %16455, 71
  store i64 %16561, i64* %3, align 8
  %16562 = inttoptr i64 %16560 to i32*
  store i32 %16520, i32* %16562, align 4
  %16563 = load i64, i64* %RBP.i, align 8
  %16564 = add i64 %16563, -44
  %16565 = load i64, i64* %3, align 8
  %16566 = add i64 %16565, 4
  store i64 %16566, i64* %3, align 8
  %16567 = inttoptr i64 %16564 to i32*
  %16568 = load i32, i32* %16567, align 4
  %16569 = sext i32 %16568 to i64
  %16570 = shl nsw i64 %16569, 6
  store i64 %16570, i64* %RCX.i1588, align 8
  %16571 = load i64, i64* %RAX.i1659, align 8
  %16572 = add i64 %16570, %16571
  store i64 %16572, i64* %RAX.i1659, align 8
  %16573 = icmp ult i64 %16572, %16571
  %16574 = icmp ult i64 %16572, %16570
  %16575 = or i1 %16573, %16574
  %16576 = zext i1 %16575 to i8
  store i8 %16576, i8* %17, align 1
  %16577 = trunc i64 %16572 to i32
  %16578 = and i32 %16577, 255
  %16579 = tail call i32 @llvm.ctpop.i32(i32 %16578)
  %16580 = trunc i32 %16579 to i8
  %16581 = and i8 %16580, 1
  %16582 = xor i8 %16581, 1
  store i8 %16582, i8* %18, align 1
  %16583 = xor i64 %16571, %16572
  %16584 = lshr i64 %16583, 4
  %16585 = trunc i64 %16584 to i8
  %16586 = and i8 %16585, 1
  store i8 %16586, i8* %19, align 1
  %16587 = icmp eq i64 %16572, 0
  %16588 = zext i1 %16587 to i8
  store i8 %16588, i8* %20, align 1
  %16589 = lshr i64 %16572, 63
  %16590 = trunc i64 %16589 to i8
  store i8 %16590, i8* %21, align 1
  %16591 = lshr i64 %16571, 63
  %16592 = lshr i64 %16569, 57
  %16593 = and i64 %16592, 1
  %16594 = xor i64 %16589, %16591
  %16595 = xor i64 %16589, %16593
  %16596 = add nuw nsw i64 %16594, %16595
  %16597 = icmp eq i64 %16596, 2
  %16598 = zext i1 %16597 to i8
  store i8 %16598, i8* %22, align 1
  %16599 = add i64 %16563, -48
  %16600 = add i64 %16565, 15
  store i64 %16600, i64* %3, align 8
  %16601 = inttoptr i64 %16599 to i32*
  %16602 = load i32, i32* %16601, align 4
  %16603 = sext i32 %16602 to i64
  store i64 %16603, i64* %RCX.i1588, align 8
  %16604 = shl nsw i64 %16603, 2
  %16605 = add i64 %16604, %16572
  %16606 = add i64 %16565, 18
  store i64 %16606, i64* %3, align 8
  %16607 = inttoptr i64 %16605 to i32*
  %16608 = load i32, i32* %16607, align 4
  %16609 = zext i32 %16608 to i64
  store i64 %16609, i64* %RDI.i6998, align 8
  %16610 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %16611 = add i64 %16610, 13112
  store i64 %16611, i64* %RAX.i1659, align 8
  %16612 = icmp ugt i64 %16610, -13113
  %16613 = zext i1 %16612 to i8
  store i8 %16613, i8* %17, align 1
  %16614 = trunc i64 %16611 to i32
  %16615 = and i32 %16614, 255
  %16616 = tail call i32 @llvm.ctpop.i32(i32 %16615)
  %16617 = trunc i32 %16616 to i8
  %16618 = and i8 %16617, 1
  %16619 = xor i8 %16618, 1
  store i8 %16619, i8* %18, align 1
  %16620 = xor i64 %16610, 16
  %16621 = xor i64 %16620, %16611
  %16622 = lshr i64 %16621, 4
  %16623 = trunc i64 %16622 to i8
  %16624 = and i8 %16623, 1
  store i8 %16624, i8* %19, align 1
  %16625 = icmp eq i64 %16611, 0
  %16626 = zext i1 %16625 to i8
  store i8 %16626, i8* %20, align 1
  %16627 = lshr i64 %16611, 63
  %16628 = trunc i64 %16627 to i8
  store i8 %16628, i8* %21, align 1
  %16629 = lshr i64 %16610, 63
  %16630 = xor i64 %16627, %16629
  %16631 = add nuw nsw i64 %16630, %16627
  %16632 = icmp eq i64 %16631, 2
  %16633 = zext i1 %16632 to i8
  store i8 %16633, i8* %22, align 1
  %16634 = load i64, i64* %RBP.i, align 8
  %16635 = add i64 %16634, -44
  %16636 = add i64 %16565, 36
  store i64 %16636, i64* %3, align 8
  %16637 = inttoptr i64 %16635 to i32*
  %16638 = load i32, i32* %16637, align 4
  %16639 = sext i32 %16638 to i64
  %16640 = shl nsw i64 %16639, 6
  store i64 %16640, i64* %RCX.i1588, align 8
  %16641 = add i64 %16640, %16611
  store i64 %16641, i64* %RAX.i1659, align 8
  %16642 = icmp ult i64 %16641, %16611
  %16643 = icmp ult i64 %16641, %16640
  %16644 = or i1 %16642, %16643
  %16645 = zext i1 %16644 to i8
  store i8 %16645, i8* %17, align 1
  %16646 = trunc i64 %16641 to i32
  %16647 = and i32 %16646, 255
  %16648 = tail call i32 @llvm.ctpop.i32(i32 %16647)
  %16649 = trunc i32 %16648 to i8
  %16650 = and i8 %16649, 1
  %16651 = xor i8 %16650, 1
  store i8 %16651, i8* %18, align 1
  %16652 = xor i64 %16611, %16641
  %16653 = lshr i64 %16652, 4
  %16654 = trunc i64 %16653 to i8
  %16655 = and i8 %16654, 1
  store i8 %16655, i8* %19, align 1
  %16656 = icmp eq i64 %16641, 0
  %16657 = zext i1 %16656 to i8
  store i8 %16657, i8* %20, align 1
  %16658 = lshr i64 %16641, 63
  %16659 = trunc i64 %16658 to i8
  store i8 %16659, i8* %21, align 1
  %16660 = lshr i64 %16639, 57
  %16661 = and i64 %16660, 1
  %16662 = xor i64 %16658, %16627
  %16663 = xor i64 %16658, %16661
  %16664 = add nuw nsw i64 %16662, %16663
  %16665 = icmp eq i64 %16664, 2
  %16666 = zext i1 %16665 to i8
  store i8 %16666, i8* %22, align 1
  %16667 = add i64 %16634, -48
  %16668 = add i64 %16565, 47
  store i64 %16668, i64* %3, align 8
  %16669 = inttoptr i64 %16667 to i32*
  %16670 = load i32, i32* %16669, align 4
  %16671 = sext i32 %16670 to i64
  store i64 %16671, i64* %RCX.i1588, align 8
  %16672 = shl nsw i64 %16671, 2
  %16673 = add i64 %16672, %16641
  %16674 = load i32, i32* %EDI.i1741, align 4
  %16675 = add i64 %16565, 50
  store i64 %16675, i64* %3, align 8
  %16676 = inttoptr i64 %16673 to i32*
  store i32 %16674, i32* %16676, align 4
  %16677 = load i64, i64* %RBP.i, align 8
  %16678 = add i64 %16677, -44
  %16679 = load i64, i64* %3, align 8
  %16680 = add i64 %16679, 3
  store i64 %16680, i64* %3, align 8
  %16681 = inttoptr i64 %16678 to i32*
  %16682 = load i32, i32* %16681, align 4
  %16683 = add i32 %16682, 1
  %16684 = zext i32 %16683 to i64
  store i64 %16684, i64* %RAX.i1659, align 8
  %16685 = icmp eq i32 %16682, -1
  %16686 = icmp eq i32 %16683, 0
  %16687 = or i1 %16685, %16686
  %16688 = zext i1 %16687 to i8
  store i8 %16688, i8* %17, align 1
  %16689 = and i32 %16683, 255
  %16690 = tail call i32 @llvm.ctpop.i32(i32 %16689)
  %16691 = trunc i32 %16690 to i8
  %16692 = and i8 %16691, 1
  %16693 = xor i8 %16692, 1
  store i8 %16693, i8* %18, align 1
  %16694 = xor i32 %16683, %16682
  %16695 = lshr i32 %16694, 4
  %16696 = trunc i32 %16695 to i8
  %16697 = and i8 %16696, 1
  store i8 %16697, i8* %19, align 1
  %16698 = zext i1 %16686 to i8
  store i8 %16698, i8* %20, align 1
  %16699 = lshr i32 %16683, 31
  %16700 = trunc i32 %16699 to i8
  store i8 %16700, i8* %21, align 1
  %16701 = lshr i32 %16682, 31
  %16702 = xor i32 %16699, %16701
  %16703 = add nuw nsw i32 %16702, %16699
  %16704 = icmp eq i32 %16703, 2
  %16705 = zext i1 %16704 to i8
  store i8 %16705, i8* %22, align 1
  %16706 = add i64 %16679, 9
  store i64 %16706, i64* %3, align 8
  store i32 %16683, i32* %16681, align 4
  %16707 = load i64, i64* %3, align 8
  %16708 = add i64 %16707, -140
  store i64 %16708, i64* %3, align 8
  br label %block_.L_485def

block_.L_485e80:                                  ; preds = %block_.L_485def
  %16709 = add i64 %16427, -48
  %16710 = add i64 %16455, 8
  store i64 %16710, i64* %3, align 8
  %16711 = inttoptr i64 %16709 to i32*
  %16712 = load i32, i32* %16711, align 4
  %16713 = add i32 %16712, 1
  %16714 = zext i32 %16713 to i64
  store i64 %16714, i64* %RAX.i1659, align 8
  %16715 = icmp eq i32 %16712, -1
  %16716 = icmp eq i32 %16713, 0
  %16717 = or i1 %16715, %16716
  %16718 = zext i1 %16717 to i8
  store i8 %16718, i8* %17, align 1
  %16719 = and i32 %16713, 255
  %16720 = tail call i32 @llvm.ctpop.i32(i32 %16719)
  %16721 = trunc i32 %16720 to i8
  %16722 = and i8 %16721, 1
  %16723 = xor i8 %16722, 1
  store i8 %16723, i8* %18, align 1
  %16724 = xor i32 %16713, %16712
  %16725 = lshr i32 %16724, 4
  %16726 = trunc i32 %16725 to i8
  %16727 = and i8 %16726, 1
  store i8 %16727, i8* %19, align 1
  %16728 = zext i1 %16716 to i8
  store i8 %16728, i8* %20, align 1
  %16729 = lshr i32 %16713, 31
  %16730 = trunc i32 %16729 to i8
  store i8 %16730, i8* %21, align 1
  %16731 = lshr i32 %16712, 31
  %16732 = xor i32 %16729, %16731
  %16733 = add nuw nsw i32 %16732, %16729
  %16734 = icmp eq i32 %16733, 2
  %16735 = zext i1 %16734 to i8
  store i8 %16735, i8* %22, align 1
  %16736 = add i64 %16455, 14
  store i64 %16736, i64* %3, align 8
  store i32 %16713, i32* %16711, align 4
  %16737 = load i64, i64* %3, align 8
  %16738 = add i64 %16737, -176
  store i64 %16738, i64* %3, align 8
  br label %block_.L_485dde

block_.L_485e93:                                  ; preds = %block_.L_485dde
  store i64 1, i64* %RDI.i6998, align 8
  %16739 = add i64 %16394, -12
  %16740 = add i64 %16422, 8
  store i64 %16740, i64* %3, align 8
  %16741 = inttoptr i64 %16739 to i32*
  %16742 = load i32, i32* %16741, align 4
  %16743 = add i32 %16742, 8
  %16744 = zext i32 %16743 to i64
  store i64 %16744, i64* %RAX.i1659, align 8
  %16745 = icmp ugt i32 %16742, -9
  %16746 = zext i1 %16745 to i8
  store i8 %16746, i8* %17, align 1
  %16747 = and i32 %16743, 255
  %16748 = tail call i32 @llvm.ctpop.i32(i32 %16747)
  %16749 = trunc i32 %16748 to i8
  %16750 = and i8 %16749, 1
  %16751 = xor i8 %16750, 1
  store i8 %16751, i8* %18, align 1
  %16752 = xor i32 %16743, %16742
  %16753 = lshr i32 %16752, 4
  %16754 = trunc i32 %16753 to i8
  %16755 = and i8 %16754, 1
  store i8 %16755, i8* %19, align 1
  %16756 = icmp eq i32 %16743, 0
  %16757 = zext i1 %16756 to i8
  store i8 %16757, i8* %20, align 1
  %16758 = lshr i32 %16743, 31
  %16759 = trunc i32 %16758 to i8
  store i8 %16759, i8* %21, align 1
  %16760 = lshr i32 %16742, 31
  %16761 = xor i32 %16758, %16760
  %16762 = add nuw nsw i32 %16761, %16758
  %16763 = icmp eq i32 %16762, 2
  %16764 = zext i1 %16763 to i8
  store i8 %16764, i8* %22, align 1
  %16765 = add i64 %16394, -16
  %16766 = add i64 %16422, 14
  store i64 %16766, i64* %3, align 8
  %16767 = inttoptr i64 %16765 to i32*
  %16768 = load i32, i32* %16767, align 4
  %16769 = zext i32 %16768 to i64
  store i64 %16769, i64* %RDX.i1943, align 8
  store i64 %16744, i64* %RSI.i2015, align 8
  %16770 = add i64 %16422, -504275
  %16771 = add i64 %16422, 21
  %16772 = load i64, i64* %6, align 8
  %16773 = add i64 %16772, -8
  %16774 = inttoptr i64 %16773 to i64*
  store i64 %16771, i64* %16774, align 8
  store i64 %16773, i64* %6, align 8
  store i64 %16770, i64* %3, align 8
  %call2_485ea3 = tail call %struct.Memory* @sub_40acc0.dct_chroma4x4(%struct.State* nonnull %0, i64 %16770, %struct.Memory* %16344)
  %16775 = load i64, i64* %3, align 8
  store i64 2, i64* %RDX.i1943, align 8
  store i64 add (i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64 64), i64* %RCX.i1588, align 8
  store i64 add (i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64 64), i64* %25, align 8
  store i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64* %R9.i1633, align 8
  store i8 zext (i1 or (i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64)), i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 64)) to i8), i8* %17, align 1
  %16776 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64) to i32), i32 255))
  %16777 = trunc i32 %16776 to i8
  %16778 = and i8 %16777, 1
  %16779 = xor i8 %16778, 1
  store i8 %16779, i8* %18, align 1
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64)), i64 4) to i8), i8 1), i8* %19, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 0) to i8), i8* %20, align 1
  store i8 trunc (i64 lshr (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 63) to i8), i8* %21, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 63), i64 lshr (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 63)), i64 lshr (i64 add (i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64 64), i64 63)), i64 2) to i8), i8* %22, align 1
  %16780 = load i64, i64* %RBP.i, align 8
  %16781 = add i64 %16780, -12
  %16782 = add i64 %16775, 50
  store i64 %16782, i64* %3, align 8
  %16783 = inttoptr i64 %16781 to i32*
  %16784 = load i32, i32* %16783, align 4
  %16785 = zext i32 %16784 to i64
  store i64 %16785, i64* %RSI.i2015, align 8
  %16786 = add i64 %16780, -704
  %16787 = load i32, i32* %EAX.i2033, align 4
  %16788 = add i64 %16775, 56
  store i64 %16788, i64* %3, align 8
  %16789 = inttoptr i64 %16786 to i32*
  store i32 %16787, i32* %16789, align 4
  %16790 = load i32, i32* %ESI.i1759, align 4
  %16791 = zext i32 %16790 to i64
  %16792 = load i64, i64* %3, align 8
  store i64 %16791, i64* %RAX.i1659, align 8
  %16793 = load i64, i64* %RBP.i, align 8
  %16794 = add i64 %16793, -708
  %16795 = load i32, i32* %108, align 4
  %16796 = add i64 %16792, 8
  store i64 %16796, i64* %3, align 8
  %16797 = inttoptr i64 %16794 to i32*
  store i32 %16795, i32* %16797, align 4
  %16798 = load i64, i64* %3, align 8
  %16799 = load i32, i32* %EAX.i2033, align 8
  %16800 = sext i32 %16799 to i64
  %16801 = lshr i64 %16800, 32
  store i64 %16801, i64* %103, align 8
  %16802 = load i64, i64* %RBP.i, align 8
  %16803 = add i64 %16802, -708
  %16804 = add i64 %16798, 7
  store i64 %16804, i64* %3, align 8
  %16805 = inttoptr i64 %16803 to i32*
  %16806 = load i32, i32* %16805, align 4
  %16807 = zext i32 %16806 to i64
  store i64 %16807, i64* %RSI.i2015, align 8
  %16808 = add i64 %16798, 9
  store i64 %16808, i64* %3, align 8
  %16809 = zext i32 %16799 to i64
  %16810 = sext i32 %16806 to i64
  %16811 = shl nuw i64 %16801, 32
  %16812 = or i64 %16811, %16809
  %16813 = sdiv i64 %16812, %16810
  %16814 = shl i64 %16813, 32
  %16815 = ashr exact i64 %16814, 32
  %16816 = icmp eq i64 %16813, %16815
  br i1 %16816, label %16819, label %16817

; <label>:16817:                                  ; preds = %block_.L_485e93
  %16818 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16808, %struct.Memory* %call2_485ea3)
  %.pre506 = load i64, i64* %RDX.i1943, align 8
  %.pre507 = load i64, i64* %3, align 8
  %.pre508 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1757

; <label>:16819:                                  ; preds = %block_.L_485e93
  %16820 = srem i64 %16812, %16810
  %16821 = and i64 %16813, 4294967295
  store i64 %16821, i64* %RAX.i1659, align 8
  %16822 = and i64 %16820, 4294967295
  store i64 %16822, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit1757

routine_idivl__esi.exit1757:                      ; preds = %16819, %16817
  %16823 = phi i64 [ %.pre508, %16817 ], [ %16802, %16819 ]
  %16824 = phi i64 [ %.pre507, %16817 ], [ %16808, %16819 ]
  %16825 = phi i64 [ %.pre506, %16817 ], [ %16822, %16819 ]
  %16826 = phi %struct.Memory* [ %16818, %16817 ], [ %call2_485ea3, %16819 ]
  %16827 = trunc i64 %16825 to i32
  %16828 = shl i32 %16827, 1
  %16829 = icmp slt i32 %16827, 0
  %16830 = icmp slt i32 %16828, 0
  %16831 = xor i1 %16829, %16830
  %16832 = zext i32 %16828 to i64
  store i64 %16832, i64* %RDX.i1943, align 8
  %.lobit248 = lshr i32 %16827, 31
  %16833 = trunc i32 %.lobit248 to i8
  store i8 %16833, i8* %17, align 1
  %16834 = and i32 %16828, 254
  %16835 = tail call i32 @llvm.ctpop.i32(i32 %16834)
  %16836 = trunc i32 %16835 to i8
  %16837 = and i8 %16836, 1
  %16838 = xor i8 %16837, 1
  store i8 %16838, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %16839 = icmp eq i32 %16828, 0
  %16840 = zext i1 %16839 to i8
  store i8 %16840, i8* %20, align 1
  %16841 = lshr i32 %16827, 30
  %16842 = trunc i32 %16841 to i8
  %16843 = and i8 %16842, 1
  store i8 %16843, i8* %21, align 1
  %16844 = zext i1 %16831 to i8
  store i8 %16844, i8* %22, align 1
  %16845 = add i64 %16823, -16
  %16846 = add i64 %16824, 5
  store i64 %16846, i64* %3, align 8
  %16847 = inttoptr i64 %16845 to i32*
  %16848 = load i32, i32* %16847, align 4
  %16849 = zext i32 %16848 to i64
  store i64 %16849, i64* %RDI.i6998, align 8
  store i64 %16849, i64* %RAX.i1659, align 8
  %16850 = add i64 %16823, -712
  %16851 = add i64 %16824, 13
  store i64 %16851, i64* %3, align 8
  %16852 = inttoptr i64 %16850 to i32*
  store i32 %16828, i32* %16852, align 4
  %16853 = load i64, i64* %3, align 8
  %16854 = load i32, i32* %EAX.i2033, align 8
  %16855 = sext i32 %16854 to i64
  %16856 = lshr i64 %16855, 32
  store i64 %16856, i64* %103, align 8
  %16857 = load i32, i32* %ESI.i1759, align 4
  %16858 = add i64 %16853, 3
  store i64 %16858, i64* %3, align 8
  %16859 = zext i32 %16854 to i64
  %16860 = sext i32 %16857 to i64
  %16861 = shl nuw i64 %16856, 32
  %16862 = or i64 %16861, %16859
  %16863 = sdiv i64 %16862, %16860
  %16864 = shl i64 %16863, 32
  %16865 = ashr exact i64 %16864, 32
  %16866 = icmp eq i64 %16863, %16865
  br i1 %16866, label %16869, label %16867

; <label>:16867:                                  ; preds = %routine_idivl__esi.exit1757
  %16868 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16858, %struct.Memory* %16826)
  %.pre509 = load i64, i64* %3, align 8
  %.pre510 = load i32, i32* %108, align 4
  br label %routine_idivl__esi.exit1739

; <label>:16869:                                  ; preds = %routine_idivl__esi.exit1757
  %16870 = srem i64 %16862, %16860
  %16871 = and i64 %16863, 4294967295
  store i64 %16871, i64* %RAX.i1659, align 8
  %16872 = and i64 %16870, 4294967295
  store i64 %16872, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %16873 = trunc i64 %16870 to i32
  br label %routine_idivl__esi.exit1739

routine_idivl__esi.exit1739:                      ; preds = %16869, %16867
  %16874 = phi i32 [ %.pre510, %16867 ], [ %16873, %16869 ]
  %16875 = phi i64 [ %.pre509, %16867 ], [ %16858, %16869 ]
  %16876 = phi %struct.Memory* [ %16868, %16867 ], [ %16826, %16869 ]
  %16877 = load i64, i64* %RBP.i, align 8
  %16878 = add i64 %16877, -712
  %16879 = add i64 %16875, 6
  store i64 %16879, i64* %3, align 8
  %16880 = inttoptr i64 %16878 to i32*
  %16881 = load i32, i32* %16880, align 4
  %16882 = add i32 %16874, %16881
  %16883 = zext i32 %16882 to i64
  store i64 %16883, i64* %RDI.i6998, align 8
  %16884 = sext i32 %16882 to i64
  %16885 = shl nsw i64 %16884, 4
  store i64 %16885, i64* %50, align 8
  %16886 = load i64, i64* %R9.i1633, align 8
  %16887 = add i64 %16885, %16886
  store i64 %16887, i64* %R9.i1633, align 8
  %16888 = icmp ult i64 %16887, %16886
  %16889 = icmp ult i64 %16887, %16885
  %16890 = or i1 %16888, %16889
  %16891 = zext i1 %16890 to i8
  store i8 %16891, i8* %17, align 1
  %16892 = trunc i64 %16887 to i32
  %16893 = and i32 %16892, 255
  %16894 = tail call i32 @llvm.ctpop.i32(i32 %16893)
  %16895 = trunc i32 %16894 to i8
  %16896 = and i8 %16895, 1
  %16897 = xor i8 %16896, 1
  store i8 %16897, i8* %18, align 1
  %16898 = xor i64 %16885, %16886
  %16899 = xor i64 %16898, %16887
  %16900 = lshr i64 %16899, 4
  %16901 = trunc i64 %16900 to i8
  %16902 = and i8 %16901, 1
  store i8 %16902, i8* %19, align 1
  %16903 = icmp eq i64 %16887, 0
  %16904 = zext i1 %16903 to i8
  store i8 %16904, i8* %20, align 1
  %16905 = lshr i64 %16887, 63
  %16906 = trunc i64 %16905 to i8
  store i8 %16906, i8* %21, align 1
  %16907 = lshr i64 %16886, 63
  %16908 = lshr i64 %16884, 59
  %16909 = and i64 %16908, 1
  %16910 = xor i64 %16905, %16907
  %16911 = xor i64 %16905, %16909
  %16912 = add nuw nsw i64 %16910, %16911
  %16913 = icmp eq i64 %16912, 2
  %16914 = zext i1 %16913 to i8
  store i8 %16914, i8* %22, align 1
  %16915 = load i64, i64* %RBP.i, align 8
  %16916 = add i64 %16915, -12
  %16917 = add i64 %16875, 21
  store i64 %16917, i64* %3, align 8
  %16918 = inttoptr i64 %16916 to i32*
  %16919 = load i32, i32* %16918, align 4
  %16920 = zext i32 %16919 to i64
  store i64 %16920, i64* %RAX.i1659, align 8
  %16921 = sext i32 %16919 to i64
  %16922 = lshr i64 %16921, 32
  store i64 %16922, i64* %103, align 8
  %16923 = load i32, i32* %ESI.i1759, align 4
  %16924 = add i64 %16875, 26
  store i64 %16924, i64* %3, align 8
  %16925 = sext i32 %16923 to i64
  %16926 = shl nuw i64 %16922, 32
  %16927 = or i64 %16926, %16920
  %16928 = sdiv i64 %16927, %16925
  %16929 = shl i64 %16928, 32
  %16930 = ashr exact i64 %16929, 32
  %16931 = icmp eq i64 %16928, %16930
  br i1 %16931, label %16934, label %16932

; <label>:16932:                                  ; preds = %routine_idivl__esi.exit1739
  %16933 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16924, %struct.Memory* %16876)
  %.pre511 = load i64, i64* %RAX.i1659, align 8
  %.pre512 = load i64, i64* %3, align 8
  %.pre513 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1713

; <label>:16934:                                  ; preds = %routine_idivl__esi.exit1739
  %16935 = srem i64 %16927, %16925
  %16936 = and i64 %16928, 4294967295
  store i64 %16936, i64* %RAX.i1659, align 8
  %16937 = and i64 %16935, 4294967295
  store i64 %16937, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit1713

routine_idivl__esi.exit1713:                      ; preds = %16934, %16932
  %16938 = phi i64 [ %.pre513, %16932 ], [ %16915, %16934 ]
  %16939 = phi i64 [ %.pre512, %16932 ], [ %16924, %16934 ]
  %16940 = phi i64 [ %.pre511, %16932 ], [ %16936, %16934 ]
  %16941 = phi %struct.Memory* [ %16933, %16932 ], [ %16876, %16934 ]
  %16942 = trunc i64 %16940 to i32
  %16943 = shl i32 %16942, 1
  %16944 = icmp slt i32 %16942, 0
  %16945 = icmp slt i32 %16943, 0
  %16946 = xor i1 %16944, %16945
  %16947 = zext i32 %16943 to i64
  store i64 %16947, i64* %RAX.i1659, align 8
  %.lobit250 = lshr i32 %16942, 31
  %16948 = trunc i32 %.lobit250 to i8
  store i8 %16948, i8* %17, align 1
  %16949 = and i32 %16943, 254
  %16950 = tail call i32 @llvm.ctpop.i32(i32 %16949)
  %16951 = trunc i32 %16950 to i8
  %16952 = and i8 %16951, 1
  %16953 = xor i8 %16952, 1
  store i8 %16953, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %16954 = icmp eq i32 %16943, 0
  %16955 = zext i1 %16954 to i8
  store i8 %16955, i8* %20, align 1
  %16956 = lshr i32 %16942, 30
  %16957 = trunc i32 %16956 to i8
  %16958 = and i8 %16957, 1
  store i8 %16958, i8* %21, align 1
  %16959 = zext i1 %16946 to i8
  store i8 %16959, i8* %22, align 1
  %16960 = add i64 %16938, -16
  %16961 = add i64 %16939, 5
  store i64 %16961, i64* %3, align 8
  %16962 = inttoptr i64 %16960 to i32*
  %16963 = load i32, i32* %16962, align 4
  %16964 = zext i32 %16963 to i64
  store i64 %16964, i64* %RDI.i6998, align 8
  %16965 = add i64 %16938, -716
  %16966 = add i64 %16939, 11
  store i64 %16966, i64* %3, align 8
  %16967 = inttoptr i64 %16965 to i32*
  store i32 %16943, i32* %16967, align 4
  %16968 = load i32, i32* %EDI.i1741, align 4
  %16969 = zext i32 %16968 to i64
  %16970 = load i64, i64* %3, align 8
  store i64 %16969, i64* %RAX.i1659, align 8
  %16971 = sext i32 %16968 to i64
  %16972 = lshr i64 %16971, 32
  store i64 %16972, i64* %103, align 8
  %16973 = load i32, i32* %ESI.i1759, align 4
  %16974 = add i64 %16970, 5
  store i64 %16974, i64* %3, align 8
  %16975 = sext i32 %16973 to i64
  %16976 = shl nuw i64 %16972, 32
  %16977 = or i64 %16976, %16969
  %16978 = sdiv i64 %16977, %16975
  %16979 = shl i64 %16978, 32
  %16980 = ashr exact i64 %16979, 32
  %16981 = icmp eq i64 %16978, %16980
  br i1 %16981, label %16984, label %16982

; <label>:16982:                                  ; preds = %routine_idivl__esi.exit1713
  %16983 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %16974, %struct.Memory* %16941)
  %.pre514 = load i64, i64* %3, align 8
  %.pre515 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit1697

; <label>:16984:                                  ; preds = %routine_idivl__esi.exit1713
  %16985 = srem i64 %16977, %16975
  %16986 = and i64 %16978, 4294967295
  store i64 %16986, i64* %RAX.i1659, align 8
  %16987 = and i64 %16985, 4294967295
  store i64 %16987, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %16988 = trunc i64 %16978 to i32
  br label %routine_idivl__esi.exit1697

routine_idivl__esi.exit1697:                      ; preds = %16984, %16982
  %16989 = phi i32 [ %.pre515, %16982 ], [ %16988, %16984 ]
  %16990 = phi i64 [ %.pre514, %16982 ], [ %16974, %16984 ]
  %16991 = phi %struct.Memory* [ %16983, %16982 ], [ %16941, %16984 ]
  %16992 = load i64, i64* %RBP.i, align 8
  %16993 = add i64 %16992, -716
  %16994 = add i64 %16990, 6
  store i64 %16994, i64* %3, align 8
  %16995 = inttoptr i64 %16993 to i32*
  %16996 = load i32, i32* %16995, align 4
  %16997 = add i32 %16989, %16996
  %16998 = zext i32 %16997 to i64
  store i64 %16998, i64* %RDI.i6998, align 8
  %16999 = icmp ult i32 %16997, %16996
  %17000 = icmp ult i32 %16997, %16989
  %17001 = or i1 %16999, %17000
  %17002 = zext i1 %17001 to i8
  store i8 %17002, i8* %17, align 1
  %17003 = and i32 %16997, 255
  %17004 = tail call i32 @llvm.ctpop.i32(i32 %17003)
  %17005 = trunc i32 %17004 to i8
  %17006 = and i8 %17005, 1
  %17007 = xor i8 %17006, 1
  store i8 %17007, i8* %18, align 1
  %17008 = xor i32 %16989, %16996
  %17009 = xor i32 %17008, %16997
  %17010 = lshr i32 %17009, 4
  %17011 = trunc i32 %17010 to i8
  %17012 = and i8 %17011, 1
  store i8 %17012, i8* %19, align 1
  %17013 = icmp eq i32 %16997, 0
  %17014 = zext i1 %17013 to i8
  store i8 %17014, i8* %20, align 1
  %17015 = lshr i32 %16997, 31
  %17016 = trunc i32 %17015 to i8
  store i8 %17016, i8* %21, align 1
  %17017 = lshr i32 %16996, 31
  %17018 = lshr i32 %16989, 31
  %17019 = xor i32 %17015, %17017
  %17020 = xor i32 %17015, %17018
  %17021 = add nuw nsw i32 %17019, %17020
  %17022 = icmp eq i32 %17021, 2
  %17023 = zext i1 %17022 to i8
  store i8 %17023, i8* %22, align 1
  %17024 = sext i32 %16997 to i64
  store i64 %17024, i64* %50, align 8
  %17025 = add i64 %16992, -704
  %17026 = add i64 %16990, 17
  store i64 %17026, i64* %3, align 8
  %17027 = inttoptr i64 %17025 to i32*
  %17028 = load i32, i32* %17027, align 4
  %17029 = zext i32 %17028 to i64
  store i64 %17029, i64* %RAX.i1659, align 8
  %17030 = load i64, i64* %R9.i1633, align 8
  %17031 = shl nsw i64 %17024, 2
  %17032 = add i64 %17031, %17030
  %17033 = add i64 %16990, 21
  store i64 %17033, i64* %3, align 8
  %17034 = inttoptr i64 %17032 to i32*
  store i32 %17028, i32* %17034, align 4
  %17035 = load i64, i64* %RBP.i, align 8
  %17036 = add i64 %17035, -12
  %17037 = load i64, i64* %3, align 8
  %17038 = add i64 %17037, 3
  store i64 %17038, i64* %3, align 8
  %17039 = inttoptr i64 %17036 to i32*
  %17040 = load i32, i32* %17039, align 4
  %17041 = zext i32 %17040 to i64
  store i64 %17041, i64* %RAX.i1659, align 8
  %17042 = sext i32 %17040 to i64
  %17043 = lshr i64 %17042, 32
  store i64 %17043, i64* %103, align 8
  %17044 = load i32, i32* %ESI.i1759, align 4
  %17045 = add i64 %17037, 6
  store i64 %17045, i64* %3, align 8
  %17046 = sext i32 %17044 to i64
  %17047 = shl nuw i64 %17043, 32
  %17048 = or i64 %17047, %17041
  %17049 = sdiv i64 %17048, %17046
  %17050 = shl i64 %17049, 32
  %17051 = ashr exact i64 %17050, 32
  %17052 = icmp eq i64 %17049, %17051
  br i1 %17052, label %17055, label %17053

; <label>:17053:                                  ; preds = %routine_idivl__esi.exit1697
  %17054 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17045, %struct.Memory* %16991)
  %.pre516 = load i64, i64* %RDX.i1943, align 8
  %.pre517 = load i64, i64* %3, align 8
  %.pre518 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1674

; <label>:17055:                                  ; preds = %routine_idivl__esi.exit1697
  %17056 = srem i64 %17048, %17046
  %17057 = and i64 %17049, 4294967295
  store i64 %17057, i64* %RAX.i1659, align 8
  %17058 = and i64 %17056, 4294967295
  store i64 %17058, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit1674

routine_idivl__esi.exit1674:                      ; preds = %17055, %17053
  %17059 = phi i64 [ %.pre518, %17053 ], [ %17035, %17055 ]
  %17060 = phi i64 [ %.pre517, %17053 ], [ %17045, %17055 ]
  %17061 = phi i64 [ %.pre516, %17053 ], [ %17058, %17055 ]
  %17062 = phi %struct.Memory* [ %17054, %17053 ], [ %16991, %17055 ]
  %17063 = trunc i64 %17061 to i32
  %17064 = shl i32 %17063, 1
  %17065 = icmp slt i32 %17063, 0
  %17066 = icmp slt i32 %17064, 0
  %17067 = xor i1 %17065, %17066
  %17068 = zext i32 %17064 to i64
  store i64 %17068, i64* %RDX.i1943, align 8
  %.lobit251 = lshr i32 %17063, 31
  %17069 = trunc i32 %.lobit251 to i8
  store i8 %17069, i8* %17, align 1
  %17070 = and i32 %17064, 254
  %17071 = tail call i32 @llvm.ctpop.i32(i32 %17070)
  %17072 = trunc i32 %17071 to i8
  %17073 = and i8 %17072, 1
  %17074 = xor i8 %17073, 1
  store i8 %17074, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %17075 = icmp eq i32 %17064, 0
  %17076 = zext i1 %17075 to i8
  store i8 %17076, i8* %20, align 1
  %17077 = lshr i32 %17063, 30
  %17078 = trunc i32 %17077 to i8
  %17079 = and i8 %17078, 1
  store i8 %17079, i8* %21, align 1
  %17080 = zext i1 %17067 to i8
  store i8 %17080, i8* %22, align 1
  %17081 = add i64 %17059, -16
  %17082 = add i64 %17060, 5
  store i64 %17082, i64* %3, align 8
  %17083 = inttoptr i64 %17081 to i32*
  %17084 = load i32, i32* %17083, align 4
  %17085 = zext i32 %17084 to i64
  store i64 %17085, i64* %RDI.i6998, align 8
  store i64 %17085, i64* %RAX.i1659, align 8
  %17086 = add i64 %17059, -720
  %17087 = add i64 %17060, 13
  store i64 %17087, i64* %3, align 8
  %17088 = inttoptr i64 %17086 to i32*
  store i32 %17064, i32* %17088, align 4
  %17089 = load i64, i64* %3, align 8
  %17090 = load i32, i32* %EAX.i2033, align 8
  %17091 = sext i32 %17090 to i64
  %17092 = lshr i64 %17091, 32
  store i64 %17092, i64* %103, align 8
  %17093 = load i32, i32* %ESI.i1759, align 4
  %17094 = add i64 %17089, 3
  store i64 %17094, i64* %3, align 8
  %17095 = zext i32 %17090 to i64
  %17096 = sext i32 %17093 to i64
  %17097 = shl nuw i64 %17092, 32
  %17098 = or i64 %17097, %17095
  %17099 = sdiv i64 %17098, %17096
  %17100 = shl i64 %17099, 32
  %17101 = ashr exact i64 %17100, 32
  %17102 = icmp eq i64 %17099, %17101
  br i1 %17102, label %17105, label %17103

; <label>:17103:                                  ; preds = %routine_idivl__esi.exit1674
  %17104 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17094, %struct.Memory* %17062)
  %.pre519 = load i64, i64* %3, align 8
  %.pre520 = load i32, i32* %108, align 4
  br label %routine_idivl__esi.exit1657

; <label>:17105:                                  ; preds = %routine_idivl__esi.exit1674
  %17106 = srem i64 %17098, %17096
  %17107 = and i64 %17099, 4294967295
  store i64 %17107, i64* %RAX.i1659, align 8
  %17108 = and i64 %17106, 4294967295
  store i64 %17108, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %17109 = trunc i64 %17106 to i32
  br label %routine_idivl__esi.exit1657

routine_idivl__esi.exit1657:                      ; preds = %17105, %17103
  %17110 = phi i32 [ %.pre520, %17103 ], [ %17109, %17105 ]
  %17111 = phi i64 [ %.pre519, %17103 ], [ %17094, %17105 ]
  %17112 = phi %struct.Memory* [ %17104, %17103 ], [ %17062, %17105 ]
  %17113 = load i64, i64* %RBP.i, align 8
  %17114 = add i64 %17113, -720
  %17115 = add i64 %17111, 6
  store i64 %17115, i64* %3, align 8
  %17116 = inttoptr i64 %17114 to i32*
  %17117 = load i32, i32* %17116, align 4
  %17118 = add i32 %17110, %17117
  %17119 = zext i32 %17118 to i64
  store i64 %17119, i64* %RDI.i6998, align 8
  %17120 = sext i32 %17118 to i64
  %17121 = shl nsw i64 %17120, 4
  store i64 %17121, i64* %R9.i1633, align 8
  %17122 = load i64, i64* %25, align 8
  %17123 = add i64 %17121, %17122
  store i64 %17123, i64* %25, align 8
  %17124 = icmp ult i64 %17123, %17122
  %17125 = icmp ult i64 %17123, %17121
  %17126 = or i1 %17124, %17125
  %17127 = zext i1 %17126 to i8
  store i8 %17127, i8* %17, align 1
  %17128 = trunc i64 %17123 to i32
  %17129 = and i32 %17128, 255
  %17130 = tail call i32 @llvm.ctpop.i32(i32 %17129)
  %17131 = trunc i32 %17130 to i8
  %17132 = and i8 %17131, 1
  %17133 = xor i8 %17132, 1
  store i8 %17133, i8* %18, align 1
  %17134 = xor i64 %17121, %17122
  %17135 = xor i64 %17134, %17123
  %17136 = lshr i64 %17135, 4
  %17137 = trunc i64 %17136 to i8
  %17138 = and i8 %17137, 1
  store i8 %17138, i8* %19, align 1
  %17139 = icmp eq i64 %17123, 0
  %17140 = zext i1 %17139 to i8
  store i8 %17140, i8* %20, align 1
  %17141 = lshr i64 %17123, 63
  %17142 = trunc i64 %17141 to i8
  store i8 %17142, i8* %21, align 1
  %17143 = lshr i64 %17122, 63
  %17144 = lshr i64 %17120, 59
  %17145 = and i64 %17144, 1
  %17146 = xor i64 %17141, %17143
  %17147 = xor i64 %17141, %17145
  %17148 = add nuw nsw i64 %17146, %17147
  %17149 = icmp eq i64 %17148, 2
  %17150 = zext i1 %17149 to i8
  store i8 %17150, i8* %22, align 1
  %17151 = load i64, i64* %RBP.i, align 8
  %17152 = add i64 %17151, -12
  %17153 = add i64 %17111, 21
  store i64 %17153, i64* %3, align 8
  %17154 = inttoptr i64 %17152 to i32*
  %17155 = load i32, i32* %17154, align 4
  %17156 = zext i32 %17155 to i64
  store i64 %17156, i64* %RAX.i1659, align 8
  %17157 = sext i32 %17155 to i64
  %17158 = lshr i64 %17157, 32
  store i64 %17158, i64* %103, align 8
  %17159 = load i32, i32* %ESI.i1759, align 4
  %17160 = add i64 %17111, 26
  store i64 %17160, i64* %3, align 8
  %17161 = sext i32 %17159 to i64
  %17162 = shl nuw i64 %17158, 32
  %17163 = or i64 %17162, %17156
  %17164 = sdiv i64 %17163, %17161
  %17165 = shl i64 %17164, 32
  %17166 = ashr exact i64 %17165, 32
  %17167 = icmp eq i64 %17164, %17166
  br i1 %17167, label %17170, label %17168

; <label>:17168:                                  ; preds = %routine_idivl__esi.exit1657
  %17169 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17160, %struct.Memory* %17112)
  %.pre521 = load i64, i64* %RAX.i1659, align 8
  %.pre522 = load i64, i64* %3, align 8
  %.pre523 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1630

; <label>:17170:                                  ; preds = %routine_idivl__esi.exit1657
  %17171 = srem i64 %17163, %17161
  %17172 = and i64 %17164, 4294967295
  store i64 %17172, i64* %RAX.i1659, align 8
  %17173 = and i64 %17171, 4294967295
  store i64 %17173, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit1630

routine_idivl__esi.exit1630:                      ; preds = %17170, %17168
  %17174 = phi i64 [ %.pre523, %17168 ], [ %17151, %17170 ]
  %17175 = phi i64 [ %.pre522, %17168 ], [ %17160, %17170 ]
  %17176 = phi i64 [ %.pre521, %17168 ], [ %17172, %17170 ]
  %17177 = phi %struct.Memory* [ %17169, %17168 ], [ %17112, %17170 ]
  %17178 = trunc i64 %17176 to i32
  %17179 = shl i32 %17178, 1
  %17180 = icmp slt i32 %17178, 0
  %17181 = icmp slt i32 %17179, 0
  %17182 = xor i1 %17180, %17181
  %17183 = zext i32 %17179 to i64
  store i64 %17183, i64* %RAX.i1659, align 8
  %.lobit253 = lshr i32 %17178, 31
  %17184 = trunc i32 %.lobit253 to i8
  store i8 %17184, i8* %17, align 1
  %17185 = and i32 %17179, 254
  %17186 = tail call i32 @llvm.ctpop.i32(i32 %17185)
  %17187 = trunc i32 %17186 to i8
  %17188 = and i8 %17187, 1
  %17189 = xor i8 %17188, 1
  store i8 %17189, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %17190 = icmp eq i32 %17179, 0
  %17191 = zext i1 %17190 to i8
  store i8 %17191, i8* %20, align 1
  %17192 = lshr i32 %17178, 30
  %17193 = trunc i32 %17192 to i8
  %17194 = and i8 %17193, 1
  store i8 %17194, i8* %21, align 1
  %17195 = zext i1 %17182 to i8
  store i8 %17195, i8* %22, align 1
  %17196 = add i64 %17174, -16
  %17197 = add i64 %17175, 5
  store i64 %17197, i64* %3, align 8
  %17198 = inttoptr i64 %17196 to i32*
  %17199 = load i32, i32* %17198, align 4
  %17200 = zext i32 %17199 to i64
  store i64 %17200, i64* %RDI.i6998, align 8
  %17201 = add i64 %17174, -724
  %17202 = add i64 %17175, 11
  store i64 %17202, i64* %3, align 8
  %17203 = inttoptr i64 %17201 to i32*
  store i32 %17179, i32* %17203, align 4
  %17204 = load i32, i32* %EDI.i1741, align 4
  %17205 = zext i32 %17204 to i64
  %17206 = load i64, i64* %3, align 8
  store i64 %17205, i64* %RAX.i1659, align 8
  %17207 = sext i32 %17204 to i64
  %17208 = lshr i64 %17207, 32
  store i64 %17208, i64* %103, align 8
  %17209 = load i32, i32* %ESI.i1759, align 4
  %17210 = add i64 %17206, 5
  store i64 %17210, i64* %3, align 8
  %17211 = sext i32 %17209 to i64
  %17212 = shl nuw i64 %17208, 32
  %17213 = or i64 %17212, %17205
  %17214 = sdiv i64 %17213, %17211
  %17215 = shl i64 %17214, 32
  %17216 = ashr exact i64 %17215, 32
  %17217 = icmp eq i64 %17214, %17216
  br i1 %17217, label %17220, label %17218

; <label>:17218:                                  ; preds = %routine_idivl__esi.exit1630
  %17219 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17210, %struct.Memory* %17177)
  %.pre524 = load i64, i64* %3, align 8
  %.pre525 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit1613

; <label>:17220:                                  ; preds = %routine_idivl__esi.exit1630
  %17221 = srem i64 %17213, %17211
  %17222 = and i64 %17214, 4294967295
  store i64 %17222, i64* %RAX.i1659, align 8
  %17223 = and i64 %17221, 4294967295
  store i64 %17223, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %17224 = trunc i64 %17214 to i32
  br label %routine_idivl__esi.exit1613

routine_idivl__esi.exit1613:                      ; preds = %17220, %17218
  %17225 = phi i32 [ %.pre525, %17218 ], [ %17224, %17220 ]
  %17226 = phi i64 [ %.pre524, %17218 ], [ %17210, %17220 ]
  %17227 = phi %struct.Memory* [ %17219, %17218 ], [ %17177, %17220 ]
  %17228 = load i64, i64* %RBP.i, align 8
  %17229 = add i64 %17228, -724
  %17230 = add i64 %17226, 6
  store i64 %17230, i64* %3, align 8
  %17231 = inttoptr i64 %17229 to i32*
  %17232 = load i32, i32* %17231, align 4
  %17233 = add i32 %17225, %17232
  %17234 = zext i32 %17233 to i64
  store i64 %17234, i64* %RDI.i6998, align 8
  %17235 = icmp ult i32 %17233, %17232
  %17236 = icmp ult i32 %17233, %17225
  %17237 = or i1 %17235, %17236
  %17238 = zext i1 %17237 to i8
  store i8 %17238, i8* %17, align 1
  %17239 = and i32 %17233, 255
  %17240 = tail call i32 @llvm.ctpop.i32(i32 %17239)
  %17241 = trunc i32 %17240 to i8
  %17242 = and i8 %17241, 1
  %17243 = xor i8 %17242, 1
  store i8 %17243, i8* %18, align 1
  %17244 = xor i32 %17225, %17232
  %17245 = xor i32 %17244, %17233
  %17246 = lshr i32 %17245, 4
  %17247 = trunc i32 %17246 to i8
  %17248 = and i8 %17247, 1
  store i8 %17248, i8* %19, align 1
  %17249 = icmp eq i32 %17233, 0
  %17250 = zext i1 %17249 to i8
  store i8 %17250, i8* %20, align 1
  %17251 = lshr i32 %17233, 31
  %17252 = trunc i32 %17251 to i8
  store i8 %17252, i8* %21, align 1
  %17253 = lshr i32 %17232, 31
  %17254 = lshr i32 %17225, 31
  %17255 = xor i32 %17251, %17253
  %17256 = xor i32 %17251, %17254
  %17257 = add nuw nsw i32 %17255, %17256
  %17258 = icmp eq i32 %17257, 2
  %17259 = zext i1 %17258 to i8
  store i8 %17259, i8* %22, align 1
  %17260 = sext i32 %17233 to i64
  store i64 %17260, i64* %R9.i1633, align 8
  %17261 = load i64, i64* %25, align 8
  %17262 = shl nsw i64 %17260, 2
  %17263 = add i64 %17261, %17262
  %17264 = add i64 %17226, 15
  store i64 %17264, i64* %3, align 8
  %17265 = inttoptr i64 %17263 to i32*
  %17266 = load i32, i32* %17265, align 4
  %17267 = zext i32 %17266 to i64
  store i64 %17267, i64* %RAX.i1659, align 8
  %17268 = add i64 %17228, -12
  %17269 = add i64 %17226, 18
  store i64 %17269, i64* %3, align 8
  %17270 = inttoptr i64 %17268 to i32*
  %17271 = load i32, i32* %17270, align 4
  %17272 = zext i32 %17271 to i64
  store i64 %17272, i64* %RDI.i6998, align 8
  %17273 = add i64 %17228, -728
  %17274 = add i64 %17226, 24
  store i64 %17274, i64* %3, align 8
  %17275 = inttoptr i64 %17273 to i32*
  store i32 %17266, i32* %17275, align 4
  %17276 = load i32, i32* %EDI.i1741, align 4
  %17277 = zext i32 %17276 to i64
  %17278 = load i64, i64* %3, align 8
  store i64 %17277, i64* %RAX.i1659, align 8
  %17279 = sext i32 %17276 to i64
  %17280 = lshr i64 %17279, 32
  store i64 %17280, i64* %103, align 8
  %17281 = load i32, i32* %ESI.i1759, align 4
  %17282 = add i64 %17278, 5
  store i64 %17282, i64* %3, align 8
  %17283 = sext i32 %17281 to i64
  %17284 = shl nuw i64 %17280, 32
  %17285 = or i64 %17284, %17277
  %17286 = sdiv i64 %17285, %17283
  %17287 = shl i64 %17286, 32
  %17288 = ashr exact i64 %17287, 32
  %17289 = icmp eq i64 %17286, %17288
  br i1 %17289, label %17292, label %17290

; <label>:17290:                                  ; preds = %routine_idivl__esi.exit1613
  %17291 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17282, %struct.Memory* %17227)
  %.pre526 = load i64, i64* %RDX.i1943, align 8
  %.pre527 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit1586

; <label>:17292:                                  ; preds = %routine_idivl__esi.exit1613
  %17293 = srem i64 %17285, %17283
  %17294 = and i64 %17286, 4294967295
  store i64 %17294, i64* %RAX.i1659, align 8
  %17295 = and i64 %17293, 4294967295
  store i64 %17295, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit1586

routine_idivl__esi.exit1586:                      ; preds = %17292, %17290
  %17296 = phi i64 [ %.pre527, %17290 ], [ %17282, %17292 ]
  %17297 = phi i64 [ %.pre526, %17290 ], [ %17295, %17292 ]
  %17298 = phi %struct.Memory* [ %17291, %17290 ], [ %17227, %17292 ]
  %17299 = trunc i64 %17297 to i32
  %17300 = shl i32 %17299, 1
  %17301 = icmp slt i32 %17299, 0
  %17302 = icmp slt i32 %17300, 0
  %17303 = xor i1 %17301, %17302
  %17304 = zext i32 %17300 to i64
  store i64 %17304, i64* %RDX.i1943, align 8
  %.lobit254 = lshr i32 %17299, 31
  %17305 = trunc i32 %.lobit254 to i8
  store i8 %17305, i8* %17, align 1
  %17306 = and i32 %17300, 254
  %17307 = tail call i32 @llvm.ctpop.i32(i32 %17306)
  %17308 = trunc i32 %17307 to i8
  %17309 = and i8 %17308, 1
  %17310 = xor i8 %17309, 1
  store i8 %17310, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %17311 = icmp eq i32 %17300, 0
  %17312 = zext i1 %17311 to i8
  store i8 %17312, i8* %20, align 1
  %17313 = lshr i32 %17299, 30
  %17314 = trunc i32 %17313 to i8
  %17315 = and i8 %17314, 1
  store i8 %17315, i8* %21, align 1
  %17316 = zext i1 %17303 to i8
  store i8 %17316, i8* %22, align 1
  %17317 = load i64, i64* %RBP.i, align 8
  %17318 = add i64 %17317, -16
  %17319 = add i64 %17296, 5
  store i64 %17319, i64* %3, align 8
  %17320 = inttoptr i64 %17318 to i32*
  %17321 = load i32, i32* %17320, align 4
  %17322 = zext i32 %17321 to i64
  store i64 %17322, i64* %RDI.i6998, align 8
  store i64 %17322, i64* %RAX.i1659, align 8
  %17323 = add i64 %17317, -732
  %17324 = add i64 %17296, 13
  store i64 %17324, i64* %3, align 8
  %17325 = inttoptr i64 %17323 to i32*
  store i32 %17300, i32* %17325, align 4
  %17326 = load i64, i64* %3, align 8
  %17327 = load i32, i32* %EAX.i2033, align 8
  %17328 = sext i32 %17327 to i64
  %17329 = lshr i64 %17328, 32
  store i64 %17329, i64* %103, align 8
  %17330 = load i32, i32* %ESI.i1759, align 4
  %17331 = add i64 %17326, 3
  store i64 %17331, i64* %3, align 8
  %17332 = zext i32 %17327 to i64
  %17333 = sext i32 %17330 to i64
  %17334 = shl nuw i64 %17329, 32
  %17335 = or i64 %17334, %17332
  %17336 = sdiv i64 %17335, %17333
  %17337 = shl i64 %17336, 32
  %17338 = ashr exact i64 %17337, 32
  %17339 = icmp eq i64 %17336, %17338
  br i1 %17339, label %17342, label %17340

; <label>:17340:                                  ; preds = %routine_idivl__esi.exit1586
  %17341 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17331, %struct.Memory* %17298)
  %.pre528 = load i64, i64* %3, align 8
  %.pre529 = load i32, i32* %108, align 4
  br label %routine_idivl__esi.exit1569

; <label>:17342:                                  ; preds = %routine_idivl__esi.exit1586
  %17343 = srem i64 %17335, %17333
  %17344 = and i64 %17336, 4294967295
  store i64 %17344, i64* %RAX.i1659, align 8
  %17345 = and i64 %17343, 4294967295
  store i64 %17345, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %17346 = trunc i64 %17343 to i32
  br label %routine_idivl__esi.exit1569

routine_idivl__esi.exit1569:                      ; preds = %17342, %17340
  %17347 = phi i32 [ %.pre529, %17340 ], [ %17346, %17342 ]
  %17348 = phi i64 [ %.pre528, %17340 ], [ %17331, %17342 ]
  %17349 = phi %struct.Memory* [ %17341, %17340 ], [ %17298, %17342 ]
  %17350 = load i64, i64* %RBP.i, align 8
  %17351 = add i64 %17350, -732
  %17352 = add i64 %17348, 6
  store i64 %17352, i64* %3, align 8
  %17353 = inttoptr i64 %17351 to i32*
  %17354 = load i32, i32* %17353, align 4
  %17355 = add i32 %17347, %17354
  %17356 = zext i32 %17355 to i64
  store i64 %17356, i64* %RDI.i6998, align 8
  %17357 = sext i32 %17355 to i64
  %17358 = shl nsw i64 %17357, 4
  store i64 %17358, i64* %25, align 8
  %17359 = load i64, i64* %RCX.i1588, align 8
  %17360 = add i64 %17358, %17359
  store i64 %17360, i64* %RCX.i1588, align 8
  %17361 = icmp ult i64 %17360, %17359
  %17362 = icmp ult i64 %17360, %17358
  %17363 = or i1 %17361, %17362
  %17364 = zext i1 %17363 to i8
  store i8 %17364, i8* %17, align 1
  %17365 = trunc i64 %17360 to i32
  %17366 = and i32 %17365, 255
  %17367 = tail call i32 @llvm.ctpop.i32(i32 %17366)
  %17368 = trunc i32 %17367 to i8
  %17369 = and i8 %17368, 1
  %17370 = xor i8 %17369, 1
  store i8 %17370, i8* %18, align 1
  %17371 = xor i64 %17358, %17359
  %17372 = xor i64 %17371, %17360
  %17373 = lshr i64 %17372, 4
  %17374 = trunc i64 %17373 to i8
  %17375 = and i8 %17374, 1
  store i8 %17375, i8* %19, align 1
  %17376 = icmp eq i64 %17360, 0
  %17377 = zext i1 %17376 to i8
  store i8 %17377, i8* %20, align 1
  %17378 = lshr i64 %17360, 63
  %17379 = trunc i64 %17378 to i8
  store i8 %17379, i8* %21, align 1
  %17380 = lshr i64 %17359, 63
  %17381 = lshr i64 %17357, 59
  %17382 = and i64 %17381, 1
  %17383 = xor i64 %17378, %17380
  %17384 = xor i64 %17378, %17382
  %17385 = add nuw nsw i64 %17383, %17384
  %17386 = icmp eq i64 %17385, 2
  %17387 = zext i1 %17386 to i8
  store i8 %17387, i8* %22, align 1
  %17388 = load i64, i64* %RBP.i, align 8
  %17389 = add i64 %17388, -12
  %17390 = add i64 %17348, 21
  store i64 %17390, i64* %3, align 8
  %17391 = inttoptr i64 %17389 to i32*
  %17392 = load i32, i32* %17391, align 4
  %17393 = zext i32 %17392 to i64
  store i64 %17393, i64* %RAX.i1659, align 8
  %17394 = sext i32 %17392 to i64
  %17395 = lshr i64 %17394, 32
  store i64 %17395, i64* %103, align 8
  %17396 = load i32, i32* %ESI.i1759, align 4
  %17397 = add i64 %17348, 26
  store i64 %17397, i64* %3, align 8
  %17398 = sext i32 %17396 to i64
  %17399 = shl nuw i64 %17395, 32
  %17400 = or i64 %17399, %17393
  %17401 = sdiv i64 %17400, %17398
  %17402 = shl i64 %17401, 32
  %17403 = ashr exact i64 %17402, 32
  %17404 = icmp eq i64 %17401, %17403
  br i1 %17404, label %17407, label %17405

; <label>:17405:                                  ; preds = %routine_idivl__esi.exit1569
  %17406 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17397, %struct.Memory* %17349)
  %.pre530 = load i64, i64* %RAX.i1659, align 8
  %.pre531 = load i64, i64* %3, align 8
  %.pre532 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit1543

; <label>:17407:                                  ; preds = %routine_idivl__esi.exit1569
  %17408 = srem i64 %17400, %17398
  %17409 = and i64 %17401, 4294967295
  store i64 %17409, i64* %RAX.i1659, align 8
  %17410 = and i64 %17408, 4294967295
  store i64 %17410, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  br label %routine_idivl__esi.exit1543

routine_idivl__esi.exit1543:                      ; preds = %17407, %17405
  %17411 = phi i64 [ %.pre532, %17405 ], [ %17388, %17407 ]
  %17412 = phi i64 [ %.pre531, %17405 ], [ %17397, %17407 ]
  %17413 = phi i64 [ %.pre530, %17405 ], [ %17409, %17407 ]
  %17414 = phi %struct.Memory* [ %17406, %17405 ], [ %17349, %17407 ]
  %17415 = trunc i64 %17413 to i32
  %17416 = shl i32 %17415, 1
  %17417 = icmp slt i32 %17415, 0
  %17418 = icmp slt i32 %17416, 0
  %17419 = xor i1 %17417, %17418
  %17420 = zext i32 %17416 to i64
  store i64 %17420, i64* %RAX.i1659, align 8
  %.lobit256 = lshr i32 %17415, 31
  %17421 = trunc i32 %.lobit256 to i8
  store i8 %17421, i8* %17, align 1
  %17422 = and i32 %17416, 254
  %17423 = tail call i32 @llvm.ctpop.i32(i32 %17422)
  %17424 = trunc i32 %17423 to i8
  %17425 = and i8 %17424, 1
  %17426 = xor i8 %17425, 1
  store i8 %17426, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %17427 = icmp eq i32 %17416, 0
  %17428 = zext i1 %17427 to i8
  store i8 %17428, i8* %20, align 1
  %17429 = lshr i32 %17415, 30
  %17430 = trunc i32 %17429 to i8
  %17431 = and i8 %17430, 1
  store i8 %17431, i8* %21, align 1
  %17432 = zext i1 %17419 to i8
  store i8 %17432, i8* %22, align 1
  %17433 = add i64 %17411, -16
  %17434 = add i64 %17412, 5
  store i64 %17434, i64* %3, align 8
  %17435 = inttoptr i64 %17433 to i32*
  %17436 = load i32, i32* %17435, align 4
  %17437 = zext i32 %17436 to i64
  store i64 %17437, i64* %RDI.i6998, align 8
  %17438 = add i64 %17411, -736
  %17439 = add i64 %17412, 11
  store i64 %17439, i64* %3, align 8
  %17440 = inttoptr i64 %17438 to i32*
  store i32 %17416, i32* %17440, align 4
  %17441 = load i32, i32* %EDI.i1741, align 4
  %17442 = zext i32 %17441 to i64
  %17443 = load i64, i64* %3, align 8
  store i64 %17442, i64* %RAX.i1659, align 8
  %17444 = sext i32 %17441 to i64
  %17445 = lshr i64 %17444, 32
  store i64 %17445, i64* %103, align 8
  %17446 = load i32, i32* %ESI.i1759, align 4
  %17447 = add i64 %17443, 5
  store i64 %17447, i64* %3, align 8
  %17448 = sext i32 %17446 to i64
  %17449 = shl nuw i64 %17445, 32
  %17450 = or i64 %17449, %17442
  %17451 = sdiv i64 %17450, %17448
  %17452 = shl i64 %17451, 32
  %17453 = ashr exact i64 %17452, 32
  %17454 = icmp eq i64 %17451, %17453
  br i1 %17454, label %17457, label %17455

; <label>:17455:                                  ; preds = %routine_idivl__esi.exit1543
  %17456 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %17447, %struct.Memory* %17414)
  %.pre533 = load i64, i64* %3, align 8
  %.pre534 = load i32, i32* %EAX.i2033, align 4
  br label %routine_idivl__esi.exit

; <label>:17457:                                  ; preds = %routine_idivl__esi.exit1543
  %17458 = srem i64 %17450, %17448
  %17459 = and i64 %17451, 4294967295
  store i64 %17459, i64* %RAX.i1659, align 8
  %17460 = and i64 %17458, 4294967295
  store i64 %17460, i64* %RDX.i1943, align 8
  store i8 0, i8* %17, align 1
  store i8 0, i8* %18, align 1
  store i8 0, i8* %19, align 1
  store i8 0, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %17461 = trunc i64 %17451 to i32
  br label %routine_idivl__esi.exit

routine_idivl__esi.exit:                          ; preds = %17457, %17455
  %17462 = phi i32 [ %.pre534, %17455 ], [ %17461, %17457 ]
  %17463 = phi i64 [ %.pre533, %17455 ], [ %17447, %17457 ]
  %17464 = phi %struct.Memory* [ %17456, %17455 ], [ %17414, %17457 ]
  %17465 = load i64, i64* %RBP.i, align 8
  %17466 = add i64 %17465, -736
  %17467 = add i64 %17463, 6
  store i64 %17467, i64* %3, align 8
  %17468 = inttoptr i64 %17466 to i32*
  %17469 = load i32, i32* %17468, align 4
  %17470 = add i32 %17462, %17469
  %17471 = zext i32 %17470 to i64
  store i64 %17471, i64* %RDI.i6998, align 8
  %17472 = icmp ult i32 %17470, %17469
  %17473 = icmp ult i32 %17470, %17462
  %17474 = or i1 %17472, %17473
  %17475 = zext i1 %17474 to i8
  store i8 %17475, i8* %17, align 1
  %17476 = and i32 %17470, 255
  %17477 = tail call i32 @llvm.ctpop.i32(i32 %17476)
  %17478 = trunc i32 %17477 to i8
  %17479 = and i8 %17478, 1
  %17480 = xor i8 %17479, 1
  store i8 %17480, i8* %18, align 1
  %17481 = xor i32 %17462, %17469
  %17482 = xor i32 %17481, %17470
  %17483 = lshr i32 %17482, 4
  %17484 = trunc i32 %17483 to i8
  %17485 = and i8 %17484, 1
  store i8 %17485, i8* %19, align 1
  %17486 = icmp eq i32 %17470, 0
  %17487 = zext i1 %17486 to i8
  store i8 %17487, i8* %20, align 1
  %17488 = lshr i32 %17470, 31
  %17489 = trunc i32 %17488 to i8
  store i8 %17489, i8* %21, align 1
  %17490 = lshr i32 %17469, 31
  %17491 = lshr i32 %17462, 31
  %17492 = xor i32 %17488, %17490
  %17493 = xor i32 %17488, %17491
  %17494 = add nuw nsw i32 %17492, %17493
  %17495 = icmp eq i32 %17494, 2
  %17496 = zext i1 %17495 to i8
  store i8 %17496, i8* %22, align 1
  %17497 = sext i32 %17470 to i64
  store i64 %17497, i64* %25, align 8
  %17498 = add i64 %17465, -728
  %17499 = add i64 %17463, 17
  store i64 %17499, i64* %3, align 8
  %17500 = inttoptr i64 %17498 to i32*
  %17501 = load i32, i32* %17500, align 4
  %17502 = zext i32 %17501 to i64
  store i64 %17502, i64* %RAX.i1659, align 8
  %17503 = load i64, i64* %RCX.i1588, align 8
  %17504 = shl nsw i64 %17497, 2
  %17505 = add i64 %17504, %17503
  %17506 = add i64 %17463, 21
  store i64 %17506, i64* %3, align 8
  %17507 = inttoptr i64 %17505 to i32*
  store i32 %17501, i32* %17507, align 4
  %17508 = load i64, i64* %RBP.i, align 8
  %17509 = add i64 %17508, -48
  %17510 = load i64, i64* %3, align 8
  %17511 = add i64 %17510, 7
  store i64 %17511, i64* %3, align 8
  %17512 = inttoptr i64 %17509 to i32*
  store i32 0, i32* %17512, align 4
  %.pre535 = load i64, i64* %3, align 8
  br label %block_.L_485ff9

block_.L_485ff9:                                  ; preds = %block_.L_48605f, %routine_idivl__esi.exit
  %17513 = phi i64 [ %17744, %block_.L_48605f ], [ %.pre535, %routine_idivl__esi.exit ]
  %17514 = load i64, i64* %RBP.i, align 8
  %17515 = add i64 %17514, -48
  %17516 = add i64 %17513, 4
  store i64 %17516, i64* %3, align 8
  %17517 = inttoptr i64 %17515 to i32*
  %17518 = load i32, i32* %17517, align 4
  %17519 = add i32 %17518, -4
  %17520 = icmp ult i32 %17518, 4
  %17521 = zext i1 %17520 to i8
  store i8 %17521, i8* %17, align 1
  %17522 = and i32 %17519, 255
  %17523 = tail call i32 @llvm.ctpop.i32(i32 %17522)
  %17524 = trunc i32 %17523 to i8
  %17525 = and i8 %17524, 1
  %17526 = xor i8 %17525, 1
  store i8 %17526, i8* %18, align 1
  %17527 = xor i32 %17519, %17518
  %17528 = lshr i32 %17527, 4
  %17529 = trunc i32 %17528 to i8
  %17530 = and i8 %17529, 1
  store i8 %17530, i8* %19, align 1
  %17531 = icmp eq i32 %17519, 0
  %17532 = zext i1 %17531 to i8
  store i8 %17532, i8* %20, align 1
  %17533 = lshr i32 %17519, 31
  %17534 = trunc i32 %17533 to i8
  store i8 %17534, i8* %21, align 1
  %17535 = lshr i32 %17518, 31
  %17536 = xor i32 %17533, %17535
  %17537 = add nuw nsw i32 %17536, %17535
  %17538 = icmp eq i32 %17537, 2
  %17539 = zext i1 %17538 to i8
  store i8 %17539, i8* %22, align 1
  %17540 = icmp ne i8 %17534, 0
  %17541 = xor i1 %17540, %17538
  %.v714 = select i1 %17541, i64 10, i64 121
  %17542 = add i64 %17513, %.v714
  store i64 %17542, i64* %3, align 8
  br i1 %17541, label %block_486003, label %block_.L_486072

block_486003:                                     ; preds = %block_.L_485ff9
  %17543 = add i64 %17514, -44
  %17544 = add i64 %17542, 7
  store i64 %17544, i64* %3, align 8
  %17545 = inttoptr i64 %17543 to i32*
  store i32 0, i32* %17545, align 4
  %.pre547 = load i64, i64* %3, align 8
  br label %block_.L_48600a

block_.L_48600a:                                  ; preds = %block_486014, %block_486003
  %17546 = phi i64 [ %17714, %block_486014 ], [ %.pre547, %block_486003 ]
  %17547 = load i64, i64* %RBP.i, align 8
  %17548 = add i64 %17547, -44
  %17549 = add i64 %17546, 4
  store i64 %17549, i64* %3, align 8
  %17550 = inttoptr i64 %17548 to i32*
  %17551 = load i32, i32* %17550, align 4
  %17552 = add i32 %17551, -4
  %17553 = icmp ult i32 %17551, 4
  %17554 = zext i1 %17553 to i8
  store i8 %17554, i8* %17, align 1
  %17555 = and i32 %17552, 255
  %17556 = tail call i32 @llvm.ctpop.i32(i32 %17555)
  %17557 = trunc i32 %17556 to i8
  %17558 = and i8 %17557, 1
  %17559 = xor i8 %17558, 1
  store i8 %17559, i8* %18, align 1
  %17560 = xor i32 %17552, %17551
  %17561 = lshr i32 %17560, 4
  %17562 = trunc i32 %17561 to i8
  %17563 = and i8 %17562, 1
  store i8 %17563, i8* %19, align 1
  %17564 = icmp eq i32 %17552, 0
  %17565 = zext i1 %17564 to i8
  store i8 %17565, i8* %20, align 1
  %17566 = lshr i32 %17552, 31
  %17567 = trunc i32 %17566 to i8
  store i8 %17567, i8* %21, align 1
  %17568 = lshr i32 %17551, 31
  %17569 = xor i32 %17566, %17568
  %17570 = add nuw nsw i32 %17569, %17568
  %17571 = icmp eq i32 %17570, 2
  %17572 = zext i1 %17571 to i8
  store i8 %17572, i8* %22, align 1
  %17573 = icmp ne i8 %17567, 0
  %17574 = xor i1 %17573, %17571
  %.v660 = select i1 %17574, i64 10, i64 85
  %17575 = add i64 %17546, %.v660
  store i64 %17575, i64* %3, align 8
  br i1 %17574, label %block_486014, label %block_.L_48605f

block_486014:                                     ; preds = %block_.L_48600a
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RAX.i1659, align 8
  %17576 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %17577 = add i64 %17576, 13112
  store i64 %17577, i64* %RCX.i1588, align 8
  %17578 = icmp ugt i64 %17576, -13113
  %17579 = zext i1 %17578 to i8
  store i8 %17579, i8* %17, align 1
  %17580 = trunc i64 %17577 to i32
  %17581 = and i32 %17580, 255
  %17582 = tail call i32 @llvm.ctpop.i32(i32 %17581)
  %17583 = trunc i32 %17582 to i8
  %17584 = and i8 %17583, 1
  %17585 = xor i8 %17584, 1
  store i8 %17585, i8* %18, align 1
  %17586 = xor i64 %17576, 16
  %17587 = xor i64 %17586, %17577
  %17588 = lshr i64 %17587, 4
  %17589 = trunc i64 %17588 to i8
  %17590 = and i8 %17589, 1
  store i8 %17590, i8* %19, align 1
  %17591 = icmp eq i64 %17577, 0
  %17592 = zext i1 %17591 to i8
  store i8 %17592, i8* %20, align 1
  %17593 = lshr i64 %17577, 63
  %17594 = trunc i64 %17593 to i8
  store i8 %17594, i8* %21, align 1
  %17595 = lshr i64 %17576, 63
  %17596 = xor i64 %17593, %17595
  %17597 = add nuw nsw i64 %17596, %17593
  %17598 = icmp eq i64 %17597, 2
  %17599 = zext i1 %17598 to i8
  store i8 %17599, i8* %22, align 1
  %17600 = add i64 %17575, 29
  store i64 %17600, i64* %3, align 8
  %17601 = load i32, i32* %17550, align 4
  %17602 = sext i32 %17601 to i64
  %17603 = shl nsw i64 %17602, 6
  store i64 %17603, i64* %RDX.i1943, align 8
  %17604 = add i64 %17603, %17577
  store i64 %17604, i64* %RCX.i1588, align 8
  %17605 = icmp ult i64 %17604, %17577
  %17606 = icmp ult i64 %17604, %17603
  %17607 = or i1 %17605, %17606
  %17608 = zext i1 %17607 to i8
  store i8 %17608, i8* %17, align 1
  %17609 = trunc i64 %17604 to i32
  %17610 = and i32 %17609, 255
  %17611 = tail call i32 @llvm.ctpop.i32(i32 %17610)
  %17612 = trunc i32 %17611 to i8
  %17613 = and i8 %17612, 1
  %17614 = xor i8 %17613, 1
  store i8 %17614, i8* %18, align 1
  %17615 = xor i64 %17577, %17604
  %17616 = lshr i64 %17615, 4
  %17617 = trunc i64 %17616 to i8
  %17618 = and i8 %17617, 1
  store i8 %17618, i8* %19, align 1
  %17619 = icmp eq i64 %17604, 0
  %17620 = zext i1 %17619 to i8
  store i8 %17620, i8* %20, align 1
  %17621 = lshr i64 %17604, 63
  %17622 = trunc i64 %17621 to i8
  store i8 %17622, i8* %21, align 1
  %17623 = lshr i64 %17602, 57
  %17624 = and i64 %17623, 1
  %17625 = xor i64 %17621, %17593
  %17626 = xor i64 %17621, %17624
  %17627 = add nuw nsw i64 %17625, %17626
  %17628 = icmp eq i64 %17627, 2
  %17629 = zext i1 %17628 to i8
  store i8 %17629, i8* %22, align 1
  %17630 = load i64, i64* %RBP.i, align 8
  %17631 = add i64 %17630, -48
  %17632 = add i64 %17575, 40
  store i64 %17632, i64* %3, align 8
  %17633 = inttoptr i64 %17631 to i32*
  %17634 = load i32, i32* %17633, align 4
  %17635 = sext i32 %17634 to i64
  store i64 %17635, i64* %RDX.i1943, align 8
  %17636 = shl nsw i64 %17635, 2
  %17637 = add i64 %17636, %17604
  %17638 = add i64 %17575, 43
  store i64 %17638, i64* %3, align 8
  %17639 = inttoptr i64 %17637 to i32*
  %17640 = load i32, i32* %17639, align 4
  %17641 = zext i32 %17640 to i64
  store i64 %17641, i64* %RSI.i2015, align 8
  %17642 = add i64 %17630, -44
  %17643 = add i64 %17575, 47
  store i64 %17643, i64* %3, align 8
  %17644 = inttoptr i64 %17642 to i32*
  %17645 = load i32, i32* %17644, align 4
  %17646 = sext i32 %17645 to i64
  %17647 = shl nsw i64 %17646, 6
  store i64 %17647, i64* %RCX.i1588, align 8
  %17648 = load i64, i64* %RAX.i1659, align 8
  %17649 = add i64 %17647, %17648
  store i64 %17649, i64* %RAX.i1659, align 8
  %17650 = icmp ult i64 %17649, %17648
  %17651 = icmp ult i64 %17649, %17647
  %17652 = or i1 %17650, %17651
  %17653 = zext i1 %17652 to i8
  store i8 %17653, i8* %17, align 1
  %17654 = trunc i64 %17649 to i32
  %17655 = and i32 %17654, 255
  %17656 = tail call i32 @llvm.ctpop.i32(i32 %17655)
  %17657 = trunc i32 %17656 to i8
  %17658 = and i8 %17657, 1
  %17659 = xor i8 %17658, 1
  store i8 %17659, i8* %18, align 1
  %17660 = xor i64 %17648, %17649
  %17661 = lshr i64 %17660, 4
  %17662 = trunc i64 %17661 to i8
  %17663 = and i8 %17662, 1
  store i8 %17663, i8* %19, align 1
  %17664 = icmp eq i64 %17649, 0
  %17665 = zext i1 %17664 to i8
  store i8 %17665, i8* %20, align 1
  %17666 = lshr i64 %17649, 63
  %17667 = trunc i64 %17666 to i8
  store i8 %17667, i8* %21, align 1
  %17668 = lshr i64 %17648, 63
  %17669 = lshr i64 %17646, 57
  %17670 = and i64 %17669, 1
  %17671 = xor i64 %17666, %17668
  %17672 = xor i64 %17666, %17670
  %17673 = add nuw nsw i64 %17671, %17672
  %17674 = icmp eq i64 %17673, 2
  %17675 = zext i1 %17674 to i8
  store i8 %17675, i8* %22, align 1
  %17676 = add i64 %17575, 58
  store i64 %17676, i64* %3, align 8
  %17677 = load i32, i32* %17633, align 4
  %17678 = sext i32 %17677 to i64
  store i64 %17678, i64* %RCX.i1588, align 8
  %17679 = shl nsw i64 %17678, 2
  %17680 = add i64 %17679, %17649
  %17681 = add i64 %17575, 61
  store i64 %17681, i64* %3, align 8
  %17682 = inttoptr i64 %17680 to i32*
  store i32 %17640, i32* %17682, align 4
  %17683 = load i64, i64* %RBP.i, align 8
  %17684 = add i64 %17683, -44
  %17685 = load i64, i64* %3, align 8
  %17686 = add i64 %17685, 3
  store i64 %17686, i64* %3, align 8
  %17687 = inttoptr i64 %17684 to i32*
  %17688 = load i32, i32* %17687, align 4
  %17689 = add i32 %17688, 1
  %17690 = zext i32 %17689 to i64
  store i64 %17690, i64* %RAX.i1659, align 8
  %17691 = icmp eq i32 %17688, -1
  %17692 = icmp eq i32 %17689, 0
  %17693 = or i1 %17691, %17692
  %17694 = zext i1 %17693 to i8
  store i8 %17694, i8* %17, align 1
  %17695 = and i32 %17689, 255
  %17696 = tail call i32 @llvm.ctpop.i32(i32 %17695)
  %17697 = trunc i32 %17696 to i8
  %17698 = and i8 %17697, 1
  %17699 = xor i8 %17698, 1
  store i8 %17699, i8* %18, align 1
  %17700 = xor i32 %17689, %17688
  %17701 = lshr i32 %17700, 4
  %17702 = trunc i32 %17701 to i8
  %17703 = and i8 %17702, 1
  store i8 %17703, i8* %19, align 1
  %17704 = zext i1 %17692 to i8
  store i8 %17704, i8* %20, align 1
  %17705 = lshr i32 %17689, 31
  %17706 = trunc i32 %17705 to i8
  store i8 %17706, i8* %21, align 1
  %17707 = lshr i32 %17688, 31
  %17708 = xor i32 %17705, %17707
  %17709 = add nuw nsw i32 %17708, %17705
  %17710 = icmp eq i32 %17709, 2
  %17711 = zext i1 %17710 to i8
  store i8 %17711, i8* %22, align 1
  %17712 = add i64 %17685, 9
  store i64 %17712, i64* %3, align 8
  store i32 %17689, i32* %17687, align 4
  %17713 = load i64, i64* %3, align 8
  %17714 = add i64 %17713, -80
  store i64 %17714, i64* %3, align 8
  br label %block_.L_48600a

block_.L_48605f:                                  ; preds = %block_.L_48600a
  %17715 = add i64 %17547, -48
  %17716 = add i64 %17575, 8
  store i64 %17716, i64* %3, align 8
  %17717 = inttoptr i64 %17715 to i32*
  %17718 = load i32, i32* %17717, align 4
  %17719 = add i32 %17718, 1
  %17720 = zext i32 %17719 to i64
  store i64 %17720, i64* %RAX.i1659, align 8
  %17721 = icmp eq i32 %17718, -1
  %17722 = icmp eq i32 %17719, 0
  %17723 = or i1 %17721, %17722
  %17724 = zext i1 %17723 to i8
  store i8 %17724, i8* %17, align 1
  %17725 = and i32 %17719, 255
  %17726 = tail call i32 @llvm.ctpop.i32(i32 %17725)
  %17727 = trunc i32 %17726 to i8
  %17728 = and i8 %17727, 1
  %17729 = xor i8 %17728, 1
  store i8 %17729, i8* %18, align 1
  %17730 = xor i32 %17719, %17718
  %17731 = lshr i32 %17730, 4
  %17732 = trunc i32 %17731 to i8
  %17733 = and i8 %17732, 1
  store i8 %17733, i8* %19, align 1
  %17734 = zext i1 %17722 to i8
  store i8 %17734, i8* %20, align 1
  %17735 = lshr i32 %17719, 31
  %17736 = trunc i32 %17735 to i8
  store i8 %17736, i8* %21, align 1
  %17737 = lshr i32 %17718, 31
  %17738 = xor i32 %17735, %17737
  %17739 = add nuw nsw i32 %17738, %17735
  %17740 = icmp eq i32 %17739, 2
  %17741 = zext i1 %17740 to i8
  store i8 %17741, i8* %22, align 1
  %17742 = add i64 %17575, 14
  store i64 %17742, i64* %3, align 8
  store i32 %17719, i32* %17717, align 4
  %17743 = load i64, i64* %3, align 8
  %17744 = add i64 %17743, -116
  store i64 %17744, i64* %3, align 8
  br label %block_.L_485ff9

block_.L_486072:                                  ; preds = %block_.L_485ff9
  %17745 = add i64 %17542, 7
  store i64 %17745, i64* %3, align 8
  store i32 0, i32* %17517, align 4
  %.pre536 = load i64, i64* %3, align 8
  br label %block_.L_486079

block_.L_486079:                                  ; preds = %block_.L_4866ee, %block_.L_486072
  %17746 = phi i64 [ %20818, %block_.L_4866ee ], [ %.pre536, %block_.L_486072 ]
  %17747 = load i64, i64* %RBP.i, align 8
  %17748 = add i64 %17747, -48
  %17749 = add i64 %17746, 4
  store i64 %17749, i64* %3, align 8
  %17750 = inttoptr i64 %17748 to i32*
  %17751 = load i32, i32* %17750, align 4
  %17752 = add i32 %17751, -4
  %17753 = icmp ult i32 %17751, 4
  %17754 = zext i1 %17753 to i8
  store i8 %17754, i8* %17, align 1
  %17755 = and i32 %17752, 255
  %17756 = tail call i32 @llvm.ctpop.i32(i32 %17755)
  %17757 = trunc i32 %17756 to i8
  %17758 = and i8 %17757, 1
  %17759 = xor i8 %17758, 1
  store i8 %17759, i8* %18, align 1
  %17760 = xor i32 %17752, %17751
  %17761 = lshr i32 %17760, 4
  %17762 = trunc i32 %17761 to i8
  %17763 = and i8 %17762, 1
  store i8 %17763, i8* %19, align 1
  %17764 = icmp eq i32 %17752, 0
  %17765 = zext i1 %17764 to i8
  store i8 %17765, i8* %20, align 1
  %17766 = lshr i32 %17752, 31
  %17767 = trunc i32 %17766 to i8
  store i8 %17767, i8* %21, align 1
  %17768 = lshr i32 %17751, 31
  %17769 = xor i32 %17766, %17768
  %17770 = add nuw nsw i32 %17769, %17768
  %17771 = icmp eq i32 %17770, 2
  %17772 = zext i1 %17771 to i8
  store i8 %17772, i8* %22, align 1
  %17773 = icmp ne i8 %17767, 0
  %17774 = xor i1 %17773, %17771
  %.v715 = select i1 %17774, i64 10, i64 1672
  %17775 = add i64 %17746, %.v715
  store i64 %17775, i64* %3, align 8
  br i1 %17774, label %block_486083, label %block_.L_486701

block_486083:                                     ; preds = %block_.L_486079
  %17776 = add i64 %17747, -44
  %17777 = add i64 %17775, 7
  store i64 %17777, i64* %3, align 8
  %17778 = inttoptr i64 %17776 to i32*
  store i32 0, i32* %17778, align 4
  %.pre537 = load i64, i64* %3, align 8
  br label %block_.L_48608a

block_.L_48608a:                                  ; preds = %block_.L_4866a4, %block_486083
  %17779 = phi i64 [ %20788, %block_.L_4866a4 ], [ %.pre537, %block_486083 ]
  %17780 = load i64, i64* %RBP.i, align 8
  %17781 = add i64 %17780, -44
  %17782 = add i64 %17779, 4
  store i64 %17782, i64* %3, align 8
  %17783 = inttoptr i64 %17781 to i32*
  %17784 = load i32, i32* %17783, align 4
  %17785 = add i32 %17784, -4
  %17786 = icmp ult i32 %17784, 4
  %17787 = zext i1 %17786 to i8
  store i8 %17787, i8* %17, align 1
  %17788 = and i32 %17785, 255
  %17789 = tail call i32 @llvm.ctpop.i32(i32 %17788)
  %17790 = trunc i32 %17789 to i8
  %17791 = and i8 %17790, 1
  %17792 = xor i8 %17791, 1
  store i8 %17792, i8* %18, align 1
  %17793 = xor i32 %17785, %17784
  %17794 = lshr i32 %17793, 4
  %17795 = trunc i32 %17794 to i8
  %17796 = and i8 %17795, 1
  store i8 %17796, i8* %19, align 1
  %17797 = icmp eq i32 %17785, 0
  %17798 = zext i1 %17797 to i8
  store i8 %17798, i8* %20, align 1
  %17799 = lshr i32 %17785, 31
  %17800 = trunc i32 %17799 to i8
  store i8 %17800, i8* %21, align 1
  %17801 = lshr i32 %17784, 31
  %17802 = xor i32 %17799, %17801
  %17803 = add nuw nsw i32 %17802, %17801
  %17804 = icmp eq i32 %17803, 2
  %17805 = zext i1 %17804 to i8
  store i8 %17805, i8* %22, align 1
  %17806 = icmp ne i8 %17800, 0
  %17807 = xor i1 %17806, %17804
  %.v659 = select i1 %17807, i64 10, i64 1636
  %17808 = add i64 %17779, %.v659
  store i64 %17808, i64* %3, align 8
  br i1 %17807, label %block_486094, label %block_.L_4866ee

block_486094:                                     ; preds = %block_.L_48608a
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX.i1588, align 8
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RDX.i1943, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RSI.i2015, align 8
  %17809 = add i64 %17808, 36
  store i64 %17809, i64* %3, align 8
  %17810 = load i32, i32* %17783, align 4
  %17811 = sext i32 %17810 to i64
  %17812 = shl nsw i64 %17811, 6
  store i64 %17812, i64* %RDI.i6998, align 8
  %17813 = add i64 %17812, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  store i64 %17813, i64* %RSI.i2015, align 8
  %17814 = icmp ult i64 %17813, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  %17815 = icmp ult i64 %17813, %17812
  %17816 = or i1 %17814, %17815
  %17817 = zext i1 %17816 to i8
  store i8 %17817, i8* %17, align 1
  %17818 = trunc i64 %17813 to i32
  %17819 = and i32 %17818, 248
  %17820 = tail call i32 @llvm.ctpop.i32(i32 %17819)
  %17821 = trunc i32 %17820 to i8
  %17822 = and i8 %17821, 1
  %17823 = xor i8 %17822, 1
  store i8 %17823, i8* %18, align 1
  %17824 = xor i64 %17813, ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64)
  %17825 = lshr i64 %17824, 4
  %17826 = trunc i64 %17825 to i8
  %17827 = and i8 %17826, 1
  store i8 %17827, i8* %19, align 1
  %17828 = icmp eq i64 %17813, 0
  %17829 = zext i1 %17828 to i8
  store i8 %17829, i8* %20, align 1
  %17830 = lshr i64 %17813, 63
  %17831 = trunc i64 %17830 to i8
  store i8 %17831, i8* %21, align 1
  %17832 = lshr i64 %17811, 57
  %17833 = and i64 %17832, 1
  %17834 = xor i64 %17830, lshr (i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64 63)
  %17835 = xor i64 %17830, %17833
  %17836 = add nuw nsw i64 %17834, %17835
  %17837 = icmp eq i64 %17836, 2
  %17838 = zext i1 %17837 to i8
  store i8 %17838, i8* %22, align 1
  %17839 = add i64 %17780, -48
  %17840 = add i64 %17808, 47
  store i64 %17840, i64* %3, align 8
  %17841 = inttoptr i64 %17839 to i32*
  %17842 = load i32, i32* %17841, align 4
  %17843 = sext i32 %17842 to i64
  store i64 %17843, i64* %RDI.i6998, align 8
  %17844 = shl nsw i64 %17843, 2
  %17845 = add i64 %17844, %17813
  %17846 = add i64 %17808, 51
  store i64 %17846, i64* %3, align 8
  %17847 = inttoptr i64 %17845 to i32*
  %17848 = load i32, i32* %17847, align 4
  %17849 = zext i32 %17848 to i64
  store i64 %17849, i64* %25, align 8
  %17850 = load i64, i64* %RBP.i, align 8
  %17851 = add i64 %17850, -44
  %17852 = add i64 %17808, 55
  store i64 %17852, i64* %3, align 8
  %17853 = inttoptr i64 %17851 to i32*
  %17854 = load i32, i32* %17853, align 4
  %17855 = sext i32 %17854 to i64
  %17856 = shl nsw i64 %17855, 6
  store i64 %17856, i64* %RSI.i2015, align 8
  %17857 = load i64, i64* %RDX.i1943, align 8
  %17858 = add i64 %17856, %17857
  store i64 %17858, i64* %RDI.i6998, align 8
  %17859 = icmp ult i64 %17858, %17857
  %17860 = icmp ult i64 %17858, %17856
  %17861 = or i1 %17859, %17860
  %17862 = zext i1 %17861 to i8
  store i8 %17862, i8* %17, align 1
  %17863 = trunc i64 %17858 to i32
  %17864 = and i32 %17863, 255
  %17865 = tail call i32 @llvm.ctpop.i32(i32 %17864)
  %17866 = trunc i32 %17865 to i8
  %17867 = and i8 %17866, 1
  %17868 = xor i8 %17867, 1
  store i8 %17868, i8* %18, align 1
  %17869 = xor i64 %17857, %17858
  %17870 = lshr i64 %17869, 4
  %17871 = trunc i64 %17870 to i8
  %17872 = and i8 %17871, 1
  store i8 %17872, i8* %19, align 1
  %17873 = icmp eq i64 %17858, 0
  %17874 = zext i1 %17873 to i8
  store i8 %17874, i8* %20, align 1
  %17875 = lshr i64 %17858, 63
  %17876 = trunc i64 %17875 to i8
  store i8 %17876, i8* %21, align 1
  %17877 = lshr i64 %17857, 63
  %17878 = lshr i64 %17855, 57
  %17879 = and i64 %17878, 1
  %17880 = xor i64 %17875, %17877
  %17881 = xor i64 %17875, %17879
  %17882 = add nuw nsw i64 %17880, %17881
  %17883 = icmp eq i64 %17882, 2
  %17884 = zext i1 %17883 to i8
  store i8 %17884, i8* %22, align 1
  %17885 = add i64 %17850, -48
  %17886 = add i64 %17808, 69
  store i64 %17886, i64* %3, align 8
  %17887 = inttoptr i64 %17885 to i32*
  %17888 = load i32, i32* %17887, align 4
  %17889 = sext i32 %17888 to i64
  store i64 %17889, i64* %RSI.i2015, align 8
  %17890 = shl nsw i64 %17889, 2
  %17891 = add i64 %17890, %17858
  %17892 = add i64 %17808, 73
  store i64 %17892, i64* %3, align 8
  %17893 = inttoptr i64 %17891 to i32*
  %17894 = load i32, i32* %17893, align 4
  %17895 = zext i32 %17894 to i64
  %17896 = shl nuw i64 %17895, 32
  %17897 = ashr i64 %17896, 33
  %17898 = and i64 %17897, 4294967295
  store i64 %17898, i64* %R9.i1633, align 8
  %17899 = load i32, i32* %R8D.i1615, align 4
  %17900 = trunc i64 %17897 to i32
  %17901 = sub i32 %17899, %17900
  %17902 = zext i32 %17901 to i64
  store i64 %17902, i64* %25, align 8
  %17903 = icmp ult i32 %17899, %17900
  %17904 = zext i1 %17903 to i8
  store i8 %17904, i8* %17, align 1
  %17905 = and i32 %17901, 255
  %17906 = tail call i32 @llvm.ctpop.i32(i32 %17905)
  %17907 = trunc i32 %17906 to i8
  %17908 = and i8 %17907, 1
  %17909 = xor i8 %17908, 1
  store i8 %17909, i8* %18, align 1
  %17910 = xor i32 %17900, %17899
  %17911 = xor i32 %17910, %17901
  %17912 = lshr i32 %17911, 4
  %17913 = trunc i32 %17912 to i8
  %17914 = and i8 %17913, 1
  store i8 %17914, i8* %19, align 1
  %17915 = icmp eq i32 %17901, 0
  %17916 = zext i1 %17915 to i8
  store i8 %17916, i8* %20, align 1
  %17917 = lshr i32 %17901, 31
  %17918 = trunc i32 %17917 to i8
  store i8 %17918, i8* %21, align 1
  %17919 = lshr i32 %17899, 31
  %17920 = lshr i64 %17897, 31
  %17921 = trunc i64 %17920 to i32
  %17922 = and i32 %17921, 1
  %17923 = xor i32 %17922, %17919
  %17924 = xor i32 %17917, %17919
  %17925 = add nuw nsw i32 %17924, %17923
  %17926 = icmp eq i32 %17925, 2
  %17927 = zext i1 %17926 to i8
  store i8 %17927, i8* %22, align 1
  %17928 = load i64, i64* %RBP.i, align 8
  %17929 = add i64 %17928, -360
  %17930 = add i64 %17808, 86
  store i64 %17930, i64* %3, align 8
  %17931 = inttoptr i64 %17929 to i32*
  store i32 %17901, i32* %17931, align 4
  %17932 = load i64, i64* %RBP.i, align 8
  %17933 = add i64 %17932, -44
  %17934 = load i64, i64* %3, align 8
  %17935 = add i64 %17934, 4
  store i64 %17935, i64* %3, align 8
  %17936 = inttoptr i64 %17933 to i32*
  %17937 = load i32, i32* %17936, align 4
  %17938 = sext i32 %17937 to i64
  %17939 = shl nsw i64 %17938, 6
  store i64 %17939, i64* %RSI.i2015, align 8
  %17940 = load i64, i64* %RDX.i1943, align 8
  %17941 = add i64 %17939, %17940
  store i64 %17941, i64* %RDX.i1943, align 8
  %17942 = icmp ult i64 %17941, %17940
  %17943 = icmp ult i64 %17941, %17939
  %17944 = or i1 %17942, %17943
  %17945 = zext i1 %17944 to i8
  store i8 %17945, i8* %17, align 1
  %17946 = trunc i64 %17941 to i32
  %17947 = and i32 %17946, 255
  %17948 = tail call i32 @llvm.ctpop.i32(i32 %17947)
  %17949 = trunc i32 %17948 to i8
  %17950 = and i8 %17949, 1
  %17951 = xor i8 %17950, 1
  store i8 %17951, i8* %18, align 1
  %17952 = xor i64 %17940, %17941
  %17953 = lshr i64 %17952, 4
  %17954 = trunc i64 %17953 to i8
  %17955 = and i8 %17954, 1
  store i8 %17955, i8* %19, align 1
  %17956 = icmp eq i64 %17941, 0
  %17957 = zext i1 %17956 to i8
  store i8 %17957, i8* %20, align 1
  %17958 = lshr i64 %17941, 63
  %17959 = trunc i64 %17958 to i8
  store i8 %17959, i8* %21, align 1
  %17960 = lshr i64 %17940, 63
  %17961 = lshr i64 %17938, 57
  %17962 = and i64 %17961, 1
  %17963 = xor i64 %17958, %17960
  %17964 = xor i64 %17958, %17962
  %17965 = add nuw nsw i64 %17963, %17964
  %17966 = icmp eq i64 %17965, 2
  %17967 = zext i1 %17966 to i8
  store i8 %17967, i8* %22, align 1
  %17968 = add i64 %17932, -48
  %17969 = add i64 %17934, 15
  store i64 %17969, i64* %3, align 8
  %17970 = inttoptr i64 %17968 to i32*
  %17971 = load i32, i32* %17970, align 4
  %17972 = sext i32 %17971 to i64
  store i64 %17972, i64* %RSI.i2015, align 8
  %17973 = shl nsw i64 %17972, 2
  %17974 = add i64 %17973, %17941
  %17975 = add i64 %17934, 19
  store i64 %17975, i64* %3, align 8
  %17976 = inttoptr i64 %17974 to i32*
  %17977 = load i32, i32* %17976, align 4
  %17978 = zext i32 %17977 to i64
  store i64 %17978, i64* %25, align 8
  %17979 = add i64 %17932, -360
  %17980 = add i64 %17934, 26
  store i64 %17980, i64* %3, align 8
  %17981 = inttoptr i64 %17979 to i32*
  %17982 = load i32, i32* %17981, align 4
  %17983 = add i32 %17982, %17977
  %17984 = zext i32 %17983 to i64
  store i64 %17984, i64* %25, align 8
  %17985 = icmp ult i32 %17983, %17977
  %17986 = icmp ult i32 %17983, %17982
  %17987 = or i1 %17985, %17986
  %17988 = zext i1 %17987 to i8
  store i8 %17988, i8* %17, align 1
  %17989 = and i32 %17983, 255
  %17990 = tail call i32 @llvm.ctpop.i32(i32 %17989)
  %17991 = trunc i32 %17990 to i8
  %17992 = and i8 %17991, 1
  %17993 = xor i8 %17992, 1
  store i8 %17993, i8* %18, align 1
  %17994 = xor i32 %17982, %17977
  %17995 = xor i32 %17994, %17983
  %17996 = lshr i32 %17995, 4
  %17997 = trunc i32 %17996 to i8
  %17998 = and i8 %17997, 1
  store i8 %17998, i8* %19, align 1
  %17999 = icmp eq i32 %17983, 0
  %18000 = zext i1 %17999 to i8
  store i8 %18000, i8* %20, align 1
  %18001 = lshr i32 %17983, 31
  %18002 = trunc i32 %18001 to i8
  store i8 %18002, i8* %21, align 1
  %18003 = lshr i32 %17977, 31
  %18004 = lshr i32 %17982, 31
  %18005 = xor i32 %18001, %18003
  %18006 = xor i32 %18001, %18004
  %18007 = add nuw nsw i32 %18005, %18006
  %18008 = icmp eq i32 %18007, 2
  %18009 = zext i1 %18008 to i8
  store i8 %18009, i8* %22, align 1
  %18010 = load i64, i64* %RBP.i, align 8
  %18011 = add i64 %18010, -344
  %18012 = add i64 %17934, 33
  store i64 %18012, i64* %3, align 8
  %18013 = inttoptr i64 %18011 to i32*
  store i32 %17983, i32* %18013, align 4
  %18014 = load i64, i64* %RBP.i, align 8
  %18015 = add i64 %18014, -360
  %18016 = load i64, i64* %3, align 8
  %18017 = add i64 %18016, 7
  store i64 %18017, i64* %3, align 8
  %18018 = inttoptr i64 %18015 to i32*
  %18019 = load i32, i32* %18018, align 4
  %18020 = zext i32 %18019 to i64
  store i64 %18020, i64* %25, align 8
  %18021 = add i64 %18014, -44
  %18022 = add i64 %18016, 11
  store i64 %18022, i64* %3, align 8
  %18023 = inttoptr i64 %18021 to i32*
  %18024 = load i32, i32* %18023, align 4
  %18025 = sext i32 %18024 to i64
  %18026 = shl nsw i64 %18025, 6
  store i64 %18026, i64* %RDX.i1943, align 8
  %18027 = load i64, i64* %RCX.i1588, align 8
  %18028 = add i64 %18026, %18027
  store i64 %18028, i64* %RSI.i2015, align 8
  %18029 = icmp ult i64 %18028, %18027
  %18030 = icmp ult i64 %18028, %18026
  %18031 = or i1 %18029, %18030
  %18032 = zext i1 %18031 to i8
  store i8 %18032, i8* %17, align 1
  %18033 = trunc i64 %18028 to i32
  %18034 = and i32 %18033, 255
  %18035 = tail call i32 @llvm.ctpop.i32(i32 %18034)
  %18036 = trunc i32 %18035 to i8
  %18037 = and i8 %18036, 1
  %18038 = xor i8 %18037, 1
  store i8 %18038, i8* %18, align 1
  %18039 = xor i64 %18027, %18028
  %18040 = lshr i64 %18039, 4
  %18041 = trunc i64 %18040 to i8
  %18042 = and i8 %18041, 1
  store i8 %18042, i8* %19, align 1
  %18043 = icmp eq i64 %18028, 0
  %18044 = zext i1 %18043 to i8
  store i8 %18044, i8* %20, align 1
  %18045 = lshr i64 %18028, 63
  %18046 = trunc i64 %18045 to i8
  store i8 %18046, i8* %21, align 1
  %18047 = lshr i64 %18027, 63
  %18048 = lshr i64 %18025, 57
  %18049 = and i64 %18048, 1
  %18050 = xor i64 %18045, %18047
  %18051 = xor i64 %18045, %18049
  %18052 = add nuw nsw i64 %18050, %18051
  %18053 = icmp eq i64 %18052, 2
  %18054 = zext i1 %18053 to i8
  store i8 %18054, i8* %22, align 1
  %18055 = add i64 %18014, -48
  %18056 = add i64 %18016, 25
  store i64 %18056, i64* %3, align 8
  %18057 = inttoptr i64 %18055 to i32*
  %18058 = load i32, i32* %18057, align 4
  %18059 = sext i32 %18058 to i64
  store i64 %18059, i64* %RDX.i1943, align 8
  %18060 = shl nsw i64 %18059, 2
  %18061 = add i64 %18060, %18028
  %18062 = add i64 %18016, 29
  store i64 %18062, i64* %3, align 8
  %18063 = inttoptr i64 %18061 to i32*
  %18064 = load i32, i32* %18063, align 4
  %18065 = zext i32 %18064 to i64
  %18066 = shl nuw i64 %18065, 32
  %18067 = ashr i64 %18066, 33
  %18068 = and i64 %18067, 4294967295
  store i64 %18068, i64* %R9.i1633, align 8
  %18069 = load i32, i32* %R8D.i1615, align 4
  %18070 = trunc i64 %18067 to i32
  %18071 = sub i32 %18069, %18070
  %18072 = zext i32 %18071 to i64
  store i64 %18072, i64* %25, align 8
  %18073 = icmp ult i32 %18069, %18070
  %18074 = zext i1 %18073 to i8
  store i8 %18074, i8* %17, align 1
  %18075 = and i32 %18071, 255
  %18076 = tail call i32 @llvm.ctpop.i32(i32 %18075)
  %18077 = trunc i32 %18076 to i8
  %18078 = and i8 %18077, 1
  %18079 = xor i8 %18078, 1
  store i8 %18079, i8* %18, align 1
  %18080 = xor i32 %18070, %18069
  %18081 = xor i32 %18080, %18071
  %18082 = lshr i32 %18081, 4
  %18083 = trunc i32 %18082 to i8
  %18084 = and i8 %18083, 1
  store i8 %18084, i8* %19, align 1
  %18085 = icmp eq i32 %18071, 0
  %18086 = zext i1 %18085 to i8
  store i8 %18086, i8* %20, align 1
  %18087 = lshr i32 %18071, 31
  %18088 = trunc i32 %18087 to i8
  store i8 %18088, i8* %21, align 1
  %18089 = lshr i32 %18069, 31
  %18090 = lshr i64 %18067, 31
  %18091 = trunc i64 %18090 to i32
  %18092 = and i32 %18091, 1
  %18093 = xor i32 %18092, %18089
  %18094 = xor i32 %18087, %18089
  %18095 = add nuw nsw i32 %18094, %18093
  %18096 = icmp eq i32 %18095, 2
  %18097 = zext i1 %18096 to i8
  store i8 %18097, i8* %22, align 1
  %18098 = load i64, i64* %RBP.i, align 8
  %18099 = add i64 %18098, -348
  %18100 = add i64 %18016, 42
  store i64 %18100, i64* %3, align 8
  %18101 = inttoptr i64 %18099 to i32*
  store i32 %18071, i32* %18101, align 4
  %18102 = load i64, i64* %RBP.i, align 8
  %18103 = add i64 %18102, -348
  %18104 = load i64, i64* %3, align 8
  %18105 = add i64 %18104, 7
  store i64 %18105, i64* %3, align 8
  %18106 = inttoptr i64 %18103 to i32*
  %18107 = load i32, i32* %18106, align 4
  %18108 = zext i32 %18107 to i64
  store i64 %18108, i64* %25, align 8
  %18109 = add i64 %18102, -44
  %18110 = add i64 %18104, 11
  store i64 %18110, i64* %3, align 8
  %18111 = inttoptr i64 %18109 to i32*
  %18112 = load i32, i32* %18111, align 4
  %18113 = sext i32 %18112 to i64
  %18114 = shl nsw i64 %18113, 6
  store i64 %18114, i64* %RDX.i1943, align 8
  %18115 = load i64, i64* %RCX.i1588, align 8
  %18116 = add i64 %18114, %18115
  store i64 %18116, i64* %RCX.i1588, align 8
  %18117 = icmp ult i64 %18116, %18115
  %18118 = icmp ult i64 %18116, %18114
  %18119 = or i1 %18117, %18118
  %18120 = zext i1 %18119 to i8
  store i8 %18120, i8* %17, align 1
  %18121 = trunc i64 %18116 to i32
  %18122 = and i32 %18121, 255
  %18123 = tail call i32 @llvm.ctpop.i32(i32 %18122)
  %18124 = trunc i32 %18123 to i8
  %18125 = and i8 %18124, 1
  %18126 = xor i8 %18125, 1
  store i8 %18126, i8* %18, align 1
  %18127 = xor i64 %18115, %18116
  %18128 = lshr i64 %18127, 4
  %18129 = trunc i64 %18128 to i8
  %18130 = and i8 %18129, 1
  store i8 %18130, i8* %19, align 1
  %18131 = icmp eq i64 %18116, 0
  %18132 = zext i1 %18131 to i8
  store i8 %18132, i8* %20, align 1
  %18133 = lshr i64 %18116, 63
  %18134 = trunc i64 %18133 to i8
  store i8 %18134, i8* %21, align 1
  %18135 = lshr i64 %18115, 63
  %18136 = lshr i64 %18113, 57
  %18137 = and i64 %18136, 1
  %18138 = xor i64 %18133, %18135
  %18139 = xor i64 %18133, %18137
  %18140 = add nuw nsw i64 %18138, %18139
  %18141 = icmp eq i64 %18140, 2
  %18142 = zext i1 %18141 to i8
  store i8 %18142, i8* %22, align 1
  %18143 = add i64 %18102, -48
  %18144 = add i64 %18104, 22
  store i64 %18144, i64* %3, align 8
  %18145 = inttoptr i64 %18143 to i32*
  %18146 = load i32, i32* %18145, align 4
  %18147 = sext i32 %18146 to i64
  store i64 %18147, i64* %RDX.i1943, align 8
  %18148 = shl nsw i64 %18147, 2
  %18149 = add i64 %18116, %18148
  %18150 = add i64 %18104, 26
  store i64 %18150, i64* %3, align 8
  %18151 = inttoptr i64 %18149 to i32*
  %18152 = load i32, i32* %18151, align 4
  %18153 = add i32 %18152, %18107
  %18154 = zext i32 %18153 to i64
  store i64 %18154, i64* %25, align 8
  %18155 = icmp ult i32 %18153, %18107
  %18156 = icmp ult i32 %18153, %18152
  %18157 = or i1 %18155, %18156
  %18158 = zext i1 %18157 to i8
  store i8 %18158, i8* %17, align 1
  %18159 = and i32 %18153, 255
  %18160 = tail call i32 @llvm.ctpop.i32(i32 %18159)
  %18161 = trunc i32 %18160 to i8
  %18162 = and i8 %18161, 1
  %18163 = xor i8 %18162, 1
  store i8 %18163, i8* %18, align 1
  %18164 = xor i32 %18152, %18107
  %18165 = xor i32 %18164, %18153
  %18166 = lshr i32 %18165, 4
  %18167 = trunc i32 %18166 to i8
  %18168 = and i8 %18167, 1
  store i8 %18168, i8* %19, align 1
  %18169 = icmp eq i32 %18153, 0
  %18170 = zext i1 %18169 to i8
  store i8 %18170, i8* %20, align 1
  %18171 = lshr i32 %18153, 31
  %18172 = trunc i32 %18171 to i8
  store i8 %18172, i8* %21, align 1
  %18173 = lshr i32 %18107, 31
  %18174 = lshr i32 %18152, 31
  %18175 = xor i32 %18171, %18173
  %18176 = xor i32 %18171, %18174
  %18177 = add nuw nsw i32 %18175, %18176
  %18178 = icmp eq i32 %18177, 2
  %18179 = zext i1 %18178 to i8
  store i8 %18179, i8* %22, align 1
  %18180 = load i64, i64* %RBP.i, align 8
  %18181 = add i64 %18180, -340
  %18182 = add i64 %18104, 33
  store i64 %18182, i64* %3, align 8
  %18183 = inttoptr i64 %18181 to i32*
  store i32 %18153, i32* %18183, align 4
  %18184 = load i64, i64* %3, align 8
  %18185 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %18185, i64* %RCX.i1588, align 8
  %18186 = add i64 %18185, 72688
  %18187 = add i64 %18184, 15
  store i64 %18187, i64* %3, align 8
  %18188 = inttoptr i64 %18186 to i32*
  %18189 = load i32, i32* %18188, align 4
  %18190 = zext i32 %18189 to i64
  store i64 %18190, i64* %25, align 8
  %18191 = load i64, i64* %RBP.i, align 8
  %18192 = add i64 %18191, -348
  %18193 = add i64 %18184, 22
  store i64 %18193, i64* %3, align 8
  %18194 = inttoptr i64 %18192 to i32*
  %18195 = load i32, i32* %18194, align 4
  %18196 = zext i32 %18195 to i64
  store i64 %18196, i64* %R9.i1633, align 8
  %18197 = add i64 %18185, 8504
  store i64 %18197, i64* %RCX.i1588, align 8
  %18198 = icmp ugt i64 %18185, -8505
  %18199 = zext i1 %18198 to i8
  store i8 %18199, i8* %17, align 1
  %18200 = trunc i64 %18197 to i32
  %18201 = and i32 %18200, 255
  %18202 = tail call i32 @llvm.ctpop.i32(i32 %18201)
  %18203 = trunc i32 %18202 to i8
  %18204 = and i8 %18203, 1
  %18205 = xor i8 %18204, 1
  store i8 %18205, i8* %18, align 1
  %18206 = xor i64 %18185, 16
  %18207 = xor i64 %18206, %18197
  %18208 = lshr i64 %18207, 4
  %18209 = trunc i64 %18208 to i8
  %18210 = and i8 %18209, 1
  store i8 %18210, i8* %19, align 1
  %18211 = icmp eq i64 %18197, 0
  %18212 = zext i1 %18211 to i8
  store i8 %18212, i8* %20, align 1
  %18213 = lshr i64 %18197, 63
  %18214 = trunc i64 %18213 to i8
  store i8 %18214, i8* %21, align 1
  %18215 = lshr i64 %18185, 63
  %18216 = xor i64 %18213, %18215
  %18217 = add nuw nsw i64 %18216, %18213
  %18218 = icmp eq i64 %18217, 2
  %18219 = zext i1 %18218 to i8
  store i8 %18219, i8* %22, align 1
  %18220 = add i64 %18191, -364
  %18221 = add i64 %18184, 44
  store i64 %18221, i64* %3, align 8
  %18222 = inttoptr i64 %18220 to i32*
  %18223 = load i32, i32* %18222, align 4
  %18224 = sext i32 %18223 to i64
  %18225 = shl nsw i64 %18224, 9
  store i64 %18225, i64* %RDX.i1943, align 8
  %18226 = add i64 %18225, %18197
  store i64 %18226, i64* %RCX.i1588, align 8
  %18227 = icmp ult i64 %18226, %18197
  %18228 = icmp ult i64 %18226, %18225
  %18229 = or i1 %18227, %18228
  %18230 = zext i1 %18229 to i8
  store i8 %18230, i8* %17, align 1
  %18231 = trunc i64 %18226 to i32
  %18232 = and i32 %18231, 255
  %18233 = tail call i32 @llvm.ctpop.i32(i32 %18232)
  %18234 = trunc i32 %18233 to i8
  %18235 = and i8 %18234, 1
  %18236 = xor i8 %18235, 1
  store i8 %18236, i8* %18, align 1
  %18237 = xor i64 %18197, %18226
  %18238 = lshr i64 %18237, 4
  %18239 = trunc i64 %18238 to i8
  %18240 = and i8 %18239, 1
  store i8 %18240, i8* %19, align 1
  %18241 = icmp eq i64 %18226, 0
  %18242 = zext i1 %18241 to i8
  store i8 %18242, i8* %20, align 1
  %18243 = lshr i64 %18226, 63
  %18244 = trunc i64 %18243 to i8
  store i8 %18244, i8* %21, align 1
  %18245 = lshr i64 %18224, 54
  %18246 = and i64 %18245, 1
  %18247 = xor i64 %18243, %18213
  %18248 = xor i64 %18243, %18246
  %18249 = add nuw nsw i64 %18247, %18248
  %18250 = icmp eq i64 %18249, 2
  %18251 = zext i1 %18250 to i8
  store i8 %18251, i8* %22, align 1
  %18252 = load i64, i64* %RBP.i, align 8
  %18253 = add i64 %18252, -220
  %18254 = add i64 %18184, 58
  store i64 %18254, i64* %3, align 8
  %18255 = inttoptr i64 %18253 to i32*
  %18256 = load i32, i32* %18255, align 4
  %18257 = zext i32 %18256 to i64
  store i64 %18257, i64* %50, align 8
  %18258 = add i64 %18252, -44
  %18259 = add i64 %18184, 62
  store i64 %18259, i64* %3, align 8
  %18260 = inttoptr i64 %18258 to i32*
  %18261 = load i32, i32* %18260, align 4
  %18262 = add i32 %18261, %18256
  %18263 = zext i32 %18262 to i64
  store i64 %18263, i64* %50, align 8
  %18264 = sext i32 %18262 to i64
  %18265 = shl nsw i64 %18264, 5
  store i64 %18265, i64* %RDX.i1943, align 8
  %18266 = load i64, i64* %RCX.i1588, align 8
  %18267 = add i64 %18265, %18266
  store i64 %18267, i64* %RCX.i1588, align 8
  %18268 = icmp ult i64 %18267, %18266
  %18269 = icmp ult i64 %18267, %18265
  %18270 = or i1 %18268, %18269
  %18271 = zext i1 %18270 to i8
  store i8 %18271, i8* %17, align 1
  %18272 = trunc i64 %18267 to i32
  %18273 = and i32 %18272, 255
  %18274 = tail call i32 @llvm.ctpop.i32(i32 %18273)
  %18275 = trunc i32 %18274 to i8
  %18276 = and i8 %18275, 1
  %18277 = xor i8 %18276, 1
  store i8 %18277, i8* %18, align 1
  %18278 = xor i64 %18266, %18267
  %18279 = lshr i64 %18278, 4
  %18280 = trunc i64 %18279 to i8
  %18281 = and i8 %18280, 1
  store i8 %18281, i8* %19, align 1
  %18282 = icmp eq i64 %18267, 0
  %18283 = zext i1 %18282 to i8
  store i8 %18283, i8* %20, align 1
  %18284 = lshr i64 %18267, 63
  %18285 = trunc i64 %18284 to i8
  store i8 %18285, i8* %21, align 1
  %18286 = lshr i64 %18266, 63
  %18287 = lshr i64 %18264, 58
  %18288 = and i64 %18287, 1
  %18289 = xor i64 %18284, %18286
  %18290 = xor i64 %18284, %18288
  %18291 = add nuw nsw i64 %18289, %18290
  %18292 = icmp eq i64 %18291, 2
  %18293 = zext i1 %18292 to i8
  store i8 %18293, i8* %22, align 1
  %18294 = load i64, i64* %RBP.i, align 8
  %18295 = add i64 %18294, -224
  %18296 = add i64 %18184, 79
  store i64 %18296, i64* %3, align 8
  %18297 = inttoptr i64 %18295 to i32*
  %18298 = load i32, i32* %18297, align 4
  %18299 = zext i32 %18298 to i64
  store i64 %18299, i64* %50, align 8
  %18300 = add i64 %18294, -48
  %18301 = add i64 %18184, 83
  store i64 %18301, i64* %3, align 8
  %18302 = inttoptr i64 %18300 to i32*
  %18303 = load i32, i32* %18302, align 4
  %18304 = add i32 %18303, %18298
  %18305 = zext i32 %18304 to i64
  store i64 %18305, i64* %50, align 8
  %18306 = icmp ult i32 %18304, %18298
  %18307 = icmp ult i32 %18304, %18303
  %18308 = or i1 %18306, %18307
  %18309 = zext i1 %18308 to i8
  store i8 %18309, i8* %17, align 1
  %18310 = and i32 %18304, 255
  %18311 = tail call i32 @llvm.ctpop.i32(i32 %18310)
  %18312 = trunc i32 %18311 to i8
  %18313 = and i8 %18312, 1
  %18314 = xor i8 %18313, 1
  store i8 %18314, i8* %18, align 1
  %18315 = xor i32 %18303, %18298
  %18316 = xor i32 %18315, %18304
  %18317 = lshr i32 %18316, 4
  %18318 = trunc i32 %18317 to i8
  %18319 = and i8 %18318, 1
  store i8 %18319, i8* %19, align 1
  %18320 = icmp eq i32 %18304, 0
  %18321 = zext i1 %18320 to i8
  store i8 %18321, i8* %20, align 1
  %18322 = lshr i32 %18304, 31
  %18323 = trunc i32 %18322 to i8
  store i8 %18323, i8* %21, align 1
  %18324 = lshr i32 %18298, 31
  %18325 = lshr i32 %18303, 31
  %18326 = xor i32 %18322, %18324
  %18327 = xor i32 %18322, %18325
  %18328 = add nuw nsw i32 %18326, %18327
  %18329 = icmp eq i32 %18328, 2
  %18330 = zext i1 %18329 to i8
  store i8 %18330, i8* %22, align 1
  %18331 = sext i32 %18304 to i64
  store i64 %18331, i64* %RDX.i1943, align 8
  %18332 = shl nsw i64 %18331, 1
  %18333 = add i64 %18267, %18332
  %18334 = add i64 %18184, 91
  store i64 %18334, i64* %3, align 8
  %18335 = inttoptr i64 %18333 to i16*
  %18336 = load i16, i16* %18335, align 2
  %18337 = zext i16 %18336 to i64
  store i64 %18337, i64* %50, align 8
  %18338 = load i32, i32* %R9D.i5956, align 4
  %18339 = zext i16 %18336 to i32
  %18340 = add i32 %18339, %18338
  %18341 = zext i32 %18340 to i64
  store i64 %18341, i64* %R9.i1633, align 8
  %18342 = lshr i32 %18340, 31
  %18343 = load i32, i32* %EAX.i2033, align 4
  %18344 = sub i32 %18343, %18340
  %18345 = icmp ult i32 %18343, %18340
  %18346 = zext i1 %18345 to i8
  store i8 %18346, i8* %17, align 1
  %18347 = and i32 %18344, 255
  %18348 = tail call i32 @llvm.ctpop.i32(i32 %18347)
  %18349 = trunc i32 %18348 to i8
  %18350 = and i8 %18349, 1
  %18351 = xor i8 %18350, 1
  store i8 %18351, i8* %18, align 1
  %18352 = xor i32 %18340, %18343
  %18353 = xor i32 %18352, %18344
  %18354 = lshr i32 %18353, 4
  %18355 = trunc i32 %18354 to i8
  %18356 = and i8 %18355, 1
  store i8 %18356, i8* %19, align 1
  %18357 = icmp eq i32 %18344, 0
  %18358 = zext i1 %18357 to i8
  store i8 %18358, i8* %20, align 1
  %18359 = lshr i32 %18344, 31
  %18360 = trunc i32 %18359 to i8
  store i8 %18360, i8* %21, align 1
  %18361 = lshr i32 %18343, 31
  %18362 = xor i32 %18342, %18361
  %18363 = xor i32 %18359, %18361
  %18364 = add nuw nsw i32 %18363, %18362
  %18365 = icmp eq i32 %18364, 2
  %18366 = zext i1 %18365 to i8
  store i8 %18366, i8* %22, align 1
  %18367 = load i64, i64* %RBP.i, align 8
  %18368 = add i64 %18367, -740
  %18369 = load i32, i32* %R8D.i1615, align 4
  %18370 = add i64 %18184, 104
  store i64 %18370, i64* %3, align 8
  %18371 = inttoptr i64 %18368 to i32*
  store i32 %18369, i32* %18371, align 4
  %18372 = load i64, i64* %3, align 8
  %18373 = load i8, i8* %20, align 1
  %18374 = icmp ne i8 %18373, 0
  %18375 = load i8, i8* %21, align 1
  %18376 = icmp ne i8 %18375, 0
  %18377 = load i8, i8* %22, align 1
  %18378 = icmp ne i8 %18377, 0
  %18379 = xor i1 %18376, %18378
  %18380 = or i1 %18374, %18379
  %.v875 = select i1 %18380, i64 19, i64 6
  %18381 = add i64 %18372, %.v875
  store i64 %18381, i64* %3, align 8
  br i1 %18380, label %block_.L_4861d3, label %block_4861c6

block_4861c6:                                     ; preds = %block_486094
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %18382 = load i64, i64* %RBP.i, align 8
  %18383 = add i64 %18382, -744
  %18384 = add i64 %18381, 8
  store i64 %18384, i64* %3, align 8
  %18385 = inttoptr i64 %18383 to i32*
  store i32 0, i32* %18385, align 4
  %18386 = load i64, i64* %3, align 8
  %18387 = add i64 %18386, 83
  store i64 %18387, i64* %3, align 8
  br label %block_.L_486221

block_.L_4861d3:                                  ; preds = %block_486094
  %18388 = load i64, i64* %RBP.i, align 8
  %18389 = add i64 %18388, -348
  %18390 = add i64 %18381, 6
  store i64 %18390, i64* %3, align 8
  %18391 = inttoptr i64 %18389 to i32*
  %18392 = load i32, i32* %18391, align 4
  %18393 = zext i32 %18392 to i64
  store i64 %18393, i64* %RAX.i1659, align 8
  %18394 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %18395 = add i64 %18394, 8504
  store i64 %18395, i64* %RCX.i1588, align 8
  %18396 = icmp ugt i64 %18394, -8505
  %18397 = zext i1 %18396 to i8
  store i8 %18397, i8* %17, align 1
  %18398 = trunc i64 %18395 to i32
  %18399 = and i32 %18398, 255
  %18400 = tail call i32 @llvm.ctpop.i32(i32 %18399)
  %18401 = trunc i32 %18400 to i8
  %18402 = and i8 %18401, 1
  %18403 = xor i8 %18402, 1
  store i8 %18403, i8* %18, align 1
  %18404 = xor i64 %18394, 16
  %18405 = xor i64 %18404, %18395
  %18406 = lshr i64 %18405, 4
  %18407 = trunc i64 %18406 to i8
  %18408 = and i8 %18407, 1
  store i8 %18408, i8* %19, align 1
  %18409 = icmp eq i64 %18395, 0
  %18410 = zext i1 %18409 to i8
  store i8 %18410, i8* %20, align 1
  %18411 = lshr i64 %18395, 63
  %18412 = trunc i64 %18411 to i8
  store i8 %18412, i8* %21, align 1
  %18413 = lshr i64 %18394, 63
  %18414 = xor i64 %18411, %18413
  %18415 = add nuw nsw i64 %18414, %18411
  %18416 = icmp eq i64 %18415, 2
  %18417 = zext i1 %18416 to i8
  store i8 %18417, i8* %22, align 1
  %18418 = add i64 %18388, -364
  %18419 = add i64 %18381, 28
  store i64 %18419, i64* %3, align 8
  %18420 = inttoptr i64 %18418 to i32*
  %18421 = load i32, i32* %18420, align 4
  %18422 = sext i32 %18421 to i64
  %18423 = shl nsw i64 %18422, 9
  store i64 %18423, i64* %RDX.i1943, align 8
  %18424 = add i64 %18423, %18395
  store i64 %18424, i64* %RCX.i1588, align 8
  %18425 = icmp ult i64 %18424, %18395
  %18426 = icmp ult i64 %18424, %18423
  %18427 = or i1 %18425, %18426
  %18428 = zext i1 %18427 to i8
  store i8 %18428, i8* %17, align 1
  %18429 = trunc i64 %18424 to i32
  %18430 = and i32 %18429, 255
  %18431 = tail call i32 @llvm.ctpop.i32(i32 %18430)
  %18432 = trunc i32 %18431 to i8
  %18433 = and i8 %18432, 1
  %18434 = xor i8 %18433, 1
  store i8 %18434, i8* %18, align 1
  %18435 = xor i64 %18395, %18424
  %18436 = lshr i64 %18435, 4
  %18437 = trunc i64 %18436 to i8
  %18438 = and i8 %18437, 1
  store i8 %18438, i8* %19, align 1
  %18439 = icmp eq i64 %18424, 0
  %18440 = zext i1 %18439 to i8
  store i8 %18440, i8* %20, align 1
  %18441 = lshr i64 %18424, 63
  %18442 = trunc i64 %18441 to i8
  store i8 %18442, i8* %21, align 1
  %18443 = lshr i64 %18422, 54
  %18444 = and i64 %18443, 1
  %18445 = xor i64 %18441, %18411
  %18446 = xor i64 %18441, %18444
  %18447 = add nuw nsw i64 %18445, %18446
  %18448 = icmp eq i64 %18447, 2
  %18449 = zext i1 %18448 to i8
  store i8 %18449, i8* %22, align 1
  %18450 = load i64, i64* %RBP.i, align 8
  %18451 = add i64 %18450, -220
  %18452 = add i64 %18381, 41
  store i64 %18452, i64* %3, align 8
  %18453 = inttoptr i64 %18451 to i32*
  %18454 = load i32, i32* %18453, align 4
  %18455 = zext i32 %18454 to i64
  store i64 %18455, i64* %RSI.i2015, align 8
  %18456 = add i64 %18450, -44
  %18457 = add i64 %18381, 44
  store i64 %18457, i64* %3, align 8
  %18458 = inttoptr i64 %18456 to i32*
  %18459 = load i32, i32* %18458, align 4
  %18460 = add i32 %18459, %18454
  %18461 = zext i32 %18460 to i64
  store i64 %18461, i64* %RSI.i2015, align 8
  %18462 = sext i32 %18460 to i64
  %18463 = shl nsw i64 %18462, 5
  store i64 %18463, i64* %RDX.i1943, align 8
  %18464 = load i64, i64* %RCX.i1588, align 8
  %18465 = add i64 %18463, %18464
  store i64 %18465, i64* %RCX.i1588, align 8
  %18466 = icmp ult i64 %18465, %18464
  %18467 = icmp ult i64 %18465, %18463
  %18468 = or i1 %18466, %18467
  %18469 = zext i1 %18468 to i8
  store i8 %18469, i8* %17, align 1
  %18470 = trunc i64 %18465 to i32
  %18471 = and i32 %18470, 255
  %18472 = tail call i32 @llvm.ctpop.i32(i32 %18471)
  %18473 = trunc i32 %18472 to i8
  %18474 = and i8 %18473, 1
  %18475 = xor i8 %18474, 1
  store i8 %18475, i8* %18, align 1
  %18476 = xor i64 %18464, %18465
  %18477 = lshr i64 %18476, 4
  %18478 = trunc i64 %18477 to i8
  %18479 = and i8 %18478, 1
  store i8 %18479, i8* %19, align 1
  %18480 = icmp eq i64 %18465, 0
  %18481 = zext i1 %18480 to i8
  store i8 %18481, i8* %20, align 1
  %18482 = lshr i64 %18465, 63
  %18483 = trunc i64 %18482 to i8
  store i8 %18483, i8* %21, align 1
  %18484 = lshr i64 %18464, 63
  %18485 = lshr i64 %18462, 58
  %18486 = and i64 %18485, 1
  %18487 = xor i64 %18482, %18484
  %18488 = xor i64 %18482, %18486
  %18489 = add nuw nsw i64 %18487, %18488
  %18490 = icmp eq i64 %18489, 2
  %18491 = zext i1 %18490 to i8
  store i8 %18491, i8* %22, align 1
  %18492 = load i64, i64* %RBP.i, align 8
  %18493 = add i64 %18492, -224
  %18494 = add i64 %18381, 60
  store i64 %18494, i64* %3, align 8
  %18495 = inttoptr i64 %18493 to i32*
  %18496 = load i32, i32* %18495, align 4
  %18497 = zext i32 %18496 to i64
  store i64 %18497, i64* %RSI.i2015, align 8
  %18498 = add i64 %18492, -48
  %18499 = add i64 %18381, 63
  store i64 %18499, i64* %3, align 8
  %18500 = inttoptr i64 %18498 to i32*
  %18501 = load i32, i32* %18500, align 4
  %18502 = add i32 %18501, %18496
  %18503 = zext i32 %18502 to i64
  store i64 %18503, i64* %RSI.i2015, align 8
  %18504 = icmp ult i32 %18502, %18496
  %18505 = icmp ult i32 %18502, %18501
  %18506 = or i1 %18504, %18505
  %18507 = zext i1 %18506 to i8
  store i8 %18507, i8* %17, align 1
  %18508 = and i32 %18502, 255
  %18509 = tail call i32 @llvm.ctpop.i32(i32 %18508)
  %18510 = trunc i32 %18509 to i8
  %18511 = and i8 %18510, 1
  %18512 = xor i8 %18511, 1
  store i8 %18512, i8* %18, align 1
  %18513 = xor i32 %18501, %18496
  %18514 = xor i32 %18513, %18502
  %18515 = lshr i32 %18514, 4
  %18516 = trunc i32 %18515 to i8
  %18517 = and i8 %18516, 1
  store i8 %18517, i8* %19, align 1
  %18518 = icmp eq i32 %18502, 0
  %18519 = zext i1 %18518 to i8
  store i8 %18519, i8* %20, align 1
  %18520 = lshr i32 %18502, 31
  %18521 = trunc i32 %18520 to i8
  store i8 %18521, i8* %21, align 1
  %18522 = lshr i32 %18496, 31
  %18523 = lshr i32 %18501, 31
  %18524 = xor i32 %18520, %18522
  %18525 = xor i32 %18520, %18523
  %18526 = add nuw nsw i32 %18524, %18525
  %18527 = icmp eq i32 %18526, 2
  %18528 = zext i1 %18527 to i8
  store i8 %18528, i8* %22, align 1
  %18529 = sext i32 %18502 to i64
  store i64 %18529, i64* %RDX.i1943, align 8
  %18530 = shl nsw i64 %18529, 1
  %18531 = add i64 %18465, %18530
  %18532 = add i64 %18381, 70
  store i64 %18532, i64* %3, align 8
  %18533 = inttoptr i64 %18531 to i16*
  %18534 = load i16, i16* %18533, align 2
  %18535 = zext i16 %18534 to i64
  store i64 %18535, i64* %RSI.i2015, align 8
  %18536 = load i64, i64* %RAX.i1659, align 8
  %18537 = zext i16 %18534 to i32
  %18538 = zext i16 %18534 to i64
  %18539 = trunc i64 %18536 to i32
  %18540 = add i32 %18537, %18539
  %18541 = zext i32 %18540 to i64
  store i64 %18541, i64* %RAX.i1659, align 8
  %18542 = icmp ult i32 %18540, %18539
  %18543 = icmp ult i32 %18540, %18537
  %18544 = or i1 %18542, %18543
  %18545 = zext i1 %18544 to i8
  store i8 %18545, i8* %17, align 1
  %18546 = and i32 %18540, 255
  %18547 = tail call i32 @llvm.ctpop.i32(i32 %18546)
  %18548 = trunc i32 %18547 to i8
  %18549 = and i8 %18548, 1
  %18550 = xor i8 %18549, 1
  store i8 %18550, i8* %18, align 1
  %18551 = xor i64 %18538, %18536
  %18552 = trunc i64 %18551 to i32
  %18553 = xor i32 %18552, %18540
  %18554 = lshr i32 %18553, 4
  %18555 = trunc i32 %18554 to i8
  %18556 = and i8 %18555, 1
  store i8 %18556, i8* %19, align 1
  %18557 = icmp eq i32 %18540, 0
  %18558 = zext i1 %18557 to i8
  store i8 %18558, i8* %20, align 1
  %18559 = lshr i32 %18540, 31
  %18560 = trunc i32 %18559 to i8
  store i8 %18560, i8* %21, align 1
  %18561 = lshr i32 %18539, 31
  %18562 = xor i32 %18559, %18561
  %18563 = add nuw nsw i32 %18562, %18559
  %18564 = icmp eq i32 %18563, 2
  %18565 = zext i1 %18564 to i8
  store i8 %18565, i8* %22, align 1
  %18566 = add i64 %18492, -744
  %18567 = add i64 %18381, 78
  store i64 %18567, i64* %3, align 8
  %18568 = inttoptr i64 %18566 to i32*
  store i32 %18540, i32* %18568, align 4
  %.pre538 = load i64, i64* %3, align 8
  br label %block_.L_486221

block_.L_486221:                                  ; preds = %block_.L_4861d3, %block_4861c6
  %18569 = phi i64 [ %.pre538, %block_.L_4861d3 ], [ %18387, %block_4861c6 ]
  %18570 = load i64, i64* %RBP.i, align 8
  %18571 = add i64 %18570, -744
  %18572 = add i64 %18569, 6
  store i64 %18572, i64* %3, align 8
  %18573 = inttoptr i64 %18571 to i32*
  %18574 = load i32, i32* %18573, align 4
  %18575 = zext i32 %18574 to i64
  store i64 %18575, i64* %RAX.i1659, align 8
  %18576 = add i64 %18570, -740
  %18577 = add i64 %18569, 12
  store i64 %18577, i64* %3, align 8
  %18578 = inttoptr i64 %18576 to i32*
  %18579 = load i32, i32* %18578, align 4
  %18580 = zext i32 %18579 to i64
  store i64 %18580, i64* %RCX.i1588, align 8
  %18581 = sub i32 %18579, %18574
  %18582 = icmp ult i32 %18579, %18574
  %18583 = zext i1 %18582 to i8
  store i8 %18583, i8* %17, align 1
  %18584 = and i32 %18581, 255
  %18585 = tail call i32 @llvm.ctpop.i32(i32 %18584)
  %18586 = trunc i32 %18585 to i8
  %18587 = and i8 %18586, 1
  %18588 = xor i8 %18587, 1
  store i8 %18588, i8* %18, align 1
  %18589 = xor i32 %18574, %18579
  %18590 = xor i32 %18589, %18581
  %18591 = lshr i32 %18590, 4
  %18592 = trunc i32 %18591 to i8
  %18593 = and i8 %18592, 1
  store i8 %18593, i8* %19, align 1
  %18594 = icmp eq i32 %18581, 0
  %18595 = zext i1 %18594 to i8
  store i8 %18595, i8* %20, align 1
  %18596 = lshr i32 %18581, 31
  %18597 = trunc i32 %18596 to i8
  store i8 %18597, i8* %21, align 1
  %18598 = lshr i32 %18579, 31
  %18599 = lshr i32 %18574, 31
  %18600 = xor i32 %18599, %18598
  %18601 = xor i32 %18596, %18598
  %18602 = add nuw nsw i32 %18601, %18600
  %18603 = icmp eq i32 %18602, 2
  %18604 = zext i1 %18603 to i8
  store i8 %18604, i8* %22, align 1
  %18605 = icmp ne i8 %18597, 0
  %18606 = xor i1 %18605, %18603
  %.v716 = select i1 %18606, i64 20, i64 45
  %18607 = add i64 %18569, %.v716
  store i64 %18607, i64* %3, align 8
  br i1 %18606, label %block_486235, label %block_.L_48624e

block_486235:                                     ; preds = %block_.L_486221
  %18608 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %18608, i64* %RAX.i1659, align 8
  %18609 = add i64 %18608, 72688
  %18610 = add i64 %18607, 14
  store i64 %18610, i64* %3, align 8
  %18611 = inttoptr i64 %18609 to i32*
  %18612 = load i32, i32* %18611, align 4
  %18613 = zext i32 %18612 to i64
  store i64 %18613, i64* %RCX.i1588, align 8
  %18614 = add i64 %18570, -748
  %18615 = add i64 %18607, 20
  store i64 %18615, i64* %3, align 8
  %18616 = inttoptr i64 %18614 to i32*
  store i32 %18612, i32* %18616, align 4
  %18617 = load i64, i64* %3, align 8
  %18618 = add i64 %18617, 190
  store i64 %18618, i64* %3, align 8
  br label %block_.L_486307

block_.L_48624e:                                  ; preds = %block_.L_486221
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %18619 = add i64 %18570, -348
  %18620 = add i64 %18607, 8
  store i64 %18620, i64* %3, align 8
  %18621 = inttoptr i64 %18619 to i32*
  %18622 = load i32, i32* %18621, align 4
  %18623 = zext i32 %18622 to i64
  store i64 %18623, i64* %RCX.i1588, align 8
  %18624 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %18625 = add i64 %18624, 8504
  store i64 %18625, i64* %RDX.i1943, align 8
  %18626 = icmp ugt i64 %18624, -8505
  %18627 = zext i1 %18626 to i8
  store i8 %18627, i8* %17, align 1
  %18628 = trunc i64 %18625 to i32
  %18629 = and i32 %18628, 255
  %18630 = tail call i32 @llvm.ctpop.i32(i32 %18629)
  %18631 = trunc i32 %18630 to i8
  %18632 = and i8 %18631, 1
  %18633 = xor i8 %18632, 1
  store i8 %18633, i8* %18, align 1
  %18634 = xor i64 %18624, 16
  %18635 = xor i64 %18634, %18625
  %18636 = lshr i64 %18635, 4
  %18637 = trunc i64 %18636 to i8
  %18638 = and i8 %18637, 1
  store i8 %18638, i8* %19, align 1
  %18639 = icmp eq i64 %18625, 0
  %18640 = zext i1 %18639 to i8
  store i8 %18640, i8* %20, align 1
  %18641 = lshr i64 %18625, 63
  %18642 = trunc i64 %18641 to i8
  store i8 %18642, i8* %21, align 1
  %18643 = lshr i64 %18624, 63
  %18644 = xor i64 %18641, %18643
  %18645 = add nuw nsw i64 %18644, %18641
  %18646 = icmp eq i64 %18645, 2
  %18647 = zext i1 %18646 to i8
  store i8 %18647, i8* %22, align 1
  %18648 = add i64 %18570, -364
  %18649 = add i64 %18607, 30
  store i64 %18649, i64* %3, align 8
  %18650 = inttoptr i64 %18648 to i32*
  %18651 = load i32, i32* %18650, align 4
  %18652 = sext i32 %18651 to i64
  %18653 = shl nsw i64 %18652, 9
  store i64 %18653, i64* %RSI.i2015, align 8
  %18654 = add i64 %18653, %18625
  store i64 %18654, i64* %RDX.i1943, align 8
  %18655 = icmp ult i64 %18654, %18625
  %18656 = icmp ult i64 %18654, %18653
  %18657 = or i1 %18655, %18656
  %18658 = zext i1 %18657 to i8
  store i8 %18658, i8* %17, align 1
  %18659 = trunc i64 %18654 to i32
  %18660 = and i32 %18659, 255
  %18661 = tail call i32 @llvm.ctpop.i32(i32 %18660)
  %18662 = trunc i32 %18661 to i8
  %18663 = and i8 %18662, 1
  %18664 = xor i8 %18663, 1
  store i8 %18664, i8* %18, align 1
  %18665 = xor i64 %18625, %18654
  %18666 = lshr i64 %18665, 4
  %18667 = trunc i64 %18666 to i8
  %18668 = and i8 %18667, 1
  store i8 %18668, i8* %19, align 1
  %18669 = icmp eq i64 %18654, 0
  %18670 = zext i1 %18669 to i8
  store i8 %18670, i8* %20, align 1
  %18671 = lshr i64 %18654, 63
  %18672 = trunc i64 %18671 to i8
  store i8 %18672, i8* %21, align 1
  %18673 = lshr i64 %18652, 54
  %18674 = and i64 %18673, 1
  %18675 = xor i64 %18671, %18641
  %18676 = xor i64 %18671, %18674
  %18677 = add nuw nsw i64 %18675, %18676
  %18678 = icmp eq i64 %18677, 2
  %18679 = zext i1 %18678 to i8
  store i8 %18679, i8* %22, align 1
  %18680 = load i64, i64* %RBP.i, align 8
  %18681 = add i64 %18680, -220
  %18682 = add i64 %18607, 43
  store i64 %18682, i64* %3, align 8
  %18683 = inttoptr i64 %18681 to i32*
  %18684 = load i32, i32* %18683, align 4
  %18685 = zext i32 %18684 to i64
  store i64 %18685, i64* %RDI.i6998, align 8
  %18686 = add i64 %18680, -44
  %18687 = add i64 %18607, 46
  store i64 %18687, i64* %3, align 8
  %18688 = inttoptr i64 %18686 to i32*
  %18689 = load i32, i32* %18688, align 4
  %18690 = add i32 %18689, %18684
  %18691 = zext i32 %18690 to i64
  store i64 %18691, i64* %RDI.i6998, align 8
  %18692 = sext i32 %18690 to i64
  %18693 = shl nsw i64 %18692, 5
  store i64 %18693, i64* %RSI.i2015, align 8
  %18694 = load i64, i64* %RDX.i1943, align 8
  %18695 = add i64 %18693, %18694
  store i64 %18695, i64* %RDX.i1943, align 8
  %18696 = icmp ult i64 %18695, %18694
  %18697 = icmp ult i64 %18695, %18693
  %18698 = or i1 %18696, %18697
  %18699 = zext i1 %18698 to i8
  store i8 %18699, i8* %17, align 1
  %18700 = trunc i64 %18695 to i32
  %18701 = and i32 %18700, 255
  %18702 = tail call i32 @llvm.ctpop.i32(i32 %18701)
  %18703 = trunc i32 %18702 to i8
  %18704 = and i8 %18703, 1
  %18705 = xor i8 %18704, 1
  store i8 %18705, i8* %18, align 1
  %18706 = xor i64 %18694, %18695
  %18707 = lshr i64 %18706, 4
  %18708 = trunc i64 %18707 to i8
  %18709 = and i8 %18708, 1
  store i8 %18709, i8* %19, align 1
  %18710 = icmp eq i64 %18695, 0
  %18711 = zext i1 %18710 to i8
  store i8 %18711, i8* %20, align 1
  %18712 = lshr i64 %18695, 63
  %18713 = trunc i64 %18712 to i8
  store i8 %18713, i8* %21, align 1
  %18714 = lshr i64 %18694, 63
  %18715 = lshr i64 %18692, 58
  %18716 = and i64 %18715, 1
  %18717 = xor i64 %18712, %18714
  %18718 = xor i64 %18712, %18716
  %18719 = add nuw nsw i64 %18717, %18718
  %18720 = icmp eq i64 %18719, 2
  %18721 = zext i1 %18720 to i8
  store i8 %18721, i8* %22, align 1
  %18722 = load i64, i64* %RBP.i, align 8
  %18723 = add i64 %18722, -224
  %18724 = add i64 %18607, 62
  store i64 %18724, i64* %3, align 8
  %18725 = inttoptr i64 %18723 to i32*
  %18726 = load i32, i32* %18725, align 4
  %18727 = zext i32 %18726 to i64
  store i64 %18727, i64* %RDI.i6998, align 8
  %18728 = add i64 %18722, -48
  %18729 = add i64 %18607, 65
  store i64 %18729, i64* %3, align 8
  %18730 = inttoptr i64 %18728 to i32*
  %18731 = load i32, i32* %18730, align 4
  %18732 = add i32 %18731, %18726
  %18733 = zext i32 %18732 to i64
  store i64 %18733, i64* %RDI.i6998, align 8
  %18734 = icmp ult i32 %18732, %18726
  %18735 = icmp ult i32 %18732, %18731
  %18736 = or i1 %18734, %18735
  %18737 = zext i1 %18736 to i8
  store i8 %18737, i8* %17, align 1
  %18738 = and i32 %18732, 255
  %18739 = tail call i32 @llvm.ctpop.i32(i32 %18738)
  %18740 = trunc i32 %18739 to i8
  %18741 = and i8 %18740, 1
  %18742 = xor i8 %18741, 1
  store i8 %18742, i8* %18, align 1
  %18743 = xor i32 %18731, %18726
  %18744 = xor i32 %18743, %18732
  %18745 = lshr i32 %18744, 4
  %18746 = trunc i32 %18745 to i8
  %18747 = and i8 %18746, 1
  store i8 %18747, i8* %19, align 1
  %18748 = icmp eq i32 %18732, 0
  %18749 = zext i1 %18748 to i8
  store i8 %18749, i8* %20, align 1
  %18750 = lshr i32 %18732, 31
  %18751 = trunc i32 %18750 to i8
  store i8 %18751, i8* %21, align 1
  %18752 = lshr i32 %18726, 31
  %18753 = lshr i32 %18731, 31
  %18754 = xor i32 %18750, %18752
  %18755 = xor i32 %18750, %18753
  %18756 = add nuw nsw i32 %18754, %18755
  %18757 = icmp eq i32 %18756, 2
  %18758 = zext i1 %18757 to i8
  store i8 %18758, i8* %22, align 1
  %18759 = sext i32 %18732 to i64
  store i64 %18759, i64* %RSI.i2015, align 8
  %18760 = shl nsw i64 %18759, 1
  %18761 = add i64 %18695, %18760
  %18762 = add i64 %18607, 72
  store i64 %18762, i64* %3, align 8
  %18763 = inttoptr i64 %18761 to i16*
  %18764 = load i16, i16* %18763, align 2
  %18765 = zext i16 %18764 to i64
  store i64 %18765, i64* %RDI.i6998, align 8
  %18766 = load i64, i64* %RCX.i1588, align 8
  %18767 = zext i16 %18764 to i32
  %18768 = trunc i64 %18766 to i32
  %18769 = add i32 %18767, %18768
  %18770 = zext i32 %18769 to i64
  store i64 %18770, i64* %RCX.i1588, align 8
  %18771 = lshr i32 %18769, 31
  %18772 = load i32, i32* %EAX.i2033, align 4
  %18773 = sub i32 %18772, %18769
  %18774 = icmp ult i32 %18772, %18769
  %18775 = zext i1 %18774 to i8
  store i8 %18775, i8* %17, align 1
  %18776 = and i32 %18773, 255
  %18777 = tail call i32 @llvm.ctpop.i32(i32 %18776)
  %18778 = trunc i32 %18777 to i8
  %18779 = and i8 %18778, 1
  %18780 = xor i8 %18779, 1
  store i8 %18780, i8* %18, align 1
  %18781 = xor i32 %18769, %18772
  %18782 = xor i32 %18781, %18773
  %18783 = lshr i32 %18782, 4
  %18784 = trunc i32 %18783 to i8
  %18785 = and i8 %18784, 1
  store i8 %18785, i8* %19, align 1
  %18786 = icmp eq i32 %18773, 0
  %18787 = zext i1 %18786 to i8
  store i8 %18787, i8* %20, align 1
  %18788 = lshr i32 %18773, 31
  %18789 = trunc i32 %18788 to i8
  store i8 %18789, i8* %21, align 1
  %18790 = lshr i32 %18772, 31
  %18791 = xor i32 %18771, %18790
  %18792 = xor i32 %18788, %18790
  %18793 = add nuw nsw i32 %18792, %18791
  %18794 = icmp eq i32 %18793, 2
  %18795 = zext i1 %18794 to i8
  store i8 %18795, i8* %22, align 1
  %18796 = icmp ne i8 %18789, 0
  %18797 = xor i1 %18796, %18794
  %18798 = or i1 %18786, %18797
  %.v717 = select i1 %18798, i64 95, i64 82
  %18799 = add i64 %18607, %.v717
  store i64 %18799, i64* %3, align 8
  br i1 %18798, label %block_.L_4862ad, label %block_4862a0

block_4862a0:                                     ; preds = %block_.L_48624e
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %18800 = load i64, i64* %RBP.i, align 8
  %18801 = add i64 %18800, -752
  %18802 = add i64 %18799, 8
  store i64 %18802, i64* %3, align 8
  %18803 = inttoptr i64 %18801 to i32*
  store i32 0, i32* %18803, align 4
  %18804 = load i64, i64* %3, align 8
  %18805 = add i64 %18804, 83
  store i64 %18805, i64* %3, align 8
  br label %block_.L_4862fb

block_.L_4862ad:                                  ; preds = %block_.L_48624e
  %18806 = load i64, i64* %RBP.i, align 8
  %18807 = add i64 %18806, -348
  %18808 = add i64 %18799, 6
  store i64 %18808, i64* %3, align 8
  %18809 = inttoptr i64 %18807 to i32*
  %18810 = load i32, i32* %18809, align 4
  %18811 = zext i32 %18810 to i64
  store i64 %18811, i64* %RAX.i1659, align 8
  %18812 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %18813 = add i64 %18812, 8504
  store i64 %18813, i64* %RCX.i1588, align 8
  %18814 = icmp ugt i64 %18812, -8505
  %18815 = zext i1 %18814 to i8
  store i8 %18815, i8* %17, align 1
  %18816 = trunc i64 %18813 to i32
  %18817 = and i32 %18816, 255
  %18818 = tail call i32 @llvm.ctpop.i32(i32 %18817)
  %18819 = trunc i32 %18818 to i8
  %18820 = and i8 %18819, 1
  %18821 = xor i8 %18820, 1
  store i8 %18821, i8* %18, align 1
  %18822 = xor i64 %18812, 16
  %18823 = xor i64 %18822, %18813
  %18824 = lshr i64 %18823, 4
  %18825 = trunc i64 %18824 to i8
  %18826 = and i8 %18825, 1
  store i8 %18826, i8* %19, align 1
  %18827 = icmp eq i64 %18813, 0
  %18828 = zext i1 %18827 to i8
  store i8 %18828, i8* %20, align 1
  %18829 = lshr i64 %18813, 63
  %18830 = trunc i64 %18829 to i8
  store i8 %18830, i8* %21, align 1
  %18831 = lshr i64 %18812, 63
  %18832 = xor i64 %18829, %18831
  %18833 = add nuw nsw i64 %18832, %18829
  %18834 = icmp eq i64 %18833, 2
  %18835 = zext i1 %18834 to i8
  store i8 %18835, i8* %22, align 1
  %18836 = add i64 %18806, -364
  %18837 = add i64 %18799, 28
  store i64 %18837, i64* %3, align 8
  %18838 = inttoptr i64 %18836 to i32*
  %18839 = load i32, i32* %18838, align 4
  %18840 = sext i32 %18839 to i64
  %18841 = shl nsw i64 %18840, 9
  store i64 %18841, i64* %RDX.i1943, align 8
  %18842 = add i64 %18841, %18813
  store i64 %18842, i64* %RCX.i1588, align 8
  %18843 = icmp ult i64 %18842, %18813
  %18844 = icmp ult i64 %18842, %18841
  %18845 = or i1 %18843, %18844
  %18846 = zext i1 %18845 to i8
  store i8 %18846, i8* %17, align 1
  %18847 = trunc i64 %18842 to i32
  %18848 = and i32 %18847, 255
  %18849 = tail call i32 @llvm.ctpop.i32(i32 %18848)
  %18850 = trunc i32 %18849 to i8
  %18851 = and i8 %18850, 1
  %18852 = xor i8 %18851, 1
  store i8 %18852, i8* %18, align 1
  %18853 = xor i64 %18813, %18842
  %18854 = lshr i64 %18853, 4
  %18855 = trunc i64 %18854 to i8
  %18856 = and i8 %18855, 1
  store i8 %18856, i8* %19, align 1
  %18857 = icmp eq i64 %18842, 0
  %18858 = zext i1 %18857 to i8
  store i8 %18858, i8* %20, align 1
  %18859 = lshr i64 %18842, 63
  %18860 = trunc i64 %18859 to i8
  store i8 %18860, i8* %21, align 1
  %18861 = lshr i64 %18840, 54
  %18862 = and i64 %18861, 1
  %18863 = xor i64 %18859, %18829
  %18864 = xor i64 %18859, %18862
  %18865 = add nuw nsw i64 %18863, %18864
  %18866 = icmp eq i64 %18865, 2
  %18867 = zext i1 %18866 to i8
  store i8 %18867, i8* %22, align 1
  %18868 = load i64, i64* %RBP.i, align 8
  %18869 = add i64 %18868, -220
  %18870 = add i64 %18799, 41
  store i64 %18870, i64* %3, align 8
  %18871 = inttoptr i64 %18869 to i32*
  %18872 = load i32, i32* %18871, align 4
  %18873 = zext i32 %18872 to i64
  store i64 %18873, i64* %RSI.i2015, align 8
  %18874 = add i64 %18868, -44
  %18875 = add i64 %18799, 44
  store i64 %18875, i64* %3, align 8
  %18876 = inttoptr i64 %18874 to i32*
  %18877 = load i32, i32* %18876, align 4
  %18878 = add i32 %18877, %18872
  %18879 = zext i32 %18878 to i64
  store i64 %18879, i64* %RSI.i2015, align 8
  %18880 = sext i32 %18878 to i64
  %18881 = shl nsw i64 %18880, 5
  store i64 %18881, i64* %RDX.i1943, align 8
  %18882 = load i64, i64* %RCX.i1588, align 8
  %18883 = add i64 %18881, %18882
  store i64 %18883, i64* %RCX.i1588, align 8
  %18884 = icmp ult i64 %18883, %18882
  %18885 = icmp ult i64 %18883, %18881
  %18886 = or i1 %18884, %18885
  %18887 = zext i1 %18886 to i8
  store i8 %18887, i8* %17, align 1
  %18888 = trunc i64 %18883 to i32
  %18889 = and i32 %18888, 255
  %18890 = tail call i32 @llvm.ctpop.i32(i32 %18889)
  %18891 = trunc i32 %18890 to i8
  %18892 = and i8 %18891, 1
  %18893 = xor i8 %18892, 1
  store i8 %18893, i8* %18, align 1
  %18894 = xor i64 %18882, %18883
  %18895 = lshr i64 %18894, 4
  %18896 = trunc i64 %18895 to i8
  %18897 = and i8 %18896, 1
  store i8 %18897, i8* %19, align 1
  %18898 = icmp eq i64 %18883, 0
  %18899 = zext i1 %18898 to i8
  store i8 %18899, i8* %20, align 1
  %18900 = lshr i64 %18883, 63
  %18901 = trunc i64 %18900 to i8
  store i8 %18901, i8* %21, align 1
  %18902 = lshr i64 %18882, 63
  %18903 = lshr i64 %18880, 58
  %18904 = and i64 %18903, 1
  %18905 = xor i64 %18900, %18902
  %18906 = xor i64 %18900, %18904
  %18907 = add nuw nsw i64 %18905, %18906
  %18908 = icmp eq i64 %18907, 2
  %18909 = zext i1 %18908 to i8
  store i8 %18909, i8* %22, align 1
  %18910 = load i64, i64* %RBP.i, align 8
  %18911 = add i64 %18910, -224
  %18912 = add i64 %18799, 60
  store i64 %18912, i64* %3, align 8
  %18913 = inttoptr i64 %18911 to i32*
  %18914 = load i32, i32* %18913, align 4
  %18915 = zext i32 %18914 to i64
  store i64 %18915, i64* %RSI.i2015, align 8
  %18916 = add i64 %18910, -48
  %18917 = add i64 %18799, 63
  store i64 %18917, i64* %3, align 8
  %18918 = inttoptr i64 %18916 to i32*
  %18919 = load i32, i32* %18918, align 4
  %18920 = add i32 %18919, %18914
  %18921 = zext i32 %18920 to i64
  store i64 %18921, i64* %RSI.i2015, align 8
  %18922 = icmp ult i32 %18920, %18914
  %18923 = icmp ult i32 %18920, %18919
  %18924 = or i1 %18922, %18923
  %18925 = zext i1 %18924 to i8
  store i8 %18925, i8* %17, align 1
  %18926 = and i32 %18920, 255
  %18927 = tail call i32 @llvm.ctpop.i32(i32 %18926)
  %18928 = trunc i32 %18927 to i8
  %18929 = and i8 %18928, 1
  %18930 = xor i8 %18929, 1
  store i8 %18930, i8* %18, align 1
  %18931 = xor i32 %18919, %18914
  %18932 = xor i32 %18931, %18920
  %18933 = lshr i32 %18932, 4
  %18934 = trunc i32 %18933 to i8
  %18935 = and i8 %18934, 1
  store i8 %18935, i8* %19, align 1
  %18936 = icmp eq i32 %18920, 0
  %18937 = zext i1 %18936 to i8
  store i8 %18937, i8* %20, align 1
  %18938 = lshr i32 %18920, 31
  %18939 = trunc i32 %18938 to i8
  store i8 %18939, i8* %21, align 1
  %18940 = lshr i32 %18914, 31
  %18941 = lshr i32 %18919, 31
  %18942 = xor i32 %18938, %18940
  %18943 = xor i32 %18938, %18941
  %18944 = add nuw nsw i32 %18942, %18943
  %18945 = icmp eq i32 %18944, 2
  %18946 = zext i1 %18945 to i8
  store i8 %18946, i8* %22, align 1
  %18947 = sext i32 %18920 to i64
  store i64 %18947, i64* %RDX.i1943, align 8
  %18948 = shl nsw i64 %18947, 1
  %18949 = add i64 %18883, %18948
  %18950 = add i64 %18799, 70
  store i64 %18950, i64* %3, align 8
  %18951 = inttoptr i64 %18949 to i16*
  %18952 = load i16, i16* %18951, align 2
  %18953 = zext i16 %18952 to i64
  store i64 %18953, i64* %RSI.i2015, align 8
  %18954 = load i64, i64* %RAX.i1659, align 8
  %18955 = zext i16 %18952 to i32
  %18956 = zext i16 %18952 to i64
  %18957 = trunc i64 %18954 to i32
  %18958 = add i32 %18955, %18957
  %18959 = zext i32 %18958 to i64
  store i64 %18959, i64* %RAX.i1659, align 8
  %18960 = icmp ult i32 %18958, %18957
  %18961 = icmp ult i32 %18958, %18955
  %18962 = or i1 %18960, %18961
  %18963 = zext i1 %18962 to i8
  store i8 %18963, i8* %17, align 1
  %18964 = and i32 %18958, 255
  %18965 = tail call i32 @llvm.ctpop.i32(i32 %18964)
  %18966 = trunc i32 %18965 to i8
  %18967 = and i8 %18966, 1
  %18968 = xor i8 %18967, 1
  store i8 %18968, i8* %18, align 1
  %18969 = xor i64 %18956, %18954
  %18970 = trunc i64 %18969 to i32
  %18971 = xor i32 %18970, %18958
  %18972 = lshr i32 %18971, 4
  %18973 = trunc i32 %18972 to i8
  %18974 = and i8 %18973, 1
  store i8 %18974, i8* %19, align 1
  %18975 = icmp eq i32 %18958, 0
  %18976 = zext i1 %18975 to i8
  store i8 %18976, i8* %20, align 1
  %18977 = lshr i32 %18958, 31
  %18978 = trunc i32 %18977 to i8
  store i8 %18978, i8* %21, align 1
  %18979 = lshr i32 %18957, 31
  %18980 = xor i32 %18977, %18979
  %18981 = add nuw nsw i32 %18980, %18977
  %18982 = icmp eq i32 %18981, 2
  %18983 = zext i1 %18982 to i8
  store i8 %18983, i8* %22, align 1
  %18984 = add i64 %18910, -752
  %18985 = add i64 %18799, 78
  store i64 %18985, i64* %3, align 8
  %18986 = inttoptr i64 %18984 to i32*
  store i32 %18958, i32* %18986, align 4
  %.pre539 = load i64, i64* %3, align 8
  br label %block_.L_4862fb

block_.L_4862fb:                                  ; preds = %block_.L_4862ad, %block_4862a0
  %18987 = phi i64 [ %.pre539, %block_.L_4862ad ], [ %18805, %block_4862a0 ]
  %18988 = load i64, i64* %RBP.i, align 8
  %18989 = add i64 %18988, -752
  %18990 = add i64 %18987, 6
  store i64 %18990, i64* %3, align 8
  %18991 = inttoptr i64 %18989 to i32*
  %18992 = load i32, i32* %18991, align 4
  %18993 = zext i32 %18992 to i64
  store i64 %18993, i64* %RAX.i1659, align 8
  %18994 = add i64 %18988, -748
  %18995 = add i64 %18987, 12
  store i64 %18995, i64* %3, align 8
  %18996 = inttoptr i64 %18994 to i32*
  store i32 %18992, i32* %18996, align 4
  %.pre540 = load i64, i64* %3, align 8
  br label %block_.L_486307

block_.L_486307:                                  ; preds = %block_.L_4862fb, %block_486235
  %18997 = phi i64 [ %.pre540, %block_.L_4862fb ], [ %18618, %block_486235 ]
  %18998 = load i64, i64* %RBP.i, align 8
  %18999 = add i64 %18998, -748
  %19000 = add i64 %18997, 6
  store i64 %19000, i64* %3, align 8
  %19001 = inttoptr i64 %18999 to i32*
  %19002 = load i32, i32* %19001, align 4
  %19003 = zext i32 %19002 to i64
  store i64 %19003, i64* %RAX.i1659, align 8
  store i64 0, i64* %RCX.i1588, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %19004 = trunc i32 %19002 to i16
  store i16 %19004, i16* %DX.i4863, align 2
  %19005 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %19005, i64* %RSI.i2015, align 8
  %19006 = add i64 %19005, 6464
  %19007 = add i64 %18997, 26
  store i64 %19007, i64* %3, align 8
  %19008 = inttoptr i64 %19006 to i64*
  %19009 = load i64, i64* %19008, align 8
  store i64 %19009, i64* %RSI.i2015, align 8
  %19010 = add i64 %18997, 29
  store i64 %19010, i64* %3, align 8
  %19011 = inttoptr i64 %19009 to i64*
  %19012 = load i64, i64* %19011, align 8
  store i64 %19012, i64* %RSI.i2015, align 8
  %19013 = add i64 %18998, -232
  %19014 = add i64 %18997, 35
  store i64 %19014, i64* %3, align 8
  %19015 = inttoptr i64 %19013 to i32*
  %19016 = load i32, i32* %19015, align 4
  %19017 = zext i32 %19016 to i64
  store i64 %19017, i64* %RAX.i1659, align 8
  %19018 = add i64 %18998, -48
  %19019 = add i64 %18997, 38
  store i64 %19019, i64* %3, align 8
  %19020 = inttoptr i64 %19018 to i32*
  %19021 = load i32, i32* %19020, align 4
  %19022 = add i32 %19021, %19016
  %19023 = zext i32 %19022 to i64
  store i64 %19023, i64* %RAX.i1659, align 8
  %19024 = icmp ult i32 %19022, %19016
  %19025 = icmp ult i32 %19022, %19021
  %19026 = or i1 %19024, %19025
  %19027 = zext i1 %19026 to i8
  store i8 %19027, i8* %17, align 1
  %19028 = and i32 %19022, 255
  %19029 = tail call i32 @llvm.ctpop.i32(i32 %19028)
  %19030 = trunc i32 %19029 to i8
  %19031 = and i8 %19030, 1
  %19032 = xor i8 %19031, 1
  store i8 %19032, i8* %18, align 1
  %19033 = xor i32 %19021, %19016
  %19034 = xor i32 %19033, %19022
  %19035 = lshr i32 %19034, 4
  %19036 = trunc i32 %19035 to i8
  %19037 = and i8 %19036, 1
  store i8 %19037, i8* %19, align 1
  %19038 = icmp eq i32 %19022, 0
  %19039 = zext i1 %19038 to i8
  store i8 %19039, i8* %20, align 1
  %19040 = lshr i32 %19022, 31
  %19041 = trunc i32 %19040 to i8
  store i8 %19041, i8* %21, align 1
  %19042 = lshr i32 %19016, 31
  %19043 = lshr i32 %19021, 31
  %19044 = xor i32 %19040, %19042
  %19045 = xor i32 %19040, %19043
  %19046 = add nuw nsw i32 %19044, %19045
  %19047 = icmp eq i32 %19046, 2
  %19048 = zext i1 %19047 to i8
  store i8 %19048, i8* %22, align 1
  %19049 = sext i32 %19022 to i64
  store i64 %19049, i64* %RDI.i6998, align 8
  %19050 = shl nsw i64 %19049, 3
  %19051 = add i64 %19012, %19050
  %19052 = add i64 %18997, 45
  store i64 %19052, i64* %3, align 8
  %19053 = inttoptr i64 %19051 to i64*
  %19054 = load i64, i64* %19053, align 8
  store i64 %19054, i64* %RSI.i2015, align 8
  %19055 = load i64, i64* %RBP.i, align 8
  %19056 = add i64 %19055, -228
  %19057 = add i64 %18997, 51
  store i64 %19057, i64* %3, align 8
  %19058 = inttoptr i64 %19056 to i32*
  %19059 = load i32, i32* %19058, align 4
  %19060 = zext i32 %19059 to i64
  store i64 %19060, i64* %RAX.i1659, align 8
  %19061 = add i64 %19055, -44
  %19062 = add i64 %18997, 54
  store i64 %19062, i64* %3, align 8
  %19063 = inttoptr i64 %19061 to i32*
  %19064 = load i32, i32* %19063, align 4
  %19065 = add i32 %19064, %19059
  %19066 = zext i32 %19065 to i64
  store i64 %19066, i64* %RAX.i1659, align 8
  %19067 = icmp ult i32 %19065, %19059
  %19068 = icmp ult i32 %19065, %19064
  %19069 = or i1 %19067, %19068
  %19070 = zext i1 %19069 to i8
  store i8 %19070, i8* %17, align 1
  %19071 = and i32 %19065, 255
  %19072 = tail call i32 @llvm.ctpop.i32(i32 %19071)
  %19073 = trunc i32 %19072 to i8
  %19074 = and i8 %19073, 1
  %19075 = xor i8 %19074, 1
  store i8 %19075, i8* %18, align 1
  %19076 = xor i32 %19064, %19059
  %19077 = xor i32 %19076, %19065
  %19078 = lshr i32 %19077, 4
  %19079 = trunc i32 %19078 to i8
  %19080 = and i8 %19079, 1
  store i8 %19080, i8* %19, align 1
  %19081 = icmp eq i32 %19065, 0
  %19082 = zext i1 %19081 to i8
  store i8 %19082, i8* %20, align 1
  %19083 = lshr i32 %19065, 31
  %19084 = trunc i32 %19083 to i8
  store i8 %19084, i8* %21, align 1
  %19085 = lshr i32 %19059, 31
  %19086 = lshr i32 %19064, 31
  %19087 = xor i32 %19083, %19085
  %19088 = xor i32 %19083, %19086
  %19089 = add nuw nsw i32 %19087, %19088
  %19090 = icmp eq i32 %19089, 2
  %19091 = zext i1 %19090 to i8
  store i8 %19091, i8* %22, align 1
  %19092 = sext i32 %19065 to i64
  store i64 %19092, i64* %RDI.i6998, align 8
  %19093 = shl nsw i64 %19092, 1
  %19094 = add i64 %19054, %19093
  %19095 = load i16, i16* %DX.i4863, align 2
  %19096 = add i64 %18997, 61
  store i64 %19096, i64* %3, align 8
  %19097 = inttoptr i64 %19094 to i16*
  store i16 %19095, i16* %19097, align 2
  %19098 = load i64, i64* %3, align 8
  %19099 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %19099, i64* %RSI.i2015, align 8
  %19100 = add i64 %19099, 72684
  %19101 = add i64 %19098, 14
  store i64 %19101, i64* %3, align 8
  %19102 = inttoptr i64 %19100 to i32*
  %19103 = load i32, i32* %19102, align 4
  %19104 = zext i32 %19103 to i64
  store i64 %19104, i64* %RAX.i1659, align 8
  %19105 = load i64, i64* %RBP.i, align 8
  %19106 = add i64 %19105, -344
  %19107 = add i64 %19098, 21
  store i64 %19107, i64* %3, align 8
  %19108 = inttoptr i64 %19106 to i32*
  %19109 = load i32, i32* %19108, align 4
  %19110 = zext i32 %19109 to i64
  store i64 %19110, i64* %25, align 8
  %19111 = add i64 %19099, 184
  store i64 %19111, i64* %RSI.i2015, align 8
  %19112 = icmp ugt i64 %19099, -185
  %19113 = zext i1 %19112 to i8
  store i8 %19113, i8* %17, align 1
  %19114 = trunc i64 %19111 to i32
  %19115 = and i32 %19114, 255
  %19116 = tail call i32 @llvm.ctpop.i32(i32 %19115)
  %19117 = trunc i32 %19116 to i8
  %19118 = and i8 %19117, 1
  %19119 = xor i8 %19118, 1
  store i8 %19119, i8* %18, align 1
  %19120 = xor i64 %19099, 16
  %19121 = xor i64 %19120, %19111
  %19122 = lshr i64 %19121, 4
  %19123 = trunc i64 %19122 to i8
  %19124 = and i8 %19123, 1
  store i8 %19124, i8* %19, align 1
  %19125 = icmp eq i64 %19111, 0
  %19126 = zext i1 %19125 to i8
  store i8 %19126, i8* %20, align 1
  %19127 = lshr i64 %19111, 63
  %19128 = trunc i64 %19127 to i8
  store i8 %19128, i8* %21, align 1
  %19129 = lshr i64 %19099, 63
  %19130 = xor i64 %19127, %19129
  %19131 = add nuw nsw i64 %19130, %19127
  %19132 = icmp eq i64 %19131, 2
  %19133 = zext i1 %19132 to i8
  store i8 %19133, i8* %22, align 1
  %19134 = add i64 %19105, -40
  %19135 = add i64 %19098, 40
  store i64 %19135, i64* %3, align 8
  %19136 = inttoptr i64 %19134 to i32*
  %19137 = load i32, i32* %19136, align 4
  %19138 = sext i32 %19137 to i64
  %19139 = shl nsw i64 %19138, 9
  store i64 %19139, i64* %RDI.i6998, align 8
  %19140 = add i64 %19139, %19111
  store i64 %19140, i64* %RSI.i2015, align 8
  %19141 = icmp ult i64 %19140, %19111
  %19142 = icmp ult i64 %19140, %19139
  %19143 = or i1 %19141, %19142
  %19144 = zext i1 %19143 to i8
  store i8 %19144, i8* %17, align 1
  %19145 = trunc i64 %19140 to i32
  %19146 = and i32 %19145, 255
  %19147 = tail call i32 @llvm.ctpop.i32(i32 %19146)
  %19148 = trunc i32 %19147 to i8
  %19149 = and i8 %19148, 1
  %19150 = xor i8 %19149, 1
  store i8 %19150, i8* %18, align 1
  %19151 = xor i64 %19111, %19140
  %19152 = lshr i64 %19151, 4
  %19153 = trunc i64 %19152 to i8
  %19154 = and i8 %19153, 1
  store i8 %19154, i8* %19, align 1
  %19155 = icmp eq i64 %19140, 0
  %19156 = zext i1 %19155 to i8
  store i8 %19156, i8* %20, align 1
  %19157 = lshr i64 %19140, 63
  %19158 = trunc i64 %19157 to i8
  store i8 %19158, i8* %21, align 1
  %19159 = lshr i64 %19138, 54
  %19160 = and i64 %19159, 1
  %19161 = xor i64 %19157, %19127
  %19162 = xor i64 %19157, %19160
  %19163 = add nuw nsw i64 %19161, %19162
  %19164 = icmp eq i64 %19163, 2
  %19165 = zext i1 %19164 to i8
  store i8 %19165, i8* %22, align 1
  %19166 = load i64, i64* %RBP.i, align 8
  %19167 = add i64 %19166, -48
  %19168 = add i64 %19098, 51
  store i64 %19168, i64* %3, align 8
  %19169 = inttoptr i64 %19167 to i32*
  %19170 = load i32, i32* %19169, align 4
  %19171 = sext i32 %19170 to i64
  %19172 = shl nsw i64 %19171, 5
  store i64 %19172, i64* %RDI.i6998, align 8
  %19173 = add i64 %19172, %19140
  store i64 %19173, i64* %RSI.i2015, align 8
  %19174 = icmp ult i64 %19173, %19140
  %19175 = icmp ult i64 %19173, %19172
  %19176 = or i1 %19174, %19175
  %19177 = zext i1 %19176 to i8
  store i8 %19177, i8* %17, align 1
  %19178 = trunc i64 %19173 to i32
  %19179 = and i32 %19178, 255
  %19180 = tail call i32 @llvm.ctpop.i32(i32 %19179)
  %19181 = trunc i32 %19180 to i8
  %19182 = and i8 %19181, 1
  %19183 = xor i8 %19182, 1
  store i8 %19183, i8* %18, align 1
  %19184 = xor i64 %19140, %19173
  %19185 = lshr i64 %19184, 4
  %19186 = trunc i64 %19185 to i8
  %19187 = and i8 %19186, 1
  store i8 %19187, i8* %19, align 1
  %19188 = icmp eq i64 %19173, 0
  %19189 = zext i1 %19188 to i8
  store i8 %19189, i8* %20, align 1
  %19190 = lshr i64 %19173, 63
  %19191 = trunc i64 %19190 to i8
  store i8 %19191, i8* %21, align 1
  %19192 = lshr i64 %19171, 58
  %19193 = and i64 %19192, 1
  %19194 = xor i64 %19190, %19157
  %19195 = xor i64 %19190, %19193
  %19196 = add nuw nsw i64 %19194, %19195
  %19197 = icmp eq i64 %19196, 2
  %19198 = zext i1 %19197 to i8
  store i8 %19198, i8* %22, align 1
  %19199 = add i64 %19166, -44
  %19200 = add i64 %19098, 62
  store i64 %19200, i64* %3, align 8
  %19201 = inttoptr i64 %19199 to i32*
  %19202 = load i32, i32* %19201, align 4
  %19203 = sext i32 %19202 to i64
  store i64 %19203, i64* %RDI.i6998, align 8
  %19204 = shl nsw i64 %19203, 1
  %19205 = add i64 %19204, %19173
  %19206 = add i64 %19098, 67
  store i64 %19206, i64* %3, align 8
  %19207 = inttoptr i64 %19205 to i16*
  %19208 = load i16, i16* %19207, align 2
  %19209 = zext i16 %19208 to i64
  store i64 %19209, i64* %R9.i1633, align 8
  %19210 = load i32, i32* %R8D.i1615, align 4
  %19211 = zext i16 %19208 to i32
  %19212 = add i32 %19211, %19210
  %19213 = zext i32 %19212 to i64
  store i64 %19213, i64* %25, align 8
  %19214 = lshr i32 %19212, 31
  %19215 = load i32, i32* %ECX.i6962, align 4
  %19216 = sub i32 %19215, %19212
  %19217 = icmp ult i32 %19215, %19212
  %19218 = zext i1 %19217 to i8
  store i8 %19218, i8* %17, align 1
  %19219 = and i32 %19216, 255
  %19220 = tail call i32 @llvm.ctpop.i32(i32 %19219)
  %19221 = trunc i32 %19220 to i8
  %19222 = and i8 %19221, 1
  %19223 = xor i8 %19222, 1
  store i8 %19223, i8* %18, align 1
  %19224 = xor i32 %19212, %19215
  %19225 = xor i32 %19224, %19216
  %19226 = lshr i32 %19225, 4
  %19227 = trunc i32 %19226 to i8
  %19228 = and i8 %19227, 1
  store i8 %19228, i8* %19, align 1
  %19229 = icmp eq i32 %19216, 0
  %19230 = zext i1 %19229 to i8
  store i8 %19230, i8* %20, align 1
  %19231 = lshr i32 %19216, 31
  %19232 = trunc i32 %19231 to i8
  store i8 %19232, i8* %21, align 1
  %19233 = lshr i32 %19215, 31
  %19234 = xor i32 %19214, %19233
  %19235 = xor i32 %19231, %19233
  %19236 = add nuw nsw i32 %19235, %19234
  %19237 = icmp eq i32 %19236, 2
  %19238 = zext i1 %19237 to i8
  store i8 %19238, i8* %22, align 1
  %19239 = load i64, i64* %RBP.i, align 8
  %19240 = add i64 %19239, -756
  %19241 = load i32, i32* %EAX.i2033, align 4
  %19242 = add i64 %19098, 79
  store i64 %19242, i64* %3, align 8
  %19243 = inttoptr i64 %19240 to i32*
  store i32 %19241, i32* %19243, align 4
  %19244 = load i64, i64* %3, align 8
  %19245 = load i8, i8* %20, align 1
  %19246 = icmp ne i8 %19245, 0
  %19247 = load i8, i8* %21, align 1
  %19248 = icmp ne i8 %19247, 0
  %19249 = load i8, i8* %22, align 1
  %19250 = icmp ne i8 %19249, 0
  %19251 = xor i1 %19248, %19250
  %19252 = or i1 %19246, %19251
  %.v876 = select i1 %19252, i64 19, i64 6
  %19253 = add i64 %19244, %.v876
  store i64 %19253, i64* %3, align 8
  br i1 %19252, label %block_.L_4863a6, label %block_486399

block_486399:                                     ; preds = %block_.L_486307
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %19254 = load i64, i64* %RBP.i, align 8
  %19255 = add i64 %19254, -760
  %19256 = add i64 %19253, 8
  store i64 %19256, i64* %3, align 8
  %19257 = inttoptr i64 %19255 to i32*
  store i32 0, i32* %19257, align 4
  %19258 = load i64, i64* %3, align 8
  %19259 = add i64 %19258, 64
  store i64 %19259, i64* %3, align 8
  br label %block_.L_4863e1

block_.L_4863a6:                                  ; preds = %block_.L_486307
  %19260 = load i64, i64* %RBP.i, align 8
  %19261 = add i64 %19260, -344
  %19262 = add i64 %19253, 6
  store i64 %19262, i64* %3, align 8
  %19263 = inttoptr i64 %19261 to i32*
  %19264 = load i32, i32* %19263, align 4
  %19265 = zext i32 %19264 to i64
  store i64 %19265, i64* %RAX.i1659, align 8
  %19266 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %19267 = add i64 %19266, 184
  store i64 %19267, i64* %RCX.i1588, align 8
  %19268 = icmp ugt i64 %19266, -185
  %19269 = zext i1 %19268 to i8
  store i8 %19269, i8* %17, align 1
  %19270 = trunc i64 %19267 to i32
  %19271 = and i32 %19270, 255
  %19272 = tail call i32 @llvm.ctpop.i32(i32 %19271)
  %19273 = trunc i32 %19272 to i8
  %19274 = and i8 %19273, 1
  %19275 = xor i8 %19274, 1
  store i8 %19275, i8* %18, align 1
  %19276 = xor i64 %19266, 16
  %19277 = xor i64 %19276, %19267
  %19278 = lshr i64 %19277, 4
  %19279 = trunc i64 %19278 to i8
  %19280 = and i8 %19279, 1
  store i8 %19280, i8* %19, align 1
  %19281 = icmp eq i64 %19267, 0
  %19282 = zext i1 %19281 to i8
  store i8 %19282, i8* %20, align 1
  %19283 = lshr i64 %19267, 63
  %19284 = trunc i64 %19283 to i8
  store i8 %19284, i8* %21, align 1
  %19285 = lshr i64 %19266, 63
  %19286 = xor i64 %19283, %19285
  %19287 = add nuw nsw i64 %19286, %19283
  %19288 = icmp eq i64 %19287, 2
  %19289 = zext i1 %19288 to i8
  store i8 %19289, i8* %22, align 1
  %19290 = add i64 %19260, -40
  %19291 = add i64 %19253, 25
  store i64 %19291, i64* %3, align 8
  %19292 = inttoptr i64 %19290 to i32*
  %19293 = load i32, i32* %19292, align 4
  %19294 = sext i32 %19293 to i64
  %19295 = shl nsw i64 %19294, 9
  store i64 %19295, i64* %RDX.i1943, align 8
  %19296 = add i64 %19295, %19267
  store i64 %19296, i64* %RCX.i1588, align 8
  %19297 = icmp ult i64 %19296, %19267
  %19298 = icmp ult i64 %19296, %19295
  %19299 = or i1 %19297, %19298
  %19300 = zext i1 %19299 to i8
  store i8 %19300, i8* %17, align 1
  %19301 = trunc i64 %19296 to i32
  %19302 = and i32 %19301, 255
  %19303 = tail call i32 @llvm.ctpop.i32(i32 %19302)
  %19304 = trunc i32 %19303 to i8
  %19305 = and i8 %19304, 1
  %19306 = xor i8 %19305, 1
  store i8 %19306, i8* %18, align 1
  %19307 = xor i64 %19267, %19296
  %19308 = lshr i64 %19307, 4
  %19309 = trunc i64 %19308 to i8
  %19310 = and i8 %19309, 1
  store i8 %19310, i8* %19, align 1
  %19311 = icmp eq i64 %19296, 0
  %19312 = zext i1 %19311 to i8
  store i8 %19312, i8* %20, align 1
  %19313 = lshr i64 %19296, 63
  %19314 = trunc i64 %19313 to i8
  store i8 %19314, i8* %21, align 1
  %19315 = lshr i64 %19294, 54
  %19316 = and i64 %19315, 1
  %19317 = xor i64 %19313, %19283
  %19318 = xor i64 %19313, %19316
  %19319 = add nuw nsw i64 %19317, %19318
  %19320 = icmp eq i64 %19319, 2
  %19321 = zext i1 %19320 to i8
  store i8 %19321, i8* %22, align 1
  %19322 = load i64, i64* %RBP.i, align 8
  %19323 = add i64 %19322, -48
  %19324 = add i64 %19253, 36
  store i64 %19324, i64* %3, align 8
  %19325 = inttoptr i64 %19323 to i32*
  %19326 = load i32, i32* %19325, align 4
  %19327 = sext i32 %19326 to i64
  %19328 = shl nsw i64 %19327, 5
  store i64 %19328, i64* %RDX.i1943, align 8
  %19329 = add i64 %19328, %19296
  store i64 %19329, i64* %RCX.i1588, align 8
  %19330 = icmp ult i64 %19329, %19296
  %19331 = icmp ult i64 %19329, %19328
  %19332 = or i1 %19330, %19331
  %19333 = zext i1 %19332 to i8
  store i8 %19333, i8* %17, align 1
  %19334 = trunc i64 %19329 to i32
  %19335 = and i32 %19334, 255
  %19336 = tail call i32 @llvm.ctpop.i32(i32 %19335)
  %19337 = trunc i32 %19336 to i8
  %19338 = and i8 %19337, 1
  %19339 = xor i8 %19338, 1
  store i8 %19339, i8* %18, align 1
  %19340 = xor i64 %19296, %19329
  %19341 = lshr i64 %19340, 4
  %19342 = trunc i64 %19341 to i8
  %19343 = and i8 %19342, 1
  store i8 %19343, i8* %19, align 1
  %19344 = icmp eq i64 %19329, 0
  %19345 = zext i1 %19344 to i8
  store i8 %19345, i8* %20, align 1
  %19346 = lshr i64 %19329, 63
  %19347 = trunc i64 %19346 to i8
  store i8 %19347, i8* %21, align 1
  %19348 = lshr i64 %19327, 58
  %19349 = and i64 %19348, 1
  %19350 = xor i64 %19346, %19313
  %19351 = xor i64 %19346, %19349
  %19352 = add nuw nsw i64 %19350, %19351
  %19353 = icmp eq i64 %19352, 2
  %19354 = zext i1 %19353 to i8
  store i8 %19354, i8* %22, align 1
  %19355 = add i64 %19322, -44
  %19356 = add i64 %19253, 47
  store i64 %19356, i64* %3, align 8
  %19357 = inttoptr i64 %19355 to i32*
  %19358 = load i32, i32* %19357, align 4
  %19359 = sext i32 %19358 to i64
  store i64 %19359, i64* %RDX.i1943, align 8
  %19360 = shl nsw i64 %19359, 1
  %19361 = add i64 %19360, %19329
  %19362 = add i64 %19253, 51
  store i64 %19362, i64* %3, align 8
  %19363 = inttoptr i64 %19361 to i16*
  %19364 = load i16, i16* %19363, align 2
  %19365 = zext i16 %19364 to i64
  store i64 %19365, i64* %RSI.i2015, align 8
  %19366 = load i64, i64* %RAX.i1659, align 8
  %19367 = zext i16 %19364 to i32
  %19368 = zext i16 %19364 to i64
  %19369 = trunc i64 %19366 to i32
  %19370 = add i32 %19367, %19369
  %19371 = zext i32 %19370 to i64
  store i64 %19371, i64* %RAX.i1659, align 8
  %19372 = icmp ult i32 %19370, %19369
  %19373 = icmp ult i32 %19370, %19367
  %19374 = or i1 %19372, %19373
  %19375 = zext i1 %19374 to i8
  store i8 %19375, i8* %17, align 1
  %19376 = and i32 %19370, 255
  %19377 = tail call i32 @llvm.ctpop.i32(i32 %19376)
  %19378 = trunc i32 %19377 to i8
  %19379 = and i8 %19378, 1
  %19380 = xor i8 %19379, 1
  store i8 %19380, i8* %18, align 1
  %19381 = xor i64 %19368, %19366
  %19382 = trunc i64 %19381 to i32
  %19383 = xor i32 %19382, %19370
  %19384 = lshr i32 %19383, 4
  %19385 = trunc i32 %19384 to i8
  %19386 = and i8 %19385, 1
  store i8 %19386, i8* %19, align 1
  %19387 = icmp eq i32 %19370, 0
  %19388 = zext i1 %19387 to i8
  store i8 %19388, i8* %20, align 1
  %19389 = lshr i32 %19370, 31
  %19390 = trunc i32 %19389 to i8
  store i8 %19390, i8* %21, align 1
  %19391 = lshr i32 %19369, 31
  %19392 = xor i32 %19389, %19391
  %19393 = add nuw nsw i32 %19392, %19389
  %19394 = icmp eq i32 %19393, 2
  %19395 = zext i1 %19394 to i8
  store i8 %19395, i8* %22, align 1
  %19396 = load i64, i64* %RBP.i, align 8
  %19397 = add i64 %19396, -760
  %19398 = add i64 %19253, 59
  store i64 %19398, i64* %3, align 8
  %19399 = inttoptr i64 %19397 to i32*
  store i32 %19370, i32* %19399, align 4
  %.pre541 = load i64, i64* %3, align 8
  br label %block_.L_4863e1

block_.L_4863e1:                                  ; preds = %block_.L_4863a6, %block_486399
  %19400 = phi i64 [ %.pre541, %block_.L_4863a6 ], [ %19259, %block_486399 ]
  %19401 = load i64, i64* %RBP.i, align 8
  %19402 = add i64 %19401, -760
  %19403 = add i64 %19400, 6
  store i64 %19403, i64* %3, align 8
  %19404 = inttoptr i64 %19402 to i32*
  %19405 = load i32, i32* %19404, align 4
  %19406 = zext i32 %19405 to i64
  store i64 %19406, i64* %RAX.i1659, align 8
  %19407 = add i64 %19401, -756
  %19408 = add i64 %19400, 12
  store i64 %19408, i64* %3, align 8
  %19409 = inttoptr i64 %19407 to i32*
  %19410 = load i32, i32* %19409, align 4
  %19411 = zext i32 %19410 to i64
  store i64 %19411, i64* %RCX.i1588, align 8
  %19412 = sub i32 %19410, %19405
  %19413 = icmp ult i32 %19410, %19405
  %19414 = zext i1 %19413 to i8
  store i8 %19414, i8* %17, align 1
  %19415 = and i32 %19412, 255
  %19416 = tail call i32 @llvm.ctpop.i32(i32 %19415)
  %19417 = trunc i32 %19416 to i8
  %19418 = and i8 %19417, 1
  %19419 = xor i8 %19418, 1
  store i8 %19419, i8* %18, align 1
  %19420 = xor i32 %19405, %19410
  %19421 = xor i32 %19420, %19412
  %19422 = lshr i32 %19421, 4
  %19423 = trunc i32 %19422 to i8
  %19424 = and i8 %19423, 1
  store i8 %19424, i8* %19, align 1
  %19425 = icmp eq i32 %19412, 0
  %19426 = zext i1 %19425 to i8
  store i8 %19426, i8* %20, align 1
  %19427 = lshr i32 %19412, 31
  %19428 = trunc i32 %19427 to i8
  store i8 %19428, i8* %21, align 1
  %19429 = lshr i32 %19410, 31
  %19430 = lshr i32 %19405, 31
  %19431 = xor i32 %19430, %19429
  %19432 = xor i32 %19427, %19429
  %19433 = add nuw nsw i32 %19432, %19431
  %19434 = icmp eq i32 %19433, 2
  %19435 = zext i1 %19434 to i8
  store i8 %19435, i8* %22, align 1
  %19436 = icmp ne i8 %19428, 0
  %19437 = xor i1 %19436, %19434
  %.v718 = select i1 %19437, i64 20, i64 45
  %19438 = add i64 %19400, %.v718
  store i64 %19438, i64* %3, align 8
  br i1 %19437, label %block_4863f5, label %block_.L_48640e

block_4863f5:                                     ; preds = %block_.L_4863e1
  %19439 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %19439, i64* %RAX.i1659, align 8
  %19440 = add i64 %19439, 72684
  %19441 = add i64 %19438, 14
  store i64 %19441, i64* %3, align 8
  %19442 = inttoptr i64 %19440 to i32*
  %19443 = load i32, i32* %19442, align 4
  %19444 = zext i32 %19443 to i64
  store i64 %19444, i64* %RCX.i1588, align 8
  %19445 = add i64 %19401, -764
  %19446 = add i64 %19438, 20
  store i64 %19446, i64* %3, align 8
  %19447 = inttoptr i64 %19445 to i32*
  store i32 %19443, i32* %19447, align 4
  %19448 = load i64, i64* %3, align 8
  %19449 = add i64 %19448, 152
  store i64 %19449, i64* %3, align 8
  br label %block_.L_4864a1

block_.L_48640e:                                  ; preds = %block_.L_4863e1
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %19450 = add i64 %19401, -344
  %19451 = add i64 %19438, 8
  store i64 %19451, i64* %3, align 8
  %19452 = inttoptr i64 %19450 to i32*
  %19453 = load i32, i32* %19452, align 4
  %19454 = zext i32 %19453 to i64
  store i64 %19454, i64* %RCX.i1588, align 8
  %19455 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %19456 = add i64 %19455, 184
  store i64 %19456, i64* %RDX.i1943, align 8
  %19457 = icmp ugt i64 %19455, -185
  %19458 = zext i1 %19457 to i8
  store i8 %19458, i8* %17, align 1
  %19459 = trunc i64 %19456 to i32
  %19460 = and i32 %19459, 255
  %19461 = tail call i32 @llvm.ctpop.i32(i32 %19460)
  %19462 = trunc i32 %19461 to i8
  %19463 = and i8 %19462, 1
  %19464 = xor i8 %19463, 1
  store i8 %19464, i8* %18, align 1
  %19465 = xor i64 %19455, 16
  %19466 = xor i64 %19465, %19456
  %19467 = lshr i64 %19466, 4
  %19468 = trunc i64 %19467 to i8
  %19469 = and i8 %19468, 1
  store i8 %19469, i8* %19, align 1
  %19470 = icmp eq i64 %19456, 0
  %19471 = zext i1 %19470 to i8
  store i8 %19471, i8* %20, align 1
  %19472 = lshr i64 %19456, 63
  %19473 = trunc i64 %19472 to i8
  store i8 %19473, i8* %21, align 1
  %19474 = lshr i64 %19455, 63
  %19475 = xor i64 %19472, %19474
  %19476 = add nuw nsw i64 %19475, %19472
  %19477 = icmp eq i64 %19476, 2
  %19478 = zext i1 %19477 to i8
  store i8 %19478, i8* %22, align 1
  %19479 = add i64 %19401, -40
  %19480 = add i64 %19438, 27
  store i64 %19480, i64* %3, align 8
  %19481 = inttoptr i64 %19479 to i32*
  %19482 = load i32, i32* %19481, align 4
  %19483 = sext i32 %19482 to i64
  %19484 = shl nsw i64 %19483, 9
  store i64 %19484, i64* %RSI.i2015, align 8
  %19485 = add i64 %19484, %19456
  store i64 %19485, i64* %RDX.i1943, align 8
  %19486 = icmp ult i64 %19485, %19456
  %19487 = icmp ult i64 %19485, %19484
  %19488 = or i1 %19486, %19487
  %19489 = zext i1 %19488 to i8
  store i8 %19489, i8* %17, align 1
  %19490 = trunc i64 %19485 to i32
  %19491 = and i32 %19490, 255
  %19492 = tail call i32 @llvm.ctpop.i32(i32 %19491)
  %19493 = trunc i32 %19492 to i8
  %19494 = and i8 %19493, 1
  %19495 = xor i8 %19494, 1
  store i8 %19495, i8* %18, align 1
  %19496 = xor i64 %19456, %19485
  %19497 = lshr i64 %19496, 4
  %19498 = trunc i64 %19497 to i8
  %19499 = and i8 %19498, 1
  store i8 %19499, i8* %19, align 1
  %19500 = icmp eq i64 %19485, 0
  %19501 = zext i1 %19500 to i8
  store i8 %19501, i8* %20, align 1
  %19502 = lshr i64 %19485, 63
  %19503 = trunc i64 %19502 to i8
  store i8 %19503, i8* %21, align 1
  %19504 = lshr i64 %19483, 54
  %19505 = and i64 %19504, 1
  %19506 = xor i64 %19502, %19472
  %19507 = xor i64 %19502, %19505
  %19508 = add nuw nsw i64 %19506, %19507
  %19509 = icmp eq i64 %19508, 2
  %19510 = zext i1 %19509 to i8
  store i8 %19510, i8* %22, align 1
  %19511 = load i64, i64* %RBP.i, align 8
  %19512 = add i64 %19511, -48
  %19513 = add i64 %19438, 38
  store i64 %19513, i64* %3, align 8
  %19514 = inttoptr i64 %19512 to i32*
  %19515 = load i32, i32* %19514, align 4
  %19516 = sext i32 %19515 to i64
  %19517 = shl nsw i64 %19516, 5
  store i64 %19517, i64* %RSI.i2015, align 8
  %19518 = add i64 %19517, %19485
  store i64 %19518, i64* %RDX.i1943, align 8
  %19519 = icmp ult i64 %19518, %19485
  %19520 = icmp ult i64 %19518, %19517
  %19521 = or i1 %19519, %19520
  %19522 = zext i1 %19521 to i8
  store i8 %19522, i8* %17, align 1
  %19523 = trunc i64 %19518 to i32
  %19524 = and i32 %19523, 255
  %19525 = tail call i32 @llvm.ctpop.i32(i32 %19524)
  %19526 = trunc i32 %19525 to i8
  %19527 = and i8 %19526, 1
  %19528 = xor i8 %19527, 1
  store i8 %19528, i8* %18, align 1
  %19529 = xor i64 %19485, %19518
  %19530 = lshr i64 %19529, 4
  %19531 = trunc i64 %19530 to i8
  %19532 = and i8 %19531, 1
  store i8 %19532, i8* %19, align 1
  %19533 = icmp eq i64 %19518, 0
  %19534 = zext i1 %19533 to i8
  store i8 %19534, i8* %20, align 1
  %19535 = lshr i64 %19518, 63
  %19536 = trunc i64 %19535 to i8
  store i8 %19536, i8* %21, align 1
  %19537 = lshr i64 %19516, 58
  %19538 = and i64 %19537, 1
  %19539 = xor i64 %19535, %19502
  %19540 = xor i64 %19535, %19538
  %19541 = add nuw nsw i64 %19539, %19540
  %19542 = icmp eq i64 %19541, 2
  %19543 = zext i1 %19542 to i8
  store i8 %19543, i8* %22, align 1
  %19544 = add i64 %19511, -44
  %19545 = add i64 %19438, 49
  store i64 %19545, i64* %3, align 8
  %19546 = inttoptr i64 %19544 to i32*
  %19547 = load i32, i32* %19546, align 4
  %19548 = sext i32 %19547 to i64
  store i64 %19548, i64* %RSI.i2015, align 8
  %19549 = shl nsw i64 %19548, 1
  %19550 = add i64 %19549, %19518
  %19551 = add i64 %19438, 53
  store i64 %19551, i64* %3, align 8
  %19552 = inttoptr i64 %19550 to i16*
  %19553 = load i16, i16* %19552, align 2
  %19554 = zext i16 %19553 to i64
  store i64 %19554, i64* %RDI.i6998, align 8
  %19555 = load i64, i64* %RCX.i1588, align 8
  %19556 = zext i16 %19553 to i32
  %19557 = trunc i64 %19555 to i32
  %19558 = add i32 %19556, %19557
  %19559 = zext i32 %19558 to i64
  store i64 %19559, i64* %RCX.i1588, align 8
  %19560 = lshr i32 %19558, 31
  %19561 = load i32, i32* %EAX.i2033, align 4
  %19562 = sub i32 %19561, %19558
  %19563 = icmp ult i32 %19561, %19558
  %19564 = zext i1 %19563 to i8
  store i8 %19564, i8* %17, align 1
  %19565 = and i32 %19562, 255
  %19566 = tail call i32 @llvm.ctpop.i32(i32 %19565)
  %19567 = trunc i32 %19566 to i8
  %19568 = and i8 %19567, 1
  %19569 = xor i8 %19568, 1
  store i8 %19569, i8* %18, align 1
  %19570 = xor i32 %19558, %19561
  %19571 = xor i32 %19570, %19562
  %19572 = lshr i32 %19571, 4
  %19573 = trunc i32 %19572 to i8
  %19574 = and i8 %19573, 1
  store i8 %19574, i8* %19, align 1
  %19575 = icmp eq i32 %19562, 0
  %19576 = zext i1 %19575 to i8
  store i8 %19576, i8* %20, align 1
  %19577 = lshr i32 %19562, 31
  %19578 = trunc i32 %19577 to i8
  store i8 %19578, i8* %21, align 1
  %19579 = lshr i32 %19561, 31
  %19580 = xor i32 %19560, %19579
  %19581 = xor i32 %19577, %19579
  %19582 = add nuw nsw i32 %19581, %19580
  %19583 = icmp eq i32 %19582, 2
  %19584 = zext i1 %19583 to i8
  store i8 %19584, i8* %22, align 1
  %19585 = icmp ne i8 %19578, 0
  %19586 = xor i1 %19585, %19583
  %19587 = or i1 %19575, %19586
  %.v719 = select i1 %19587, i64 76, i64 63
  %19588 = add i64 %19438, %.v719
  store i64 %19588, i64* %3, align 8
  br i1 %19587, label %block_.L_48645a, label %block_48644d

block_48644d:                                     ; preds = %block_.L_48640e
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %19589 = load i64, i64* %RBP.i, align 8
  %19590 = add i64 %19589, -768
  %19591 = add i64 %19588, 8
  store i64 %19591, i64* %3, align 8
  %19592 = inttoptr i64 %19590 to i32*
  store i32 0, i32* %19592, align 4
  %19593 = load i64, i64* %3, align 8
  %19594 = add i64 %19593, 64
  store i64 %19594, i64* %3, align 8
  br label %block_.L_486495

block_.L_48645a:                                  ; preds = %block_.L_48640e
  %19595 = load i64, i64* %RBP.i, align 8
  %19596 = add i64 %19595, -344
  %19597 = add i64 %19588, 6
  store i64 %19597, i64* %3, align 8
  %19598 = inttoptr i64 %19596 to i32*
  %19599 = load i32, i32* %19598, align 4
  %19600 = zext i32 %19599 to i64
  store i64 %19600, i64* %RAX.i1659, align 8
  %19601 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %19602 = add i64 %19601, 184
  store i64 %19602, i64* %RCX.i1588, align 8
  %19603 = icmp ugt i64 %19601, -185
  %19604 = zext i1 %19603 to i8
  store i8 %19604, i8* %17, align 1
  %19605 = trunc i64 %19602 to i32
  %19606 = and i32 %19605, 255
  %19607 = tail call i32 @llvm.ctpop.i32(i32 %19606)
  %19608 = trunc i32 %19607 to i8
  %19609 = and i8 %19608, 1
  %19610 = xor i8 %19609, 1
  store i8 %19610, i8* %18, align 1
  %19611 = xor i64 %19601, 16
  %19612 = xor i64 %19611, %19602
  %19613 = lshr i64 %19612, 4
  %19614 = trunc i64 %19613 to i8
  %19615 = and i8 %19614, 1
  store i8 %19615, i8* %19, align 1
  %19616 = icmp eq i64 %19602, 0
  %19617 = zext i1 %19616 to i8
  store i8 %19617, i8* %20, align 1
  %19618 = lshr i64 %19602, 63
  %19619 = trunc i64 %19618 to i8
  store i8 %19619, i8* %21, align 1
  %19620 = lshr i64 %19601, 63
  %19621 = xor i64 %19618, %19620
  %19622 = add nuw nsw i64 %19621, %19618
  %19623 = icmp eq i64 %19622, 2
  %19624 = zext i1 %19623 to i8
  store i8 %19624, i8* %22, align 1
  %19625 = add i64 %19595, -40
  %19626 = add i64 %19588, 25
  store i64 %19626, i64* %3, align 8
  %19627 = inttoptr i64 %19625 to i32*
  %19628 = load i32, i32* %19627, align 4
  %19629 = sext i32 %19628 to i64
  %19630 = shl nsw i64 %19629, 9
  store i64 %19630, i64* %RDX.i1943, align 8
  %19631 = add i64 %19630, %19602
  store i64 %19631, i64* %RCX.i1588, align 8
  %19632 = icmp ult i64 %19631, %19602
  %19633 = icmp ult i64 %19631, %19630
  %19634 = or i1 %19632, %19633
  %19635 = zext i1 %19634 to i8
  store i8 %19635, i8* %17, align 1
  %19636 = trunc i64 %19631 to i32
  %19637 = and i32 %19636, 255
  %19638 = tail call i32 @llvm.ctpop.i32(i32 %19637)
  %19639 = trunc i32 %19638 to i8
  %19640 = and i8 %19639, 1
  %19641 = xor i8 %19640, 1
  store i8 %19641, i8* %18, align 1
  %19642 = xor i64 %19602, %19631
  %19643 = lshr i64 %19642, 4
  %19644 = trunc i64 %19643 to i8
  %19645 = and i8 %19644, 1
  store i8 %19645, i8* %19, align 1
  %19646 = icmp eq i64 %19631, 0
  %19647 = zext i1 %19646 to i8
  store i8 %19647, i8* %20, align 1
  %19648 = lshr i64 %19631, 63
  %19649 = trunc i64 %19648 to i8
  store i8 %19649, i8* %21, align 1
  %19650 = lshr i64 %19629, 54
  %19651 = and i64 %19650, 1
  %19652 = xor i64 %19648, %19618
  %19653 = xor i64 %19648, %19651
  %19654 = add nuw nsw i64 %19652, %19653
  %19655 = icmp eq i64 %19654, 2
  %19656 = zext i1 %19655 to i8
  store i8 %19656, i8* %22, align 1
  %19657 = load i64, i64* %RBP.i, align 8
  %19658 = add i64 %19657, -48
  %19659 = add i64 %19588, 36
  store i64 %19659, i64* %3, align 8
  %19660 = inttoptr i64 %19658 to i32*
  %19661 = load i32, i32* %19660, align 4
  %19662 = sext i32 %19661 to i64
  %19663 = shl nsw i64 %19662, 5
  store i64 %19663, i64* %RDX.i1943, align 8
  %19664 = add i64 %19663, %19631
  store i64 %19664, i64* %RCX.i1588, align 8
  %19665 = icmp ult i64 %19664, %19631
  %19666 = icmp ult i64 %19664, %19663
  %19667 = or i1 %19665, %19666
  %19668 = zext i1 %19667 to i8
  store i8 %19668, i8* %17, align 1
  %19669 = trunc i64 %19664 to i32
  %19670 = and i32 %19669, 255
  %19671 = tail call i32 @llvm.ctpop.i32(i32 %19670)
  %19672 = trunc i32 %19671 to i8
  %19673 = and i8 %19672, 1
  %19674 = xor i8 %19673, 1
  store i8 %19674, i8* %18, align 1
  %19675 = xor i64 %19631, %19664
  %19676 = lshr i64 %19675, 4
  %19677 = trunc i64 %19676 to i8
  %19678 = and i8 %19677, 1
  store i8 %19678, i8* %19, align 1
  %19679 = icmp eq i64 %19664, 0
  %19680 = zext i1 %19679 to i8
  store i8 %19680, i8* %20, align 1
  %19681 = lshr i64 %19664, 63
  %19682 = trunc i64 %19681 to i8
  store i8 %19682, i8* %21, align 1
  %19683 = lshr i64 %19662, 58
  %19684 = and i64 %19683, 1
  %19685 = xor i64 %19681, %19648
  %19686 = xor i64 %19681, %19684
  %19687 = add nuw nsw i64 %19685, %19686
  %19688 = icmp eq i64 %19687, 2
  %19689 = zext i1 %19688 to i8
  store i8 %19689, i8* %22, align 1
  %19690 = add i64 %19657, -44
  %19691 = add i64 %19588, 47
  store i64 %19691, i64* %3, align 8
  %19692 = inttoptr i64 %19690 to i32*
  %19693 = load i32, i32* %19692, align 4
  %19694 = sext i32 %19693 to i64
  store i64 %19694, i64* %RDX.i1943, align 8
  %19695 = shl nsw i64 %19694, 1
  %19696 = add i64 %19695, %19664
  %19697 = add i64 %19588, 51
  store i64 %19697, i64* %3, align 8
  %19698 = inttoptr i64 %19696 to i16*
  %19699 = load i16, i16* %19698, align 2
  %19700 = zext i16 %19699 to i64
  store i64 %19700, i64* %RSI.i2015, align 8
  %19701 = load i64, i64* %RAX.i1659, align 8
  %19702 = zext i16 %19699 to i32
  %19703 = zext i16 %19699 to i64
  %19704 = trunc i64 %19701 to i32
  %19705 = add i32 %19702, %19704
  %19706 = zext i32 %19705 to i64
  store i64 %19706, i64* %RAX.i1659, align 8
  %19707 = icmp ult i32 %19705, %19704
  %19708 = icmp ult i32 %19705, %19702
  %19709 = or i1 %19707, %19708
  %19710 = zext i1 %19709 to i8
  store i8 %19710, i8* %17, align 1
  %19711 = and i32 %19705, 255
  %19712 = tail call i32 @llvm.ctpop.i32(i32 %19711)
  %19713 = trunc i32 %19712 to i8
  %19714 = and i8 %19713, 1
  %19715 = xor i8 %19714, 1
  store i8 %19715, i8* %18, align 1
  %19716 = xor i64 %19703, %19701
  %19717 = trunc i64 %19716 to i32
  %19718 = xor i32 %19717, %19705
  %19719 = lshr i32 %19718, 4
  %19720 = trunc i32 %19719 to i8
  %19721 = and i8 %19720, 1
  store i8 %19721, i8* %19, align 1
  %19722 = icmp eq i32 %19705, 0
  %19723 = zext i1 %19722 to i8
  store i8 %19723, i8* %20, align 1
  %19724 = lshr i32 %19705, 31
  %19725 = trunc i32 %19724 to i8
  store i8 %19725, i8* %21, align 1
  %19726 = lshr i32 %19704, 31
  %19727 = xor i32 %19724, %19726
  %19728 = add nuw nsw i32 %19727, %19724
  %19729 = icmp eq i32 %19728, 2
  %19730 = zext i1 %19729 to i8
  store i8 %19730, i8* %22, align 1
  %19731 = load i64, i64* %RBP.i, align 8
  %19732 = add i64 %19731, -768
  %19733 = add i64 %19588, 59
  store i64 %19733, i64* %3, align 8
  %19734 = inttoptr i64 %19732 to i32*
  store i32 %19705, i32* %19734, align 4
  %.pre542 = load i64, i64* %3, align 8
  br label %block_.L_486495

block_.L_486495:                                  ; preds = %block_.L_48645a, %block_48644d
  %19735 = phi i64 [ %.pre542, %block_.L_48645a ], [ %19594, %block_48644d ]
  %19736 = load i64, i64* %RBP.i, align 8
  %19737 = add i64 %19736, -768
  %19738 = add i64 %19735, 6
  store i64 %19738, i64* %3, align 8
  %19739 = inttoptr i64 %19737 to i32*
  %19740 = load i32, i32* %19739, align 4
  %19741 = zext i32 %19740 to i64
  store i64 %19741, i64* %RAX.i1659, align 8
  %19742 = add i64 %19736, -764
  %19743 = add i64 %19735, 12
  store i64 %19743, i64* %3, align 8
  %19744 = inttoptr i64 %19742 to i32*
  store i32 %19740, i32* %19744, align 4
  %.pre543 = load i64, i64* %3, align 8
  br label %block_.L_4864a1

block_.L_4864a1:                                  ; preds = %block_.L_486495, %block_4863f5
  %19745 = phi i64 [ %.pre543, %block_.L_486495 ], [ %19449, %block_4863f5 ]
  %19746 = load i64, i64* %RBP.i, align 8
  %19747 = add i64 %19746, -764
  %19748 = add i64 %19745, 6
  store i64 %19748, i64* %3, align 8
  %19749 = inttoptr i64 %19747 to i32*
  %19750 = load i32, i32* %19749, align 4
  %19751 = zext i32 %19750 to i64
  store i64 %19751, i64* %RAX.i1659, align 8
  store i64 0, i64* %RCX.i1588, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %19752 = trunc i32 %19750 to i16
  store i16 %19752, i16* %DX.i4863, align 2
  %19753 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %19753, i64* %RSI.i2015, align 8
  %19754 = add i64 %19753, 6424
  %19755 = add i64 %19745, 26
  store i64 %19755, i64* %3, align 8
  %19756 = inttoptr i64 %19754 to i64*
  %19757 = load i64, i64* %19756, align 8
  store i64 %19757, i64* %RSI.i2015, align 8
  %19758 = add i64 %19746, -232
  %19759 = add i64 %19745, 32
  store i64 %19759, i64* %3, align 8
  %19760 = inttoptr i64 %19758 to i32*
  %19761 = load i32, i32* %19760, align 4
  %19762 = zext i32 %19761 to i64
  store i64 %19762, i64* %RAX.i1659, align 8
  %19763 = add i64 %19746, -48
  %19764 = add i64 %19745, 35
  store i64 %19764, i64* %3, align 8
  %19765 = inttoptr i64 %19763 to i32*
  %19766 = load i32, i32* %19765, align 4
  %19767 = add i32 %19766, %19761
  %19768 = zext i32 %19767 to i64
  store i64 %19768, i64* %RAX.i1659, align 8
  %19769 = icmp ult i32 %19767, %19761
  %19770 = icmp ult i32 %19767, %19766
  %19771 = or i1 %19769, %19770
  %19772 = zext i1 %19771 to i8
  store i8 %19772, i8* %17, align 1
  %19773 = and i32 %19767, 255
  %19774 = tail call i32 @llvm.ctpop.i32(i32 %19773)
  %19775 = trunc i32 %19774 to i8
  %19776 = and i8 %19775, 1
  %19777 = xor i8 %19776, 1
  store i8 %19777, i8* %18, align 1
  %19778 = xor i32 %19766, %19761
  %19779 = xor i32 %19778, %19767
  %19780 = lshr i32 %19779, 4
  %19781 = trunc i32 %19780 to i8
  %19782 = and i8 %19781, 1
  store i8 %19782, i8* %19, align 1
  %19783 = icmp eq i32 %19767, 0
  %19784 = zext i1 %19783 to i8
  store i8 %19784, i8* %20, align 1
  %19785 = lshr i32 %19767, 31
  %19786 = trunc i32 %19785 to i8
  store i8 %19786, i8* %21, align 1
  %19787 = lshr i32 %19761, 31
  %19788 = lshr i32 %19766, 31
  %19789 = xor i32 %19785, %19787
  %19790 = xor i32 %19785, %19788
  %19791 = add nuw nsw i32 %19789, %19790
  %19792 = icmp eq i32 %19791, 2
  %19793 = zext i1 %19792 to i8
  store i8 %19793, i8* %22, align 1
  %19794 = sext i32 %19767 to i64
  store i64 %19794, i64* %RDI.i6998, align 8
  %19795 = shl nsw i64 %19794, 3
  %19796 = add i64 %19757, %19795
  %19797 = add i64 %19745, 42
  store i64 %19797, i64* %3, align 8
  %19798 = inttoptr i64 %19796 to i64*
  %19799 = load i64, i64* %19798, align 8
  store i64 %19799, i64* %RSI.i2015, align 8
  %19800 = load i64, i64* %RBP.i, align 8
  %19801 = add i64 %19800, -228
  %19802 = add i64 %19745, 48
  store i64 %19802, i64* %3, align 8
  %19803 = inttoptr i64 %19801 to i32*
  %19804 = load i32, i32* %19803, align 4
  %19805 = zext i32 %19804 to i64
  store i64 %19805, i64* %RAX.i1659, align 8
  %19806 = add i64 %19800, -44
  %19807 = add i64 %19745, 51
  store i64 %19807, i64* %3, align 8
  %19808 = inttoptr i64 %19806 to i32*
  %19809 = load i32, i32* %19808, align 4
  %19810 = add i32 %19809, %19804
  %19811 = zext i32 %19810 to i64
  store i64 %19811, i64* %RAX.i1659, align 8
  %19812 = icmp ult i32 %19810, %19804
  %19813 = icmp ult i32 %19810, %19809
  %19814 = or i1 %19812, %19813
  %19815 = zext i1 %19814 to i8
  store i8 %19815, i8* %17, align 1
  %19816 = and i32 %19810, 255
  %19817 = tail call i32 @llvm.ctpop.i32(i32 %19816)
  %19818 = trunc i32 %19817 to i8
  %19819 = and i8 %19818, 1
  %19820 = xor i8 %19819, 1
  store i8 %19820, i8* %18, align 1
  %19821 = xor i32 %19809, %19804
  %19822 = xor i32 %19821, %19810
  %19823 = lshr i32 %19822, 4
  %19824 = trunc i32 %19823 to i8
  %19825 = and i8 %19824, 1
  store i8 %19825, i8* %19, align 1
  %19826 = icmp eq i32 %19810, 0
  %19827 = zext i1 %19826 to i8
  store i8 %19827, i8* %20, align 1
  %19828 = lshr i32 %19810, 31
  %19829 = trunc i32 %19828 to i8
  store i8 %19829, i8* %21, align 1
  %19830 = lshr i32 %19804, 31
  %19831 = lshr i32 %19809, 31
  %19832 = xor i32 %19828, %19830
  %19833 = xor i32 %19828, %19831
  %19834 = add nuw nsw i32 %19832, %19833
  %19835 = icmp eq i32 %19834, 2
  %19836 = zext i1 %19835 to i8
  store i8 %19836, i8* %22, align 1
  %19837 = sext i32 %19810 to i64
  store i64 %19837, i64* %RDI.i6998, align 8
  %19838 = shl nsw i64 %19837, 1
  %19839 = add i64 %19799, %19838
  %19840 = load i16, i16* %DX.i4863, align 2
  %19841 = add i64 %19745, 58
  store i64 %19841, i64* %3, align 8
  %19842 = inttoptr i64 %19839 to i16*
  store i16 %19840, i16* %19842, align 2
  %19843 = load i64, i64* %3, align 8
  %19844 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %19844, i64* %RSI.i2015, align 8
  %19845 = add i64 %19844, 72688
  %19846 = add i64 %19843, 14
  store i64 %19846, i64* %3, align 8
  %19847 = inttoptr i64 %19845 to i32*
  %19848 = load i32, i32* %19847, align 4
  %19849 = zext i32 %19848 to i64
  store i64 %19849, i64* %RAX.i1659, align 8
  %19850 = load i64, i64* %RBP.i, align 8
  %19851 = add i64 %19850, -340
  %19852 = add i64 %19843, 21
  store i64 %19852, i64* %3, align 8
  %19853 = inttoptr i64 %19851 to i32*
  %19854 = load i32, i32* %19853, align 4
  %19855 = zext i32 %19854 to i64
  store i64 %19855, i64* %25, align 8
  %19856 = add i64 %19844, 8504
  %19857 = lshr i64 %19856, 63
  %19858 = add i64 %19844, 10552
  store i64 %19858, i64* %RSI.i2015, align 8
  %19859 = icmp ugt i64 %19856, -2049
  %19860 = zext i1 %19859 to i8
  store i8 %19860, i8* %17, align 1
  %19861 = trunc i64 %19858 to i32
  %19862 = and i32 %19861, 255
  %19863 = tail call i32 @llvm.ctpop.i32(i32 %19862)
  %19864 = trunc i32 %19863 to i8
  %19865 = and i8 %19864, 1
  %19866 = xor i8 %19865, 1
  store i8 %19866, i8* %18, align 1
  %19867 = xor i64 %19858, %19856
  %19868 = lshr i64 %19867, 4
  %19869 = trunc i64 %19868 to i8
  %19870 = and i8 %19869, 1
  store i8 %19870, i8* %19, align 1
  %19871 = icmp eq i64 %19858, 0
  %19872 = zext i1 %19871 to i8
  store i8 %19872, i8* %20, align 1
  %19873 = lshr i64 %19858, 63
  %19874 = trunc i64 %19873 to i8
  store i8 %19874, i8* %21, align 1
  %19875 = xor i64 %19873, %19857
  %19876 = add nuw nsw i64 %19875, %19873
  %19877 = icmp eq i64 %19876, 2
  %19878 = zext i1 %19877 to i8
  store i8 %19878, i8* %22, align 1
  %19879 = add i64 %19850, -364
  %19880 = add i64 %19843, 50
  store i64 %19880, i64* %3, align 8
  %19881 = inttoptr i64 %19879 to i32*
  %19882 = load i32, i32* %19881, align 4
  %19883 = sext i32 %19882 to i64
  %19884 = shl nsw i64 %19883, 9
  store i64 %19884, i64* %RDI.i6998, align 8
  %19885 = add i64 %19884, %19858
  store i64 %19885, i64* %RSI.i2015, align 8
  %19886 = icmp ult i64 %19885, %19858
  %19887 = icmp ult i64 %19885, %19884
  %19888 = or i1 %19886, %19887
  %19889 = zext i1 %19888 to i8
  store i8 %19889, i8* %17, align 1
  %19890 = trunc i64 %19885 to i32
  %19891 = and i32 %19890, 255
  %19892 = tail call i32 @llvm.ctpop.i32(i32 %19891)
  %19893 = trunc i32 %19892 to i8
  %19894 = and i8 %19893, 1
  %19895 = xor i8 %19894, 1
  store i8 %19895, i8* %18, align 1
  %19896 = xor i64 %19858, %19885
  %19897 = lshr i64 %19896, 4
  %19898 = trunc i64 %19897 to i8
  %19899 = and i8 %19898, 1
  store i8 %19899, i8* %19, align 1
  %19900 = icmp eq i64 %19885, 0
  %19901 = zext i1 %19900 to i8
  store i8 %19901, i8* %20, align 1
  %19902 = lshr i64 %19885, 63
  %19903 = trunc i64 %19902 to i8
  store i8 %19903, i8* %21, align 1
  %19904 = lshr i64 %19883, 54
  %19905 = and i64 %19904, 1
  %19906 = xor i64 %19902, %19873
  %19907 = xor i64 %19902, %19905
  %19908 = add nuw nsw i64 %19906, %19907
  %19909 = icmp eq i64 %19908, 2
  %19910 = zext i1 %19909 to i8
  store i8 %19910, i8* %22, align 1
  %19911 = load i64, i64* %RBP.i, align 8
  %19912 = add i64 %19911, -220
  %19913 = add i64 %19843, 64
  store i64 %19913, i64* %3, align 8
  %19914 = inttoptr i64 %19912 to i32*
  %19915 = load i32, i32* %19914, align 4
  %19916 = zext i32 %19915 to i64
  store i64 %19916, i64* %R9.i1633, align 8
  %19917 = add i64 %19911, -44
  %19918 = add i64 %19843, 68
  store i64 %19918, i64* %3, align 8
  %19919 = inttoptr i64 %19917 to i32*
  %19920 = load i32, i32* %19919, align 4
  %19921 = add i32 %19920, %19915
  %19922 = zext i32 %19921 to i64
  store i64 %19922, i64* %R9.i1633, align 8
  %19923 = sext i32 %19921 to i64
  %19924 = shl nsw i64 %19923, 5
  store i64 %19924, i64* %RDI.i6998, align 8
  %19925 = load i64, i64* %RSI.i2015, align 8
  %19926 = add i64 %19924, %19925
  store i64 %19926, i64* %RSI.i2015, align 8
  %19927 = icmp ult i64 %19926, %19925
  %19928 = icmp ult i64 %19926, %19924
  %19929 = or i1 %19927, %19928
  %19930 = zext i1 %19929 to i8
  store i8 %19930, i8* %17, align 1
  %19931 = trunc i64 %19926 to i32
  %19932 = and i32 %19931, 255
  %19933 = tail call i32 @llvm.ctpop.i32(i32 %19932)
  %19934 = trunc i32 %19933 to i8
  %19935 = and i8 %19934, 1
  %19936 = xor i8 %19935, 1
  store i8 %19936, i8* %18, align 1
  %19937 = xor i64 %19925, %19926
  %19938 = lshr i64 %19937, 4
  %19939 = trunc i64 %19938 to i8
  %19940 = and i8 %19939, 1
  store i8 %19940, i8* %19, align 1
  %19941 = icmp eq i64 %19926, 0
  %19942 = zext i1 %19941 to i8
  store i8 %19942, i8* %20, align 1
  %19943 = lshr i64 %19926, 63
  %19944 = trunc i64 %19943 to i8
  store i8 %19944, i8* %21, align 1
  %19945 = lshr i64 %19925, 63
  %19946 = lshr i64 %19923, 58
  %19947 = and i64 %19946, 1
  %19948 = xor i64 %19943, %19945
  %19949 = xor i64 %19943, %19947
  %19950 = add nuw nsw i64 %19948, %19949
  %19951 = icmp eq i64 %19950, 2
  %19952 = zext i1 %19951 to i8
  store i8 %19952, i8* %22, align 1
  %19953 = load i64, i64* %RBP.i, align 8
  %19954 = add i64 %19953, -224
  %19955 = add i64 %19843, 85
  store i64 %19955, i64* %3, align 8
  %19956 = inttoptr i64 %19954 to i32*
  %19957 = load i32, i32* %19956, align 4
  %19958 = zext i32 %19957 to i64
  store i64 %19958, i64* %R9.i1633, align 8
  %19959 = add i64 %19953, -48
  %19960 = add i64 %19843, 89
  store i64 %19960, i64* %3, align 8
  %19961 = inttoptr i64 %19959 to i32*
  %19962 = load i32, i32* %19961, align 4
  %19963 = add i32 %19962, %19957
  %19964 = zext i32 %19963 to i64
  store i64 %19964, i64* %R9.i1633, align 8
  %19965 = icmp ult i32 %19963, %19957
  %19966 = icmp ult i32 %19963, %19962
  %19967 = or i1 %19965, %19966
  %19968 = zext i1 %19967 to i8
  store i8 %19968, i8* %17, align 1
  %19969 = and i32 %19963, 255
  %19970 = tail call i32 @llvm.ctpop.i32(i32 %19969)
  %19971 = trunc i32 %19970 to i8
  %19972 = and i8 %19971, 1
  %19973 = xor i8 %19972, 1
  store i8 %19973, i8* %18, align 1
  %19974 = xor i32 %19962, %19957
  %19975 = xor i32 %19974, %19963
  %19976 = lshr i32 %19975, 4
  %19977 = trunc i32 %19976 to i8
  %19978 = and i8 %19977, 1
  store i8 %19978, i8* %19, align 1
  %19979 = icmp eq i32 %19963, 0
  %19980 = zext i1 %19979 to i8
  store i8 %19980, i8* %20, align 1
  %19981 = lshr i32 %19963, 31
  %19982 = trunc i32 %19981 to i8
  store i8 %19982, i8* %21, align 1
  %19983 = lshr i32 %19957, 31
  %19984 = lshr i32 %19962, 31
  %19985 = xor i32 %19981, %19983
  %19986 = xor i32 %19981, %19984
  %19987 = add nuw nsw i32 %19985, %19986
  %19988 = icmp eq i32 %19987, 2
  %19989 = zext i1 %19988 to i8
  store i8 %19989, i8* %22, align 1
  %19990 = sext i32 %19963 to i64
  store i64 %19990, i64* %RDI.i6998, align 8
  %19991 = shl nsw i64 %19990, 1
  %19992 = add i64 %19926, %19991
  %19993 = add i64 %19843, 97
  store i64 %19993, i64* %3, align 8
  %19994 = inttoptr i64 %19992 to i16*
  %19995 = load i16, i16* %19994, align 2
  %19996 = zext i16 %19995 to i64
  store i64 %19996, i64* %R9.i1633, align 8
  %19997 = load i32, i32* %R8D.i1615, align 4
  %19998 = zext i16 %19995 to i32
  %19999 = add i32 %19998, %19997
  %20000 = zext i32 %19999 to i64
  store i64 %20000, i64* %25, align 8
  %20001 = lshr i32 %19999, 31
  %20002 = load i32, i32* %ECX.i6962, align 4
  %20003 = sub i32 %20002, %19999
  %20004 = icmp ult i32 %20002, %19999
  %20005 = zext i1 %20004 to i8
  store i8 %20005, i8* %17, align 1
  %20006 = and i32 %20003, 255
  %20007 = tail call i32 @llvm.ctpop.i32(i32 %20006)
  %20008 = trunc i32 %20007 to i8
  %20009 = and i8 %20008, 1
  %20010 = xor i8 %20009, 1
  store i8 %20010, i8* %18, align 1
  %20011 = xor i32 %19999, %20002
  %20012 = xor i32 %20011, %20003
  %20013 = lshr i32 %20012, 4
  %20014 = trunc i32 %20013 to i8
  %20015 = and i8 %20014, 1
  store i8 %20015, i8* %19, align 1
  %20016 = icmp eq i32 %20003, 0
  %20017 = zext i1 %20016 to i8
  store i8 %20017, i8* %20, align 1
  %20018 = lshr i32 %20003, 31
  %20019 = trunc i32 %20018 to i8
  store i8 %20019, i8* %21, align 1
  %20020 = lshr i32 %20002, 31
  %20021 = xor i32 %20001, %20020
  %20022 = xor i32 %20018, %20020
  %20023 = add nuw nsw i32 %20022, %20021
  %20024 = icmp eq i32 %20023, 2
  %20025 = zext i1 %20024 to i8
  store i8 %20025, i8* %22, align 1
  %20026 = load i64, i64* %RBP.i, align 8
  %20027 = add i64 %20026, -772
  %20028 = load i32, i32* %EAX.i2033, align 4
  %20029 = add i64 %19843, 109
  store i64 %20029, i64* %3, align 8
  %20030 = inttoptr i64 %20027 to i32*
  store i32 %20028, i32* %20030, align 4
  %20031 = load i64, i64* %3, align 8
  %20032 = load i8, i8* %20, align 1
  %20033 = icmp ne i8 %20032, 0
  %20034 = load i8, i8* %21, align 1
  %20035 = icmp ne i8 %20034, 0
  %20036 = load i8, i8* %22, align 1
  %20037 = icmp ne i8 %20036, 0
  %20038 = xor i1 %20035, %20037
  %20039 = or i1 %20033, %20038
  %.v877 = select i1 %20039, i64 19, i64 6
  %20040 = add i64 %20031, %.v877
  store i64 %20040, i64* %3, align 8
  br i1 %20039, label %block_.L_48655b, label %block_48654e

block_48654e:                                     ; preds = %block_.L_4864a1
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %20041 = load i64, i64* %RBP.i, align 8
  %20042 = add i64 %20041, -776
  %20043 = add i64 %20040, 8
  store i64 %20043, i64* %3, align 8
  %20044 = inttoptr i64 %20042 to i32*
  store i32 0, i32* %20044, align 4
  %20045 = load i64, i64* %3, align 8
  %20046 = add i64 %20045, 90
  store i64 %20046, i64* %3, align 8
  br label %block_.L_4865b0

block_.L_48655b:                                  ; preds = %block_.L_4864a1
  %20047 = load i64, i64* %RBP.i, align 8
  %20048 = add i64 %20047, -340
  %20049 = add i64 %20040, 6
  store i64 %20049, i64* %3, align 8
  %20050 = inttoptr i64 %20048 to i32*
  %20051 = load i32, i32* %20050, align 4
  %20052 = zext i32 %20051 to i64
  store i64 %20052, i64* %RAX.i1659, align 8
  %20053 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %20054 = add i64 %20053, 8504
  %20055 = lshr i64 %20054, 63
  %20056 = add i64 %20053, 10552
  store i64 %20056, i64* %RCX.i1588, align 8
  %20057 = icmp ugt i64 %20054, -2049
  %20058 = zext i1 %20057 to i8
  store i8 %20058, i8* %17, align 1
  %20059 = trunc i64 %20056 to i32
  %20060 = and i32 %20059, 255
  %20061 = tail call i32 @llvm.ctpop.i32(i32 %20060)
  %20062 = trunc i32 %20061 to i8
  %20063 = and i8 %20062, 1
  %20064 = xor i8 %20063, 1
  store i8 %20064, i8* %18, align 1
  %20065 = xor i64 %20056, %20054
  %20066 = lshr i64 %20065, 4
  %20067 = trunc i64 %20066 to i8
  %20068 = and i8 %20067, 1
  store i8 %20068, i8* %19, align 1
  %20069 = icmp eq i64 %20056, 0
  %20070 = zext i1 %20069 to i8
  store i8 %20070, i8* %20, align 1
  %20071 = lshr i64 %20056, 63
  %20072 = trunc i64 %20071 to i8
  store i8 %20072, i8* %21, align 1
  %20073 = xor i64 %20071, %20055
  %20074 = add nuw nsw i64 %20073, %20071
  %20075 = icmp eq i64 %20074, 2
  %20076 = zext i1 %20075 to i8
  store i8 %20076, i8* %22, align 1
  %20077 = add i64 %20047, -364
  %20078 = add i64 %20040, 35
  store i64 %20078, i64* %3, align 8
  %20079 = inttoptr i64 %20077 to i32*
  %20080 = load i32, i32* %20079, align 4
  %20081 = sext i32 %20080 to i64
  %20082 = shl nsw i64 %20081, 9
  store i64 %20082, i64* %RDX.i1943, align 8
  %20083 = add i64 %20082, %20056
  store i64 %20083, i64* %RCX.i1588, align 8
  %20084 = icmp ult i64 %20083, %20056
  %20085 = icmp ult i64 %20083, %20082
  %20086 = or i1 %20084, %20085
  %20087 = zext i1 %20086 to i8
  store i8 %20087, i8* %17, align 1
  %20088 = trunc i64 %20083 to i32
  %20089 = and i32 %20088, 255
  %20090 = tail call i32 @llvm.ctpop.i32(i32 %20089)
  %20091 = trunc i32 %20090 to i8
  %20092 = and i8 %20091, 1
  %20093 = xor i8 %20092, 1
  store i8 %20093, i8* %18, align 1
  %20094 = xor i64 %20056, %20083
  %20095 = lshr i64 %20094, 4
  %20096 = trunc i64 %20095 to i8
  %20097 = and i8 %20096, 1
  store i8 %20097, i8* %19, align 1
  %20098 = icmp eq i64 %20083, 0
  %20099 = zext i1 %20098 to i8
  store i8 %20099, i8* %20, align 1
  %20100 = lshr i64 %20083, 63
  %20101 = trunc i64 %20100 to i8
  store i8 %20101, i8* %21, align 1
  %20102 = lshr i64 %20081, 54
  %20103 = and i64 %20102, 1
  %20104 = xor i64 %20100, %20071
  %20105 = xor i64 %20100, %20103
  %20106 = add nuw nsw i64 %20104, %20105
  %20107 = icmp eq i64 %20106, 2
  %20108 = zext i1 %20107 to i8
  store i8 %20108, i8* %22, align 1
  %20109 = load i64, i64* %RBP.i, align 8
  %20110 = add i64 %20109, -220
  %20111 = add i64 %20040, 48
  store i64 %20111, i64* %3, align 8
  %20112 = inttoptr i64 %20110 to i32*
  %20113 = load i32, i32* %20112, align 4
  %20114 = zext i32 %20113 to i64
  store i64 %20114, i64* %RSI.i2015, align 8
  %20115 = add i64 %20109, -44
  %20116 = add i64 %20040, 51
  store i64 %20116, i64* %3, align 8
  %20117 = inttoptr i64 %20115 to i32*
  %20118 = load i32, i32* %20117, align 4
  %20119 = add i32 %20118, %20113
  %20120 = zext i32 %20119 to i64
  store i64 %20120, i64* %RSI.i2015, align 8
  %20121 = sext i32 %20119 to i64
  %20122 = shl nsw i64 %20121, 5
  store i64 %20122, i64* %RDX.i1943, align 8
  %20123 = load i64, i64* %RCX.i1588, align 8
  %20124 = add i64 %20122, %20123
  store i64 %20124, i64* %RCX.i1588, align 8
  %20125 = icmp ult i64 %20124, %20123
  %20126 = icmp ult i64 %20124, %20122
  %20127 = or i1 %20125, %20126
  %20128 = zext i1 %20127 to i8
  store i8 %20128, i8* %17, align 1
  %20129 = trunc i64 %20124 to i32
  %20130 = and i32 %20129, 255
  %20131 = tail call i32 @llvm.ctpop.i32(i32 %20130)
  %20132 = trunc i32 %20131 to i8
  %20133 = and i8 %20132, 1
  %20134 = xor i8 %20133, 1
  store i8 %20134, i8* %18, align 1
  %20135 = xor i64 %20123, %20124
  %20136 = lshr i64 %20135, 4
  %20137 = trunc i64 %20136 to i8
  %20138 = and i8 %20137, 1
  store i8 %20138, i8* %19, align 1
  %20139 = icmp eq i64 %20124, 0
  %20140 = zext i1 %20139 to i8
  store i8 %20140, i8* %20, align 1
  %20141 = lshr i64 %20124, 63
  %20142 = trunc i64 %20141 to i8
  store i8 %20142, i8* %21, align 1
  %20143 = lshr i64 %20123, 63
  %20144 = lshr i64 %20121, 58
  %20145 = and i64 %20144, 1
  %20146 = xor i64 %20141, %20143
  %20147 = xor i64 %20141, %20145
  %20148 = add nuw nsw i64 %20146, %20147
  %20149 = icmp eq i64 %20148, 2
  %20150 = zext i1 %20149 to i8
  store i8 %20150, i8* %22, align 1
  %20151 = load i64, i64* %RBP.i, align 8
  %20152 = add i64 %20151, -224
  %20153 = add i64 %20040, 67
  store i64 %20153, i64* %3, align 8
  %20154 = inttoptr i64 %20152 to i32*
  %20155 = load i32, i32* %20154, align 4
  %20156 = zext i32 %20155 to i64
  store i64 %20156, i64* %RSI.i2015, align 8
  %20157 = add i64 %20151, -48
  %20158 = add i64 %20040, 70
  store i64 %20158, i64* %3, align 8
  %20159 = inttoptr i64 %20157 to i32*
  %20160 = load i32, i32* %20159, align 4
  %20161 = add i32 %20160, %20155
  %20162 = zext i32 %20161 to i64
  store i64 %20162, i64* %RSI.i2015, align 8
  %20163 = icmp ult i32 %20161, %20155
  %20164 = icmp ult i32 %20161, %20160
  %20165 = or i1 %20163, %20164
  %20166 = zext i1 %20165 to i8
  store i8 %20166, i8* %17, align 1
  %20167 = and i32 %20161, 255
  %20168 = tail call i32 @llvm.ctpop.i32(i32 %20167)
  %20169 = trunc i32 %20168 to i8
  %20170 = and i8 %20169, 1
  %20171 = xor i8 %20170, 1
  store i8 %20171, i8* %18, align 1
  %20172 = xor i32 %20160, %20155
  %20173 = xor i32 %20172, %20161
  %20174 = lshr i32 %20173, 4
  %20175 = trunc i32 %20174 to i8
  %20176 = and i8 %20175, 1
  store i8 %20176, i8* %19, align 1
  %20177 = icmp eq i32 %20161, 0
  %20178 = zext i1 %20177 to i8
  store i8 %20178, i8* %20, align 1
  %20179 = lshr i32 %20161, 31
  %20180 = trunc i32 %20179 to i8
  store i8 %20180, i8* %21, align 1
  %20181 = lshr i32 %20155, 31
  %20182 = lshr i32 %20160, 31
  %20183 = xor i32 %20179, %20181
  %20184 = xor i32 %20179, %20182
  %20185 = add nuw nsw i32 %20183, %20184
  %20186 = icmp eq i32 %20185, 2
  %20187 = zext i1 %20186 to i8
  store i8 %20187, i8* %22, align 1
  %20188 = sext i32 %20161 to i64
  store i64 %20188, i64* %RDX.i1943, align 8
  %20189 = shl nsw i64 %20188, 1
  %20190 = add i64 %20124, %20189
  %20191 = add i64 %20040, 77
  store i64 %20191, i64* %3, align 8
  %20192 = inttoptr i64 %20190 to i16*
  %20193 = load i16, i16* %20192, align 2
  %20194 = zext i16 %20193 to i64
  store i64 %20194, i64* %RSI.i2015, align 8
  %20195 = load i64, i64* %RAX.i1659, align 8
  %20196 = zext i16 %20193 to i32
  %20197 = zext i16 %20193 to i64
  %20198 = trunc i64 %20195 to i32
  %20199 = add i32 %20196, %20198
  %20200 = zext i32 %20199 to i64
  store i64 %20200, i64* %RAX.i1659, align 8
  %20201 = icmp ult i32 %20199, %20198
  %20202 = icmp ult i32 %20199, %20196
  %20203 = or i1 %20201, %20202
  %20204 = zext i1 %20203 to i8
  store i8 %20204, i8* %17, align 1
  %20205 = and i32 %20199, 255
  %20206 = tail call i32 @llvm.ctpop.i32(i32 %20205)
  %20207 = trunc i32 %20206 to i8
  %20208 = and i8 %20207, 1
  %20209 = xor i8 %20208, 1
  store i8 %20209, i8* %18, align 1
  %20210 = xor i64 %20197, %20195
  %20211 = trunc i64 %20210 to i32
  %20212 = xor i32 %20211, %20199
  %20213 = lshr i32 %20212, 4
  %20214 = trunc i32 %20213 to i8
  %20215 = and i8 %20214, 1
  store i8 %20215, i8* %19, align 1
  %20216 = icmp eq i32 %20199, 0
  %20217 = zext i1 %20216 to i8
  store i8 %20217, i8* %20, align 1
  %20218 = lshr i32 %20199, 31
  %20219 = trunc i32 %20218 to i8
  store i8 %20219, i8* %21, align 1
  %20220 = lshr i32 %20198, 31
  %20221 = xor i32 %20218, %20220
  %20222 = add nuw nsw i32 %20221, %20218
  %20223 = icmp eq i32 %20222, 2
  %20224 = zext i1 %20223 to i8
  store i8 %20224, i8* %22, align 1
  %20225 = add i64 %20151, -776
  %20226 = add i64 %20040, 85
  store i64 %20226, i64* %3, align 8
  %20227 = inttoptr i64 %20225 to i32*
  store i32 %20199, i32* %20227, align 4
  %.pre544 = load i64, i64* %3, align 8
  br label %block_.L_4865b0

block_.L_4865b0:                                  ; preds = %block_.L_48655b, %block_48654e
  %20228 = phi i64 [ %.pre544, %block_.L_48655b ], [ %20046, %block_48654e ]
  %20229 = load i64, i64* %RBP.i, align 8
  %20230 = add i64 %20229, -776
  %20231 = add i64 %20228, 6
  store i64 %20231, i64* %3, align 8
  %20232 = inttoptr i64 %20230 to i32*
  %20233 = load i32, i32* %20232, align 4
  %20234 = zext i32 %20233 to i64
  store i64 %20234, i64* %RAX.i1659, align 8
  %20235 = add i64 %20229, -772
  %20236 = add i64 %20228, 12
  store i64 %20236, i64* %3, align 8
  %20237 = inttoptr i64 %20235 to i32*
  %20238 = load i32, i32* %20237, align 4
  %20239 = zext i32 %20238 to i64
  store i64 %20239, i64* %RCX.i1588, align 8
  %20240 = sub i32 %20238, %20233
  %20241 = icmp ult i32 %20238, %20233
  %20242 = zext i1 %20241 to i8
  store i8 %20242, i8* %17, align 1
  %20243 = and i32 %20240, 255
  %20244 = tail call i32 @llvm.ctpop.i32(i32 %20243)
  %20245 = trunc i32 %20244 to i8
  %20246 = and i8 %20245, 1
  %20247 = xor i8 %20246, 1
  store i8 %20247, i8* %18, align 1
  %20248 = xor i32 %20233, %20238
  %20249 = xor i32 %20248, %20240
  %20250 = lshr i32 %20249, 4
  %20251 = trunc i32 %20250 to i8
  %20252 = and i8 %20251, 1
  store i8 %20252, i8* %19, align 1
  %20253 = icmp eq i32 %20240, 0
  %20254 = zext i1 %20253 to i8
  store i8 %20254, i8* %20, align 1
  %20255 = lshr i32 %20240, 31
  %20256 = trunc i32 %20255 to i8
  store i8 %20256, i8* %21, align 1
  %20257 = lshr i32 %20238, 31
  %20258 = lshr i32 %20233, 31
  %20259 = xor i32 %20258, %20257
  %20260 = xor i32 %20255, %20257
  %20261 = add nuw nsw i32 %20260, %20259
  %20262 = icmp eq i32 %20261, 2
  %20263 = zext i1 %20262 to i8
  store i8 %20263, i8* %22, align 1
  %20264 = icmp ne i8 %20256, 0
  %20265 = xor i1 %20264, %20262
  %.v720 = select i1 %20265, i64 20, i64 45
  %20266 = add i64 %20228, %.v720
  store i64 %20266, i64* %3, align 8
  br i1 %20265, label %block_4865c4, label %block_.L_4865dd

block_4865c4:                                     ; preds = %block_.L_4865b0
  %20267 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %20267, i64* %RAX.i1659, align 8
  %20268 = add i64 %20267, 72688
  %20269 = add i64 %20266, 14
  store i64 %20269, i64* %3, align 8
  %20270 = inttoptr i64 %20268 to i32*
  %20271 = load i32, i32* %20270, align 4
  %20272 = zext i32 %20271 to i64
  store i64 %20272, i64* %RCX.i1588, align 8
  %20273 = add i64 %20229, -780
  %20274 = add i64 %20266, 20
  store i64 %20274, i64* %3, align 8
  %20275 = inttoptr i64 %20273 to i32*
  store i32 %20271, i32* %20275, align 4
  %20276 = load i64, i64* %3, align 8
  %20277 = add i64 %20276, 204
  store i64 %20277, i64* %3, align 8
  br label %block_.L_4866a4

block_.L_4865dd:                                  ; preds = %block_.L_4865b0
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %20278 = add i64 %20229, -340
  %20279 = add i64 %20266, 8
  store i64 %20279, i64* %3, align 8
  %20280 = inttoptr i64 %20278 to i32*
  %20281 = load i32, i32* %20280, align 4
  %20282 = zext i32 %20281 to i64
  store i64 %20282, i64* %RCX.i1588, align 8
  %20283 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %20284 = add i64 %20283, 8504
  %20285 = lshr i64 %20284, 63
  %20286 = add i64 %20283, 10552
  store i64 %20286, i64* %RDX.i1943, align 8
  %20287 = icmp ugt i64 %20284, -2049
  %20288 = zext i1 %20287 to i8
  store i8 %20288, i8* %17, align 1
  %20289 = trunc i64 %20286 to i32
  %20290 = and i32 %20289, 255
  %20291 = tail call i32 @llvm.ctpop.i32(i32 %20290)
  %20292 = trunc i32 %20291 to i8
  %20293 = and i8 %20292, 1
  %20294 = xor i8 %20293, 1
  store i8 %20294, i8* %18, align 1
  %20295 = xor i64 %20286, %20284
  %20296 = lshr i64 %20295, 4
  %20297 = trunc i64 %20296 to i8
  %20298 = and i8 %20297, 1
  store i8 %20298, i8* %19, align 1
  %20299 = icmp eq i64 %20286, 0
  %20300 = zext i1 %20299 to i8
  store i8 %20300, i8* %20, align 1
  %20301 = lshr i64 %20286, 63
  %20302 = trunc i64 %20301 to i8
  store i8 %20302, i8* %21, align 1
  %20303 = xor i64 %20301, %20285
  %20304 = add nuw nsw i64 %20303, %20301
  %20305 = icmp eq i64 %20304, 2
  %20306 = zext i1 %20305 to i8
  store i8 %20306, i8* %22, align 1
  %20307 = add i64 %20229, -364
  %20308 = add i64 %20266, 37
  store i64 %20308, i64* %3, align 8
  %20309 = inttoptr i64 %20307 to i32*
  %20310 = load i32, i32* %20309, align 4
  %20311 = sext i32 %20310 to i64
  %20312 = shl nsw i64 %20311, 9
  store i64 %20312, i64* %RSI.i2015, align 8
  %20313 = add i64 %20312, %20286
  store i64 %20313, i64* %RDX.i1943, align 8
  %20314 = icmp ult i64 %20313, %20286
  %20315 = icmp ult i64 %20313, %20312
  %20316 = or i1 %20314, %20315
  %20317 = zext i1 %20316 to i8
  store i8 %20317, i8* %17, align 1
  %20318 = trunc i64 %20313 to i32
  %20319 = and i32 %20318, 255
  %20320 = tail call i32 @llvm.ctpop.i32(i32 %20319)
  %20321 = trunc i32 %20320 to i8
  %20322 = and i8 %20321, 1
  %20323 = xor i8 %20322, 1
  store i8 %20323, i8* %18, align 1
  %20324 = xor i64 %20286, %20313
  %20325 = lshr i64 %20324, 4
  %20326 = trunc i64 %20325 to i8
  %20327 = and i8 %20326, 1
  store i8 %20327, i8* %19, align 1
  %20328 = icmp eq i64 %20313, 0
  %20329 = zext i1 %20328 to i8
  store i8 %20329, i8* %20, align 1
  %20330 = lshr i64 %20313, 63
  %20331 = trunc i64 %20330 to i8
  store i8 %20331, i8* %21, align 1
  %20332 = lshr i64 %20311, 54
  %20333 = and i64 %20332, 1
  %20334 = xor i64 %20330, %20301
  %20335 = xor i64 %20330, %20333
  %20336 = add nuw nsw i64 %20334, %20335
  %20337 = icmp eq i64 %20336, 2
  %20338 = zext i1 %20337 to i8
  store i8 %20338, i8* %22, align 1
  %20339 = load i64, i64* %RBP.i, align 8
  %20340 = add i64 %20339, -220
  %20341 = add i64 %20266, 50
  store i64 %20341, i64* %3, align 8
  %20342 = inttoptr i64 %20340 to i32*
  %20343 = load i32, i32* %20342, align 4
  %20344 = zext i32 %20343 to i64
  store i64 %20344, i64* %RDI.i6998, align 8
  %20345 = add i64 %20339, -44
  %20346 = add i64 %20266, 53
  store i64 %20346, i64* %3, align 8
  %20347 = inttoptr i64 %20345 to i32*
  %20348 = load i32, i32* %20347, align 4
  %20349 = add i32 %20348, %20343
  %20350 = zext i32 %20349 to i64
  store i64 %20350, i64* %RDI.i6998, align 8
  %20351 = sext i32 %20349 to i64
  %20352 = shl nsw i64 %20351, 5
  store i64 %20352, i64* %RSI.i2015, align 8
  %20353 = load i64, i64* %RDX.i1943, align 8
  %20354 = add i64 %20352, %20353
  store i64 %20354, i64* %RDX.i1943, align 8
  %20355 = icmp ult i64 %20354, %20353
  %20356 = icmp ult i64 %20354, %20352
  %20357 = or i1 %20355, %20356
  %20358 = zext i1 %20357 to i8
  store i8 %20358, i8* %17, align 1
  %20359 = trunc i64 %20354 to i32
  %20360 = and i32 %20359, 255
  %20361 = tail call i32 @llvm.ctpop.i32(i32 %20360)
  %20362 = trunc i32 %20361 to i8
  %20363 = and i8 %20362, 1
  %20364 = xor i8 %20363, 1
  store i8 %20364, i8* %18, align 1
  %20365 = xor i64 %20353, %20354
  %20366 = lshr i64 %20365, 4
  %20367 = trunc i64 %20366 to i8
  %20368 = and i8 %20367, 1
  store i8 %20368, i8* %19, align 1
  %20369 = icmp eq i64 %20354, 0
  %20370 = zext i1 %20369 to i8
  store i8 %20370, i8* %20, align 1
  %20371 = lshr i64 %20354, 63
  %20372 = trunc i64 %20371 to i8
  store i8 %20372, i8* %21, align 1
  %20373 = lshr i64 %20353, 63
  %20374 = lshr i64 %20351, 58
  %20375 = and i64 %20374, 1
  %20376 = xor i64 %20371, %20373
  %20377 = xor i64 %20371, %20375
  %20378 = add nuw nsw i64 %20376, %20377
  %20379 = icmp eq i64 %20378, 2
  %20380 = zext i1 %20379 to i8
  store i8 %20380, i8* %22, align 1
  %20381 = load i64, i64* %RBP.i, align 8
  %20382 = add i64 %20381, -224
  %20383 = add i64 %20266, 69
  store i64 %20383, i64* %3, align 8
  %20384 = inttoptr i64 %20382 to i32*
  %20385 = load i32, i32* %20384, align 4
  %20386 = zext i32 %20385 to i64
  store i64 %20386, i64* %RDI.i6998, align 8
  %20387 = add i64 %20381, -48
  %20388 = add i64 %20266, 72
  store i64 %20388, i64* %3, align 8
  %20389 = inttoptr i64 %20387 to i32*
  %20390 = load i32, i32* %20389, align 4
  %20391 = add i32 %20390, %20385
  %20392 = zext i32 %20391 to i64
  store i64 %20392, i64* %RDI.i6998, align 8
  %20393 = icmp ult i32 %20391, %20385
  %20394 = icmp ult i32 %20391, %20390
  %20395 = or i1 %20393, %20394
  %20396 = zext i1 %20395 to i8
  store i8 %20396, i8* %17, align 1
  %20397 = and i32 %20391, 255
  %20398 = tail call i32 @llvm.ctpop.i32(i32 %20397)
  %20399 = trunc i32 %20398 to i8
  %20400 = and i8 %20399, 1
  %20401 = xor i8 %20400, 1
  store i8 %20401, i8* %18, align 1
  %20402 = xor i32 %20390, %20385
  %20403 = xor i32 %20402, %20391
  %20404 = lshr i32 %20403, 4
  %20405 = trunc i32 %20404 to i8
  %20406 = and i8 %20405, 1
  store i8 %20406, i8* %19, align 1
  %20407 = icmp eq i32 %20391, 0
  %20408 = zext i1 %20407 to i8
  store i8 %20408, i8* %20, align 1
  %20409 = lshr i32 %20391, 31
  %20410 = trunc i32 %20409 to i8
  store i8 %20410, i8* %21, align 1
  %20411 = lshr i32 %20385, 31
  %20412 = lshr i32 %20390, 31
  %20413 = xor i32 %20409, %20411
  %20414 = xor i32 %20409, %20412
  %20415 = add nuw nsw i32 %20413, %20414
  %20416 = icmp eq i32 %20415, 2
  %20417 = zext i1 %20416 to i8
  store i8 %20417, i8* %22, align 1
  %20418 = sext i32 %20391 to i64
  store i64 %20418, i64* %RSI.i2015, align 8
  %20419 = shl nsw i64 %20418, 1
  %20420 = add i64 %20354, %20419
  %20421 = add i64 %20266, 79
  store i64 %20421, i64* %3, align 8
  %20422 = inttoptr i64 %20420 to i16*
  %20423 = load i16, i16* %20422, align 2
  %20424 = zext i16 %20423 to i64
  store i64 %20424, i64* %RDI.i6998, align 8
  %20425 = load i64, i64* %RCX.i1588, align 8
  %20426 = zext i16 %20423 to i32
  %20427 = trunc i64 %20425 to i32
  %20428 = add i32 %20426, %20427
  %20429 = zext i32 %20428 to i64
  store i64 %20429, i64* %RCX.i1588, align 8
  %20430 = lshr i32 %20428, 31
  %20431 = load i32, i32* %EAX.i2033, align 4
  %20432 = sub i32 %20431, %20428
  %20433 = icmp ult i32 %20431, %20428
  %20434 = zext i1 %20433 to i8
  store i8 %20434, i8* %17, align 1
  %20435 = and i32 %20432, 255
  %20436 = tail call i32 @llvm.ctpop.i32(i32 %20435)
  %20437 = trunc i32 %20436 to i8
  %20438 = and i8 %20437, 1
  %20439 = xor i8 %20438, 1
  store i8 %20439, i8* %18, align 1
  %20440 = xor i32 %20428, %20431
  %20441 = xor i32 %20440, %20432
  %20442 = lshr i32 %20441, 4
  %20443 = trunc i32 %20442 to i8
  %20444 = and i8 %20443, 1
  store i8 %20444, i8* %19, align 1
  %20445 = icmp eq i32 %20432, 0
  %20446 = zext i1 %20445 to i8
  store i8 %20446, i8* %20, align 1
  %20447 = lshr i32 %20432, 31
  %20448 = trunc i32 %20447 to i8
  store i8 %20448, i8* %21, align 1
  %20449 = lshr i32 %20431, 31
  %20450 = xor i32 %20430, %20449
  %20451 = xor i32 %20447, %20449
  %20452 = add nuw nsw i32 %20451, %20450
  %20453 = icmp eq i32 %20452, 2
  %20454 = zext i1 %20453 to i8
  store i8 %20454, i8* %22, align 1
  %20455 = icmp ne i8 %20448, 0
  %20456 = xor i1 %20455, %20453
  %20457 = or i1 %20445, %20456
  %.v721 = select i1 %20457, i64 102, i64 89
  %20458 = add i64 %20266, %.v721
  store i64 %20458, i64* %3, align 8
  br i1 %20457, label %block_.L_486643, label %block_486636

block_486636:                                     ; preds = %block_.L_4865dd
  store i64 0, i64* %RAX.i1659, align 8
  store i8 0, i8* %17, align 1
  store i8 1, i8* %18, align 1
  store i8 1, i8* %20, align 1
  store i8 0, i8* %21, align 1
  store i8 0, i8* %22, align 1
  store i8 0, i8* %19, align 1
  %20459 = load i64, i64* %RBP.i, align 8
  %20460 = add i64 %20459, -784
  %20461 = add i64 %20458, 8
  store i64 %20461, i64* %3, align 8
  %20462 = inttoptr i64 %20460 to i32*
  store i32 0, i32* %20462, align 4
  %20463 = load i64, i64* %3, align 8
  %20464 = add i64 %20463, 90
  store i64 %20464, i64* %3, align 8
  br label %block_.L_486698

block_.L_486643:                                  ; preds = %block_.L_4865dd
  %20465 = load i64, i64* %RBP.i, align 8
  %20466 = add i64 %20465, -340
  %20467 = add i64 %20458, 6
  store i64 %20467, i64* %3, align 8
  %20468 = inttoptr i64 %20466 to i32*
  %20469 = load i32, i32* %20468, align 4
  %20470 = zext i32 %20469 to i64
  store i64 %20470, i64* %RAX.i1659, align 8
  %20471 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %20472 = add i64 %20471, 8504
  %20473 = lshr i64 %20472, 63
  %20474 = add i64 %20471, 10552
  store i64 %20474, i64* %RCX.i1588, align 8
  %20475 = icmp ugt i64 %20472, -2049
  %20476 = zext i1 %20475 to i8
  store i8 %20476, i8* %17, align 1
  %20477 = trunc i64 %20474 to i32
  %20478 = and i32 %20477, 255
  %20479 = tail call i32 @llvm.ctpop.i32(i32 %20478)
  %20480 = trunc i32 %20479 to i8
  %20481 = and i8 %20480, 1
  %20482 = xor i8 %20481, 1
  store i8 %20482, i8* %18, align 1
  %20483 = xor i64 %20474, %20472
  %20484 = lshr i64 %20483, 4
  %20485 = trunc i64 %20484 to i8
  %20486 = and i8 %20485, 1
  store i8 %20486, i8* %19, align 1
  %20487 = icmp eq i64 %20474, 0
  %20488 = zext i1 %20487 to i8
  store i8 %20488, i8* %20, align 1
  %20489 = lshr i64 %20474, 63
  %20490 = trunc i64 %20489 to i8
  store i8 %20490, i8* %21, align 1
  %20491 = xor i64 %20489, %20473
  %20492 = add nuw nsw i64 %20491, %20489
  %20493 = icmp eq i64 %20492, 2
  %20494 = zext i1 %20493 to i8
  store i8 %20494, i8* %22, align 1
  %20495 = add i64 %20465, -364
  %20496 = add i64 %20458, 35
  store i64 %20496, i64* %3, align 8
  %20497 = inttoptr i64 %20495 to i32*
  %20498 = load i32, i32* %20497, align 4
  %20499 = sext i32 %20498 to i64
  %20500 = shl nsw i64 %20499, 9
  store i64 %20500, i64* %RDX.i1943, align 8
  %20501 = add i64 %20500, %20474
  store i64 %20501, i64* %RCX.i1588, align 8
  %20502 = icmp ult i64 %20501, %20474
  %20503 = icmp ult i64 %20501, %20500
  %20504 = or i1 %20502, %20503
  %20505 = zext i1 %20504 to i8
  store i8 %20505, i8* %17, align 1
  %20506 = trunc i64 %20501 to i32
  %20507 = and i32 %20506, 255
  %20508 = tail call i32 @llvm.ctpop.i32(i32 %20507)
  %20509 = trunc i32 %20508 to i8
  %20510 = and i8 %20509, 1
  %20511 = xor i8 %20510, 1
  store i8 %20511, i8* %18, align 1
  %20512 = xor i64 %20474, %20501
  %20513 = lshr i64 %20512, 4
  %20514 = trunc i64 %20513 to i8
  %20515 = and i8 %20514, 1
  store i8 %20515, i8* %19, align 1
  %20516 = icmp eq i64 %20501, 0
  %20517 = zext i1 %20516 to i8
  store i8 %20517, i8* %20, align 1
  %20518 = lshr i64 %20501, 63
  %20519 = trunc i64 %20518 to i8
  store i8 %20519, i8* %21, align 1
  %20520 = lshr i64 %20499, 54
  %20521 = and i64 %20520, 1
  %20522 = xor i64 %20518, %20489
  %20523 = xor i64 %20518, %20521
  %20524 = add nuw nsw i64 %20522, %20523
  %20525 = icmp eq i64 %20524, 2
  %20526 = zext i1 %20525 to i8
  store i8 %20526, i8* %22, align 1
  %20527 = load i64, i64* %RBP.i, align 8
  %20528 = add i64 %20527, -220
  %20529 = add i64 %20458, 48
  store i64 %20529, i64* %3, align 8
  %20530 = inttoptr i64 %20528 to i32*
  %20531 = load i32, i32* %20530, align 4
  %20532 = zext i32 %20531 to i64
  store i64 %20532, i64* %RSI.i2015, align 8
  %20533 = add i64 %20527, -44
  %20534 = add i64 %20458, 51
  store i64 %20534, i64* %3, align 8
  %20535 = inttoptr i64 %20533 to i32*
  %20536 = load i32, i32* %20535, align 4
  %20537 = add i32 %20536, %20531
  %20538 = zext i32 %20537 to i64
  store i64 %20538, i64* %RSI.i2015, align 8
  %20539 = sext i32 %20537 to i64
  %20540 = shl nsw i64 %20539, 5
  store i64 %20540, i64* %RDX.i1943, align 8
  %20541 = load i64, i64* %RCX.i1588, align 8
  %20542 = add i64 %20540, %20541
  store i64 %20542, i64* %RCX.i1588, align 8
  %20543 = icmp ult i64 %20542, %20541
  %20544 = icmp ult i64 %20542, %20540
  %20545 = or i1 %20543, %20544
  %20546 = zext i1 %20545 to i8
  store i8 %20546, i8* %17, align 1
  %20547 = trunc i64 %20542 to i32
  %20548 = and i32 %20547, 255
  %20549 = tail call i32 @llvm.ctpop.i32(i32 %20548)
  %20550 = trunc i32 %20549 to i8
  %20551 = and i8 %20550, 1
  %20552 = xor i8 %20551, 1
  store i8 %20552, i8* %18, align 1
  %20553 = xor i64 %20541, %20542
  %20554 = lshr i64 %20553, 4
  %20555 = trunc i64 %20554 to i8
  %20556 = and i8 %20555, 1
  store i8 %20556, i8* %19, align 1
  %20557 = icmp eq i64 %20542, 0
  %20558 = zext i1 %20557 to i8
  store i8 %20558, i8* %20, align 1
  %20559 = lshr i64 %20542, 63
  %20560 = trunc i64 %20559 to i8
  store i8 %20560, i8* %21, align 1
  %20561 = lshr i64 %20541, 63
  %20562 = lshr i64 %20539, 58
  %20563 = and i64 %20562, 1
  %20564 = xor i64 %20559, %20561
  %20565 = xor i64 %20559, %20563
  %20566 = add nuw nsw i64 %20564, %20565
  %20567 = icmp eq i64 %20566, 2
  %20568 = zext i1 %20567 to i8
  store i8 %20568, i8* %22, align 1
  %20569 = load i64, i64* %RBP.i, align 8
  %20570 = add i64 %20569, -224
  %20571 = add i64 %20458, 67
  store i64 %20571, i64* %3, align 8
  %20572 = inttoptr i64 %20570 to i32*
  %20573 = load i32, i32* %20572, align 4
  %20574 = zext i32 %20573 to i64
  store i64 %20574, i64* %RSI.i2015, align 8
  %20575 = add i64 %20569, -48
  %20576 = add i64 %20458, 70
  store i64 %20576, i64* %3, align 8
  %20577 = inttoptr i64 %20575 to i32*
  %20578 = load i32, i32* %20577, align 4
  %20579 = add i32 %20578, %20573
  %20580 = zext i32 %20579 to i64
  store i64 %20580, i64* %RSI.i2015, align 8
  %20581 = icmp ult i32 %20579, %20573
  %20582 = icmp ult i32 %20579, %20578
  %20583 = or i1 %20581, %20582
  %20584 = zext i1 %20583 to i8
  store i8 %20584, i8* %17, align 1
  %20585 = and i32 %20579, 255
  %20586 = tail call i32 @llvm.ctpop.i32(i32 %20585)
  %20587 = trunc i32 %20586 to i8
  %20588 = and i8 %20587, 1
  %20589 = xor i8 %20588, 1
  store i8 %20589, i8* %18, align 1
  %20590 = xor i32 %20578, %20573
  %20591 = xor i32 %20590, %20579
  %20592 = lshr i32 %20591, 4
  %20593 = trunc i32 %20592 to i8
  %20594 = and i8 %20593, 1
  store i8 %20594, i8* %19, align 1
  %20595 = icmp eq i32 %20579, 0
  %20596 = zext i1 %20595 to i8
  store i8 %20596, i8* %20, align 1
  %20597 = lshr i32 %20579, 31
  %20598 = trunc i32 %20597 to i8
  store i8 %20598, i8* %21, align 1
  %20599 = lshr i32 %20573, 31
  %20600 = lshr i32 %20578, 31
  %20601 = xor i32 %20597, %20599
  %20602 = xor i32 %20597, %20600
  %20603 = add nuw nsw i32 %20601, %20602
  %20604 = icmp eq i32 %20603, 2
  %20605 = zext i1 %20604 to i8
  store i8 %20605, i8* %22, align 1
  %20606 = sext i32 %20579 to i64
  store i64 %20606, i64* %RDX.i1943, align 8
  %20607 = shl nsw i64 %20606, 1
  %20608 = add i64 %20542, %20607
  %20609 = add i64 %20458, 77
  store i64 %20609, i64* %3, align 8
  %20610 = inttoptr i64 %20608 to i16*
  %20611 = load i16, i16* %20610, align 2
  %20612 = zext i16 %20611 to i64
  store i64 %20612, i64* %RSI.i2015, align 8
  %20613 = load i64, i64* %RAX.i1659, align 8
  %20614 = zext i16 %20611 to i32
  %20615 = zext i16 %20611 to i64
  %20616 = trunc i64 %20613 to i32
  %20617 = add i32 %20614, %20616
  %20618 = zext i32 %20617 to i64
  store i64 %20618, i64* %RAX.i1659, align 8
  %20619 = icmp ult i32 %20617, %20616
  %20620 = icmp ult i32 %20617, %20614
  %20621 = or i1 %20619, %20620
  %20622 = zext i1 %20621 to i8
  store i8 %20622, i8* %17, align 1
  %20623 = and i32 %20617, 255
  %20624 = tail call i32 @llvm.ctpop.i32(i32 %20623)
  %20625 = trunc i32 %20624 to i8
  %20626 = and i8 %20625, 1
  %20627 = xor i8 %20626, 1
  store i8 %20627, i8* %18, align 1
  %20628 = xor i64 %20615, %20613
  %20629 = trunc i64 %20628 to i32
  %20630 = xor i32 %20629, %20617
  %20631 = lshr i32 %20630, 4
  %20632 = trunc i32 %20631 to i8
  %20633 = and i8 %20632, 1
  store i8 %20633, i8* %19, align 1
  %20634 = icmp eq i32 %20617, 0
  %20635 = zext i1 %20634 to i8
  store i8 %20635, i8* %20, align 1
  %20636 = lshr i32 %20617, 31
  %20637 = trunc i32 %20636 to i8
  store i8 %20637, i8* %21, align 1
  %20638 = lshr i32 %20616, 31
  %20639 = xor i32 %20636, %20638
  %20640 = add nuw nsw i32 %20639, %20636
  %20641 = icmp eq i32 %20640, 2
  %20642 = zext i1 %20641 to i8
  store i8 %20642, i8* %22, align 1
  %20643 = add i64 %20569, -784
  %20644 = add i64 %20458, 85
  store i64 %20644, i64* %3, align 8
  %20645 = inttoptr i64 %20643 to i32*
  store i32 %20617, i32* %20645, align 4
  %.pre545 = load i64, i64* %3, align 8
  br label %block_.L_486698

block_.L_486698:                                  ; preds = %block_.L_486643, %block_486636
  %20646 = phi i64 [ %.pre545, %block_.L_486643 ], [ %20464, %block_486636 ]
  %20647 = load i64, i64* %RBP.i, align 8
  %20648 = add i64 %20647, -784
  %20649 = add i64 %20646, 6
  store i64 %20649, i64* %3, align 8
  %20650 = inttoptr i64 %20648 to i32*
  %20651 = load i32, i32* %20650, align 4
  %20652 = zext i32 %20651 to i64
  store i64 %20652, i64* %RAX.i1659, align 8
  %20653 = add i64 %20647, -780
  %20654 = add i64 %20646, 12
  store i64 %20654, i64* %3, align 8
  %20655 = inttoptr i64 %20653 to i32*
  store i32 %20651, i32* %20655, align 4
  %.pre546 = load i64, i64* %3, align 8
  br label %block_.L_4866a4

block_.L_4866a4:                                  ; preds = %block_.L_486698, %block_4865c4
  %20656 = phi i64 [ %.pre546, %block_.L_486698 ], [ %20277, %block_4865c4 ]
  %20657 = load i64, i64* %RBP.i, align 8
  %20658 = add i64 %20657, -780
  %20659 = add i64 %20656, 6
  store i64 %20659, i64* %3, align 8
  %20660 = inttoptr i64 %20658 to i32*
  %20661 = load i32, i32* %20660, align 4
  %20662 = zext i32 %20661 to i64
  store i64 %20662, i64* %RAX.i1659, align 8
  %20663 = trunc i32 %20661 to i16
  store i16 %20663, i16* %CX.i4340, align 2
  %20664 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %20664, i64* %RDX.i1943, align 8
  %20665 = add i64 %20664, 6464
  %20666 = add i64 %20656, 24
  store i64 %20666, i64* %3, align 8
  %20667 = inttoptr i64 %20665 to i64*
  %20668 = load i64, i64* %20667, align 8
  store i64 %20668, i64* %RDX.i1943, align 8
  %20669 = add i64 %20668, 8
  %20670 = add i64 %20656, 28
  store i64 %20670, i64* %3, align 8
  %20671 = inttoptr i64 %20669 to i64*
  %20672 = load i64, i64* %20671, align 8
  store i64 %20672, i64* %RDX.i1943, align 8
  %20673 = add i64 %20657, -232
  %20674 = add i64 %20656, 34
  store i64 %20674, i64* %3, align 8
  %20675 = inttoptr i64 %20673 to i32*
  %20676 = load i32, i32* %20675, align 4
  %20677 = zext i32 %20676 to i64
  store i64 %20677, i64* %RAX.i1659, align 8
  %20678 = add i64 %20657, -48
  %20679 = add i64 %20656, 37
  store i64 %20679, i64* %3, align 8
  %20680 = inttoptr i64 %20678 to i32*
  %20681 = load i32, i32* %20680, align 4
  %20682 = add i32 %20681, %20676
  %20683 = zext i32 %20682 to i64
  store i64 %20683, i64* %RAX.i1659, align 8
  %20684 = icmp ult i32 %20682, %20676
  %20685 = icmp ult i32 %20682, %20681
  %20686 = or i1 %20684, %20685
  %20687 = zext i1 %20686 to i8
  store i8 %20687, i8* %17, align 1
  %20688 = and i32 %20682, 255
  %20689 = tail call i32 @llvm.ctpop.i32(i32 %20688)
  %20690 = trunc i32 %20689 to i8
  %20691 = and i8 %20690, 1
  %20692 = xor i8 %20691, 1
  store i8 %20692, i8* %18, align 1
  %20693 = xor i32 %20681, %20676
  %20694 = xor i32 %20693, %20682
  %20695 = lshr i32 %20694, 4
  %20696 = trunc i32 %20695 to i8
  %20697 = and i8 %20696, 1
  store i8 %20697, i8* %19, align 1
  %20698 = icmp eq i32 %20682, 0
  %20699 = zext i1 %20698 to i8
  store i8 %20699, i8* %20, align 1
  %20700 = lshr i32 %20682, 31
  %20701 = trunc i32 %20700 to i8
  store i8 %20701, i8* %21, align 1
  %20702 = lshr i32 %20676, 31
  %20703 = lshr i32 %20681, 31
  %20704 = xor i32 %20700, %20702
  %20705 = xor i32 %20700, %20703
  %20706 = add nuw nsw i32 %20704, %20705
  %20707 = icmp eq i32 %20706, 2
  %20708 = zext i1 %20707 to i8
  store i8 %20708, i8* %22, align 1
  %20709 = sext i32 %20682 to i64
  store i64 %20709, i64* %RSI.i2015, align 8
  %20710 = shl nsw i64 %20709, 3
  %20711 = add i64 %20672, %20710
  %20712 = add i64 %20656, 44
  store i64 %20712, i64* %3, align 8
  %20713 = inttoptr i64 %20711 to i64*
  %20714 = load i64, i64* %20713, align 8
  store i64 %20714, i64* %RDX.i1943, align 8
  %20715 = add i64 %20657, -228
  %20716 = add i64 %20656, 50
  store i64 %20716, i64* %3, align 8
  %20717 = inttoptr i64 %20715 to i32*
  %20718 = load i32, i32* %20717, align 4
  %20719 = zext i32 %20718 to i64
  store i64 %20719, i64* %RAX.i1659, align 8
  %20720 = add i64 %20657, -44
  %20721 = add i64 %20656, 53
  store i64 %20721, i64* %3, align 8
  %20722 = inttoptr i64 %20720 to i32*
  %20723 = load i32, i32* %20722, align 4
  %20724 = add i32 %20723, %20718
  %20725 = zext i32 %20724 to i64
  store i64 %20725, i64* %RAX.i1659, align 8
  %20726 = icmp ult i32 %20724, %20718
  %20727 = icmp ult i32 %20724, %20723
  %20728 = or i1 %20726, %20727
  %20729 = zext i1 %20728 to i8
  store i8 %20729, i8* %17, align 1
  %20730 = and i32 %20724, 255
  %20731 = tail call i32 @llvm.ctpop.i32(i32 %20730)
  %20732 = trunc i32 %20731 to i8
  %20733 = and i8 %20732, 1
  %20734 = xor i8 %20733, 1
  store i8 %20734, i8* %18, align 1
  %20735 = xor i32 %20723, %20718
  %20736 = xor i32 %20735, %20724
  %20737 = lshr i32 %20736, 4
  %20738 = trunc i32 %20737 to i8
  %20739 = and i8 %20738, 1
  store i8 %20739, i8* %19, align 1
  %20740 = icmp eq i32 %20724, 0
  %20741 = zext i1 %20740 to i8
  store i8 %20741, i8* %20, align 1
  %20742 = lshr i32 %20724, 31
  %20743 = trunc i32 %20742 to i8
  store i8 %20743, i8* %21, align 1
  %20744 = lshr i32 %20718, 31
  %20745 = lshr i32 %20723, 31
  %20746 = xor i32 %20742, %20744
  %20747 = xor i32 %20742, %20745
  %20748 = add nuw nsw i32 %20746, %20747
  %20749 = icmp eq i32 %20748, 2
  %20750 = zext i1 %20749 to i8
  store i8 %20750, i8* %22, align 1
  %20751 = sext i32 %20724 to i64
  store i64 %20751, i64* %RSI.i2015, align 8
  %20752 = shl nsw i64 %20751, 1
  %20753 = add i64 %20714, %20752
  %20754 = load i16, i16* %CX.i4340, align 2
  %20755 = add i64 %20656, 60
  store i64 %20755, i64* %3, align 8
  %20756 = inttoptr i64 %20753 to i16*
  store i16 %20754, i16* %20756, align 2
  %20757 = load i64, i64* %RBP.i, align 8
  %20758 = add i64 %20757, -44
  %20759 = load i64, i64* %3, align 8
  %20760 = add i64 %20759, 3
  store i64 %20760, i64* %3, align 8
  %20761 = inttoptr i64 %20758 to i32*
  %20762 = load i32, i32* %20761, align 4
  %20763 = add i32 %20762, 1
  %20764 = zext i32 %20763 to i64
  store i64 %20764, i64* %RAX.i1659, align 8
  %20765 = icmp eq i32 %20762, -1
  %20766 = icmp eq i32 %20763, 0
  %20767 = or i1 %20765, %20766
  %20768 = zext i1 %20767 to i8
  store i8 %20768, i8* %17, align 1
  %20769 = and i32 %20763, 255
  %20770 = tail call i32 @llvm.ctpop.i32(i32 %20769)
  %20771 = trunc i32 %20770 to i8
  %20772 = and i8 %20771, 1
  %20773 = xor i8 %20772, 1
  store i8 %20773, i8* %18, align 1
  %20774 = xor i32 %20763, %20762
  %20775 = lshr i32 %20774, 4
  %20776 = trunc i32 %20775 to i8
  %20777 = and i8 %20776, 1
  store i8 %20777, i8* %19, align 1
  %20778 = zext i1 %20766 to i8
  store i8 %20778, i8* %20, align 1
  %20779 = lshr i32 %20763, 31
  %20780 = trunc i32 %20779 to i8
  store i8 %20780, i8* %21, align 1
  %20781 = lshr i32 %20762, 31
  %20782 = xor i32 %20779, %20781
  %20783 = add nuw nsw i32 %20782, %20779
  %20784 = icmp eq i32 %20783, 2
  %20785 = zext i1 %20784 to i8
  store i8 %20785, i8* %22, align 1
  %20786 = add i64 %20759, 9
  store i64 %20786, i64* %3, align 8
  store i32 %20763, i32* %20761, align 4
  %20787 = load i64, i64* %3, align 8
  %20788 = add i64 %20787, -1631
  store i64 %20788, i64* %3, align 8
  br label %block_.L_48608a

block_.L_4866ee:                                  ; preds = %block_.L_48608a
  %20789 = add i64 %17780, -48
  %20790 = add i64 %17808, 8
  store i64 %20790, i64* %3, align 8
  %20791 = inttoptr i64 %20789 to i32*
  %20792 = load i32, i32* %20791, align 4
  %20793 = add i32 %20792, 1
  %20794 = zext i32 %20793 to i64
  store i64 %20794, i64* %RAX.i1659, align 8
  %20795 = icmp eq i32 %20792, -1
  %20796 = icmp eq i32 %20793, 0
  %20797 = or i1 %20795, %20796
  %20798 = zext i1 %20797 to i8
  store i8 %20798, i8* %17, align 1
  %20799 = and i32 %20793, 255
  %20800 = tail call i32 @llvm.ctpop.i32(i32 %20799)
  %20801 = trunc i32 %20800 to i8
  %20802 = and i8 %20801, 1
  %20803 = xor i8 %20802, 1
  store i8 %20803, i8* %18, align 1
  %20804 = xor i32 %20793, %20792
  %20805 = lshr i32 %20804, 4
  %20806 = trunc i32 %20805 to i8
  %20807 = and i8 %20806, 1
  store i8 %20807, i8* %19, align 1
  %20808 = zext i1 %20796 to i8
  store i8 %20808, i8* %20, align 1
  %20809 = lshr i32 %20793, 31
  %20810 = trunc i32 %20809 to i8
  store i8 %20810, i8* %21, align 1
  %20811 = lshr i32 %20792, 31
  %20812 = xor i32 %20809, %20811
  %20813 = add nuw nsw i32 %20812, %20809
  %20814 = icmp eq i32 %20813, 2
  %20815 = zext i1 %20814 to i8
  store i8 %20815, i8* %22, align 1
  %20816 = add i64 %17808, 14
  store i64 %20816, i64* %3, align 8
  store i32 %20793, i32* %20791, align 4
  %20817 = load i64, i64* %3, align 8
  %20818 = add i64 %20817, -1667
  store i64 %20818, i64* %3, align 8
  br label %block_.L_486079

block_.L_486701:                                  ; preds = %block_.L_486079
  %20819 = add i64 %17775, 5
  store i64 %20819, i64* %3, align 8
  br label %block_.L_486706

block_.L_486706:                                  ; preds = %block_.L_486701, %block_.L_4858b5
  %.pre561 = phi i64 [ %.pre561.pre, %block_.L_4858b5 ], [ %17747, %block_.L_486701 ]
  %storemerge216 = phi i64 [ %13758, %block_.L_4858b5 ], [ %20819, %block_.L_486701 ]
  %MEMORY.96 = phi %struct.Memory* [ %call2_4858ca, %block_.L_4858b5 ], [ %17464, %block_.L_486701 ]
  %20820 = add i64 %storemerge216, 928
  br label %block_.L_486aa6

block_.L_48670b:                                  ; preds = %block_.L_485737
  %20821 = load i64, i64* %RBP.i, align 8
  %20822 = add i64 %20821, -48
  %20823 = add i64 %13127, 7
  store i64 %20823, i64* %3, align 8
  %20824 = inttoptr i64 %20822 to i32*
  store i32 0, i32* %20824, align 4
  %.pre552 = load i64, i64* %3, align 8
  br label %block_.L_486712

block_.L_486712:                                  ; preds = %block_.L_486780, %block_.L_48670b
  %20825 = phi i64 [ %21010, %block_.L_486780 ], [ %.pre552, %block_.L_48670b ]
  %20826 = load i64, i64* %RBP.i, align 8
  %20827 = add i64 %20826, -48
  %20828 = add i64 %20825, 4
  store i64 %20828, i64* %3, align 8
  %20829 = inttoptr i64 %20827 to i32*
  %20830 = load i32, i32* %20829, align 4
  %20831 = add i32 %20830, -2
  %20832 = icmp ult i32 %20830, 2
  %20833 = zext i1 %20832 to i8
  store i8 %20833, i8* %17, align 1
  %20834 = and i32 %20831, 255
  %20835 = tail call i32 @llvm.ctpop.i32(i32 %20834)
  %20836 = trunc i32 %20835 to i8
  %20837 = and i8 %20836, 1
  %20838 = xor i8 %20837, 1
  store i8 %20838, i8* %18, align 1
  %20839 = xor i32 %20831, %20830
  %20840 = lshr i32 %20839, 4
  %20841 = trunc i32 %20840 to i8
  %20842 = and i8 %20841, 1
  store i8 %20842, i8* %19, align 1
  %20843 = icmp eq i32 %20831, 0
  %20844 = zext i1 %20843 to i8
  store i8 %20844, i8* %20, align 1
  %20845 = lshr i32 %20831, 31
  %20846 = trunc i32 %20845 to i8
  store i8 %20846, i8* %21, align 1
  %20847 = lshr i32 %20830, 31
  %20848 = xor i32 %20845, %20847
  %20849 = add nuw nsw i32 %20848, %20847
  %20850 = icmp eq i32 %20849, 2
  %20851 = zext i1 %20850 to i8
  store i8 %20851, i8* %22, align 1
  %20852 = icmp ne i8 %20846, 0
  %20853 = xor i1 %20852, %20850
  %.v702 = select i1 %20853, i64 10, i64 129
  %20854 = add i64 %20825, %.v702
  store i64 %20854, i64* %3, align 8
  br i1 %20853, label %block_48671c, label %block_.L_486793

block_48671c:                                     ; preds = %block_.L_486712
  %20855 = add i64 %20826, -44
  %20856 = add i64 %20854, 7
  store i64 %20856, i64* %3, align 8
  %20857 = inttoptr i64 %20855 to i32*
  store i32 0, i32* %20857, align 4
  %.pre563 = load i64, i64* %3, align 8
  br label %block_.L_486723

block_.L_486723:                                  ; preds = %block_48672d, %block_48671c
  %20858 = phi i64 [ %20980, %block_48672d ], [ %.pre563, %block_48671c ]
  %20859 = load i64, i64* %RBP.i, align 8
  %20860 = add i64 %20859, -44
  %20861 = add i64 %20858, 4
  store i64 %20861, i64* %3, align 8
  %20862 = inttoptr i64 %20860 to i32*
  %20863 = load i32, i32* %20862, align 4
  %20864 = add i32 %20863, -18
  %20865 = icmp ult i32 %20863, 18
  %20866 = zext i1 %20865 to i8
  store i8 %20866, i8* %17, align 1
  %20867 = and i32 %20864, 255
  %20868 = tail call i32 @llvm.ctpop.i32(i32 %20867)
  %20869 = trunc i32 %20868 to i8
  %20870 = and i8 %20869, 1
  %20871 = xor i8 %20870, 1
  store i8 %20871, i8* %18, align 1
  %20872 = xor i32 %20863, 16
  %20873 = xor i32 %20872, %20864
  %20874 = lshr i32 %20873, 4
  %20875 = trunc i32 %20874 to i8
  %20876 = and i8 %20875, 1
  store i8 %20876, i8* %19, align 1
  %20877 = icmp eq i32 %20864, 0
  %20878 = zext i1 %20877 to i8
  store i8 %20878, i8* %20, align 1
  %20879 = lshr i32 %20864, 31
  %20880 = trunc i32 %20879 to i8
  store i8 %20880, i8* %21, align 1
  %20881 = lshr i32 %20863, 31
  %20882 = xor i32 %20879, %20881
  %20883 = add nuw nsw i32 %20882, %20881
  %20884 = icmp eq i32 %20883, 2
  %20885 = zext i1 %20884 to i8
  store i8 %20885, i8* %22, align 1
  %20886 = icmp ne i8 %20880, 0
  %20887 = xor i1 %20886, %20884
  %.v670 = select i1 %20887, i64 10, i64 93
  %20888 = add i64 %20858, %.v670
  store i64 %20888, i64* %3, align 8
  br i1 %20887, label %block_48672d, label %block_.L_486780

block_48672d:                                     ; preds = %block_.L_486723
  %20889 = load i64, i64* bitcast (%G_0x6cc608_type* @G_0x6cc608 to i64*), align 8
  store i64 %20889, i64* %RAX.i1659, align 8
  %20890 = add i64 %20859, -48
  %20891 = add i64 %20888, 12
  store i64 %20891, i64* %3, align 8
  %20892 = inttoptr i64 %20890 to i32*
  %20893 = load i32, i32* %20892, align 4
  %20894 = sext i32 %20893 to i64
  store i64 %20894, i64* %RCX.i1588, align 8
  %20895 = shl nsw i64 %20894, 3
  %20896 = add i64 %20895, %20889
  %20897 = add i64 %20888, 16
  store i64 %20897, i64* %3, align 8
  %20898 = inttoptr i64 %20896 to i64*
  %20899 = load i64, i64* %20898, align 8
  store i64 %20899, i64* %RAX.i1659, align 8
  %20900 = add i64 %20888, 20
  store i64 %20900, i64* %3, align 8
  %20901 = load i32, i32* %20862, align 4
  %20902 = sext i32 %20901 to i64
  store i64 %20902, i64* %RCX.i1588, align 8
  %20903 = shl nsw i64 %20902, 2
  %20904 = add i64 %20903, %20899
  %20905 = add i64 %20888, 23
  store i64 %20905, i64* %3, align 8
  %20906 = inttoptr i64 %20904 to i32*
  %20907 = load i32, i32* %20906, align 4
  %20908 = zext i32 %20907 to i64
  store i64 %20908, i64* %RDX.i1943, align 8
  %20909 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %20909, i64* %RAX.i1659, align 8
  %20910 = add i64 %20909, 14136
  %20911 = add i64 %20888, 38
  store i64 %20911, i64* %3, align 8
  %20912 = inttoptr i64 %20910 to i64*
  %20913 = load i64, i64* %20912, align 8
  store i64 %20913, i64* %RAX.i1659, align 8
  %20914 = add i64 %20859, -12
  %20915 = add i64 %20888, 42
  store i64 %20915, i64* %3, align 8
  %20916 = inttoptr i64 %20914 to i32*
  %20917 = load i32, i32* %20916, align 4
  %20918 = sext i32 %20917 to i64
  store i64 %20918, i64* %RCX.i1588, align 8
  %20919 = shl nsw i64 %20918, 3
  %20920 = add i64 %20919, %20913
  %20921 = add i64 %20888, 46
  store i64 %20921, i64* %3, align 8
  %20922 = inttoptr i64 %20920 to i64*
  %20923 = load i64, i64* %20922, align 8
  store i64 %20923, i64* %RAX.i1659, align 8
  %20924 = add i64 %20859, -16
  %20925 = add i64 %20888, 50
  store i64 %20925, i64* %3, align 8
  %20926 = inttoptr i64 %20924 to i32*
  %20927 = load i32, i32* %20926, align 4
  %20928 = sext i32 %20927 to i64
  store i64 %20928, i64* %RCX.i1588, align 8
  %20929 = shl nsw i64 %20928, 3
  %20930 = add i64 %20929, %20923
  %20931 = add i64 %20888, 54
  store i64 %20931, i64* %3, align 8
  %20932 = inttoptr i64 %20930 to i64*
  %20933 = load i64, i64* %20932, align 8
  store i64 %20933, i64* %RAX.i1659, align 8
  %20934 = add i64 %20888, 58
  store i64 %20934, i64* %3, align 8
  %20935 = load i32, i32* %20892, align 4
  %20936 = sext i32 %20935 to i64
  store i64 %20936, i64* %RCX.i1588, align 8
  %20937 = shl nsw i64 %20936, 3
  %20938 = add i64 %20937, %20933
  %20939 = add i64 %20888, 62
  store i64 %20939, i64* %3, align 8
  %20940 = inttoptr i64 %20938 to i64*
  %20941 = load i64, i64* %20940, align 8
  store i64 %20941, i64* %RAX.i1659, align 8
  %20942 = add i64 %20888, 66
  store i64 %20942, i64* %3, align 8
  %20943 = load i32, i32* %20862, align 4
  %20944 = sext i32 %20943 to i64
  store i64 %20944, i64* %RCX.i1588, align 8
  %20945 = shl nsw i64 %20944, 2
  %20946 = add i64 %20945, %20941
  %20947 = add i64 %20888, 69
  store i64 %20947, i64* %3, align 8
  %20948 = inttoptr i64 %20946 to i32*
  store i32 %20907, i32* %20948, align 4
  %20949 = load i64, i64* %RBP.i, align 8
  %20950 = add i64 %20949, -44
  %20951 = load i64, i64* %3, align 8
  %20952 = add i64 %20951, 3
  store i64 %20952, i64* %3, align 8
  %20953 = inttoptr i64 %20950 to i32*
  %20954 = load i32, i32* %20953, align 4
  %20955 = add i32 %20954, 1
  %20956 = zext i32 %20955 to i64
  store i64 %20956, i64* %RAX.i1659, align 8
  %20957 = icmp eq i32 %20954, -1
  %20958 = icmp eq i32 %20955, 0
  %20959 = or i1 %20957, %20958
  %20960 = zext i1 %20959 to i8
  store i8 %20960, i8* %17, align 1
  %20961 = and i32 %20955, 255
  %20962 = tail call i32 @llvm.ctpop.i32(i32 %20961)
  %20963 = trunc i32 %20962 to i8
  %20964 = and i8 %20963, 1
  %20965 = xor i8 %20964, 1
  store i8 %20965, i8* %18, align 1
  %20966 = xor i32 %20955, %20954
  %20967 = lshr i32 %20966, 4
  %20968 = trunc i32 %20967 to i8
  %20969 = and i8 %20968, 1
  store i8 %20969, i8* %19, align 1
  %20970 = zext i1 %20958 to i8
  store i8 %20970, i8* %20, align 1
  %20971 = lshr i32 %20955, 31
  %20972 = trunc i32 %20971 to i8
  store i8 %20972, i8* %21, align 1
  %20973 = lshr i32 %20954, 31
  %20974 = xor i32 %20971, %20973
  %20975 = add nuw nsw i32 %20974, %20971
  %20976 = icmp eq i32 %20975, 2
  %20977 = zext i1 %20976 to i8
  store i8 %20977, i8* %22, align 1
  %20978 = add i64 %20951, 9
  store i64 %20978, i64* %3, align 8
  store i32 %20955, i32* %20953, align 4
  %20979 = load i64, i64* %3, align 8
  %20980 = add i64 %20979, -88
  store i64 %20980, i64* %3, align 8
  br label %block_.L_486723

block_.L_486780:                                  ; preds = %block_.L_486723
  %20981 = add i64 %20859, -48
  %20982 = add i64 %20888, 8
  store i64 %20982, i64* %3, align 8
  %20983 = inttoptr i64 %20981 to i32*
  %20984 = load i32, i32* %20983, align 4
  %20985 = add i32 %20984, 1
  %20986 = zext i32 %20985 to i64
  store i64 %20986, i64* %RAX.i1659, align 8
  %20987 = icmp eq i32 %20984, -1
  %20988 = icmp eq i32 %20985, 0
  %20989 = or i1 %20987, %20988
  %20990 = zext i1 %20989 to i8
  store i8 %20990, i8* %17, align 1
  %20991 = and i32 %20985, 255
  %20992 = tail call i32 @llvm.ctpop.i32(i32 %20991)
  %20993 = trunc i32 %20992 to i8
  %20994 = and i8 %20993, 1
  %20995 = xor i8 %20994, 1
  store i8 %20995, i8* %18, align 1
  %20996 = xor i32 %20985, %20984
  %20997 = lshr i32 %20996, 4
  %20998 = trunc i32 %20997 to i8
  %20999 = and i8 %20998, 1
  store i8 %20999, i8* %19, align 1
  %21000 = zext i1 %20988 to i8
  store i8 %21000, i8* %20, align 1
  %21001 = lshr i32 %20985, 31
  %21002 = trunc i32 %21001 to i8
  store i8 %21002, i8* %21, align 1
  %21003 = lshr i32 %20984, 31
  %21004 = xor i32 %21001, %21003
  %21005 = add nuw nsw i32 %21004, %21001
  %21006 = icmp eq i32 %21005, 2
  %21007 = zext i1 %21006 to i8
  store i8 %21007, i8* %22, align 1
  %21008 = add i64 %20888, 14
  store i64 %21008, i64* %3, align 8
  store i32 %20985, i32* %20983, align 4
  %21009 = load i64, i64* %3, align 8
  %21010 = add i64 %21009, -124
  store i64 %21010, i64* %3, align 8
  br label %block_.L_486712

block_.L_486793:                                  ; preds = %block_.L_486712
  %21011 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %21011, i64* %RAX.i1659, align 8
  %21012 = add i64 %21011, 72724
  %21013 = add i64 %20854, 15
  store i64 %21013, i64* %3, align 8
  %21014 = inttoptr i64 %21012 to i32*
  %21015 = load i32, i32* %21014, align 4
  store i8 0, i8* %17, align 1
  %21016 = and i32 %21015, 255
  %21017 = tail call i32 @llvm.ctpop.i32(i32 %21016)
  %21018 = trunc i32 %21017 to i8
  %21019 = and i8 %21018, 1
  %21020 = xor i8 %21019, 1
  store i8 %21020, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %21021 = icmp eq i32 %21015, 0
  %21022 = zext i1 %21021 to i8
  store i8 %21022, i8* %20, align 1
  %21023 = lshr i32 %21015, 31
  %21024 = trunc i32 %21023 to i8
  store i8 %21024, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v703 = select i1 %21021, i64 324, i64 21
  %21025 = add i64 %20854, %.v703
  store i64 %21025, i64* %3, align 8
  br i1 %21021, label %block_.L_4868d7, label %block_4867a8

block_4867a8:                                     ; preds = %block_.L_486793
  %21026 = add i64 %21025, 7
  store i64 %21026, i64* %3, align 8
  store i32 0, i32* %20829, align 4
  %.pre553 = load i64, i64* %3, align 8
  br label %block_.L_4867af

block_.L_4867af:                                  ; preds = %block_.L_486827, %block_4867a8
  %21027 = phi i64 [ %21260, %block_.L_486827 ], [ %.pre553, %block_4867a8 ]
  %21028 = load i64, i64* %RBP.i, align 8
  %21029 = add i64 %21028, -48
  %21030 = add i64 %21027, 4
  store i64 %21030, i64* %3, align 8
  %21031 = inttoptr i64 %21029 to i32*
  %21032 = load i32, i32* %21031, align 4
  %21033 = add i32 %21032, -2
  %21034 = icmp ult i32 %21032, 2
  %21035 = zext i1 %21034 to i8
  store i8 %21035, i8* %17, align 1
  %21036 = and i32 %21033, 255
  %21037 = tail call i32 @llvm.ctpop.i32(i32 %21036)
  %21038 = trunc i32 %21037 to i8
  %21039 = and i8 %21038, 1
  %21040 = xor i8 %21039, 1
  store i8 %21040, i8* %18, align 1
  %21041 = xor i32 %21033, %21032
  %21042 = lshr i32 %21041, 4
  %21043 = trunc i32 %21042 to i8
  %21044 = and i8 %21043, 1
  store i8 %21044, i8* %19, align 1
  %21045 = icmp eq i32 %21033, 0
  %21046 = zext i1 %21045 to i8
  store i8 %21046, i8* %20, align 1
  %21047 = lshr i32 %21033, 31
  %21048 = trunc i32 %21047 to i8
  store i8 %21048, i8* %21, align 1
  %21049 = lshr i32 %21032, 31
  %21050 = xor i32 %21047, %21049
  %21051 = add nuw nsw i32 %21050, %21049
  %21052 = icmp eq i32 %21051, 2
  %21053 = zext i1 %21052 to i8
  store i8 %21053, i8* %22, align 1
  %21054 = icmp ne i8 %21048, 0
  %21055 = xor i1 %21054, %21052
  %.v704 = select i1 %21055, i64 10, i64 139
  %21056 = add i64 %21027, %.v704
  store i64 %21056, i64* %3, align 8
  br i1 %21055, label %block_4867b9, label %block_.L_48683a

block_4867b9:                                     ; preds = %block_.L_4867af
  %21057 = add i64 %21028, -44
  %21058 = add i64 %21056, 7
  store i64 %21058, i64* %3, align 8
  %21059 = inttoptr i64 %21057 to i32*
  store i32 0, i32* %21059, align 4
  %.pre556 = load i64, i64* %3, align 8
  br label %block_.L_4867c0

block_.L_4867c0:                                  ; preds = %block_4867ca, %block_4867b9
  %21060 = phi i64 [ %21230, %block_4867ca ], [ %.pre556, %block_4867b9 ]
  %21061 = load i64, i64* %RBP.i, align 8
  %21062 = add i64 %21061, -44
  %21063 = add i64 %21060, 4
  store i64 %21063, i64* %3, align 8
  %21064 = inttoptr i64 %21062 to i32*
  %21065 = load i32, i32* %21064, align 4
  %21066 = add i32 %21065, -18
  %21067 = icmp ult i32 %21065, 18
  %21068 = zext i1 %21067 to i8
  store i8 %21068, i8* %17, align 1
  %21069 = and i32 %21066, 255
  %21070 = tail call i32 @llvm.ctpop.i32(i32 %21069)
  %21071 = trunc i32 %21070 to i8
  %21072 = and i8 %21071, 1
  %21073 = xor i8 %21072, 1
  store i8 %21073, i8* %18, align 1
  %21074 = xor i32 %21065, 16
  %21075 = xor i32 %21074, %21066
  %21076 = lshr i32 %21075, 4
  %21077 = trunc i32 %21076 to i8
  %21078 = and i8 %21077, 1
  store i8 %21078, i8* %19, align 1
  %21079 = icmp eq i32 %21066, 0
  %21080 = zext i1 %21079 to i8
  store i8 %21080, i8* %20, align 1
  %21081 = lshr i32 %21066, 31
  %21082 = trunc i32 %21081 to i8
  store i8 %21082, i8* %21, align 1
  %21083 = lshr i32 %21065, 31
  %21084 = xor i32 %21081, %21083
  %21085 = add nuw nsw i32 %21084, %21083
  %21086 = icmp eq i32 %21085, 2
  %21087 = zext i1 %21086 to i8
  store i8 %21087, i8* %22, align 1
  %21088 = icmp ne i8 %21082, 0
  %21089 = xor i1 %21088, %21086
  %.v669 = select i1 %21089, i64 10, i64 103
  %21090 = add i64 %21060, %.v669
  store i64 %21090, i64* %3, align 8
  br i1 %21089, label %block_4867ca, label %block_.L_486827

block_4867ca:                                     ; preds = %block_.L_4867c0
  store i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64* %RAX.i1659, align 8
  %21091 = add i64 %21061, -48
  %21092 = add i64 %21090, 14
  store i64 %21092, i64* %3, align 8
  %21093 = inttoptr i64 %21091 to i32*
  %21094 = load i32, i32* %21093, align 4
  %21095 = sext i32 %21094 to i64
  %21096 = mul nsw i64 %21095, 72
  store i64 %21096, i64* %RCX.i1588, align 8
  %21097 = lshr i64 %21096, 63
  %21098 = add i64 %21096, ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64)
  store i64 %21098, i64* %RAX.i1659, align 8
  %21099 = icmp ult i64 %21098, ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64)
  %21100 = icmp ult i64 %21098, %21096
  %21101 = or i1 %21099, %21100
  %21102 = zext i1 %21101 to i8
  store i8 %21102, i8* %17, align 1
  %21103 = trunc i64 %21098 to i32
  %21104 = and i32 %21103, 248
  %21105 = tail call i32 @llvm.ctpop.i32(i32 %21104)
  %21106 = trunc i32 %21105 to i8
  %21107 = and i8 %21106, 1
  %21108 = xor i8 %21107, 1
  store i8 %21108, i8* %18, align 1
  %21109 = xor i64 %21096, ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64)
  %21110 = xor i64 %21109, %21098
  %21111 = lshr i64 %21110, 4
  %21112 = trunc i64 %21111 to i8
  %21113 = and i8 %21112, 1
  store i8 %21113, i8* %19, align 1
  %21114 = icmp eq i64 %21098, 0
  %21115 = zext i1 %21114 to i8
  store i8 %21115, i8* %20, align 1
  %21116 = lshr i64 %21098, 63
  %21117 = trunc i64 %21116 to i8
  store i8 %21117, i8* %21, align 1
  %21118 = xor i64 %21116, lshr (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 63)
  %21119 = xor i64 %21116, %21097
  %21120 = add nuw nsw i64 %21118, %21119
  %21121 = icmp eq i64 %21120, 2
  %21122 = zext i1 %21121 to i8
  store i8 %21122, i8* %22, align 1
  %21123 = add i64 %21090, 25
  store i64 %21123, i64* %3, align 8
  %21124 = load i32, i32* %21064, align 4
  %21125 = sext i32 %21124 to i64
  store i64 %21125, i64* %RCX.i1588, align 8
  %21126 = shl nsw i64 %21125, 2
  %21127 = add i64 %21126, %21098
  %21128 = add i64 %21090, 28
  store i64 %21128, i64* %3, align 8
  %21129 = inttoptr i64 %21127 to i32*
  %21130 = load i32, i32* %21129, align 4
  %21131 = zext i32 %21130 to i64
  store i64 %21131, i64* %RDX.i1943, align 8
  %21132 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %21132, i64* %RAX.i1659, align 8
  %21133 = add i64 %21132, 14136
  %21134 = add i64 %21090, 43
  store i64 %21134, i64* %3, align 8
  %21135 = inttoptr i64 %21133 to i64*
  %21136 = load i64, i64* %21135, align 8
  store i64 %21136, i64* %RAX.i1659, align 8
  %21137 = add i64 %21061, -12
  %21138 = add i64 %21090, 46
  store i64 %21138, i64* %3, align 8
  %21139 = inttoptr i64 %21137 to i32*
  %21140 = load i32, i32* %21139, align 4
  %21141 = add i32 %21140, 4
  %21142 = zext i32 %21141 to i64
  store i64 %21142, i64* %RSI.i2015, align 8
  %21143 = icmp ugt i32 %21140, -5
  %21144 = zext i1 %21143 to i8
  store i8 %21144, i8* %17, align 1
  %21145 = and i32 %21141, 255
  %21146 = tail call i32 @llvm.ctpop.i32(i32 %21145)
  %21147 = trunc i32 %21146 to i8
  %21148 = and i8 %21147, 1
  %21149 = xor i8 %21148, 1
  store i8 %21149, i8* %18, align 1
  %21150 = xor i32 %21141, %21140
  %21151 = lshr i32 %21150, 4
  %21152 = trunc i32 %21151 to i8
  %21153 = and i8 %21152, 1
  store i8 %21153, i8* %19, align 1
  %21154 = icmp eq i32 %21141, 0
  %21155 = zext i1 %21154 to i8
  store i8 %21155, i8* %20, align 1
  %21156 = lshr i32 %21141, 31
  %21157 = trunc i32 %21156 to i8
  store i8 %21157, i8* %21, align 1
  %21158 = lshr i32 %21140, 31
  %21159 = xor i32 %21156, %21158
  %21160 = add nuw nsw i32 %21159, %21156
  %21161 = icmp eq i32 %21160, 2
  %21162 = zext i1 %21161 to i8
  store i8 %21162, i8* %22, align 1
  %21163 = sext i32 %21141 to i64
  store i64 %21163, i64* %RCX.i1588, align 8
  %21164 = shl nsw i64 %21163, 3
  %21165 = add i64 %21136, %21164
  %21166 = add i64 %21090, 56
  store i64 %21166, i64* %3, align 8
  %21167 = inttoptr i64 %21165 to i64*
  %21168 = load i64, i64* %21167, align 8
  store i64 %21168, i64* %RAX.i1659, align 8
  %21169 = load i64, i64* %RBP.i, align 8
  %21170 = add i64 %21169, -16
  %21171 = add i64 %21090, 60
  store i64 %21171, i64* %3, align 8
  %21172 = inttoptr i64 %21170 to i32*
  %21173 = load i32, i32* %21172, align 4
  %21174 = sext i32 %21173 to i64
  store i64 %21174, i64* %RCX.i1588, align 8
  %21175 = shl nsw i64 %21174, 3
  %21176 = add i64 %21175, %21168
  %21177 = add i64 %21090, 64
  store i64 %21177, i64* %3, align 8
  %21178 = inttoptr i64 %21176 to i64*
  %21179 = load i64, i64* %21178, align 8
  store i64 %21179, i64* %RAX.i1659, align 8
  %21180 = add i64 %21169, -48
  %21181 = add i64 %21090, 68
  store i64 %21181, i64* %3, align 8
  %21182 = inttoptr i64 %21180 to i32*
  %21183 = load i32, i32* %21182, align 4
  %21184 = sext i32 %21183 to i64
  store i64 %21184, i64* %RCX.i1588, align 8
  %21185 = shl nsw i64 %21184, 3
  %21186 = add i64 %21185, %21179
  %21187 = add i64 %21090, 72
  store i64 %21187, i64* %3, align 8
  %21188 = inttoptr i64 %21186 to i64*
  %21189 = load i64, i64* %21188, align 8
  store i64 %21189, i64* %RAX.i1659, align 8
  %21190 = add i64 %21169, -44
  %21191 = add i64 %21090, 76
  store i64 %21191, i64* %3, align 8
  %21192 = inttoptr i64 %21190 to i32*
  %21193 = load i32, i32* %21192, align 4
  %21194 = sext i32 %21193 to i64
  store i64 %21194, i64* %RCX.i1588, align 8
  %21195 = shl nsw i64 %21194, 2
  %21196 = add i64 %21195, %21189
  %21197 = add i64 %21090, 79
  store i64 %21197, i64* %3, align 8
  %21198 = inttoptr i64 %21196 to i32*
  store i32 %21130, i32* %21198, align 4
  %21199 = load i64, i64* %RBP.i, align 8
  %21200 = add i64 %21199, -44
  %21201 = load i64, i64* %3, align 8
  %21202 = add i64 %21201, 3
  store i64 %21202, i64* %3, align 8
  %21203 = inttoptr i64 %21200 to i32*
  %21204 = load i32, i32* %21203, align 4
  %21205 = add i32 %21204, 1
  %21206 = zext i32 %21205 to i64
  store i64 %21206, i64* %RAX.i1659, align 8
  %21207 = icmp eq i32 %21204, -1
  %21208 = icmp eq i32 %21205, 0
  %21209 = or i1 %21207, %21208
  %21210 = zext i1 %21209 to i8
  store i8 %21210, i8* %17, align 1
  %21211 = and i32 %21205, 255
  %21212 = tail call i32 @llvm.ctpop.i32(i32 %21211)
  %21213 = trunc i32 %21212 to i8
  %21214 = and i8 %21213, 1
  %21215 = xor i8 %21214, 1
  store i8 %21215, i8* %18, align 1
  %21216 = xor i32 %21205, %21204
  %21217 = lshr i32 %21216, 4
  %21218 = trunc i32 %21217 to i8
  %21219 = and i8 %21218, 1
  store i8 %21219, i8* %19, align 1
  %21220 = zext i1 %21208 to i8
  store i8 %21220, i8* %20, align 1
  %21221 = lshr i32 %21205, 31
  %21222 = trunc i32 %21221 to i8
  store i8 %21222, i8* %21, align 1
  %21223 = lshr i32 %21204, 31
  %21224 = xor i32 %21221, %21223
  %21225 = add nuw nsw i32 %21224, %21221
  %21226 = icmp eq i32 %21225, 2
  %21227 = zext i1 %21226 to i8
  store i8 %21227, i8* %22, align 1
  %21228 = add i64 %21201, 9
  store i64 %21228, i64* %3, align 8
  store i32 %21205, i32* %21203, align 4
  %21229 = load i64, i64* %3, align 8
  %21230 = add i64 %21229, -98
  store i64 %21230, i64* %3, align 8
  br label %block_.L_4867c0

block_.L_486827:                                  ; preds = %block_.L_4867c0
  %21231 = add i64 %21061, -48
  %21232 = add i64 %21090, 8
  store i64 %21232, i64* %3, align 8
  %21233 = inttoptr i64 %21231 to i32*
  %21234 = load i32, i32* %21233, align 4
  %21235 = add i32 %21234, 1
  %21236 = zext i32 %21235 to i64
  store i64 %21236, i64* %RAX.i1659, align 8
  %21237 = icmp eq i32 %21234, -1
  %21238 = icmp eq i32 %21235, 0
  %21239 = or i1 %21237, %21238
  %21240 = zext i1 %21239 to i8
  store i8 %21240, i8* %17, align 1
  %21241 = and i32 %21235, 255
  %21242 = tail call i32 @llvm.ctpop.i32(i32 %21241)
  %21243 = trunc i32 %21242 to i8
  %21244 = and i8 %21243, 1
  %21245 = xor i8 %21244, 1
  store i8 %21245, i8* %18, align 1
  %21246 = xor i32 %21235, %21234
  %21247 = lshr i32 %21246, 4
  %21248 = trunc i32 %21247 to i8
  %21249 = and i8 %21248, 1
  store i8 %21249, i8* %19, align 1
  %21250 = zext i1 %21238 to i8
  store i8 %21250, i8* %20, align 1
  %21251 = lshr i32 %21235, 31
  %21252 = trunc i32 %21251 to i8
  store i8 %21252, i8* %21, align 1
  %21253 = lshr i32 %21234, 31
  %21254 = xor i32 %21251, %21253
  %21255 = add nuw nsw i32 %21254, %21251
  %21256 = icmp eq i32 %21255, 2
  %21257 = zext i1 %21256 to i8
  store i8 %21257, i8* %22, align 1
  %21258 = add i64 %21090, 14
  store i64 %21258, i64* %3, align 8
  store i32 %21235, i32* %21233, align 4
  %21259 = load i64, i64* %3, align 8
  %21260 = add i64 %21259, -134
  store i64 %21260, i64* %3, align 8
  br label %block_.L_4867af

block_.L_48683a:                                  ; preds = %block_.L_4867af
  %21261 = add i64 %21056, 7
  store i64 %21261, i64* %3, align 8
  store i32 0, i32* %21031, align 4
  %.pre554 = load i64, i64* %3, align 8
  br label %block_.L_486841

block_.L_486841:                                  ; preds = %block_.L_4868bf, %block_.L_48683a
  %21262 = phi i64 [ %21495, %block_.L_4868bf ], [ %.pre554, %block_.L_48683a ]
  %21263 = load i64, i64* %RBP.i, align 8
  %21264 = add i64 %21263, -48
  %21265 = add i64 %21262, 4
  store i64 %21265, i64* %3, align 8
  %21266 = inttoptr i64 %21264 to i32*
  %21267 = load i32, i32* %21266, align 4
  %21268 = add i32 %21267, -2
  %21269 = icmp ult i32 %21267, 2
  %21270 = zext i1 %21269 to i8
  store i8 %21270, i8* %17, align 1
  %21271 = and i32 %21268, 255
  %21272 = tail call i32 @llvm.ctpop.i32(i32 %21271)
  %21273 = trunc i32 %21272 to i8
  %21274 = and i8 %21273, 1
  %21275 = xor i8 %21274, 1
  store i8 %21275, i8* %18, align 1
  %21276 = xor i32 %21268, %21267
  %21277 = lshr i32 %21276, 4
  %21278 = trunc i32 %21277 to i8
  %21279 = and i8 %21278, 1
  store i8 %21279, i8* %19, align 1
  %21280 = icmp eq i32 %21268, 0
  %21281 = zext i1 %21280 to i8
  store i8 %21281, i8* %20, align 1
  %21282 = lshr i32 %21268, 31
  %21283 = trunc i32 %21282 to i8
  store i8 %21283, i8* %21, align 1
  %21284 = lshr i32 %21267, 31
  %21285 = xor i32 %21282, %21284
  %21286 = add nuw nsw i32 %21285, %21284
  %21287 = icmp eq i32 %21286, 2
  %21288 = zext i1 %21287 to i8
  store i8 %21288, i8* %22, align 1
  %21289 = icmp ne i8 %21283, 0
  %21290 = xor i1 %21289, %21287
  %.v705 = select i1 %21290, i64 10, i64 145
  %21291 = add i64 %21262, %.v705
  store i64 %21291, i64* %3, align 8
  br i1 %21290, label %block_48684b, label %block_.L_4868d2

block_48684b:                                     ; preds = %block_.L_486841
  %21292 = add i64 %21263, -44
  %21293 = add i64 %21291, 7
  store i64 %21293, i64* %3, align 8
  %21294 = inttoptr i64 %21292 to i32*
  store i32 0, i32* %21294, align 4
  %.pre555 = load i64, i64* %3, align 8
  br label %block_.L_486852

block_.L_486852:                                  ; preds = %block_48685c, %block_48684b
  %21295 = phi i64 [ %21465, %block_48685c ], [ %.pre555, %block_48684b ]
  %21296 = load i64, i64* %RBP.i, align 8
  %21297 = add i64 %21296, -44
  %21298 = add i64 %21295, 4
  store i64 %21298, i64* %3, align 8
  %21299 = inttoptr i64 %21297 to i32*
  %21300 = load i32, i32* %21299, align 4
  %21301 = add i32 %21300, -18
  %21302 = icmp ult i32 %21300, 18
  %21303 = zext i1 %21302 to i8
  store i8 %21303, i8* %17, align 1
  %21304 = and i32 %21301, 255
  %21305 = tail call i32 @llvm.ctpop.i32(i32 %21304)
  %21306 = trunc i32 %21305 to i8
  %21307 = and i8 %21306, 1
  %21308 = xor i8 %21307, 1
  store i8 %21308, i8* %18, align 1
  %21309 = xor i32 %21300, 16
  %21310 = xor i32 %21309, %21301
  %21311 = lshr i32 %21310, 4
  %21312 = trunc i32 %21311 to i8
  %21313 = and i8 %21312, 1
  store i8 %21313, i8* %19, align 1
  %21314 = icmp eq i32 %21301, 0
  %21315 = zext i1 %21314 to i8
  store i8 %21315, i8* %20, align 1
  %21316 = lshr i32 %21301, 31
  %21317 = trunc i32 %21316 to i8
  store i8 %21317, i8* %21, align 1
  %21318 = lshr i32 %21300, 31
  %21319 = xor i32 %21316, %21318
  %21320 = add nuw nsw i32 %21319, %21318
  %21321 = icmp eq i32 %21320, 2
  %21322 = zext i1 %21321 to i8
  store i8 %21322, i8* %22, align 1
  %21323 = icmp ne i8 %21317, 0
  %21324 = xor i1 %21323, %21321
  %.v668 = select i1 %21324, i64 10, i64 109
  %21325 = add i64 %21295, %.v668
  store i64 %21325, i64* %3, align 8
  br i1 %21324, label %block_48685c, label %block_.L_4868bf

block_48685c:                                     ; preds = %block_.L_486852
  store i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64* %RAX.i1659, align 8
  store i8 zext (i1 or (i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64)), i1 icmp ult (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 144)) to i8), i8* %17, align 1
  store i8 %1194, i8* %18, align 1
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144)), i64 4) to i8), i8 1), i8* %19, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 0) to i8), i8* %20, align 1
  store i8 trunc (i64 lshr (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 63) to i8), i8* %21, align 1
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 63), i64 lshr (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 63)), i64 lshr (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 63)), i64 2) to i8), i8* %22, align 1
  %21326 = add i64 %21296, -48
  %21327 = add i64 %21325, 20
  store i64 %21327, i64* %3, align 8
  %21328 = inttoptr i64 %21326 to i32*
  %21329 = load i32, i32* %21328, align 4
  %21330 = sext i32 %21329 to i64
  %21331 = mul nsw i64 %21330, 72
  store i64 %21331, i64* %RCX.i1588, align 8
  %21332 = lshr i64 %21331, 63
  %21333 = add i64 %21331, add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144)
  store i64 %21333, i64* %RAX.i1659, align 8
  %21334 = icmp ult i64 %21333, add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144)
  %21335 = icmp ult i64 %21333, %21331
  %21336 = or i1 %21334, %21335
  %21337 = zext i1 %21336 to i8
  store i8 %21337, i8* %17, align 1
  %21338 = trunc i64 %21333 to i32
  %21339 = and i32 %21338, 248
  %21340 = tail call i32 @llvm.ctpop.i32(i32 %21339)
  %21341 = trunc i32 %21340 to i8
  %21342 = and i8 %21341, 1
  %21343 = xor i8 %21342, 1
  store i8 %21343, i8* %18, align 1
  %21344 = xor i64 %21331, add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144)
  %21345 = xor i64 %21344, %21333
  %21346 = lshr i64 %21345, 4
  %21347 = trunc i64 %21346 to i8
  %21348 = and i8 %21347, 1
  store i8 %21348, i8* %19, align 1
  %21349 = icmp eq i64 %21333, 0
  %21350 = zext i1 %21349 to i8
  store i8 %21350, i8* %20, align 1
  %21351 = lshr i64 %21333, 63
  %21352 = trunc i64 %21351 to i8
  store i8 %21352, i8* %21, align 1
  %21353 = xor i64 %21351, lshr (i64 add (i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64 144), i64 63)
  %21354 = xor i64 %21351, %21332
  %21355 = add nuw nsw i64 %21353, %21354
  %21356 = icmp eq i64 %21355, 2
  %21357 = zext i1 %21356 to i8
  store i8 %21357, i8* %22, align 1
  %21358 = add i64 %21325, 31
  store i64 %21358, i64* %3, align 8
  %21359 = load i32, i32* %21299, align 4
  %21360 = sext i32 %21359 to i64
  store i64 %21360, i64* %RCX.i1588, align 8
  %21361 = shl nsw i64 %21360, 2
  %21362 = add i64 %21361, %21333
  %21363 = add i64 %21325, 34
  store i64 %21363, i64* %3, align 8
  %21364 = inttoptr i64 %21362 to i32*
  %21365 = load i32, i32* %21364, align 4
  %21366 = zext i32 %21365 to i64
  store i64 %21366, i64* %RDX.i1943, align 8
  %21367 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %21367, i64* %RAX.i1659, align 8
  %21368 = add i64 %21367, 14136
  %21369 = add i64 %21325, 49
  store i64 %21369, i64* %3, align 8
  %21370 = inttoptr i64 %21368 to i64*
  %21371 = load i64, i64* %21370, align 8
  store i64 %21371, i64* %RAX.i1659, align 8
  %21372 = load i64, i64* %RBP.i, align 8
  %21373 = add i64 %21372, -12
  %21374 = add i64 %21325, 52
  store i64 %21374, i64* %3, align 8
  %21375 = inttoptr i64 %21373 to i32*
  %21376 = load i32, i32* %21375, align 4
  %21377 = add i32 %21376, 8
  %21378 = zext i32 %21377 to i64
  store i64 %21378, i64* %RSI.i2015, align 8
  %21379 = icmp ugt i32 %21376, -9
  %21380 = zext i1 %21379 to i8
  store i8 %21380, i8* %17, align 1
  %21381 = and i32 %21377, 255
  %21382 = tail call i32 @llvm.ctpop.i32(i32 %21381)
  %21383 = trunc i32 %21382 to i8
  %21384 = and i8 %21383, 1
  %21385 = xor i8 %21384, 1
  store i8 %21385, i8* %18, align 1
  %21386 = xor i32 %21377, %21376
  %21387 = lshr i32 %21386, 4
  %21388 = trunc i32 %21387 to i8
  %21389 = and i8 %21388, 1
  store i8 %21389, i8* %19, align 1
  %21390 = icmp eq i32 %21377, 0
  %21391 = zext i1 %21390 to i8
  store i8 %21391, i8* %20, align 1
  %21392 = lshr i32 %21377, 31
  %21393 = trunc i32 %21392 to i8
  store i8 %21393, i8* %21, align 1
  %21394 = lshr i32 %21376, 31
  %21395 = xor i32 %21392, %21394
  %21396 = add nuw nsw i32 %21395, %21392
  %21397 = icmp eq i32 %21396, 2
  %21398 = zext i1 %21397 to i8
  store i8 %21398, i8* %22, align 1
  %21399 = sext i32 %21377 to i64
  store i64 %21399, i64* %RCX.i1588, align 8
  %21400 = shl nsw i64 %21399, 3
  %21401 = add i64 %21371, %21400
  %21402 = add i64 %21325, 62
  store i64 %21402, i64* %3, align 8
  %21403 = inttoptr i64 %21401 to i64*
  %21404 = load i64, i64* %21403, align 8
  store i64 %21404, i64* %RAX.i1659, align 8
  %21405 = add i64 %21372, -16
  %21406 = add i64 %21325, 66
  store i64 %21406, i64* %3, align 8
  %21407 = inttoptr i64 %21405 to i32*
  %21408 = load i32, i32* %21407, align 4
  %21409 = sext i32 %21408 to i64
  store i64 %21409, i64* %RCX.i1588, align 8
  %21410 = shl nsw i64 %21409, 3
  %21411 = add i64 %21410, %21404
  %21412 = add i64 %21325, 70
  store i64 %21412, i64* %3, align 8
  %21413 = inttoptr i64 %21411 to i64*
  %21414 = load i64, i64* %21413, align 8
  store i64 %21414, i64* %RAX.i1659, align 8
  %21415 = add i64 %21372, -48
  %21416 = add i64 %21325, 74
  store i64 %21416, i64* %3, align 8
  %21417 = inttoptr i64 %21415 to i32*
  %21418 = load i32, i32* %21417, align 4
  %21419 = sext i32 %21418 to i64
  store i64 %21419, i64* %RCX.i1588, align 8
  %21420 = shl nsw i64 %21419, 3
  %21421 = add i64 %21420, %21414
  %21422 = add i64 %21325, 78
  store i64 %21422, i64* %3, align 8
  %21423 = inttoptr i64 %21421 to i64*
  %21424 = load i64, i64* %21423, align 8
  store i64 %21424, i64* %RAX.i1659, align 8
  %21425 = add i64 %21372, -44
  %21426 = add i64 %21325, 82
  store i64 %21426, i64* %3, align 8
  %21427 = inttoptr i64 %21425 to i32*
  %21428 = load i32, i32* %21427, align 4
  %21429 = sext i32 %21428 to i64
  store i64 %21429, i64* %RCX.i1588, align 8
  %21430 = shl nsw i64 %21429, 2
  %21431 = add i64 %21430, %21424
  %21432 = add i64 %21325, 85
  store i64 %21432, i64* %3, align 8
  %21433 = inttoptr i64 %21431 to i32*
  store i32 %21365, i32* %21433, align 4
  %21434 = load i64, i64* %RBP.i, align 8
  %21435 = add i64 %21434, -44
  %21436 = load i64, i64* %3, align 8
  %21437 = add i64 %21436, 3
  store i64 %21437, i64* %3, align 8
  %21438 = inttoptr i64 %21435 to i32*
  %21439 = load i32, i32* %21438, align 4
  %21440 = add i32 %21439, 1
  %21441 = zext i32 %21440 to i64
  store i64 %21441, i64* %RAX.i1659, align 8
  %21442 = icmp eq i32 %21439, -1
  %21443 = icmp eq i32 %21440, 0
  %21444 = or i1 %21442, %21443
  %21445 = zext i1 %21444 to i8
  store i8 %21445, i8* %17, align 1
  %21446 = and i32 %21440, 255
  %21447 = tail call i32 @llvm.ctpop.i32(i32 %21446)
  %21448 = trunc i32 %21447 to i8
  %21449 = and i8 %21448, 1
  %21450 = xor i8 %21449, 1
  store i8 %21450, i8* %18, align 1
  %21451 = xor i32 %21440, %21439
  %21452 = lshr i32 %21451, 4
  %21453 = trunc i32 %21452 to i8
  %21454 = and i8 %21453, 1
  store i8 %21454, i8* %19, align 1
  %21455 = zext i1 %21443 to i8
  store i8 %21455, i8* %20, align 1
  %21456 = lshr i32 %21440, 31
  %21457 = trunc i32 %21456 to i8
  store i8 %21457, i8* %21, align 1
  %21458 = lshr i32 %21439, 31
  %21459 = xor i32 %21456, %21458
  %21460 = add nuw nsw i32 %21459, %21456
  %21461 = icmp eq i32 %21460, 2
  %21462 = zext i1 %21461 to i8
  store i8 %21462, i8* %22, align 1
  %21463 = add i64 %21436, 9
  store i64 %21463, i64* %3, align 8
  store i32 %21440, i32* %21438, align 4
  %21464 = load i64, i64* %3, align 8
  %21465 = add i64 %21464, -104
  store i64 %21465, i64* %3, align 8
  br label %block_.L_486852

block_.L_4868bf:                                  ; preds = %block_.L_486852
  %21466 = add i64 %21296, -48
  %21467 = add i64 %21325, 8
  store i64 %21467, i64* %3, align 8
  %21468 = inttoptr i64 %21466 to i32*
  %21469 = load i32, i32* %21468, align 4
  %21470 = add i32 %21469, 1
  %21471 = zext i32 %21470 to i64
  store i64 %21471, i64* %RAX.i1659, align 8
  %21472 = icmp eq i32 %21469, -1
  %21473 = icmp eq i32 %21470, 0
  %21474 = or i1 %21472, %21473
  %21475 = zext i1 %21474 to i8
  store i8 %21475, i8* %17, align 1
  %21476 = and i32 %21470, 255
  %21477 = tail call i32 @llvm.ctpop.i32(i32 %21476)
  %21478 = trunc i32 %21477 to i8
  %21479 = and i8 %21478, 1
  %21480 = xor i8 %21479, 1
  store i8 %21480, i8* %18, align 1
  %21481 = xor i32 %21470, %21469
  %21482 = lshr i32 %21481, 4
  %21483 = trunc i32 %21482 to i8
  %21484 = and i8 %21483, 1
  store i8 %21484, i8* %19, align 1
  %21485 = zext i1 %21473 to i8
  store i8 %21485, i8* %20, align 1
  %21486 = lshr i32 %21470, 31
  %21487 = trunc i32 %21486 to i8
  store i8 %21487, i8* %21, align 1
  %21488 = lshr i32 %21469, 31
  %21489 = xor i32 %21486, %21488
  %21490 = add nuw nsw i32 %21489, %21486
  %21491 = icmp eq i32 %21490, 2
  %21492 = zext i1 %21491 to i8
  store i8 %21492, i8* %22, align 1
  %21493 = add i64 %21325, 14
  store i64 %21493, i64* %3, align 8
  store i32 %21470, i32* %21468, align 4
  %21494 = load i64, i64* %3, align 8
  %21495 = add i64 %21494, -140
  store i64 %21495, i64* %3, align 8
  br label %block_.L_486841

block_.L_4868d2:                                  ; preds = %block_.L_486841
  %21496 = add i64 %21291, 5
  store i64 %21496, i64* %3, align 8
  br label %block_.L_4868d7

block_.L_4868d7:                                  ; preds = %block_.L_4868d2, %block_.L_486793
  %21497 = phi i64 [ %21496, %block_.L_4868d2 ], [ %21025, %block_.L_486793 ]
  %21498 = phi i64 [ %21263, %block_.L_4868d2 ], [ %20826, %block_.L_486793 ]
  %21499 = add i64 %21498, -60
  %21500 = add i64 %21497, 7
  store i64 %21500, i64* %3, align 8
  %21501 = inttoptr i64 %21499 to i32*
  store i32 0, i32* %21501, align 4
  %SI.i225 = bitcast %union.anon* %56 to i16*
  %.pre557 = load i64, i64* %3, align 8
  br label %block_.L_4868de

block_.L_4868de:                                  ; preds = %block_.L_4869af, %block_.L_4868d7
  %21502 = phi i64 [ %21943, %block_.L_4869af ], [ %.pre557, %block_.L_4868d7 ]
  %21503 = load i64, i64* %RBP.i, align 8
  %21504 = add i64 %21503, -60
  %21505 = add i64 %21502, 4
  store i64 %21505, i64* %3, align 8
  %21506 = inttoptr i64 %21504 to i32*
  %21507 = load i32, i32* %21506, align 4
  %21508 = add i32 %21507, -4
  %21509 = icmp ult i32 %21507, 4
  %21510 = zext i1 %21509 to i8
  store i8 %21510, i8* %17, align 1
  %21511 = and i32 %21508, 255
  %21512 = tail call i32 @llvm.ctpop.i32(i32 %21511)
  %21513 = trunc i32 %21512 to i8
  %21514 = and i8 %21513, 1
  %21515 = xor i8 %21514, 1
  store i8 %21515, i8* %18, align 1
  %21516 = xor i32 %21508, %21507
  %21517 = lshr i32 %21516, 4
  %21518 = trunc i32 %21517 to i8
  %21519 = and i8 %21518, 1
  store i8 %21519, i8* %19, align 1
  %21520 = icmp eq i32 %21508, 0
  %21521 = zext i1 %21520 to i8
  store i8 %21521, i8* %20, align 1
  %21522 = lshr i32 %21508, 31
  %21523 = trunc i32 %21522 to i8
  store i8 %21523, i8* %21, align 1
  %21524 = lshr i32 %21507, 31
  %21525 = xor i32 %21522, %21524
  %21526 = add nuw nsw i32 %21525, %21524
  %21527 = icmp eq i32 %21526, 2
  %21528 = zext i1 %21527 to i8
  store i8 %21528, i8* %22, align 1
  %21529 = icmp ne i8 %21523, 0
  %21530 = xor i1 %21529, %21527
  %.v706 = select i1 %21530, i64 10, i64 228
  %21531 = add i64 %21502, %.v706
  store i64 %21531, i64* %3, align 8
  br i1 %21530, label %block_4868e8, label %block_.L_4869c2

block_4868e8:                                     ; preds = %block_.L_4868de
  %21532 = add i64 %21503, -56
  %21533 = add i64 %21531, 7
  store i64 %21533, i64* %3, align 8
  %21534 = inttoptr i64 %21532 to i32*
  store i32 0, i32* %21534, align 4
  %.pre562 = load i64, i64* %3, align 8
  br label %block_.L_4868ef

block_.L_4868ef:                                  ; preds = %block_4868f9, %block_4868e8
  %21535 = phi i64 [ %21913, %block_4868f9 ], [ %.pre562, %block_4868e8 ]
  %21536 = load i64, i64* %RBP.i, align 8
  %21537 = add i64 %21536, -56
  %21538 = add i64 %21535, 4
  store i64 %21538, i64* %3, align 8
  %21539 = inttoptr i64 %21537 to i32*
  %21540 = load i32, i32* %21539, align 4
  %21541 = add i32 %21540, -4
  %21542 = icmp ult i32 %21540, 4
  %21543 = zext i1 %21542 to i8
  store i8 %21543, i8* %17, align 1
  %21544 = and i32 %21541, 255
  %21545 = tail call i32 @llvm.ctpop.i32(i32 %21544)
  %21546 = trunc i32 %21545 to i8
  %21547 = and i8 %21546, 1
  %21548 = xor i8 %21547, 1
  store i8 %21548, i8* %18, align 1
  %21549 = xor i32 %21541, %21540
  %21550 = lshr i32 %21549, 4
  %21551 = trunc i32 %21550 to i8
  %21552 = and i8 %21551, 1
  store i8 %21552, i8* %19, align 1
  %21553 = icmp eq i32 %21541, 0
  %21554 = zext i1 %21553 to i8
  store i8 %21554, i8* %20, align 1
  %21555 = lshr i32 %21541, 31
  %21556 = trunc i32 %21555 to i8
  store i8 %21556, i8* %21, align 1
  %21557 = lshr i32 %21540, 31
  %21558 = xor i32 %21555, %21557
  %21559 = add nuw nsw i32 %21558, %21557
  %21560 = icmp eq i32 %21559, 2
  %21561 = zext i1 %21560 to i8
  store i8 %21561, i8* %22, align 1
  %21562 = icmp ne i8 %21556, 0
  %21563 = xor i1 %21562, %21560
  %.v667 = select i1 %21563, i64 10, i64 192
  %21564 = add i64 %21535, %.v667
  store i64 %21564, i64* %3, align 8
  br i1 %21563, label %block_4868f9, label %block_.L_4869af

block_4868f9:                                     ; preds = %block_.L_4868ef
  %21565 = add i64 %21536, -144
  store i64 %21565, i64* %RAX.i1659, align 8
  %21566 = add i64 %21536, -60
  %21567 = add i64 %21564, 11
  store i64 %21567, i64* %3, align 8
  %21568 = inttoptr i64 %21566 to i32*
  %21569 = load i32, i32* %21568, align 4
  %21570 = sext i32 %21569 to i64
  %21571 = shl nsw i64 %21570, 4
  store i64 %21571, i64* %RCX.i1588, align 8
  %21572 = add i64 %21571, %21565
  store i64 %21572, i64* %RAX.i1659, align 8
  %21573 = icmp ult i64 %21572, %21565
  %21574 = icmp ult i64 %21572, %21571
  %21575 = or i1 %21573, %21574
  %21576 = zext i1 %21575 to i8
  store i8 %21576, i8* %17, align 1
  %21577 = trunc i64 %21572 to i32
  %21578 = and i32 %21577, 255
  %21579 = tail call i32 @llvm.ctpop.i32(i32 %21578)
  %21580 = trunc i32 %21579 to i8
  %21581 = and i8 %21580, 1
  %21582 = xor i8 %21581, 1
  store i8 %21582, i8* %18, align 1
  %21583 = xor i64 %21571, %21565
  %21584 = xor i64 %21583, %21572
  %21585 = lshr i64 %21584, 4
  %21586 = trunc i64 %21585 to i8
  %21587 = and i8 %21586, 1
  store i8 %21587, i8* %19, align 1
  %21588 = icmp eq i64 %21572, 0
  %21589 = zext i1 %21588 to i8
  store i8 %21589, i8* %20, align 1
  %21590 = lshr i64 %21572, 63
  %21591 = trunc i64 %21590 to i8
  store i8 %21591, i8* %21, align 1
  %21592 = lshr i64 %21565, 63
  %21593 = lshr i64 %21570, 59
  %21594 = and i64 %21593, 1
  %21595 = xor i64 %21590, %21592
  %21596 = xor i64 %21590, %21594
  %21597 = add nuw nsw i64 %21595, %21596
  %21598 = icmp eq i64 %21597, 2
  %21599 = zext i1 %21598 to i8
  store i8 %21599, i8* %22, align 1
  %21600 = add i64 %21564, 22
  store i64 %21600, i64* %3, align 8
  %21601 = load i32, i32* %21539, align 4
  %21602 = sext i32 %21601 to i64
  store i64 %21602, i64* %RCX.i1588, align 8
  %21603 = shl nsw i64 %21602, 2
  %21604 = add i64 %21603, %21572
  %21605 = add i64 %21564, 25
  store i64 %21605, i64* %3, align 8
  %21606 = inttoptr i64 %21604 to i32*
  %21607 = load i32, i32* %21606, align 4
  %21608 = zext i32 %21607 to i64
  store i64 %21608, i64* %RDX.i1943, align 8
  %21609 = trunc i32 %21607 to i16
  store i16 %21609, i16* %SI.i225, align 2
  %21610 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %21610, i64* %RAX.i1659, align 8
  %21611 = add i64 %21610, 6424
  %21612 = add i64 %21564, 43
  store i64 %21612, i64* %3, align 8
  %21613 = inttoptr i64 %21611 to i64*
  %21614 = load i64, i64* %21613, align 8
  store i64 %21614, i64* %RAX.i1659, align 8
  %21615 = add i64 %21536, -232
  %21616 = add i64 %21564, 49
  store i64 %21616, i64* %3, align 8
  %21617 = inttoptr i64 %21615 to i32*
  %21618 = load i32, i32* %21617, align 4
  %21619 = zext i32 %21618 to i64
  store i64 %21619, i64* %RDX.i1943, align 8
  %21620 = load i64, i64* %RBP.i, align 8
  %21621 = add i64 %21620, -60
  %21622 = add i64 %21564, 52
  store i64 %21622, i64* %3, align 8
  %21623 = inttoptr i64 %21621 to i32*
  %21624 = load i32, i32* %21623, align 4
  %21625 = add i32 %21624, %21618
  %21626 = zext i32 %21625 to i64
  store i64 %21626, i64* %RDX.i1943, align 8
  %21627 = icmp ult i32 %21625, %21618
  %21628 = icmp ult i32 %21625, %21624
  %21629 = or i1 %21627, %21628
  %21630 = zext i1 %21629 to i8
  store i8 %21630, i8* %17, align 1
  %21631 = and i32 %21625, 255
  %21632 = tail call i32 @llvm.ctpop.i32(i32 %21631)
  %21633 = trunc i32 %21632 to i8
  %21634 = and i8 %21633, 1
  %21635 = xor i8 %21634, 1
  store i8 %21635, i8* %18, align 1
  %21636 = xor i32 %21624, %21618
  %21637 = xor i32 %21636, %21625
  %21638 = lshr i32 %21637, 4
  %21639 = trunc i32 %21638 to i8
  %21640 = and i8 %21639, 1
  store i8 %21640, i8* %19, align 1
  %21641 = icmp eq i32 %21625, 0
  %21642 = zext i1 %21641 to i8
  store i8 %21642, i8* %20, align 1
  %21643 = lshr i32 %21625, 31
  %21644 = trunc i32 %21643 to i8
  store i8 %21644, i8* %21, align 1
  %21645 = lshr i32 %21618, 31
  %21646 = lshr i32 %21624, 31
  %21647 = xor i32 %21643, %21645
  %21648 = xor i32 %21643, %21646
  %21649 = add nuw nsw i32 %21647, %21648
  %21650 = icmp eq i32 %21649, 2
  %21651 = zext i1 %21650 to i8
  store i8 %21651, i8* %22, align 1
  %21652 = sext i32 %21625 to i64
  store i64 %21652, i64* %RCX.i1588, align 8
  %21653 = shl nsw i64 %21652, 3
  %21654 = add i64 %21614, %21653
  %21655 = add i64 %21564, 59
  store i64 %21655, i64* %3, align 8
  %21656 = inttoptr i64 %21654 to i64*
  %21657 = load i64, i64* %21656, align 8
  store i64 %21657, i64* %RAX.i1659, align 8
  %21658 = add i64 %21620, -228
  %21659 = add i64 %21564, 65
  store i64 %21659, i64* %3, align 8
  %21660 = inttoptr i64 %21658 to i32*
  %21661 = load i32, i32* %21660, align 4
  %21662 = zext i32 %21661 to i64
  store i64 %21662, i64* %RDX.i1943, align 8
  %21663 = add i64 %21620, -56
  %21664 = add i64 %21564, 68
  store i64 %21664, i64* %3, align 8
  %21665 = inttoptr i64 %21663 to i32*
  %21666 = load i32, i32* %21665, align 4
  %21667 = add i32 %21666, %21661
  %21668 = zext i32 %21667 to i64
  store i64 %21668, i64* %RDX.i1943, align 8
  %21669 = sext i32 %21667 to i64
  store i64 %21669, i64* %RCX.i1588, align 8
  %21670 = shl nsw i64 %21669, 1
  %21671 = add i64 %21657, %21670
  %21672 = load i16, i16* %SI.i225, align 2
  %21673 = add i64 %21564, 75
  store i64 %21673, i64* %3, align 8
  %21674 = inttoptr i64 %21671 to i16*
  store i16 %21672, i16* %21674, align 2
  %21675 = load i64, i64* %3, align 8
  %21676 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %21677 = add i64 %21676, 184
  store i64 %21677, i64* %RAX.i1659, align 8
  %21678 = icmp ugt i64 %21676, -185
  %21679 = zext i1 %21678 to i8
  store i8 %21679, i8* %17, align 1
  %21680 = trunc i64 %21677 to i32
  %21681 = and i32 %21680, 255
  %21682 = tail call i32 @llvm.ctpop.i32(i32 %21681)
  %21683 = trunc i32 %21682 to i8
  %21684 = and i8 %21683, 1
  %21685 = xor i8 %21684, 1
  store i8 %21685, i8* %18, align 1
  %21686 = xor i64 %21676, 16
  %21687 = xor i64 %21686, %21677
  %21688 = lshr i64 %21687, 4
  %21689 = trunc i64 %21688 to i8
  %21690 = and i8 %21689, 1
  store i8 %21690, i8* %19, align 1
  %21691 = icmp eq i64 %21677, 0
  %21692 = zext i1 %21691 to i8
  store i8 %21692, i8* %20, align 1
  %21693 = lshr i64 %21677, 63
  %21694 = trunc i64 %21693 to i8
  store i8 %21694, i8* %21, align 1
  %21695 = lshr i64 %21676, 63
  %21696 = xor i64 %21693, %21695
  %21697 = add nuw nsw i64 %21696, %21693
  %21698 = icmp eq i64 %21697, 2
  %21699 = zext i1 %21698 to i8
  store i8 %21699, i8* %22, align 1
  %21700 = load i64, i64* %RBP.i, align 8
  %21701 = add i64 %21700, -40
  %21702 = add i64 %21675, 18
  store i64 %21702, i64* %3, align 8
  %21703 = inttoptr i64 %21701 to i32*
  %21704 = load i32, i32* %21703, align 4
  %21705 = sext i32 %21704 to i64
  %21706 = shl nsw i64 %21705, 9
  store i64 %21706, i64* %RCX.i1588, align 8
  %21707 = add i64 %21706, %21677
  store i64 %21707, i64* %RAX.i1659, align 8
  %21708 = icmp ult i64 %21707, %21677
  %21709 = icmp ult i64 %21707, %21706
  %21710 = or i1 %21708, %21709
  %21711 = zext i1 %21710 to i8
  store i8 %21711, i8* %17, align 1
  %21712 = trunc i64 %21707 to i32
  %21713 = and i32 %21712, 255
  %21714 = tail call i32 @llvm.ctpop.i32(i32 %21713)
  %21715 = trunc i32 %21714 to i8
  %21716 = and i8 %21715, 1
  %21717 = xor i8 %21716, 1
  store i8 %21717, i8* %18, align 1
  %21718 = xor i64 %21677, %21707
  %21719 = lshr i64 %21718, 4
  %21720 = trunc i64 %21719 to i8
  %21721 = and i8 %21720, 1
  store i8 %21721, i8* %19, align 1
  %21722 = icmp eq i64 %21707, 0
  %21723 = zext i1 %21722 to i8
  store i8 %21723, i8* %20, align 1
  %21724 = lshr i64 %21707, 63
  %21725 = trunc i64 %21724 to i8
  store i8 %21725, i8* %21, align 1
  %21726 = lshr i64 %21705, 54
  %21727 = and i64 %21726, 1
  %21728 = xor i64 %21724, %21693
  %21729 = xor i64 %21724, %21727
  %21730 = add nuw nsw i64 %21728, %21729
  %21731 = icmp eq i64 %21730, 2
  %21732 = zext i1 %21731 to i8
  store i8 %21732, i8* %22, align 1
  %21733 = add i64 %21700, -60
  %21734 = add i64 %21675, 29
  store i64 %21734, i64* %3, align 8
  %21735 = inttoptr i64 %21733 to i32*
  %21736 = load i32, i32* %21735, align 4
  %21737 = sext i32 %21736 to i64
  %21738 = shl nsw i64 %21737, 5
  store i64 %21738, i64* %RCX.i1588, align 8
  %21739 = add i64 %21738, %21707
  store i64 %21739, i64* %RAX.i1659, align 8
  %21740 = icmp ult i64 %21739, %21707
  %21741 = icmp ult i64 %21739, %21738
  %21742 = or i1 %21740, %21741
  %21743 = zext i1 %21742 to i8
  store i8 %21743, i8* %17, align 1
  %21744 = trunc i64 %21739 to i32
  %21745 = and i32 %21744, 255
  %21746 = tail call i32 @llvm.ctpop.i32(i32 %21745)
  %21747 = trunc i32 %21746 to i8
  %21748 = and i8 %21747, 1
  %21749 = xor i8 %21748, 1
  store i8 %21749, i8* %18, align 1
  %21750 = xor i64 %21707, %21739
  %21751 = lshr i64 %21750, 4
  %21752 = trunc i64 %21751 to i8
  %21753 = and i8 %21752, 1
  store i8 %21753, i8* %19, align 1
  %21754 = icmp eq i64 %21739, 0
  %21755 = zext i1 %21754 to i8
  store i8 %21755, i8* %20, align 1
  %21756 = lshr i64 %21739, 63
  %21757 = trunc i64 %21756 to i8
  store i8 %21757, i8* %21, align 1
  %21758 = lshr i64 %21737, 58
  %21759 = and i64 %21758, 1
  %21760 = xor i64 %21756, %21724
  %21761 = xor i64 %21756, %21759
  %21762 = add nuw nsw i64 %21760, %21761
  %21763 = icmp eq i64 %21762, 2
  %21764 = zext i1 %21763 to i8
  store i8 %21764, i8* %22, align 1
  %21765 = load i64, i64* %RBP.i, align 8
  %21766 = add i64 %21765, -56
  %21767 = add i64 %21675, 40
  store i64 %21767, i64* %3, align 8
  %21768 = inttoptr i64 %21766 to i32*
  %21769 = load i32, i32* %21768, align 4
  %21770 = sext i32 %21769 to i64
  store i64 %21770, i64* %RCX.i1588, align 8
  %21771 = shl nsw i64 %21770, 1
  %21772 = add i64 %21771, %21739
  %21773 = add i64 %21675, 44
  store i64 %21773, i64* %3, align 8
  %21774 = inttoptr i64 %21772 to i16*
  %21775 = load i16, i16* %21774, align 2
  store i16 %21775, i16* %SI.i225, align 2
  %21776 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %21777 = add i64 %21776, 12600
  store i64 %21777, i64* %RAX.i1659, align 8
  %21778 = icmp ugt i64 %21776, -12601
  %21779 = zext i1 %21778 to i8
  store i8 %21779, i8* %17, align 1
  %21780 = trunc i64 %21777 to i32
  %21781 = and i32 %21780, 255
  %21782 = tail call i32 @llvm.ctpop.i32(i32 %21781)
  %21783 = trunc i32 %21782 to i8
  %21784 = and i8 %21783, 1
  %21785 = xor i8 %21784, 1
  store i8 %21785, i8* %18, align 1
  %21786 = xor i64 %21776, 16
  %21787 = xor i64 %21786, %21777
  %21788 = lshr i64 %21787, 4
  %21789 = trunc i64 %21788 to i8
  %21790 = and i8 %21789, 1
  store i8 %21790, i8* %19, align 1
  %21791 = icmp eq i64 %21777, 0
  %21792 = zext i1 %21791 to i8
  store i8 %21792, i8* %20, align 1
  %21793 = lshr i64 %21777, 63
  %21794 = trunc i64 %21793 to i8
  store i8 %21794, i8* %21, align 1
  %21795 = lshr i64 %21776, 63
  %21796 = xor i64 %21793, %21795
  %21797 = add nuw nsw i64 %21796, %21793
  %21798 = icmp eq i64 %21797, 2
  %21799 = zext i1 %21798 to i8
  store i8 %21799, i8* %22, align 1
  %21800 = add i64 %21765, -220
  %21801 = add i64 %21675, 64
  store i64 %21801, i64* %3, align 8
  %21802 = inttoptr i64 %21800 to i32*
  %21803 = load i32, i32* %21802, align 4
  %21804 = zext i32 %21803 to i64
  store i64 %21804, i64* %RDX.i1943, align 8
  %21805 = add i64 %21675, 67
  store i64 %21805, i64* %3, align 8
  %21806 = load i32, i32* %21768, align 4
  %21807 = add i32 %21806, %21803
  %21808 = zext i32 %21807 to i64
  store i64 %21808, i64* %RDX.i1943, align 8
  %21809 = sext i32 %21807 to i64
  %21810 = shl nsw i64 %21809, 5
  store i64 %21810, i64* %RCX.i1588, align 8
  %21811 = load i64, i64* %RAX.i1659, align 8
  %21812 = add i64 %21810, %21811
  store i64 %21812, i64* %RAX.i1659, align 8
  %21813 = icmp ult i64 %21812, %21811
  %21814 = icmp ult i64 %21812, %21810
  %21815 = or i1 %21813, %21814
  %21816 = zext i1 %21815 to i8
  store i8 %21816, i8* %17, align 1
  %21817 = trunc i64 %21812 to i32
  %21818 = and i32 %21817, 255
  %21819 = tail call i32 @llvm.ctpop.i32(i32 %21818)
  %21820 = trunc i32 %21819 to i8
  %21821 = and i8 %21820, 1
  %21822 = xor i8 %21821, 1
  store i8 %21822, i8* %18, align 1
  %21823 = xor i64 %21811, %21812
  %21824 = lshr i64 %21823, 4
  %21825 = trunc i64 %21824 to i8
  %21826 = and i8 %21825, 1
  store i8 %21826, i8* %19, align 1
  %21827 = icmp eq i64 %21812, 0
  %21828 = zext i1 %21827 to i8
  store i8 %21828, i8* %20, align 1
  %21829 = lshr i64 %21812, 63
  %21830 = trunc i64 %21829 to i8
  store i8 %21830, i8* %21, align 1
  %21831 = lshr i64 %21811, 63
  %21832 = lshr i64 %21809, 58
  %21833 = and i64 %21832, 1
  %21834 = xor i64 %21829, %21831
  %21835 = xor i64 %21829, %21833
  %21836 = add nuw nsw i64 %21834, %21835
  %21837 = icmp eq i64 %21836, 2
  %21838 = zext i1 %21837 to i8
  store i8 %21838, i8* %22, align 1
  %21839 = load i64, i64* %RBP.i, align 8
  %21840 = add i64 %21839, -224
  %21841 = add i64 %21675, 83
  store i64 %21841, i64* %3, align 8
  %21842 = inttoptr i64 %21840 to i32*
  %21843 = load i32, i32* %21842, align 4
  %21844 = zext i32 %21843 to i64
  store i64 %21844, i64* %RDX.i1943, align 8
  %21845 = add i64 %21839, -60
  %21846 = add i64 %21675, 86
  store i64 %21846, i64* %3, align 8
  %21847 = inttoptr i64 %21845 to i32*
  %21848 = load i32, i32* %21847, align 4
  %21849 = add i32 %21848, %21843
  %21850 = zext i32 %21849 to i64
  store i64 %21850, i64* %RDX.i1943, align 8
  %21851 = icmp ult i32 %21849, %21843
  %21852 = icmp ult i32 %21849, %21848
  %21853 = or i1 %21851, %21852
  %21854 = zext i1 %21853 to i8
  store i8 %21854, i8* %17, align 1
  %21855 = and i32 %21849, 255
  %21856 = tail call i32 @llvm.ctpop.i32(i32 %21855)
  %21857 = trunc i32 %21856 to i8
  %21858 = and i8 %21857, 1
  %21859 = xor i8 %21858, 1
  store i8 %21859, i8* %18, align 1
  %21860 = xor i32 %21848, %21843
  %21861 = xor i32 %21860, %21849
  %21862 = lshr i32 %21861, 4
  %21863 = trunc i32 %21862 to i8
  %21864 = and i8 %21863, 1
  store i8 %21864, i8* %19, align 1
  %21865 = icmp eq i32 %21849, 0
  %21866 = zext i1 %21865 to i8
  store i8 %21866, i8* %20, align 1
  %21867 = lshr i32 %21849, 31
  %21868 = trunc i32 %21867 to i8
  store i8 %21868, i8* %21, align 1
  %21869 = lshr i32 %21843, 31
  %21870 = lshr i32 %21848, 31
  %21871 = xor i32 %21867, %21869
  %21872 = xor i32 %21867, %21870
  %21873 = add nuw nsw i32 %21871, %21872
  %21874 = icmp eq i32 %21873, 2
  %21875 = zext i1 %21874 to i8
  store i8 %21875, i8* %22, align 1
  %21876 = sext i32 %21849 to i64
  store i64 %21876, i64* %RCX.i1588, align 8
  %21877 = shl nsw i64 %21876, 1
  %21878 = add i64 %21812, %21877
  %21879 = load i16, i16* %SI.i225, align 2
  %21880 = add i64 %21675, 93
  store i64 %21880, i64* %3, align 8
  %21881 = inttoptr i64 %21878 to i16*
  store i16 %21879, i16* %21881, align 2
  %21882 = load i64, i64* %RBP.i, align 8
  %21883 = add i64 %21882, -56
  %21884 = load i64, i64* %3, align 8
  %21885 = add i64 %21884, 3
  store i64 %21885, i64* %3, align 8
  %21886 = inttoptr i64 %21883 to i32*
  %21887 = load i32, i32* %21886, align 4
  %21888 = add i32 %21887, 1
  %21889 = zext i32 %21888 to i64
  store i64 %21889, i64* %RAX.i1659, align 8
  %21890 = icmp eq i32 %21887, -1
  %21891 = icmp eq i32 %21888, 0
  %21892 = or i1 %21890, %21891
  %21893 = zext i1 %21892 to i8
  store i8 %21893, i8* %17, align 1
  %21894 = and i32 %21888, 255
  %21895 = tail call i32 @llvm.ctpop.i32(i32 %21894)
  %21896 = trunc i32 %21895 to i8
  %21897 = and i8 %21896, 1
  %21898 = xor i8 %21897, 1
  store i8 %21898, i8* %18, align 1
  %21899 = xor i32 %21888, %21887
  %21900 = lshr i32 %21899, 4
  %21901 = trunc i32 %21900 to i8
  %21902 = and i8 %21901, 1
  store i8 %21902, i8* %19, align 1
  %21903 = zext i1 %21891 to i8
  store i8 %21903, i8* %20, align 1
  %21904 = lshr i32 %21888, 31
  %21905 = trunc i32 %21904 to i8
  store i8 %21905, i8* %21, align 1
  %21906 = lshr i32 %21887, 31
  %21907 = xor i32 %21904, %21906
  %21908 = add nuw nsw i32 %21907, %21904
  %21909 = icmp eq i32 %21908, 2
  %21910 = zext i1 %21909 to i8
  store i8 %21910, i8* %22, align 1
  %21911 = add i64 %21884, 9
  store i64 %21911, i64* %3, align 8
  store i32 %21888, i32* %21886, align 4
  %21912 = load i64, i64* %3, align 8
  %21913 = add i64 %21912, -187
  store i64 %21913, i64* %3, align 8
  br label %block_.L_4868ef

block_.L_4869af:                                  ; preds = %block_.L_4868ef
  %21914 = add i64 %21536, -60
  %21915 = add i64 %21564, 8
  store i64 %21915, i64* %3, align 8
  %21916 = inttoptr i64 %21914 to i32*
  %21917 = load i32, i32* %21916, align 4
  %21918 = add i32 %21917, 1
  %21919 = zext i32 %21918 to i64
  store i64 %21919, i64* %RAX.i1659, align 8
  %21920 = icmp eq i32 %21917, -1
  %21921 = icmp eq i32 %21918, 0
  %21922 = or i1 %21920, %21921
  %21923 = zext i1 %21922 to i8
  store i8 %21923, i8* %17, align 1
  %21924 = and i32 %21918, 255
  %21925 = tail call i32 @llvm.ctpop.i32(i32 %21924)
  %21926 = trunc i32 %21925 to i8
  %21927 = and i8 %21926, 1
  %21928 = xor i8 %21927, 1
  store i8 %21928, i8* %18, align 1
  %21929 = xor i32 %21918, %21917
  %21930 = lshr i32 %21929, 4
  %21931 = trunc i32 %21930 to i8
  %21932 = and i8 %21931, 1
  store i8 %21932, i8* %19, align 1
  %21933 = zext i1 %21921 to i8
  store i8 %21933, i8* %20, align 1
  %21934 = lshr i32 %21918, 31
  %21935 = trunc i32 %21934 to i8
  store i8 %21935, i8* %21, align 1
  %21936 = lshr i32 %21917, 31
  %21937 = xor i32 %21934, %21936
  %21938 = add nuw nsw i32 %21937, %21934
  %21939 = icmp eq i32 %21938, 2
  %21940 = zext i1 %21939 to i8
  store i8 %21940, i8* %22, align 1
  %21941 = add i64 %21564, 14
  store i64 %21941, i64* %3, align 8
  store i32 %21918, i32* %21916, align 4
  %21942 = load i64, i64* %3, align 8
  %21943 = add i64 %21942, -223
  store i64 %21943, i64* %3, align 8
  br label %block_.L_4868de

block_.L_4869c2:                                  ; preds = %block_.L_4868de
  %21944 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %21944, i64* %RAX.i1659, align 8
  %21945 = add i64 %21944, 72724
  %21946 = add i64 %21531, 15
  store i64 %21946, i64* %3, align 8
  %21947 = inttoptr i64 %21945 to i32*
  %21948 = load i32, i32* %21947, align 4
  store i8 0, i8* %17, align 1
  %21949 = and i32 %21948, 255
  %21950 = tail call i32 @llvm.ctpop.i32(i32 %21949)
  %21951 = trunc i32 %21950 to i8
  %21952 = and i8 %21951, 1
  %21953 = xor i8 %21952, 1
  store i8 %21953, i8* %18, align 1
  store i8 0, i8* %19, align 1
  %21954 = icmp eq i32 %21948, 0
  %21955 = zext i1 %21954 to i8
  store i8 %21955, i8* %20, align 1
  %21956 = lshr i32 %21948, 31
  %21957 = trunc i32 %21956 to i8
  store i8 %21957, i8* %21, align 1
  store i8 0, i8* %22, align 1
  %.v707 = select i1 %21954, i64 223, i64 21
  %21958 = add i64 %21531, %.v707
  store i64 %21958, i64* %3, align 8
  br i1 %21954, label %block_.L_486aa1, label %block_4869d7

block_4869d7:                                     ; preds = %block_.L_4869c2
  %21959 = add i64 %21503, -44
  %21960 = add i64 %21958, 7
  store i64 %21960, i64* %3, align 8
  %21961 = inttoptr i64 %21959 to i32*
  store i32 0, i32* %21961, align 4
  %.pre558 = load i64, i64* %3, align 8
  br label %block_.L_4869de

block_.L_4869de:                                  ; preds = %block_.L_486a89, %block_4869d7
  %21962 = phi i64 [ %22329, %block_.L_486a89 ], [ %.pre558, %block_4869d7 ]
  %21963 = load i64, i64* %RBP.i, align 8
  %21964 = add i64 %21963, -44
  %21965 = add i64 %21962, 4
  store i64 %21965, i64* %3, align 8
  %21966 = inttoptr i64 %21964 to i32*
  %21967 = load i32, i32* %21966, align 4
  %21968 = add i32 %21967, -2
  %21969 = icmp ult i32 %21967, 2
  %21970 = zext i1 %21969 to i8
  store i8 %21970, i8* %17, align 1
  %21971 = and i32 %21968, 255
  %21972 = tail call i32 @llvm.ctpop.i32(i32 %21971)
  %21973 = trunc i32 %21972 to i8
  %21974 = and i8 %21973, 1
  %21975 = xor i8 %21974, 1
  store i8 %21975, i8* %18, align 1
  %21976 = xor i32 %21968, %21967
  %21977 = lshr i32 %21976, 4
  %21978 = trunc i32 %21977 to i8
  %21979 = and i8 %21978, 1
  store i8 %21979, i8* %19, align 1
  %21980 = icmp eq i32 %21968, 0
  %21981 = zext i1 %21980 to i8
  store i8 %21981, i8* %20, align 1
  %21982 = lshr i32 %21968, 31
  %21983 = trunc i32 %21982 to i8
  store i8 %21983, i8* %21, align 1
  %21984 = lshr i32 %21967, 31
  %21985 = xor i32 %21982, %21984
  %21986 = add nuw nsw i32 %21985, %21984
  %21987 = icmp eq i32 %21986, 2
  %21988 = zext i1 %21987 to i8
  store i8 %21988, i8* %22, align 1
  %21989 = icmp ne i8 %21983, 0
  %21990 = xor i1 %21989, %21987
  %.v708 = select i1 %21990, i64 10, i64 190
  %21991 = add i64 %21962, %.v708
  store i64 %21991, i64* %3, align 8
  br i1 %21990, label %block_4869e8, label %block_.L_486a9c

block_4869e8:                                     ; preds = %block_.L_4869de
  %21992 = add i64 %21963, -60
  %21993 = add i64 %21991, 7
  store i64 %21993, i64* %3, align 8
  %21994 = inttoptr i64 %21992 to i32*
  store i32 0, i32* %21994, align 4
  %.pre559 = load i64, i64* %3, align 8
  br label %block_.L_4869ef

block_.L_4869ef:                                  ; preds = %block_.L_486a76, %block_4869e8
  %21995 = phi i64 [ %22299, %block_.L_486a76 ], [ %.pre559, %block_4869e8 ]
  %21996 = load i64, i64* %RBP.i, align 8
  %21997 = add i64 %21996, -60
  %21998 = add i64 %21995, 4
  store i64 %21998, i64* %3, align 8
  %21999 = inttoptr i64 %21997 to i32*
  %22000 = load i32, i32* %21999, align 4
  %22001 = add i32 %22000, -4
  %22002 = icmp ult i32 %22000, 4
  %22003 = zext i1 %22002 to i8
  store i8 %22003, i8* %17, align 1
  %22004 = and i32 %22001, 255
  %22005 = tail call i32 @llvm.ctpop.i32(i32 %22004)
  %22006 = trunc i32 %22005 to i8
  %22007 = and i8 %22006, 1
  %22008 = xor i8 %22007, 1
  store i8 %22008, i8* %18, align 1
  %22009 = xor i32 %22001, %22000
  %22010 = lshr i32 %22009, 4
  %22011 = trunc i32 %22010 to i8
  %22012 = and i8 %22011, 1
  store i8 %22012, i8* %19, align 1
  %22013 = icmp eq i32 %22001, 0
  %22014 = zext i1 %22013 to i8
  store i8 %22014, i8* %20, align 1
  %22015 = lshr i32 %22001, 31
  %22016 = trunc i32 %22015 to i8
  store i8 %22016, i8* %21, align 1
  %22017 = lshr i32 %22000, 31
  %22018 = xor i32 %22015, %22017
  %22019 = add nuw nsw i32 %22018, %22017
  %22020 = icmp eq i32 %22019, 2
  %22021 = zext i1 %22020 to i8
  store i8 %22021, i8* %22, align 1
  %22022 = icmp ne i8 %22016, 0
  %22023 = xor i1 %22022, %22020
  %.v665 = select i1 %22023, i64 10, i64 154
  %22024 = add i64 %21995, %.v665
  store i64 %22024, i64* %3, align 8
  br i1 %22023, label %block_4869f9, label %block_.L_486a89

block_4869f9:                                     ; preds = %block_.L_4869ef
  %22025 = add i64 %21996, -56
  %22026 = add i64 %22024, 7
  store i64 %22026, i64* %3, align 8
  %22027 = inttoptr i64 %22025 to i32*
  store i32 0, i32* %22027, align 4
  %.pre560 = load i64, i64* %3, align 8
  br label %block_.L_486a00

block_.L_486a00:                                  ; preds = %block_486a0a, %block_4869f9
  %22028 = phi i64 [ %22269, %block_486a0a ], [ %.pre560, %block_4869f9 ]
  %22029 = load i64, i64* %RBP.i, align 8
  %22030 = add i64 %22029, -56
  %22031 = add i64 %22028, 4
  store i64 %22031, i64* %3, align 8
  %22032 = inttoptr i64 %22030 to i32*
  %22033 = load i32, i32* %22032, align 4
  %22034 = add i32 %22033, -4
  %22035 = icmp ult i32 %22033, 4
  %22036 = zext i1 %22035 to i8
  store i8 %22036, i8* %17, align 1
  %22037 = and i32 %22034, 255
  %22038 = tail call i32 @llvm.ctpop.i32(i32 %22037)
  %22039 = trunc i32 %22038 to i8
  %22040 = and i8 %22039, 1
  %22041 = xor i8 %22040, 1
  store i8 %22041, i8* %18, align 1
  %22042 = xor i32 %22034, %22033
  %22043 = lshr i32 %22042, 4
  %22044 = trunc i32 %22043 to i8
  %22045 = and i8 %22044, 1
  store i8 %22045, i8* %19, align 1
  %22046 = icmp eq i32 %22034, 0
  %22047 = zext i1 %22046 to i8
  store i8 %22047, i8* %20, align 1
  %22048 = lshr i32 %22034, 31
  %22049 = trunc i32 %22048 to i8
  store i8 %22049, i8* %21, align 1
  %22050 = lshr i32 %22033, 31
  %22051 = xor i32 %22048, %22050
  %22052 = add nuw nsw i32 %22051, %22050
  %22053 = icmp eq i32 %22052, 2
  %22054 = zext i1 %22053 to i8
  store i8 %22054, i8* %22, align 1
  %22055 = icmp ne i8 %22049, 0
  %22056 = xor i1 %22055, %22053
  %.v666 = select i1 %22056, i64 10, i64 118
  %22057 = add i64 %22028, %.v666
  store i64 %22057, i64* %3, align 8
  br i1 %22056, label %block_486a0a, label %block_.L_486a76

block_486a0a:                                     ; preds = %block_.L_486a00
  %22058 = add i64 %22029, -496
  store i64 %22058, i64* %RAX.i1659, align 8
  %22059 = add i64 %22029, -44
  %22060 = add i64 %22057, 11
  store i64 %22060, i64* %3, align 8
  %22061 = inttoptr i64 %22059 to i32*
  %22062 = load i32, i32* %22061, align 4
  %22063 = sext i32 %22062 to i64
  %22064 = shl nsw i64 %22063, 6
  store i64 %22064, i64* %RCX.i1588, align 8
  %22065 = add i64 %22064, %22058
  store i64 %22065, i64* %RAX.i1659, align 8
  %22066 = icmp ult i64 %22065, %22058
  %22067 = icmp ult i64 %22065, %22064
  %22068 = or i1 %22066, %22067
  %22069 = zext i1 %22068 to i8
  store i8 %22069, i8* %17, align 1
  %22070 = trunc i64 %22065 to i32
  %22071 = and i32 %22070, 255
  %22072 = tail call i32 @llvm.ctpop.i32(i32 %22071)
  %22073 = trunc i32 %22072 to i8
  %22074 = and i8 %22073, 1
  %22075 = xor i8 %22074, 1
  store i8 %22075, i8* %18, align 1
  %22076 = xor i64 %22058, %22065
  %22077 = lshr i64 %22076, 4
  %22078 = trunc i64 %22077 to i8
  %22079 = and i8 %22078, 1
  store i8 %22079, i8* %19, align 1
  %22080 = icmp eq i64 %22065, 0
  %22081 = zext i1 %22080 to i8
  store i8 %22081, i8* %20, align 1
  %22082 = lshr i64 %22065, 63
  %22083 = trunc i64 %22082 to i8
  store i8 %22083, i8* %21, align 1
  %22084 = lshr i64 %22058, 63
  %22085 = lshr i64 %22063, 57
  %22086 = and i64 %22085, 1
  %22087 = xor i64 %22082, %22084
  %22088 = xor i64 %22082, %22086
  %22089 = add nuw nsw i64 %22087, %22088
  %22090 = icmp eq i64 %22089, 2
  %22091 = zext i1 %22090 to i8
  store i8 %22091, i8* %22, align 1
  %22092 = add i64 %22029, -60
  %22093 = add i64 %22057, 22
  store i64 %22093, i64* %3, align 8
  %22094 = inttoptr i64 %22092 to i32*
  %22095 = load i32, i32* %22094, align 4
  %22096 = sext i32 %22095 to i64
  %22097 = shl nsw i64 %22096, 4
  store i64 %22097, i64* %RCX.i1588, align 8
  %22098 = add i64 %22097, %22065
  store i64 %22098, i64* %RAX.i1659, align 8
  %22099 = icmp ult i64 %22098, %22065
  %22100 = icmp ult i64 %22098, %22097
  %22101 = or i1 %22099, %22100
  %22102 = zext i1 %22101 to i8
  store i8 %22102, i8* %17, align 1
  %22103 = trunc i64 %22098 to i32
  %22104 = and i32 %22103, 255
  %22105 = tail call i32 @llvm.ctpop.i32(i32 %22104)
  %22106 = trunc i32 %22105 to i8
  %22107 = and i8 %22106, 1
  %22108 = xor i8 %22107, 1
  store i8 %22108, i8* %18, align 1
  %22109 = xor i64 %22097, %22065
  %22110 = xor i64 %22109, %22098
  %22111 = lshr i64 %22110, 4
  %22112 = trunc i64 %22111 to i8
  %22113 = and i8 %22112, 1
  store i8 %22113, i8* %19, align 1
  %22114 = icmp eq i64 %22098, 0
  %22115 = zext i1 %22114 to i8
  store i8 %22115, i8* %20, align 1
  %22116 = lshr i64 %22098, 63
  %22117 = trunc i64 %22116 to i8
  store i8 %22117, i8* %21, align 1
  %22118 = lshr i64 %22096, 59
  %22119 = and i64 %22118, 1
  %22120 = xor i64 %22116, %22082
  %22121 = xor i64 %22116, %22119
  %22122 = add nuw nsw i64 %22120, %22121
  %22123 = icmp eq i64 %22122, 2
  %22124 = zext i1 %22123 to i8
  store i8 %22124, i8* %22, align 1
  %22125 = load i64, i64* %RBP.i, align 8
  %22126 = add i64 %22125, -56
  %22127 = add i64 %22057, 33
  store i64 %22127, i64* %3, align 8
  %22128 = inttoptr i64 %22126 to i32*
  %22129 = load i32, i32* %22128, align 4
  %22130 = sext i32 %22129 to i64
  store i64 %22130, i64* %RCX.i1588, align 8
  %22131 = shl nsw i64 %22130, 2
  %22132 = add i64 %22131, %22098
  %22133 = add i64 %22057, 36
  store i64 %22133, i64* %3, align 8
  %22134 = inttoptr i64 %22132 to i32*
  %22135 = load i32, i32* %22134, align 4
  %22136 = zext i32 %22135 to i64
  store i64 %22136, i64* %RDX.i1943, align 8
  %22137 = trunc i32 %22135 to i16
  store i16 %22137, i16* %SI.i225, align 2
  %22138 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %22138, i64* %RAX.i1659, align 8
  %22139 = add i64 %22138, 6464
  %22140 = add i64 %22057, 54
  store i64 %22140, i64* %3, align 8
  %22141 = inttoptr i64 %22139 to i64*
  %22142 = load i64, i64* %22141, align 8
  store i64 %22142, i64* %RAX.i1659, align 8
  %22143 = add i64 %22125, -44
  %22144 = add i64 %22057, 58
  store i64 %22144, i64* %3, align 8
  %22145 = inttoptr i64 %22143 to i32*
  %22146 = load i32, i32* %22145, align 4
  %22147 = sext i32 %22146 to i64
  store i64 %22147, i64* %RCX.i1588, align 8
  %22148 = shl nsw i64 %22147, 3
  %22149 = add i64 %22148, %22142
  %22150 = add i64 %22057, 62
  store i64 %22150, i64* %3, align 8
  %22151 = inttoptr i64 %22149 to i64*
  %22152 = load i64, i64* %22151, align 8
  store i64 %22152, i64* %RAX.i1659, align 8
  %22153 = add i64 %22125, -232
  %22154 = add i64 %22057, 68
  store i64 %22154, i64* %3, align 8
  %22155 = inttoptr i64 %22153 to i32*
  %22156 = load i32, i32* %22155, align 4
  %22157 = zext i32 %22156 to i64
  store i64 %22157, i64* %RDX.i1943, align 8
  %22158 = add i64 %22125, -60
  %22159 = add i64 %22057, 71
  store i64 %22159, i64* %3, align 8
  %22160 = inttoptr i64 %22158 to i32*
  %22161 = load i32, i32* %22160, align 4
  %22162 = add i32 %22161, %22156
  %22163 = zext i32 %22162 to i64
  store i64 %22163, i64* %RDX.i1943, align 8
  %22164 = icmp ult i32 %22162, %22156
  %22165 = icmp ult i32 %22162, %22161
  %22166 = or i1 %22164, %22165
  %22167 = zext i1 %22166 to i8
  store i8 %22167, i8* %17, align 1
  %22168 = and i32 %22162, 255
  %22169 = tail call i32 @llvm.ctpop.i32(i32 %22168)
  %22170 = trunc i32 %22169 to i8
  %22171 = and i8 %22170, 1
  %22172 = xor i8 %22171, 1
  store i8 %22172, i8* %18, align 1
  %22173 = xor i32 %22161, %22156
  %22174 = xor i32 %22173, %22162
  %22175 = lshr i32 %22174, 4
  %22176 = trunc i32 %22175 to i8
  %22177 = and i8 %22176, 1
  store i8 %22177, i8* %19, align 1
  %22178 = icmp eq i32 %22162, 0
  %22179 = zext i1 %22178 to i8
  store i8 %22179, i8* %20, align 1
  %22180 = lshr i32 %22162, 31
  %22181 = trunc i32 %22180 to i8
  store i8 %22181, i8* %21, align 1
  %22182 = lshr i32 %22156, 31
  %22183 = lshr i32 %22161, 31
  %22184 = xor i32 %22180, %22182
  %22185 = xor i32 %22180, %22183
  %22186 = add nuw nsw i32 %22184, %22185
  %22187 = icmp eq i32 %22186, 2
  %22188 = zext i1 %22187 to i8
  store i8 %22188, i8* %22, align 1
  %22189 = sext i32 %22162 to i64
  store i64 %22189, i64* %RCX.i1588, align 8
  %22190 = shl nsw i64 %22189, 3
  %22191 = add i64 %22152, %22190
  %22192 = add i64 %22057, 78
  store i64 %22192, i64* %3, align 8
  %22193 = inttoptr i64 %22191 to i64*
  %22194 = load i64, i64* %22193, align 8
  store i64 %22194, i64* %RAX.i1659, align 8
  %22195 = load i64, i64* %RBP.i, align 8
  %22196 = add i64 %22195, -228
  %22197 = add i64 %22057, 84
  store i64 %22197, i64* %3, align 8
  %22198 = inttoptr i64 %22196 to i32*
  %22199 = load i32, i32* %22198, align 4
  %22200 = zext i32 %22199 to i64
  store i64 %22200, i64* %RDX.i1943, align 8
  %22201 = add i64 %22195, -56
  %22202 = add i64 %22057, 87
  store i64 %22202, i64* %3, align 8
  %22203 = inttoptr i64 %22201 to i32*
  %22204 = load i32, i32* %22203, align 4
  %22205 = add i32 %22204, %22199
  %22206 = zext i32 %22205 to i64
  store i64 %22206, i64* %RDX.i1943, align 8
  %22207 = icmp ult i32 %22205, %22199
  %22208 = icmp ult i32 %22205, %22204
  %22209 = or i1 %22207, %22208
  %22210 = zext i1 %22209 to i8
  store i8 %22210, i8* %17, align 1
  %22211 = and i32 %22205, 255
  %22212 = tail call i32 @llvm.ctpop.i32(i32 %22211)
  %22213 = trunc i32 %22212 to i8
  %22214 = and i8 %22213, 1
  %22215 = xor i8 %22214, 1
  store i8 %22215, i8* %18, align 1
  %22216 = xor i32 %22204, %22199
  %22217 = xor i32 %22216, %22205
  %22218 = lshr i32 %22217, 4
  %22219 = trunc i32 %22218 to i8
  %22220 = and i8 %22219, 1
  store i8 %22220, i8* %19, align 1
  %22221 = icmp eq i32 %22205, 0
  %22222 = zext i1 %22221 to i8
  store i8 %22222, i8* %20, align 1
  %22223 = lshr i32 %22205, 31
  %22224 = trunc i32 %22223 to i8
  store i8 %22224, i8* %21, align 1
  %22225 = lshr i32 %22199, 31
  %22226 = lshr i32 %22204, 31
  %22227 = xor i32 %22223, %22225
  %22228 = xor i32 %22223, %22226
  %22229 = add nuw nsw i32 %22227, %22228
  %22230 = icmp eq i32 %22229, 2
  %22231 = zext i1 %22230 to i8
  store i8 %22231, i8* %22, align 1
  %22232 = sext i32 %22205 to i64
  store i64 %22232, i64* %RCX.i1588, align 8
  %22233 = shl nsw i64 %22232, 1
  %22234 = add i64 %22194, %22233
  %22235 = load i16, i16* %SI.i225, align 2
  %22236 = add i64 %22057, 94
  store i64 %22236, i64* %3, align 8
  %22237 = inttoptr i64 %22234 to i16*
  store i16 %22235, i16* %22237, align 2
  %22238 = load i64, i64* %RBP.i, align 8
  %22239 = add i64 %22238, -56
  %22240 = load i64, i64* %3, align 8
  %22241 = add i64 %22240, 3
  store i64 %22241, i64* %3, align 8
  %22242 = inttoptr i64 %22239 to i32*
  %22243 = load i32, i32* %22242, align 4
  %22244 = add i32 %22243, 1
  %22245 = zext i32 %22244 to i64
  store i64 %22245, i64* %RAX.i1659, align 8
  %22246 = icmp eq i32 %22243, -1
  %22247 = icmp eq i32 %22244, 0
  %22248 = or i1 %22246, %22247
  %22249 = zext i1 %22248 to i8
  store i8 %22249, i8* %17, align 1
  %22250 = and i32 %22244, 255
  %22251 = tail call i32 @llvm.ctpop.i32(i32 %22250)
  %22252 = trunc i32 %22251 to i8
  %22253 = and i8 %22252, 1
  %22254 = xor i8 %22253, 1
  store i8 %22254, i8* %18, align 1
  %22255 = xor i32 %22244, %22243
  %22256 = lshr i32 %22255, 4
  %22257 = trunc i32 %22256 to i8
  %22258 = and i8 %22257, 1
  store i8 %22258, i8* %19, align 1
  %22259 = zext i1 %22247 to i8
  store i8 %22259, i8* %20, align 1
  %22260 = lshr i32 %22244, 31
  %22261 = trunc i32 %22260 to i8
  store i8 %22261, i8* %21, align 1
  %22262 = lshr i32 %22243, 31
  %22263 = xor i32 %22260, %22262
  %22264 = add nuw nsw i32 %22263, %22260
  %22265 = icmp eq i32 %22264, 2
  %22266 = zext i1 %22265 to i8
  store i8 %22266, i8* %22, align 1
  %22267 = add i64 %22240, 9
  store i64 %22267, i64* %3, align 8
  store i32 %22244, i32* %22242, align 4
  %22268 = load i64, i64* %3, align 8
  %22269 = add i64 %22268, -113
  store i64 %22269, i64* %3, align 8
  br label %block_.L_486a00

block_.L_486a76:                                  ; preds = %block_.L_486a00
  %22270 = add i64 %22029, -60
  %22271 = add i64 %22057, 8
  store i64 %22271, i64* %3, align 8
  %22272 = inttoptr i64 %22270 to i32*
  %22273 = load i32, i32* %22272, align 4
  %22274 = add i32 %22273, 1
  %22275 = zext i32 %22274 to i64
  store i64 %22275, i64* %RAX.i1659, align 8
  %22276 = icmp eq i32 %22273, -1
  %22277 = icmp eq i32 %22274, 0
  %22278 = or i1 %22276, %22277
  %22279 = zext i1 %22278 to i8
  store i8 %22279, i8* %17, align 1
  %22280 = and i32 %22274, 255
  %22281 = tail call i32 @llvm.ctpop.i32(i32 %22280)
  %22282 = trunc i32 %22281 to i8
  %22283 = and i8 %22282, 1
  %22284 = xor i8 %22283, 1
  store i8 %22284, i8* %18, align 1
  %22285 = xor i32 %22274, %22273
  %22286 = lshr i32 %22285, 4
  %22287 = trunc i32 %22286 to i8
  %22288 = and i8 %22287, 1
  store i8 %22288, i8* %19, align 1
  %22289 = zext i1 %22277 to i8
  store i8 %22289, i8* %20, align 1
  %22290 = lshr i32 %22274, 31
  %22291 = trunc i32 %22290 to i8
  store i8 %22291, i8* %21, align 1
  %22292 = lshr i32 %22273, 31
  %22293 = xor i32 %22290, %22292
  %22294 = add nuw nsw i32 %22293, %22290
  %22295 = icmp eq i32 %22294, 2
  %22296 = zext i1 %22295 to i8
  store i8 %22296, i8* %22, align 1
  %22297 = add i64 %22057, 14
  store i64 %22297, i64* %3, align 8
  store i32 %22274, i32* %22272, align 4
  %22298 = load i64, i64* %3, align 8
  %22299 = add i64 %22298, -149
  store i64 %22299, i64* %3, align 8
  br label %block_.L_4869ef

block_.L_486a89:                                  ; preds = %block_.L_4869ef
  %22300 = add i64 %21996, -44
  %22301 = add i64 %22024, 8
  store i64 %22301, i64* %3, align 8
  %22302 = inttoptr i64 %22300 to i32*
  %22303 = load i32, i32* %22302, align 4
  %22304 = add i32 %22303, 1
  %22305 = zext i32 %22304 to i64
  store i64 %22305, i64* %RAX.i1659, align 8
  %22306 = icmp eq i32 %22303, -1
  %22307 = icmp eq i32 %22304, 0
  %22308 = or i1 %22306, %22307
  %22309 = zext i1 %22308 to i8
  store i8 %22309, i8* %17, align 1
  %22310 = and i32 %22304, 255
  %22311 = tail call i32 @llvm.ctpop.i32(i32 %22310)
  %22312 = trunc i32 %22311 to i8
  %22313 = and i8 %22312, 1
  %22314 = xor i8 %22313, 1
  store i8 %22314, i8* %18, align 1
  %22315 = xor i32 %22304, %22303
  %22316 = lshr i32 %22315, 4
  %22317 = trunc i32 %22316 to i8
  %22318 = and i8 %22317, 1
  store i8 %22318, i8* %19, align 1
  %22319 = zext i1 %22307 to i8
  store i8 %22319, i8* %20, align 1
  %22320 = lshr i32 %22304, 31
  %22321 = trunc i32 %22320 to i8
  store i8 %22321, i8* %21, align 1
  %22322 = lshr i32 %22303, 31
  %22323 = xor i32 %22320, %22322
  %22324 = add nuw nsw i32 %22323, %22320
  %22325 = icmp eq i32 %22324, 2
  %22326 = zext i1 %22325 to i8
  store i8 %22326, i8* %22, align 1
  %22327 = add i64 %22024, 14
  store i64 %22327, i64* %3, align 8
  store i32 %22304, i32* %22302, align 4
  %22328 = load i64, i64* %3, align 8
  %22329 = add i64 %22328, -185
  store i64 %22329, i64* %3, align 8
  br label %block_.L_4869de

block_.L_486a9c:                                  ; preds = %block_.L_4869de
  %22330 = add i64 %21991, 5
  store i64 %22330, i64* %3, align 8
  br label %block_.L_486aa1

block_.L_486aa1:                                  ; preds = %block_.L_486a9c, %block_.L_4869c2
  %22331 = phi i64 [ %21963, %block_.L_486a9c ], [ %21503, %block_.L_4869c2 ]
  %22332 = phi i64 [ %22330, %block_.L_486a9c ], [ %21958, %block_.L_4869c2 ]
  %22333 = add i64 %22332, 5
  store i64 %22333, i64* %3, align 8
  br label %block_.L_486aa6

block_.L_486aa6:                                  ; preds = %block_.L_486aa1, %block_.L_486706
  %22334 = phi i64 [ %.pre561, %block_.L_486706 ], [ %22331, %block_.L_486aa1 ]
  %storemerge217 = phi i64 [ %20820, %block_.L_486706 ], [ %22333, %block_.L_486aa1 ]
  %MEMORY.110 = phi %struct.Memory* [ %MEMORY.96, %block_.L_486706 ], [ %MEMORY.8, %block_.L_486aa1 ]
  %22335 = add i64 %22334, -76
  %22336 = add i64 %storemerge217, 3
  store i64 %22336, i64* %3, align 8
  %22337 = inttoptr i64 %22335 to i32*
  %22338 = load i32, i32* %22337, align 4
  %22339 = zext i32 %22338 to i64
  store i64 %22339, i64* %RAX.i1659, align 8
  %22340 = load i64, i64* %6, align 8
  %22341 = add i64 %22340, 776
  store i64 %22341, i64* %6, align 8
  %22342 = icmp ugt i64 %22340, -777
  %22343 = zext i1 %22342 to i8
  store i8 %22343, i8* %17, align 1
  %22344 = trunc i64 %22341 to i32
  %22345 = and i32 %22344, 255
  %22346 = tail call i32 @llvm.ctpop.i32(i32 %22345)
  %22347 = trunc i32 %22346 to i8
  %22348 = and i8 %22347, 1
  %22349 = xor i8 %22348, 1
  store i8 %22349, i8* %18, align 1
  %22350 = xor i64 %22341, %22340
  %22351 = lshr i64 %22350, 4
  %22352 = trunc i64 %22351 to i8
  %22353 = and i8 %22352, 1
  store i8 %22353, i8* %19, align 1
  %22354 = icmp eq i64 %22341, 0
  %22355 = zext i1 %22354 to i8
  store i8 %22355, i8* %20, align 1
  %22356 = lshr i64 %22341, 63
  %22357 = trunc i64 %22356 to i8
  store i8 %22357, i8* %21, align 1
  %22358 = lshr i64 %22340, 63
  %22359 = xor i64 %22356, %22358
  %22360 = add nuw nsw i64 %22359, %22356
  %22361 = icmp eq i64 %22360, 2
  %22362 = zext i1 %22361 to i8
  store i8 %22362, i8* %22, align 1
  %22363 = add i64 %storemerge217, 11
  store i64 %22363, i64* %3, align 8
  %22364 = add i64 %22340, 784
  %22365 = inttoptr i64 %22341 to i64*
  %22366 = load i64, i64* %22365, align 8
  store i64 %22366, i64* %RBX.i1545, align 8
  store i64 %22364, i64* %6, align 8
  %22367 = add i64 %storemerge217, 12
  store i64 %22367, i64* %3, align 8
  %22368 = add i64 %22340, 792
  %22369 = inttoptr i64 %22364 to i64*
  %22370 = load i64, i64* %22369, align 8
  store i64 %22370, i64* %RBP.i, align 8
  store i64 %22368, i64* %6, align 8
  %22371 = add i64 %storemerge217, 13
  store i64 %22371, i64* %3, align 8
  %22372 = inttoptr i64 %22368 to i64*
  %22373 = load i64, i64* %22372, align 8
  store i64 %22373, i64* %3, align 8
  %22374 = add i64 %22340, 800
  store i64 %22374, i64* %6, align 8
  ret %struct.Memory* %MEMORY.110
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_pushq__rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %3, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsp___rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RBP, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_pushq__rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %RBX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %3, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subq__0x308___rsp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, -776
  store i64 %6, i64* %RSP, align 8
  %7 = icmp ult i64 %3, 776
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %28
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 4294967295, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_xorl__r8d___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 0, i64* %3, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %10, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x138__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -312
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x4___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 4, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_0x2e030__rip____xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, ptrtoint (%G_0x2e030__rip__type* @G_0x2e030__rip_ to i64)
  %5 = add i64 %3, 8
  store i64 %5, i64* %PC, align 8
  %6 = inttoptr i64 %4 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  store i64 %7, i64* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %10 = bitcast i64* %9 to double*
  store double 0.000000e+00, double* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_0x2def0__rip____xmm2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, ptrtoint (%G_0x2def0__rip__type* @G_0x2def0__rip_ to i64)
  %5 = add i64 %3, 8
  store i64 %5, i64* %PC, align 8
  %6 = inttoptr i64 %4 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 0
  store i64 %7, i64* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %10 = bitcast i64* %9 to double*
  store double 0.000000e+00, double* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2___r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  store i64 2, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0xc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x10__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm0__MINUS0x18__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 5
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0x20__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x28__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x4c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -76
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1f8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -504
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cltd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %7 = bitcast %union.anon* %6 to i32*
  %8 = load i32, i32* %7, align 8
  %9 = sext i32 %8 to i64
  %10 = lshr i64 %9, 32
  store i64 %10, i64* %5, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__r10d(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x3___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 3
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RDX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 29
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 28
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x1fc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -508
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x2___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 2
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RDX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 30
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 252
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 29
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1fc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -508
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edx___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EDX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0xdc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -220
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x3___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 3
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RAX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 29
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 28
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x200__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -512
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x2___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 2
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RAX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 30
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 252
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 29
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x200__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -512
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EAX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0xe0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -224
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x98__r11____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 152
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0xdc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -220
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xe4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -228
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x9c__r11____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 156
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0xe0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -224
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xe8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -232
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xa8__r11____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xec__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -236
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xac__r11____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 172
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xf0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -240
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -228
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -504
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__esi(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xf4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -244
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -232
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xf8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -248
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm2__MINUS0x100__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -256
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm1__MINUS0x108__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -264
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3758__r11____r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 14168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RBX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0xc__rbx____rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %RBX, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RBX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x278___rbx___rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %RBX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 632
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RBX, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rbx___r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = load i64, i64* %RBX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %R11, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x20c__r11____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 524
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x16c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -364
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xc__r11____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xdc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -220
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe0__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -224
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x204__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -516
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r10d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x204__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -516
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.getLuma4x4Neighbour(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__ecx___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RCX, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  store i64 4294967295, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x150__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -336
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xdc__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -220
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x208__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -520
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x208__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -520
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x20c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -524
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x20c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -524
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0xd8__r9_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = add i64 %3, 216
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483c09(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x138__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -312
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483ba6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x11868__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 71784
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x134__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -308
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rcx_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x210__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -528
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483bb3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__eax___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x210__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -528
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x210__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -528
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x138__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -312
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x150__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -336
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483bf0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x14c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -332
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x214__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -532
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483bfd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x214__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -532
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x214__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -532
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x150__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -336
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483c42(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x68__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 104
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x140__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -320
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax__rcx_8____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x13c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -316
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x218__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -536
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483c52(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 4294967295, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x218__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -536
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x218__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -536
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x118__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -280
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483c97(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x128__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -296
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x124__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -292
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x21c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -540
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483ca7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x21c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -540
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x21c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -540
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x11c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -284
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x118__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -280
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jl_.L_483ccd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = zext i1 %10 to i8
  store i8 %11, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off1, i64 %rel_off2
  %12 = add i64 %.v, %3
  store i64 %12, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x11c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -284
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_483cdd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 2, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x220__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -544
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483d18(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x118__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -280
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl_MINUS0x11c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %5, -284
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %4, %10
  %12 = icmp ult i32 %4, %10
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %10, %4
  %22 = xor i32 %21, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %11, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %4, 31
  %34 = lshr i32 %10, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_483d00(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x224__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -548
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483d0c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x11c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -284
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x224__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -548
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x220__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -544
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x10c__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -268
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x110__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -272
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x114__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -276
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x120__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -288
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x20__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x7fffffff____rsi_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = bitcast i64* %RSI to i32**
  %4 = load i32*, i32** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  store i32 2147483647, i32* %4, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -228
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -232
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.intrapred_luma(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x9__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -9
  %10 = icmp ult i32 %8, 9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4856bf(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__0x1___al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  store i8 1, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__al__MINUS0x225__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -549
  %6 = load i8, i8* %AL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483de3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483d95(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x7__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -7
  %10 = icmp ult i32 %8, 7
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x3__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -3
  %10 = icmp ult i32 %8, 3
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_483daa(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x110__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -272
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_483de3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -1
  %10 = icmp eq i32 %8, 0
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483dbe(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_483dd3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x10c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -268
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x114__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -276
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_setne__al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %7 = load i8, i8* %6, align 1
  %8 = icmp eq i8 %7, 0
  %9 = zext i1 %8 to i8
  store i8 %9, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb_MINUS0x225__rbp____al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -549
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  store i8 %9, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_andb__0x1___al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = load i8, i8* %AL, align 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = and i8 %4, 1
  store i8 %7, i8* %AL, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = zext i8 %7 to i32
  %10 = tail call i32 @llvm.ctpop.i32(i32 %9)
  %11 = trunc i32 %10 to i8
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = xor i8 %7, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %16, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzbl__al___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i8, i8* %AL, align 1
  %5 = zext i8 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x1f4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -500
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x95c__rdx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 2396
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483e1b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__0x18__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483ea0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x960__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 2400
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483e49(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483e44(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_483e49(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4856b1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x964__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 2404
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483e77(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483e72(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_483e77(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x968__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 2408
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_483e9b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x5__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -5
  %10 = icmp ult i32 %8, 5
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jl_.L_483e9b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = zext i1 %10 to i8
  store i8 %11, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off1, i64 %rel_off2
  %12 = add i64 %.v, %3
  store i64 %12, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483ea0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x1f4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -500
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4856ac(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x9a0__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 2464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_483ff7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x34__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_483f76(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_483f63(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x726418___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xf0__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -240
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__ecx___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %ECX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax__rdx_8____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xec__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -236
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rdx_2____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0xb8___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 184
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -185
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RAX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rdx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__esi___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x34__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0xd0__rbp__rax_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RAX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -208
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ECX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 1
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp eq i32 %6, -1
  %10 = icmp eq i32 %7, 0
  %11 = or i1 %9, %10
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1
  %14 = and i32 %7, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i32 %7, %6
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = zext i1 %10 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %7, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %6, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %27
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x34__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x34__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -52
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483ee1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483f68(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x30__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483ed0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x24__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl_MINUS0x120__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %5, -288
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %4, %10
  %12 = icmp ult i32 %4, %10
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %10, %4
  %22 = xor i32 %21, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %11, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %4, 31
  %34 = lshr i32 %10, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_483f92(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x22c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -556
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483fae(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_0x2d89e__rip____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, ptrtoint (%G_0x2d89e__rip__type* @G_0x2d89e__rip_ to i64)
  %5 = add i64 %3, 8
  store i64 %5, i64* %PC, align 8
  %6 = inttoptr i64 %4 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %7, i64* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %10 = bitcast i64* %9 to double*
  store double 0.000000e+00, double* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_mulsd_MINUS0x18__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -24
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 5
  store i64 %7, i64* %PC, align 8
  %8 = bitcast %union.VectorReg* %3 to double*
  %9 = load double, double* %8, align 1
  %10 = inttoptr i64 %5 to double*
  %11 = load double, double* %10, align 8
  %12 = fmul double %9, %11
  store double %12, double* %8, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.floor_plt(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cvttsd2si__xmm0___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = bitcast %union.VectorReg* %3 to double*
  %7 = load double, double* %6, align 1
  %8 = tail call double @llvm.trunc.f64(double %7)
  %9 = tail call double @llvm.fabs.f64(double %8)
  %10 = fcmp ogt double %9, 0x41DFFFFFFFC00000
  %11 = fptosi double %8 to i32
  %12 = zext i32 %11 to i64
  %13 = select i1 %10, i64 2147483648, i64 %12
  store i64 %13, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x22c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -556
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0xd0__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -208
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x40__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -64
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x18__rcx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.SATD(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x40__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x40__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -64
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x20__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl___rcx____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = bitcast i64* %RCX to i32**
  %6 = load i32*, i32** %5, align 8
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = load i32, i32* %6, align 4
  %10 = sub i32 %4, %9
  %11 = icmp ult i32 %4, %9
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1
  %14 = and i32 %10, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i32 %9, %4
  %21 = xor i32 %20, %10
  %22 = lshr i32 %21, 4
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i32 %10, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %10, 31
  %30 = trunc i32 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %4, 31
  %33 = lshr i32 %9, 31
  %34 = xor i32 %33, %32
  %35 = xor i32 %29, %32
  %36 = add nuw nsw i32 %35, %34
  %37 = icmp eq i32 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_483ff2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x28__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -40
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = bitcast i64* %RCX to i32**
  %5 = load i32*, i32** %4, align 8
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  store i32 %6, i32* %5, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4856a7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11c14__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72724
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4842e1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484122(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48410f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rcx___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RAX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rax__rcx_2____dx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %DX, align 2
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3138___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 12600
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -12601
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xdc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -220
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -224
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__dx____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %DX, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xf0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -240
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xec__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -236
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rcx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rcx_2____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__edi___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EDI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %ESI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484024(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484114(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484013(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cc628___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cc628_type* @G_0x6cc628 to i64*), align 8
  store i64 %5, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.store_coding_state(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x48__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x24__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_MINUS0x18__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 5
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %8, i64* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %11 = bitcast i64* %10 to double*
  store double 0.000000e+00, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_MINUS0x100__rbp____xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -256
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  store i64 %8, i64* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %11 = bitcast i64* %10 to double*
  store double 0.000000e+00, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x120__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -288
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.RDCost_for_4x4IntraBlocks(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm0__MINUS0xd8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -216
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_MINUS0xd8__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -216
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %8, i64* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %11 = bitcast i64* %10 to double*
  store double 0.000000e+00, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_subsd_MINUS0x100__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -256
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = bitcast %union.VectorReg* %3 to double*
  %9 = load double, double* %8, align 1
  %10 = inttoptr i64 %5 to double*
  %11 = load double, double* %10, align 8
  %12 = fsub double %9, %11
  store double %12, double* %8, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movaps_0x3964c__rip____xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %4 = bitcast %union.VectorReg* %3 to i8*
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, ptrtoint (%G_0x3964c__rip__type* @G_0x3964c__rip_ to i64)
  %7 = add i64 %5, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %6 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = add i64 %5, add (i64 ptrtoint (%G_0x3964c__rip__type* @G_0x3964c__rip_ to i64), i64 4)
  %11 = inttoptr i64 %10 to i32*
  %12 = load i32, i32* %11, align 4
  %13 = add i64 %5, add (i64 ptrtoint (%G_0x3964c__rip__type* @G_0x3964c__rip_ to i64), i64 8)
  %14 = inttoptr i64 %13 to i32*
  %15 = load i32, i32* %14, align 4
  %16 = add i64 %5, add (i64 ptrtoint (%G_0x3964c__rip__type* @G_0x3964c__rip_ to i64), i64 12)
  %17 = inttoptr i64 %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = bitcast %union.VectorReg* %3 to i32*
  store i32 %9, i32* %19, align 1
  %20 = getelementptr inbounds i8, i8* %4, i64 4
  %21 = bitcast i8* %20 to i32*
  store i32 %12, i32* %21, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %23 = bitcast i64* %22 to i32*
  store i32 %15, i32* %23, align 1
  %24 = getelementptr inbounds i8, i8* %4, i64 12
  %25 = bitcast i8* %24 to i32*
  store i32 %18, i32* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_pand__xmm1___xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %4 = bitcast [32 x %union.VectorReg]* %3 to i8*
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %3, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %10 = load i64, i64* %9, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  %12 = load i64, i64* %11, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %14 = load i64, i64* %13, align 1
  %15 = and i64 %12, %8
  %16 = and i64 %14, %10
  %17 = trunc i64 %15 to i32
  %18 = lshr i64 %15, 32
  %19 = trunc i64 %18 to i32
  %20 = bitcast [32 x %union.VectorReg]* %3 to i32*
  store i32 %17, i32* %20, align 1
  %21 = getelementptr inbounds i8, i8* %4, i64 4
  %22 = bitcast i8* %21 to i32*
  store i32 %19, i32* %22, align 1
  %23 = trunc i64 %16 to i32
  %24 = bitcast i64* %9 to i32*
  store i32 %23, i32* %24, align 1
  %25 = lshr i64 %16, 32
  %26 = trunc i64 %25 to i32
  %27 = getelementptr inbounds i8, i8* %4, i64 12
  %28 = bitcast i8* %27 to i32*
  store i32 %26, i32* %28, align 1
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_ucomisd_MINUS0x108__rbp____xmm0(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -264
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = bitcast %union.VectorReg* %3 to double*
  %9 = load double, double* %8, align 1
  %10 = inttoptr i64 %5 to double*
  %11 = load double, double* %10, align 8
  %12 = fcmp uno double %9, %11
  br i1 %12, label %13, label %23

; <label>:13:                                     ; preds = %block_400488
  %14 = fadd double %9, %11
  %15 = bitcast double %14 to i64
  %16 = and i64 %15, 9221120237041090560
  %17 = icmp eq i64 %16, 9218868437227405312
  %18 = and i64 %15, 2251799813685247
  %19 = icmp ne i64 %18, 0
  %20 = and i1 %17, %19
  br i1 %20, label %21, label %29

; <label>:21:                                     ; preds = %13
  %22 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %7, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tE3MVnI7vec64_tEEEP6MemoryS8_R5StateT_T0_.exit

; <label>:23:                                     ; preds = %block_400488
  %24 = fcmp ogt double %9, %11
  br i1 %24, label %29, label %25

; <label>:25:                                     ; preds = %23
  %26 = fcmp olt double %9, %11
  br i1 %26, label %29, label %27

; <label>:27:                                     ; preds = %25
  %28 = fcmp oeq double %9, %11
  br i1 %28, label %29, label %36

; <label>:29:                                     ; preds = %27, %25, %23, %13
  %30 = phi i8 [ 0, %23 ], [ 0, %25 ], [ 1, %27 ], [ 1, %13 ]
  %31 = phi i8 [ 0, %23 ], [ 0, %25 ], [ 0, %27 ], [ 1, %13 ]
  %32 = phi i8 [ 0, %23 ], [ 1, %25 ], [ 0, %27 ], [ 1, %13 ]
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %31, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %32, i8* %35, align 1
  br label %36

; <label>:36:                                     ; preds = %29, %27
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %37, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %38, align 1
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %39, align 1
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tE3MVnI7vec64_tEEEP6MemoryS8_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tE3MVnI7vec64_tEEEP6MemoryS8_R5StateT_T0_.exit: ; preds = %36, %21
  %40 = phi %struct.Memory* [ %22, %21 ], [ %2, %36 ]
  ret %struct.Memory* %40
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jbe_.L_4842cf(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %5 = load i8, i8* %4, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %7 = load i8, i8* %6, align 1
  %8 = or i8 %7, %5
  %9 = icmp ne i8 %8, 0
  %10 = zext i1 %9 to i8
  store i8 %10, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %9, i64 %rel_off1, i64 %rel_off2
  %11 = add i64 %.v, %3
  store i64 %11, i64* %PC, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_ucomisd__xmm0___xmm1(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = bitcast %union.VectorReg* %4 to double*
  %8 = load double, double* %7, align 1
  %9 = bitcast [32 x %union.VectorReg]* %3 to double*
  %10 = load double, double* %9, align 1
  %11 = fcmp uno double %8, %10
  br i1 %11, label %12, label %22

; <label>:12:                                     ; preds = %block_400488
  %13 = fadd double %8, %10
  %14 = bitcast double %13 to i64
  %15 = and i64 %14, 9221120237041090560
  %16 = icmp eq i64 %15, 9218868437227405312
  %17 = and i64 %14, 2251799813685247
  %18 = icmp ne i64 %17, 0
  %19 = and i1 %16, %18
  br i1 %19, label %20, label %28

; <label>:20:                                     ; preds = %12
  %21 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:22:                                     ; preds = %block_400488
  %23 = fcmp ogt double %8, %10
  br i1 %23, label %28, label %24

; <label>:24:                                     ; preds = %22
  %25 = fcmp olt double %8, %10
  br i1 %25, label %28, label %26

; <label>:26:                                     ; preds = %24
  %27 = fcmp oeq double %8, %10
  br i1 %27, label %28, label %35

; <label>:28:                                     ; preds = %26, %24, %22, %12
  %29 = phi i8 [ 0, %22 ], [ 0, %24 ], [ 1, %26 ], [ 1, %12 ]
  %30 = phi i8 [ 0, %22 ], [ 0, %24 ], [ 0, %26 ], [ 1, %12 ]
  %31 = phi i8 [ 0, %22 ], [ 1, %24 ], [ 0, %26 ], [ 1, %12 ]
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %30, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %31, i8* %34, align 1
  br label %35

; <label>:35:                                     ; preds = %28, %26
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %36, align 1
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %37, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %38, align 1
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %35, %20
  %39 = phi %struct.Memory* [ %21, %20 ], [ %2, %35 ]
  ret %struct.Memory* %39
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484228(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x12__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -18
  %10 = icmp ult i32 %8, 18
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %8, 16
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %8, 31
  %32 = xor i32 %28, %31
  %33 = add nuw nsw i32 %32, %31
  %34 = icmp eq i32 %33, 2
  %35 = zext i1 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %35, i8* %36, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484215(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3738__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xc__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x10__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cc608___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cc608_type* @G_0x6cc608 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4841b8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48421a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4841a7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4842b3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4842a0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x90__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1918__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 6424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe8__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -232
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x3c__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx__rsi_8____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe4__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -228
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x38__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -56
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rcx__rsi_2____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x3c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x38__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x38__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -56
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484240(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4842a5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x3c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48422f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x48__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x4c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -76
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd__xmm0__MINUS0x100__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -256
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 8
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  %8 = load i64, i64* %7, align 1
  %9 = inttoptr i64 %4 to i64*
  store i64 %8, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.reset_coding_state(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4856a2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484539(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484526(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x723720___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x723720_type* @G__0x723720 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d40f0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6f6fa0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6f6f90___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = bitcast i64* %RSI to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xf0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -240
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi__r8_8____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xec__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -236
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rsi__r8_2____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 5
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x2138___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 8504
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -8505
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x16c__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -364
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r8___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xdc__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -220
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R9D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -44
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r9d___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i32, i32* %R9D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe0__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -224
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R9D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -48
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rsi__r8_2____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %R8, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 5
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__r9d___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %R9D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x15c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -348
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x726418___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x726418_type* @G_0x726418 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0xb8___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 184
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -185
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x158__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -344
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x800___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 2048
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -2049
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x154__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -340
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x154__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -340
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x15c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -348
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %R8, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____r8__rsi_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x15c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -348
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdx__rsi_4____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x1___r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R9D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = shl nuw i64 %6, 32
  %10 = ashr i64 %9, 33
  %11 = trunc i32 %5 to i8
  %12 = and i8 %11, 1
  %13 = trunc i64 %10 to i32
  %14 = and i64 %10, 4294967295
  store i64 %14, i64* %4, align 8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %17 = and i32 %13, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  store i8 %21, i8* %16, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %24 = icmp eq i32 %13, 0
  %25 = zext i1 %24 to i8
  store i8 %25, i8* %23, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %27 = lshr i64 %10, 31
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  store i8 %29, i8* %26, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %30, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__r9d___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %R9D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x168__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -360
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x158__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -344
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x168__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -360
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rcx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____rsi__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x168__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -360
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rcx__rdx_4____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4842f9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48452b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4842e8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4845b8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4845a5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484551(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4845aa(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484540(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cvttsd2si__xmm0___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = bitcast %union.VectorReg* %3 to double*
  %7 = load double, double* %6, align 1
  %8 = tail call double @llvm.trunc.f64(double %7)
  %9 = tail call double @llvm.fabs.f64(double %8)
  %10 = fcmp ogt double %9, 0x41DFFFFFFFC00000
  %11 = fptosi double %8 to i32
  %12 = zext i32 %11 to i64
  %13 = select i1 %10, i64 2147483648, i64 %12
  store i64 %13, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x160__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -352
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4846be(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4846ab(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6f6fa0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6f6fa0_type* @G__0x6f6fa0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x722ff0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdx__rsi_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____rcx__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rcx_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48461a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4846b0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484609(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__edx___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RDX, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x4___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp ugt i32 %6, -5
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.RDCost_for_4x4Blocks_Chroma(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x160__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -352
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x160__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -352
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4847a5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484792(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d40f0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d40f0_type* @G__0x6d40f0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6f8f20___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6f8f20_type* @G__0x6f8f20 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484701(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484797(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4846f0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 1, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x8___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 8
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp ugt i32 %6, -9
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484853(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484840(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d2ec0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4847eb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484845(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4847da(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484ee2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484ecf(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d2ec0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d2ec0_type* @G__0x6d2ec0 to i64), i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x722ff0___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x722ff0_type* @G__0x722ff0 to i64), i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdi___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rsi__rdi_4____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdi__rsi_4____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__r9d___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %6 = load i32, i32* %R8D, align 4
  %7 = load i32, i32* %R9D, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = sub i32 %6, %7
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %6, %7
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %7, %6
  %22 = xor i32 %21, %10
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %10, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %10, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %6, 31
  %34 = lshr i32 %7, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x168__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -360
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdx__rsi_4____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x168__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -360
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x158__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -344
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x168__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -360
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rsi__rdx_4____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x15c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -348
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x15c__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -348
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl___rcx__rdx_4____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RCX, align 8
  %7 = load i64, i64* %RDX, align 8
  %8 = shl i64 %7, 2
  %9 = add i64 %8, %6
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 4
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %9 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i32 %13, %5
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %4, align 8
  %16 = icmp ult i32 %14, %5
  %17 = icmp ult i32 %14, %13
  %18 = or i1 %16, %17
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1
  %21 = and i32 %14, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21)
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1
  %27 = xor i32 %13, %5
  %28 = xor i32 %27, %14
  %29 = lshr i32 %28, 4
  %30 = trunc i32 %29 to i8
  %31 = and i8 %30, 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %31, i8* %32, align 1
  %33 = icmp eq i32 %14, 0
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %14, 31
  %37 = trunc i32 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %37, i8* %38, align 1
  %39 = lshr i32 %5, 31
  %40 = lshr i32 %13, 31
  %41 = xor i32 %36, %39
  %42 = xor i32 %36, %40
  %43 = add nuw nsw i32 %41, %42
  %44 = icmp eq i32 %43, 2
  %45 = zext i1 %44 to i8
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %45, i8* %46, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x154__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -340
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bf0__rcx____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 72688
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x15c__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -348
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x2138___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 8504
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -8505
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x16c__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -364
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xdc__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -220
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R10D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -44
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R10D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -48
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rcx__rdx_2____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 5
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__r10d___r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %6 = load i32, i32* %R9D, align 4
  %7 = load i32, i32* %R10D, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__r9d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %EAX, align 4
  %6 = load i32, i32* %R9D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x230__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -560
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4849b4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x234__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -564
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484a02(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x15c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -348
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rcx__rdx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__esi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x234__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -564
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x230__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -560
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__eax___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %ECX, align 4
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484a2f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bf0__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72688
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x238__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -568
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484ae8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x15c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -348
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x2138___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 8504
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -8505
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x16c__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -364
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xdc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -220
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -224
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rdx__rsi_2____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edi___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i32, i32* %EDI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__ecx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %EAX, align 4
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_484a8e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x23c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -572
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484adc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x23c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -572
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x238__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -568
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x238__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -568
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__ax___dx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AX = bitcast %union.anon* %3 to i16*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %4 to i16*
  %5 = load i16, i16* %AX, align 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i16 %5, i16* %DX, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x30__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi__rdi_8____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x2c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__dx____rsi__rdi_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %DX, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bec__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 72684
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x158__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -344
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x9___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 9
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 55
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 54
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rsi__rdi_2____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 5
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  store i64 %12, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__r9d___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %6 = load i32, i32* %R8D, align 4
  %7 = load i32, i32* %R9D, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__r8d___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %ECX, align 4
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x240__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -576
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_484b87(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x244__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -580
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484bc2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x158__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -344
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0xb8___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 184
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -185
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x244__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -580
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x240__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -576
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484bef(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bec__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72684
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x248__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -584
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484c82(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x158__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -344
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0xb8___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 184
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -185
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_484c3b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x24c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -588
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484c76(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x24c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -588
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x248__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -584
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x248__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -584
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1918__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 6424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bf0__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 72688
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x154__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -340
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x16c__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -364
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r9d___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %R9D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x250__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -592
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_484d3c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x254__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -596
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484d91(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x154__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -340
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x800___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 2048
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -2049
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x254__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -596
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x250__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -592
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_484dbe(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x258__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -600
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484e85(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x154__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -340
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x800___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 2048
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -2049
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_484e24(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x25c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484e79(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x25c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -604
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x258__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -600
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x258__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -600
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__ax___cx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AX = bitcast %union.anon* %3 to i16*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CX = bitcast %union.anon* %4 to i16*
  %5 = load i16, i16* %AX, align 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i16 %5, i16* %CX, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rdx__rsi_8____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__cx____rdx__rsi_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CX = bitcast %union.anon* %3 to i16*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %CX, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48486b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484ed4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48485a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x164__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -356
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48513a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe4__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -228
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x4___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RCX, align 8
  %9 = icmp ugt i32 %6, -5
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485127(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe8__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -232
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x3c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x38__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1918__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x3c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -232
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x3c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rdx_2____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imull__esi___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = shl i64 %4, 32
  %9 = ashr exact i64 %8, 32
  %10 = sext i32 %5 to i64
  %11 = mul nsw i64 %10, %9
  %12 = trunc i64 %11 to i32
  %13 = and i64 %11, 4294967295
  store i64 %13, i64* %RCX, align 8
  %14 = shl i64 %11, 32
  %15 = ashr exact i64 %14, 32
  %16 = icmp ne i64 %15, %11
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %25, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %26, align 1
  %27 = lshr i32 %12, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %17, i8* %30, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x164__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -356
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x164__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -356
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6f6f90___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6f6f90_type* @G_0x6f6f90 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = bitcast i64* %RAX to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484f06(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48512c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_484ef3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cvtsi2sdl_MINUS0x164__rbp____xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -356
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = sitofp i32 %9 to double
  %11 = bitcast %union.VectorReg* %3 to double*
  store double %10, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movsd_MINUS0x18__rbp____xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 5
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 0
  store i64 %8, i64* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %11 = bitcast i64* %10 to double*
  store double 0.000000e+00, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cvtsi2sdl_MINUS0x160__rbp____xmm2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -352
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = sitofp i32 %9 to double
  %11 = bitcast %union.VectorReg* %3 to double*
  store double %10, double* %11, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_mulsd__xmm2___xmm1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = bitcast %union.VectorReg* %3 to double*
  %8 = load double, double* %7, align 1
  %9 = bitcast %union.VectorReg* %4 to double*
  %10 = load double, double* %9, align 1
  %11 = fmul double %8, %10
  store double %11, double* %7, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_addsd__xmm1___xmm0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = bitcast [32 x %union.VectorReg]* %3 to double*
  %8 = load double, double* %7, align 1
  %9 = bitcast %union.VectorReg* %4 to double*
  %10 = load double, double* %9, align 1
  %11 = fadd double %8, %10
  store double %11, double* %7, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jbe_.L_48569d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %5 = load i8, i8* %4, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %7 = load i8, i8* %6, align 1
  %8 = or i8 %7, %5
  %9 = icmp ne i8 %8, 0
  %10 = zext i1 %9 to i8
  store i8 %10, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %9, i64 %rel_off1, i64 %rel_off2
  %11 = add i64 %.v, %3
  store i64 %11, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485201(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4851ee(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485191(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4851f3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485180(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485293(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485280(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6f9560___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6f9560_type* @G__0x6f9560 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3738__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x4___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RDX, align 8
  %9 = icmp ugt i32 %6, -5
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x10__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rcx__rsi_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x48___rcx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 72
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485219(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485285(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485208(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48532b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485318(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x90___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 144
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -145
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x8___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 8
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RDX, align 8
  %9 = icmp ugt i32 %6, -9
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4852ab(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48531d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48529a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4855f6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d0920___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6cd4f0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6cd4f0_type* @G__0x6cd4f0 to i64), i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x7107b0___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d4600___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r8___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x260__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -608
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r9d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %R9D, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0x268__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -616
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x260__rbp____r9d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -608
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__r9d(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %R9D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x1___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = shl i32 %6, 1
  %8 = icmp slt i32 %6, 0
  %9 = icmp slt i32 %7, 0
  %10 = xor i1 %8, %9
  %11 = zext i32 %7 to i64
  store i64 %11, i64* %RDX, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %.lobit = lshr i32 %6, 31
  %13 = trunc i32 %.lobit to i8
  store i8 %13, i8* %12, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %7, 254
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %7, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i32 %6, 30
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %29 = zext i1 %10 to i8
  store i8 %29, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x26c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -620
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x26c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -620
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edx___r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %6 = load i32, i32* %R10D, align 4
  %7 = load i32, i32* %EDX, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = shl i32 %6, 1
  %8 = icmp slt i32 %6, 0
  %9 = icmp slt i32 %7, 0
  %10 = xor i1 %8, %9
  %11 = zext i32 %7 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %.lobit = lshr i32 %6, 31
  %13 = trunc i32 %.lobit to i8
  store i8 %13, i8* %12, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %7, 254
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %7, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i32 %6, 30
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %29 = zext i1 %10 to i8
  store i8 %29, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x270__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x270__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %6 = load i32, i32* %R10D, align 4
  %7 = load i32, i32* %EAX, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdi__r8_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x274__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -628
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x278__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -632
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x278__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -632
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x27c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -636
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x27c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -636
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x274__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rsi__rdi_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x268__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -616
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x280__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -640
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x280__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -640
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x284__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -644
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x284__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -644
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rdi__rsi_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x288__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -648
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x28c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -652
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x28c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -652
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x290__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -656
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x290__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -656
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x288__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -648
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx__rsi_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4855e3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4855d0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x1f0__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -496
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx__rdx_8____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -228
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x38__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -56
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48555d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4855d5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48554c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4855e8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485332(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485681(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48566e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48560e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485673(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4855fd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4856ac(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -36
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_483d5b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x28__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x68__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 104
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xf4__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -244
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xf8__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -248
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x120__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -288
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl_MINUS0x28__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %5, -40
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %4, %10
  %12 = icmp ult i32 %4, %10
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %10, %4
  %22 = xor i32 %21, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %11, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %4, 31
  %34 = lshr i32 %10, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_485702(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x294__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -660
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485737(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48571f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x298__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -664
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48572b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, -1
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp eq i32 %6, 0
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %29
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x298__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -664
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x294__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -660
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3758__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 14168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0xc__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x278___rdx___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 632
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RDX, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x2___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 2
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RSI, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 30
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 252
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 29
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x10__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x14c__rcx__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 332
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x9a0__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 2464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48670b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4858d7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4858b5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4858a2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4857b7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4858a7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4857a6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x44__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -68
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 1, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.dct_luma(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486706(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485b2f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485b1c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4858ef(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485b21(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4858de(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485bae(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485b9b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485b47(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485ba0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485b36(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485c87(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485c74(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485be3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485c79(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485bd2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__edi___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.dct_chroma4x4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 2, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x7107b0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x7107b0_type* @G__0x7107b0 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d4600___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d4600_type* @G__0x6d4600 to i64), i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d0920___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d0920_type* @G__0x6d0920 to i64), i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x29c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -668
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x2a0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -672
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2a0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -672
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x2a4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -676
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2a4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -676
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edx___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %EDX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___r10(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R10, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___r10(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %3 = load i64, i64* %R10, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %R10, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r10___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %R10, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %R9, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2a8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -680
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2a8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -680
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %EAX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x29c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -668
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____r9__r10_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %R9, align 8
  %5 = load i64, i64* %R10, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x2ac__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -684
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2ac__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -684
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %R9, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r9___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %R9, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %R8, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2b0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -688
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2b0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -688
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___r8__r9_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %R9, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2b4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -692
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x2b8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -696
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2b8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -696
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r8___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2bc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -700
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2bc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -700
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2b4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -692
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx__r8_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %R8, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485e93(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_485e80(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485def(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485e85(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485dde(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 1, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x40___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 64
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -65
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x40___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 64
  store i64 %6, i64* %R8, align 8
  %7 = icmp ugt i64 %3, -65
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x40___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 64
  store i64 %6, i64* %R9, align 8
  %7 = icmp ugt i64 %3, -65
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2c0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -704
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x2c4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -708
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -708
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x2c8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -712
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -712
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2cc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -716
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2cc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -716
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -704
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x2d0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -720
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2d0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -720
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2d4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -724
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2d4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -724
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2d8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -728
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x2dc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -732
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2dc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -732
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2e0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -736
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2e0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -736
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2d8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -728
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_486072(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48605f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48600a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486064(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_485ff9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_486701(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4866ee(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d__MINUS0x2e4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -740
  %6 = load i32, i32* %R8D, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4861d3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2e8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -744
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486221(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2e8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -744
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2e4__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -740
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48624e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x2ec__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -748
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486307(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4862ad(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2f0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -752
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4862fb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2f0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -752
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2ec__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -748
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2ec__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -748
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2f4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -756
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4863a6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2f8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -760
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4863e1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2f8__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -760
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2f4__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -756
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48640e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x2fc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -764
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4864a1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x28__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_48645a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x300__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -768
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486495(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x300__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -768
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2fc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -764
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2fc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -764
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x304__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -772
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_48655b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x308__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -776
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4865b0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x308__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -776
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x304__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -772
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4865dd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x30c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -780
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4866a4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_486643(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x310__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -784
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486698(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x310__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -784
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x30c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -780
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x30c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -780
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48608a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4866f3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486079(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486aa6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_486793(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_486780(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486723(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486785(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486712(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4868d7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48683a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_486827(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x4___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RSI, align 8
  %9 = icmp ugt i32 %6, -5
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4867c0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48682c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4867af(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4868d2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4868bf(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x8___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 8
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RSI, align 8
  %9 = icmp ugt i32 %6, -9
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486852(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4868c4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486841(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4868d7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4869c2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4869af(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__dx___si(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %4 to i16*
  %5 = load i16, i16* %DX, align 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i16 %5, i16* %SI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__si____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %SI, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rax__rcx_2____si(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %SI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xe0__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -224
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4868ef(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4869b4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4868de(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_486aa1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_486a9c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_486a89(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_486a76(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486a00(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486a7b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4869ef(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486a8e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4869de(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_486aa1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -76
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x308___rsp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 776
  store i64 %6, i64* %RSP, align 8
  %7 = icmp ugt i64 %3, -777
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_popq__rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 8
  %8 = inttoptr i64 %6 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %RBX, align 8
  store i64 %7, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_popq__rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 8
  %8 = inttoptr i64 %6 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %RBP, align 8
  store i64 %7, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_retq(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = inttoptr i64 %6 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %PC, align 8
  %9 = add i64 %6, 8
  store i64 %9, i64* %5, align 8
  ret %struct.Memory* %2
}

attributes #0 = { nounwind readnone }
attributes #1 = { alwaysinline }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
