; ModuleID = 'mcsema/test.proposed.inline.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%__bss_start_type = type <{ [8 x i8] }>
%G_0x6cb8f8_type = type <{ [8 x i8] }>
%G_0x6cb900_type = type <{ [8 x i8] }>
%G_0x70fcf0_type = type <{ [8 x i8] }>
%G__0x4ba450_type = type <{ [8 x i8] }>
%G__0x6cfc70_type = type <{ [8 x i8] }>
%G__0x6d0bc0_type = type <{ [8 x i8] }>
%G__0x6d12c0_type = type <{ [8 x i8] }>
%G__0x70f6e0_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.anon = type { i64 }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque

@__bss_start = local_unnamed_addr global %__bss_start_type zeroinitializer
@G_0x6cb8f8 = local_unnamed_addr global %G_0x6cb8f8_type zeroinitializer
@G_0x6cb900 = local_unnamed_addr global %G_0x6cb900_type zeroinitializer
@G_0x70fcf0 = local_unnamed_addr global %G_0x70fcf0_type zeroinitializer
@G__0x4ba450 = global %G__0x4ba450_type zeroinitializer
@G__0x6cfc70 = global %G__0x6cfc70_type zeroinitializer
@G__0x6d0bc0 = global %G__0x6d0bc0_type zeroinitializer
@G__0x6d12c0 = global %G__0x6d12c0_type zeroinitializer
@G__0x70f6e0 = global %G__0x70f6e0_type zeroinitializer

declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

declare extern_weak x86_64_sysvcc i64 @abs(i64)

declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr

declare %struct.Memory* @sub_475150.sign(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: alwaysinline
define %struct.Memory* @dct_luma8x8(%struct.State* noalias, i64, %struct.Memory* noalias) local_unnamed_addr #1 {
entry:
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP.i = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP.i, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %3, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  %10 = load i64, i64* %3, align 8
  store i64 %8, i64* %RBP.i, align 8
  %11 = add i64 %7, -760
  store i64 %11, i64* %6, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX.i2609 = bitcast %union.anon* %18 to i32*
  %RAX.i2610 = getelementptr inbounds %union.anon, %union.anon* %18, i64 0, i32 0
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %AL.i3806 = bitcast %union.anon* %18 to i8*
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL.i3807 = bitcast %union.anon* %19 to i8*
  store i8 0, i8* %CL.i3807, align 1
  store i64 2, i64* %RAX.i2610, align 8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI.i3928 = bitcast %union.anon* %20 to i32*
  %21 = add i64 %7, -12
  %22 = load i32, i32* %EDI.i3928, align 4
  %23 = add i64 %10, 22
  store i64 %23, i64* %3, align 8
  %24 = inttoptr i64 %21 to i32*
  store i32 %22, i32* %24, align 4
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %RSI.i3950 = getelementptr inbounds %union.anon, %union.anon* %25, i64 0, i32 0
  %26 = load i64, i64* %RBP.i, align 8
  %27 = add i64 %26, -16
  %28 = load i64, i64* %RSI.i3950, align 8
  %29 = load i64, i64* %3, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %3, align 8
  %31 = inttoptr i64 %27 to i64*
  store i64 %28, i64* %31, align 8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX.i4064 = bitcast %union.anon* %32 to i32*
  %33 = load i64, i64* %RBP.i, align 8
  %34 = add i64 %33, -20
  %35 = load i32, i32* %EDX.i4064, align 4
  %36 = load i64, i64* %3, align 8
  %37 = add i64 %36, 3
  store i64 %37, i64* %3, align 8
  %38 = inttoptr i64 %34 to i32*
  store i32 %35, i32* %38, align 4
  %39 = load i64, i64* %RBP.i, align 8
  %40 = add i64 %39, -72
  %41 = load i64, i64* %3, align 8
  %42 = add i64 %41, 7
  store i64 %42, i64* %3, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 0, i32* %43, align 4
  %44 = load i64, i64* %RBP.i, align 8
  %45 = add i64 %44, -76
  %46 = load i64, i64* %3, align 8
  %47 = add i64 %46, 7
  store i64 %47, i64* %3, align 8
  %48 = inttoptr i64 %45 to i32*
  store i32 0, i32* %48, align 4
  %49 = load i64, i64* %RBP.i, align 8
  %50 = add i64 %49, -80
  %51 = load i64, i64* %3, align 8
  %52 = add i64 %51, 7
  store i64 %52, i64* %3, align 8
  %53 = inttoptr i64 %50 to i32*
  store i32 0, i32* %53, align 4
  %RDX.i4094 = getelementptr inbounds %union.anon, %union.anon* %32, i64 0, i32 0
  %54 = load i64, i64* %RBP.i, align 8
  %55 = add i64 %54, -4
  %56 = load i64, i64* %3, align 8
  %57 = add i64 %56, 3
  store i64 %57, i64* %3, align 8
  %58 = inttoptr i64 %55 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = zext i32 %59 to i64
  store i64 %60, i64* %RDX.i4094, align 8
  %61 = add i64 %54, -676
  %62 = load i32, i32* %EAX.i2609, align 4
  %63 = add i64 %56, 9
  store i64 %63, i64* %3, align 8
  %64 = inttoptr i64 %61 to i32*
  store i32 %62, i32* %64, align 4
  %65 = load i32, i32* %EDX.i4064, align 4
  %66 = zext i32 %65 to i64
  %67 = load i64, i64* %3, align 8
  store i64 %66, i64* %RAX.i2610, align 8
  %68 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %69 = sext i32 %65 to i64
  %70 = lshr i64 %69, 32
  store i64 %70, i64* %68, align 8
  %RDI.i4084 = getelementptr inbounds %union.anon, %union.anon* %20, i64 0, i32 0
  %71 = load i64, i64* %RBP.i, align 8
  %72 = add i64 %71, -676
  %73 = add i64 %67, 9
  store i64 %73, i64* %3, align 8
  %74 = inttoptr i64 %72 to i32*
  %75 = load i32, i32* %74, align 4
  %76 = zext i32 %75 to i64
  store i64 %76, i64* %RDI.i4084, align 8
  %77 = add i64 %67, 11
  store i64 %77, i64* %3, align 8
  %78 = sext i32 %75 to i64
  %79 = shl nuw i64 %70, 32
  %80 = or i64 %79, %66
  %81 = sdiv i64 %80, %78
  %82 = shl i64 %81, 32
  %83 = ashr exact i64 %82, 32
  %84 = icmp eq i64 %81, %83
  br i1 %84, label %87, label %85

; <label>:85:                                     ; preds = %entry
  %86 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %77, %struct.Memory* %2)
  %.pre = load i64, i64* %RDX.i4094, align 8
  %.pre154 = load i64, i64* %3, align 8
  %.pre155 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__edi.exit4080

; <label>:87:                                     ; preds = %entry
  %88 = srem i64 %80, %78
  %89 = and i64 %81, 4294967295
  store i64 %89, i64* %RAX.i2610, align 8
  %90 = and i64 %88, 4294967295
  store i64 %90, i64* %RDX.i4094, align 8
  store i8 0, i8* %12, align 1
  store i8 0, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  br label %routine_idivl__edi.exit4080

routine_idivl__edi.exit4080:                      ; preds = %87, %85
  %91 = phi i64 [ %.pre155, %85 ], [ %71, %87 ]
  %92 = phi i64 [ %.pre154, %85 ], [ %77, %87 ]
  %93 = phi i64 [ %.pre, %85 ], [ %90, %87 ]
  %94 = phi %struct.Memory* [ %86, %85 ], [ %2, %87 ]
  %.tr = trunc i64 %93 to i32
  %95 = shl i32 %.tr, 3
  %96 = zext i32 %95 to i64
  store i64 %96, i64* %RDX.i4094, align 8
  %97 = lshr i64 %93, 29
  %98 = trunc i64 %97 to i8
  %99 = and i8 %98, 1
  store i8 %99, i8* %12, align 1
  %100 = and i32 %95, 248
  %101 = tail call i32 @llvm.ctpop.i32(i32 %100)
  %102 = trunc i32 %101 to i8
  %103 = and i8 %102, 1
  %104 = xor i8 %103, 1
  store i8 %104, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %105 = icmp eq i32 %95, 0
  %106 = zext i1 %105 to i8
  store i8 %106, i8* %15, align 1
  %107 = lshr i32 %.tr, 28
  %108 = trunc i32 %107 to i8
  %109 = and i8 %108, 1
  store i8 %109, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %110 = add i64 %91, -84
  %111 = add i64 %92, 6
  store i64 %111, i64* %3, align 8
  %112 = inttoptr i64 %110 to i32*
  store i32 %95, i32* %112, align 4
  %113 = load i64, i64* %RBP.i, align 8
  %114 = add i64 %113, -4
  %115 = load i64, i64* %3, align 8
  %116 = add i64 %115, 3
  store i64 %116, i64* %3, align 8
  %117 = inttoptr i64 %114 to i32*
  %118 = load i32, i32* %117, align 4
  %119 = zext i32 %118 to i64
  store i64 %119, i64* %RAX.i2610, align 8
  %120 = sext i32 %118 to i64
  %121 = lshr i64 %120, 32
  store i64 %121, i64* %68, align 8
  %122 = load i32, i32* %EDI.i3928, align 4
  %123 = add i64 %115, 8
  store i64 %123, i64* %3, align 8
  %124 = sext i32 %122 to i64
  %125 = shl nuw i64 %121, 32
  %126 = or i64 %125, %119
  %127 = sdiv i64 %126, %124
  %128 = shl i64 %127, 32
  %129 = ashr exact i64 %128, 32
  %130 = icmp eq i64 %127, %129
  br i1 %130, label %133, label %131

; <label>:131:                                    ; preds = %routine_idivl__edi.exit4080
  %132 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %123, %struct.Memory* %94)
  %.pre156 = load i64, i64* %RAX.i2610, align 8
  %.pre157 = load i64, i64* %3, align 8
  %.pre158 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__edi.exit

; <label>:133:                                    ; preds = %routine_idivl__edi.exit4080
  %134 = srem i64 %126, %124
  %135 = and i64 %127, 4294967295
  store i64 %135, i64* %RAX.i2610, align 8
  %136 = and i64 %134, 4294967295
  store i64 %136, i64* %RDX.i4094, align 8
  store i8 0, i8* %12, align 1
  store i8 0, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  br label %routine_idivl__edi.exit

routine_idivl__edi.exit:                          ; preds = %133, %131
  %137 = phi i64 [ %.pre158, %131 ], [ %113, %133 ]
  %138 = phi i64 [ %.pre157, %131 ], [ %123, %133 ]
  %139 = phi i64 [ %.pre156, %131 ], [ %135, %133 ]
  %140 = phi %struct.Memory* [ %132, %131 ], [ %94, %133 ]
  %.tr40 = trunc i64 %139 to i32
  %141 = shl i32 %.tr40, 3
  %142 = zext i32 %141 to i64
  store i64 %142, i64* %RAX.i2610, align 8
  %143 = lshr i64 %139, 29
  %144 = trunc i64 %143 to i8
  %145 = and i8 %144, 1
  store i8 %145, i8* %12, align 1
  %146 = and i32 %141, 248
  %147 = tail call i32 @llvm.ctpop.i32(i32 %146)
  %148 = trunc i32 %147 to i8
  %149 = and i8 %148, 1
  %150 = xor i8 %149, 1
  store i8 %150, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %151 = icmp eq i32 %141, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %15, align 1
  %153 = lshr i32 %.tr40, 28
  %154 = trunc i32 %153 to i8
  %155 = and i8 %154, 1
  store i8 %155, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %156 = add i64 %137, -88
  %157 = add i64 %138, 6
  store i64 %157, i64* %3, align 8
  %158 = inttoptr i64 %156 to i32*
  store i32 %141, i32* %158, align 4
  %159 = load i64, i64* %3, align 8
  %160 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %160, i64* %RSI.i3950, align 8
  %161 = add i64 %160, 14136
  %162 = add i64 %159, 15
  store i64 %162, i64* %3, align 8
  %163 = inttoptr i64 %161 to i64*
  %164 = load i64, i64* %163, align 8
  store i64 %164, i64* %RSI.i3950, align 8
  %R8.i4051 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %165 = load i64, i64* %RBP.i, align 8
  %166 = add i64 %165, -4
  %167 = add i64 %159, 19
  store i64 %167, i64* %3, align 8
  %168 = inttoptr i64 %166 to i32*
  %169 = load i32, i32* %168, align 4
  %170 = sext i32 %169 to i64
  store i64 %170, i64* %R8.i4051, align 8
  %171 = shl nsw i64 %170, 3
  %172 = add i64 %171, %164
  %173 = add i64 %159, 23
  store i64 %173, i64* %3, align 8
  %174 = inttoptr i64 %172 to i64*
  %175 = load i64, i64* %174, align 8
  store i64 %175, i64* %RSI.i3950, align 8
  %176 = add i64 %159, 26
  store i64 %176, i64* %3, align 8
  %177 = inttoptr i64 %175 to i64*
  %178 = load i64, i64* %177, align 8
  store i64 %178, i64* %RSI.i3950, align 8
  %179 = add i64 %159, 29
  store i64 %179, i64* %3, align 8
  %180 = inttoptr i64 %178 to i64*
  %181 = load i64, i64* %180, align 8
  %182 = add i64 %165, -96
  %183 = add i64 %159, 33
  store i64 %183, i64* %3, align 8
  %184 = inttoptr i64 %182 to i64*
  store i64 %181, i64* %184, align 8
  %185 = load i64, i64* %3, align 8
  %186 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %186, i64* %RSI.i3950, align 8
  %187 = add i64 %186, 14136
  %188 = add i64 %185, 15
  store i64 %188, i64* %3, align 8
  %189 = inttoptr i64 %187 to i64*
  %190 = load i64, i64* %189, align 8
  store i64 %190, i64* %RSI.i3950, align 8
  %191 = load i64, i64* %RBP.i, align 8
  %192 = add i64 %191, -4
  %193 = add i64 %185, 19
  store i64 %193, i64* %3, align 8
  %194 = inttoptr i64 %192 to i32*
  %195 = load i32, i32* %194, align 4
  %196 = sext i32 %195 to i64
  store i64 %196, i64* %R8.i4051, align 8
  %197 = shl nsw i64 %196, 3
  %198 = add i64 %197, %190
  %199 = add i64 %185, 23
  store i64 %199, i64* %3, align 8
  %200 = inttoptr i64 %198 to i64*
  %201 = load i64, i64* %200, align 8
  store i64 %201, i64* %RSI.i3950, align 8
  %202 = add i64 %185, 26
  store i64 %202, i64* %3, align 8
  %203 = inttoptr i64 %201 to i64*
  %204 = load i64, i64* %203, align 8
  store i64 %204, i64* %RSI.i3950, align 8
  %205 = add i64 %204, 8
  %206 = add i64 %185, 30
  store i64 %206, i64* %3, align 8
  %207 = inttoptr i64 %205 to i64*
  %208 = load i64, i64* %207, align 8
  %209 = add i64 %191, -104
  %210 = add i64 %185, 34
  store i64 %210, i64* %3, align 8
  %211 = inttoptr i64 %209 to i64*
  store i64 %208, i64* %211, align 8
  %212 = load i64, i64* %3, align 8
  %213 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %213, i64* %RSI.i3950, align 8
  %214 = add i64 %213, 14168
  %215 = add i64 %212, 15
  store i64 %215, i64* %3, align 8
  %216 = inttoptr i64 %214 to i64*
  %217 = load i64, i64* %216, align 8
  store i64 %217, i64* %RSI.i3950, align 8
  store i64 %213, i64* %R8.i4051, align 8
  %218 = add i64 %213, 12
  %219 = add i64 %212, 27
  store i64 %219, i64* %3, align 8
  %220 = inttoptr i64 %218 to i32*
  %221 = load i32, i32* %220, align 4
  %222 = sext i32 %221 to i64
  %223 = mul nsw i64 %222, 632
  store i64 %223, i64* %R8.i4051, align 8
  %224 = lshr i64 %223, 63
  %225 = add i64 %223, %217
  %226 = icmp ult i64 %225, %217
  %227 = icmp ult i64 %225, %223
  %228 = or i1 %226, %227
  %229 = zext i1 %228 to i8
  store i8 %229, i8* %12, align 1
  %230 = trunc i64 %225 to i32
  %231 = and i32 %230, 255
  %232 = tail call i32 @llvm.ctpop.i32(i32 %231)
  %233 = trunc i32 %232 to i8
  %234 = and i8 %233, 1
  %235 = xor i8 %234, 1
  store i8 %235, i8* %13, align 1
  %236 = xor i64 %223, %217
  %237 = xor i64 %236, %225
  %238 = lshr i64 %237, 4
  %239 = trunc i64 %238 to i8
  %240 = and i8 %239, 1
  store i8 %240, i8* %14, align 1
  %241 = icmp eq i64 %225, 0
  %242 = zext i1 %241 to i8
  store i8 %242, i8* %15, align 1
  %243 = lshr i64 %225, 63
  %244 = trunc i64 %243 to i8
  store i8 %244, i8* %16, align 1
  %245 = lshr i64 %217, 63
  %246 = xor i64 %243, %245
  %247 = xor i64 %243, %224
  %248 = add nuw nsw i64 %246, %247
  %249 = icmp eq i64 %248, 2
  %250 = zext i1 %249 to i8
  store i8 %250, i8* %17, align 1
  %251 = load i64, i64* %RBP.i, align 8
  %252 = add i64 %251, -408
  %253 = add i64 %212, 44
  store i64 %253, i64* %3, align 8
  %254 = inttoptr i64 %252 to i64*
  store i64 %225, i64* %254, align 8
  %255 = load i64, i64* %3, align 8
  %256 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %256, i64* %RSI.i3950, align 8
  %257 = add i64 %256, 40
  %258 = add i64 %255, 11
  store i64 %258, i64* %3, align 8
  %259 = inttoptr i64 %257 to i32*
  %260 = load i32, i32* %259, align 4
  %261 = zext i32 %260 to i64
  store i64 %261, i64* %RAX.i2610, align 8
  store i64 %256, i64* %RSI.i3950, align 8
  %262 = add i64 %256, 72668
  %263 = add i64 %255, 25
  store i64 %263, i64* %3, align 8
  %264 = inttoptr i64 %262 to i32*
  %265 = load i32, i32* %264, align 4
  %266 = add i32 %265, %260
  %267 = zext i32 %266 to i64
  store i64 %267, i64* %RAX.i2610, align 8
  %268 = and i32 %266, 255
  %269 = tail call i32 @llvm.ctpop.i32(i32 %268)
  %270 = trunc i32 %269 to i8
  %271 = and i8 %270, 1
  %272 = xor i8 %271, 1
  %273 = icmp eq i32 %266, 0
  %274 = zext i1 %273 to i8
  %275 = lshr i32 %266, 31
  %276 = trunc i32 %275 to i8
  store i8 0, i8* %12, align 1
  store i8 %272, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 %274, i8* %15, align 1
  store i8 %276, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %277 = load i64, i64* %RBP.i, align 8
  %278 = add i64 %277, -677
  %279 = load i8, i8* %CL.i3807, align 1
  %280 = add i64 %255, 34
  store i64 %280, i64* %3, align 8
  %281 = inttoptr i64 %278 to i8*
  store i8 %279, i8* %281, align 1
  %282 = load i64, i64* %3, align 8
  %283 = add i64 %282, 30
  %284 = add i64 %282, 6
  %285 = load i8, i8* %15, align 1
  %286 = icmp eq i8 %285, 0
  %287 = select i1 %286, i64 %283, i64 %284
  store i64 %287, i64* %3, align 8
  br i1 %286, label %block_.L_4aa84a, label %block_4aa832

block_4aa832:                                     ; preds = %routine_idivl__edi.exit
  %288 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %288, i64* %RAX.i2610, align 8
  %289 = add i64 %288, 72704
  %290 = add i64 %287, 15
  store i64 %290, i64* %3, align 8
  %291 = inttoptr i64 %289 to i32*
  %292 = load i32, i32* %291, align 4
  %293 = add i32 %292, -1
  %294 = icmp eq i32 %292, 0
  %295 = zext i1 %294 to i8
  store i8 %295, i8* %12, align 1
  %296 = and i32 %293, 255
  %297 = tail call i32 @llvm.ctpop.i32(i32 %296)
  %298 = trunc i32 %297 to i8
  %299 = and i8 %298, 1
  %300 = xor i8 %299, 1
  store i8 %300, i8* %13, align 1
  %301 = xor i32 %293, %292
  %302 = lshr i32 %301, 4
  %303 = trunc i32 %302 to i8
  %304 = and i8 %303, 1
  store i8 %304, i8* %14, align 1
  %305 = icmp eq i32 %293, 0
  %306 = zext i1 %305 to i8
  store i8 %306, i8* %15, align 1
  %307 = lshr i32 %293, 31
  %308 = trunc i32 %307 to i8
  store i8 %308, i8* %16, align 1
  %309 = lshr i32 %292, 31
  %310 = xor i32 %307, %309
  %311 = add nuw nsw i32 %310, %309
  %312 = icmp eq i32 %311, 2
  %313 = zext i1 %312 to i8
  store i8 %313, i8* %17, align 1
  store i8 %306, i8* %CL.i3807, align 1
  %314 = load i64, i64* %RBP.i, align 8
  %315 = add i64 %314, -677
  %316 = add i64 %287, 24
  store i64 %316, i64* %3, align 8
  %317 = inttoptr i64 %315 to i8*
  store i8 %306, i8* %317, align 1
  %.pre159 = load i64, i64* %3, align 8
  br label %block_.L_4aa84a

block_.L_4aa84a:                                  ; preds = %block_4aa832, %routine_idivl__edi.exit
  %318 = phi i64 [ %.pre159, %block_4aa832 ], [ %283, %routine_idivl__edi.exit ]
  %319 = load i64, i64* %RBP.i, align 8
  %320 = add i64 %319, -677
  %321 = add i64 %318, 6
  store i64 %321, i64* %3, align 8
  %322 = inttoptr i64 %320 to i8*
  %323 = load i8, i8* %322, align 1
  %RCX.i3977 = getelementptr inbounds %union.anon, %union.anon* %19, i64 0, i32 0
  store i64 6, i64* %RCX.i3977, align 8
  %324 = and i8 %323, 1
  store i8 %324, i8* %AL.i3806, align 1
  store i8 0, i8* %12, align 1
  %325 = zext i8 %324 to i32
  %326 = tail call i32 @llvm.ctpop.i32(i32 %325)
  %327 = trunc i32 %326 to i8
  %328 = xor i8 %327, 1
  store i8 %328, i8* %13, align 1
  %329 = xor i8 %324, 1
  store i8 %329, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %330 = zext i8 %324 to i64
  store i64 %330, i64* %RDX.i4094, align 8
  %331 = add i64 %319, -412
  %332 = zext i8 %324 to i32
  %333 = add i64 %318, 22
  store i64 %333, i64* %3, align 8
  %334 = inttoptr i64 %331 to i32*
  store i32 %332, i32* %334, align 4
  %335 = load i64, i64* %3, align 8
  %336 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %336, i64* %RSI.i3950, align 8
  %337 = add i64 %336, 40
  %338 = add i64 %335, 11
  store i64 %338, i64* %3, align 8
  %339 = inttoptr i64 %337 to i32*
  %340 = load i32, i32* %339, align 4
  %341 = zext i32 %340 to i64
  store i64 %341, i64* %RDX.i4094, align 8
  store i64 %336, i64* %RSI.i3950, align 8
  %342 = add i64 %336, 72668
  %343 = add i64 %335, 25
  store i64 %343, i64* %3, align 8
  %344 = inttoptr i64 %342 to i32*
  %345 = load i32, i32* %344, align 4
  %346 = add i32 %345, %340
  %347 = and i32 %346, 255
  %348 = tail call i32 @llvm.ctpop.i32(i32 %347)
  %349 = trunc i32 %348 to i8
  %350 = and i8 %349, 1
  %351 = xor i8 %350, 1
  %352 = icmp eq i32 %346, 0
  %353 = zext i1 %352 to i8
  %354 = lshr i32 %346, 31
  %355 = trunc i32 %354 to i8
  store i8 0, i8* %12, align 1
  store i8 %351, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 %353, i8* %15, align 1
  store i8 %355, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %356 = zext i32 %346 to i64
  store i64 %356, i64* %RAX.i2610, align 8
  %357 = sext i32 %346 to i64
  %358 = lshr i64 %357, 32
  store i64 %358, i64* %68, align 8
  %ECX.i3947 = bitcast %union.anon* %19 to i32*
  %359 = load i32, i32* %ECX.i3947, align 4
  %360 = add i64 %335, 33
  store i64 %360, i64* %3, align 8
  %361 = sext i32 %359 to i64
  %362 = shl nuw i64 %358, 32
  %363 = or i64 %362, %356
  %364 = sdiv i64 %363, %361
  %365 = shl i64 %364, 32
  %366 = ashr exact i64 %365, 32
  %367 = icmp eq i64 %364, %366
  br i1 %367, label %370, label %368

; <label>:368:                                    ; preds = %block_.L_4aa84a
  %369 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %360, %struct.Memory* %140)
  %.pre160 = load i32, i32* %EAX.i2609, align 4
  %.pre161 = load i64, i64* %3, align 8
  br label %routine_idivl__ecx.exit3948

; <label>:370:                                    ; preds = %block_.L_4aa84a
  %371 = srem i64 %363, %361
  %372 = and i64 %364, 4294967295
  store i64 %372, i64* %RAX.i2610, align 8
  %373 = and i64 %371, 4294967295
  store i64 %373, i64* %RDX.i4094, align 8
  store i8 0, i8* %12, align 1
  store i8 0, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %374 = trunc i64 %364 to i32
  br label %routine_idivl__ecx.exit3948

routine_idivl__ecx.exit3948:                      ; preds = %370, %368
  %375 = phi i64 [ %.pre161, %368 ], [ %360, %370 ]
  %376 = phi i32 [ %.pre160, %368 ], [ %374, %370 ]
  %377 = phi %struct.Memory* [ %369, %368 ], [ %140, %370 ]
  %378 = load i64, i64* %RBP.i, align 8
  %379 = add i64 %378, -60
  %380 = add i64 %375, 3
  store i64 %380, i64* %3, align 8
  %381 = inttoptr i64 %379 to i32*
  store i32 %376, i32* %381, align 4
  %382 = load i64, i64* %3, align 8
  %383 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %383, i64* %RSI.i3950, align 8
  %384 = add i64 %383, 40
  %385 = add i64 %382, 11
  store i64 %385, i64* %3, align 8
  %386 = inttoptr i64 %384 to i32*
  %387 = load i32, i32* %386, align 4
  %388 = zext i32 %387 to i64
  store i64 %388, i64* %RAX.i2610, align 8
  store i64 %383, i64* %RSI.i3950, align 8
  %389 = add i64 %383, 72668
  %390 = add i64 %382, 25
  store i64 %390, i64* %3, align 8
  %391 = inttoptr i64 %389 to i32*
  %392 = load i32, i32* %391, align 4
  %393 = add i32 %392, %387
  %394 = zext i32 %393 to i64
  %395 = and i32 %393, 255
  %396 = tail call i32 @llvm.ctpop.i32(i32 %395)
  %397 = trunc i32 %396 to i8
  %398 = and i8 %397, 1
  %399 = xor i8 %398, 1
  %400 = icmp eq i32 %393, 0
  %401 = zext i1 %400 to i8
  %402 = lshr i32 %393, 31
  %403 = trunc i32 %402 to i8
  store i64 %394, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 %399, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 %401, i8* %15, align 1
  store i8 %403, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %404 = sext i32 %393 to i64
  %405 = lshr i64 %404, 32
  store i64 %405, i64* %68, align 8
  %406 = load i32, i32* %ECX.i3947, align 4
  %407 = add i64 %382, 31
  store i64 %407, i64* %3, align 8
  %408 = zext i32 %393 to i64
  %409 = sext i32 %406 to i64
  %410 = shl nuw i64 %405, 32
  %411 = or i64 %410, %408
  %412 = sdiv i64 %411, %409
  %413 = shl i64 %412, 32
  %414 = ashr exact i64 %413, 32
  %415 = icmp eq i64 %412, %414
  br i1 %415, label %418, label %416

; <label>:416:                                    ; preds = %routine_idivl__ecx.exit3948
  %417 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %407, %struct.Memory* %377)
  %.pre162 = load i32, i32* %EDX.i4064, align 4
  %.pre163 = load i64, i64* %3, align 8
  br label %routine_idivl__ecx.exit

; <label>:418:                                    ; preds = %routine_idivl__ecx.exit3948
  %419 = srem i64 %411, %409
  %420 = and i64 %412, 4294967295
  store i64 %420, i64* %RAX.i2610, align 8
  %421 = and i64 %419, 4294967295
  store i64 %421, i64* %RDX.i4094, align 8
  store i8 0, i8* %12, align 1
  store i8 0, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %422 = trunc i64 %419 to i32
  br label %routine_idivl__ecx.exit

routine_idivl__ecx.exit:                          ; preds = %418, %416
  %423 = phi i64 [ %.pre163, %416 ], [ %407, %418 ]
  %424 = phi i32 [ %.pre162, %416 ], [ %422, %418 ]
  %425 = phi %struct.Memory* [ %417, %416 ], [ %377, %418 ]
  %426 = load i64, i64* %RBP.i, align 8
  %427 = add i64 %426, -64
  %428 = add i64 %423, 3
  store i64 %428, i64* %3, align 8
  %429 = inttoptr i64 %427 to i32*
  store i32 %424, i32* %429, align 4
  %430 = load i64, i64* %RBP.i, align 8
  %431 = add i64 %430, -60
  %432 = load i64, i64* %3, align 8
  %433 = add i64 %432, 3
  store i64 %433, i64* %3, align 8
  %434 = inttoptr i64 %431 to i32*
  %435 = load i32, i32* %434, align 4
  %436 = add i32 %435, 16
  %437 = zext i32 %436 to i64
  store i64 %437, i64* %RCX.i3977, align 8
  %438 = icmp ugt i32 %435, -17
  %439 = zext i1 %438 to i8
  store i8 %439, i8* %12, align 1
  %440 = and i32 %436, 255
  %441 = tail call i32 @llvm.ctpop.i32(i32 %440)
  %442 = trunc i32 %441 to i8
  %443 = and i8 %442, 1
  %444 = xor i8 %443, 1
  store i8 %444, i8* %13, align 1
  %445 = xor i32 %435, 16
  %446 = xor i32 %445, %436
  %447 = lshr i32 %446, 4
  %448 = trunc i32 %447 to i8
  %449 = and i8 %448, 1
  store i8 %449, i8* %14, align 1
  %450 = icmp eq i32 %436, 0
  %451 = zext i1 %450 to i8
  store i8 %451, i8* %15, align 1
  %452 = lshr i32 %436, 31
  %453 = trunc i32 %452 to i8
  store i8 %453, i8* %16, align 1
  %454 = lshr i32 %435, 31
  %455 = xor i32 %452, %454
  %456 = add nuw nsw i32 %455, %452
  %457 = icmp eq i32 %456, 2
  %458 = zext i1 %457 to i8
  store i8 %458, i8* %17, align 1
  %459 = add i64 %430, -68
  %460 = add i64 %432, 9
  store i64 %460, i64* %3, align 8
  %461 = inttoptr i64 %459 to i32*
  store i32 %436, i32* %461, align 4
  %462 = load i64, i64* %RBP.i, align 8
  %463 = add i64 %462, -60
  %464 = load i64, i64* %3, align 8
  %465 = add i64 %464, 4
  store i64 %465, i64* %3, align 8
  %466 = inttoptr i64 %463 to i32*
  %467 = load i32, i32* %466, align 4
  %468 = add i32 %467, -6
  %469 = icmp ult i32 %467, 6
  %470 = zext i1 %469 to i8
  store i8 %470, i8* %12, align 1
  %471 = and i32 %468, 255
  %472 = tail call i32 @llvm.ctpop.i32(i32 %471)
  %473 = trunc i32 %472 to i8
  %474 = and i8 %473, 1
  %475 = xor i8 %474, 1
  store i8 %475, i8* %13, align 1
  %476 = xor i32 %468, %467
  %477 = lshr i32 %476, 4
  %478 = trunc i32 %477 to i8
  %479 = and i8 %478, 1
  store i8 %479, i8* %14, align 1
  %480 = icmp eq i32 %468, 0
  %481 = zext i1 %480 to i8
  store i8 %481, i8* %15, align 1
  %482 = lshr i32 %468, 31
  %483 = trunc i32 %482 to i8
  store i8 %483, i8* %16, align 1
  %484 = lshr i32 %467, 31
  %485 = xor i32 %482, %484
  %486 = add nuw nsw i32 %485, %484
  %487 = icmp eq i32 %486, 2
  %488 = zext i1 %487 to i8
  store i8 %488, i8* %17, align 1
  %489 = icmp ne i8 %483, 0
  %490 = xor i1 %489, %487
  %.v208 = select i1 %490, i64 10, i64 44
  %491 = add i64 %464, %.v208
  store i64 %491, i64* %3, align 8
  br i1 %490, label %block_4aa8b9, label %block_.L_4aa8db

block_4aa8b9:                                     ; preds = %routine_idivl__ecx.exit
  store i64 1, i64* %RAX.i2610, align 8
  store i64 5, i64* %RCX.i3977, align 8
  store i64 6, i64* %RDX.i4094, align 8
  %492 = add i64 %491, 18
  store i64 %492, i64* %3, align 8
  %493 = load i32, i32* %466, align 4
  %494 = sub i32 6, %493
  %495 = zext i32 %494 to i64
  store i64 %495, i64* %RDX.i4094, align 8
  %496 = icmp ugt i32 %493, 6
  %497 = zext i1 %496 to i8
  store i8 %497, i8* %12, align 1
  %498 = and i32 %494, 255
  %499 = tail call i32 @llvm.ctpop.i32(i32 %498)
  %500 = trunc i32 %499 to i8
  %501 = and i8 %500, 1
  %502 = xor i8 %501, 1
  store i8 %502, i8* %13, align 1
  %503 = xor i32 %494, %493
  %504 = lshr i32 %503, 4
  %505 = trunc i32 %504 to i8
  %506 = and i8 %505, 1
  store i8 %506, i8* %14, align 1
  %507 = icmp eq i32 %494, 0
  %508 = zext i1 %507 to i8
  store i8 %508, i8* %15, align 1
  %509 = lshr i32 %494, 31
  %510 = trunc i32 %509 to i8
  store i8 %510, i8* %16, align 1
  %511 = lshr i32 %493, 31
  %512 = add nuw nsw i32 %509, %511
  %513 = icmp eq i32 %512, 2
  %514 = zext i1 %513 to i8
  store i8 %514, i8* %17, align 1
  %515 = add i64 %462, -76
  %516 = add i64 %491, 21
  store i64 %516, i64* %3, align 8
  %517 = inttoptr i64 %515 to i32*
  store i32 %494, i32* %517, align 4
  %518 = load i64, i64* %RCX.i3977, align 8
  %519 = load i64, i64* %RBP.i, align 8
  %520 = add i64 %519, -60
  %521 = load i64, i64* %3, align 8
  %522 = add i64 %521, 3
  store i64 %522, i64* %3, align 8
  %523 = trunc i64 %518 to i32
  %524 = inttoptr i64 %520 to i32*
  %525 = load i32, i32* %524, align 4
  %526 = sub i32 %523, %525
  %527 = zext i32 %526 to i64
  store i64 %527, i64* %RCX.i3977, align 8
  %528 = icmp ult i32 %523, %525
  %529 = zext i1 %528 to i8
  store i8 %529, i8* %12, align 1
  %530 = and i32 %526, 255
  %531 = tail call i32 @llvm.ctpop.i32(i32 %530)
  %532 = trunc i32 %531 to i8
  %533 = and i8 %532, 1
  %534 = xor i8 %533, 1
  store i8 %534, i8* %13, align 1
  %535 = xor i32 %525, %523
  %536 = xor i32 %535, %526
  %537 = lshr i32 %536, 4
  %538 = trunc i32 %537 to i8
  %539 = and i8 %538, 1
  store i8 %539, i8* %14, align 1
  %540 = icmp eq i32 %526, 0
  %541 = zext i1 %540 to i8
  store i8 %541, i8* %15, align 1
  %542 = lshr i32 %526, 31
  %543 = trunc i32 %542 to i8
  store i8 %543, i8* %16, align 1
  %544 = lshr i32 %523, 31
  %545 = lshr i32 %525, 31
  %546 = xor i32 %545, %544
  %547 = xor i32 %542, %544
  %548 = add nuw nsw i32 %547, %546
  %549 = icmp eq i32 %548, 2
  %550 = zext i1 %549 to i8
  store i8 %550, i8* %17, align 1
  %551 = load i64, i64* %RAX.i2610, align 8
  %552 = add i64 %521, 5
  store i64 %552, i64* %3, align 8
  %553 = trunc i32 %526 to i5
  %554 = trunc i64 %551 to i32
  switch i5 %553, label %560 [
    i5 0, label %routine_shll__cl___eax.exit
    i5 1, label %555
  ]

; <label>:555:                                    ; preds = %block_4aa8b9
  %556 = shl i32 %554, 1
  %557 = icmp slt i32 %554, 0
  %558 = icmp slt i32 %556, 0
  %559 = xor i1 %557, %558
  br label %570

; <label>:560:                                    ; preds = %block_4aa8b9
  %561 = and i32 %526, 31
  %562 = zext i32 %561 to i64
  %563 = add nuw nsw i64 %562, 4294967295
  %564 = and i64 %551, 4294967295
  %565 = and i64 %563, 4294967295
  %566 = shl i64 %564, %565
  %567 = trunc i64 %566 to i32
  %568 = icmp slt i32 %567, 0
  %569 = shl i32 %567, 1
  br label %570

; <label>:570:                                    ; preds = %560, %555
  %571 = phi i1 [ %557, %555 ], [ %568, %560 ]
  %572 = phi i1 [ %559, %555 ], [ false, %560 ]
  %573 = phi i32 [ %556, %555 ], [ %569, %560 ]
  %574 = zext i32 %573 to i64
  store i64 %574, i64* %RAX.i2610, align 8
  %575 = zext i1 %571 to i8
  store i8 %575, i8* %12, align 1
  %576 = and i32 %573, 254
  %577 = tail call i32 @llvm.ctpop.i32(i32 %576)
  %578 = trunc i32 %577 to i8
  %579 = and i8 %578, 1
  %580 = xor i8 %579, 1
  store i8 %580, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %581 = icmp eq i32 %573, 0
  %582 = zext i1 %581 to i8
  store i8 %582, i8* %15, align 1
  %583 = lshr i32 %573, 31
  %584 = trunc i32 %583 to i8
  store i8 %584, i8* %16, align 1
  %585 = zext i1 %572 to i8
  store i8 %585, i8* %17, align 1
  br label %routine_shll__cl___eax.exit

routine_shll__cl___eax.exit:                      ; preds = %570, %block_4aa8b9
  %586 = phi i32 [ %573, %570 ], [ %554, %block_4aa8b9 ]
  %587 = add i64 %519, -80
  %588 = add i64 %521, 8
  store i64 %588, i64* %3, align 8
  %589 = inttoptr i64 %587 to i32*
  store i32 %586, i32* %589, align 4
  %590 = load i64, i64* %3, align 8
  %591 = add i64 %590, 14
  store i64 %591, i64* %3, align 8
  br label %block_.L_4aa8e4

block_.L_4aa8db:                                  ; preds = %routine_idivl__ecx.exit
  %592 = add i64 %491, 3
  store i64 %592, i64* %3, align 8
  %593 = load i32, i32* %466, align 4
  %594 = add i32 %593, -6
  %595 = zext i32 %594 to i64
  store i64 %595, i64* %RAX.i2610, align 8
  %596 = icmp ult i32 %593, 6
  %597 = zext i1 %596 to i8
  store i8 %597, i8* %12, align 1
  %598 = and i32 %594, 255
  %599 = tail call i32 @llvm.ctpop.i32(i32 %598)
  %600 = trunc i32 %599 to i8
  %601 = and i8 %600, 1
  %602 = xor i8 %601, 1
  store i8 %602, i8* %13, align 1
  %603 = xor i32 %594, %593
  %604 = lshr i32 %603, 4
  %605 = trunc i32 %604 to i8
  %606 = and i8 %605, 1
  store i8 %606, i8* %14, align 1
  %607 = icmp eq i32 %594, 0
  %608 = zext i1 %607 to i8
  store i8 %608, i8* %15, align 1
  %609 = lshr i32 %594, 31
  %610 = trunc i32 %609 to i8
  store i8 %610, i8* %16, align 1
  %611 = lshr i32 %593, 31
  %612 = xor i32 %609, %611
  %613 = add nuw nsw i32 %612, %611
  %614 = icmp eq i32 %613, 2
  %615 = zext i1 %614 to i8
  store i8 %615, i8* %17, align 1
  %616 = add i64 %462, -72
  %617 = add i64 %491, 9
  store i64 %617, i64* %3, align 8
  %618 = inttoptr i64 %616 to i32*
  store i32 %594, i32* %618, align 4
  %.pre164 = load i64, i64* %3, align 8
  br label %block_.L_4aa8e4

block_.L_4aa8e4:                                  ; preds = %block_.L_4aa8db, %routine_shll__cl___eax.exit
  %619 = phi i64 [ %.pre164, %block_.L_4aa8db ], [ %591, %routine_shll__cl___eax.exit ]
  %620 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %620, i64* %RAX.i2610, align 8
  %621 = add i64 %620, 24
  %622 = add i64 %619, 12
  store i64 %622, i64* %3, align 8
  %623 = inttoptr i64 %621 to i32*
  %624 = load i32, i32* %623, align 4
  %625 = add i32 %624, -2
  %626 = icmp ult i32 %624, 2
  %627 = zext i1 %626 to i8
  store i8 %627, i8* %12, align 1
  %628 = and i32 %625, 255
  %629 = tail call i32 @llvm.ctpop.i32(i32 %628)
  %630 = trunc i32 %629 to i8
  %631 = and i8 %630, 1
  %632 = xor i8 %631, 1
  store i8 %632, i8* %13, align 1
  %633 = xor i32 %625, %624
  %634 = lshr i32 %633, 4
  %635 = trunc i32 %634 to i8
  %636 = and i8 %635, 1
  store i8 %636, i8* %14, align 1
  %637 = icmp eq i32 %625, 0
  %638 = zext i1 %637 to i8
  store i8 %638, i8* %15, align 1
  %639 = lshr i32 %625, 31
  %640 = trunc i32 %639 to i8
  store i8 %640, i8* %16, align 1
  %641 = lshr i32 %624, 31
  %642 = xor i32 %639, %641
  %643 = add nuw nsw i32 %642, %641
  %644 = icmp eq i32 %643, 2
  %645 = zext i1 %644 to i8
  store i8 %645, i8* %17, align 1
  %.v209 = select i1 %637, i64 18, i64 72
  %646 = add i64 %619, %.v209
  %647 = add i64 %646, 5
  store i64 %647, i64* %3, align 8
  br i1 %637, label %block_4aa8f6, label %block_.L_4aa92c

block_4aa8f6:                                     ; preds = %block_.L_4aa8e4
  store i64 3, i64* %RAX.i2610, align 8
  store i64 1, i64* %RCX.i3977, align 8
  %648 = load i64, i64* %RBP.i, align 8
  %649 = add i64 %648, -68
  %650 = add i64 %646, 13
  store i64 %650, i64* %3, align 8
  %651 = inttoptr i64 %649 to i32*
  %652 = load i32, i32* %651, align 4
  %653 = zext i32 %652 to i64
  store i64 %653, i64* %RDX.i4094, align 8
  %654 = add i64 %648, -684
  %655 = add i64 %646, 19
  store i64 %655, i64* %3, align 8
  %656 = inttoptr i64 %654 to i32*
  store i32 1, i32* %656, align 4
  %657 = load i32, i32* %EDX.i4064, align 4
  %658 = zext i32 %657 to i64
  %659 = load i64, i64* %3, align 8
  store i64 %658, i64* %RCX.i3977, align 8
  %660 = load i64, i64* %RBP.i, align 8
  %661 = add i64 %660, -684
  %662 = add i64 %659, 8
  store i64 %662, i64* %3, align 8
  %663 = inttoptr i64 %661 to i32*
  %664 = load i32, i32* %663, align 4
  %665 = zext i32 %664 to i64
  store i64 %665, i64* %RDX.i4094, align 8
  %666 = add i64 %659, 10
  store i64 %666, i64* %3, align 8
  %667 = trunc i32 %657 to i5
  switch i5 %667, label %673 [
    i5 0, label %routine_shll__cl___edx.exit3859
    i5 1, label %668
  ]

; <label>:668:                                    ; preds = %block_4aa8f6
  %669 = shl i32 %664, 1
  %670 = icmp slt i32 %664, 0
  %671 = icmp slt i32 %669, 0
  %672 = xor i1 %670, %671
  br label %682

; <label>:673:                                    ; preds = %block_4aa8f6
  %674 = and i32 %657, 31
  %675 = zext i32 %674 to i64
  %676 = add nuw nsw i64 %675, 4294967295
  %677 = and i64 %676, 4294967295
  %678 = shl i64 %665, %677
  %679 = trunc i64 %678 to i32
  %680 = icmp slt i32 %679, 0
  %681 = shl i32 %679, 1
  br label %682

; <label>:682:                                    ; preds = %673, %668
  %683 = phi i1 [ %670, %668 ], [ %680, %673 ]
  %684 = phi i1 [ %672, %668 ], [ false, %673 ]
  %685 = phi i32 [ %669, %668 ], [ %681, %673 ]
  %686 = zext i32 %685 to i64
  store i64 %686, i64* %RDX.i4094, align 8
  %687 = zext i1 %683 to i8
  store i8 %687, i8* %12, align 1
  %688 = and i32 %685, 254
  %689 = tail call i32 @llvm.ctpop.i32(i32 %688)
  %690 = trunc i32 %689 to i8
  %691 = and i8 %690, 1
  %692 = xor i8 %691, 1
  store i8 %692, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %693 = icmp eq i32 %685, 0
  %694 = zext i1 %693 to i8
  store i8 %694, i8* %15, align 1
  %695 = lshr i32 %685, 31
  %696 = trunc i32 %695 to i8
  store i8 %696, i8* %16, align 1
  %697 = zext i1 %684 to i8
  store i8 %697, i8* %17, align 1
  br label %routine_shll__cl___edx.exit3859

routine_shll__cl___edx.exit3859:                  ; preds = %682, %block_4aa8f6
  %698 = add i64 %660, -688
  %699 = load i32, i32* %EAX.i2609, align 4
  %700 = add i64 %659, 16
  store i64 %700, i64* %3, align 8
  %701 = inttoptr i64 %698 to i32*
  store i32 %699, i32* %701, align 4
  %702 = load i32, i32* %EDX.i4064, align 4
  %703 = zext i32 %702 to i64
  %704 = load i64, i64* %3, align 8
  store i64 %703, i64* %RAX.i2610, align 8
  %705 = sext i32 %702 to i64
  %706 = lshr i64 %705, 32
  store i64 %706, i64* %68, align 8
  %707 = load i64, i64* %RBP.i, align 8
  %708 = add i64 %707, -688
  %709 = add i64 %704, 9
  store i64 %709, i64* %3, align 8
  %710 = inttoptr i64 %708 to i32*
  %711 = load i32, i32* %710, align 4
  %712 = zext i32 %711 to i64
  store i64 %712, i64* %RSI.i3950, align 8
  %713 = add i64 %704, 11
  store i64 %713, i64* %3, align 8
  %714 = sext i32 %711 to i64
  %715 = shl nuw i64 %706, 32
  %716 = or i64 %715, %703
  %717 = sdiv i64 %716, %714
  %718 = shl i64 %717, 32
  %719 = ashr exact i64 %718, 32
  %720 = icmp eq i64 %717, %719
  br i1 %720, label %723, label %721

; <label>:721:                                    ; preds = %routine_shll__cl___edx.exit3859
  %722 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %713, %struct.Memory* %425)
  %.pre165 = load i64, i64* %RBP.i, align 8
  %.pre166 = load i32, i32* %EAX.i2609, align 4
  %.pre167 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit3843

; <label>:723:                                    ; preds = %routine_shll__cl___edx.exit3859
  %724 = srem i64 %716, %714
  %725 = and i64 %717, 4294967295
  store i64 %725, i64* %RAX.i2610, align 8
  %726 = and i64 %724, 4294967295
  store i64 %726, i64* %RDX.i4094, align 8
  store i8 0, i8* %12, align 1
  store i8 0, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %727 = trunc i64 %717 to i32
  br label %routine_idivl__esi.exit3843

routine_idivl__esi.exit3843:                      ; preds = %723, %721
  %728 = phi i64 [ %.pre167, %721 ], [ %713, %723 ]
  %729 = phi i32 [ %.pre166, %721 ], [ %727, %723 ]
  %730 = phi i64 [ %.pre165, %721 ], [ %707, %723 ]
  %731 = phi %struct.Memory* [ %722, %721 ], [ %425, %723 ]
  %732 = add i64 %730, -40
  %733 = add i64 %728, 3
  store i64 %733, i64* %3, align 8
  %734 = inttoptr i64 %732 to i32*
  store i32 %729, i32* %734, align 4
  %735 = load i64, i64* %3, align 8
  %736 = add i64 %735, 54
  store i64 %736, i64* %3, align 8
  br label %block_.L_4aa95d

block_.L_4aa92c:                                  ; preds = %block_.L_4aa8e4
  store i64 6, i64* %RAX.i2610, align 8
  store i64 1, i64* %RCX.i3977, align 8
  %737 = load i64, i64* %RBP.i, align 8
  %738 = add i64 %737, -68
  %739 = add i64 %646, 13
  store i64 %739, i64* %3, align 8
  %740 = inttoptr i64 %738 to i32*
  %741 = load i32, i32* %740, align 4
  %742 = zext i32 %741 to i64
  store i64 %742, i64* %RDX.i4094, align 8
  %743 = add i64 %737, -692
  %744 = add i64 %646, 19
  store i64 %744, i64* %3, align 8
  %745 = inttoptr i64 %743 to i32*
  store i32 1, i32* %745, align 4
  %746 = load i32, i32* %EDX.i4064, align 4
  %747 = zext i32 %746 to i64
  %748 = load i64, i64* %3, align 8
  store i64 %747, i64* %RCX.i3977, align 8
  %749 = load i64, i64* %RBP.i, align 8
  %750 = add i64 %749, -692
  %751 = add i64 %748, 8
  store i64 %751, i64* %3, align 8
  %752 = inttoptr i64 %750 to i32*
  %753 = load i32, i32* %752, align 4
  %754 = zext i32 %753 to i64
  store i64 %754, i64* %RDX.i4094, align 8
  %755 = add i64 %748, 10
  store i64 %755, i64* %3, align 8
  %756 = trunc i32 %746 to i5
  switch i5 %756, label %762 [
    i5 0, label %routine_shll__cl___edx.exit
    i5 1, label %757
  ]

; <label>:757:                                    ; preds = %block_.L_4aa92c
  %758 = shl i32 %753, 1
  %759 = icmp slt i32 %753, 0
  %760 = icmp slt i32 %758, 0
  %761 = xor i1 %759, %760
  br label %771

; <label>:762:                                    ; preds = %block_.L_4aa92c
  %763 = and i32 %746, 31
  %764 = zext i32 %763 to i64
  %765 = add nuw nsw i64 %764, 4294967295
  %766 = and i64 %765, 4294967295
  %767 = shl i64 %754, %766
  %768 = trunc i64 %767 to i32
  %769 = icmp slt i32 %768, 0
  %770 = shl i32 %768, 1
  br label %771

; <label>:771:                                    ; preds = %762, %757
  %772 = phi i1 [ %759, %757 ], [ %769, %762 ]
  %773 = phi i1 [ %761, %757 ], [ false, %762 ]
  %774 = phi i32 [ %758, %757 ], [ %770, %762 ]
  %775 = zext i32 %774 to i64
  store i64 %775, i64* %RDX.i4094, align 8
  %776 = zext i1 %772 to i8
  store i8 %776, i8* %12, align 1
  %777 = and i32 %774, 254
  %778 = tail call i32 @llvm.ctpop.i32(i32 %777)
  %779 = trunc i32 %778 to i8
  %780 = and i8 %779, 1
  %781 = xor i8 %780, 1
  store i8 %781, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %782 = icmp eq i32 %774, 0
  %783 = zext i1 %782 to i8
  store i8 %783, i8* %15, align 1
  %784 = lshr i32 %774, 31
  %785 = trunc i32 %784 to i8
  store i8 %785, i8* %16, align 1
  %786 = zext i1 %773 to i8
  store i8 %786, i8* %17, align 1
  br label %routine_shll__cl___edx.exit

routine_shll__cl___edx.exit:                      ; preds = %771, %block_.L_4aa92c
  %787 = add i64 %749, -696
  %788 = load i32, i32* %EAX.i2609, align 4
  %789 = add i64 %748, 16
  store i64 %789, i64* %3, align 8
  %790 = inttoptr i64 %787 to i32*
  store i32 %788, i32* %790, align 4
  %791 = load i32, i32* %EDX.i4064, align 4
  %792 = zext i32 %791 to i64
  %793 = load i64, i64* %3, align 8
  store i64 %792, i64* %RAX.i2610, align 8
  %794 = sext i32 %791 to i64
  %795 = lshr i64 %794, 32
  store i64 %795, i64* %68, align 8
  %796 = load i64, i64* %RBP.i, align 8
  %797 = add i64 %796, -696
  %798 = add i64 %793, 9
  store i64 %798, i64* %3, align 8
  %799 = inttoptr i64 %797 to i32*
  %800 = load i32, i32* %799, align 4
  %801 = zext i32 %800 to i64
  store i64 %801, i64* %RSI.i3950, align 8
  %802 = add i64 %793, 11
  store i64 %802, i64* %3, align 8
  %803 = sext i32 %800 to i64
  %804 = shl nuw i64 %795, 32
  %805 = or i64 %804, %792
  %806 = sdiv i64 %805, %803
  %807 = shl i64 %806, 32
  %808 = ashr exact i64 %807, 32
  %809 = icmp eq i64 %806, %808
  br i1 %809, label %812, label %810

; <label>:810:                                    ; preds = %routine_shll__cl___edx.exit
  %811 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %802, %struct.Memory* %425)
  %.pre168 = load i64, i64* %RBP.i, align 8
  %.pre169 = load i32, i32* %EAX.i2609, align 4
  %.pre170 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit

; <label>:812:                                    ; preds = %routine_shll__cl___edx.exit
  %813 = srem i64 %805, %803
  %814 = and i64 %806, 4294967295
  store i64 %814, i64* %RAX.i2610, align 8
  %815 = and i64 %813, 4294967295
  store i64 %815, i64* %RDX.i4094, align 8
  store i8 0, i8* %12, align 1
  store i8 0, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %816 = trunc i64 %806 to i32
  br label %routine_idivl__esi.exit

routine_idivl__esi.exit:                          ; preds = %812, %810
  %817 = phi i64 [ %.pre170, %810 ], [ %802, %812 ]
  %818 = phi i32 [ %.pre169, %810 ], [ %816, %812 ]
  %819 = phi i64 [ %.pre168, %810 ], [ %796, %812 ]
  %820 = phi %struct.Memory* [ %811, %810 ], [ %425, %812 ]
  %821 = add i64 %819, -40
  %822 = add i64 %817, 3
  store i64 %822, i64* %3, align 8
  %823 = inttoptr i64 %821 to i32*
  store i32 %818, i32* %823, align 4
  %.pre171 = load i64, i64* %3, align 8
  br label %block_.L_4aa95d

block_.L_4aa95d:                                  ; preds = %routine_idivl__esi.exit, %routine_idivl__esi.exit3843
  %824 = phi i64 [ %.pre171, %routine_idivl__esi.exit ], [ %736, %routine_idivl__esi.exit3843 ]
  %MEMORY.2 = phi %struct.Memory* [ %820, %routine_idivl__esi.exit ], [ %731, %routine_idivl__esi.exit3843 ]
  %ESI.i3747.pre-phi = bitcast %union.anon* %25 to i32*
  %825 = load i64, i64* %RBP.i, align 8
  %826 = add i64 %825, -24
  %827 = add i64 %824, 7
  store i64 %827, i64* %3, align 8
  %828 = inttoptr i64 %826 to i32*
  store i32 0, i32* %828, align 4
  %.pre172 = load i64, i64* %3, align 8
  br label %block_.L_4aa964

block_.L_4aa964:                                  ; preds = %block_.L_4aa99d, %block_.L_4aa95d
  %829 = phi i64 [ %2362, %block_.L_4aa99d ], [ %.pre172, %block_.L_4aa95d ]
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %CL.i3807, align 1
  %830 = load i64, i64* %RBP.i, align 8
  %831 = add i64 %830, -24
  %832 = add i64 %829, 8
  store i64 %832, i64* %3, align 8
  %833 = inttoptr i64 %831 to i32*
  %834 = load i32, i32* %833, align 4
  %835 = add i32 %834, -8
  %836 = icmp ult i32 %834, 8
  %837 = zext i1 %836 to i8
  store i8 %837, i8* %12, align 1
  %838 = and i32 %835, 255
  %839 = tail call i32 @llvm.ctpop.i32(i32 %838)
  %840 = trunc i32 %839 to i8
  %841 = and i8 %840, 1
  %842 = xor i8 %841, 1
  store i8 %842, i8* %13, align 1
  %843 = xor i32 %835, %834
  %844 = lshr i32 %843, 4
  %845 = trunc i32 %844 to i8
  %846 = and i8 %845, 1
  store i8 %846, i8* %14, align 1
  %847 = icmp eq i32 %835, 0
  %848 = zext i1 %847 to i8
  store i8 %848, i8* %15, align 1
  %849 = lshr i32 %835, 31
  %850 = trunc i32 %849 to i8
  store i8 %850, i8* %16, align 1
  %851 = lshr i32 %834, 31
  %852 = xor i32 %849, %851
  %853 = add nuw nsw i32 %852, %851
  %854 = icmp eq i32 %853, 2
  %855 = zext i1 %854 to i8
  store i8 %855, i8* %17, align 1
  %856 = add i64 %830, -697
  %857 = add i64 %829, 14
  store i64 %857, i64* %3, align 8
  %858 = inttoptr i64 %856 to i8*
  store i8 0, i8* %858, align 1
  %859 = load i64, i64* %3, align 8
  %860 = add i64 %859, 24
  %861 = add i64 %859, 6
  %862 = load i8, i8* %16, align 1
  %863 = icmp ne i8 %862, 0
  %864 = load i8, i8* %17, align 1
  %865 = icmp ne i8 %864, 0
  %866 = xor i1 %863, %865
  %867 = select i1 %866, i64 %861, i64 %860
  store i64 %867, i64* %3, align 8
  br i1 %866, label %block_4aa978, label %block_.L_4aa98a

block_4aa978:                                     ; preds = %block_.L_4aa964
  %868 = load i64, i64* %RBP.i, align 8
  %869 = add i64 %868, -412
  %870 = add i64 %867, 7
  store i64 %870, i64* %3, align 8
  %871 = inttoptr i64 %869 to i32*
  %872 = load i32, i32* %871, align 4
  %873 = icmp ne i32 %872, 0
  %874 = zext i1 %873 to i64
  %875 = xor i64 %874, 255
  %876 = trunc i64 %875 to i8
  store i8 %876, i8* %AL.i3806, align 1
  store i8 0, i8* %12, align 1
  %877 = trunc i64 %875 to i32
  %878 = tail call i32 @llvm.ctpop.i32(i32 %877)
  %879 = trunc i32 %878 to i8
  %880 = and i8 %879, 1
  %881 = xor i8 %880, 1
  store i8 %881, i8* %13, align 1
  store i8 0, i8* %15, align 1
  store i8 1, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %882 = add i64 %868, -697
  %883 = add i64 %867, 18
  store i64 %883, i64* %3, align 8
  %884 = inttoptr i64 %882 to i8*
  store i8 %876, i8* %884, align 1
  %.pre173 = load i64, i64* %3, align 8
  br label %block_.L_4aa98a

block_.L_4aa98a:                                  ; preds = %block_.L_4aa964, %block_4aa978
  %885 = phi i64 [ %860, %block_.L_4aa964 ], [ %.pre173, %block_4aa978 ]
  %886 = load i64, i64* %RBP.i, align 8
  %887 = add i64 %886, -697
  %888 = add i64 %885, 6
  store i64 %888, i64* %3, align 8
  %889 = inttoptr i64 %887 to i8*
  %890 = load i8, i8* %889, align 1
  store i8 %890, i8* %AL.i3806, align 1
  %891 = and i8 %890, 1
  store i8 0, i8* %12, align 1
  %892 = zext i8 %891 to i32
  %893 = tail call i32 @llvm.ctpop.i32(i32 %892)
  %894 = trunc i32 %893 to i8
  %895 = xor i8 %894, 1
  store i8 %895, i8* %13, align 1
  %896 = xor i8 %891, 1
  store i8 %896, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %897 = icmp eq i8 %896, 0
  %.v = select i1 %897, i64 19, i64 14
  %898 = add i64 %885, %.v
  store i64 %898, i64* %3, align 8
  br i1 %897, label %block_.L_4aa99d, label %block_4aa998

block_4aa998:                                     ; preds = %block_.L_4aa98a
  %899 = add i64 %886, -24
  %900 = add i64 %898, 804
  store i64 %900, i64* %3, align 8
  %901 = inttoptr i64 %899 to i32*
  store i32 0, i32* %901, align 4
  %.pre174 = load i64, i64* %3, align 8
  br label %block_.L_4aacbc

block_.L_4aa99d:                                  ; preds = %block_.L_4aa98a
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %902 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %902, i64* %RCX.i3977, align 8
  %903 = add i64 %886, -24
  %904 = add i64 %898, 14
  store i64 %904, i64* %3, align 8
  %905 = inttoptr i64 %903 to i32*
  %906 = load i32, i32* %905, align 4
  %907 = sext i32 %906 to i64
  store i64 %907, i64* %RDX.i4094, align 8
  %908 = shl nsw i64 %907, 2
  %909 = add i64 %902, 13112
  %910 = add i64 %909, %908
  %911 = add i64 %898, 21
  store i64 %911, i64* %3, align 8
  %912 = inttoptr i64 %910 to i32*
  %913 = load i32, i32* %912, align 4
  %914 = zext i32 %913 to i64
  store i64 %914, i64* %RSI.i3950, align 8
  store i64 %902, i64* %RCX.i3977, align 8
  %915 = add i64 %898, 33
  store i64 %915, i64* %3, align 8
  %916 = load i32, i32* %905, align 4
  %917 = sext i32 %916 to i64
  store i64 %917, i64* %RDX.i4094, align 8
  %918 = shl nsw i64 %917, 2
  %919 = add nsw i64 %918, 13560
  %920 = add i64 %919, %902
  %921 = add i64 %898, 40
  store i64 %921, i64* %3, align 8
  %922 = inttoptr i64 %920 to i32*
  %923 = load i32, i32* %922, align 4
  %924 = add i32 %923, %913
  %925 = zext i32 %924 to i64
  store i64 %925, i64* %RSI.i3950, align 8
  %926 = icmp ult i32 %924, %913
  %927 = icmp ult i32 %924, %923
  %928 = or i1 %926, %927
  %929 = zext i1 %928 to i8
  store i8 %929, i8* %12, align 1
  %930 = and i32 %924, 255
  %931 = tail call i32 @llvm.ctpop.i32(i32 %930)
  %932 = trunc i32 %931 to i8
  %933 = and i8 %932, 1
  %934 = xor i8 %933, 1
  store i8 %934, i8* %13, align 1
  %935 = xor i32 %923, %913
  %936 = xor i32 %935, %924
  %937 = lshr i32 %936, 4
  %938 = trunc i32 %937 to i8
  %939 = and i8 %938, 1
  store i8 %939, i8* %14, align 1
  %940 = icmp eq i32 %924, 0
  %941 = zext i1 %940 to i8
  store i8 %941, i8* %15, align 1
  %942 = lshr i32 %924, 31
  %943 = trunc i32 %942 to i8
  store i8 %943, i8* %16, align 1
  %944 = lshr i32 %913, 31
  %945 = lshr i32 %923, 31
  %946 = xor i32 %942, %944
  %947 = xor i32 %942, %945
  %948 = add nuw nsw i32 %946, %947
  %949 = icmp eq i32 %948, 2
  %950 = zext i1 %949 to i8
  store i8 %950, i8* %17, align 1
  %951 = add i64 %886, -448
  %952 = add i64 %898, 46
  store i64 %952, i64* %3, align 8
  %953 = inttoptr i64 %951 to i32*
  store i32 %924, i32* %953, align 4
  %954 = load i64, i64* %3, align 8
  %955 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %955, i64* %RCX.i3977, align 8
  %956 = load i64, i64* %RBP.i, align 8
  %957 = add i64 %956, -24
  %958 = add i64 %954, 12
  store i64 %958, i64* %3, align 8
  %959 = inttoptr i64 %957 to i32*
  %960 = load i32, i32* %959, align 4
  %961 = sext i32 %960 to i64
  store i64 %961, i64* %RDX.i4094, align 8
  %962 = shl nsw i64 %961, 2
  %963 = add i64 %955, 13176
  %964 = add i64 %963, %962
  %965 = add i64 %954, 19
  store i64 %965, i64* %3, align 8
  %966 = inttoptr i64 %964 to i32*
  %967 = load i32, i32* %966, align 4
  %968 = zext i32 %967 to i64
  store i64 %968, i64* %RSI.i3950, align 8
  store i64 %955, i64* %RCX.i3977, align 8
  %969 = add i64 %954, 31
  store i64 %969, i64* %3, align 8
  %970 = load i32, i32* %959, align 4
  %971 = sext i32 %970 to i64
  store i64 %971, i64* %RDX.i4094, align 8
  %972 = shl nsw i64 %971, 2
  %973 = add nsw i64 %972, 13496
  %974 = add i64 %973, %955
  %975 = add i64 %954, 38
  store i64 %975, i64* %3, align 8
  %976 = inttoptr i64 %974 to i32*
  %977 = load i32, i32* %976, align 4
  %978 = add i32 %977, %967
  %979 = zext i32 %978 to i64
  store i64 %979, i64* %RSI.i3950, align 8
  %980 = icmp ult i32 %978, %967
  %981 = icmp ult i32 %978, %977
  %982 = or i1 %980, %981
  %983 = zext i1 %982 to i8
  store i8 %983, i8* %12, align 1
  %984 = and i32 %978, 255
  %985 = tail call i32 @llvm.ctpop.i32(i32 %984)
  %986 = trunc i32 %985 to i8
  %987 = and i8 %986, 1
  %988 = xor i8 %987, 1
  store i8 %988, i8* %13, align 1
  %989 = xor i32 %977, %967
  %990 = xor i32 %989, %978
  %991 = lshr i32 %990, 4
  %992 = trunc i32 %991 to i8
  %993 = and i8 %992, 1
  store i8 %993, i8* %14, align 1
  %994 = icmp eq i32 %978, 0
  %995 = zext i1 %994 to i8
  store i8 %995, i8* %15, align 1
  %996 = lshr i32 %978, 31
  %997 = trunc i32 %996 to i8
  store i8 %997, i8* %16, align 1
  %998 = lshr i32 %967, 31
  %999 = lshr i32 %977, 31
  %1000 = xor i32 %996, %998
  %1001 = xor i32 %996, %999
  %1002 = add nuw nsw i32 %1000, %1001
  %1003 = icmp eq i32 %1002, 2
  %1004 = zext i1 %1003 to i8
  store i8 %1004, i8* %17, align 1
  %1005 = add i64 %956, -444
  %1006 = add i64 %954, 44
  store i64 %1006, i64* %3, align 8
  %1007 = inttoptr i64 %1005 to i32*
  store i32 %978, i32* %1007, align 4
  %1008 = load i64, i64* %3, align 8
  %1009 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1009, i64* %RCX.i3977, align 8
  %1010 = load i64, i64* %RBP.i, align 8
  %1011 = add i64 %1010, -24
  %1012 = add i64 %1008, 12
  store i64 %1012, i64* %3, align 8
  %1013 = inttoptr i64 %1011 to i32*
  %1014 = load i32, i32* %1013, align 4
  %1015 = sext i32 %1014 to i64
  store i64 %1015, i64* %RDX.i4094, align 8
  %1016 = shl nsw i64 %1015, 2
  %1017 = add i64 %1009, 13240
  %1018 = add i64 %1017, %1016
  %1019 = add i64 %1008, 19
  store i64 %1019, i64* %3, align 8
  %1020 = inttoptr i64 %1018 to i32*
  %1021 = load i32, i32* %1020, align 4
  %1022 = zext i32 %1021 to i64
  store i64 %1022, i64* %RSI.i3950, align 8
  store i64 %1009, i64* %RCX.i3977, align 8
  %1023 = add i64 %1008, 31
  store i64 %1023, i64* %3, align 8
  %1024 = load i32, i32* %1013, align 4
  %1025 = sext i32 %1024 to i64
  store i64 %1025, i64* %RDX.i4094, align 8
  %1026 = shl nsw i64 %1025, 2
  %1027 = add nsw i64 %1026, 13432
  %1028 = add i64 %1027, %1009
  %1029 = add i64 %1008, 38
  store i64 %1029, i64* %3, align 8
  %1030 = inttoptr i64 %1028 to i32*
  %1031 = load i32, i32* %1030, align 4
  %1032 = add i32 %1031, %1021
  %1033 = zext i32 %1032 to i64
  store i64 %1033, i64* %RSI.i3950, align 8
  %1034 = icmp ult i32 %1032, %1021
  %1035 = icmp ult i32 %1032, %1031
  %1036 = or i1 %1034, %1035
  %1037 = zext i1 %1036 to i8
  store i8 %1037, i8* %12, align 1
  %1038 = and i32 %1032, 255
  %1039 = tail call i32 @llvm.ctpop.i32(i32 %1038)
  %1040 = trunc i32 %1039 to i8
  %1041 = and i8 %1040, 1
  %1042 = xor i8 %1041, 1
  store i8 %1042, i8* %13, align 1
  %1043 = xor i32 %1031, %1021
  %1044 = xor i32 %1043, %1032
  %1045 = lshr i32 %1044, 4
  %1046 = trunc i32 %1045 to i8
  %1047 = and i8 %1046, 1
  store i8 %1047, i8* %14, align 1
  %1048 = icmp eq i32 %1032, 0
  %1049 = zext i1 %1048 to i8
  store i8 %1049, i8* %15, align 1
  %1050 = lshr i32 %1032, 31
  %1051 = trunc i32 %1050 to i8
  store i8 %1051, i8* %16, align 1
  %1052 = lshr i32 %1021, 31
  %1053 = lshr i32 %1031, 31
  %1054 = xor i32 %1050, %1052
  %1055 = xor i32 %1050, %1053
  %1056 = add nuw nsw i32 %1054, %1055
  %1057 = icmp eq i32 %1056, 2
  %1058 = zext i1 %1057 to i8
  store i8 %1058, i8* %17, align 1
  %1059 = add i64 %1010, -440
  %1060 = add i64 %1008, 44
  store i64 %1060, i64* %3, align 8
  %1061 = inttoptr i64 %1059 to i32*
  store i32 %1032, i32* %1061, align 4
  %1062 = load i64, i64* %3, align 8
  %1063 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1063, i64* %RCX.i3977, align 8
  %1064 = load i64, i64* %RBP.i, align 8
  %1065 = add i64 %1064, -24
  %1066 = add i64 %1062, 12
  store i64 %1066, i64* %3, align 8
  %1067 = inttoptr i64 %1065 to i32*
  %1068 = load i32, i32* %1067, align 4
  %1069 = sext i32 %1068 to i64
  store i64 %1069, i64* %RDX.i4094, align 8
  %1070 = shl nsw i64 %1069, 2
  %1071 = add i64 %1063, 13304
  %1072 = add i64 %1071, %1070
  %1073 = add i64 %1062, 19
  store i64 %1073, i64* %3, align 8
  %1074 = inttoptr i64 %1072 to i32*
  %1075 = load i32, i32* %1074, align 4
  %1076 = zext i32 %1075 to i64
  store i64 %1076, i64* %RSI.i3950, align 8
  store i64 %1063, i64* %RCX.i3977, align 8
  %1077 = add i64 %1062, 31
  store i64 %1077, i64* %3, align 8
  %1078 = load i32, i32* %1067, align 4
  %1079 = sext i32 %1078 to i64
  store i64 %1079, i64* %RDX.i4094, align 8
  %1080 = shl nsw i64 %1079, 2
  %1081 = add nsw i64 %1080, 13368
  %1082 = add i64 %1081, %1063
  %1083 = add i64 %1062, 38
  store i64 %1083, i64* %3, align 8
  %1084 = inttoptr i64 %1082 to i32*
  %1085 = load i32, i32* %1084, align 4
  %1086 = add i32 %1085, %1075
  %1087 = zext i32 %1086 to i64
  store i64 %1087, i64* %RSI.i3950, align 8
  %1088 = icmp ult i32 %1086, %1075
  %1089 = icmp ult i32 %1086, %1085
  %1090 = or i1 %1088, %1089
  %1091 = zext i1 %1090 to i8
  store i8 %1091, i8* %12, align 1
  %1092 = and i32 %1086, 255
  %1093 = tail call i32 @llvm.ctpop.i32(i32 %1092)
  %1094 = trunc i32 %1093 to i8
  %1095 = and i8 %1094, 1
  %1096 = xor i8 %1095, 1
  store i8 %1096, i8* %13, align 1
  %1097 = xor i32 %1085, %1075
  %1098 = xor i32 %1097, %1086
  %1099 = lshr i32 %1098, 4
  %1100 = trunc i32 %1099 to i8
  %1101 = and i8 %1100, 1
  store i8 %1101, i8* %14, align 1
  %1102 = icmp eq i32 %1086, 0
  %1103 = zext i1 %1102 to i8
  store i8 %1103, i8* %15, align 1
  %1104 = lshr i32 %1086, 31
  %1105 = trunc i32 %1104 to i8
  store i8 %1105, i8* %16, align 1
  %1106 = lshr i32 %1075, 31
  %1107 = lshr i32 %1085, 31
  %1108 = xor i32 %1104, %1106
  %1109 = xor i32 %1104, %1107
  %1110 = add nuw nsw i32 %1108, %1109
  %1111 = icmp eq i32 %1110, 2
  %1112 = zext i1 %1111 to i8
  store i8 %1112, i8* %17, align 1
  %1113 = add i64 %1064, -436
  %1114 = add i64 %1062, 44
  store i64 %1114, i64* %3, align 8
  %1115 = inttoptr i64 %1113 to i32*
  store i32 %1086, i32* %1115, align 4
  %1116 = load i64, i64* %RBP.i, align 8
  %1117 = add i64 %1116, -448
  %1118 = load i64, i64* %3, align 8
  %1119 = add i64 %1118, 6
  store i64 %1119, i64* %3, align 8
  %1120 = inttoptr i64 %1117 to i32*
  %1121 = load i32, i32* %1120, align 4
  %1122 = zext i32 %1121 to i64
  store i64 %1122, i64* %RSI.i3950, align 8
  %1123 = add i64 %1116, -436
  %1124 = add i64 %1118, 12
  store i64 %1124, i64* %3, align 8
  %1125 = inttoptr i64 %1123 to i32*
  %1126 = load i32, i32* %1125, align 4
  %1127 = add i32 %1126, %1121
  %1128 = zext i32 %1127 to i64
  store i64 %1128, i64* %RSI.i3950, align 8
  %1129 = icmp ult i32 %1127, %1121
  %1130 = icmp ult i32 %1127, %1126
  %1131 = or i1 %1129, %1130
  %1132 = zext i1 %1131 to i8
  store i8 %1132, i8* %12, align 1
  %1133 = and i32 %1127, 255
  %1134 = tail call i32 @llvm.ctpop.i32(i32 %1133)
  %1135 = trunc i32 %1134 to i8
  %1136 = and i8 %1135, 1
  %1137 = xor i8 %1136, 1
  store i8 %1137, i8* %13, align 1
  %1138 = xor i32 %1126, %1121
  %1139 = xor i32 %1138, %1127
  %1140 = lshr i32 %1139, 4
  %1141 = trunc i32 %1140 to i8
  %1142 = and i8 %1141, 1
  store i8 %1142, i8* %14, align 1
  %1143 = icmp eq i32 %1127, 0
  %1144 = zext i1 %1143 to i8
  store i8 %1144, i8* %15, align 1
  %1145 = lshr i32 %1127, 31
  %1146 = trunc i32 %1145 to i8
  store i8 %1146, i8* %16, align 1
  %1147 = lshr i32 %1121, 31
  %1148 = lshr i32 %1126, 31
  %1149 = xor i32 %1145, %1147
  %1150 = xor i32 %1145, %1148
  %1151 = add nuw nsw i32 %1149, %1150
  %1152 = icmp eq i32 %1151, 2
  %1153 = zext i1 %1152 to i8
  store i8 %1153, i8* %17, align 1
  %1154 = add i64 %1116, -480
  %1155 = add i64 %1118, 18
  store i64 %1155, i64* %3, align 8
  %1156 = inttoptr i64 %1154 to i32*
  store i32 %1127, i32* %1156, align 4
  %1157 = load i64, i64* %RBP.i, align 8
  %1158 = add i64 %1157, -444
  %1159 = load i64, i64* %3, align 8
  %1160 = add i64 %1159, 6
  store i64 %1160, i64* %3, align 8
  %1161 = inttoptr i64 %1158 to i32*
  %1162 = load i32, i32* %1161, align 4
  %1163 = zext i32 %1162 to i64
  store i64 %1163, i64* %RSI.i3950, align 8
  %1164 = add i64 %1157, -440
  %1165 = add i64 %1159, 12
  store i64 %1165, i64* %3, align 8
  %1166 = inttoptr i64 %1164 to i32*
  %1167 = load i32, i32* %1166, align 4
  %1168 = add i32 %1167, %1162
  %1169 = zext i32 %1168 to i64
  store i64 %1169, i64* %RSI.i3950, align 8
  %1170 = icmp ult i32 %1168, %1162
  %1171 = icmp ult i32 %1168, %1167
  %1172 = or i1 %1170, %1171
  %1173 = zext i1 %1172 to i8
  store i8 %1173, i8* %12, align 1
  %1174 = and i32 %1168, 255
  %1175 = tail call i32 @llvm.ctpop.i32(i32 %1174)
  %1176 = trunc i32 %1175 to i8
  %1177 = and i8 %1176, 1
  %1178 = xor i8 %1177, 1
  store i8 %1178, i8* %13, align 1
  %1179 = xor i32 %1167, %1162
  %1180 = xor i32 %1179, %1168
  %1181 = lshr i32 %1180, 4
  %1182 = trunc i32 %1181 to i8
  %1183 = and i8 %1182, 1
  store i8 %1183, i8* %14, align 1
  %1184 = icmp eq i32 %1168, 0
  %1185 = zext i1 %1184 to i8
  store i8 %1185, i8* %15, align 1
  %1186 = lshr i32 %1168, 31
  %1187 = trunc i32 %1186 to i8
  store i8 %1187, i8* %16, align 1
  %1188 = lshr i32 %1162, 31
  %1189 = lshr i32 %1167, 31
  %1190 = xor i32 %1186, %1188
  %1191 = xor i32 %1186, %1189
  %1192 = add nuw nsw i32 %1190, %1191
  %1193 = icmp eq i32 %1192, 2
  %1194 = zext i1 %1193 to i8
  store i8 %1194, i8* %17, align 1
  %1195 = add i64 %1157, -476
  %1196 = add i64 %1159, 18
  store i64 %1196, i64* %3, align 8
  %1197 = inttoptr i64 %1195 to i32*
  store i32 %1168, i32* %1197, align 4
  %1198 = load i64, i64* %RBP.i, align 8
  %1199 = add i64 %1198, -448
  %1200 = load i64, i64* %3, align 8
  %1201 = add i64 %1200, 6
  store i64 %1201, i64* %3, align 8
  %1202 = inttoptr i64 %1199 to i32*
  %1203 = load i32, i32* %1202, align 4
  %1204 = zext i32 %1203 to i64
  store i64 %1204, i64* %RSI.i3950, align 8
  %1205 = add i64 %1198, -436
  %1206 = add i64 %1200, 12
  store i64 %1206, i64* %3, align 8
  %1207 = inttoptr i64 %1205 to i32*
  %1208 = load i32, i32* %1207, align 4
  %1209 = sub i32 %1203, %1208
  %1210 = zext i32 %1209 to i64
  store i64 %1210, i64* %RSI.i3950, align 8
  %1211 = icmp ult i32 %1203, %1208
  %1212 = zext i1 %1211 to i8
  store i8 %1212, i8* %12, align 1
  %1213 = and i32 %1209, 255
  %1214 = tail call i32 @llvm.ctpop.i32(i32 %1213)
  %1215 = trunc i32 %1214 to i8
  %1216 = and i8 %1215, 1
  %1217 = xor i8 %1216, 1
  store i8 %1217, i8* %13, align 1
  %1218 = xor i32 %1208, %1203
  %1219 = xor i32 %1218, %1209
  %1220 = lshr i32 %1219, 4
  %1221 = trunc i32 %1220 to i8
  %1222 = and i8 %1221, 1
  store i8 %1222, i8* %14, align 1
  %1223 = icmp eq i32 %1209, 0
  %1224 = zext i1 %1223 to i8
  store i8 %1224, i8* %15, align 1
  %1225 = lshr i32 %1209, 31
  %1226 = trunc i32 %1225 to i8
  store i8 %1226, i8* %16, align 1
  %1227 = lshr i32 %1203, 31
  %1228 = lshr i32 %1208, 31
  %1229 = xor i32 %1228, %1227
  %1230 = xor i32 %1225, %1227
  %1231 = add nuw nsw i32 %1230, %1229
  %1232 = icmp eq i32 %1231, 2
  %1233 = zext i1 %1232 to i8
  store i8 %1233, i8* %17, align 1
  %1234 = add i64 %1198, -472
  %1235 = add i64 %1200, 18
  store i64 %1235, i64* %3, align 8
  %1236 = inttoptr i64 %1234 to i32*
  store i32 %1209, i32* %1236, align 4
  %1237 = load i64, i64* %RBP.i, align 8
  %1238 = add i64 %1237, -444
  %1239 = load i64, i64* %3, align 8
  %1240 = add i64 %1239, 6
  store i64 %1240, i64* %3, align 8
  %1241 = inttoptr i64 %1238 to i32*
  %1242 = load i32, i32* %1241, align 4
  %1243 = zext i32 %1242 to i64
  store i64 %1243, i64* %RSI.i3950, align 8
  %1244 = add i64 %1237, -440
  %1245 = add i64 %1239, 12
  store i64 %1245, i64* %3, align 8
  %1246 = inttoptr i64 %1244 to i32*
  %1247 = load i32, i32* %1246, align 4
  %1248 = sub i32 %1242, %1247
  %1249 = zext i32 %1248 to i64
  store i64 %1249, i64* %RSI.i3950, align 8
  %1250 = icmp ult i32 %1242, %1247
  %1251 = zext i1 %1250 to i8
  store i8 %1251, i8* %12, align 1
  %1252 = and i32 %1248, 255
  %1253 = tail call i32 @llvm.ctpop.i32(i32 %1252)
  %1254 = trunc i32 %1253 to i8
  %1255 = and i8 %1254, 1
  %1256 = xor i8 %1255, 1
  store i8 %1256, i8* %13, align 1
  %1257 = xor i32 %1247, %1242
  %1258 = xor i32 %1257, %1248
  %1259 = lshr i32 %1258, 4
  %1260 = trunc i32 %1259 to i8
  %1261 = and i8 %1260, 1
  store i8 %1261, i8* %14, align 1
  %1262 = icmp eq i32 %1248, 0
  %1263 = zext i1 %1262 to i8
  store i8 %1263, i8* %15, align 1
  %1264 = lshr i32 %1248, 31
  %1265 = trunc i32 %1264 to i8
  store i8 %1265, i8* %16, align 1
  %1266 = lshr i32 %1242, 31
  %1267 = lshr i32 %1247, 31
  %1268 = xor i32 %1267, %1266
  %1269 = xor i32 %1264, %1266
  %1270 = add nuw nsw i32 %1269, %1268
  %1271 = icmp eq i32 %1270, 2
  %1272 = zext i1 %1271 to i8
  store i8 %1272, i8* %17, align 1
  %1273 = add i64 %1237, -468
  %1274 = add i64 %1239, 18
  store i64 %1274, i64* %3, align 8
  %1275 = inttoptr i64 %1273 to i32*
  store i32 %1248, i32* %1275, align 4
  %1276 = load i64, i64* %3, align 8
  %1277 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1277, i64* %RCX.i3977, align 8
  %1278 = load i64, i64* %RBP.i, align 8
  %1279 = add i64 %1278, -24
  %1280 = add i64 %1276, 12
  store i64 %1280, i64* %3, align 8
  %1281 = inttoptr i64 %1279 to i32*
  %1282 = load i32, i32* %1281, align 4
  %1283 = sext i32 %1282 to i64
  store i64 %1283, i64* %RDX.i4094, align 8
  %1284 = shl nsw i64 %1283, 2
  %1285 = add i64 %1277, 13112
  %1286 = add i64 %1285, %1284
  %1287 = add i64 %1276, 19
  store i64 %1287, i64* %3, align 8
  %1288 = inttoptr i64 %1286 to i32*
  %1289 = load i32, i32* %1288, align 4
  %1290 = zext i32 %1289 to i64
  store i64 %1290, i64* %RSI.i3950, align 8
  store i64 %1277, i64* %RCX.i3977, align 8
  %1291 = add i64 %1276, 31
  store i64 %1291, i64* %3, align 8
  %1292 = load i32, i32* %1281, align 4
  %1293 = sext i32 %1292 to i64
  store i64 %1293, i64* %RDX.i4094, align 8
  %1294 = shl nsw i64 %1293, 2
  %1295 = add nsw i64 %1294, 13560
  %1296 = add i64 %1295, %1277
  %1297 = add i64 %1276, 38
  store i64 %1297, i64* %3, align 8
  %1298 = inttoptr i64 %1296 to i32*
  %1299 = load i32, i32* %1298, align 4
  %1300 = sub i32 %1289, %1299
  %1301 = zext i32 %1300 to i64
  store i64 %1301, i64* %RSI.i3950, align 8
  %1302 = icmp ult i32 %1289, %1299
  %1303 = zext i1 %1302 to i8
  store i8 %1303, i8* %12, align 1
  %1304 = and i32 %1300, 255
  %1305 = tail call i32 @llvm.ctpop.i32(i32 %1304)
  %1306 = trunc i32 %1305 to i8
  %1307 = and i8 %1306, 1
  %1308 = xor i8 %1307, 1
  store i8 %1308, i8* %13, align 1
  %1309 = xor i32 %1299, %1289
  %1310 = xor i32 %1309, %1300
  %1311 = lshr i32 %1310, 4
  %1312 = trunc i32 %1311 to i8
  %1313 = and i8 %1312, 1
  store i8 %1313, i8* %14, align 1
  %1314 = icmp eq i32 %1300, 0
  %1315 = zext i1 %1314 to i8
  store i8 %1315, i8* %15, align 1
  %1316 = lshr i32 %1300, 31
  %1317 = trunc i32 %1316 to i8
  store i8 %1317, i8* %16, align 1
  %1318 = lshr i32 %1289, 31
  %1319 = lshr i32 %1299, 31
  %1320 = xor i32 %1319, %1318
  %1321 = xor i32 %1316, %1318
  %1322 = add nuw nsw i32 %1321, %1320
  %1323 = icmp eq i32 %1322, 2
  %1324 = zext i1 %1323 to i8
  store i8 %1324, i8* %17, align 1
  %1325 = add i64 %1278, -432
  %1326 = add i64 %1276, 44
  store i64 %1326, i64* %3, align 8
  %1327 = inttoptr i64 %1325 to i32*
  store i32 %1300, i32* %1327, align 4
  %1328 = load i64, i64* %3, align 8
  %1329 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1329, i64* %RCX.i3977, align 8
  %1330 = load i64, i64* %RBP.i, align 8
  %1331 = add i64 %1330, -24
  %1332 = add i64 %1328, 12
  store i64 %1332, i64* %3, align 8
  %1333 = inttoptr i64 %1331 to i32*
  %1334 = load i32, i32* %1333, align 4
  %1335 = sext i32 %1334 to i64
  store i64 %1335, i64* %RDX.i4094, align 8
  %1336 = shl nsw i64 %1335, 2
  %1337 = add i64 %1329, 13176
  %1338 = add i64 %1337, %1336
  %1339 = add i64 %1328, 19
  store i64 %1339, i64* %3, align 8
  %1340 = inttoptr i64 %1338 to i32*
  %1341 = load i32, i32* %1340, align 4
  %1342 = zext i32 %1341 to i64
  store i64 %1342, i64* %RSI.i3950, align 8
  store i64 %1329, i64* %RCX.i3977, align 8
  %1343 = add i64 %1328, 31
  store i64 %1343, i64* %3, align 8
  %1344 = load i32, i32* %1333, align 4
  %1345 = sext i32 %1344 to i64
  store i64 %1345, i64* %RDX.i4094, align 8
  %1346 = shl nsw i64 %1345, 2
  %1347 = add nsw i64 %1346, 13496
  %1348 = add i64 %1347, %1329
  %1349 = add i64 %1328, 38
  store i64 %1349, i64* %3, align 8
  %1350 = inttoptr i64 %1348 to i32*
  %1351 = load i32, i32* %1350, align 4
  %1352 = sub i32 %1341, %1351
  %1353 = zext i32 %1352 to i64
  store i64 %1353, i64* %RSI.i3950, align 8
  %1354 = icmp ult i32 %1341, %1351
  %1355 = zext i1 %1354 to i8
  store i8 %1355, i8* %12, align 1
  %1356 = and i32 %1352, 255
  %1357 = tail call i32 @llvm.ctpop.i32(i32 %1356)
  %1358 = trunc i32 %1357 to i8
  %1359 = and i8 %1358, 1
  %1360 = xor i8 %1359, 1
  store i8 %1360, i8* %13, align 1
  %1361 = xor i32 %1351, %1341
  %1362 = xor i32 %1361, %1352
  %1363 = lshr i32 %1362, 4
  %1364 = trunc i32 %1363 to i8
  %1365 = and i8 %1364, 1
  store i8 %1365, i8* %14, align 1
  %1366 = icmp eq i32 %1352, 0
  %1367 = zext i1 %1366 to i8
  store i8 %1367, i8* %15, align 1
  %1368 = lshr i32 %1352, 31
  %1369 = trunc i32 %1368 to i8
  store i8 %1369, i8* %16, align 1
  %1370 = lshr i32 %1341, 31
  %1371 = lshr i32 %1351, 31
  %1372 = xor i32 %1371, %1370
  %1373 = xor i32 %1368, %1370
  %1374 = add nuw nsw i32 %1373, %1372
  %1375 = icmp eq i32 %1374, 2
  %1376 = zext i1 %1375 to i8
  store i8 %1376, i8* %17, align 1
  %1377 = add i64 %1330, -428
  %1378 = add i64 %1328, 44
  store i64 %1378, i64* %3, align 8
  %1379 = inttoptr i64 %1377 to i32*
  store i32 %1352, i32* %1379, align 4
  %1380 = load i64, i64* %3, align 8
  %1381 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1381, i64* %RCX.i3977, align 8
  %1382 = load i64, i64* %RBP.i, align 8
  %1383 = add i64 %1382, -24
  %1384 = add i64 %1380, 12
  store i64 %1384, i64* %3, align 8
  %1385 = inttoptr i64 %1383 to i32*
  %1386 = load i32, i32* %1385, align 4
  %1387 = sext i32 %1386 to i64
  store i64 %1387, i64* %RDX.i4094, align 8
  %1388 = shl nsw i64 %1387, 2
  %1389 = add i64 %1381, 13240
  %1390 = add i64 %1389, %1388
  %1391 = add i64 %1380, 19
  store i64 %1391, i64* %3, align 8
  %1392 = inttoptr i64 %1390 to i32*
  %1393 = load i32, i32* %1392, align 4
  %1394 = zext i32 %1393 to i64
  store i64 %1394, i64* %RSI.i3950, align 8
  store i64 %1381, i64* %RCX.i3977, align 8
  %1395 = add i64 %1380, 31
  store i64 %1395, i64* %3, align 8
  %1396 = load i32, i32* %1385, align 4
  %1397 = sext i32 %1396 to i64
  store i64 %1397, i64* %RDX.i4094, align 8
  %1398 = shl nsw i64 %1397, 2
  %1399 = add nsw i64 %1398, 13432
  %1400 = add i64 %1399, %1381
  %1401 = add i64 %1380, 38
  store i64 %1401, i64* %3, align 8
  %1402 = inttoptr i64 %1400 to i32*
  %1403 = load i32, i32* %1402, align 4
  %1404 = sub i32 %1393, %1403
  %1405 = zext i32 %1404 to i64
  store i64 %1405, i64* %RSI.i3950, align 8
  %1406 = icmp ult i32 %1393, %1403
  %1407 = zext i1 %1406 to i8
  store i8 %1407, i8* %12, align 1
  %1408 = and i32 %1404, 255
  %1409 = tail call i32 @llvm.ctpop.i32(i32 %1408)
  %1410 = trunc i32 %1409 to i8
  %1411 = and i8 %1410, 1
  %1412 = xor i8 %1411, 1
  store i8 %1412, i8* %13, align 1
  %1413 = xor i32 %1403, %1393
  %1414 = xor i32 %1413, %1404
  %1415 = lshr i32 %1414, 4
  %1416 = trunc i32 %1415 to i8
  %1417 = and i8 %1416, 1
  store i8 %1417, i8* %14, align 1
  %1418 = icmp eq i32 %1404, 0
  %1419 = zext i1 %1418 to i8
  store i8 %1419, i8* %15, align 1
  %1420 = lshr i32 %1404, 31
  %1421 = trunc i32 %1420 to i8
  store i8 %1421, i8* %16, align 1
  %1422 = lshr i32 %1393, 31
  %1423 = lshr i32 %1403, 31
  %1424 = xor i32 %1423, %1422
  %1425 = xor i32 %1420, %1422
  %1426 = add nuw nsw i32 %1425, %1424
  %1427 = icmp eq i32 %1426, 2
  %1428 = zext i1 %1427 to i8
  store i8 %1428, i8* %17, align 1
  %1429 = add i64 %1382, -424
  %1430 = add i64 %1380, 44
  store i64 %1430, i64* %3, align 8
  %1431 = inttoptr i64 %1429 to i32*
  store i32 %1404, i32* %1431, align 4
  %1432 = load i64, i64* %3, align 8
  %1433 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1433, i64* %RCX.i3977, align 8
  %1434 = load i64, i64* %RBP.i, align 8
  %1435 = add i64 %1434, -24
  %1436 = add i64 %1432, 12
  store i64 %1436, i64* %3, align 8
  %1437 = inttoptr i64 %1435 to i32*
  %1438 = load i32, i32* %1437, align 4
  %1439 = sext i32 %1438 to i64
  store i64 %1439, i64* %RDX.i4094, align 8
  %1440 = shl nsw i64 %1439, 2
  %1441 = add i64 %1433, 13304
  %1442 = add i64 %1441, %1440
  %1443 = add i64 %1432, 19
  store i64 %1443, i64* %3, align 8
  %1444 = inttoptr i64 %1442 to i32*
  %1445 = load i32, i32* %1444, align 4
  %1446 = zext i32 %1445 to i64
  store i64 %1446, i64* %RSI.i3950, align 8
  store i64 %1433, i64* %RCX.i3977, align 8
  %1447 = add i64 %1432, 31
  store i64 %1447, i64* %3, align 8
  %1448 = load i32, i32* %1437, align 4
  %1449 = sext i32 %1448 to i64
  store i64 %1449, i64* %RDX.i4094, align 8
  %1450 = shl nsw i64 %1449, 2
  %1451 = add nsw i64 %1450, 13368
  %1452 = add i64 %1451, %1433
  %1453 = add i64 %1432, 38
  store i64 %1453, i64* %3, align 8
  %1454 = inttoptr i64 %1452 to i32*
  %1455 = load i32, i32* %1454, align 4
  %1456 = sub i32 %1445, %1455
  %1457 = zext i32 %1456 to i64
  store i64 %1457, i64* %RSI.i3950, align 8
  %1458 = icmp ult i32 %1445, %1455
  %1459 = zext i1 %1458 to i8
  store i8 %1459, i8* %12, align 1
  %1460 = and i32 %1456, 255
  %1461 = tail call i32 @llvm.ctpop.i32(i32 %1460)
  %1462 = trunc i32 %1461 to i8
  %1463 = and i8 %1462, 1
  %1464 = xor i8 %1463, 1
  store i8 %1464, i8* %13, align 1
  %1465 = xor i32 %1455, %1445
  %1466 = xor i32 %1465, %1456
  %1467 = lshr i32 %1466, 4
  %1468 = trunc i32 %1467 to i8
  %1469 = and i8 %1468, 1
  store i8 %1469, i8* %14, align 1
  %1470 = icmp eq i32 %1456, 0
  %1471 = zext i1 %1470 to i8
  store i8 %1471, i8* %15, align 1
  %1472 = lshr i32 %1456, 31
  %1473 = trunc i32 %1472 to i8
  store i8 %1473, i8* %16, align 1
  %1474 = lshr i32 %1445, 31
  %1475 = lshr i32 %1455, 31
  %1476 = xor i32 %1475, %1474
  %1477 = xor i32 %1472, %1474
  %1478 = add nuw nsw i32 %1477, %1476
  %1479 = icmp eq i32 %1478, 2
  %1480 = zext i1 %1479 to i8
  store i8 %1480, i8* %17, align 1
  %1481 = add i64 %1434, -420
  %1482 = add i64 %1432, 44
  store i64 %1482, i64* %3, align 8
  %1483 = inttoptr i64 %1481 to i32*
  store i32 %1456, i32* %1483, align 4
  %1484 = load i64, i64* %RBP.i, align 8
  %1485 = add i64 %1484, -428
  %1486 = load i64, i64* %3, align 8
  %1487 = add i64 %1486, 6
  store i64 %1487, i64* %3, align 8
  %1488 = inttoptr i64 %1485 to i32*
  %1489 = load i32, i32* %1488, align 4
  %1490 = zext i32 %1489 to i64
  store i64 %1490, i64* %RSI.i3950, align 8
  %1491 = add i64 %1484, -424
  %1492 = add i64 %1486, 12
  store i64 %1492, i64* %3, align 8
  %1493 = inttoptr i64 %1491 to i32*
  %1494 = load i32, i32* %1493, align 4
  %1495 = add i32 %1494, %1489
  %1496 = zext i32 %1495 to i64
  store i64 %1496, i64* %RSI.i3950, align 8
  %1497 = icmp ult i32 %1495, %1489
  %1498 = icmp ult i32 %1495, %1494
  %1499 = or i1 %1497, %1498
  %1500 = zext i1 %1499 to i8
  store i8 %1500, i8* %12, align 1
  %1501 = and i32 %1495, 255
  %1502 = tail call i32 @llvm.ctpop.i32(i32 %1501)
  %1503 = trunc i32 %1502 to i8
  %1504 = and i8 %1503, 1
  %1505 = xor i8 %1504, 1
  store i8 %1505, i8* %13, align 1
  %1506 = xor i32 %1494, %1489
  %1507 = xor i32 %1506, %1495
  %1508 = lshr i32 %1507, 4
  %1509 = trunc i32 %1508 to i8
  %1510 = and i8 %1509, 1
  store i8 %1510, i8* %14, align 1
  %1511 = icmp eq i32 %1495, 0
  %1512 = zext i1 %1511 to i8
  store i8 %1512, i8* %15, align 1
  %1513 = lshr i32 %1495, 31
  %1514 = trunc i32 %1513 to i8
  store i8 %1514, i8* %16, align 1
  %1515 = lshr i32 %1489, 31
  %1516 = lshr i32 %1494, 31
  %1517 = xor i32 %1513, %1515
  %1518 = xor i32 %1513, %1516
  %1519 = add nuw nsw i32 %1517, %1518
  %1520 = icmp eq i32 %1519, 2
  %1521 = zext i1 %1520 to i8
  store i8 %1521, i8* %17, align 1
  %1522 = add i64 %1484, -432
  %1523 = add i64 %1486, 18
  store i64 %1523, i64* %3, align 8
  %1524 = inttoptr i64 %1522 to i32*
  %1525 = load i32, i32* %1524, align 4
  %1526 = zext i32 %1525 to i64
  %1527 = shl nuw i64 %1526, 32
  %1528 = ashr i64 %1527, 33
  %1529 = trunc i32 %1525 to i8
  %1530 = and i8 %1529, 1
  %1531 = trunc i64 %1528 to i32
  %1532 = and i64 %1528, 4294967295
  store i64 %1532, i64* %RDI.i4084, align 8
  store i8 %1530, i8* %12, align 1
  %1533 = and i32 %1531, 255
  %1534 = tail call i32 @llvm.ctpop.i32(i32 %1533)
  %1535 = trunc i32 %1534 to i8
  %1536 = and i8 %1535, 1
  %1537 = xor i8 %1536, 1
  store i8 %1537, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %1538 = icmp eq i32 %1531, 0
  %1539 = zext i1 %1538 to i8
  store i8 %1539, i8* %15, align 1
  %1540 = lshr i64 %1528, 31
  %1541 = trunc i64 %1540 to i8
  %1542 = and i8 %1541, 1
  store i8 %1542, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %1543 = add i64 %1486, 26
  store i64 %1543, i64* %3, align 8
  %1544 = trunc i64 %1528 to i32
  %1545 = load i32, i32* %1524, align 4
  %1546 = add i32 %1545, %1544
  %1547 = zext i32 %1546 to i64
  store i64 %1547, i64* %RDI.i4084, align 8
  %1548 = lshr i32 %1546, 31
  %1549 = load i64, i64* %RSI.i3950, align 8
  %1550 = trunc i64 %1549 to i32
  %1551 = add i32 %1546, %1550
  %1552 = zext i32 %1551 to i64
  store i64 %1552, i64* %RSI.i3950, align 8
  %1553 = icmp ult i32 %1551, %1550
  %1554 = icmp ult i32 %1551, %1546
  %1555 = or i1 %1553, %1554
  %1556 = zext i1 %1555 to i8
  store i8 %1556, i8* %12, align 1
  %1557 = and i32 %1551, 255
  %1558 = tail call i32 @llvm.ctpop.i32(i32 %1557)
  %1559 = trunc i32 %1558 to i8
  %1560 = and i8 %1559, 1
  %1561 = xor i8 %1560, 1
  store i8 %1561, i8* %13, align 1
  %1562 = xor i64 %1547, %1549
  %1563 = trunc i64 %1562 to i32
  %1564 = xor i32 %1563, %1551
  %1565 = lshr i32 %1564, 4
  %1566 = trunc i32 %1565 to i8
  %1567 = and i8 %1566, 1
  store i8 %1567, i8* %14, align 1
  %1568 = icmp eq i32 %1551, 0
  %1569 = zext i1 %1568 to i8
  store i8 %1569, i8* %15, align 1
  %1570 = lshr i32 %1551, 31
  %1571 = trunc i32 %1570 to i8
  store i8 %1571, i8* %16, align 1
  %1572 = lshr i32 %1550, 31
  %1573 = xor i32 %1570, %1572
  %1574 = xor i32 %1570, %1548
  %1575 = add nuw nsw i32 %1573, %1574
  %1576 = icmp eq i32 %1575, 2
  %1577 = zext i1 %1576 to i8
  store i8 %1577, i8* %17, align 1
  %1578 = load i64, i64* %RBP.i, align 8
  %1579 = add i64 %1578, -464
  %1580 = add i64 %1486, 34
  store i64 %1580, i64* %3, align 8
  %1581 = inttoptr i64 %1579 to i32*
  store i32 %1551, i32* %1581, align 4
  %1582 = load i64, i64* %RBP.i, align 8
  %1583 = add i64 %1582, -432
  %1584 = load i64, i64* %3, align 8
  %1585 = add i64 %1584, 6
  store i64 %1585, i64* %3, align 8
  %1586 = inttoptr i64 %1583 to i32*
  %1587 = load i32, i32* %1586, align 4
  %1588 = zext i32 %1587 to i64
  store i64 %1588, i64* %RSI.i3950, align 8
  %1589 = add i64 %1582, -420
  %1590 = add i64 %1584, 12
  store i64 %1590, i64* %3, align 8
  %1591 = inttoptr i64 %1589 to i32*
  %1592 = load i32, i32* %1591, align 4
  %1593 = sub i32 %1587, %1592
  %1594 = zext i32 %1593 to i64
  store i64 %1594, i64* %RSI.i3950, align 8
  %1595 = icmp ult i32 %1587, %1592
  %1596 = zext i1 %1595 to i8
  store i8 %1596, i8* %12, align 1
  %1597 = and i32 %1593, 255
  %1598 = tail call i32 @llvm.ctpop.i32(i32 %1597)
  %1599 = trunc i32 %1598 to i8
  %1600 = and i8 %1599, 1
  %1601 = xor i8 %1600, 1
  store i8 %1601, i8* %13, align 1
  %1602 = xor i32 %1592, %1587
  %1603 = xor i32 %1602, %1593
  %1604 = lshr i32 %1603, 4
  %1605 = trunc i32 %1604 to i8
  %1606 = and i8 %1605, 1
  store i8 %1606, i8* %14, align 1
  %1607 = icmp eq i32 %1593, 0
  %1608 = zext i1 %1607 to i8
  store i8 %1608, i8* %15, align 1
  %1609 = lshr i32 %1593, 31
  %1610 = trunc i32 %1609 to i8
  store i8 %1610, i8* %16, align 1
  %1611 = lshr i32 %1587, 31
  %1612 = lshr i32 %1592, 31
  %1613 = xor i32 %1612, %1611
  %1614 = xor i32 %1609, %1611
  %1615 = add nuw nsw i32 %1614, %1613
  %1616 = icmp eq i32 %1615, 2
  %1617 = zext i1 %1616 to i8
  store i8 %1617, i8* %17, align 1
  %1618 = add i64 %1582, -424
  %1619 = add i64 %1584, 18
  store i64 %1619, i64* %3, align 8
  %1620 = inttoptr i64 %1618 to i32*
  %1621 = load i32, i32* %1620, align 4
  %1622 = zext i32 %1621 to i64
  %1623 = shl nuw i64 %1622, 32
  %1624 = ashr i64 %1623, 33
  %1625 = trunc i32 %1621 to i8
  %1626 = and i8 %1625, 1
  %1627 = trunc i64 %1624 to i32
  %1628 = and i64 %1624, 4294967295
  store i64 %1628, i64* %RDI.i4084, align 8
  store i8 %1626, i8* %12, align 1
  %1629 = and i32 %1627, 255
  %1630 = tail call i32 @llvm.ctpop.i32(i32 %1629)
  %1631 = trunc i32 %1630 to i8
  %1632 = and i8 %1631, 1
  %1633 = xor i8 %1632, 1
  store i8 %1633, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %1634 = icmp eq i32 %1627, 0
  %1635 = zext i1 %1634 to i8
  store i8 %1635, i8* %15, align 1
  %1636 = lshr i64 %1624, 31
  %1637 = trunc i64 %1636 to i8
  %1638 = and i8 %1637, 1
  store i8 %1638, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %1639 = add i64 %1584, 26
  store i64 %1639, i64* %3, align 8
  %1640 = trunc i64 %1624 to i32
  %1641 = load i32, i32* %1620, align 4
  %1642 = add i32 %1641, %1640
  %1643 = zext i32 %1642 to i64
  store i64 %1643, i64* %RDI.i4084, align 8
  %1644 = lshr i32 %1642, 31
  %1645 = load i64, i64* %RSI.i3950, align 8
  %1646 = trunc i64 %1645 to i32
  %1647 = sub i32 %1646, %1642
  %1648 = zext i32 %1647 to i64
  store i64 %1648, i64* %RSI.i3950, align 8
  %1649 = icmp ult i32 %1646, %1642
  %1650 = zext i1 %1649 to i8
  store i8 %1650, i8* %12, align 1
  %1651 = and i32 %1647, 255
  %1652 = tail call i32 @llvm.ctpop.i32(i32 %1651)
  %1653 = trunc i32 %1652 to i8
  %1654 = and i8 %1653, 1
  %1655 = xor i8 %1654, 1
  store i8 %1655, i8* %13, align 1
  %1656 = xor i64 %1643, %1645
  %1657 = trunc i64 %1656 to i32
  %1658 = xor i32 %1657, %1647
  %1659 = lshr i32 %1658, 4
  %1660 = trunc i32 %1659 to i8
  %1661 = and i8 %1660, 1
  store i8 %1661, i8* %14, align 1
  %1662 = icmp eq i32 %1647, 0
  %1663 = zext i1 %1662 to i8
  store i8 %1663, i8* %15, align 1
  %1664 = lshr i32 %1647, 31
  %1665 = trunc i32 %1664 to i8
  store i8 %1665, i8* %16, align 1
  %1666 = lshr i32 %1646, 31
  %1667 = xor i32 %1644, %1666
  %1668 = xor i32 %1664, %1666
  %1669 = add nuw nsw i32 %1668, %1667
  %1670 = icmp eq i32 %1669, 2
  %1671 = zext i1 %1670 to i8
  store i8 %1671, i8* %17, align 1
  %1672 = load i64, i64* %RBP.i, align 8
  %1673 = add i64 %1672, -460
  %1674 = add i64 %1584, 34
  store i64 %1674, i64* %3, align 8
  %1675 = inttoptr i64 %1673 to i32*
  store i32 %1647, i32* %1675, align 4
  %1676 = load i64, i64* %RBP.i, align 8
  %1677 = add i64 %1676, -432
  %1678 = load i64, i64* %3, align 8
  %1679 = add i64 %1678, 6
  store i64 %1679, i64* %3, align 8
  %1680 = inttoptr i64 %1677 to i32*
  %1681 = load i32, i32* %1680, align 4
  %1682 = zext i32 %1681 to i64
  store i64 %1682, i64* %RSI.i3950, align 8
  %1683 = add i64 %1676, -420
  %1684 = add i64 %1678, 12
  store i64 %1684, i64* %3, align 8
  %1685 = inttoptr i64 %1683 to i32*
  %1686 = load i32, i32* %1685, align 4
  %1687 = add i32 %1686, %1681
  %1688 = zext i32 %1687 to i64
  store i64 %1688, i64* %RSI.i3950, align 8
  %1689 = icmp ult i32 %1687, %1681
  %1690 = icmp ult i32 %1687, %1686
  %1691 = or i1 %1689, %1690
  %1692 = zext i1 %1691 to i8
  store i8 %1692, i8* %12, align 1
  %1693 = and i32 %1687, 255
  %1694 = tail call i32 @llvm.ctpop.i32(i32 %1693)
  %1695 = trunc i32 %1694 to i8
  %1696 = and i8 %1695, 1
  %1697 = xor i8 %1696, 1
  store i8 %1697, i8* %13, align 1
  %1698 = xor i32 %1686, %1681
  %1699 = xor i32 %1698, %1687
  %1700 = lshr i32 %1699, 4
  %1701 = trunc i32 %1700 to i8
  %1702 = and i8 %1701, 1
  store i8 %1702, i8* %14, align 1
  %1703 = icmp eq i32 %1687, 0
  %1704 = zext i1 %1703 to i8
  store i8 %1704, i8* %15, align 1
  %1705 = lshr i32 %1687, 31
  %1706 = trunc i32 %1705 to i8
  store i8 %1706, i8* %16, align 1
  %1707 = lshr i32 %1681, 31
  %1708 = lshr i32 %1686, 31
  %1709 = xor i32 %1705, %1707
  %1710 = xor i32 %1705, %1708
  %1711 = add nuw nsw i32 %1709, %1710
  %1712 = icmp eq i32 %1711, 2
  %1713 = zext i1 %1712 to i8
  store i8 %1713, i8* %17, align 1
  %1714 = add i64 %1676, -428
  %1715 = add i64 %1678, 18
  store i64 %1715, i64* %3, align 8
  %1716 = inttoptr i64 %1714 to i32*
  %1717 = load i32, i32* %1716, align 4
  %1718 = zext i32 %1717 to i64
  %1719 = shl nuw i64 %1718, 32
  %1720 = ashr i64 %1719, 33
  %1721 = trunc i32 %1717 to i8
  %1722 = and i8 %1721, 1
  %1723 = trunc i64 %1720 to i32
  %1724 = and i64 %1720, 4294967295
  store i64 %1724, i64* %RDI.i4084, align 8
  store i8 %1722, i8* %12, align 1
  %1725 = and i32 %1723, 255
  %1726 = tail call i32 @llvm.ctpop.i32(i32 %1725)
  %1727 = trunc i32 %1726 to i8
  %1728 = and i8 %1727, 1
  %1729 = xor i8 %1728, 1
  store i8 %1729, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %1730 = icmp eq i32 %1723, 0
  %1731 = zext i1 %1730 to i8
  store i8 %1731, i8* %15, align 1
  %1732 = lshr i64 %1720, 31
  %1733 = trunc i64 %1732 to i8
  %1734 = and i8 %1733, 1
  store i8 %1734, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %1735 = add i64 %1678, 26
  store i64 %1735, i64* %3, align 8
  %1736 = trunc i64 %1720 to i32
  %1737 = load i32, i32* %1716, align 4
  %1738 = add i32 %1737, %1736
  %1739 = zext i32 %1738 to i64
  store i64 %1739, i64* %RDI.i4084, align 8
  %1740 = lshr i32 %1738, 31
  %1741 = load i64, i64* %RSI.i3950, align 8
  %1742 = trunc i64 %1741 to i32
  %1743 = sub i32 %1742, %1738
  %1744 = zext i32 %1743 to i64
  store i64 %1744, i64* %RSI.i3950, align 8
  %1745 = icmp ult i32 %1742, %1738
  %1746 = zext i1 %1745 to i8
  store i8 %1746, i8* %12, align 1
  %1747 = and i32 %1743, 255
  %1748 = tail call i32 @llvm.ctpop.i32(i32 %1747)
  %1749 = trunc i32 %1748 to i8
  %1750 = and i8 %1749, 1
  %1751 = xor i8 %1750, 1
  store i8 %1751, i8* %13, align 1
  %1752 = xor i64 %1739, %1741
  %1753 = trunc i64 %1752 to i32
  %1754 = xor i32 %1753, %1743
  %1755 = lshr i32 %1754, 4
  %1756 = trunc i32 %1755 to i8
  %1757 = and i8 %1756, 1
  store i8 %1757, i8* %14, align 1
  %1758 = icmp eq i32 %1743, 0
  %1759 = zext i1 %1758 to i8
  store i8 %1759, i8* %15, align 1
  %1760 = lshr i32 %1743, 31
  %1761 = trunc i32 %1760 to i8
  store i8 %1761, i8* %16, align 1
  %1762 = lshr i32 %1742, 31
  %1763 = xor i32 %1740, %1762
  %1764 = xor i32 %1760, %1762
  %1765 = add nuw nsw i32 %1764, %1763
  %1766 = icmp eq i32 %1765, 2
  %1767 = zext i1 %1766 to i8
  store i8 %1767, i8* %17, align 1
  %1768 = load i64, i64* %RBP.i, align 8
  %1769 = add i64 %1768, -456
  %1770 = add i64 %1678, 34
  store i64 %1770, i64* %3, align 8
  %1771 = inttoptr i64 %1769 to i32*
  store i32 %1743, i32* %1771, align 4
  %1772 = load i64, i64* %RBP.i, align 8
  %1773 = add i64 %1772, -428
  %1774 = load i64, i64* %3, align 8
  %1775 = add i64 %1774, 6
  store i64 %1775, i64* %3, align 8
  %1776 = inttoptr i64 %1773 to i32*
  %1777 = load i32, i32* %1776, align 4
  %1778 = zext i32 %1777 to i64
  store i64 %1778, i64* %RSI.i3950, align 8
  %1779 = add i64 %1772, -424
  %1780 = add i64 %1774, 12
  store i64 %1780, i64* %3, align 8
  %1781 = inttoptr i64 %1779 to i32*
  %1782 = load i32, i32* %1781, align 4
  %1783 = sub i32 %1777, %1782
  %1784 = zext i32 %1783 to i64
  store i64 %1784, i64* %RSI.i3950, align 8
  %1785 = icmp ult i32 %1777, %1782
  %1786 = zext i1 %1785 to i8
  store i8 %1786, i8* %12, align 1
  %1787 = and i32 %1783, 255
  %1788 = tail call i32 @llvm.ctpop.i32(i32 %1787)
  %1789 = trunc i32 %1788 to i8
  %1790 = and i8 %1789, 1
  %1791 = xor i8 %1790, 1
  store i8 %1791, i8* %13, align 1
  %1792 = xor i32 %1782, %1777
  %1793 = xor i32 %1792, %1783
  %1794 = lshr i32 %1793, 4
  %1795 = trunc i32 %1794 to i8
  %1796 = and i8 %1795, 1
  store i8 %1796, i8* %14, align 1
  %1797 = icmp eq i32 %1783, 0
  %1798 = zext i1 %1797 to i8
  store i8 %1798, i8* %15, align 1
  %1799 = lshr i32 %1783, 31
  %1800 = trunc i32 %1799 to i8
  store i8 %1800, i8* %16, align 1
  %1801 = lshr i32 %1777, 31
  %1802 = lshr i32 %1782, 31
  %1803 = xor i32 %1802, %1801
  %1804 = xor i32 %1799, %1801
  %1805 = add nuw nsw i32 %1804, %1803
  %1806 = icmp eq i32 %1805, 2
  %1807 = zext i1 %1806 to i8
  store i8 %1807, i8* %17, align 1
  %1808 = add i64 %1772, -420
  %1809 = add i64 %1774, 18
  store i64 %1809, i64* %3, align 8
  %1810 = inttoptr i64 %1808 to i32*
  %1811 = load i32, i32* %1810, align 4
  %1812 = zext i32 %1811 to i64
  %1813 = shl nuw i64 %1812, 32
  %1814 = ashr i64 %1813, 33
  %1815 = trunc i32 %1811 to i8
  %1816 = and i8 %1815, 1
  %1817 = trunc i64 %1814 to i32
  %1818 = and i64 %1814, 4294967295
  store i64 %1818, i64* %RDI.i4084, align 8
  store i8 %1816, i8* %12, align 1
  %1819 = and i32 %1817, 255
  %1820 = tail call i32 @llvm.ctpop.i32(i32 %1819)
  %1821 = trunc i32 %1820 to i8
  %1822 = and i8 %1821, 1
  %1823 = xor i8 %1822, 1
  store i8 %1823, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %1824 = icmp eq i32 %1817, 0
  %1825 = zext i1 %1824 to i8
  store i8 %1825, i8* %15, align 1
  %1826 = lshr i64 %1814, 31
  %1827 = trunc i64 %1826 to i8
  %1828 = and i8 %1827, 1
  store i8 %1828, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %1829 = add i64 %1774, 26
  store i64 %1829, i64* %3, align 8
  %1830 = trunc i64 %1814 to i32
  %1831 = load i32, i32* %1810, align 4
  %1832 = add i32 %1831, %1830
  %1833 = zext i32 %1832 to i64
  store i64 %1833, i64* %RDI.i4084, align 8
  %1834 = lshr i32 %1832, 31
  %1835 = load i64, i64* %RSI.i3950, align 8
  %1836 = trunc i64 %1835 to i32
  %1837 = add i32 %1832, %1836
  %1838 = zext i32 %1837 to i64
  store i64 %1838, i64* %RSI.i3950, align 8
  %1839 = icmp ult i32 %1837, %1836
  %1840 = icmp ult i32 %1837, %1832
  %1841 = or i1 %1839, %1840
  %1842 = zext i1 %1841 to i8
  store i8 %1842, i8* %12, align 1
  %1843 = and i32 %1837, 255
  %1844 = tail call i32 @llvm.ctpop.i32(i32 %1843)
  %1845 = trunc i32 %1844 to i8
  %1846 = and i8 %1845, 1
  %1847 = xor i8 %1846, 1
  store i8 %1847, i8* %13, align 1
  %1848 = xor i64 %1833, %1835
  %1849 = trunc i64 %1848 to i32
  %1850 = xor i32 %1849, %1837
  %1851 = lshr i32 %1850, 4
  %1852 = trunc i32 %1851 to i8
  %1853 = and i8 %1852, 1
  store i8 %1853, i8* %14, align 1
  %1854 = icmp eq i32 %1837, 0
  %1855 = zext i1 %1854 to i8
  store i8 %1855, i8* %15, align 1
  %1856 = lshr i32 %1837, 31
  %1857 = trunc i32 %1856 to i8
  store i8 %1857, i8* %16, align 1
  %1858 = lshr i32 %1836, 31
  %1859 = xor i32 %1856, %1858
  %1860 = xor i32 %1856, %1834
  %1861 = add nuw nsw i32 %1859, %1860
  %1862 = icmp eq i32 %1861, 2
  %1863 = zext i1 %1862 to i8
  store i8 %1863, i8* %17, align 1
  %1864 = load i64, i64* %RBP.i, align 8
  %1865 = add i64 %1864, -452
  %1866 = add i64 %1774, 34
  store i64 %1866, i64* %3, align 8
  %1867 = inttoptr i64 %1865 to i32*
  store i32 %1837, i32* %1867, align 4
  %1868 = load i64, i64* %RBP.i, align 8
  %1869 = add i64 %1868, -480
  %1870 = load i64, i64* %3, align 8
  %1871 = add i64 %1870, 6
  store i64 %1871, i64* %3, align 8
  %1872 = inttoptr i64 %1869 to i32*
  %1873 = load i32, i32* %1872, align 4
  %1874 = zext i32 %1873 to i64
  store i64 %1874, i64* %RSI.i3950, align 8
  %1875 = add i64 %1868, -476
  %1876 = add i64 %1870, 12
  store i64 %1876, i64* %3, align 8
  %1877 = inttoptr i64 %1875 to i32*
  %1878 = load i32, i32* %1877, align 4
  %1879 = add i32 %1878, %1873
  %1880 = zext i32 %1879 to i64
  store i64 %1880, i64* %RSI.i3950, align 8
  %1881 = icmp ult i32 %1879, %1873
  %1882 = icmp ult i32 %1879, %1878
  %1883 = or i1 %1881, %1882
  %1884 = zext i1 %1883 to i8
  store i8 %1884, i8* %12, align 1
  %1885 = and i32 %1879, 255
  %1886 = tail call i32 @llvm.ctpop.i32(i32 %1885)
  %1887 = trunc i32 %1886 to i8
  %1888 = and i8 %1887, 1
  %1889 = xor i8 %1888, 1
  store i8 %1889, i8* %13, align 1
  %1890 = xor i32 %1878, %1873
  %1891 = xor i32 %1890, %1879
  %1892 = lshr i32 %1891, 4
  %1893 = trunc i32 %1892 to i8
  %1894 = and i8 %1893, 1
  store i8 %1894, i8* %14, align 1
  %1895 = icmp eq i32 %1879, 0
  %1896 = zext i1 %1895 to i8
  store i8 %1896, i8* %15, align 1
  %1897 = lshr i32 %1879, 31
  %1898 = trunc i32 %1897 to i8
  store i8 %1898, i8* %16, align 1
  %1899 = lshr i32 %1873, 31
  %1900 = lshr i32 %1878, 31
  %1901 = xor i32 %1897, %1899
  %1902 = xor i32 %1897, %1900
  %1903 = add nuw nsw i32 %1901, %1902
  %1904 = icmp eq i32 %1903, 2
  %1905 = zext i1 %1904 to i8
  store i8 %1905, i8* %17, align 1
  %1906 = add i64 %1868, -24
  %1907 = add i64 %1870, 16
  store i64 %1907, i64* %3, align 8
  %1908 = inttoptr i64 %1906 to i32*
  %1909 = load i32, i32* %1908, align 4
  %1910 = sext i32 %1909 to i64
  store i64 %1910, i64* %RCX.i3977, align 8
  %1911 = shl nsw i64 %1910, 2
  %1912 = add i64 %1868, -368
  %1913 = add i64 %1912, %1911
  %1914 = add i64 %1870, 23
  store i64 %1914, i64* %3, align 8
  %1915 = inttoptr i64 %1913 to i32*
  store i32 %1879, i32* %1915, align 4
  %1916 = load i64, i64* %RBP.i, align 8
  %1917 = add i64 %1916, -472
  %1918 = load i64, i64* %3, align 8
  %1919 = add i64 %1918, 6
  store i64 %1919, i64* %3, align 8
  %1920 = inttoptr i64 %1917 to i32*
  %1921 = load i32, i32* %1920, align 4
  %1922 = zext i32 %1921 to i64
  store i64 %1922, i64* %RSI.i3950, align 8
  %1923 = add i64 %1916, -468
  %1924 = add i64 %1918, 12
  store i64 %1924, i64* %3, align 8
  %1925 = inttoptr i64 %1923 to i32*
  %1926 = load i32, i32* %1925, align 4
  %1927 = zext i32 %1926 to i64
  %1928 = shl nuw i64 %1927, 32
  %1929 = ashr i64 %1928, 33
  %1930 = and i64 %1929, 4294967295
  store i64 %1930, i64* %RDI.i4084, align 8
  %1931 = trunc i64 %1929 to i32
  %1932 = add i32 %1931, %1921
  %1933 = zext i32 %1932 to i64
  store i64 %1933, i64* %RSI.i3950, align 8
  %1934 = icmp ult i32 %1932, %1921
  %1935 = icmp ult i32 %1932, %1931
  %1936 = or i1 %1934, %1935
  %1937 = zext i1 %1936 to i8
  store i8 %1937, i8* %12, align 1
  %1938 = and i32 %1932, 255
  %1939 = tail call i32 @llvm.ctpop.i32(i32 %1938)
  %1940 = trunc i32 %1939 to i8
  %1941 = and i8 %1940, 1
  %1942 = xor i8 %1941, 1
  store i8 %1942, i8* %13, align 1
  %1943 = xor i64 %1929, %1922
  %1944 = trunc i64 %1943 to i32
  %1945 = xor i32 %1944, %1932
  %1946 = lshr i32 %1945, 4
  %1947 = trunc i32 %1946 to i8
  %1948 = and i8 %1947, 1
  store i8 %1948, i8* %14, align 1
  %1949 = icmp eq i32 %1932, 0
  %1950 = zext i1 %1949 to i8
  store i8 %1950, i8* %15, align 1
  %1951 = lshr i32 %1932, 31
  %1952 = trunc i32 %1951 to i8
  store i8 %1952, i8* %16, align 1
  %1953 = lshr i32 %1921, 31
  %1954 = lshr i64 %1929, 31
  %1955 = trunc i64 %1954 to i32
  %1956 = and i32 %1955, 1
  %1957 = xor i32 %1951, %1953
  %1958 = xor i32 %1951, %1956
  %1959 = add nuw nsw i32 %1957, %1958
  %1960 = icmp eq i32 %1959, 2
  %1961 = zext i1 %1960 to i8
  store i8 %1961, i8* %17, align 1
  %1962 = add i64 %1916, -24
  %1963 = add i64 %1918, 20
  store i64 %1963, i64* %3, align 8
  %1964 = inttoptr i64 %1962 to i32*
  %1965 = load i32, i32* %1964, align 4
  %1966 = sext i32 %1965 to i64
  store i64 %1966, i64* %RCX.i3977, align 8
  %1967 = shl nsw i64 %1966, 2
  %1968 = add i64 %1916, -304
  %1969 = add i64 %1968, %1967
  %1970 = add i64 %1918, 27
  store i64 %1970, i64* %3, align 8
  %1971 = inttoptr i64 %1969 to i32*
  store i32 %1932, i32* %1971, align 4
  %1972 = load i64, i64* %RBP.i, align 8
  %1973 = add i64 %1972, -480
  %1974 = load i64, i64* %3, align 8
  %1975 = add i64 %1974, 6
  store i64 %1975, i64* %3, align 8
  %1976 = inttoptr i64 %1973 to i32*
  %1977 = load i32, i32* %1976, align 4
  %1978 = zext i32 %1977 to i64
  store i64 %1978, i64* %RSI.i3950, align 8
  %1979 = add i64 %1972, -476
  %1980 = add i64 %1974, 12
  store i64 %1980, i64* %3, align 8
  %1981 = inttoptr i64 %1979 to i32*
  %1982 = load i32, i32* %1981, align 4
  %1983 = sub i32 %1977, %1982
  %1984 = zext i32 %1983 to i64
  store i64 %1984, i64* %RSI.i3950, align 8
  %1985 = icmp ult i32 %1977, %1982
  %1986 = zext i1 %1985 to i8
  store i8 %1986, i8* %12, align 1
  %1987 = and i32 %1983, 255
  %1988 = tail call i32 @llvm.ctpop.i32(i32 %1987)
  %1989 = trunc i32 %1988 to i8
  %1990 = and i8 %1989, 1
  %1991 = xor i8 %1990, 1
  store i8 %1991, i8* %13, align 1
  %1992 = xor i32 %1982, %1977
  %1993 = xor i32 %1992, %1983
  %1994 = lshr i32 %1993, 4
  %1995 = trunc i32 %1994 to i8
  %1996 = and i8 %1995, 1
  store i8 %1996, i8* %14, align 1
  %1997 = icmp eq i32 %1983, 0
  %1998 = zext i1 %1997 to i8
  store i8 %1998, i8* %15, align 1
  %1999 = lshr i32 %1983, 31
  %2000 = trunc i32 %1999 to i8
  store i8 %2000, i8* %16, align 1
  %2001 = lshr i32 %1977, 31
  %2002 = lshr i32 %1982, 31
  %2003 = xor i32 %2002, %2001
  %2004 = xor i32 %1999, %2001
  %2005 = add nuw nsw i32 %2004, %2003
  %2006 = icmp eq i32 %2005, 2
  %2007 = zext i1 %2006 to i8
  store i8 %2007, i8* %17, align 1
  %2008 = add i64 %1972, -24
  %2009 = add i64 %1974, 16
  store i64 %2009, i64* %3, align 8
  %2010 = inttoptr i64 %2008 to i32*
  %2011 = load i32, i32* %2010, align 4
  %2012 = sext i32 %2011 to i64
  store i64 %2012, i64* %RCX.i3977, align 8
  %2013 = shl nsw i64 %2012, 2
  %2014 = add i64 %1972, -240
  %2015 = add i64 %2014, %2013
  %2016 = add i64 %1974, 23
  store i64 %2016, i64* %3, align 8
  %2017 = inttoptr i64 %2015 to i32*
  store i32 %1983, i32* %2017, align 4
  %2018 = load i64, i64* %RBP.i, align 8
  %2019 = add i64 %2018, -472
  %2020 = load i64, i64* %3, align 8
  %2021 = add i64 %2020, 6
  store i64 %2021, i64* %3, align 8
  %2022 = inttoptr i64 %2019 to i32*
  %2023 = load i32, i32* %2022, align 4
  %2024 = zext i32 %2023 to i64
  %2025 = shl nuw i64 %2024, 32
  %2026 = ashr i64 %2025, 33
  %2027 = trunc i32 %2023 to i8
  %2028 = and i8 %2027, 1
  %2029 = trunc i64 %2026 to i32
  %2030 = and i64 %2026, 4294967295
  store i64 %2030, i64* %RSI.i3950, align 8
  store i8 %2028, i8* %12, align 1
  %2031 = and i32 %2029, 255
  %2032 = tail call i32 @llvm.ctpop.i32(i32 %2031)
  %2033 = trunc i32 %2032 to i8
  %2034 = and i8 %2033, 1
  %2035 = xor i8 %2034, 1
  store i8 %2035, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %2036 = icmp eq i32 %2029, 0
  %2037 = zext i1 %2036 to i8
  store i8 %2037, i8* %15, align 1
  %2038 = lshr i64 %2026, 31
  %2039 = trunc i64 %2038 to i8
  %2040 = and i8 %2039, 1
  store i8 %2040, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %2041 = add i64 %2018, -468
  %2042 = add i64 %2020, 14
  store i64 %2042, i64* %3, align 8
  %2043 = trunc i64 %2026 to i32
  %2044 = inttoptr i64 %2041 to i32*
  %2045 = load i32, i32* %2044, align 4
  %2046 = sub i32 %2043, %2045
  %2047 = zext i32 %2046 to i64
  store i64 %2047, i64* %RSI.i3950, align 8
  %2048 = icmp ult i32 %2043, %2045
  %2049 = zext i1 %2048 to i8
  store i8 %2049, i8* %12, align 1
  %2050 = and i32 %2046, 255
  %2051 = tail call i32 @llvm.ctpop.i32(i32 %2050)
  %2052 = trunc i32 %2051 to i8
  %2053 = and i8 %2052, 1
  %2054 = xor i8 %2053, 1
  store i8 %2054, i8* %13, align 1
  %2055 = xor i32 %2045, %2043
  %2056 = xor i32 %2055, %2046
  %2057 = lshr i32 %2056, 4
  %2058 = trunc i32 %2057 to i8
  %2059 = and i8 %2058, 1
  store i8 %2059, i8* %14, align 1
  %2060 = icmp eq i32 %2046, 0
  %2061 = zext i1 %2060 to i8
  store i8 %2061, i8* %15, align 1
  %2062 = lshr i32 %2046, 31
  %2063 = trunc i32 %2062 to i8
  store i8 %2063, i8* %16, align 1
  %2064 = lshr i64 %2026, 31
  %2065 = trunc i64 %2064 to i32
  %2066 = and i32 %2065, 1
  %2067 = lshr i32 %2045, 31
  %2068 = xor i32 %2067, %2066
  %2069 = xor i32 %2062, %2066
  %2070 = add nuw nsw i32 %2069, %2068
  %2071 = icmp eq i32 %2070, 2
  %2072 = zext i1 %2071 to i8
  store i8 %2072, i8* %17, align 1
  %2073 = add i64 %2018, -24
  %2074 = add i64 %2020, 18
  store i64 %2074, i64* %3, align 8
  %2075 = inttoptr i64 %2073 to i32*
  %2076 = load i32, i32* %2075, align 4
  %2077 = sext i32 %2076 to i64
  store i64 %2077, i64* %RCX.i3977, align 8
  %2078 = shl nsw i64 %2077, 2
  %2079 = add i64 %2018, -176
  %2080 = add i64 %2079, %2078
  %2081 = add i64 %2020, 25
  store i64 %2081, i64* %3, align 8
  %2082 = inttoptr i64 %2080 to i32*
  store i32 %2046, i32* %2082, align 4
  %2083 = load i64, i64* %RBP.i, align 8
  %2084 = add i64 %2083, -464
  %2085 = load i64, i64* %3, align 8
  %2086 = add i64 %2085, 6
  store i64 %2086, i64* %3, align 8
  %2087 = inttoptr i64 %2084 to i32*
  %2088 = load i32, i32* %2087, align 4
  %2089 = zext i32 %2088 to i64
  store i64 %2089, i64* %RSI.i3950, align 8
  %2090 = add i64 %2083, -452
  %2091 = add i64 %2085, 12
  store i64 %2091, i64* %3, align 8
  %2092 = inttoptr i64 %2090 to i32*
  %2093 = load i32, i32* %2092, align 4
  %2094 = sext i32 %2093 to i64
  %2095 = ashr i64 %2094, 1
  %2096 = lshr i64 %2095, 1
  %2097 = and i64 %2096, 4294967295
  store i64 %2097, i64* %RDI.i4084, align 8
  %2098 = trunc i64 %2096 to i32
  %2099 = add i32 %2098, %2088
  %2100 = zext i32 %2099 to i64
  store i64 %2100, i64* %RSI.i3950, align 8
  %2101 = icmp ult i32 %2099, %2088
  %2102 = icmp ult i32 %2099, %2098
  %2103 = or i1 %2101, %2102
  %2104 = zext i1 %2103 to i8
  store i8 %2104, i8* %12, align 1
  %2105 = and i32 %2099, 255
  %2106 = tail call i32 @llvm.ctpop.i32(i32 %2105)
  %2107 = trunc i32 %2106 to i8
  %2108 = and i8 %2107, 1
  %2109 = xor i8 %2108, 1
  store i8 %2109, i8* %13, align 1
  %2110 = xor i64 %2096, %2089
  %2111 = trunc i64 %2110 to i32
  %2112 = xor i32 %2111, %2099
  %2113 = lshr i32 %2112, 4
  %2114 = trunc i32 %2113 to i8
  %2115 = and i8 %2114, 1
  store i8 %2115, i8* %14, align 1
  %2116 = icmp eq i32 %2099, 0
  %2117 = zext i1 %2116 to i8
  store i8 %2117, i8* %15, align 1
  %2118 = lshr i32 %2099, 31
  %2119 = trunc i32 %2118 to i8
  store i8 %2119, i8* %16, align 1
  %2120 = lshr i32 %2088, 31
  %2121 = lshr i64 %2095, 32
  %2122 = trunc i64 %2121 to i32
  %2123 = and i32 %2122, 1
  %2124 = xor i32 %2118, %2120
  %2125 = xor i32 %2118, %2123
  %2126 = add nuw nsw i32 %2124, %2125
  %2127 = icmp eq i32 %2126, 2
  %2128 = zext i1 %2127 to i8
  store i8 %2128, i8* %17, align 1
  %2129 = add i64 %2083, -24
  %2130 = add i64 %2085, 21
  store i64 %2130, i64* %3, align 8
  %2131 = inttoptr i64 %2129 to i32*
  %2132 = load i32, i32* %2131, align 4
  %2133 = sext i32 %2132 to i64
  store i64 %2133, i64* %RCX.i3977, align 8
  %2134 = shl nsw i64 %2133, 2
  %2135 = add i64 %2083, -336
  %2136 = add i64 %2135, %2134
  %2137 = add i64 %2085, 28
  store i64 %2137, i64* %3, align 8
  %2138 = inttoptr i64 %2136 to i32*
  store i32 %2099, i32* %2138, align 4
  %2139 = load i64, i64* %RBP.i, align 8
  %2140 = add i64 %2139, -460
  %2141 = load i64, i64* %3, align 8
  %2142 = add i64 %2141, 6
  store i64 %2142, i64* %3, align 8
  %2143 = inttoptr i64 %2140 to i32*
  %2144 = load i32, i32* %2143, align 4
  %2145 = zext i32 %2144 to i64
  store i64 %2145, i64* %RSI.i3950, align 8
  %2146 = add i64 %2139, -456
  %2147 = add i64 %2141, 12
  store i64 %2147, i64* %3, align 8
  %2148 = inttoptr i64 %2146 to i32*
  %2149 = load i32, i32* %2148, align 4
  %2150 = sext i32 %2149 to i64
  %2151 = ashr i64 %2150, 1
  %2152 = lshr i64 %2151, 1
  %2153 = and i64 %2152, 4294967295
  store i64 %2153, i64* %RDI.i4084, align 8
  %2154 = trunc i64 %2152 to i32
  %2155 = add i32 %2154, %2144
  %2156 = zext i32 %2155 to i64
  store i64 %2156, i64* %RSI.i3950, align 8
  %2157 = icmp ult i32 %2155, %2144
  %2158 = icmp ult i32 %2155, %2154
  %2159 = or i1 %2157, %2158
  %2160 = zext i1 %2159 to i8
  store i8 %2160, i8* %12, align 1
  %2161 = and i32 %2155, 255
  %2162 = tail call i32 @llvm.ctpop.i32(i32 %2161)
  %2163 = trunc i32 %2162 to i8
  %2164 = and i8 %2163, 1
  %2165 = xor i8 %2164, 1
  store i8 %2165, i8* %13, align 1
  %2166 = xor i64 %2152, %2145
  %2167 = trunc i64 %2166 to i32
  %2168 = xor i32 %2167, %2155
  %2169 = lshr i32 %2168, 4
  %2170 = trunc i32 %2169 to i8
  %2171 = and i8 %2170, 1
  store i8 %2171, i8* %14, align 1
  %2172 = icmp eq i32 %2155, 0
  %2173 = zext i1 %2172 to i8
  store i8 %2173, i8* %15, align 1
  %2174 = lshr i32 %2155, 31
  %2175 = trunc i32 %2174 to i8
  store i8 %2175, i8* %16, align 1
  %2176 = lshr i32 %2144, 31
  %2177 = lshr i64 %2151, 32
  %2178 = trunc i64 %2177 to i32
  %2179 = and i32 %2178, 1
  %2180 = xor i32 %2174, %2176
  %2181 = xor i32 %2174, %2179
  %2182 = add nuw nsw i32 %2180, %2181
  %2183 = icmp eq i32 %2182, 2
  %2184 = zext i1 %2183 to i8
  store i8 %2184, i8* %17, align 1
  %2185 = add i64 %2139, -24
  %2186 = add i64 %2141, 21
  store i64 %2186, i64* %3, align 8
  %2187 = inttoptr i64 %2185 to i32*
  %2188 = load i32, i32* %2187, align 4
  %2189 = sext i32 %2188 to i64
  store i64 %2189, i64* %RCX.i3977, align 8
  %2190 = shl nsw i64 %2189, 2
  %2191 = add i64 %2139, -272
  %2192 = add i64 %2191, %2190
  %2193 = add i64 %2141, 28
  store i64 %2193, i64* %3, align 8
  %2194 = inttoptr i64 %2192 to i32*
  store i32 %2155, i32* %2194, align 4
  %2195 = load i64, i64* %RBP.i, align 8
  %2196 = add i64 %2195, -456
  %2197 = load i64, i64* %3, align 8
  %2198 = add i64 %2197, 6
  store i64 %2198, i64* %3, align 8
  %2199 = inttoptr i64 %2196 to i32*
  %2200 = load i32, i32* %2199, align 4
  %2201 = zext i32 %2200 to i64
  store i64 %2201, i64* %RSI.i3950, align 8
  %2202 = add i64 %2195, -460
  %2203 = add i64 %2197, 12
  store i64 %2203, i64* %3, align 8
  %2204 = inttoptr i64 %2202 to i32*
  %2205 = load i32, i32* %2204, align 4
  %2206 = sext i32 %2205 to i64
  %2207 = ashr i64 %2206, 1
  %2208 = lshr i64 %2207, 1
  %2209 = and i64 %2208, 4294967295
  store i64 %2209, i64* %RDI.i4084, align 8
  %2210 = trunc i64 %2208 to i32
  %2211 = sub i32 %2200, %2210
  %2212 = zext i32 %2211 to i64
  store i64 %2212, i64* %RSI.i3950, align 8
  %2213 = icmp ult i32 %2200, %2210
  %2214 = zext i1 %2213 to i8
  store i8 %2214, i8* %12, align 1
  %2215 = and i32 %2211, 255
  %2216 = tail call i32 @llvm.ctpop.i32(i32 %2215)
  %2217 = trunc i32 %2216 to i8
  %2218 = and i8 %2217, 1
  %2219 = xor i8 %2218, 1
  store i8 %2219, i8* %13, align 1
  %2220 = xor i64 %2208, %2201
  %2221 = trunc i64 %2220 to i32
  %2222 = xor i32 %2221, %2211
  %2223 = lshr i32 %2222, 4
  %2224 = trunc i32 %2223 to i8
  %2225 = and i8 %2224, 1
  store i8 %2225, i8* %14, align 1
  %2226 = icmp eq i32 %2211, 0
  %2227 = zext i1 %2226 to i8
  store i8 %2227, i8* %15, align 1
  %2228 = lshr i32 %2211, 31
  %2229 = trunc i32 %2228 to i8
  store i8 %2229, i8* %16, align 1
  %2230 = lshr i32 %2200, 31
  %2231 = lshr i64 %2207, 32
  %2232 = trunc i64 %2231 to i32
  %2233 = and i32 %2232, 1
  %2234 = xor i32 %2233, %2230
  %2235 = xor i32 %2228, %2230
  %2236 = add nuw nsw i32 %2235, %2234
  %2237 = icmp eq i32 %2236, 2
  %2238 = zext i1 %2237 to i8
  store i8 %2238, i8* %17, align 1
  %2239 = add i64 %2195, -24
  %2240 = add i64 %2197, 21
  store i64 %2240, i64* %3, align 8
  %2241 = inttoptr i64 %2239 to i32*
  %2242 = load i32, i32* %2241, align 4
  %2243 = sext i32 %2242 to i64
  store i64 %2243, i64* %RCX.i3977, align 8
  %2244 = shl nsw i64 %2243, 2
  %2245 = add i64 %2195, -208
  %2246 = add i64 %2245, %2244
  %2247 = add i64 %2197, 28
  store i64 %2247, i64* %3, align 8
  %2248 = inttoptr i64 %2246 to i32*
  store i32 %2211, i32* %2248, align 4
  %2249 = load i64, i64* %RAX.i2610, align 8
  %2250 = load i64, i64* %RBP.i, align 8
  %2251 = add i64 %2250, -452
  %2252 = load i64, i64* %3, align 8
  %2253 = add i64 %2252, 6
  store i64 %2253, i64* %3, align 8
  %2254 = trunc i64 %2249 to i32
  %2255 = inttoptr i64 %2251 to i32*
  %2256 = load i32, i32* %2255, align 4
  %2257 = sub i32 %2254, %2256
  %2258 = zext i32 %2257 to i64
  store i64 %2258, i64* %RAX.i2610, align 8
  %2259 = icmp ult i32 %2254, %2256
  %2260 = zext i1 %2259 to i8
  store i8 %2260, i8* %12, align 1
  %2261 = and i32 %2257, 255
  %2262 = tail call i32 @llvm.ctpop.i32(i32 %2261)
  %2263 = trunc i32 %2262 to i8
  %2264 = and i8 %2263, 1
  %2265 = xor i8 %2264, 1
  store i8 %2265, i8* %13, align 1
  %2266 = xor i32 %2256, %2254
  %2267 = xor i32 %2266, %2257
  %2268 = lshr i32 %2267, 4
  %2269 = trunc i32 %2268 to i8
  %2270 = and i8 %2269, 1
  store i8 %2270, i8* %14, align 1
  %2271 = icmp eq i32 %2257, 0
  %2272 = zext i1 %2271 to i8
  store i8 %2272, i8* %15, align 1
  %2273 = lshr i32 %2257, 31
  %2274 = trunc i32 %2273 to i8
  store i8 %2274, i8* %16, align 1
  %2275 = lshr i32 %2254, 31
  %2276 = lshr i32 %2256, 31
  %2277 = xor i32 %2276, %2275
  %2278 = xor i32 %2273, %2275
  %2279 = add nuw nsw i32 %2278, %2277
  %2280 = icmp eq i32 %2279, 2
  %2281 = zext i1 %2280 to i8
  store i8 %2281, i8* %17, align 1
  %2282 = add i64 %2250, -464
  %2283 = add i64 %2252, 12
  store i64 %2283, i64* %3, align 8
  %2284 = inttoptr i64 %2282 to i32*
  %2285 = load i32, i32* %2284, align 4
  %2286 = sext i32 %2285 to i64
  %2287 = ashr i64 %2286, 1
  %2288 = lshr i64 %2287, 1
  %2289 = and i64 %2288, 4294967295
  store i64 %2289, i64* %RSI.i3950, align 8
  %2290 = trunc i64 %2288 to i32
  %2291 = add i32 %2290, %2257
  %2292 = zext i32 %2291 to i64
  store i64 %2292, i64* %RAX.i2610, align 8
  %2293 = icmp ult i32 %2291, %2257
  %2294 = icmp ult i32 %2291, %2290
  %2295 = or i1 %2293, %2294
  %2296 = zext i1 %2295 to i8
  store i8 %2296, i8* %12, align 1
  %2297 = and i32 %2291, 255
  %2298 = tail call i32 @llvm.ctpop.i32(i32 %2297)
  %2299 = trunc i32 %2298 to i8
  %2300 = and i8 %2299, 1
  %2301 = xor i8 %2300, 1
  store i8 %2301, i8* %13, align 1
  %2302 = xor i64 %2288, %2258
  %2303 = trunc i64 %2302 to i32
  %2304 = xor i32 %2303, %2291
  %2305 = lshr i32 %2304, 4
  %2306 = trunc i32 %2305 to i8
  %2307 = and i8 %2306, 1
  store i8 %2307, i8* %14, align 1
  %2308 = icmp eq i32 %2291, 0
  %2309 = zext i1 %2308 to i8
  store i8 %2309, i8* %15, align 1
  %2310 = lshr i32 %2291, 31
  %2311 = trunc i32 %2310 to i8
  store i8 %2311, i8* %16, align 1
  %2312 = lshr i64 %2287, 32
  %2313 = trunc i64 %2312 to i32
  %2314 = and i32 %2313, 1
  %2315 = xor i32 %2310, %2273
  %2316 = xor i32 %2310, %2314
  %2317 = add nuw nsw i32 %2315, %2316
  %2318 = icmp eq i32 %2317, 2
  %2319 = zext i1 %2318 to i8
  store i8 %2319, i8* %17, align 1
  %2320 = load i64, i64* %RBP.i, align 8
  %2321 = add i64 %2320, -24
  %2322 = add i64 %2252, 21
  store i64 %2322, i64* %3, align 8
  %2323 = inttoptr i64 %2321 to i32*
  %2324 = load i32, i32* %2323, align 4
  %2325 = sext i32 %2324 to i64
  store i64 %2325, i64* %RCX.i3977, align 8
  %2326 = shl nsw i64 %2325, 2
  %2327 = add i64 %2320, -144
  %2328 = add i64 %2327, %2326
  %2329 = add i64 %2252, 28
  store i64 %2329, i64* %3, align 8
  %2330 = inttoptr i64 %2328 to i32*
  store i32 %2291, i32* %2330, align 4
  %2331 = load i64, i64* %RBP.i, align 8
  %2332 = add i64 %2331, -24
  %2333 = load i64, i64* %3, align 8
  %2334 = add i64 %2333, 3
  store i64 %2334, i64* %3, align 8
  %2335 = inttoptr i64 %2332 to i32*
  %2336 = load i32, i32* %2335, align 4
  %2337 = add i32 %2336, 1
  %2338 = zext i32 %2337 to i64
  store i64 %2338, i64* %RAX.i2610, align 8
  %2339 = icmp eq i32 %2336, -1
  %2340 = icmp eq i32 %2337, 0
  %2341 = or i1 %2339, %2340
  %2342 = zext i1 %2341 to i8
  store i8 %2342, i8* %12, align 1
  %2343 = and i32 %2337, 255
  %2344 = tail call i32 @llvm.ctpop.i32(i32 %2343)
  %2345 = trunc i32 %2344 to i8
  %2346 = and i8 %2345, 1
  %2347 = xor i8 %2346, 1
  store i8 %2347, i8* %13, align 1
  %2348 = xor i32 %2337, %2336
  %2349 = lshr i32 %2348, 4
  %2350 = trunc i32 %2349 to i8
  %2351 = and i8 %2350, 1
  store i8 %2351, i8* %14, align 1
  %2352 = zext i1 %2340 to i8
  store i8 %2352, i8* %15, align 1
  %2353 = lshr i32 %2337, 31
  %2354 = trunc i32 %2353 to i8
  store i8 %2354, i8* %16, align 1
  %2355 = lshr i32 %2336, 31
  %2356 = xor i32 %2353, %2355
  %2357 = add nuw nsw i32 %2356, %2353
  %2358 = icmp eq i32 %2357, 2
  %2359 = zext i1 %2358 to i8
  store i8 %2359, i8* %17, align 1
  %2360 = add i64 %2333, 9
  store i64 %2360, i64* %3, align 8
  store i32 %2337, i32* %2335, align 4
  %2361 = load i64, i64* %3, align 8
  %2362 = add i64 %2361, -844
  store i64 %2362, i64* %3, align 8
  br label %block_.L_4aa964

block_.L_4aacbc:                                  ; preds = %block_.L_4aacf5, %block_4aa998
  %2363 = phi i64 [ %4564, %block_.L_4aacf5 ], [ %.pre174, %block_4aa998 ]
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %CL.i3807, align 1
  %2364 = load i64, i64* %RBP.i, align 8
  %2365 = add i64 %2364, -24
  %2366 = add i64 %2363, 8
  store i64 %2366, i64* %3, align 8
  %2367 = inttoptr i64 %2365 to i32*
  %2368 = load i32, i32* %2367, align 4
  %2369 = add i32 %2368, -8
  %2370 = icmp ult i32 %2368, 8
  %2371 = zext i1 %2370 to i8
  store i8 %2371, i8* %12, align 1
  %2372 = and i32 %2369, 255
  %2373 = tail call i32 @llvm.ctpop.i32(i32 %2372)
  %2374 = trunc i32 %2373 to i8
  %2375 = and i8 %2374, 1
  %2376 = xor i8 %2375, 1
  store i8 %2376, i8* %13, align 1
  %2377 = xor i32 %2369, %2368
  %2378 = lshr i32 %2377, 4
  %2379 = trunc i32 %2378 to i8
  %2380 = and i8 %2379, 1
  store i8 %2380, i8* %14, align 1
  %2381 = icmp eq i32 %2369, 0
  %2382 = zext i1 %2381 to i8
  store i8 %2382, i8* %15, align 1
  %2383 = lshr i32 %2369, 31
  %2384 = trunc i32 %2383 to i8
  store i8 %2384, i8* %16, align 1
  %2385 = lshr i32 %2368, 31
  %2386 = xor i32 %2383, %2385
  %2387 = add nuw nsw i32 %2386, %2385
  %2388 = icmp eq i32 %2387, 2
  %2389 = zext i1 %2388 to i8
  store i8 %2389, i8* %17, align 1
  %2390 = add i64 %2364, -698
  %2391 = add i64 %2363, 14
  store i64 %2391, i64* %3, align 8
  %2392 = inttoptr i64 %2390 to i8*
  store i8 0, i8* %2392, align 1
  %2393 = load i64, i64* %3, align 8
  %2394 = add i64 %2393, 24
  %2395 = add i64 %2393, 6
  %2396 = load i8, i8* %16, align 1
  %2397 = icmp ne i8 %2396, 0
  %2398 = load i8, i8* %17, align 1
  %2399 = icmp ne i8 %2398, 0
  %2400 = xor i1 %2397, %2399
  %2401 = select i1 %2400, i64 %2395, i64 %2394
  store i64 %2401, i64* %3, align 8
  br i1 %2400, label %block_4aacd0, label %block_.L_4aace2

block_4aacd0:                                     ; preds = %block_.L_4aacbc
  %2402 = load i64, i64* %RBP.i, align 8
  %2403 = add i64 %2402, -412
  %2404 = add i64 %2401, 7
  store i64 %2404, i64* %3, align 8
  %2405 = inttoptr i64 %2403 to i32*
  %2406 = load i32, i32* %2405, align 4
  %2407 = icmp ne i32 %2406, 0
  %2408 = zext i1 %2407 to i64
  %2409 = xor i64 %2408, 255
  %2410 = trunc i64 %2409 to i8
  store i8 %2410, i8* %AL.i3806, align 1
  store i8 0, i8* %12, align 1
  %2411 = trunc i64 %2409 to i32
  %2412 = tail call i32 @llvm.ctpop.i32(i32 %2411)
  %2413 = trunc i32 %2412 to i8
  %2414 = and i8 %2413, 1
  %2415 = xor i8 %2414, 1
  store i8 %2415, i8* %13, align 1
  store i8 0, i8* %15, align 1
  store i8 1, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %2416 = add i64 %2402, -698
  %2417 = add i64 %2401, 18
  store i64 %2417, i64* %3, align 8
  %2418 = inttoptr i64 %2416 to i8*
  store i8 %2410, i8* %2418, align 1
  %.pre175 = load i64, i64* %3, align 8
  br label %block_.L_4aace2

block_.L_4aace2:                                  ; preds = %block_.L_4aacbc, %block_4aacd0
  %2419 = phi i64 [ %2394, %block_.L_4aacbc ], [ %.pre175, %block_4aacd0 ]
  %2420 = load i64, i64* %RBP.i, align 8
  %2421 = add i64 %2420, -698
  %2422 = add i64 %2419, 6
  store i64 %2422, i64* %3, align 8
  %2423 = inttoptr i64 %2421 to i8*
  %2424 = load i8, i8* %2423, align 1
  store i8 %2424, i8* %AL.i3806, align 1
  %2425 = and i8 %2424, 1
  store i8 0, i8* %12, align 1
  %2426 = zext i8 %2425 to i32
  %2427 = tail call i32 @llvm.ctpop.i32(i32 %2426)
  %2428 = trunc i32 %2427 to i8
  %2429 = xor i8 %2428, 1
  store i8 %2429, i8* %13, align 1
  %2430 = xor i8 %2425, 1
  store i8 %2430, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %2431 = icmp eq i8 %2430, 0
  %.v201 = select i1 %2431, i64 19, i64 14
  %2432 = add i64 %2419, %.v201
  store i64 %2432, i64* %3, align 8
  br i1 %2431, label %block_.L_4aacf5, label %block_4aacf0

block_4aacf0:                                     ; preds = %block_.L_4aace2
  %2433 = add i64 %2420, -56
  %2434 = add i64 %2432, 945
  store i64 %2434, i64* %3, align 8
  %2435 = inttoptr i64 %2433 to i32*
  store i32 0, i32* %2435, align 4
  %2436 = load i64, i64* %RBP.i, align 8
  %2437 = add i64 %2436, -52
  %2438 = load i64, i64* %3, align 8
  %2439 = add i64 %2438, 7
  store i64 %2439, i64* %3, align 8
  %2440 = inttoptr i64 %2437 to i32*
  store i32 -1, i32* %2440, align 4
  %2441 = load i64, i64* %RBP.i, align 8
  %2442 = add i64 %2441, -48
  %2443 = load i64, i64* %3, align 8
  %2444 = add i64 %2443, 7
  store i64 %2444, i64* %3, align 8
  %2445 = inttoptr i64 %2442 to i32*
  store i32 0, i32* %2445, align 4
  %2446 = load i64, i64* %RBP.i, align 8
  %2447 = add i64 %2446, -388
  %2448 = load i64, i64* %3, align 8
  %2449 = add i64 %2448, 10
  store i64 %2449, i64* %3, align 8
  %2450 = inttoptr i64 %2447 to i32*
  store i32 -1, i32* %2450, align 4
  %2451 = load i64, i64* %RBP.i, align 8
  %2452 = add i64 %2451, -392
  %2453 = load i64, i64* %3, align 8
  %2454 = add i64 %2453, 10
  store i64 %2454, i64* %3, align 8
  %2455 = inttoptr i64 %2452 to i32*
  store i32 -1, i32* %2455, align 4
  %2456 = load i64, i64* %RBP.i, align 8
  %2457 = add i64 %2456, -396
  %2458 = load i64, i64* %3, align 8
  %2459 = add i64 %2458, 10
  store i64 %2459, i64* %3, align 8
  %2460 = inttoptr i64 %2457 to i32*
  store i32 -1, i32* %2460, align 4
  %2461 = load i64, i64* %RBP.i, align 8
  %2462 = add i64 %2461, -400
  %2463 = load i64, i64* %3, align 8
  %2464 = add i64 %2463, 10
  store i64 %2464, i64* %3, align 8
  %2465 = inttoptr i64 %2462 to i32*
  store i32 -1, i32* %2465, align 4
  %2466 = load i64, i64* %RBP.i, align 8
  %2467 = add i64 %2466, -372
  %2468 = load i64, i64* %3, align 8
  %2469 = add i64 %2468, 10
  store i64 %2469, i64* %3, align 8
  %2470 = inttoptr i64 %2467 to i32*
  store i32 0, i32* %2470, align 4
  %2471 = load i64, i64* %RBP.i, align 8
  %2472 = add i64 %2471, -376
  %2473 = load i64, i64* %3, align 8
  %2474 = add i64 %2473, 10
  store i64 %2474, i64* %3, align 8
  %2475 = inttoptr i64 %2472 to i32*
  store i32 0, i32* %2475, align 4
  %2476 = load i64, i64* %RBP.i, align 8
  %2477 = add i64 %2476, -380
  %2478 = load i64, i64* %3, align 8
  %2479 = add i64 %2478, 10
  store i64 %2479, i64* %3, align 8
  %2480 = inttoptr i64 %2477 to i32*
  store i32 0, i32* %2480, align 4
  %2481 = load i64, i64* %RBP.i, align 8
  %2482 = add i64 %2481, -384
  %2483 = load i64, i64* %3, align 8
  %2484 = add i64 %2483, 10
  store i64 %2484, i64* %3, align 8
  %2485 = inttoptr i64 %2482 to i32*
  store i32 0, i32* %2485, align 4
  %2486 = load i64, i64* %RBP.i, align 8
  %2487 = add i64 %2486, -36
  %2488 = load i64, i64* %3, align 8
  %2489 = add i64 %2488, 7
  store i64 %2489, i64* %3, align 8
  %2490 = inttoptr i64 %2487 to i32*
  store i32 0, i32* %2490, align 4
  %.pre176 = load i64, i64* %3, align 8
  br label %block_.L_4ab106

block_.L_4aacf5:                                  ; preds = %block_.L_4aace2
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %2491 = add i64 %2420, -368
  store i64 %2491, i64* %RCX.i3977, align 8
  %2492 = add i64 %2420, -24
  %2493 = add i64 %2432, 13
  store i64 %2493, i64* %3, align 8
  %2494 = inttoptr i64 %2492 to i32*
  %2495 = load i32, i32* %2494, align 4
  %2496 = sext i32 %2495 to i64
  %2497 = shl nsw i64 %2496, 5
  store i64 %2497, i64* %RDX.i4094, align 8
  %2498 = add i64 %2497, %2491
  store i64 %2498, i64* %RSI.i3950, align 8
  %2499 = icmp ult i64 %2498, %2491
  %2500 = icmp ult i64 %2498, %2497
  %2501 = or i1 %2499, %2500
  %2502 = zext i1 %2501 to i8
  store i8 %2502, i8* %12, align 1
  %2503 = trunc i64 %2498 to i32
  %2504 = and i32 %2503, 255
  %2505 = tail call i32 @llvm.ctpop.i32(i32 %2504)
  %2506 = trunc i32 %2505 to i8
  %2507 = and i8 %2506, 1
  %2508 = xor i8 %2507, 1
  store i8 %2508, i8* %13, align 1
  %2509 = xor i64 %2491, %2498
  %2510 = lshr i64 %2509, 4
  %2511 = trunc i64 %2510 to i8
  %2512 = and i8 %2511, 1
  store i8 %2512, i8* %14, align 1
  %2513 = icmp eq i64 %2498, 0
  %2514 = zext i1 %2513 to i8
  store i8 %2514, i8* %15, align 1
  %2515 = lshr i64 %2498, 63
  %2516 = trunc i64 %2515 to i8
  store i8 %2516, i8* %16, align 1
  %2517 = lshr i64 %2491, 63
  %2518 = lshr i64 %2496, 58
  %2519 = and i64 %2518, 1
  %2520 = xor i64 %2515, %2517
  %2521 = xor i64 %2515, %2519
  %2522 = add nuw nsw i64 %2520, %2521
  %2523 = icmp eq i64 %2522, 2
  %2524 = zext i1 %2523 to i8
  store i8 %2524, i8* %17, align 1
  %2525 = inttoptr i64 %2498 to i32*
  %2526 = add i64 %2432, 25
  store i64 %2526, i64* %3, align 8
  %2527 = load i32, i32* %2525, align 4
  %2528 = zext i32 %2527 to i64
  store i64 %2528, i64* %RDI.i4084, align 8
  %2529 = load i64, i64* %RBP.i, align 8
  %2530 = add i64 %2529, -24
  %2531 = add i64 %2432, 29
  store i64 %2531, i64* %3, align 8
  %2532 = inttoptr i64 %2530 to i32*
  %2533 = load i32, i32* %2532, align 4
  %2534 = sext i32 %2533 to i64
  %2535 = shl nsw i64 %2534, 5
  store i64 %2535, i64* %RDX.i4094, align 8
  %2536 = load i64, i64* %RCX.i3977, align 8
  %2537 = add i64 %2535, %2536
  store i64 %2537, i64* %RSI.i3950, align 8
  %2538 = icmp ult i64 %2537, %2536
  %2539 = icmp ult i64 %2537, %2535
  %2540 = or i1 %2538, %2539
  %2541 = zext i1 %2540 to i8
  store i8 %2541, i8* %12, align 1
  %2542 = trunc i64 %2537 to i32
  %2543 = and i32 %2542, 255
  %2544 = tail call i32 @llvm.ctpop.i32(i32 %2543)
  %2545 = trunc i32 %2544 to i8
  %2546 = and i8 %2545, 1
  %2547 = xor i8 %2546, 1
  store i8 %2547, i8* %13, align 1
  %2548 = xor i64 %2536, %2537
  %2549 = lshr i64 %2548, 4
  %2550 = trunc i64 %2549 to i8
  %2551 = and i8 %2550, 1
  store i8 %2551, i8* %14, align 1
  %2552 = icmp eq i64 %2537, 0
  %2553 = zext i1 %2552 to i8
  store i8 %2553, i8* %15, align 1
  %2554 = lshr i64 %2537, 63
  %2555 = trunc i64 %2554 to i8
  store i8 %2555, i8* %16, align 1
  %2556 = lshr i64 %2536, 63
  %2557 = lshr i64 %2534, 58
  %2558 = and i64 %2557, 1
  %2559 = xor i64 %2554, %2556
  %2560 = xor i64 %2554, %2558
  %2561 = add nuw nsw i64 %2559, %2560
  %2562 = icmp eq i64 %2561, 2
  %2563 = zext i1 %2562 to i8
  store i8 %2563, i8* %17, align 1
  %2564 = add i64 %2537, 28
  %2565 = add i64 %2432, 42
  store i64 %2565, i64* %3, align 8
  %2566 = inttoptr i64 %2564 to i32*
  %2567 = load i32, i32* %2566, align 4
  %2568 = add i32 %2567, %2527
  %2569 = zext i32 %2568 to i64
  store i64 %2569, i64* %RDI.i4084, align 8
  %2570 = icmp ult i32 %2568, %2527
  %2571 = icmp ult i32 %2568, %2567
  %2572 = or i1 %2570, %2571
  %2573 = zext i1 %2572 to i8
  store i8 %2573, i8* %12, align 1
  %2574 = and i32 %2568, 255
  %2575 = tail call i32 @llvm.ctpop.i32(i32 %2574)
  %2576 = trunc i32 %2575 to i8
  %2577 = and i8 %2576, 1
  %2578 = xor i8 %2577, 1
  store i8 %2578, i8* %13, align 1
  %2579 = xor i32 %2567, %2527
  %2580 = xor i32 %2579, %2568
  %2581 = lshr i32 %2580, 4
  %2582 = trunc i32 %2581 to i8
  %2583 = and i8 %2582, 1
  store i8 %2583, i8* %14, align 1
  %2584 = icmp eq i32 %2568, 0
  %2585 = zext i1 %2584 to i8
  store i8 %2585, i8* %15, align 1
  %2586 = lshr i32 %2568, 31
  %2587 = trunc i32 %2586 to i8
  store i8 %2587, i8* %16, align 1
  %2588 = lshr i32 %2527, 31
  %2589 = lshr i32 %2567, 31
  %2590 = xor i32 %2586, %2588
  %2591 = xor i32 %2586, %2589
  %2592 = add nuw nsw i32 %2590, %2591
  %2593 = icmp eq i32 %2592, 2
  %2594 = zext i1 %2593 to i8
  store i8 %2594, i8* %17, align 1
  %2595 = load i64, i64* %RBP.i, align 8
  %2596 = add i64 %2595, -512
  %2597 = add i64 %2432, 48
  store i64 %2597, i64* %3, align 8
  %2598 = inttoptr i64 %2596 to i32*
  store i32 %2568, i32* %2598, align 4
  %2599 = load i64, i64* %RBP.i, align 8
  %2600 = add i64 %2599, -24
  %2601 = load i64, i64* %3, align 8
  %2602 = add i64 %2601, 4
  store i64 %2602, i64* %3, align 8
  %2603 = inttoptr i64 %2600 to i32*
  %2604 = load i32, i32* %2603, align 4
  %2605 = sext i32 %2604 to i64
  %2606 = shl nsw i64 %2605, 5
  store i64 %2606, i64* %RDX.i4094, align 8
  %2607 = load i64, i64* %RCX.i3977, align 8
  %2608 = add i64 %2606, %2607
  store i64 %2608, i64* %RSI.i3950, align 8
  %2609 = icmp ult i64 %2608, %2607
  %2610 = icmp ult i64 %2608, %2606
  %2611 = or i1 %2609, %2610
  %2612 = zext i1 %2611 to i8
  store i8 %2612, i8* %12, align 1
  %2613 = trunc i64 %2608 to i32
  %2614 = and i32 %2613, 255
  %2615 = tail call i32 @llvm.ctpop.i32(i32 %2614)
  %2616 = trunc i32 %2615 to i8
  %2617 = and i8 %2616, 1
  %2618 = xor i8 %2617, 1
  store i8 %2618, i8* %13, align 1
  %2619 = xor i64 %2607, %2608
  %2620 = lshr i64 %2619, 4
  %2621 = trunc i64 %2620 to i8
  %2622 = and i8 %2621, 1
  store i8 %2622, i8* %14, align 1
  %2623 = icmp eq i64 %2608, 0
  %2624 = zext i1 %2623 to i8
  store i8 %2624, i8* %15, align 1
  %2625 = lshr i64 %2608, 63
  %2626 = trunc i64 %2625 to i8
  store i8 %2626, i8* %16, align 1
  %2627 = lshr i64 %2607, 63
  %2628 = lshr i64 %2605, 58
  %2629 = and i64 %2628, 1
  %2630 = xor i64 %2625, %2627
  %2631 = xor i64 %2625, %2629
  %2632 = add nuw nsw i64 %2630, %2631
  %2633 = icmp eq i64 %2632, 2
  %2634 = zext i1 %2633 to i8
  store i8 %2634, i8* %17, align 1
  %2635 = add i64 %2608, 4
  %2636 = add i64 %2601, 17
  store i64 %2636, i64* %3, align 8
  %2637 = inttoptr i64 %2635 to i32*
  %2638 = load i32, i32* %2637, align 4
  %2639 = zext i32 %2638 to i64
  store i64 %2639, i64* %RDI.i4084, align 8
  %2640 = add i64 %2601, 21
  store i64 %2640, i64* %3, align 8
  %2641 = load i32, i32* %2603, align 4
  %2642 = sext i32 %2641 to i64
  %2643 = shl nsw i64 %2642, 5
  store i64 %2643, i64* %RDX.i4094, align 8
  %2644 = add i64 %2643, %2607
  store i64 %2644, i64* %RSI.i3950, align 8
  %2645 = icmp ult i64 %2644, %2607
  %2646 = icmp ult i64 %2644, %2643
  %2647 = or i1 %2645, %2646
  %2648 = zext i1 %2647 to i8
  store i8 %2648, i8* %12, align 1
  %2649 = trunc i64 %2644 to i32
  %2650 = and i32 %2649, 255
  %2651 = tail call i32 @llvm.ctpop.i32(i32 %2650)
  %2652 = trunc i32 %2651 to i8
  %2653 = and i8 %2652, 1
  %2654 = xor i8 %2653, 1
  store i8 %2654, i8* %13, align 1
  %2655 = xor i64 %2607, %2644
  %2656 = lshr i64 %2655, 4
  %2657 = trunc i64 %2656 to i8
  %2658 = and i8 %2657, 1
  store i8 %2658, i8* %14, align 1
  %2659 = icmp eq i64 %2644, 0
  %2660 = zext i1 %2659 to i8
  store i8 %2660, i8* %15, align 1
  %2661 = lshr i64 %2644, 63
  %2662 = trunc i64 %2661 to i8
  store i8 %2662, i8* %16, align 1
  %2663 = lshr i64 %2642, 58
  %2664 = and i64 %2663, 1
  %2665 = xor i64 %2661, %2627
  %2666 = xor i64 %2661, %2664
  %2667 = add nuw nsw i64 %2665, %2666
  %2668 = icmp eq i64 %2667, 2
  %2669 = zext i1 %2668 to i8
  store i8 %2669, i8* %17, align 1
  %2670 = add i64 %2644, 24
  %2671 = add i64 %2601, 34
  store i64 %2671, i64* %3, align 8
  %2672 = inttoptr i64 %2670 to i32*
  %2673 = load i32, i32* %2672, align 4
  %2674 = add i32 %2673, %2638
  %2675 = zext i32 %2674 to i64
  store i64 %2675, i64* %RDI.i4084, align 8
  %2676 = icmp ult i32 %2674, %2638
  %2677 = icmp ult i32 %2674, %2673
  %2678 = or i1 %2676, %2677
  %2679 = zext i1 %2678 to i8
  store i8 %2679, i8* %12, align 1
  %2680 = and i32 %2674, 255
  %2681 = tail call i32 @llvm.ctpop.i32(i32 %2680)
  %2682 = trunc i32 %2681 to i8
  %2683 = and i8 %2682, 1
  %2684 = xor i8 %2683, 1
  store i8 %2684, i8* %13, align 1
  %2685 = xor i32 %2673, %2638
  %2686 = xor i32 %2685, %2674
  %2687 = lshr i32 %2686, 4
  %2688 = trunc i32 %2687 to i8
  %2689 = and i8 %2688, 1
  store i8 %2689, i8* %14, align 1
  %2690 = icmp eq i32 %2674, 0
  %2691 = zext i1 %2690 to i8
  store i8 %2691, i8* %15, align 1
  %2692 = lshr i32 %2674, 31
  %2693 = trunc i32 %2692 to i8
  store i8 %2693, i8* %16, align 1
  %2694 = lshr i32 %2638, 31
  %2695 = lshr i32 %2673, 31
  %2696 = xor i32 %2692, %2694
  %2697 = xor i32 %2692, %2695
  %2698 = add nuw nsw i32 %2696, %2697
  %2699 = icmp eq i32 %2698, 2
  %2700 = zext i1 %2699 to i8
  store i8 %2700, i8* %17, align 1
  %2701 = load i64, i64* %RBP.i, align 8
  %2702 = add i64 %2701, -508
  %2703 = add i64 %2601, 40
  store i64 %2703, i64* %3, align 8
  %2704 = inttoptr i64 %2702 to i32*
  store i32 %2674, i32* %2704, align 4
  %2705 = load i64, i64* %RBP.i, align 8
  %2706 = add i64 %2705, -24
  %2707 = load i64, i64* %3, align 8
  %2708 = add i64 %2707, 4
  store i64 %2708, i64* %3, align 8
  %2709 = inttoptr i64 %2706 to i32*
  %2710 = load i32, i32* %2709, align 4
  %2711 = sext i32 %2710 to i64
  %2712 = shl nsw i64 %2711, 5
  store i64 %2712, i64* %RDX.i4094, align 8
  %2713 = load i64, i64* %RCX.i3977, align 8
  %2714 = add i64 %2712, %2713
  store i64 %2714, i64* %RSI.i3950, align 8
  %2715 = icmp ult i64 %2714, %2713
  %2716 = icmp ult i64 %2714, %2712
  %2717 = or i1 %2715, %2716
  %2718 = zext i1 %2717 to i8
  store i8 %2718, i8* %12, align 1
  %2719 = trunc i64 %2714 to i32
  %2720 = and i32 %2719, 255
  %2721 = tail call i32 @llvm.ctpop.i32(i32 %2720)
  %2722 = trunc i32 %2721 to i8
  %2723 = and i8 %2722, 1
  %2724 = xor i8 %2723, 1
  store i8 %2724, i8* %13, align 1
  %2725 = xor i64 %2713, %2714
  %2726 = lshr i64 %2725, 4
  %2727 = trunc i64 %2726 to i8
  %2728 = and i8 %2727, 1
  store i8 %2728, i8* %14, align 1
  %2729 = icmp eq i64 %2714, 0
  %2730 = zext i1 %2729 to i8
  store i8 %2730, i8* %15, align 1
  %2731 = lshr i64 %2714, 63
  %2732 = trunc i64 %2731 to i8
  store i8 %2732, i8* %16, align 1
  %2733 = lshr i64 %2713, 63
  %2734 = lshr i64 %2711, 58
  %2735 = and i64 %2734, 1
  %2736 = xor i64 %2731, %2733
  %2737 = xor i64 %2731, %2735
  %2738 = add nuw nsw i64 %2736, %2737
  %2739 = icmp eq i64 %2738, 2
  %2740 = zext i1 %2739 to i8
  store i8 %2740, i8* %17, align 1
  %2741 = add i64 %2714, 8
  %2742 = add i64 %2707, 17
  store i64 %2742, i64* %3, align 8
  %2743 = inttoptr i64 %2741 to i32*
  %2744 = load i32, i32* %2743, align 4
  %2745 = zext i32 %2744 to i64
  store i64 %2745, i64* %RDI.i4084, align 8
  %2746 = add i64 %2707, 21
  store i64 %2746, i64* %3, align 8
  %2747 = load i32, i32* %2709, align 4
  %2748 = sext i32 %2747 to i64
  %2749 = shl nsw i64 %2748, 5
  store i64 %2749, i64* %RDX.i4094, align 8
  %2750 = add i64 %2749, %2713
  store i64 %2750, i64* %RSI.i3950, align 8
  %2751 = icmp ult i64 %2750, %2713
  %2752 = icmp ult i64 %2750, %2749
  %2753 = or i1 %2751, %2752
  %2754 = zext i1 %2753 to i8
  store i8 %2754, i8* %12, align 1
  %2755 = trunc i64 %2750 to i32
  %2756 = and i32 %2755, 255
  %2757 = tail call i32 @llvm.ctpop.i32(i32 %2756)
  %2758 = trunc i32 %2757 to i8
  %2759 = and i8 %2758, 1
  %2760 = xor i8 %2759, 1
  store i8 %2760, i8* %13, align 1
  %2761 = xor i64 %2713, %2750
  %2762 = lshr i64 %2761, 4
  %2763 = trunc i64 %2762 to i8
  %2764 = and i8 %2763, 1
  store i8 %2764, i8* %14, align 1
  %2765 = icmp eq i64 %2750, 0
  %2766 = zext i1 %2765 to i8
  store i8 %2766, i8* %15, align 1
  %2767 = lshr i64 %2750, 63
  %2768 = trunc i64 %2767 to i8
  store i8 %2768, i8* %16, align 1
  %2769 = lshr i64 %2748, 58
  %2770 = and i64 %2769, 1
  %2771 = xor i64 %2767, %2733
  %2772 = xor i64 %2767, %2770
  %2773 = add nuw nsw i64 %2771, %2772
  %2774 = icmp eq i64 %2773, 2
  %2775 = zext i1 %2774 to i8
  store i8 %2775, i8* %17, align 1
  %2776 = add i64 %2750, 20
  %2777 = add i64 %2707, 34
  store i64 %2777, i64* %3, align 8
  %2778 = inttoptr i64 %2776 to i32*
  %2779 = load i32, i32* %2778, align 4
  %2780 = add i32 %2779, %2744
  %2781 = zext i32 %2780 to i64
  store i64 %2781, i64* %RDI.i4084, align 8
  %2782 = icmp ult i32 %2780, %2744
  %2783 = icmp ult i32 %2780, %2779
  %2784 = or i1 %2782, %2783
  %2785 = zext i1 %2784 to i8
  store i8 %2785, i8* %12, align 1
  %2786 = and i32 %2780, 255
  %2787 = tail call i32 @llvm.ctpop.i32(i32 %2786)
  %2788 = trunc i32 %2787 to i8
  %2789 = and i8 %2788, 1
  %2790 = xor i8 %2789, 1
  store i8 %2790, i8* %13, align 1
  %2791 = xor i32 %2779, %2744
  %2792 = xor i32 %2791, %2780
  %2793 = lshr i32 %2792, 4
  %2794 = trunc i32 %2793 to i8
  %2795 = and i8 %2794, 1
  store i8 %2795, i8* %14, align 1
  %2796 = icmp eq i32 %2780, 0
  %2797 = zext i1 %2796 to i8
  store i8 %2797, i8* %15, align 1
  %2798 = lshr i32 %2780, 31
  %2799 = trunc i32 %2798 to i8
  store i8 %2799, i8* %16, align 1
  %2800 = lshr i32 %2744, 31
  %2801 = lshr i32 %2779, 31
  %2802 = xor i32 %2798, %2800
  %2803 = xor i32 %2798, %2801
  %2804 = add nuw nsw i32 %2802, %2803
  %2805 = icmp eq i32 %2804, 2
  %2806 = zext i1 %2805 to i8
  store i8 %2806, i8* %17, align 1
  %2807 = load i64, i64* %RBP.i, align 8
  %2808 = add i64 %2807, -504
  %2809 = add i64 %2707, 40
  store i64 %2809, i64* %3, align 8
  %2810 = inttoptr i64 %2808 to i32*
  store i32 %2780, i32* %2810, align 4
  %2811 = load i64, i64* %RBP.i, align 8
  %2812 = add i64 %2811, -24
  %2813 = load i64, i64* %3, align 8
  %2814 = add i64 %2813, 4
  store i64 %2814, i64* %3, align 8
  %2815 = inttoptr i64 %2812 to i32*
  %2816 = load i32, i32* %2815, align 4
  %2817 = sext i32 %2816 to i64
  %2818 = shl nsw i64 %2817, 5
  store i64 %2818, i64* %RDX.i4094, align 8
  %2819 = load i64, i64* %RCX.i3977, align 8
  %2820 = add i64 %2818, %2819
  store i64 %2820, i64* %RSI.i3950, align 8
  %2821 = icmp ult i64 %2820, %2819
  %2822 = icmp ult i64 %2820, %2818
  %2823 = or i1 %2821, %2822
  %2824 = zext i1 %2823 to i8
  store i8 %2824, i8* %12, align 1
  %2825 = trunc i64 %2820 to i32
  %2826 = and i32 %2825, 255
  %2827 = tail call i32 @llvm.ctpop.i32(i32 %2826)
  %2828 = trunc i32 %2827 to i8
  %2829 = and i8 %2828, 1
  %2830 = xor i8 %2829, 1
  store i8 %2830, i8* %13, align 1
  %2831 = xor i64 %2819, %2820
  %2832 = lshr i64 %2831, 4
  %2833 = trunc i64 %2832 to i8
  %2834 = and i8 %2833, 1
  store i8 %2834, i8* %14, align 1
  %2835 = icmp eq i64 %2820, 0
  %2836 = zext i1 %2835 to i8
  store i8 %2836, i8* %15, align 1
  %2837 = lshr i64 %2820, 63
  %2838 = trunc i64 %2837 to i8
  store i8 %2838, i8* %16, align 1
  %2839 = lshr i64 %2819, 63
  %2840 = lshr i64 %2817, 58
  %2841 = and i64 %2840, 1
  %2842 = xor i64 %2837, %2839
  %2843 = xor i64 %2837, %2841
  %2844 = add nuw nsw i64 %2842, %2843
  %2845 = icmp eq i64 %2844, 2
  %2846 = zext i1 %2845 to i8
  store i8 %2846, i8* %17, align 1
  %2847 = add i64 %2820, 12
  %2848 = add i64 %2813, 17
  store i64 %2848, i64* %3, align 8
  %2849 = inttoptr i64 %2847 to i32*
  %2850 = load i32, i32* %2849, align 4
  %2851 = zext i32 %2850 to i64
  store i64 %2851, i64* %RDI.i4084, align 8
  %2852 = add i64 %2813, 21
  store i64 %2852, i64* %3, align 8
  %2853 = load i32, i32* %2815, align 4
  %2854 = sext i32 %2853 to i64
  %2855 = shl nsw i64 %2854, 5
  store i64 %2855, i64* %RDX.i4094, align 8
  %2856 = add i64 %2855, %2819
  store i64 %2856, i64* %RSI.i3950, align 8
  %2857 = icmp ult i64 %2856, %2819
  %2858 = icmp ult i64 %2856, %2855
  %2859 = or i1 %2857, %2858
  %2860 = zext i1 %2859 to i8
  store i8 %2860, i8* %12, align 1
  %2861 = trunc i64 %2856 to i32
  %2862 = and i32 %2861, 255
  %2863 = tail call i32 @llvm.ctpop.i32(i32 %2862)
  %2864 = trunc i32 %2863 to i8
  %2865 = and i8 %2864, 1
  %2866 = xor i8 %2865, 1
  store i8 %2866, i8* %13, align 1
  %2867 = xor i64 %2819, %2856
  %2868 = lshr i64 %2867, 4
  %2869 = trunc i64 %2868 to i8
  %2870 = and i8 %2869, 1
  store i8 %2870, i8* %14, align 1
  %2871 = icmp eq i64 %2856, 0
  %2872 = zext i1 %2871 to i8
  store i8 %2872, i8* %15, align 1
  %2873 = lshr i64 %2856, 63
  %2874 = trunc i64 %2873 to i8
  store i8 %2874, i8* %16, align 1
  %2875 = lshr i64 %2854, 58
  %2876 = and i64 %2875, 1
  %2877 = xor i64 %2873, %2839
  %2878 = xor i64 %2873, %2876
  %2879 = add nuw nsw i64 %2877, %2878
  %2880 = icmp eq i64 %2879, 2
  %2881 = zext i1 %2880 to i8
  store i8 %2881, i8* %17, align 1
  %2882 = add i64 %2856, 16
  %2883 = add i64 %2813, 34
  store i64 %2883, i64* %3, align 8
  %2884 = inttoptr i64 %2882 to i32*
  %2885 = load i32, i32* %2884, align 4
  %2886 = add i32 %2885, %2850
  %2887 = zext i32 %2886 to i64
  store i64 %2887, i64* %RDI.i4084, align 8
  %2888 = icmp ult i32 %2886, %2850
  %2889 = icmp ult i32 %2886, %2885
  %2890 = or i1 %2888, %2889
  %2891 = zext i1 %2890 to i8
  store i8 %2891, i8* %12, align 1
  %2892 = and i32 %2886, 255
  %2893 = tail call i32 @llvm.ctpop.i32(i32 %2892)
  %2894 = trunc i32 %2893 to i8
  %2895 = and i8 %2894, 1
  %2896 = xor i8 %2895, 1
  store i8 %2896, i8* %13, align 1
  %2897 = xor i32 %2885, %2850
  %2898 = xor i32 %2897, %2886
  %2899 = lshr i32 %2898, 4
  %2900 = trunc i32 %2899 to i8
  %2901 = and i8 %2900, 1
  store i8 %2901, i8* %14, align 1
  %2902 = icmp eq i32 %2886, 0
  %2903 = zext i1 %2902 to i8
  store i8 %2903, i8* %15, align 1
  %2904 = lshr i32 %2886, 31
  %2905 = trunc i32 %2904 to i8
  store i8 %2905, i8* %16, align 1
  %2906 = lshr i32 %2850, 31
  %2907 = lshr i32 %2885, 31
  %2908 = xor i32 %2904, %2906
  %2909 = xor i32 %2904, %2907
  %2910 = add nuw nsw i32 %2908, %2909
  %2911 = icmp eq i32 %2910, 2
  %2912 = zext i1 %2911 to i8
  store i8 %2912, i8* %17, align 1
  %2913 = load i64, i64* %RBP.i, align 8
  %2914 = add i64 %2913, -500
  %2915 = add i64 %2813, 40
  store i64 %2915, i64* %3, align 8
  %2916 = inttoptr i64 %2914 to i32*
  store i32 %2886, i32* %2916, align 4
  %2917 = load i64, i64* %RBP.i, align 8
  %2918 = add i64 %2917, -512
  %2919 = load i64, i64* %3, align 8
  %2920 = add i64 %2919, 6
  store i64 %2920, i64* %3, align 8
  %2921 = inttoptr i64 %2918 to i32*
  %2922 = load i32, i32* %2921, align 4
  %2923 = zext i32 %2922 to i64
  store i64 %2923, i64* %RDI.i4084, align 8
  %2924 = add i64 %2917, -500
  %2925 = add i64 %2919, 12
  store i64 %2925, i64* %3, align 8
  %2926 = inttoptr i64 %2924 to i32*
  %2927 = load i32, i32* %2926, align 4
  %2928 = add i32 %2927, %2922
  %2929 = zext i32 %2928 to i64
  store i64 %2929, i64* %RDI.i4084, align 8
  %2930 = icmp ult i32 %2928, %2922
  %2931 = icmp ult i32 %2928, %2927
  %2932 = or i1 %2930, %2931
  %2933 = zext i1 %2932 to i8
  store i8 %2933, i8* %12, align 1
  %2934 = and i32 %2928, 255
  %2935 = tail call i32 @llvm.ctpop.i32(i32 %2934)
  %2936 = trunc i32 %2935 to i8
  %2937 = and i8 %2936, 1
  %2938 = xor i8 %2937, 1
  store i8 %2938, i8* %13, align 1
  %2939 = xor i32 %2927, %2922
  %2940 = xor i32 %2939, %2928
  %2941 = lshr i32 %2940, 4
  %2942 = trunc i32 %2941 to i8
  %2943 = and i8 %2942, 1
  store i8 %2943, i8* %14, align 1
  %2944 = icmp eq i32 %2928, 0
  %2945 = zext i1 %2944 to i8
  store i8 %2945, i8* %15, align 1
  %2946 = lshr i32 %2928, 31
  %2947 = trunc i32 %2946 to i8
  store i8 %2947, i8* %16, align 1
  %2948 = lshr i32 %2922, 31
  %2949 = lshr i32 %2927, 31
  %2950 = xor i32 %2946, %2948
  %2951 = xor i32 %2946, %2949
  %2952 = add nuw nsw i32 %2950, %2951
  %2953 = icmp eq i32 %2952, 2
  %2954 = zext i1 %2953 to i8
  store i8 %2954, i8* %17, align 1
  %2955 = add i64 %2917, -544
  %2956 = add i64 %2919, 18
  store i64 %2956, i64* %3, align 8
  %2957 = inttoptr i64 %2955 to i32*
  store i32 %2928, i32* %2957, align 4
  %2958 = load i64, i64* %RBP.i, align 8
  %2959 = add i64 %2958, -508
  %2960 = load i64, i64* %3, align 8
  %2961 = add i64 %2960, 6
  store i64 %2961, i64* %3, align 8
  %2962 = inttoptr i64 %2959 to i32*
  %2963 = load i32, i32* %2962, align 4
  %2964 = zext i32 %2963 to i64
  store i64 %2964, i64* %RDI.i4084, align 8
  %2965 = add i64 %2958, -504
  %2966 = add i64 %2960, 12
  store i64 %2966, i64* %3, align 8
  %2967 = inttoptr i64 %2965 to i32*
  %2968 = load i32, i32* %2967, align 4
  %2969 = add i32 %2968, %2963
  %2970 = zext i32 %2969 to i64
  store i64 %2970, i64* %RDI.i4084, align 8
  %2971 = icmp ult i32 %2969, %2963
  %2972 = icmp ult i32 %2969, %2968
  %2973 = or i1 %2971, %2972
  %2974 = zext i1 %2973 to i8
  store i8 %2974, i8* %12, align 1
  %2975 = and i32 %2969, 255
  %2976 = tail call i32 @llvm.ctpop.i32(i32 %2975)
  %2977 = trunc i32 %2976 to i8
  %2978 = and i8 %2977, 1
  %2979 = xor i8 %2978, 1
  store i8 %2979, i8* %13, align 1
  %2980 = xor i32 %2968, %2963
  %2981 = xor i32 %2980, %2969
  %2982 = lshr i32 %2981, 4
  %2983 = trunc i32 %2982 to i8
  %2984 = and i8 %2983, 1
  store i8 %2984, i8* %14, align 1
  %2985 = icmp eq i32 %2969, 0
  %2986 = zext i1 %2985 to i8
  store i8 %2986, i8* %15, align 1
  %2987 = lshr i32 %2969, 31
  %2988 = trunc i32 %2987 to i8
  store i8 %2988, i8* %16, align 1
  %2989 = lshr i32 %2963, 31
  %2990 = lshr i32 %2968, 31
  %2991 = xor i32 %2987, %2989
  %2992 = xor i32 %2987, %2990
  %2993 = add nuw nsw i32 %2991, %2992
  %2994 = icmp eq i32 %2993, 2
  %2995 = zext i1 %2994 to i8
  store i8 %2995, i8* %17, align 1
  %2996 = add i64 %2958, -540
  %2997 = add i64 %2960, 18
  store i64 %2997, i64* %3, align 8
  %2998 = inttoptr i64 %2996 to i32*
  store i32 %2969, i32* %2998, align 4
  %2999 = load i64, i64* %RBP.i, align 8
  %3000 = add i64 %2999, -512
  %3001 = load i64, i64* %3, align 8
  %3002 = add i64 %3001, 6
  store i64 %3002, i64* %3, align 8
  %3003 = inttoptr i64 %3000 to i32*
  %3004 = load i32, i32* %3003, align 4
  %3005 = zext i32 %3004 to i64
  store i64 %3005, i64* %RDI.i4084, align 8
  %3006 = add i64 %2999, -500
  %3007 = add i64 %3001, 12
  store i64 %3007, i64* %3, align 8
  %3008 = inttoptr i64 %3006 to i32*
  %3009 = load i32, i32* %3008, align 4
  %3010 = sub i32 %3004, %3009
  %3011 = zext i32 %3010 to i64
  store i64 %3011, i64* %RDI.i4084, align 8
  %3012 = icmp ult i32 %3004, %3009
  %3013 = zext i1 %3012 to i8
  store i8 %3013, i8* %12, align 1
  %3014 = and i32 %3010, 255
  %3015 = tail call i32 @llvm.ctpop.i32(i32 %3014)
  %3016 = trunc i32 %3015 to i8
  %3017 = and i8 %3016, 1
  %3018 = xor i8 %3017, 1
  store i8 %3018, i8* %13, align 1
  %3019 = xor i32 %3009, %3004
  %3020 = xor i32 %3019, %3010
  %3021 = lshr i32 %3020, 4
  %3022 = trunc i32 %3021 to i8
  %3023 = and i8 %3022, 1
  store i8 %3023, i8* %14, align 1
  %3024 = icmp eq i32 %3010, 0
  %3025 = zext i1 %3024 to i8
  store i8 %3025, i8* %15, align 1
  %3026 = lshr i32 %3010, 31
  %3027 = trunc i32 %3026 to i8
  store i8 %3027, i8* %16, align 1
  %3028 = lshr i32 %3004, 31
  %3029 = lshr i32 %3009, 31
  %3030 = xor i32 %3029, %3028
  %3031 = xor i32 %3026, %3028
  %3032 = add nuw nsw i32 %3031, %3030
  %3033 = icmp eq i32 %3032, 2
  %3034 = zext i1 %3033 to i8
  store i8 %3034, i8* %17, align 1
  %3035 = add i64 %2999, -536
  %3036 = add i64 %3001, 18
  store i64 %3036, i64* %3, align 8
  %3037 = inttoptr i64 %3035 to i32*
  store i32 %3010, i32* %3037, align 4
  %3038 = load i64, i64* %RBP.i, align 8
  %3039 = add i64 %3038, -508
  %3040 = load i64, i64* %3, align 8
  %3041 = add i64 %3040, 6
  store i64 %3041, i64* %3, align 8
  %3042 = inttoptr i64 %3039 to i32*
  %3043 = load i32, i32* %3042, align 4
  %3044 = zext i32 %3043 to i64
  store i64 %3044, i64* %RDI.i4084, align 8
  %3045 = add i64 %3038, -504
  %3046 = add i64 %3040, 12
  store i64 %3046, i64* %3, align 8
  %3047 = inttoptr i64 %3045 to i32*
  %3048 = load i32, i32* %3047, align 4
  %3049 = sub i32 %3043, %3048
  %3050 = zext i32 %3049 to i64
  store i64 %3050, i64* %RDI.i4084, align 8
  %3051 = icmp ult i32 %3043, %3048
  %3052 = zext i1 %3051 to i8
  store i8 %3052, i8* %12, align 1
  %3053 = and i32 %3049, 255
  %3054 = tail call i32 @llvm.ctpop.i32(i32 %3053)
  %3055 = trunc i32 %3054 to i8
  %3056 = and i8 %3055, 1
  %3057 = xor i8 %3056, 1
  store i8 %3057, i8* %13, align 1
  %3058 = xor i32 %3048, %3043
  %3059 = xor i32 %3058, %3049
  %3060 = lshr i32 %3059, 4
  %3061 = trunc i32 %3060 to i8
  %3062 = and i8 %3061, 1
  store i8 %3062, i8* %14, align 1
  %3063 = icmp eq i32 %3049, 0
  %3064 = zext i1 %3063 to i8
  store i8 %3064, i8* %15, align 1
  %3065 = lshr i32 %3049, 31
  %3066 = trunc i32 %3065 to i8
  store i8 %3066, i8* %16, align 1
  %3067 = lshr i32 %3043, 31
  %3068 = lshr i32 %3048, 31
  %3069 = xor i32 %3068, %3067
  %3070 = xor i32 %3065, %3067
  %3071 = add nuw nsw i32 %3070, %3069
  %3072 = icmp eq i32 %3071, 2
  %3073 = zext i1 %3072 to i8
  store i8 %3073, i8* %17, align 1
  %3074 = add i64 %3038, -532
  %3075 = add i64 %3040, 18
  store i64 %3075, i64* %3, align 8
  %3076 = inttoptr i64 %3074 to i32*
  store i32 %3049, i32* %3076, align 4
  %3077 = load i64, i64* %RBP.i, align 8
  %3078 = add i64 %3077, -24
  %3079 = load i64, i64* %3, align 8
  %3080 = add i64 %3079, 4
  store i64 %3080, i64* %3, align 8
  %3081 = inttoptr i64 %3078 to i32*
  %3082 = load i32, i32* %3081, align 4
  %3083 = sext i32 %3082 to i64
  %3084 = shl nsw i64 %3083, 5
  store i64 %3084, i64* %RDX.i4094, align 8
  %3085 = load i64, i64* %RCX.i3977, align 8
  %3086 = add i64 %3084, %3085
  store i64 %3086, i64* %RSI.i3950, align 8
  %3087 = icmp ult i64 %3086, %3085
  %3088 = icmp ult i64 %3086, %3084
  %3089 = or i1 %3087, %3088
  %3090 = zext i1 %3089 to i8
  store i8 %3090, i8* %12, align 1
  %3091 = trunc i64 %3086 to i32
  %3092 = and i32 %3091, 255
  %3093 = tail call i32 @llvm.ctpop.i32(i32 %3092)
  %3094 = trunc i32 %3093 to i8
  %3095 = and i8 %3094, 1
  %3096 = xor i8 %3095, 1
  store i8 %3096, i8* %13, align 1
  %3097 = xor i64 %3085, %3086
  %3098 = lshr i64 %3097, 4
  %3099 = trunc i64 %3098 to i8
  %3100 = and i8 %3099, 1
  store i8 %3100, i8* %14, align 1
  %3101 = icmp eq i64 %3086, 0
  %3102 = zext i1 %3101 to i8
  store i8 %3102, i8* %15, align 1
  %3103 = lshr i64 %3086, 63
  %3104 = trunc i64 %3103 to i8
  store i8 %3104, i8* %16, align 1
  %3105 = lshr i64 %3085, 63
  %3106 = lshr i64 %3083, 58
  %3107 = and i64 %3106, 1
  %3108 = xor i64 %3103, %3105
  %3109 = xor i64 %3103, %3107
  %3110 = add nuw nsw i64 %3108, %3109
  %3111 = icmp eq i64 %3110, 2
  %3112 = zext i1 %3111 to i8
  store i8 %3112, i8* %17, align 1
  %3113 = inttoptr i64 %3086 to i32*
  %3114 = add i64 %3079, 16
  store i64 %3114, i64* %3, align 8
  %3115 = load i32, i32* %3113, align 4
  %3116 = zext i32 %3115 to i64
  store i64 %3116, i64* %RDI.i4084, align 8
  %3117 = add i64 %3079, 20
  store i64 %3117, i64* %3, align 8
  %3118 = load i32, i32* %3081, align 4
  %3119 = sext i32 %3118 to i64
  %3120 = shl nsw i64 %3119, 5
  store i64 %3120, i64* %RDX.i4094, align 8
  %3121 = add i64 %3120, %3085
  store i64 %3121, i64* %RSI.i3950, align 8
  %3122 = icmp ult i64 %3121, %3085
  %3123 = icmp ult i64 %3121, %3120
  %3124 = or i1 %3122, %3123
  %3125 = zext i1 %3124 to i8
  store i8 %3125, i8* %12, align 1
  %3126 = trunc i64 %3121 to i32
  %3127 = and i32 %3126, 255
  %3128 = tail call i32 @llvm.ctpop.i32(i32 %3127)
  %3129 = trunc i32 %3128 to i8
  %3130 = and i8 %3129, 1
  %3131 = xor i8 %3130, 1
  store i8 %3131, i8* %13, align 1
  %3132 = xor i64 %3085, %3121
  %3133 = lshr i64 %3132, 4
  %3134 = trunc i64 %3133 to i8
  %3135 = and i8 %3134, 1
  store i8 %3135, i8* %14, align 1
  %3136 = icmp eq i64 %3121, 0
  %3137 = zext i1 %3136 to i8
  store i8 %3137, i8* %15, align 1
  %3138 = lshr i64 %3121, 63
  %3139 = trunc i64 %3138 to i8
  store i8 %3139, i8* %16, align 1
  %3140 = lshr i64 %3119, 58
  %3141 = and i64 %3140, 1
  %3142 = xor i64 %3138, %3105
  %3143 = xor i64 %3138, %3141
  %3144 = add nuw nsw i64 %3142, %3143
  %3145 = icmp eq i64 %3144, 2
  %3146 = zext i1 %3145 to i8
  store i8 %3146, i8* %17, align 1
  %3147 = add i64 %3121, 28
  %3148 = add i64 %3079, 33
  store i64 %3148, i64* %3, align 8
  %3149 = inttoptr i64 %3147 to i32*
  %3150 = load i32, i32* %3149, align 4
  %3151 = sub i32 %3115, %3150
  %3152 = zext i32 %3151 to i64
  store i64 %3152, i64* %RDI.i4084, align 8
  %3153 = icmp ult i32 %3115, %3150
  %3154 = zext i1 %3153 to i8
  store i8 %3154, i8* %12, align 1
  %3155 = and i32 %3151, 255
  %3156 = tail call i32 @llvm.ctpop.i32(i32 %3155)
  %3157 = trunc i32 %3156 to i8
  %3158 = and i8 %3157, 1
  %3159 = xor i8 %3158, 1
  store i8 %3159, i8* %13, align 1
  %3160 = xor i32 %3150, %3115
  %3161 = xor i32 %3160, %3151
  %3162 = lshr i32 %3161, 4
  %3163 = trunc i32 %3162 to i8
  %3164 = and i8 %3163, 1
  store i8 %3164, i8* %14, align 1
  %3165 = icmp eq i32 %3151, 0
  %3166 = zext i1 %3165 to i8
  store i8 %3166, i8* %15, align 1
  %3167 = lshr i32 %3151, 31
  %3168 = trunc i32 %3167 to i8
  store i8 %3168, i8* %16, align 1
  %3169 = lshr i32 %3115, 31
  %3170 = lshr i32 %3150, 31
  %3171 = xor i32 %3170, %3169
  %3172 = xor i32 %3167, %3169
  %3173 = add nuw nsw i32 %3172, %3171
  %3174 = icmp eq i32 %3173, 2
  %3175 = zext i1 %3174 to i8
  store i8 %3175, i8* %17, align 1
  %3176 = load i64, i64* %RBP.i, align 8
  %3177 = add i64 %3176, -496
  %3178 = add i64 %3079, 39
  store i64 %3178, i64* %3, align 8
  %3179 = inttoptr i64 %3177 to i32*
  store i32 %3151, i32* %3179, align 4
  %3180 = load i64, i64* %RBP.i, align 8
  %3181 = add i64 %3180, -24
  %3182 = load i64, i64* %3, align 8
  %3183 = add i64 %3182, 4
  store i64 %3183, i64* %3, align 8
  %3184 = inttoptr i64 %3181 to i32*
  %3185 = load i32, i32* %3184, align 4
  %3186 = sext i32 %3185 to i64
  %3187 = shl nsw i64 %3186, 5
  store i64 %3187, i64* %RDX.i4094, align 8
  %3188 = load i64, i64* %RCX.i3977, align 8
  %3189 = add i64 %3187, %3188
  store i64 %3189, i64* %RSI.i3950, align 8
  %3190 = icmp ult i64 %3189, %3188
  %3191 = icmp ult i64 %3189, %3187
  %3192 = or i1 %3190, %3191
  %3193 = zext i1 %3192 to i8
  store i8 %3193, i8* %12, align 1
  %3194 = trunc i64 %3189 to i32
  %3195 = and i32 %3194, 255
  %3196 = tail call i32 @llvm.ctpop.i32(i32 %3195)
  %3197 = trunc i32 %3196 to i8
  %3198 = and i8 %3197, 1
  %3199 = xor i8 %3198, 1
  store i8 %3199, i8* %13, align 1
  %3200 = xor i64 %3188, %3189
  %3201 = lshr i64 %3200, 4
  %3202 = trunc i64 %3201 to i8
  %3203 = and i8 %3202, 1
  store i8 %3203, i8* %14, align 1
  %3204 = icmp eq i64 %3189, 0
  %3205 = zext i1 %3204 to i8
  store i8 %3205, i8* %15, align 1
  %3206 = lshr i64 %3189, 63
  %3207 = trunc i64 %3206 to i8
  store i8 %3207, i8* %16, align 1
  %3208 = lshr i64 %3188, 63
  %3209 = lshr i64 %3186, 58
  %3210 = and i64 %3209, 1
  %3211 = xor i64 %3206, %3208
  %3212 = xor i64 %3206, %3210
  %3213 = add nuw nsw i64 %3211, %3212
  %3214 = icmp eq i64 %3213, 2
  %3215 = zext i1 %3214 to i8
  store i8 %3215, i8* %17, align 1
  %3216 = add i64 %3189, 4
  %3217 = add i64 %3182, 17
  store i64 %3217, i64* %3, align 8
  %3218 = inttoptr i64 %3216 to i32*
  %3219 = load i32, i32* %3218, align 4
  %3220 = zext i32 %3219 to i64
  store i64 %3220, i64* %RDI.i4084, align 8
  %3221 = add i64 %3182, 21
  store i64 %3221, i64* %3, align 8
  %3222 = load i32, i32* %3184, align 4
  %3223 = sext i32 %3222 to i64
  %3224 = shl nsw i64 %3223, 5
  store i64 %3224, i64* %RDX.i4094, align 8
  %3225 = add i64 %3224, %3188
  store i64 %3225, i64* %RSI.i3950, align 8
  %3226 = icmp ult i64 %3225, %3188
  %3227 = icmp ult i64 %3225, %3224
  %3228 = or i1 %3226, %3227
  %3229 = zext i1 %3228 to i8
  store i8 %3229, i8* %12, align 1
  %3230 = trunc i64 %3225 to i32
  %3231 = and i32 %3230, 255
  %3232 = tail call i32 @llvm.ctpop.i32(i32 %3231)
  %3233 = trunc i32 %3232 to i8
  %3234 = and i8 %3233, 1
  %3235 = xor i8 %3234, 1
  store i8 %3235, i8* %13, align 1
  %3236 = xor i64 %3188, %3225
  %3237 = lshr i64 %3236, 4
  %3238 = trunc i64 %3237 to i8
  %3239 = and i8 %3238, 1
  store i8 %3239, i8* %14, align 1
  %3240 = icmp eq i64 %3225, 0
  %3241 = zext i1 %3240 to i8
  store i8 %3241, i8* %15, align 1
  %3242 = lshr i64 %3225, 63
  %3243 = trunc i64 %3242 to i8
  store i8 %3243, i8* %16, align 1
  %3244 = lshr i64 %3223, 58
  %3245 = and i64 %3244, 1
  %3246 = xor i64 %3242, %3208
  %3247 = xor i64 %3242, %3245
  %3248 = add nuw nsw i64 %3246, %3247
  %3249 = icmp eq i64 %3248, 2
  %3250 = zext i1 %3249 to i8
  store i8 %3250, i8* %17, align 1
  %3251 = add i64 %3225, 24
  %3252 = add i64 %3182, 34
  store i64 %3252, i64* %3, align 8
  %3253 = inttoptr i64 %3251 to i32*
  %3254 = load i32, i32* %3253, align 4
  %3255 = sub i32 %3219, %3254
  %3256 = zext i32 %3255 to i64
  store i64 %3256, i64* %RDI.i4084, align 8
  %3257 = icmp ult i32 %3219, %3254
  %3258 = zext i1 %3257 to i8
  store i8 %3258, i8* %12, align 1
  %3259 = and i32 %3255, 255
  %3260 = tail call i32 @llvm.ctpop.i32(i32 %3259)
  %3261 = trunc i32 %3260 to i8
  %3262 = and i8 %3261, 1
  %3263 = xor i8 %3262, 1
  store i8 %3263, i8* %13, align 1
  %3264 = xor i32 %3254, %3219
  %3265 = xor i32 %3264, %3255
  %3266 = lshr i32 %3265, 4
  %3267 = trunc i32 %3266 to i8
  %3268 = and i8 %3267, 1
  store i8 %3268, i8* %14, align 1
  %3269 = icmp eq i32 %3255, 0
  %3270 = zext i1 %3269 to i8
  store i8 %3270, i8* %15, align 1
  %3271 = lshr i32 %3255, 31
  %3272 = trunc i32 %3271 to i8
  store i8 %3272, i8* %16, align 1
  %3273 = lshr i32 %3219, 31
  %3274 = lshr i32 %3254, 31
  %3275 = xor i32 %3274, %3273
  %3276 = xor i32 %3271, %3273
  %3277 = add nuw nsw i32 %3276, %3275
  %3278 = icmp eq i32 %3277, 2
  %3279 = zext i1 %3278 to i8
  store i8 %3279, i8* %17, align 1
  %3280 = load i64, i64* %RBP.i, align 8
  %3281 = add i64 %3280, -492
  %3282 = add i64 %3182, 40
  store i64 %3282, i64* %3, align 8
  %3283 = inttoptr i64 %3281 to i32*
  store i32 %3255, i32* %3283, align 4
  %3284 = load i64, i64* %RBP.i, align 8
  %3285 = add i64 %3284, -24
  %3286 = load i64, i64* %3, align 8
  %3287 = add i64 %3286, 4
  store i64 %3287, i64* %3, align 8
  %3288 = inttoptr i64 %3285 to i32*
  %3289 = load i32, i32* %3288, align 4
  %3290 = sext i32 %3289 to i64
  %3291 = shl nsw i64 %3290, 5
  store i64 %3291, i64* %RDX.i4094, align 8
  %3292 = load i64, i64* %RCX.i3977, align 8
  %3293 = add i64 %3291, %3292
  store i64 %3293, i64* %RSI.i3950, align 8
  %3294 = icmp ult i64 %3293, %3292
  %3295 = icmp ult i64 %3293, %3291
  %3296 = or i1 %3294, %3295
  %3297 = zext i1 %3296 to i8
  store i8 %3297, i8* %12, align 1
  %3298 = trunc i64 %3293 to i32
  %3299 = and i32 %3298, 255
  %3300 = tail call i32 @llvm.ctpop.i32(i32 %3299)
  %3301 = trunc i32 %3300 to i8
  %3302 = and i8 %3301, 1
  %3303 = xor i8 %3302, 1
  store i8 %3303, i8* %13, align 1
  %3304 = xor i64 %3292, %3293
  %3305 = lshr i64 %3304, 4
  %3306 = trunc i64 %3305 to i8
  %3307 = and i8 %3306, 1
  store i8 %3307, i8* %14, align 1
  %3308 = icmp eq i64 %3293, 0
  %3309 = zext i1 %3308 to i8
  store i8 %3309, i8* %15, align 1
  %3310 = lshr i64 %3293, 63
  %3311 = trunc i64 %3310 to i8
  store i8 %3311, i8* %16, align 1
  %3312 = lshr i64 %3292, 63
  %3313 = lshr i64 %3290, 58
  %3314 = and i64 %3313, 1
  %3315 = xor i64 %3310, %3312
  %3316 = xor i64 %3310, %3314
  %3317 = add nuw nsw i64 %3315, %3316
  %3318 = icmp eq i64 %3317, 2
  %3319 = zext i1 %3318 to i8
  store i8 %3319, i8* %17, align 1
  %3320 = add i64 %3293, 8
  %3321 = add i64 %3286, 17
  store i64 %3321, i64* %3, align 8
  %3322 = inttoptr i64 %3320 to i32*
  %3323 = load i32, i32* %3322, align 4
  %3324 = zext i32 %3323 to i64
  store i64 %3324, i64* %RDI.i4084, align 8
  %3325 = add i64 %3286, 21
  store i64 %3325, i64* %3, align 8
  %3326 = load i32, i32* %3288, align 4
  %3327 = sext i32 %3326 to i64
  %3328 = shl nsw i64 %3327, 5
  store i64 %3328, i64* %RDX.i4094, align 8
  %3329 = add i64 %3328, %3292
  store i64 %3329, i64* %RSI.i3950, align 8
  %3330 = icmp ult i64 %3329, %3292
  %3331 = icmp ult i64 %3329, %3328
  %3332 = or i1 %3330, %3331
  %3333 = zext i1 %3332 to i8
  store i8 %3333, i8* %12, align 1
  %3334 = trunc i64 %3329 to i32
  %3335 = and i32 %3334, 255
  %3336 = tail call i32 @llvm.ctpop.i32(i32 %3335)
  %3337 = trunc i32 %3336 to i8
  %3338 = and i8 %3337, 1
  %3339 = xor i8 %3338, 1
  store i8 %3339, i8* %13, align 1
  %3340 = xor i64 %3292, %3329
  %3341 = lshr i64 %3340, 4
  %3342 = trunc i64 %3341 to i8
  %3343 = and i8 %3342, 1
  store i8 %3343, i8* %14, align 1
  %3344 = icmp eq i64 %3329, 0
  %3345 = zext i1 %3344 to i8
  store i8 %3345, i8* %15, align 1
  %3346 = lshr i64 %3329, 63
  %3347 = trunc i64 %3346 to i8
  store i8 %3347, i8* %16, align 1
  %3348 = lshr i64 %3327, 58
  %3349 = and i64 %3348, 1
  %3350 = xor i64 %3346, %3312
  %3351 = xor i64 %3346, %3349
  %3352 = add nuw nsw i64 %3350, %3351
  %3353 = icmp eq i64 %3352, 2
  %3354 = zext i1 %3353 to i8
  store i8 %3354, i8* %17, align 1
  %3355 = add i64 %3329, 20
  %3356 = add i64 %3286, 34
  store i64 %3356, i64* %3, align 8
  %3357 = inttoptr i64 %3355 to i32*
  %3358 = load i32, i32* %3357, align 4
  %3359 = sub i32 %3323, %3358
  %3360 = zext i32 %3359 to i64
  store i64 %3360, i64* %RDI.i4084, align 8
  %3361 = icmp ult i32 %3323, %3358
  %3362 = zext i1 %3361 to i8
  store i8 %3362, i8* %12, align 1
  %3363 = and i32 %3359, 255
  %3364 = tail call i32 @llvm.ctpop.i32(i32 %3363)
  %3365 = trunc i32 %3364 to i8
  %3366 = and i8 %3365, 1
  %3367 = xor i8 %3366, 1
  store i8 %3367, i8* %13, align 1
  %3368 = xor i32 %3358, %3323
  %3369 = xor i32 %3368, %3359
  %3370 = lshr i32 %3369, 4
  %3371 = trunc i32 %3370 to i8
  %3372 = and i8 %3371, 1
  store i8 %3372, i8* %14, align 1
  %3373 = icmp eq i32 %3359, 0
  %3374 = zext i1 %3373 to i8
  store i8 %3374, i8* %15, align 1
  %3375 = lshr i32 %3359, 31
  %3376 = trunc i32 %3375 to i8
  store i8 %3376, i8* %16, align 1
  %3377 = lshr i32 %3323, 31
  %3378 = lshr i32 %3358, 31
  %3379 = xor i32 %3378, %3377
  %3380 = xor i32 %3375, %3377
  %3381 = add nuw nsw i32 %3380, %3379
  %3382 = icmp eq i32 %3381, 2
  %3383 = zext i1 %3382 to i8
  store i8 %3383, i8* %17, align 1
  %3384 = load i64, i64* %RBP.i, align 8
  %3385 = add i64 %3384, -488
  %3386 = add i64 %3286, 40
  store i64 %3386, i64* %3, align 8
  %3387 = inttoptr i64 %3385 to i32*
  store i32 %3359, i32* %3387, align 4
  %3388 = load i64, i64* %RBP.i, align 8
  %3389 = add i64 %3388, -24
  %3390 = load i64, i64* %3, align 8
  %3391 = add i64 %3390, 4
  store i64 %3391, i64* %3, align 8
  %3392 = inttoptr i64 %3389 to i32*
  %3393 = load i32, i32* %3392, align 4
  %3394 = sext i32 %3393 to i64
  %3395 = shl nsw i64 %3394, 5
  store i64 %3395, i64* %RDX.i4094, align 8
  %3396 = load i64, i64* %RCX.i3977, align 8
  %3397 = add i64 %3395, %3396
  store i64 %3397, i64* %RSI.i3950, align 8
  %3398 = icmp ult i64 %3397, %3396
  %3399 = icmp ult i64 %3397, %3395
  %3400 = or i1 %3398, %3399
  %3401 = zext i1 %3400 to i8
  store i8 %3401, i8* %12, align 1
  %3402 = trunc i64 %3397 to i32
  %3403 = and i32 %3402, 255
  %3404 = tail call i32 @llvm.ctpop.i32(i32 %3403)
  %3405 = trunc i32 %3404 to i8
  %3406 = and i8 %3405, 1
  %3407 = xor i8 %3406, 1
  store i8 %3407, i8* %13, align 1
  %3408 = xor i64 %3396, %3397
  %3409 = lshr i64 %3408, 4
  %3410 = trunc i64 %3409 to i8
  %3411 = and i8 %3410, 1
  store i8 %3411, i8* %14, align 1
  %3412 = icmp eq i64 %3397, 0
  %3413 = zext i1 %3412 to i8
  store i8 %3413, i8* %15, align 1
  %3414 = lshr i64 %3397, 63
  %3415 = trunc i64 %3414 to i8
  store i8 %3415, i8* %16, align 1
  %3416 = lshr i64 %3396, 63
  %3417 = lshr i64 %3394, 58
  %3418 = and i64 %3417, 1
  %3419 = xor i64 %3414, %3416
  %3420 = xor i64 %3414, %3418
  %3421 = add nuw nsw i64 %3419, %3420
  %3422 = icmp eq i64 %3421, 2
  %3423 = zext i1 %3422 to i8
  store i8 %3423, i8* %17, align 1
  %3424 = add i64 %3397, 12
  %3425 = add i64 %3390, 17
  store i64 %3425, i64* %3, align 8
  %3426 = inttoptr i64 %3424 to i32*
  %3427 = load i32, i32* %3426, align 4
  %3428 = zext i32 %3427 to i64
  store i64 %3428, i64* %RDI.i4084, align 8
  %3429 = add i64 %3390, 21
  store i64 %3429, i64* %3, align 8
  %3430 = load i32, i32* %3392, align 4
  %3431 = sext i32 %3430 to i64
  %3432 = shl nsw i64 %3431, 5
  store i64 %3432, i64* %RDX.i4094, align 8
  %3433 = add i64 %3432, %3396
  store i64 %3433, i64* %RCX.i3977, align 8
  %3434 = icmp ult i64 %3433, %3396
  %3435 = icmp ult i64 %3433, %3432
  %3436 = or i1 %3434, %3435
  %3437 = zext i1 %3436 to i8
  store i8 %3437, i8* %12, align 1
  %3438 = trunc i64 %3433 to i32
  %3439 = and i32 %3438, 255
  %3440 = tail call i32 @llvm.ctpop.i32(i32 %3439)
  %3441 = trunc i32 %3440 to i8
  %3442 = and i8 %3441, 1
  %3443 = xor i8 %3442, 1
  store i8 %3443, i8* %13, align 1
  %3444 = xor i64 %3396, %3433
  %3445 = lshr i64 %3444, 4
  %3446 = trunc i64 %3445 to i8
  %3447 = and i8 %3446, 1
  store i8 %3447, i8* %14, align 1
  %3448 = icmp eq i64 %3433, 0
  %3449 = zext i1 %3448 to i8
  store i8 %3449, i8* %15, align 1
  %3450 = lshr i64 %3433, 63
  %3451 = trunc i64 %3450 to i8
  store i8 %3451, i8* %16, align 1
  %3452 = lshr i64 %3431, 58
  %3453 = and i64 %3452, 1
  %3454 = xor i64 %3450, %3416
  %3455 = xor i64 %3450, %3453
  %3456 = add nuw nsw i64 %3454, %3455
  %3457 = icmp eq i64 %3456, 2
  %3458 = zext i1 %3457 to i8
  store i8 %3458, i8* %17, align 1
  %3459 = add i64 %3433, 16
  %3460 = add i64 %3390, 31
  store i64 %3460, i64* %3, align 8
  %3461 = inttoptr i64 %3459 to i32*
  %3462 = load i32, i32* %3461, align 4
  %3463 = sub i32 %3427, %3462
  %3464 = zext i32 %3463 to i64
  store i64 %3464, i64* %RDI.i4084, align 8
  %3465 = icmp ult i32 %3427, %3462
  %3466 = zext i1 %3465 to i8
  store i8 %3466, i8* %12, align 1
  %3467 = and i32 %3463, 255
  %3468 = tail call i32 @llvm.ctpop.i32(i32 %3467)
  %3469 = trunc i32 %3468 to i8
  %3470 = and i8 %3469, 1
  %3471 = xor i8 %3470, 1
  store i8 %3471, i8* %13, align 1
  %3472 = xor i32 %3462, %3427
  %3473 = xor i32 %3472, %3463
  %3474 = lshr i32 %3473, 4
  %3475 = trunc i32 %3474 to i8
  %3476 = and i8 %3475, 1
  store i8 %3476, i8* %14, align 1
  %3477 = icmp eq i32 %3463, 0
  %3478 = zext i1 %3477 to i8
  store i8 %3478, i8* %15, align 1
  %3479 = lshr i32 %3463, 31
  %3480 = trunc i32 %3479 to i8
  store i8 %3480, i8* %16, align 1
  %3481 = lshr i32 %3427, 31
  %3482 = lshr i32 %3462, 31
  %3483 = xor i32 %3482, %3481
  %3484 = xor i32 %3479, %3481
  %3485 = add nuw nsw i32 %3484, %3483
  %3486 = icmp eq i32 %3485, 2
  %3487 = zext i1 %3486 to i8
  store i8 %3487, i8* %17, align 1
  %3488 = load i64, i64* %RBP.i, align 8
  %3489 = add i64 %3488, -484
  %3490 = add i64 %3390, 37
  store i64 %3490, i64* %3, align 8
  %3491 = inttoptr i64 %3489 to i32*
  store i32 %3463, i32* %3491, align 4
  %3492 = load i64, i64* %RBP.i, align 8
  %3493 = add i64 %3492, -492
  %3494 = load i64, i64* %3, align 8
  %3495 = add i64 %3494, 6
  store i64 %3495, i64* %3, align 8
  %3496 = inttoptr i64 %3493 to i32*
  %3497 = load i32, i32* %3496, align 4
  %3498 = zext i32 %3497 to i64
  store i64 %3498, i64* %RDI.i4084, align 8
  %3499 = add i64 %3492, -488
  %3500 = add i64 %3494, 12
  store i64 %3500, i64* %3, align 8
  %3501 = inttoptr i64 %3499 to i32*
  %3502 = load i32, i32* %3501, align 4
  %3503 = add i32 %3502, %3497
  %3504 = zext i32 %3503 to i64
  store i64 %3504, i64* %RDI.i4084, align 8
  %3505 = icmp ult i32 %3503, %3497
  %3506 = icmp ult i32 %3503, %3502
  %3507 = or i1 %3505, %3506
  %3508 = zext i1 %3507 to i8
  store i8 %3508, i8* %12, align 1
  %3509 = and i32 %3503, 255
  %3510 = tail call i32 @llvm.ctpop.i32(i32 %3509)
  %3511 = trunc i32 %3510 to i8
  %3512 = and i8 %3511, 1
  %3513 = xor i8 %3512, 1
  store i8 %3513, i8* %13, align 1
  %3514 = xor i32 %3502, %3497
  %3515 = xor i32 %3514, %3503
  %3516 = lshr i32 %3515, 4
  %3517 = trunc i32 %3516 to i8
  %3518 = and i8 %3517, 1
  store i8 %3518, i8* %14, align 1
  %3519 = icmp eq i32 %3503, 0
  %3520 = zext i1 %3519 to i8
  store i8 %3520, i8* %15, align 1
  %3521 = lshr i32 %3503, 31
  %3522 = trunc i32 %3521 to i8
  store i8 %3522, i8* %16, align 1
  %3523 = lshr i32 %3497, 31
  %3524 = lshr i32 %3502, 31
  %3525 = xor i32 %3521, %3523
  %3526 = xor i32 %3521, %3524
  %3527 = add nuw nsw i32 %3525, %3526
  %3528 = icmp eq i32 %3527, 2
  %3529 = zext i1 %3528 to i8
  store i8 %3529, i8* %17, align 1
  %3530 = add i64 %3492, -496
  %3531 = add i64 %3494, 19
  store i64 %3531, i64* %3, align 8
  %3532 = inttoptr i64 %3530 to i32*
  %3533 = load i32, i32* %3532, align 4
  %3534 = zext i32 %3533 to i64
  %3535 = shl nuw i64 %3534, 32
  %3536 = ashr i64 %3535, 33
  %3537 = trunc i32 %3533 to i8
  %3538 = and i8 %3537, 1
  %3539 = trunc i64 %3536 to i32
  %3540 = and i64 %3536, 4294967295
  store i64 %3540, i64* %R8.i4051, align 8
  store i8 %3538, i8* %12, align 1
  %3541 = and i32 %3539, 255
  %3542 = tail call i32 @llvm.ctpop.i32(i32 %3541)
  %3543 = trunc i32 %3542 to i8
  %3544 = and i8 %3543, 1
  %3545 = xor i8 %3544, 1
  store i8 %3545, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %3546 = icmp eq i32 %3539, 0
  %3547 = zext i1 %3546 to i8
  store i8 %3547, i8* %15, align 1
  %3548 = lshr i64 %3536, 31
  %3549 = trunc i64 %3548 to i8
  %3550 = and i8 %3549, 1
  store i8 %3550, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %3551 = trunc i64 %3536 to i32
  %3552 = add i64 %3494, 29
  store i64 %3552, i64* %3, align 8
  %3553 = load i32, i32* %3532, align 4
  %3554 = add i32 %3553, %3551
  %3555 = zext i32 %3554 to i64
  store i64 %3555, i64* %R8.i4051, align 8
  %3556 = lshr i32 %3554, 31
  %3557 = load i64, i64* %RDI.i4084, align 8
  %3558 = trunc i64 %3557 to i32
  %3559 = add i32 %3554, %3558
  %3560 = zext i32 %3559 to i64
  store i64 %3560, i64* %RDI.i4084, align 8
  %3561 = icmp ult i32 %3559, %3558
  %3562 = icmp ult i32 %3559, %3554
  %3563 = or i1 %3561, %3562
  %3564 = zext i1 %3563 to i8
  store i8 %3564, i8* %12, align 1
  %3565 = and i32 %3559, 255
  %3566 = tail call i32 @llvm.ctpop.i32(i32 %3565)
  %3567 = trunc i32 %3566 to i8
  %3568 = and i8 %3567, 1
  %3569 = xor i8 %3568, 1
  store i8 %3569, i8* %13, align 1
  %3570 = xor i64 %3555, %3557
  %3571 = trunc i64 %3570 to i32
  %3572 = xor i32 %3571, %3559
  %3573 = lshr i32 %3572, 4
  %3574 = trunc i32 %3573 to i8
  %3575 = and i8 %3574, 1
  store i8 %3575, i8* %14, align 1
  %3576 = icmp eq i32 %3559, 0
  %3577 = zext i1 %3576 to i8
  store i8 %3577, i8* %15, align 1
  %3578 = lshr i32 %3559, 31
  %3579 = trunc i32 %3578 to i8
  store i8 %3579, i8* %16, align 1
  %3580 = lshr i32 %3558, 31
  %3581 = xor i32 %3578, %3580
  %3582 = xor i32 %3578, %3556
  %3583 = add nuw nsw i32 %3581, %3582
  %3584 = icmp eq i32 %3583, 2
  %3585 = zext i1 %3584 to i8
  store i8 %3585, i8* %17, align 1
  %3586 = load i64, i64* %RBP.i, align 8
  %3587 = add i64 %3586, -528
  %3588 = add i64 %3494, 38
  store i64 %3588, i64* %3, align 8
  %3589 = inttoptr i64 %3587 to i32*
  store i32 %3559, i32* %3589, align 4
  %3590 = load i64, i64* %RBP.i, align 8
  %3591 = add i64 %3590, -496
  %3592 = load i64, i64* %3, align 8
  %3593 = add i64 %3592, 6
  store i64 %3593, i64* %3, align 8
  %3594 = inttoptr i64 %3591 to i32*
  %3595 = load i32, i32* %3594, align 4
  %3596 = zext i32 %3595 to i64
  store i64 %3596, i64* %RDI.i4084, align 8
  %3597 = add i64 %3590, -484
  %3598 = add i64 %3592, 12
  store i64 %3598, i64* %3, align 8
  %3599 = inttoptr i64 %3597 to i32*
  %3600 = load i32, i32* %3599, align 4
  %3601 = sub i32 %3595, %3600
  %3602 = zext i32 %3601 to i64
  store i64 %3602, i64* %RDI.i4084, align 8
  %3603 = icmp ult i32 %3595, %3600
  %3604 = zext i1 %3603 to i8
  store i8 %3604, i8* %12, align 1
  %3605 = and i32 %3601, 255
  %3606 = tail call i32 @llvm.ctpop.i32(i32 %3605)
  %3607 = trunc i32 %3606 to i8
  %3608 = and i8 %3607, 1
  %3609 = xor i8 %3608, 1
  store i8 %3609, i8* %13, align 1
  %3610 = xor i32 %3600, %3595
  %3611 = xor i32 %3610, %3601
  %3612 = lshr i32 %3611, 4
  %3613 = trunc i32 %3612 to i8
  %3614 = and i8 %3613, 1
  store i8 %3614, i8* %14, align 1
  %3615 = icmp eq i32 %3601, 0
  %3616 = zext i1 %3615 to i8
  store i8 %3616, i8* %15, align 1
  %3617 = lshr i32 %3601, 31
  %3618 = trunc i32 %3617 to i8
  store i8 %3618, i8* %16, align 1
  %3619 = lshr i32 %3595, 31
  %3620 = lshr i32 %3600, 31
  %3621 = xor i32 %3620, %3619
  %3622 = xor i32 %3617, %3619
  %3623 = add nuw nsw i32 %3622, %3621
  %3624 = icmp eq i32 %3623, 2
  %3625 = zext i1 %3624 to i8
  store i8 %3625, i8* %17, align 1
  %3626 = add i64 %3590, -488
  %3627 = add i64 %3592, 19
  store i64 %3627, i64* %3, align 8
  %3628 = inttoptr i64 %3626 to i32*
  %3629 = load i32, i32* %3628, align 4
  %3630 = zext i32 %3629 to i64
  %3631 = shl nuw i64 %3630, 32
  %3632 = ashr i64 %3631, 33
  %3633 = trunc i32 %3629 to i8
  %3634 = and i8 %3633, 1
  %3635 = trunc i64 %3632 to i32
  %3636 = and i64 %3632, 4294967295
  store i64 %3636, i64* %R8.i4051, align 8
  store i8 %3634, i8* %12, align 1
  %3637 = and i32 %3635, 255
  %3638 = tail call i32 @llvm.ctpop.i32(i32 %3637)
  %3639 = trunc i32 %3638 to i8
  %3640 = and i8 %3639, 1
  %3641 = xor i8 %3640, 1
  store i8 %3641, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %3642 = icmp eq i32 %3635, 0
  %3643 = zext i1 %3642 to i8
  store i8 %3643, i8* %15, align 1
  %3644 = lshr i64 %3632, 31
  %3645 = trunc i64 %3644 to i8
  %3646 = and i8 %3645, 1
  store i8 %3646, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %3647 = trunc i64 %3632 to i32
  %3648 = add i64 %3592, 29
  store i64 %3648, i64* %3, align 8
  %3649 = load i32, i32* %3628, align 4
  %3650 = add i32 %3649, %3647
  %3651 = zext i32 %3650 to i64
  store i64 %3651, i64* %R8.i4051, align 8
  %3652 = lshr i32 %3650, 31
  %3653 = load i64, i64* %RDI.i4084, align 8
  %3654 = trunc i64 %3653 to i32
  %3655 = sub i32 %3654, %3650
  %3656 = zext i32 %3655 to i64
  store i64 %3656, i64* %RDI.i4084, align 8
  %3657 = icmp ult i32 %3654, %3650
  %3658 = zext i1 %3657 to i8
  store i8 %3658, i8* %12, align 1
  %3659 = and i32 %3655, 255
  %3660 = tail call i32 @llvm.ctpop.i32(i32 %3659)
  %3661 = trunc i32 %3660 to i8
  %3662 = and i8 %3661, 1
  %3663 = xor i8 %3662, 1
  store i8 %3663, i8* %13, align 1
  %3664 = xor i64 %3651, %3653
  %3665 = trunc i64 %3664 to i32
  %3666 = xor i32 %3665, %3655
  %3667 = lshr i32 %3666, 4
  %3668 = trunc i32 %3667 to i8
  %3669 = and i8 %3668, 1
  store i8 %3669, i8* %14, align 1
  %3670 = icmp eq i32 %3655, 0
  %3671 = zext i1 %3670 to i8
  store i8 %3671, i8* %15, align 1
  %3672 = lshr i32 %3655, 31
  %3673 = trunc i32 %3672 to i8
  store i8 %3673, i8* %16, align 1
  %3674 = lshr i32 %3654, 31
  %3675 = xor i32 %3652, %3674
  %3676 = xor i32 %3672, %3674
  %3677 = add nuw nsw i32 %3676, %3675
  %3678 = icmp eq i32 %3677, 2
  %3679 = zext i1 %3678 to i8
  store i8 %3679, i8* %17, align 1
  %3680 = load i64, i64* %RBP.i, align 8
  %3681 = add i64 %3680, -524
  %3682 = add i64 %3592, 38
  store i64 %3682, i64* %3, align 8
  %3683 = inttoptr i64 %3681 to i32*
  store i32 %3655, i32* %3683, align 4
  %3684 = load i64, i64* %RBP.i, align 8
  %3685 = add i64 %3684, -496
  %3686 = load i64, i64* %3, align 8
  %3687 = add i64 %3686, 6
  store i64 %3687, i64* %3, align 8
  %3688 = inttoptr i64 %3685 to i32*
  %3689 = load i32, i32* %3688, align 4
  %3690 = zext i32 %3689 to i64
  store i64 %3690, i64* %RDI.i4084, align 8
  %3691 = add i64 %3684, -484
  %3692 = add i64 %3686, 12
  store i64 %3692, i64* %3, align 8
  %3693 = inttoptr i64 %3691 to i32*
  %3694 = load i32, i32* %3693, align 4
  %3695 = add i32 %3694, %3689
  %3696 = zext i32 %3695 to i64
  store i64 %3696, i64* %RDI.i4084, align 8
  %3697 = icmp ult i32 %3695, %3689
  %3698 = icmp ult i32 %3695, %3694
  %3699 = or i1 %3697, %3698
  %3700 = zext i1 %3699 to i8
  store i8 %3700, i8* %12, align 1
  %3701 = and i32 %3695, 255
  %3702 = tail call i32 @llvm.ctpop.i32(i32 %3701)
  %3703 = trunc i32 %3702 to i8
  %3704 = and i8 %3703, 1
  %3705 = xor i8 %3704, 1
  store i8 %3705, i8* %13, align 1
  %3706 = xor i32 %3694, %3689
  %3707 = xor i32 %3706, %3695
  %3708 = lshr i32 %3707, 4
  %3709 = trunc i32 %3708 to i8
  %3710 = and i8 %3709, 1
  store i8 %3710, i8* %14, align 1
  %3711 = icmp eq i32 %3695, 0
  %3712 = zext i1 %3711 to i8
  store i8 %3712, i8* %15, align 1
  %3713 = lshr i32 %3695, 31
  %3714 = trunc i32 %3713 to i8
  store i8 %3714, i8* %16, align 1
  %3715 = lshr i32 %3689, 31
  %3716 = lshr i32 %3694, 31
  %3717 = xor i32 %3713, %3715
  %3718 = xor i32 %3713, %3716
  %3719 = add nuw nsw i32 %3717, %3718
  %3720 = icmp eq i32 %3719, 2
  %3721 = zext i1 %3720 to i8
  store i8 %3721, i8* %17, align 1
  %3722 = add i64 %3684, -492
  %3723 = add i64 %3686, 19
  store i64 %3723, i64* %3, align 8
  %3724 = inttoptr i64 %3722 to i32*
  %3725 = load i32, i32* %3724, align 4
  %3726 = zext i32 %3725 to i64
  %3727 = shl nuw i64 %3726, 32
  %3728 = ashr i64 %3727, 33
  %3729 = trunc i32 %3725 to i8
  %3730 = and i8 %3729, 1
  %3731 = trunc i64 %3728 to i32
  %3732 = and i64 %3728, 4294967295
  store i64 %3732, i64* %R8.i4051, align 8
  store i8 %3730, i8* %12, align 1
  %3733 = and i32 %3731, 255
  %3734 = tail call i32 @llvm.ctpop.i32(i32 %3733)
  %3735 = trunc i32 %3734 to i8
  %3736 = and i8 %3735, 1
  %3737 = xor i8 %3736, 1
  store i8 %3737, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %3738 = icmp eq i32 %3731, 0
  %3739 = zext i1 %3738 to i8
  store i8 %3739, i8* %15, align 1
  %3740 = lshr i64 %3728, 31
  %3741 = trunc i64 %3740 to i8
  %3742 = and i8 %3741, 1
  store i8 %3742, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %3743 = trunc i64 %3728 to i32
  %3744 = add i64 %3686, 29
  store i64 %3744, i64* %3, align 8
  %3745 = load i32, i32* %3724, align 4
  %3746 = add i32 %3745, %3743
  %3747 = zext i32 %3746 to i64
  store i64 %3747, i64* %R8.i4051, align 8
  %3748 = lshr i32 %3746, 31
  %3749 = load i64, i64* %RDI.i4084, align 8
  %3750 = trunc i64 %3749 to i32
  %3751 = sub i32 %3750, %3746
  %3752 = zext i32 %3751 to i64
  store i64 %3752, i64* %RDI.i4084, align 8
  %3753 = icmp ult i32 %3750, %3746
  %3754 = zext i1 %3753 to i8
  store i8 %3754, i8* %12, align 1
  %3755 = and i32 %3751, 255
  %3756 = tail call i32 @llvm.ctpop.i32(i32 %3755)
  %3757 = trunc i32 %3756 to i8
  %3758 = and i8 %3757, 1
  %3759 = xor i8 %3758, 1
  store i8 %3759, i8* %13, align 1
  %3760 = xor i64 %3747, %3749
  %3761 = trunc i64 %3760 to i32
  %3762 = xor i32 %3761, %3751
  %3763 = lshr i32 %3762, 4
  %3764 = trunc i32 %3763 to i8
  %3765 = and i8 %3764, 1
  store i8 %3765, i8* %14, align 1
  %3766 = icmp eq i32 %3751, 0
  %3767 = zext i1 %3766 to i8
  store i8 %3767, i8* %15, align 1
  %3768 = lshr i32 %3751, 31
  %3769 = trunc i32 %3768 to i8
  store i8 %3769, i8* %16, align 1
  %3770 = lshr i32 %3750, 31
  %3771 = xor i32 %3748, %3770
  %3772 = xor i32 %3768, %3770
  %3773 = add nuw nsw i32 %3772, %3771
  %3774 = icmp eq i32 %3773, 2
  %3775 = zext i1 %3774 to i8
  store i8 %3775, i8* %17, align 1
  %3776 = load i64, i64* %RBP.i, align 8
  %3777 = add i64 %3776, -520
  %3778 = add i64 %3686, 38
  store i64 %3778, i64* %3, align 8
  %3779 = inttoptr i64 %3777 to i32*
  store i32 %3751, i32* %3779, align 4
  %3780 = load i64, i64* %RBP.i, align 8
  %3781 = add i64 %3780, -492
  %3782 = load i64, i64* %3, align 8
  %3783 = add i64 %3782, 6
  store i64 %3783, i64* %3, align 8
  %3784 = inttoptr i64 %3781 to i32*
  %3785 = load i32, i32* %3784, align 4
  %3786 = zext i32 %3785 to i64
  store i64 %3786, i64* %RDI.i4084, align 8
  %3787 = add i64 %3780, -488
  %3788 = add i64 %3782, 12
  store i64 %3788, i64* %3, align 8
  %3789 = inttoptr i64 %3787 to i32*
  %3790 = load i32, i32* %3789, align 4
  %3791 = sub i32 %3785, %3790
  %3792 = zext i32 %3791 to i64
  store i64 %3792, i64* %RDI.i4084, align 8
  %3793 = icmp ult i32 %3785, %3790
  %3794 = zext i1 %3793 to i8
  store i8 %3794, i8* %12, align 1
  %3795 = and i32 %3791, 255
  %3796 = tail call i32 @llvm.ctpop.i32(i32 %3795)
  %3797 = trunc i32 %3796 to i8
  %3798 = and i8 %3797, 1
  %3799 = xor i8 %3798, 1
  store i8 %3799, i8* %13, align 1
  %3800 = xor i32 %3790, %3785
  %3801 = xor i32 %3800, %3791
  %3802 = lshr i32 %3801, 4
  %3803 = trunc i32 %3802 to i8
  %3804 = and i8 %3803, 1
  store i8 %3804, i8* %14, align 1
  %3805 = icmp eq i32 %3791, 0
  %3806 = zext i1 %3805 to i8
  store i8 %3806, i8* %15, align 1
  %3807 = lshr i32 %3791, 31
  %3808 = trunc i32 %3807 to i8
  store i8 %3808, i8* %16, align 1
  %3809 = lshr i32 %3785, 31
  %3810 = lshr i32 %3790, 31
  %3811 = xor i32 %3810, %3809
  %3812 = xor i32 %3807, %3809
  %3813 = add nuw nsw i32 %3812, %3811
  %3814 = icmp eq i32 %3813, 2
  %3815 = zext i1 %3814 to i8
  store i8 %3815, i8* %17, align 1
  %3816 = add i64 %3780, -484
  %3817 = add i64 %3782, 19
  store i64 %3817, i64* %3, align 8
  %3818 = inttoptr i64 %3816 to i32*
  %3819 = load i32, i32* %3818, align 4
  %3820 = zext i32 %3819 to i64
  %3821 = shl nuw i64 %3820, 32
  %3822 = ashr i64 %3821, 33
  %3823 = trunc i32 %3819 to i8
  %3824 = and i8 %3823, 1
  %3825 = trunc i64 %3822 to i32
  %3826 = and i64 %3822, 4294967295
  store i64 %3826, i64* %R8.i4051, align 8
  store i8 %3824, i8* %12, align 1
  %3827 = and i32 %3825, 255
  %3828 = tail call i32 @llvm.ctpop.i32(i32 %3827)
  %3829 = trunc i32 %3828 to i8
  %3830 = and i8 %3829, 1
  %3831 = xor i8 %3830, 1
  store i8 %3831, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %3832 = icmp eq i32 %3825, 0
  %3833 = zext i1 %3832 to i8
  store i8 %3833, i8* %15, align 1
  %3834 = lshr i64 %3822, 31
  %3835 = trunc i64 %3834 to i8
  %3836 = and i8 %3835, 1
  store i8 %3836, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %3837 = trunc i64 %3822 to i32
  %3838 = add i64 %3782, 29
  store i64 %3838, i64* %3, align 8
  %3839 = load i32, i32* %3818, align 4
  %3840 = add i32 %3839, %3837
  %3841 = zext i32 %3840 to i64
  store i64 %3841, i64* %R8.i4051, align 8
  %3842 = lshr i32 %3840, 31
  %3843 = load i64, i64* %RDI.i4084, align 8
  %3844 = trunc i64 %3843 to i32
  %3845 = add i32 %3840, %3844
  %3846 = zext i32 %3845 to i64
  store i64 %3846, i64* %RDI.i4084, align 8
  %3847 = icmp ult i32 %3845, %3844
  %3848 = icmp ult i32 %3845, %3840
  %3849 = or i1 %3847, %3848
  %3850 = zext i1 %3849 to i8
  store i8 %3850, i8* %12, align 1
  %3851 = and i32 %3845, 255
  %3852 = tail call i32 @llvm.ctpop.i32(i32 %3851)
  %3853 = trunc i32 %3852 to i8
  %3854 = and i8 %3853, 1
  %3855 = xor i8 %3854, 1
  store i8 %3855, i8* %13, align 1
  %3856 = xor i64 %3841, %3843
  %3857 = trunc i64 %3856 to i32
  %3858 = xor i32 %3857, %3845
  %3859 = lshr i32 %3858, 4
  %3860 = trunc i32 %3859 to i8
  %3861 = and i8 %3860, 1
  store i8 %3861, i8* %14, align 1
  %3862 = icmp eq i32 %3845, 0
  %3863 = zext i1 %3862 to i8
  store i8 %3863, i8* %15, align 1
  %3864 = lshr i32 %3845, 31
  %3865 = trunc i32 %3864 to i8
  store i8 %3865, i8* %16, align 1
  %3866 = lshr i32 %3844, 31
  %3867 = xor i32 %3864, %3866
  %3868 = xor i32 %3864, %3842
  %3869 = add nuw nsw i32 %3867, %3868
  %3870 = icmp eq i32 %3869, 2
  %3871 = zext i1 %3870 to i8
  store i8 %3871, i8* %17, align 1
  %3872 = load i64, i64* %RBP.i, align 8
  %3873 = add i64 %3872, -516
  %3874 = add i64 %3782, 38
  store i64 %3874, i64* %3, align 8
  %3875 = inttoptr i64 %3873 to i32*
  store i32 %3845, i32* %3875, align 4
  %3876 = load i64, i64* %RBP.i, align 8
  %3877 = add i64 %3876, -544
  %3878 = load i64, i64* %3, align 8
  %3879 = add i64 %3878, 6
  store i64 %3879, i64* %3, align 8
  %3880 = inttoptr i64 %3877 to i32*
  %3881 = load i32, i32* %3880, align 4
  %3882 = zext i32 %3881 to i64
  store i64 %3882, i64* %RDI.i4084, align 8
  %3883 = add i64 %3876, -540
  %3884 = add i64 %3878, 12
  store i64 %3884, i64* %3, align 8
  %3885 = inttoptr i64 %3883 to i32*
  %3886 = load i32, i32* %3885, align 4
  %3887 = add i32 %3886, %3881
  %3888 = zext i32 %3887 to i64
  store i64 %3888, i64* %RDI.i4084, align 8
  %3889 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %3890 = add i64 %3889, 13112
  store i64 %3890, i64* %RCX.i3977, align 8
  %3891 = icmp ugt i64 %3889, -13113
  %3892 = zext i1 %3891 to i8
  store i8 %3892, i8* %12, align 1
  %3893 = trunc i64 %3890 to i32
  %3894 = and i32 %3893, 255
  %3895 = tail call i32 @llvm.ctpop.i32(i32 %3894)
  %3896 = trunc i32 %3895 to i8
  %3897 = and i8 %3896, 1
  %3898 = xor i8 %3897, 1
  store i8 %3898, i8* %13, align 1
  %3899 = xor i64 %3889, 16
  %3900 = xor i64 %3899, %3890
  %3901 = lshr i64 %3900, 4
  %3902 = trunc i64 %3901 to i8
  %3903 = and i8 %3902, 1
  store i8 %3903, i8* %14, align 1
  %3904 = icmp eq i64 %3890, 0
  %3905 = zext i1 %3904 to i8
  store i8 %3905, i8* %15, align 1
  %3906 = lshr i64 %3890, 63
  %3907 = trunc i64 %3906 to i8
  store i8 %3907, i8* %16, align 1
  %3908 = lshr i64 %3889, 63
  %3909 = xor i64 %3906, %3908
  %3910 = add nuw nsw i64 %3909, %3906
  %3911 = icmp eq i64 %3910, 2
  %3912 = zext i1 %3911 to i8
  store i8 %3912, i8* %17, align 1
  %3913 = add i64 %3876, -24
  %3914 = add i64 %3878, 31
  store i64 %3914, i64* %3, align 8
  %3915 = inttoptr i64 %3913 to i32*
  %3916 = load i32, i32* %3915, align 4
  %3917 = sext i32 %3916 to i64
  %3918 = shl nsw i64 %3917, 6
  store i64 %3918, i64* %RDX.i4094, align 8
  %3919 = add i64 %3918, %3890
  store i64 %3919, i64* %RCX.i3977, align 8
  %3920 = icmp ult i64 %3919, %3890
  %3921 = icmp ult i64 %3919, %3918
  %3922 = or i1 %3920, %3921
  %3923 = zext i1 %3922 to i8
  store i8 %3923, i8* %12, align 1
  %3924 = trunc i64 %3919 to i32
  %3925 = and i32 %3924, 255
  %3926 = tail call i32 @llvm.ctpop.i32(i32 %3925)
  %3927 = trunc i32 %3926 to i8
  %3928 = and i8 %3927, 1
  %3929 = xor i8 %3928, 1
  store i8 %3929, i8* %13, align 1
  %3930 = xor i64 %3890, %3919
  %3931 = lshr i64 %3930, 4
  %3932 = trunc i64 %3931 to i8
  %3933 = and i8 %3932, 1
  store i8 %3933, i8* %14, align 1
  %3934 = icmp eq i64 %3919, 0
  %3935 = zext i1 %3934 to i8
  store i8 %3935, i8* %15, align 1
  %3936 = lshr i64 %3919, 63
  %3937 = trunc i64 %3936 to i8
  store i8 %3937, i8* %16, align 1
  %3938 = lshr i64 %3917, 57
  %3939 = and i64 %3938, 1
  %3940 = xor i64 %3936, %3906
  %3941 = xor i64 %3936, %3939
  %3942 = add nuw nsw i64 %3940, %3941
  %3943 = icmp eq i64 %3942, 2
  %3944 = zext i1 %3943 to i8
  store i8 %3944, i8* %17, align 1
  %3945 = inttoptr i64 %3919 to i32*
  %3946 = load i32, i32* %EDI.i3928, align 4
  %3947 = add i64 %3878, 40
  store i64 %3947, i64* %3, align 8
  store i32 %3946, i32* %3945, align 4
  %3948 = load i64, i64* %RBP.i, align 8
  %3949 = add i64 %3948, -536
  %3950 = load i64, i64* %3, align 8
  %3951 = add i64 %3950, 6
  store i64 %3951, i64* %3, align 8
  %3952 = inttoptr i64 %3949 to i32*
  %3953 = load i32, i32* %3952, align 4
  %3954 = zext i32 %3953 to i64
  store i64 %3954, i64* %RDI.i4084, align 8
  %3955 = add i64 %3948, -532
  %3956 = add i64 %3950, 13
  store i64 %3956, i64* %3, align 8
  %3957 = inttoptr i64 %3955 to i32*
  %3958 = load i32, i32* %3957, align 4
  %3959 = zext i32 %3958 to i64
  %3960 = shl nuw i64 %3959, 32
  %3961 = ashr i64 %3960, 33
  %3962 = and i64 %3961, 4294967295
  store i64 %3962, i64* %R8.i4051, align 8
  %3963 = trunc i64 %3961 to i32
  %3964 = add i32 %3963, %3953
  %3965 = zext i32 %3964 to i64
  store i64 %3965, i64* %RDI.i4084, align 8
  %3966 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %3967 = add i64 %3966, 13112
  store i64 %3967, i64* %RCX.i3977, align 8
  %3968 = icmp ugt i64 %3966, -13113
  %3969 = zext i1 %3968 to i8
  store i8 %3969, i8* %12, align 1
  %3970 = trunc i64 %3967 to i32
  %3971 = and i32 %3970, 255
  %3972 = tail call i32 @llvm.ctpop.i32(i32 %3971)
  %3973 = trunc i32 %3972 to i8
  %3974 = and i8 %3973, 1
  %3975 = xor i8 %3974, 1
  store i8 %3975, i8* %13, align 1
  %3976 = xor i64 %3966, 16
  %3977 = xor i64 %3976, %3967
  %3978 = lshr i64 %3977, 4
  %3979 = trunc i64 %3978 to i8
  %3980 = and i8 %3979, 1
  store i8 %3980, i8* %14, align 1
  %3981 = icmp eq i64 %3967, 0
  %3982 = zext i1 %3981 to i8
  store i8 %3982, i8* %15, align 1
  %3983 = lshr i64 %3967, 63
  %3984 = trunc i64 %3983 to i8
  store i8 %3984, i8* %16, align 1
  %3985 = lshr i64 %3966, 63
  %3986 = xor i64 %3983, %3985
  %3987 = add nuw nsw i64 %3986, %3983
  %3988 = icmp eq i64 %3987, 2
  %3989 = zext i1 %3988 to i8
  store i8 %3989, i8* %17, align 1
  %3990 = load i64, i64* %RBP.i, align 8
  %3991 = add i64 %3990, -24
  %3992 = add i64 %3950, 38
  store i64 %3992, i64* %3, align 8
  %3993 = inttoptr i64 %3991 to i32*
  %3994 = load i32, i32* %3993, align 4
  %3995 = sext i32 %3994 to i64
  %3996 = shl nsw i64 %3995, 6
  store i64 %3996, i64* %RDX.i4094, align 8
  %3997 = add i64 %3996, %3967
  store i64 %3997, i64* %RCX.i3977, align 8
  %3998 = icmp ult i64 %3997, %3967
  %3999 = icmp ult i64 %3997, %3996
  %4000 = or i1 %3998, %3999
  %4001 = zext i1 %4000 to i8
  store i8 %4001, i8* %12, align 1
  %4002 = trunc i64 %3997 to i32
  %4003 = and i32 %4002, 255
  %4004 = tail call i32 @llvm.ctpop.i32(i32 %4003)
  %4005 = trunc i32 %4004 to i8
  %4006 = and i8 %4005, 1
  %4007 = xor i8 %4006, 1
  store i8 %4007, i8* %13, align 1
  %4008 = xor i64 %3967, %3997
  %4009 = lshr i64 %4008, 4
  %4010 = trunc i64 %4009 to i8
  %4011 = and i8 %4010, 1
  store i8 %4011, i8* %14, align 1
  %4012 = icmp eq i64 %3997, 0
  %4013 = zext i1 %4012 to i8
  store i8 %4013, i8* %15, align 1
  %4014 = lshr i64 %3997, 63
  %4015 = trunc i64 %4014 to i8
  store i8 %4015, i8* %16, align 1
  %4016 = lshr i64 %3995, 57
  %4017 = and i64 %4016, 1
  %4018 = xor i64 %4014, %3983
  %4019 = xor i64 %4014, %4017
  %4020 = add nuw nsw i64 %4018, %4019
  %4021 = icmp eq i64 %4020, 2
  %4022 = zext i1 %4021 to i8
  store i8 %4022, i8* %17, align 1
  %4023 = add i64 %3997, 8
  %4024 = load i32, i32* %EDI.i3928, align 4
  %4025 = add i64 %3950, 48
  store i64 %4025, i64* %3, align 8
  %4026 = inttoptr i64 %4023 to i32*
  store i32 %4024, i32* %4026, align 4
  %4027 = load i64, i64* %RBP.i, align 8
  %4028 = add i64 %4027, -544
  %4029 = load i64, i64* %3, align 8
  %4030 = add i64 %4029, 6
  store i64 %4030, i64* %3, align 8
  %4031 = inttoptr i64 %4028 to i32*
  %4032 = load i32, i32* %4031, align 4
  %4033 = zext i32 %4032 to i64
  store i64 %4033, i64* %RDI.i4084, align 8
  %4034 = add i64 %4027, -540
  %4035 = add i64 %4029, 12
  store i64 %4035, i64* %3, align 8
  %4036 = inttoptr i64 %4034 to i32*
  %4037 = load i32, i32* %4036, align 4
  %4038 = sub i32 %4032, %4037
  %4039 = zext i32 %4038 to i64
  store i64 %4039, i64* %RDI.i4084, align 8
  %4040 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4041 = add i64 %4040, 13112
  store i64 %4041, i64* %RCX.i3977, align 8
  %4042 = icmp ugt i64 %4040, -13113
  %4043 = zext i1 %4042 to i8
  store i8 %4043, i8* %12, align 1
  %4044 = trunc i64 %4041 to i32
  %4045 = and i32 %4044, 255
  %4046 = tail call i32 @llvm.ctpop.i32(i32 %4045)
  %4047 = trunc i32 %4046 to i8
  %4048 = and i8 %4047, 1
  %4049 = xor i8 %4048, 1
  store i8 %4049, i8* %13, align 1
  %4050 = xor i64 %4040, 16
  %4051 = xor i64 %4050, %4041
  %4052 = lshr i64 %4051, 4
  %4053 = trunc i64 %4052 to i8
  %4054 = and i8 %4053, 1
  store i8 %4054, i8* %14, align 1
  %4055 = icmp eq i64 %4041, 0
  %4056 = zext i1 %4055 to i8
  store i8 %4056, i8* %15, align 1
  %4057 = lshr i64 %4041, 63
  %4058 = trunc i64 %4057 to i8
  store i8 %4058, i8* %16, align 1
  %4059 = lshr i64 %4040, 63
  %4060 = xor i64 %4057, %4059
  %4061 = add nuw nsw i64 %4060, %4057
  %4062 = icmp eq i64 %4061, 2
  %4063 = zext i1 %4062 to i8
  store i8 %4063, i8* %17, align 1
  %4064 = add i64 %4027, -24
  %4065 = add i64 %4029, 31
  store i64 %4065, i64* %3, align 8
  %4066 = inttoptr i64 %4064 to i32*
  %4067 = load i32, i32* %4066, align 4
  %4068 = sext i32 %4067 to i64
  %4069 = shl nsw i64 %4068, 6
  store i64 %4069, i64* %RDX.i4094, align 8
  %4070 = add i64 %4069, %4041
  store i64 %4070, i64* %RCX.i3977, align 8
  %4071 = icmp ult i64 %4070, %4041
  %4072 = icmp ult i64 %4070, %4069
  %4073 = or i1 %4071, %4072
  %4074 = zext i1 %4073 to i8
  store i8 %4074, i8* %12, align 1
  %4075 = trunc i64 %4070 to i32
  %4076 = and i32 %4075, 255
  %4077 = tail call i32 @llvm.ctpop.i32(i32 %4076)
  %4078 = trunc i32 %4077 to i8
  %4079 = and i8 %4078, 1
  %4080 = xor i8 %4079, 1
  store i8 %4080, i8* %13, align 1
  %4081 = xor i64 %4041, %4070
  %4082 = lshr i64 %4081, 4
  %4083 = trunc i64 %4082 to i8
  %4084 = and i8 %4083, 1
  store i8 %4084, i8* %14, align 1
  %4085 = icmp eq i64 %4070, 0
  %4086 = zext i1 %4085 to i8
  store i8 %4086, i8* %15, align 1
  %4087 = lshr i64 %4070, 63
  %4088 = trunc i64 %4087 to i8
  store i8 %4088, i8* %16, align 1
  %4089 = lshr i64 %4068, 57
  %4090 = and i64 %4089, 1
  %4091 = xor i64 %4087, %4057
  %4092 = xor i64 %4087, %4090
  %4093 = add nuw nsw i64 %4091, %4092
  %4094 = icmp eq i64 %4093, 2
  %4095 = zext i1 %4094 to i8
  store i8 %4095, i8* %17, align 1
  %4096 = add i64 %4070, 16
  %4097 = load i32, i32* %EDI.i3928, align 4
  %4098 = add i64 %4029, 41
  store i64 %4098, i64* %3, align 8
  %4099 = inttoptr i64 %4096 to i32*
  store i32 %4097, i32* %4099, align 4
  %4100 = load i64, i64* %RBP.i, align 8
  %4101 = add i64 %4100, -536
  %4102 = load i64, i64* %3, align 8
  %4103 = add i64 %4102, 6
  store i64 %4103, i64* %3, align 8
  %4104 = inttoptr i64 %4101 to i32*
  %4105 = load i32, i32* %4104, align 4
  %4106 = zext i32 %4105 to i64
  %4107 = shl nuw i64 %4106, 32
  %4108 = ashr i64 %4107, 33
  %4109 = trunc i32 %4105 to i8
  %4110 = and i8 %4109, 1
  %4111 = trunc i64 %4108 to i32
  %4112 = and i64 %4108, 4294967295
  store i64 %4112, i64* %RDI.i4084, align 8
  store i8 %4110, i8* %12, align 1
  %4113 = and i32 %4111, 255
  %4114 = tail call i32 @llvm.ctpop.i32(i32 %4113)
  %4115 = trunc i32 %4114 to i8
  %4116 = and i8 %4115, 1
  %4117 = xor i8 %4116, 1
  store i8 %4117, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %4118 = icmp eq i32 %4111, 0
  %4119 = zext i1 %4118 to i8
  store i8 %4119, i8* %15, align 1
  %4120 = lshr i64 %4108, 31
  %4121 = trunc i64 %4120 to i8
  %4122 = and i8 %4121, 1
  store i8 %4122, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %4123 = add i64 %4100, -532
  %4124 = add i64 %4102, 14
  store i64 %4124, i64* %3, align 8
  %4125 = trunc i64 %4108 to i32
  %4126 = inttoptr i64 %4123 to i32*
  %4127 = load i32, i32* %4126, align 4
  %4128 = sub i32 %4125, %4127
  %4129 = zext i32 %4128 to i64
  store i64 %4129, i64* %RDI.i4084, align 8
  %4130 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4131 = add i64 %4130, 13112
  store i64 %4131, i64* %RCX.i3977, align 8
  %4132 = icmp ugt i64 %4130, -13113
  %4133 = zext i1 %4132 to i8
  store i8 %4133, i8* %12, align 1
  %4134 = trunc i64 %4131 to i32
  %4135 = and i32 %4134, 255
  %4136 = tail call i32 @llvm.ctpop.i32(i32 %4135)
  %4137 = trunc i32 %4136 to i8
  %4138 = and i8 %4137, 1
  %4139 = xor i8 %4138, 1
  store i8 %4139, i8* %13, align 1
  %4140 = xor i64 %4130, 16
  %4141 = xor i64 %4140, %4131
  %4142 = lshr i64 %4141, 4
  %4143 = trunc i64 %4142 to i8
  %4144 = and i8 %4143, 1
  store i8 %4144, i8* %14, align 1
  %4145 = icmp eq i64 %4131, 0
  %4146 = zext i1 %4145 to i8
  store i8 %4146, i8* %15, align 1
  %4147 = lshr i64 %4131, 63
  %4148 = trunc i64 %4147 to i8
  store i8 %4148, i8* %16, align 1
  %4149 = lshr i64 %4130, 63
  %4150 = xor i64 %4147, %4149
  %4151 = add nuw nsw i64 %4150, %4147
  %4152 = icmp eq i64 %4151, 2
  %4153 = zext i1 %4152 to i8
  store i8 %4153, i8* %17, align 1
  %4154 = load i64, i64* %RBP.i, align 8
  %4155 = add i64 %4154, -24
  %4156 = add i64 %4102, 33
  store i64 %4156, i64* %3, align 8
  %4157 = inttoptr i64 %4155 to i32*
  %4158 = load i32, i32* %4157, align 4
  %4159 = sext i32 %4158 to i64
  %4160 = shl nsw i64 %4159, 6
  store i64 %4160, i64* %RDX.i4094, align 8
  %4161 = add i64 %4160, %4131
  store i64 %4161, i64* %RCX.i3977, align 8
  %4162 = icmp ult i64 %4161, %4131
  %4163 = icmp ult i64 %4161, %4160
  %4164 = or i1 %4162, %4163
  %4165 = zext i1 %4164 to i8
  store i8 %4165, i8* %12, align 1
  %4166 = trunc i64 %4161 to i32
  %4167 = and i32 %4166, 255
  %4168 = tail call i32 @llvm.ctpop.i32(i32 %4167)
  %4169 = trunc i32 %4168 to i8
  %4170 = and i8 %4169, 1
  %4171 = xor i8 %4170, 1
  store i8 %4171, i8* %13, align 1
  %4172 = xor i64 %4131, %4161
  %4173 = lshr i64 %4172, 4
  %4174 = trunc i64 %4173 to i8
  %4175 = and i8 %4174, 1
  store i8 %4175, i8* %14, align 1
  %4176 = icmp eq i64 %4161, 0
  %4177 = zext i1 %4176 to i8
  store i8 %4177, i8* %15, align 1
  %4178 = lshr i64 %4161, 63
  %4179 = trunc i64 %4178 to i8
  store i8 %4179, i8* %16, align 1
  %4180 = lshr i64 %4159, 57
  %4181 = and i64 %4180, 1
  %4182 = xor i64 %4178, %4147
  %4183 = xor i64 %4178, %4181
  %4184 = add nuw nsw i64 %4182, %4183
  %4185 = icmp eq i64 %4184, 2
  %4186 = zext i1 %4185 to i8
  store i8 %4186, i8* %17, align 1
  %4187 = add i64 %4161, 24
  %4188 = load i32, i32* %EDI.i3928, align 4
  %4189 = add i64 %4102, 43
  store i64 %4189, i64* %3, align 8
  %4190 = inttoptr i64 %4187 to i32*
  store i32 %4188, i32* %4190, align 4
  %4191 = load i64, i64* %RBP.i, align 8
  %4192 = add i64 %4191, -528
  %4193 = load i64, i64* %3, align 8
  %4194 = add i64 %4193, 6
  store i64 %4194, i64* %3, align 8
  %4195 = inttoptr i64 %4192 to i32*
  %4196 = load i32, i32* %4195, align 4
  %4197 = zext i32 %4196 to i64
  store i64 %4197, i64* %RDI.i4084, align 8
  %4198 = add i64 %4191, -516
  %4199 = add i64 %4193, 13
  store i64 %4199, i64* %3, align 8
  %4200 = inttoptr i64 %4198 to i32*
  %4201 = load i32, i32* %4200, align 4
  %4202 = sext i32 %4201 to i64
  %4203 = ashr i64 %4202, 1
  %4204 = lshr i64 %4203, 1
  %4205 = and i64 %4204, 4294967295
  store i64 %4205, i64* %R8.i4051, align 8
  %4206 = trunc i64 %4204 to i32
  %4207 = add i32 %4206, %4196
  %4208 = zext i32 %4207 to i64
  store i64 %4208, i64* %RDI.i4084, align 8
  %4209 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4210 = add i64 %4209, 13112
  store i64 %4210, i64* %RCX.i3977, align 8
  %4211 = icmp ugt i64 %4209, -13113
  %4212 = zext i1 %4211 to i8
  store i8 %4212, i8* %12, align 1
  %4213 = trunc i64 %4210 to i32
  %4214 = and i32 %4213, 255
  %4215 = tail call i32 @llvm.ctpop.i32(i32 %4214)
  %4216 = trunc i32 %4215 to i8
  %4217 = and i8 %4216, 1
  %4218 = xor i8 %4217, 1
  store i8 %4218, i8* %13, align 1
  %4219 = xor i64 %4209, 16
  %4220 = xor i64 %4219, %4210
  %4221 = lshr i64 %4220, 4
  %4222 = trunc i64 %4221 to i8
  %4223 = and i8 %4222, 1
  store i8 %4223, i8* %14, align 1
  %4224 = icmp eq i64 %4210, 0
  %4225 = zext i1 %4224 to i8
  store i8 %4225, i8* %15, align 1
  %4226 = lshr i64 %4210, 63
  %4227 = trunc i64 %4226 to i8
  store i8 %4227, i8* %16, align 1
  %4228 = lshr i64 %4209, 63
  %4229 = xor i64 %4226, %4228
  %4230 = add nuw nsw i64 %4229, %4226
  %4231 = icmp eq i64 %4230, 2
  %4232 = zext i1 %4231 to i8
  store i8 %4232, i8* %17, align 1
  %4233 = load i64, i64* %RBP.i, align 8
  %4234 = add i64 %4233, -24
  %4235 = add i64 %4193, 39
  store i64 %4235, i64* %3, align 8
  %4236 = inttoptr i64 %4234 to i32*
  %4237 = load i32, i32* %4236, align 4
  %4238 = sext i32 %4237 to i64
  %4239 = shl nsw i64 %4238, 6
  store i64 %4239, i64* %RDX.i4094, align 8
  %4240 = add i64 %4239, %4210
  store i64 %4240, i64* %RCX.i3977, align 8
  %4241 = icmp ult i64 %4240, %4210
  %4242 = icmp ult i64 %4240, %4239
  %4243 = or i1 %4241, %4242
  %4244 = zext i1 %4243 to i8
  store i8 %4244, i8* %12, align 1
  %4245 = trunc i64 %4240 to i32
  %4246 = and i32 %4245, 255
  %4247 = tail call i32 @llvm.ctpop.i32(i32 %4246)
  %4248 = trunc i32 %4247 to i8
  %4249 = and i8 %4248, 1
  %4250 = xor i8 %4249, 1
  store i8 %4250, i8* %13, align 1
  %4251 = xor i64 %4210, %4240
  %4252 = lshr i64 %4251, 4
  %4253 = trunc i64 %4252 to i8
  %4254 = and i8 %4253, 1
  store i8 %4254, i8* %14, align 1
  %4255 = icmp eq i64 %4240, 0
  %4256 = zext i1 %4255 to i8
  store i8 %4256, i8* %15, align 1
  %4257 = lshr i64 %4240, 63
  %4258 = trunc i64 %4257 to i8
  store i8 %4258, i8* %16, align 1
  %4259 = lshr i64 %4238, 57
  %4260 = and i64 %4259, 1
  %4261 = xor i64 %4257, %4226
  %4262 = xor i64 %4257, %4260
  %4263 = add nuw nsw i64 %4261, %4262
  %4264 = icmp eq i64 %4263, 2
  %4265 = zext i1 %4264 to i8
  store i8 %4265, i8* %17, align 1
  %4266 = add i64 %4240, 4
  %4267 = load i32, i32* %EDI.i3928, align 4
  %4268 = add i64 %4193, 49
  store i64 %4268, i64* %3, align 8
  %4269 = inttoptr i64 %4266 to i32*
  store i32 %4267, i32* %4269, align 4
  %4270 = load i64, i64* %RBP.i, align 8
  %4271 = add i64 %4270, -524
  %4272 = load i64, i64* %3, align 8
  %4273 = add i64 %4272, 6
  store i64 %4273, i64* %3, align 8
  %4274 = inttoptr i64 %4271 to i32*
  %4275 = load i32, i32* %4274, align 4
  %4276 = zext i32 %4275 to i64
  store i64 %4276, i64* %RDI.i4084, align 8
  %4277 = add i64 %4270, -520
  %4278 = add i64 %4272, 13
  store i64 %4278, i64* %3, align 8
  %4279 = inttoptr i64 %4277 to i32*
  %4280 = load i32, i32* %4279, align 4
  %4281 = sext i32 %4280 to i64
  %4282 = ashr i64 %4281, 1
  %4283 = lshr i64 %4282, 1
  %4284 = and i64 %4283, 4294967295
  store i64 %4284, i64* %R8.i4051, align 8
  %4285 = trunc i64 %4283 to i32
  %4286 = add i32 %4285, %4275
  %4287 = zext i32 %4286 to i64
  store i64 %4287, i64* %RDI.i4084, align 8
  %4288 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4289 = add i64 %4288, 13112
  store i64 %4289, i64* %RCX.i3977, align 8
  %4290 = icmp ugt i64 %4288, -13113
  %4291 = zext i1 %4290 to i8
  store i8 %4291, i8* %12, align 1
  %4292 = trunc i64 %4289 to i32
  %4293 = and i32 %4292, 255
  %4294 = tail call i32 @llvm.ctpop.i32(i32 %4293)
  %4295 = trunc i32 %4294 to i8
  %4296 = and i8 %4295, 1
  %4297 = xor i8 %4296, 1
  store i8 %4297, i8* %13, align 1
  %4298 = xor i64 %4288, 16
  %4299 = xor i64 %4298, %4289
  %4300 = lshr i64 %4299, 4
  %4301 = trunc i64 %4300 to i8
  %4302 = and i8 %4301, 1
  store i8 %4302, i8* %14, align 1
  %4303 = icmp eq i64 %4289, 0
  %4304 = zext i1 %4303 to i8
  store i8 %4304, i8* %15, align 1
  %4305 = lshr i64 %4289, 63
  %4306 = trunc i64 %4305 to i8
  store i8 %4306, i8* %16, align 1
  %4307 = lshr i64 %4288, 63
  %4308 = xor i64 %4305, %4307
  %4309 = add nuw nsw i64 %4308, %4305
  %4310 = icmp eq i64 %4309, 2
  %4311 = zext i1 %4310 to i8
  store i8 %4311, i8* %17, align 1
  %4312 = load i64, i64* %RBP.i, align 8
  %4313 = add i64 %4312, -24
  %4314 = add i64 %4272, 39
  store i64 %4314, i64* %3, align 8
  %4315 = inttoptr i64 %4313 to i32*
  %4316 = load i32, i32* %4315, align 4
  %4317 = sext i32 %4316 to i64
  %4318 = shl nsw i64 %4317, 6
  store i64 %4318, i64* %RDX.i4094, align 8
  %4319 = add i64 %4318, %4289
  store i64 %4319, i64* %RCX.i3977, align 8
  %4320 = icmp ult i64 %4319, %4289
  %4321 = icmp ult i64 %4319, %4318
  %4322 = or i1 %4320, %4321
  %4323 = zext i1 %4322 to i8
  store i8 %4323, i8* %12, align 1
  %4324 = trunc i64 %4319 to i32
  %4325 = and i32 %4324, 255
  %4326 = tail call i32 @llvm.ctpop.i32(i32 %4325)
  %4327 = trunc i32 %4326 to i8
  %4328 = and i8 %4327, 1
  %4329 = xor i8 %4328, 1
  store i8 %4329, i8* %13, align 1
  %4330 = xor i64 %4289, %4319
  %4331 = lshr i64 %4330, 4
  %4332 = trunc i64 %4331 to i8
  %4333 = and i8 %4332, 1
  store i8 %4333, i8* %14, align 1
  %4334 = icmp eq i64 %4319, 0
  %4335 = zext i1 %4334 to i8
  store i8 %4335, i8* %15, align 1
  %4336 = lshr i64 %4319, 63
  %4337 = trunc i64 %4336 to i8
  store i8 %4337, i8* %16, align 1
  %4338 = lshr i64 %4317, 57
  %4339 = and i64 %4338, 1
  %4340 = xor i64 %4336, %4305
  %4341 = xor i64 %4336, %4339
  %4342 = add nuw nsw i64 %4340, %4341
  %4343 = icmp eq i64 %4342, 2
  %4344 = zext i1 %4343 to i8
  store i8 %4344, i8* %17, align 1
  %4345 = add i64 %4319, 12
  %4346 = load i32, i32* %EDI.i3928, align 4
  %4347 = add i64 %4272, 49
  store i64 %4347, i64* %3, align 8
  %4348 = inttoptr i64 %4345 to i32*
  store i32 %4346, i32* %4348, align 4
  %4349 = load i64, i64* %RBP.i, align 8
  %4350 = add i64 %4349, -520
  %4351 = load i64, i64* %3, align 8
  %4352 = add i64 %4351, 6
  store i64 %4352, i64* %3, align 8
  %4353 = inttoptr i64 %4350 to i32*
  %4354 = load i32, i32* %4353, align 4
  %4355 = zext i32 %4354 to i64
  store i64 %4355, i64* %RDI.i4084, align 8
  %4356 = add i64 %4349, -524
  %4357 = add i64 %4351, 13
  store i64 %4357, i64* %3, align 8
  %4358 = inttoptr i64 %4356 to i32*
  %4359 = load i32, i32* %4358, align 4
  %4360 = sext i32 %4359 to i64
  %4361 = ashr i64 %4360, 1
  %4362 = lshr i64 %4361, 1
  %4363 = and i64 %4362, 4294967295
  store i64 %4363, i64* %R8.i4051, align 8
  %4364 = trunc i64 %4362 to i32
  %4365 = sub i32 %4354, %4364
  %4366 = zext i32 %4365 to i64
  store i64 %4366, i64* %RDI.i4084, align 8
  %4367 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4368 = add i64 %4367, 13112
  store i64 %4368, i64* %RCX.i3977, align 8
  %4369 = icmp ugt i64 %4367, -13113
  %4370 = zext i1 %4369 to i8
  store i8 %4370, i8* %12, align 1
  %4371 = trunc i64 %4368 to i32
  %4372 = and i32 %4371, 255
  %4373 = tail call i32 @llvm.ctpop.i32(i32 %4372)
  %4374 = trunc i32 %4373 to i8
  %4375 = and i8 %4374, 1
  %4376 = xor i8 %4375, 1
  store i8 %4376, i8* %13, align 1
  %4377 = xor i64 %4367, 16
  %4378 = xor i64 %4377, %4368
  %4379 = lshr i64 %4378, 4
  %4380 = trunc i64 %4379 to i8
  %4381 = and i8 %4380, 1
  store i8 %4381, i8* %14, align 1
  %4382 = icmp eq i64 %4368, 0
  %4383 = zext i1 %4382 to i8
  store i8 %4383, i8* %15, align 1
  %4384 = lshr i64 %4368, 63
  %4385 = trunc i64 %4384 to i8
  store i8 %4385, i8* %16, align 1
  %4386 = lshr i64 %4367, 63
  %4387 = xor i64 %4384, %4386
  %4388 = add nuw nsw i64 %4387, %4384
  %4389 = icmp eq i64 %4388, 2
  %4390 = zext i1 %4389 to i8
  store i8 %4390, i8* %17, align 1
  %4391 = load i64, i64* %RBP.i, align 8
  %4392 = add i64 %4391, -24
  %4393 = add i64 %4351, 39
  store i64 %4393, i64* %3, align 8
  %4394 = inttoptr i64 %4392 to i32*
  %4395 = load i32, i32* %4394, align 4
  %4396 = sext i32 %4395 to i64
  %4397 = shl nsw i64 %4396, 6
  store i64 %4397, i64* %RDX.i4094, align 8
  %4398 = add i64 %4397, %4368
  store i64 %4398, i64* %RCX.i3977, align 8
  %4399 = icmp ult i64 %4398, %4368
  %4400 = icmp ult i64 %4398, %4397
  %4401 = or i1 %4399, %4400
  %4402 = zext i1 %4401 to i8
  store i8 %4402, i8* %12, align 1
  %4403 = trunc i64 %4398 to i32
  %4404 = and i32 %4403, 255
  %4405 = tail call i32 @llvm.ctpop.i32(i32 %4404)
  %4406 = trunc i32 %4405 to i8
  %4407 = and i8 %4406, 1
  %4408 = xor i8 %4407, 1
  store i8 %4408, i8* %13, align 1
  %4409 = xor i64 %4368, %4398
  %4410 = lshr i64 %4409, 4
  %4411 = trunc i64 %4410 to i8
  %4412 = and i8 %4411, 1
  store i8 %4412, i8* %14, align 1
  %4413 = icmp eq i64 %4398, 0
  %4414 = zext i1 %4413 to i8
  store i8 %4414, i8* %15, align 1
  %4415 = lshr i64 %4398, 63
  %4416 = trunc i64 %4415 to i8
  store i8 %4416, i8* %16, align 1
  %4417 = lshr i64 %4396, 57
  %4418 = and i64 %4417, 1
  %4419 = xor i64 %4415, %4384
  %4420 = xor i64 %4415, %4418
  %4421 = add nuw nsw i64 %4419, %4420
  %4422 = icmp eq i64 %4421, 2
  %4423 = zext i1 %4422 to i8
  store i8 %4423, i8* %17, align 1
  %4424 = add i64 %4398, 20
  %4425 = load i32, i32* %EDI.i3928, align 4
  %4426 = add i64 %4351, 49
  store i64 %4426, i64* %3, align 8
  %4427 = inttoptr i64 %4424 to i32*
  store i32 %4425, i32* %4427, align 4
  %4428 = load i64, i64* %RAX.i2610, align 8
  %4429 = load i64, i64* %RBP.i, align 8
  %4430 = add i64 %4429, -516
  %4431 = load i64, i64* %3, align 8
  %4432 = add i64 %4431, 6
  store i64 %4432, i64* %3, align 8
  %4433 = trunc i64 %4428 to i32
  %4434 = inttoptr i64 %4430 to i32*
  %4435 = load i32, i32* %4434, align 4
  %4436 = sub i32 %4433, %4435
  %4437 = zext i32 %4436 to i64
  store i64 %4437, i64* %RAX.i2610, align 8
  %4438 = icmp ult i32 %4433, %4435
  %4439 = zext i1 %4438 to i8
  store i8 %4439, i8* %12, align 1
  %4440 = and i32 %4436, 255
  %4441 = tail call i32 @llvm.ctpop.i32(i32 %4440)
  %4442 = trunc i32 %4441 to i8
  %4443 = and i8 %4442, 1
  %4444 = xor i8 %4443, 1
  store i8 %4444, i8* %13, align 1
  %4445 = xor i32 %4435, %4433
  %4446 = xor i32 %4445, %4436
  %4447 = lshr i32 %4446, 4
  %4448 = trunc i32 %4447 to i8
  %4449 = and i8 %4448, 1
  store i8 %4449, i8* %14, align 1
  %4450 = icmp eq i32 %4436, 0
  %4451 = zext i1 %4450 to i8
  store i8 %4451, i8* %15, align 1
  %4452 = lshr i32 %4436, 31
  %4453 = trunc i32 %4452 to i8
  store i8 %4453, i8* %16, align 1
  %4454 = lshr i32 %4433, 31
  %4455 = lshr i32 %4435, 31
  %4456 = xor i32 %4455, %4454
  %4457 = xor i32 %4452, %4454
  %4458 = add nuw nsw i32 %4457, %4456
  %4459 = icmp eq i32 %4458, 2
  %4460 = zext i1 %4459 to i8
  store i8 %4460, i8* %17, align 1
  %4461 = add i64 %4429, -528
  %4462 = add i64 %4431, 12
  store i64 %4462, i64* %3, align 8
  %4463 = inttoptr i64 %4461 to i32*
  %4464 = load i32, i32* %4463, align 4
  %4465 = sext i32 %4464 to i64
  %4466 = ashr i64 %4465, 1
  %4467 = lshr i64 %4466, 1
  %4468 = and i64 %4467, 4294967295
  store i64 %4468, i64* %RDI.i4084, align 8
  %4469 = trunc i64 %4467 to i32
  %4470 = add i32 %4469, %4436
  %4471 = zext i32 %4470 to i64
  store i64 %4471, i64* %RAX.i2610, align 8
  %4472 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4473 = add i64 %4472, 13112
  store i64 %4473, i64* %RCX.i3977, align 8
  %4474 = icmp ugt i64 %4472, -13113
  %4475 = zext i1 %4474 to i8
  store i8 %4475, i8* %12, align 1
  %4476 = trunc i64 %4473 to i32
  %4477 = and i32 %4476, 255
  %4478 = tail call i32 @llvm.ctpop.i32(i32 %4477)
  %4479 = trunc i32 %4478 to i8
  %4480 = and i8 %4479, 1
  %4481 = xor i8 %4480, 1
  store i8 %4481, i8* %13, align 1
  %4482 = xor i64 %4472, 16
  %4483 = xor i64 %4482, %4473
  %4484 = lshr i64 %4483, 4
  %4485 = trunc i64 %4484 to i8
  %4486 = and i8 %4485, 1
  store i8 %4486, i8* %14, align 1
  %4487 = icmp eq i64 %4473, 0
  %4488 = zext i1 %4487 to i8
  store i8 %4488, i8* %15, align 1
  %4489 = lshr i64 %4473, 63
  %4490 = trunc i64 %4489 to i8
  store i8 %4490, i8* %16, align 1
  %4491 = lshr i64 %4472, 63
  %4492 = xor i64 %4489, %4491
  %4493 = add nuw nsw i64 %4492, %4489
  %4494 = icmp eq i64 %4493, 2
  %4495 = zext i1 %4494 to i8
  store i8 %4495, i8* %17, align 1
  %4496 = load i64, i64* %RBP.i, align 8
  %4497 = add i64 %4496, -24
  %4498 = add i64 %4431, 36
  store i64 %4498, i64* %3, align 8
  %4499 = inttoptr i64 %4497 to i32*
  %4500 = load i32, i32* %4499, align 4
  %4501 = sext i32 %4500 to i64
  %4502 = shl nsw i64 %4501, 6
  store i64 %4502, i64* %RDX.i4094, align 8
  %4503 = add i64 %4502, %4473
  store i64 %4503, i64* %RCX.i3977, align 8
  %4504 = icmp ult i64 %4503, %4473
  %4505 = icmp ult i64 %4503, %4502
  %4506 = or i1 %4504, %4505
  %4507 = zext i1 %4506 to i8
  store i8 %4507, i8* %12, align 1
  %4508 = trunc i64 %4503 to i32
  %4509 = and i32 %4508, 255
  %4510 = tail call i32 @llvm.ctpop.i32(i32 %4509)
  %4511 = trunc i32 %4510 to i8
  %4512 = and i8 %4511, 1
  %4513 = xor i8 %4512, 1
  store i8 %4513, i8* %13, align 1
  %4514 = xor i64 %4473, %4503
  %4515 = lshr i64 %4514, 4
  %4516 = trunc i64 %4515 to i8
  %4517 = and i8 %4516, 1
  store i8 %4517, i8* %14, align 1
  %4518 = icmp eq i64 %4503, 0
  %4519 = zext i1 %4518 to i8
  store i8 %4519, i8* %15, align 1
  %4520 = lshr i64 %4503, 63
  %4521 = trunc i64 %4520 to i8
  store i8 %4521, i8* %16, align 1
  %4522 = lshr i64 %4501, 57
  %4523 = and i64 %4522, 1
  %4524 = xor i64 %4520, %4489
  %4525 = xor i64 %4520, %4523
  %4526 = add nuw nsw i64 %4524, %4525
  %4527 = icmp eq i64 %4526, 2
  %4528 = zext i1 %4527 to i8
  store i8 %4528, i8* %17, align 1
  %4529 = add i64 %4503, 28
  %4530 = load i32, i32* %EAX.i2609, align 4
  %4531 = add i64 %4431, 46
  store i64 %4531, i64* %3, align 8
  %4532 = inttoptr i64 %4529 to i32*
  store i32 %4530, i32* %4532, align 4
  %4533 = load i64, i64* %RBP.i, align 8
  %4534 = add i64 %4533, -24
  %4535 = load i64, i64* %3, align 8
  %4536 = add i64 %4535, 3
  store i64 %4536, i64* %3, align 8
  %4537 = inttoptr i64 %4534 to i32*
  %4538 = load i32, i32* %4537, align 4
  %4539 = add i32 %4538, 1
  %4540 = zext i32 %4539 to i64
  store i64 %4540, i64* %RAX.i2610, align 8
  %4541 = icmp eq i32 %4538, -1
  %4542 = icmp eq i32 %4539, 0
  %4543 = or i1 %4541, %4542
  %4544 = zext i1 %4543 to i8
  store i8 %4544, i8* %12, align 1
  %4545 = and i32 %4539, 255
  %4546 = tail call i32 @llvm.ctpop.i32(i32 %4545)
  %4547 = trunc i32 %4546 to i8
  %4548 = and i8 %4547, 1
  %4549 = xor i8 %4548, 1
  store i8 %4549, i8* %13, align 1
  %4550 = xor i32 %4539, %4538
  %4551 = lshr i32 %4550, 4
  %4552 = trunc i32 %4551 to i8
  %4553 = and i8 %4552, 1
  store i8 %4553, i8* %14, align 1
  %4554 = zext i1 %4542 to i8
  store i8 %4554, i8* %15, align 1
  %4555 = lshr i32 %4539, 31
  %4556 = trunc i32 %4555 to i8
  store i8 %4556, i8* %16, align 1
  %4557 = lshr i32 %4538, 31
  %4558 = xor i32 %4555, %4557
  %4559 = add nuw nsw i32 %4558, %4555
  %4560 = icmp eq i32 %4559, 2
  %4561 = zext i1 %4560 to i8
  store i8 %4561, i8* %17, align 1
  %4562 = add i64 %4535, 9
  store i64 %4562, i64* %3, align 8
  store i32 %4539, i32* %4537, align 4
  %4563 = load i64, i64* %3, align 8
  %4564 = add i64 %4563, -985
  store i64 %4564, i64* %3, align 8
  br label %block_.L_4aacbc

block_.L_4ab106:                                  ; preds = %block_.L_4ab6cd, %block_4aacf0
  %4565 = phi i64 [ %.pre176, %block_4aacf0 ], [ %7011, %block_.L_4ab6cd ]
  %MEMORY.7 = phi %struct.Memory* [ %MEMORY.2, %block_4aacf0 ], [ %MEMORY.21, %block_.L_4ab6cd ]
  %4566 = load i64, i64* %RBP.i, align 8
  %4567 = add i64 %4566, -36
  %4568 = add i64 %4565, 4
  store i64 %4568, i64* %3, align 8
  %4569 = inttoptr i64 %4567 to i32*
  %4570 = load i32, i32* %4569, align 4
  %4571 = add i32 %4570, -64
  %4572 = icmp ult i32 %4570, 64
  %4573 = zext i1 %4572 to i8
  store i8 %4573, i8* %12, align 1
  %4574 = and i32 %4571, 255
  %4575 = tail call i32 @llvm.ctpop.i32(i32 %4574)
  %4576 = trunc i32 %4575 to i8
  %4577 = and i8 %4576, 1
  %4578 = xor i8 %4577, 1
  store i8 %4578, i8* %13, align 1
  %4579 = xor i32 %4571, %4570
  %4580 = lshr i32 %4579, 4
  %4581 = trunc i32 %4580 to i8
  %4582 = and i8 %4581, 1
  store i8 %4582, i8* %14, align 1
  %4583 = icmp eq i32 %4571, 0
  %4584 = zext i1 %4583 to i8
  store i8 %4584, i8* %15, align 1
  %4585 = lshr i32 %4571, 31
  %4586 = trunc i32 %4585 to i8
  store i8 %4586, i8* %16, align 1
  %4587 = lshr i32 %4570, 31
  %4588 = xor i32 %4585, %4587
  %4589 = add nuw nsw i32 %4588, %4587
  %4590 = icmp eq i32 %4589, 2
  %4591 = zext i1 %4590 to i8
  store i8 %4591, i8* %17, align 1
  %4592 = icmp ne i8 %4586, 0
  %4593 = xor i1 %4592, %4590
  %.v210 = select i1 %4593, i64 10, i64 1498
  %4594 = add i64 %4565, %.v210
  store i64 %4594, i64* %3, align 8
  br i1 %4593, label %block_4ab110, label %block_.L_4ab6e0

block_4ab110:                                     ; preds = %block_.L_4ab106
  %4595 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %4595, i64* %RAX.i2610, align 8
  %4596 = add i64 %4595, 72444
  %4597 = add i64 %4594, 15
  store i64 %4597, i64* %3, align 8
  %4598 = inttoptr i64 %4596 to i32*
  %4599 = load i32, i32* %4598, align 4
  store i8 0, i8* %12, align 1
  %4600 = and i32 %4599, 255
  %4601 = tail call i32 @llvm.ctpop.i32(i32 %4600)
  %4602 = trunc i32 %4601 to i8
  %4603 = and i8 %4602, 1
  %4604 = xor i8 %4603, 1
  store i8 %4604, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %4605 = icmp eq i32 %4599, 0
  %4606 = zext i1 %4605 to i8
  store i8 %4606, i8* %15, align 1
  %4607 = lshr i32 %4599, 31
  %4608 = trunc i32 %4607 to i8
  store i8 %4608, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v221 = select i1 %4605, i64 21, i64 62
  %4609 = add i64 %4594, %.v221
  store i64 %4609, i64* %3, align 8
  br i1 %4605, label %block_4ab125, label %block_.L_4ab14e

block_4ab125:                                     ; preds = %block_4ab110
  store i64 %4595, i64* %RAX.i2610, align 8
  %4610 = add i64 %4595, 72400
  %4611 = add i64 %4609, 15
  store i64 %4611, i64* %3, align 8
  %4612 = inttoptr i64 %4610 to i32*
  %4613 = load i32, i32* %4612, align 4
  store i8 0, i8* %12, align 1
  %4614 = and i32 %4613, 255
  %4615 = tail call i32 @llvm.ctpop.i32(i32 %4614)
  %4616 = trunc i32 %4615 to i8
  %4617 = and i8 %4616, 1
  %4618 = xor i8 %4617, 1
  store i8 %4618, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %4619 = icmp eq i32 %4613, 0
  %4620 = zext i1 %4619 to i8
  store i8 %4620, i8* %15, align 1
  %4621 = lshr i32 %4613, 31
  %4622 = trunc i32 %4621 to i8
  store i8 %4622, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v231 = select i1 %4619, i64 76, i64 21
  %4623 = add i64 %4609, %.v231
  store i64 %4623, i64* %3, align 8
  br i1 %4619, label %block_.L_4ab171, label %block_4ab13a

block_4ab13a:                                     ; preds = %block_4ab125
  %4624 = add i64 %4566, -408
  %4625 = add i64 %4623, 7
  store i64 %4625, i64* %3, align 8
  %4626 = inttoptr i64 %4624 to i64*
  %4627 = load i64, i64* %4626, align 8
  store i64 %4627, i64* %RAX.i2610, align 8
  %4628 = add i64 %4627, 532
  %4629 = add i64 %4623, 14
  store i64 %4629, i64* %3, align 8
  %4630 = inttoptr i64 %4628 to i32*
  %4631 = load i32, i32* %4630, align 4
  store i8 0, i8* %12, align 1
  %4632 = and i32 %4631, 255
  %4633 = tail call i32 @llvm.ctpop.i32(i32 %4632)
  %4634 = trunc i32 %4633 to i8
  %4635 = and i8 %4634, 1
  %4636 = xor i8 %4635, 1
  store i8 %4636, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %4637 = icmp eq i32 %4631, 0
  %4638 = zext i1 %4637 to i8
  store i8 %4638, i8* %15, align 1
  %4639 = lshr i32 %4631, 31
  %4640 = trunc i32 %4639 to i8
  store i8 %4640, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v232 = select i1 %4637, i64 55, i64 20
  %4641 = add i64 %4623, %.v232
  store i64 %4641, i64* %3, align 8
  br i1 %4637, label %block_.L_4ab171, label %block_.L_4ab14e

block_.L_4ab14e:                                  ; preds = %block_4ab110, %block_4ab13a
  %4642 = phi i64 [ %4641, %block_4ab13a ], [ %4609, %block_4ab110 ]
  %4643 = add i64 %4642, 4
  store i64 %4643, i64* %3, align 8
  %4644 = load i32, i32* %4569, align 4
  %4645 = sext i32 %4644 to i64
  store i64 %4645, i64* %RAX.i2610, align 8
  %4646 = shl nsw i64 %4645, 1
  %4647 = add nsw i64 %4646, 4957136
  %4648 = add i64 %4642, 12
  store i64 %4648, i64* %3, align 8
  %4649 = inttoptr i64 %4647 to i8*
  %4650 = load i8, i8* %4649, align 2
  %4651 = zext i8 %4650 to i64
  store i64 %4651, i64* %RCX.i3977, align 8
  %4652 = add i64 %4566, -24
  %4653 = zext i8 %4650 to i32
  %4654 = add i64 %4642, 15
  store i64 %4654, i64* %3, align 8
  %4655 = inttoptr i64 %4652 to i32*
  store i32 %4653, i32* %4655, align 4
  %4656 = load i64, i64* %RBP.i, align 8
  %4657 = add i64 %4656, -36
  %4658 = load i64, i64* %3, align 8
  %4659 = add i64 %4658, 4
  store i64 %4659, i64* %3, align 8
  %4660 = inttoptr i64 %4657 to i32*
  %4661 = load i32, i32* %4660, align 4
  %4662 = sext i32 %4661 to i64
  store i64 %4662, i64* %RAX.i2610, align 8
  %4663 = shl nsw i64 %4662, 1
  %4664 = add nsw i64 %4663, 4957137
  %4665 = add i64 %4658, 12
  store i64 %4665, i64* %3, align 8
  %4666 = inttoptr i64 %4664 to i8*
  %4667 = load i8, i8* %4666, align 1
  %4668 = zext i8 %4667 to i64
  store i64 %4668, i64* %RCX.i3977, align 8
  %4669 = add i64 %4656, -28
  %4670 = zext i8 %4667 to i32
  %4671 = add i64 %4658, 15
  store i64 %4671, i64* %3, align 8
  %4672 = inttoptr i64 %4669 to i32*
  store i32 %4670, i32* %4672, align 4
  %4673 = load i64, i64* %3, align 8
  %4674 = add i64 %4673, 35
  store i64 %4674, i64* %3, align 8
  br label %block_.L_4ab18f

block_.L_4ab171:                                  ; preds = %block_4ab13a, %block_4ab125
  %4675 = phi i64 [ %4641, %block_4ab13a ], [ %4623, %block_4ab125 ]
  %4676 = add i64 %4675, 4
  store i64 %4676, i64* %3, align 8
  %4677 = load i32, i32* %4569, align 4
  %4678 = sext i32 %4677 to i64
  store i64 %4678, i64* %RAX.i2610, align 8
  %4679 = shl nsw i64 %4678, 1
  %4680 = add nsw i64 %4679, 4957008
  %4681 = add i64 %4675, 12
  store i64 %4681, i64* %3, align 8
  %4682 = inttoptr i64 %4680 to i8*
  %4683 = load i8, i8* %4682, align 2
  %4684 = zext i8 %4683 to i64
  store i64 %4684, i64* %RCX.i3977, align 8
  %4685 = add i64 %4566, -24
  %4686 = zext i8 %4683 to i32
  %4687 = add i64 %4675, 15
  store i64 %4687, i64* %3, align 8
  %4688 = inttoptr i64 %4685 to i32*
  store i32 %4686, i32* %4688, align 4
  %4689 = load i64, i64* %RBP.i, align 8
  %4690 = add i64 %4689, -36
  %4691 = load i64, i64* %3, align 8
  %4692 = add i64 %4691, 4
  store i64 %4692, i64* %3, align 8
  %4693 = inttoptr i64 %4690 to i32*
  %4694 = load i32, i32* %4693, align 4
  %4695 = sext i32 %4694 to i64
  store i64 %4695, i64* %RAX.i2610, align 8
  %4696 = shl nsw i64 %4695, 1
  %4697 = add nsw i64 %4696, 4957009
  %4698 = add i64 %4691, 12
  store i64 %4698, i64* %3, align 8
  %4699 = inttoptr i64 %4697 to i8*
  %4700 = load i8, i8* %4699, align 1
  %4701 = zext i8 %4700 to i64
  store i64 %4701, i64* %RCX.i3977, align 8
  %4702 = add i64 %4689, -28
  %4703 = zext i8 %4700 to i32
  %4704 = add i64 %4691, 15
  store i64 %4704, i64* %3, align 8
  %4705 = inttoptr i64 %4702 to i32*
  store i32 %4703, i32* %4705, align 4
  %.pre191 = load i64, i64* %3, align 8
  br label %block_.L_4ab18f

block_.L_4ab18f:                                  ; preds = %block_.L_4ab171, %block_.L_4ab14e
  %4706 = phi i64 [ %.pre191, %block_.L_4ab171 ], [ %4674, %block_.L_4ab14e ]
  %4707 = load i64, i64* %RBP.i, align 8
  %4708 = add i64 %4707, -52
  %4709 = add i64 %4706, 3
  store i64 %4709, i64* %3, align 8
  %4710 = inttoptr i64 %4708 to i32*
  %4711 = load i32, i32* %4710, align 4
  %4712 = add i32 %4711, 1
  %4713 = zext i32 %4712 to i64
  store i64 %4713, i64* %RAX.i2610, align 8
  %4714 = icmp eq i32 %4711, -1
  %4715 = icmp eq i32 %4712, 0
  %4716 = or i1 %4714, %4715
  %4717 = zext i1 %4716 to i8
  store i8 %4717, i8* %12, align 1
  %4718 = and i32 %4712, 255
  %4719 = tail call i32 @llvm.ctpop.i32(i32 %4718)
  %4720 = trunc i32 %4719 to i8
  %4721 = and i8 %4720, 1
  %4722 = xor i8 %4721, 1
  store i8 %4722, i8* %13, align 1
  %4723 = xor i32 %4712, %4711
  %4724 = lshr i32 %4723, 4
  %4725 = trunc i32 %4724 to i8
  %4726 = and i8 %4725, 1
  store i8 %4726, i8* %14, align 1
  %4727 = zext i1 %4715 to i8
  store i8 %4727, i8* %15, align 1
  %4728 = lshr i32 %4712, 31
  %4729 = trunc i32 %4728 to i8
  store i8 %4729, i8* %16, align 1
  %4730 = lshr i32 %4711, 31
  %4731 = xor i32 %4728, %4730
  %4732 = add nuw nsw i32 %4731, %4728
  %4733 = icmp eq i32 %4732, 2
  %4734 = zext i1 %4733 to i8
  store i8 %4734, i8* %17, align 1
  %4735 = add i64 %4706, 9
  store i64 %4735, i64* %3, align 8
  store i32 %4712, i32* %4710, align 4
  %4736 = load i64, i64* %RBP.i, align 8
  %4737 = add i64 %4736, -32
  %4738 = load i64, i64* %3, align 8
  %4739 = add i64 %4738, 7
  store i64 %4739, i64* %3, align 8
  %4740 = inttoptr i64 %4737 to i32*
  store i32 0, i32* %4740, align 4
  %4741 = load i64, i64* %RBP.i, align 8
  %4742 = add i64 %4741, -36
  %4743 = load i64, i64* %3, align 8
  %4744 = add i64 %4743, 3
  store i64 %4744, i64* %3, align 8
  %4745 = inttoptr i64 %4742 to i32*
  %4746 = load i32, i32* %4745, align 4
  %4747 = and i32 %4746, 3
  %4748 = zext i32 %4747 to i64
  store i64 %4748, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  %4749 = tail call i32 @llvm.ctpop.i32(i32 %4747)
  %4750 = trunc i32 %4749 to i8
  %4751 = and i8 %4750, 1
  %4752 = xor i8 %4751, 1
  store i8 %4752, i8* %13, align 1
  %4753 = icmp eq i32 %4747, 0
  %4754 = zext i1 %4753 to i8
  store i8 %4754, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %4748, i64* %RCX.i3977, align 8
  %4755 = shl nuw nsw i32 %4747, 2
  %4756 = zext i32 %4755 to i64
  %4757 = or i64 %4756, -400
  %4758 = add i64 %4757, %4741
  %4759 = add i64 %4743, 16
  store i64 %4759, i64* %3, align 8
  %4760 = inttoptr i64 %4758 to i32*
  %4761 = load i32, i32* %4760, align 4
  %4762 = add i32 %4761, 1
  %4763 = zext i32 %4762 to i64
  store i64 %4763, i64* %RAX.i2610, align 8
  %4764 = icmp eq i32 %4761, -1
  %4765 = icmp eq i32 %4762, 0
  %4766 = or i1 %4764, %4765
  %4767 = zext i1 %4766 to i8
  store i8 %4767, i8* %12, align 1
  %4768 = and i32 %4762, 255
  %4769 = tail call i32 @llvm.ctpop.i32(i32 %4768)
  %4770 = trunc i32 %4769 to i8
  %4771 = and i8 %4770, 1
  %4772 = xor i8 %4771, 1
  store i8 %4772, i8* %13, align 1
  %4773 = xor i32 %4762, %4761
  %4774 = lshr i32 %4773, 4
  %4775 = trunc i32 %4774 to i8
  %4776 = and i8 %4775, 1
  store i8 %4776, i8* %14, align 1
  %4777 = zext i1 %4765 to i8
  store i8 %4777, i8* %15, align 1
  %4778 = lshr i32 %4762, 31
  %4779 = trunc i32 %4778 to i8
  store i8 %4779, i8* %16, align 1
  %4780 = lshr i32 %4761, 31
  %4781 = xor i32 %4778, %4780
  %4782 = add nuw nsw i32 %4781, %4778
  %4783 = icmp eq i32 %4782, 2
  %4784 = zext i1 %4783 to i8
  store i8 %4784, i8* %17, align 1
  %4785 = add i64 %4741, -400
  %4786 = add i64 %4785, %4756
  %4787 = add i64 %4743, 26
  store i64 %4787, i64* %3, align 8
  %4788 = inttoptr i64 %4786 to i32*
  store i32 %4762, i32* %4788, align 4
  %4789 = load i64, i64* %RBP.i, align 8
  %4790 = add i64 %4789, -412
  %4791 = load i64, i64* %3, align 8
  %4792 = add i64 %4791, 7
  store i64 %4792, i64* %3, align 8
  %4793 = inttoptr i64 %4790 to i32*
  %4794 = load i32, i32* %4793, align 4
  store i8 0, i8* %12, align 1
  %4795 = and i32 %4794, 255
  %4796 = tail call i32 @llvm.ctpop.i32(i32 %4795)
  %4797 = trunc i32 %4796 to i8
  %4798 = and i8 %4797, 1
  %4799 = xor i8 %4798, 1
  store i8 %4799, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %4800 = icmp eq i32 %4794, 0
  %4801 = zext i1 %4800 to i8
  store i8 %4801, i8* %15, align 1
  %4802 = lshr i32 %4794, 31
  %4803 = trunc i32 %4802 to i8
  store i8 %4803, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v222 = select i1 %4800, i64 58, i64 13
  %4804 = add i64 %4791, %.v222
  store i64 %4804, i64* %3, align 8
  br i1 %4800, label %block_.L_4ab1f3, label %block_4ab1c6

block_4ab1c6:                                     ; preds = %block_.L_4ab18f
  %4805 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4806 = add i64 %4805, 13112
  store i64 %4806, i64* %RAX.i2610, align 8
  %4807 = icmp ugt i64 %4805, -13113
  %4808 = zext i1 %4807 to i8
  store i8 %4808, i8* %12, align 1
  %4809 = trunc i64 %4806 to i32
  %4810 = and i32 %4809, 255
  %4811 = tail call i32 @llvm.ctpop.i32(i32 %4810)
  %4812 = trunc i32 %4811 to i8
  %4813 = and i8 %4812, 1
  %4814 = xor i8 %4813, 1
  store i8 %4814, i8* %13, align 1
  %4815 = xor i64 %4805, 16
  %4816 = xor i64 %4815, %4806
  %4817 = lshr i64 %4816, 4
  %4818 = trunc i64 %4817 to i8
  %4819 = and i8 %4818, 1
  store i8 %4819, i8* %14, align 1
  %4820 = icmp eq i64 %4806, 0
  %4821 = zext i1 %4820 to i8
  store i8 %4821, i8* %15, align 1
  %4822 = lshr i64 %4806, 63
  %4823 = trunc i64 %4822 to i8
  store i8 %4823, i8* %16, align 1
  %4824 = lshr i64 %4805, 63
  %4825 = xor i64 %4822, %4824
  %4826 = add nuw nsw i64 %4825, %4822
  %4827 = icmp eq i64 %4826, 2
  %4828 = zext i1 %4827 to i8
  store i8 %4828, i8* %17, align 1
  %4829 = add i64 %4789, -24
  %4830 = add i64 %4804, 18
  store i64 %4830, i64* %3, align 8
  %4831 = inttoptr i64 %4829 to i32*
  %4832 = load i32, i32* %4831, align 4
  %4833 = sext i32 %4832 to i64
  %4834 = shl nsw i64 %4833, 6
  store i64 %4834, i64* %RCX.i3977, align 8
  %4835 = add i64 %4834, %4806
  store i64 %4835, i64* %RAX.i2610, align 8
  %4836 = icmp ult i64 %4835, %4806
  %4837 = icmp ult i64 %4835, %4834
  %4838 = or i1 %4836, %4837
  %4839 = zext i1 %4838 to i8
  store i8 %4839, i8* %12, align 1
  %4840 = trunc i64 %4835 to i32
  %4841 = and i32 %4840, 255
  %4842 = tail call i32 @llvm.ctpop.i32(i32 %4841)
  %4843 = trunc i32 %4842 to i8
  %4844 = and i8 %4843, 1
  %4845 = xor i8 %4844, 1
  store i8 %4845, i8* %13, align 1
  %4846 = xor i64 %4806, %4835
  %4847 = lshr i64 %4846, 4
  %4848 = trunc i64 %4847 to i8
  %4849 = and i8 %4848, 1
  store i8 %4849, i8* %14, align 1
  %4850 = icmp eq i64 %4835, 0
  %4851 = zext i1 %4850 to i8
  store i8 %4851, i8* %15, align 1
  %4852 = lshr i64 %4835, 63
  %4853 = trunc i64 %4852 to i8
  store i8 %4853, i8* %16, align 1
  %4854 = lshr i64 %4833, 57
  %4855 = and i64 %4854, 1
  %4856 = xor i64 %4852, %4822
  %4857 = xor i64 %4852, %4855
  %4858 = add nuw nsw i64 %4856, %4857
  %4859 = icmp eq i64 %4858, 2
  %4860 = zext i1 %4859 to i8
  store i8 %4860, i8* %17, align 1
  %4861 = load i64, i64* %RBP.i, align 8
  %4862 = add i64 %4861, -28
  %4863 = add i64 %4804, 29
  store i64 %4863, i64* %3, align 8
  %4864 = inttoptr i64 %4862 to i32*
  %4865 = load i32, i32* %4864, align 4
  %4866 = sext i32 %4865 to i64
  store i64 %4866, i64* %RCX.i3977, align 8
  %4867 = shl nsw i64 %4866, 2
  %4868 = add i64 %4867, %4835
  %4869 = add i64 %4804, 32
  store i64 %4869, i64* %3, align 8
  %4870 = inttoptr i64 %4868 to i32*
  %4871 = load i32, i32* %4870, align 4
  %4872 = zext i32 %4871 to i64
  store i64 %4872, i64* %RDI.i4084, align 8
  %4873 = add i64 %4804, -696774
  %4874 = add i64 %4804, 37
  %4875 = load i64, i64* %6, align 8
  %4876 = add i64 %4875, -8
  %4877 = inttoptr i64 %4876 to i64*
  store i64 %4874, i64* %4877, align 8
  store i64 %4876, i64* %6, align 8
  store i64 %4873, i64* %3, align 8
  %4878 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 ptrtoint (i64 (i64)* @abs to i64), %struct.Memory* %MEMORY.7)
  %4879 = load i64, i64* %RBP.i, align 8
  %4880 = add i64 %4879, -44
  %4881 = load i32, i32* %EAX.i2609, align 4
  %4882 = load i64, i64* %3, align 8
  %4883 = add i64 %4882, 3
  store i64 %4883, i64* %3, align 8
  %4884 = inttoptr i64 %4880 to i32*
  store i32 %4881, i32* %4884, align 4
  %4885 = load i64, i64* %3, align 8
  %4886 = add i64 %4885, 273
  br label %block_.L_4ab2ff

block_.L_4ab1f3:                                  ; preds = %block_.L_4ab18f
  %4887 = add i64 %4789, -20
  %4888 = add i64 %4804, 4
  store i64 %4888, i64* %3, align 8
  %4889 = inttoptr i64 %4887 to i32*
  %4890 = load i32, i32* %4889, align 4
  %4891 = icmp eq i32 %4890, 1
  %.v230 = select i1 %4891, i64 10, i64 139
  %4892 = add i64 %4804, %.v230
  %4893 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %4894 = add i64 %4893, 13112
  store i64 %4894, i64* %RAX.i2610, align 8
  %4895 = icmp ugt i64 %4893, -13113
  %4896 = zext i1 %4895 to i8
  store i8 %4896, i8* %12, align 1
  %4897 = trunc i64 %4894 to i32
  %4898 = and i32 %4897, 255
  %4899 = tail call i32 @llvm.ctpop.i32(i32 %4898)
  %4900 = trunc i32 %4899 to i8
  %4901 = and i8 %4900, 1
  %4902 = xor i8 %4901, 1
  store i8 %4902, i8* %13, align 1
  %4903 = xor i64 %4893, 16
  %4904 = xor i64 %4903, %4894
  %4905 = lshr i64 %4904, 4
  %4906 = trunc i64 %4905 to i8
  %4907 = and i8 %4906, 1
  store i8 %4907, i8* %14, align 1
  %4908 = icmp eq i64 %4894, 0
  %4909 = zext i1 %4908 to i8
  store i8 %4909, i8* %15, align 1
  %4910 = lshr i64 %4894, 63
  %4911 = trunc i64 %4910 to i8
  store i8 %4911, i8* %16, align 1
  %4912 = lshr i64 %4893, 63
  %4913 = xor i64 %4910, %4912
  %4914 = add nuw nsw i64 %4913, %4910
  %4915 = icmp eq i64 %4914, 2
  %4916 = zext i1 %4915 to i8
  store i8 %4916, i8* %17, align 1
  %4917 = add i64 %4789, -24
  %4918 = add i64 %4892, 18
  store i64 %4918, i64* %3, align 8
  %4919 = inttoptr i64 %4917 to i32*
  %4920 = load i32, i32* %4919, align 4
  %4921 = sext i32 %4920 to i64
  %4922 = shl nsw i64 %4921, 6
  store i64 %4922, i64* %RCX.i3977, align 8
  %4923 = add i64 %4922, %4894
  store i64 %4923, i64* %RAX.i2610, align 8
  %4924 = icmp ult i64 %4923, %4894
  %4925 = icmp ult i64 %4923, %4922
  %4926 = or i1 %4924, %4925
  %4927 = zext i1 %4926 to i8
  store i8 %4927, i8* %12, align 1
  %4928 = trunc i64 %4923 to i32
  %4929 = and i32 %4928, 255
  %4930 = tail call i32 @llvm.ctpop.i32(i32 %4929)
  %4931 = trunc i32 %4930 to i8
  %4932 = and i8 %4931, 1
  %4933 = xor i8 %4932, 1
  store i8 %4933, i8* %13, align 1
  %4934 = xor i64 %4894, %4923
  %4935 = lshr i64 %4934, 4
  %4936 = trunc i64 %4935 to i8
  %4937 = and i8 %4936, 1
  store i8 %4937, i8* %14, align 1
  %4938 = icmp eq i64 %4923, 0
  %4939 = zext i1 %4938 to i8
  store i8 %4939, i8* %15, align 1
  %4940 = lshr i64 %4923, 63
  %4941 = trunc i64 %4940 to i8
  store i8 %4941, i8* %16, align 1
  %4942 = lshr i64 %4921, 57
  %4943 = and i64 %4942, 1
  %4944 = xor i64 %4940, %4910
  %4945 = xor i64 %4940, %4943
  %4946 = add nuw nsw i64 %4944, %4945
  %4947 = icmp eq i64 %4946, 2
  %4948 = zext i1 %4947 to i8
  store i8 %4948, i8* %17, align 1
  %4949 = load i64, i64* %RBP.i, align 8
  %4950 = add i64 %4949, -28
  %4951 = add i64 %4892, 29
  store i64 %4951, i64* %3, align 8
  %4952 = inttoptr i64 %4950 to i32*
  %4953 = load i32, i32* %4952, align 4
  %4954 = sext i32 %4953 to i64
  store i64 %4954, i64* %RCX.i3977, align 8
  %4955 = shl nsw i64 %4954, 2
  %4956 = add i64 %4955, %4923
  %4957 = add i64 %4892, 32
  store i64 %4957, i64* %3, align 8
  %4958 = inttoptr i64 %4956 to i32*
  %4959 = load i32, i32* %4958, align 4
  %4960 = zext i32 %4959 to i64
  store i64 %4960, i64* %RDI.i4084, align 8
  br i1 %4891, label %block_4ab1fd, label %block_.L_4ab27e

block_4ab1fd:                                     ; preds = %block_.L_4ab1f3
  %4961 = add i64 %4892, -696829
  %4962 = add i64 %4892, 37
  %4963 = load i64, i64* %6, align 8
  %4964 = add i64 %4963, -8
  %4965 = inttoptr i64 %4964 to i64*
  store i64 %4962, i64* %4965, align 8
  store i64 %4964, i64* %6, align 8
  store i64 %4961, i64* %3, align 8
  %4966 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 ptrtoint (i64 (i64)* @abs to i64), %struct.Memory* %MEMORY.7)
  %4967 = load i64, i64* %3, align 8
  store i64 7156720, i64* %RCX.i3977, align 8
  store i64 ptrtoint (%G__0x6d0bc0_type* @G__0x6d0bc0 to i64), i64* %RDX.i4094, align 8
  %4968 = load i64, i64* %RBP.i, align 8
  %4969 = add i64 %4968, -64
  %4970 = add i64 %4967, 24
  store i64 %4970, i64* %3, align 8
  %4971 = inttoptr i64 %4969 to i32*
  %4972 = load i32, i32* %4971, align 4
  %4973 = sext i32 %4972 to i64
  %4974 = shl nsw i64 %4973, 8
  store i64 %4974, i64* %RSI.i3950, align 8
  %4975 = add i64 %4974, ptrtoint (%G__0x6d0bc0_type* @G__0x6d0bc0 to i64)
  store i64 %4975, i64* %RDX.i4094, align 8
  %4976 = icmp ult i64 %4975, ptrtoint (%G__0x6d0bc0_type* @G__0x6d0bc0 to i64)
  %4977 = icmp ult i64 %4975, %4974
  %4978 = or i1 %4976, %4977
  %4979 = zext i1 %4978 to i8
  store i8 %4979, i8* %12, align 1
  %4980 = trunc i64 %4975 to i32
  %4981 = and i32 %4980, 248
  %4982 = tail call i32 @llvm.ctpop.i32(i32 %4981)
  %4983 = trunc i32 %4982 to i8
  %4984 = and i8 %4983, 1
  %4985 = xor i8 %4984, 1
  store i8 %4985, i8* %13, align 1
  %4986 = xor i64 %4975, ptrtoint (%G__0x6d0bc0_type* @G__0x6d0bc0 to i64)
  %4987 = lshr i64 %4986, 4
  %4988 = trunc i64 %4987 to i8
  %4989 = and i8 %4988, 1
  store i8 %4989, i8* %14, align 1
  %4990 = icmp eq i64 %4975, 0
  %4991 = zext i1 %4990 to i8
  store i8 %4991, i8* %15, align 1
  %4992 = lshr i64 %4975, 63
  %4993 = trunc i64 %4992 to i8
  store i8 %4993, i8* %16, align 1
  %4994 = lshr i64 %4973, 55
  %4995 = and i64 %4994, 1
  %4996 = xor i64 %4992, lshr (i64 ptrtoint (%G__0x6d0bc0_type* @G__0x6d0bc0 to i64), i64 63)
  %4997 = xor i64 %4992, %4995
  %4998 = add nuw nsw i64 %4996, %4997
  %4999 = icmp eq i64 %4998, 2
  %5000 = zext i1 %4999 to i8
  store i8 %5000, i8* %17, align 1
  %5001 = add i64 %4968, -24
  %5002 = add i64 %4967, 35
  store i64 %5002, i64* %3, align 8
  %5003 = inttoptr i64 %5001 to i32*
  %5004 = load i32, i32* %5003, align 4
  %5005 = sext i32 %5004 to i64
  %5006 = shl nsw i64 %5005, 5
  store i64 %5006, i64* %RSI.i3950, align 8
  %5007 = add i64 %5006, %4975
  store i64 %5007, i64* %RDX.i4094, align 8
  %5008 = icmp ult i64 %5007, %4975
  %5009 = icmp ult i64 %5007, %5006
  %5010 = or i1 %5008, %5009
  %5011 = zext i1 %5010 to i8
  store i8 %5011, i8* %12, align 1
  %5012 = trunc i64 %5007 to i32
  %5013 = and i32 %5012, 248
  %5014 = tail call i32 @llvm.ctpop.i32(i32 %5013)
  %5015 = trunc i32 %5014 to i8
  %5016 = and i8 %5015, 1
  %5017 = xor i8 %5016, 1
  store i8 %5017, i8* %13, align 1
  %5018 = xor i64 %4975, %5007
  %5019 = lshr i64 %5018, 4
  %5020 = trunc i64 %5019 to i8
  %5021 = and i8 %5020, 1
  store i8 %5021, i8* %14, align 1
  %5022 = icmp eq i64 %5007, 0
  %5023 = zext i1 %5022 to i8
  store i8 %5023, i8* %15, align 1
  %5024 = lshr i64 %5007, 63
  %5025 = trunc i64 %5024 to i8
  store i8 %5025, i8* %16, align 1
  %5026 = lshr i64 %5005, 58
  %5027 = and i64 %5026, 1
  %5028 = xor i64 %5024, %4992
  %5029 = xor i64 %5024, %5027
  %5030 = add nuw nsw i64 %5028, %5029
  %5031 = icmp eq i64 %5030, 2
  %5032 = zext i1 %5031 to i8
  store i8 %5032, i8* %17, align 1
  %5033 = load i64, i64* %RBP.i, align 8
  %5034 = add i64 %5033, -28
  %5035 = add i64 %4967, 46
  store i64 %5035, i64* %3, align 8
  %5036 = inttoptr i64 %5034 to i32*
  %5037 = load i32, i32* %5036, align 4
  %5038 = sext i32 %5037 to i64
  store i64 %5038, i64* %RSI.i3950, align 8
  %5039 = load i64, i64* %RAX.i2610, align 8
  %5040 = shl nsw i64 %5038, 2
  %5041 = add i64 %5007, %5040
  %5042 = add i64 %4967, 50
  store i64 %5042, i64* %3, align 8
  %5043 = inttoptr i64 %5041 to i32*
  %5044 = load i32, i32* %5043, align 4
  %5045 = shl i64 %5039, 32
  %5046 = ashr exact i64 %5045, 32
  %5047 = sext i32 %5044 to i64
  %5048 = mul nsw i64 %5047, %5046
  %5049 = trunc i64 %5048 to i32
  %5050 = and i64 %5048, 4294967295
  store i64 %5050, i64* %RAX.i2610, align 8
  %5051 = shl i64 %5048, 32
  %5052 = ashr exact i64 %5051, 32
  %5053 = icmp ne i64 %5052, %5048
  %5054 = zext i1 %5053 to i8
  store i8 %5054, i8* %12, align 1
  %5055 = and i32 %5049, 255
  %5056 = tail call i32 @llvm.ctpop.i32(i32 %5055)
  %5057 = trunc i32 %5056 to i8
  %5058 = and i8 %5057, 1
  %5059 = xor i8 %5058, 1
  store i8 %5059, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  %5060 = lshr i32 %5049, 31
  %5061 = trunc i32 %5060 to i8
  store i8 %5061, i8* %16, align 1
  store i8 %5054, i8* %17, align 1
  %5062 = add i64 %5033, -60
  %5063 = add i64 %4967, 54
  store i64 %5063, i64* %3, align 8
  %5064 = inttoptr i64 %5062 to i32*
  %5065 = load i32, i32* %5064, align 4
  %5066 = sext i32 %5065 to i64
  %5067 = shl nsw i64 %5066, 8
  store i64 %5067, i64* %RDX.i4094, align 8
  %5068 = load i64, i64* %RCX.i3977, align 8
  %5069 = add i64 %5067, %5068
  store i64 %5069, i64* %RCX.i3977, align 8
  %5070 = icmp ult i64 %5069, %5068
  %5071 = icmp ult i64 %5069, %5067
  %5072 = or i1 %5070, %5071
  %5073 = zext i1 %5072 to i8
  store i8 %5073, i8* %12, align 1
  %5074 = trunc i64 %5069 to i32
  %5075 = and i32 %5074, 255
  %5076 = tail call i32 @llvm.ctpop.i32(i32 %5075)
  %5077 = trunc i32 %5076 to i8
  %5078 = and i8 %5077, 1
  %5079 = xor i8 %5078, 1
  store i8 %5079, i8* %13, align 1
  %5080 = xor i64 %5068, %5069
  %5081 = lshr i64 %5080, 4
  %5082 = trunc i64 %5081 to i8
  %5083 = and i8 %5082, 1
  store i8 %5083, i8* %14, align 1
  %5084 = icmp eq i64 %5069, 0
  %5085 = zext i1 %5084 to i8
  store i8 %5085, i8* %15, align 1
  %5086 = lshr i64 %5069, 63
  %5087 = trunc i64 %5086 to i8
  store i8 %5087, i8* %16, align 1
  %5088 = lshr i64 %5068, 63
  %5089 = lshr i64 %5066, 55
  %5090 = and i64 %5089, 1
  %5091 = xor i64 %5086, %5088
  %5092 = xor i64 %5086, %5090
  %5093 = add nuw nsw i64 %5091, %5092
  %5094 = icmp eq i64 %5093, 2
  %5095 = zext i1 %5094 to i8
  store i8 %5095, i8* %17, align 1
  %5096 = load i64, i64* %RBP.i, align 8
  %5097 = add i64 %5096, -24
  %5098 = add i64 %4967, 65
  store i64 %5098, i64* %3, align 8
  %5099 = inttoptr i64 %5097 to i32*
  %5100 = load i32, i32* %5099, align 4
  %5101 = sext i32 %5100 to i64
  %5102 = shl nsw i64 %5101, 5
  store i64 %5102, i64* %RDX.i4094, align 8
  %5103 = add i64 %5102, %5069
  store i64 %5103, i64* %RCX.i3977, align 8
  %5104 = icmp ult i64 %5103, %5069
  %5105 = icmp ult i64 %5103, %5102
  %5106 = or i1 %5104, %5105
  %5107 = zext i1 %5106 to i8
  store i8 %5107, i8* %12, align 1
  %5108 = trunc i64 %5103 to i32
  %5109 = and i32 %5108, 255
  %5110 = tail call i32 @llvm.ctpop.i32(i32 %5109)
  %5111 = trunc i32 %5110 to i8
  %5112 = and i8 %5111, 1
  %5113 = xor i8 %5112, 1
  store i8 %5113, i8* %13, align 1
  %5114 = xor i64 %5069, %5103
  %5115 = lshr i64 %5114, 4
  %5116 = trunc i64 %5115 to i8
  %5117 = and i8 %5116, 1
  store i8 %5117, i8* %14, align 1
  %5118 = icmp eq i64 %5103, 0
  %5119 = zext i1 %5118 to i8
  store i8 %5119, i8* %15, align 1
  %5120 = lshr i64 %5103, 63
  %5121 = trunc i64 %5120 to i8
  store i8 %5121, i8* %16, align 1
  %5122 = lshr i64 %5101, 58
  %5123 = and i64 %5122, 1
  %5124 = xor i64 %5120, %5086
  %5125 = xor i64 %5120, %5123
  %5126 = add nuw nsw i64 %5124, %5125
  %5127 = icmp eq i64 %5126, 2
  %5128 = zext i1 %5127 to i8
  store i8 %5128, i8* %17, align 1
  %5129 = add i64 %5096, -28
  %5130 = add i64 %4967, 76
  store i64 %5130, i64* %3, align 8
  %5131 = inttoptr i64 %5129 to i32*
  %5132 = load i32, i32* %5131, align 4
  %5133 = sext i32 %5132 to i64
  store i64 %5133, i64* %RDX.i4094, align 8
  %5134 = load i64, i64* %RAX.i2610, align 8
  %5135 = shl nsw i64 %5133, 2
  %5136 = add i64 %5103, %5135
  %5137 = add i64 %4967, 79
  store i64 %5137, i64* %3, align 8
  %5138 = trunc i64 %5134 to i32
  %5139 = inttoptr i64 %5136 to i32*
  %5140 = load i32, i32* %5139, align 4
  %5141 = add i32 %5140, %5138
  %5142 = zext i32 %5141 to i64
  store i64 %5142, i64* %RAX.i2610, align 8
  %5143 = icmp ult i32 %5141, %5138
  %5144 = icmp ult i32 %5141, %5140
  %5145 = or i1 %5143, %5144
  %5146 = zext i1 %5145 to i8
  store i8 %5146, i8* %12, align 1
  %5147 = and i32 %5141, 255
  %5148 = tail call i32 @llvm.ctpop.i32(i32 %5147)
  %5149 = trunc i32 %5148 to i8
  %5150 = and i8 %5149, 1
  %5151 = xor i8 %5150, 1
  store i8 %5151, i8* %13, align 1
  %5152 = xor i32 %5140, %5138
  %5153 = xor i32 %5152, %5141
  %5154 = lshr i32 %5153, 4
  %5155 = trunc i32 %5154 to i8
  %5156 = and i8 %5155, 1
  store i8 %5156, i8* %14, align 1
  %5157 = icmp eq i32 %5141, 0
  %5158 = zext i1 %5157 to i8
  store i8 %5158, i8* %15, align 1
  %5159 = lshr i32 %5141, 31
  %5160 = trunc i32 %5159 to i8
  store i8 %5160, i8* %16, align 1
  %5161 = lshr i32 %5138, 31
  %5162 = lshr i32 %5140, 31
  %5163 = xor i32 %5159, %5161
  %5164 = xor i32 %5159, %5162
  %5165 = add nuw nsw i32 %5163, %5164
  %5166 = icmp eq i32 %5165, 2
  %5167 = zext i1 %5166 to i8
  store i8 %5167, i8* %17, align 1
  %5168 = load i64, i64* %RBP.i, align 8
  %5169 = add i64 %5168, -68
  %5170 = add i64 %4967, 82
  store i64 %5170, i64* %3, align 8
  %5171 = inttoptr i64 %5169 to i32*
  %5172 = load i32, i32* %5171, align 4
  %5173 = zext i32 %5172 to i64
  store i64 %5173, i64* %RCX.i3977, align 8
  %5174 = add i64 %4967, 84
  store i64 %5174, i64* %3, align 8
  %5175 = trunc i32 %5172 to i5
  switch i5 %5175, label %5179 [
    i5 0, label %routine_sarl__cl___eax.exit2525
    i5 1, label %5176
  ]

; <label>:5176:                                   ; preds = %block_4ab1fd
  %5177 = shl nuw i64 %5142, 32
  %5178 = ashr i64 %5177, 33
  br label %5186

; <label>:5179:                                   ; preds = %block_4ab1fd
  %5180 = and i32 %5172, 31
  %5181 = zext i32 %5180 to i64
  %5182 = add nsw i64 %5181, -1
  %5183 = sext i32 %5141 to i64
  %5184 = ashr i64 %5183, %5182
  %5185 = lshr i64 %5184, 1
  br label %5186

; <label>:5186:                                   ; preds = %5179, %5176
  %5187 = phi i64 [ %5185, %5179 ], [ %5178, %5176 ]
  %5188 = phi i64 [ %5184, %5179 ], [ %5142, %5176 ]
  %5189 = trunc i64 %5188 to i8
  %5190 = and i8 %5189, 1
  %5191 = trunc i64 %5187 to i32
  %5192 = and i64 %5187, 4294967295
  store i64 %5192, i64* %RAX.i2610, align 8
  store i8 %5190, i8* %12, align 1
  %5193 = and i32 %5191, 255
  %5194 = tail call i32 @llvm.ctpop.i32(i32 %5193)
  %5195 = trunc i32 %5194 to i8
  %5196 = and i8 %5195, 1
  %5197 = xor i8 %5196, 1
  store i8 %5197, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %5198 = icmp eq i32 %5191, 0
  %5199 = zext i1 %5198 to i8
  store i8 %5199, i8* %15, align 1
  %5200 = lshr i32 %5191, 31
  %5201 = trunc i32 %5200 to i8
  store i8 %5201, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %5202 = trunc i64 %5187 to i32
  br label %routine_sarl__cl___eax.exit2525

routine_sarl__cl___eax.exit2525:                  ; preds = %5186, %block_4ab1fd
  %5203 = phi i32 [ %5202, %5186 ], [ %5141, %block_4ab1fd ]
  %5204 = add i64 %5168, -44
  %5205 = add i64 %4967, 87
  store i64 %5205, i64* %3, align 8
  %5206 = inttoptr i64 %5204 to i32*
  store i32 %5203, i32* %5206, align 4
  %5207 = load i64, i64* %3, align 8
  %5208 = add i64 %5207, 129
  store i64 %5208, i64* %3, align 8
  br label %block_.L_4ab2fa

block_.L_4ab27e:                                  ; preds = %block_.L_4ab1f3
  %5209 = add i64 %4892, -696958
  %5210 = add i64 %4892, 37
  %5211 = load i64, i64* %6, align 8
  %5212 = add i64 %5211, -8
  %5213 = inttoptr i64 %5212 to i64*
  store i64 %5210, i64* %5213, align 8
  store i64 %5212, i64* %6, align 8
  store i64 %5209, i64* %3, align 8
  %5214 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 ptrtoint (i64 (i64)* @abs to i64), %struct.Memory* %MEMORY.7)
  %5215 = load i64, i64* %3, align 8
  store i64 7474576, i64* %RCX.i3977, align 8
  store i64 ptrtoint (%G__0x70f6e0_type* @G__0x70f6e0 to i64), i64* %RDX.i4094, align 8
  %5216 = load i64, i64* %RBP.i, align 8
  %5217 = add i64 %5216, -64
  %5218 = add i64 %5215, 24
  store i64 %5218, i64* %3, align 8
  %5219 = inttoptr i64 %5217 to i32*
  %5220 = load i32, i32* %5219, align 4
  %5221 = sext i32 %5220 to i64
  %5222 = shl nsw i64 %5221, 8
  store i64 %5222, i64* %RSI.i3950, align 8
  %5223 = add i64 %5222, ptrtoint (%G__0x70f6e0_type* @G__0x70f6e0 to i64)
  store i64 %5223, i64* %RDX.i4094, align 8
  %5224 = icmp ult i64 %5223, ptrtoint (%G__0x70f6e0_type* @G__0x70f6e0 to i64)
  %5225 = icmp ult i64 %5223, %5222
  %5226 = or i1 %5224, %5225
  %5227 = zext i1 %5226 to i8
  store i8 %5227, i8* %12, align 1
  %5228 = trunc i64 %5223 to i32
  %5229 = and i32 %5228, 248
  %5230 = tail call i32 @llvm.ctpop.i32(i32 %5229)
  %5231 = trunc i32 %5230 to i8
  %5232 = and i8 %5231, 1
  %5233 = xor i8 %5232, 1
  store i8 %5233, i8* %13, align 1
  %5234 = xor i64 %5223, ptrtoint (%G__0x70f6e0_type* @G__0x70f6e0 to i64)
  %5235 = lshr i64 %5234, 4
  %5236 = trunc i64 %5235 to i8
  %5237 = and i8 %5236, 1
  store i8 %5237, i8* %14, align 1
  %5238 = icmp eq i64 %5223, 0
  %5239 = zext i1 %5238 to i8
  store i8 %5239, i8* %15, align 1
  %5240 = lshr i64 %5223, 63
  %5241 = trunc i64 %5240 to i8
  store i8 %5241, i8* %16, align 1
  %5242 = lshr i64 %5221, 55
  %5243 = and i64 %5242, 1
  %5244 = xor i64 %5240, lshr (i64 ptrtoint (%G__0x70f6e0_type* @G__0x70f6e0 to i64), i64 63)
  %5245 = xor i64 %5240, %5243
  %5246 = add nuw nsw i64 %5244, %5245
  %5247 = icmp eq i64 %5246, 2
  %5248 = zext i1 %5247 to i8
  store i8 %5248, i8* %17, align 1
  %5249 = add i64 %5216, -24
  %5250 = add i64 %5215, 35
  store i64 %5250, i64* %3, align 8
  %5251 = inttoptr i64 %5249 to i32*
  %5252 = load i32, i32* %5251, align 4
  %5253 = sext i32 %5252 to i64
  %5254 = shl nsw i64 %5253, 5
  store i64 %5254, i64* %RSI.i3950, align 8
  %5255 = add i64 %5254, %5223
  store i64 %5255, i64* %RDX.i4094, align 8
  %5256 = icmp ult i64 %5255, %5223
  %5257 = icmp ult i64 %5255, %5254
  %5258 = or i1 %5256, %5257
  %5259 = zext i1 %5258 to i8
  store i8 %5259, i8* %12, align 1
  %5260 = trunc i64 %5255 to i32
  %5261 = and i32 %5260, 248
  %5262 = tail call i32 @llvm.ctpop.i32(i32 %5261)
  %5263 = trunc i32 %5262 to i8
  %5264 = and i8 %5263, 1
  %5265 = xor i8 %5264, 1
  store i8 %5265, i8* %13, align 1
  %5266 = xor i64 %5223, %5255
  %5267 = lshr i64 %5266, 4
  %5268 = trunc i64 %5267 to i8
  %5269 = and i8 %5268, 1
  store i8 %5269, i8* %14, align 1
  %5270 = icmp eq i64 %5255, 0
  %5271 = zext i1 %5270 to i8
  store i8 %5271, i8* %15, align 1
  %5272 = lshr i64 %5255, 63
  %5273 = trunc i64 %5272 to i8
  store i8 %5273, i8* %16, align 1
  %5274 = lshr i64 %5253, 58
  %5275 = and i64 %5274, 1
  %5276 = xor i64 %5272, %5240
  %5277 = xor i64 %5272, %5275
  %5278 = add nuw nsw i64 %5276, %5277
  %5279 = icmp eq i64 %5278, 2
  %5280 = zext i1 %5279 to i8
  store i8 %5280, i8* %17, align 1
  %5281 = load i64, i64* %RBP.i, align 8
  %5282 = add i64 %5281, -28
  %5283 = add i64 %5215, 46
  store i64 %5283, i64* %3, align 8
  %5284 = inttoptr i64 %5282 to i32*
  %5285 = load i32, i32* %5284, align 4
  %5286 = sext i32 %5285 to i64
  store i64 %5286, i64* %RSI.i3950, align 8
  %5287 = load i64, i64* %RAX.i2610, align 8
  %5288 = shl nsw i64 %5286, 2
  %5289 = add i64 %5255, %5288
  %5290 = add i64 %5215, 50
  store i64 %5290, i64* %3, align 8
  %5291 = inttoptr i64 %5289 to i32*
  %5292 = load i32, i32* %5291, align 4
  %5293 = shl i64 %5287, 32
  %5294 = ashr exact i64 %5293, 32
  %5295 = sext i32 %5292 to i64
  %5296 = mul nsw i64 %5295, %5294
  %5297 = trunc i64 %5296 to i32
  %5298 = and i64 %5296, 4294967295
  store i64 %5298, i64* %RAX.i2610, align 8
  %5299 = shl i64 %5296, 32
  %5300 = ashr exact i64 %5299, 32
  %5301 = icmp ne i64 %5300, %5296
  %5302 = zext i1 %5301 to i8
  store i8 %5302, i8* %12, align 1
  %5303 = and i32 %5297, 255
  %5304 = tail call i32 @llvm.ctpop.i32(i32 %5303)
  %5305 = trunc i32 %5304 to i8
  %5306 = and i8 %5305, 1
  %5307 = xor i8 %5306, 1
  store i8 %5307, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  %5308 = lshr i32 %5297, 31
  %5309 = trunc i32 %5308 to i8
  store i8 %5309, i8* %16, align 1
  store i8 %5302, i8* %17, align 1
  %5310 = add i64 %5281, -60
  %5311 = add i64 %5215, 54
  store i64 %5311, i64* %3, align 8
  %5312 = inttoptr i64 %5310 to i32*
  %5313 = load i32, i32* %5312, align 4
  %5314 = sext i32 %5313 to i64
  %5315 = shl nsw i64 %5314, 8
  store i64 %5315, i64* %RDX.i4094, align 8
  %5316 = load i64, i64* %RCX.i3977, align 8
  %5317 = add i64 %5315, %5316
  store i64 %5317, i64* %RCX.i3977, align 8
  %5318 = icmp ult i64 %5317, %5316
  %5319 = icmp ult i64 %5317, %5315
  %5320 = or i1 %5318, %5319
  %5321 = zext i1 %5320 to i8
  store i8 %5321, i8* %12, align 1
  %5322 = trunc i64 %5317 to i32
  %5323 = and i32 %5322, 255
  %5324 = tail call i32 @llvm.ctpop.i32(i32 %5323)
  %5325 = trunc i32 %5324 to i8
  %5326 = and i8 %5325, 1
  %5327 = xor i8 %5326, 1
  store i8 %5327, i8* %13, align 1
  %5328 = xor i64 %5316, %5317
  %5329 = lshr i64 %5328, 4
  %5330 = trunc i64 %5329 to i8
  %5331 = and i8 %5330, 1
  store i8 %5331, i8* %14, align 1
  %5332 = icmp eq i64 %5317, 0
  %5333 = zext i1 %5332 to i8
  store i8 %5333, i8* %15, align 1
  %5334 = lshr i64 %5317, 63
  %5335 = trunc i64 %5334 to i8
  store i8 %5335, i8* %16, align 1
  %5336 = lshr i64 %5316, 63
  %5337 = lshr i64 %5314, 55
  %5338 = and i64 %5337, 1
  %5339 = xor i64 %5334, %5336
  %5340 = xor i64 %5334, %5338
  %5341 = add nuw nsw i64 %5339, %5340
  %5342 = icmp eq i64 %5341, 2
  %5343 = zext i1 %5342 to i8
  store i8 %5343, i8* %17, align 1
  %5344 = load i64, i64* %RBP.i, align 8
  %5345 = add i64 %5344, -24
  %5346 = add i64 %5215, 65
  store i64 %5346, i64* %3, align 8
  %5347 = inttoptr i64 %5345 to i32*
  %5348 = load i32, i32* %5347, align 4
  %5349 = sext i32 %5348 to i64
  %5350 = shl nsw i64 %5349, 5
  store i64 %5350, i64* %RDX.i4094, align 8
  %5351 = add i64 %5350, %5317
  store i64 %5351, i64* %RCX.i3977, align 8
  %5352 = icmp ult i64 %5351, %5317
  %5353 = icmp ult i64 %5351, %5350
  %5354 = or i1 %5352, %5353
  %5355 = zext i1 %5354 to i8
  store i8 %5355, i8* %12, align 1
  %5356 = trunc i64 %5351 to i32
  %5357 = and i32 %5356, 255
  %5358 = tail call i32 @llvm.ctpop.i32(i32 %5357)
  %5359 = trunc i32 %5358 to i8
  %5360 = and i8 %5359, 1
  %5361 = xor i8 %5360, 1
  store i8 %5361, i8* %13, align 1
  %5362 = xor i64 %5317, %5351
  %5363 = lshr i64 %5362, 4
  %5364 = trunc i64 %5363 to i8
  %5365 = and i8 %5364, 1
  store i8 %5365, i8* %14, align 1
  %5366 = icmp eq i64 %5351, 0
  %5367 = zext i1 %5366 to i8
  store i8 %5367, i8* %15, align 1
  %5368 = lshr i64 %5351, 63
  %5369 = trunc i64 %5368 to i8
  store i8 %5369, i8* %16, align 1
  %5370 = lshr i64 %5349, 58
  %5371 = and i64 %5370, 1
  %5372 = xor i64 %5368, %5334
  %5373 = xor i64 %5368, %5371
  %5374 = add nuw nsw i64 %5372, %5373
  %5375 = icmp eq i64 %5374, 2
  %5376 = zext i1 %5375 to i8
  store i8 %5376, i8* %17, align 1
  %5377 = add i64 %5344, -28
  %5378 = add i64 %5215, 76
  store i64 %5378, i64* %3, align 8
  %5379 = inttoptr i64 %5377 to i32*
  %5380 = load i32, i32* %5379, align 4
  %5381 = sext i32 %5380 to i64
  store i64 %5381, i64* %RDX.i4094, align 8
  %5382 = load i64, i64* %RAX.i2610, align 8
  %5383 = shl nsw i64 %5381, 2
  %5384 = add i64 %5351, %5383
  %5385 = add i64 %5215, 79
  store i64 %5385, i64* %3, align 8
  %5386 = trunc i64 %5382 to i32
  %5387 = inttoptr i64 %5384 to i32*
  %5388 = load i32, i32* %5387, align 4
  %5389 = add i32 %5388, %5386
  %5390 = zext i32 %5389 to i64
  store i64 %5390, i64* %RAX.i2610, align 8
  %5391 = icmp ult i32 %5389, %5386
  %5392 = icmp ult i32 %5389, %5388
  %5393 = or i1 %5391, %5392
  %5394 = zext i1 %5393 to i8
  store i8 %5394, i8* %12, align 1
  %5395 = and i32 %5389, 255
  %5396 = tail call i32 @llvm.ctpop.i32(i32 %5395)
  %5397 = trunc i32 %5396 to i8
  %5398 = and i8 %5397, 1
  %5399 = xor i8 %5398, 1
  store i8 %5399, i8* %13, align 1
  %5400 = xor i32 %5388, %5386
  %5401 = xor i32 %5400, %5389
  %5402 = lshr i32 %5401, 4
  %5403 = trunc i32 %5402 to i8
  %5404 = and i8 %5403, 1
  store i8 %5404, i8* %14, align 1
  %5405 = icmp eq i32 %5389, 0
  %5406 = zext i1 %5405 to i8
  store i8 %5406, i8* %15, align 1
  %5407 = lshr i32 %5389, 31
  %5408 = trunc i32 %5407 to i8
  store i8 %5408, i8* %16, align 1
  %5409 = lshr i32 %5386, 31
  %5410 = lshr i32 %5388, 31
  %5411 = xor i32 %5407, %5409
  %5412 = xor i32 %5407, %5410
  %5413 = add nuw nsw i32 %5411, %5412
  %5414 = icmp eq i32 %5413, 2
  %5415 = zext i1 %5414 to i8
  store i8 %5415, i8* %17, align 1
  %5416 = load i64, i64* %RBP.i, align 8
  %5417 = add i64 %5416, -68
  %5418 = add i64 %5215, 82
  store i64 %5418, i64* %3, align 8
  %5419 = inttoptr i64 %5417 to i32*
  %5420 = load i32, i32* %5419, align 4
  %5421 = zext i32 %5420 to i64
  store i64 %5421, i64* %RCX.i3977, align 8
  %5422 = add i64 %5215, 84
  store i64 %5422, i64* %3, align 8
  %5423 = trunc i32 %5420 to i5
  switch i5 %5423, label %5427 [
    i5 0, label %routine_sarl__cl___eax.exit
    i5 1, label %5424
  ]

; <label>:5424:                                   ; preds = %block_.L_4ab27e
  %5425 = shl nuw i64 %5390, 32
  %5426 = ashr i64 %5425, 33
  br label %5434

; <label>:5427:                                   ; preds = %block_.L_4ab27e
  %5428 = and i32 %5420, 31
  %5429 = zext i32 %5428 to i64
  %5430 = add nsw i64 %5429, -1
  %5431 = sext i32 %5389 to i64
  %5432 = ashr i64 %5431, %5430
  %5433 = lshr i64 %5432, 1
  br label %5434

; <label>:5434:                                   ; preds = %5427, %5424
  %5435 = phi i64 [ %5433, %5427 ], [ %5426, %5424 ]
  %5436 = phi i64 [ %5432, %5427 ], [ %5390, %5424 ]
  %5437 = trunc i64 %5436 to i8
  %5438 = and i8 %5437, 1
  %5439 = trunc i64 %5435 to i32
  %5440 = and i64 %5435, 4294967295
  store i64 %5440, i64* %RAX.i2610, align 8
  store i8 %5438, i8* %12, align 1
  %5441 = and i32 %5439, 255
  %5442 = tail call i32 @llvm.ctpop.i32(i32 %5441)
  %5443 = trunc i32 %5442 to i8
  %5444 = and i8 %5443, 1
  %5445 = xor i8 %5444, 1
  store i8 %5445, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %5446 = icmp eq i32 %5439, 0
  %5447 = zext i1 %5446 to i8
  store i8 %5447, i8* %15, align 1
  %5448 = lshr i32 %5439, 31
  %5449 = trunc i32 %5448 to i8
  store i8 %5449, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %5450 = trunc i64 %5435 to i32
  br label %routine_sarl__cl___eax.exit

routine_sarl__cl___eax.exit:                      ; preds = %5434, %block_.L_4ab27e
  %5451 = phi i32 [ %5450, %5434 ], [ %5389, %block_.L_4ab27e ]
  %5452 = add i64 %5416, -44
  %5453 = add i64 %5215, 87
  store i64 %5453, i64* %3, align 8
  %5454 = inttoptr i64 %5452 to i32*
  store i32 %5451, i32* %5454, align 4
  %.pre192 = load i64, i64* %3, align 8
  br label %block_.L_4ab2fa

block_.L_4ab2fa:                                  ; preds = %routine_sarl__cl___eax.exit, %routine_sarl__cl___eax.exit2525
  %5455 = phi i64 [ %.pre192, %routine_sarl__cl___eax.exit ], [ %5208, %routine_sarl__cl___eax.exit2525 ]
  %MEMORY.11 = phi %struct.Memory* [ %5214, %routine_sarl__cl___eax.exit ], [ %4966, %routine_sarl__cl___eax.exit2525 ]
  %5456 = add i64 %5455, 5
  store i64 %5456, i64* %3, align 8
  br label %block_.L_4ab2ff

block_.L_4ab2ff:                                  ; preds = %block_.L_4ab2fa, %block_4ab1c6
  %storemerge = phi i64 [ %4886, %block_4ab1c6 ], [ %5456, %block_.L_4ab2fa ]
  %MEMORY.12 = phi %struct.Memory* [ %4878, %block_4ab1c6 ], [ %MEMORY.11, %block_.L_4ab2fa ]
  %5457 = load i64, i64* %RBP.i, align 8
  %5458 = add i64 %5457, -44
  %5459 = add i64 %storemerge, 4
  store i64 %5459, i64* %3, align 8
  %5460 = inttoptr i64 %5458 to i32*
  %5461 = load i32, i32* %5460, align 4
  store i8 0, i8* %12, align 1
  %5462 = and i32 %5461, 255
  %5463 = tail call i32 @llvm.ctpop.i32(i32 %5462)
  %5464 = trunc i32 %5463 to i8
  %5465 = and i8 %5464, 1
  %5466 = xor i8 %5465, 1
  store i8 %5466, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %5467 = icmp eq i32 %5461, 0
  %5468 = zext i1 %5467 to i8
  store i8 %5468, i8* %15, align 1
  %5469 = lshr i32 %5461, 31
  %5470 = trunc i32 %5469 to i8
  store i8 %5470, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v223 = select i1 %5467, i64 925, i64 10
  %5471 = add i64 %storemerge, %.v223
  store i64 %5471, i64* %3, align 8
  br i1 %5467, label %block_.L_4ab69c, label %block_4ab309

block_4ab309:                                     ; preds = %block_.L_4ab2ff
  %5472 = add i64 %5457, -56
  %5473 = add i64 %5471, 7
  store i64 %5473, i64* %3, align 8
  %5474 = inttoptr i64 %5472 to i32*
  store i32 1, i32* %5474, align 4
  %5475 = load i64, i64* %RBP.i, align 8
  %5476 = add i64 %5475, -408
  %5477 = load i64, i64* %3, align 8
  %5478 = add i64 %5477, 7
  store i64 %5478, i64* %3, align 8
  %5479 = inttoptr i64 %5476 to i64*
  %5480 = load i64, i64* %5479, align 8
  store i64 %5480, i64* %RAX.i2610, align 8
  %5481 = add i64 %5480, 572
  %5482 = add i64 %5477, 14
  store i64 %5482, i64* %3, align 8
  %5483 = inttoptr i64 %5481 to i32*
  %5484 = load i32, i32* %5483, align 4
  store i8 0, i8* %12, align 1
  %5485 = and i32 %5484, 255
  %5486 = tail call i32 @llvm.ctpop.i32(i32 %5485)
  %5487 = trunc i32 %5486 to i8
  %5488 = and i8 %5487, 1
  %5489 = xor i8 %5488, 1
  store i8 %5489, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %5490 = icmp eq i32 %5484, 0
  %5491 = zext i1 %5490 to i8
  store i8 %5491, i8* %15, align 1
  %5492 = lshr i32 %5484, 31
  %5493 = trunc i32 %5492 to i8
  store i8 %5493, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v224 = select i1 %5490, i64 357, i64 20
  %5494 = add i64 %5477, %.v224
  store i64 %5494, i64* %3, align 8
  br i1 %5490, label %block_.L_4ab475, label %block_4ab324

block_4ab324:                                     ; preds = %block_4ab309
  %5495 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5495, i64* %RAX.i2610, align 8
  %5496 = add i64 %5495, 2356
  %5497 = add i64 %5494, 15
  store i64 %5497, i64* %3, align 8
  %5498 = inttoptr i64 %5496 to i32*
  %5499 = load i32, i32* %5498, align 4
  store i8 0, i8* %12, align 1
  %5500 = and i32 %5499, 255
  %5501 = tail call i32 @llvm.ctpop.i32(i32 %5500)
  %5502 = trunc i32 %5501 to i8
  %5503 = and i8 %5502, 1
  %5504 = xor i8 %5503, 1
  store i8 %5504, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %5505 = icmp eq i32 %5499, 0
  %5506 = zext i1 %5505 to i8
  store i8 %5506, i8* %15, align 1
  %5507 = lshr i32 %5499, 31
  %5508 = trunc i32 %5507 to i8
  store i8 %5508, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v225 = select i1 %5505, i64 21, i64 337
  %5509 = add i64 %5494, %.v225
  store i64 %5509, i64* %3, align 8
  br i1 %5505, label %block_4ab339, label %block_.L_4ab475

block_4ab339:                                     ; preds = %block_4ab324
  %5510 = add i64 %5475, -44
  %5511 = add i64 %5509, 4
  store i64 %5511, i64* %3, align 8
  %5512 = inttoptr i64 %5510 to i32*
  %5513 = load i32, i32* %5512, align 4
  %5514 = add i32 %5513, -1
  %5515 = icmp eq i32 %5513, 0
  %5516 = zext i1 %5515 to i8
  store i8 %5516, i8* %12, align 1
  %5517 = and i32 %5514, 255
  %5518 = tail call i32 @llvm.ctpop.i32(i32 %5517)
  %5519 = trunc i32 %5518 to i8
  %5520 = and i8 %5519, 1
  %5521 = xor i8 %5520, 1
  store i8 %5521, i8* %13, align 1
  %5522 = xor i32 %5514, %5513
  %5523 = lshr i32 %5522, 4
  %5524 = trunc i32 %5523 to i8
  %5525 = and i8 %5524, 1
  store i8 %5525, i8* %14, align 1
  %5526 = icmp eq i32 %5514, 0
  %5527 = zext i1 %5526 to i8
  store i8 %5527, i8* %15, align 1
  %5528 = lshr i32 %5514, 31
  %5529 = trunc i32 %5528 to i8
  store i8 %5529, i8* %16, align 1
  %5530 = lshr i32 %5513, 31
  %5531 = xor i32 %5528, %5530
  %5532 = add nuw nsw i32 %5531, %5530
  %5533 = icmp eq i32 %5532, 2
  %5534 = zext i1 %5533 to i8
  store i8 %5534, i8* %17, align 1
  %5535 = icmp ne i8 %5529, 0
  %5536 = xor i1 %5535, %5533
  %5537 = or i1 %5526, %5536
  %.v229 = select i1 %5537, i64 29, i64 10
  %5538 = add i64 %5509, %.v229
  store i64 %5538, i64* %3, align 8
  br i1 %5537, label %block_.L_4ab356, label %block_4ab343

block_4ab343:                                     ; preds = %block_4ab339
  %5539 = add i64 %5475, -16
  %5540 = add i64 %5538, 4
  store i64 %5540, i64* %3, align 8
  %5541 = inttoptr i64 %5539 to i64*
  %5542 = load i64, i64* %5541, align 8
  store i64 %5542, i64* %RAX.i2610, align 8
  %5543 = add i64 %5538, 6
  store i64 %5543, i64* %3, align 8
  %5544 = inttoptr i64 %5542 to i32*
  %5545 = load i32, i32* %5544, align 4
  %5546 = add i32 %5545, 999999
  %5547 = zext i32 %5546 to i64
  store i64 %5547, i64* %RCX.i3977, align 8
  %5548 = icmp ugt i32 %5545, -1000000
  %5549 = zext i1 %5548 to i8
  store i8 %5549, i8* %12, align 1
  %5550 = and i32 %5546, 255
  %5551 = tail call i32 @llvm.ctpop.i32(i32 %5550)
  %5552 = trunc i32 %5551 to i8
  %5553 = and i8 %5552, 1
  %5554 = xor i8 %5553, 1
  store i8 %5554, i8* %13, align 1
  %5555 = xor i32 %5545, 16
  %5556 = xor i32 %5555, %5546
  %5557 = lshr i32 %5556, 4
  %5558 = trunc i32 %5557 to i8
  %5559 = and i8 %5558, 1
  store i8 %5559, i8* %14, align 1
  %5560 = icmp eq i32 %5546, 0
  %5561 = zext i1 %5560 to i8
  store i8 %5561, i8* %15, align 1
  %5562 = lshr i32 %5546, 31
  %5563 = trunc i32 %5562 to i8
  store i8 %5563, i8* %16, align 1
  %5564 = lshr i32 %5545, 31
  %5565 = xor i32 %5562, %5564
  %5566 = add nuw nsw i32 %5565, %5562
  %5567 = icmp eq i32 %5566, 2
  %5568 = zext i1 %5567 to i8
  store i8 %5568, i8* %17, align 1
  %5569 = add i64 %5538, 14
  store i64 %5569, i64* %3, align 8
  store i32 %5546, i32* %5544, align 4
  %5570 = load i64, i64* %3, align 8
  %5571 = add i64 %5570, 66
  store i64 %5571, i64* %3, align 8
  br label %block_.L_4ab393

block_.L_4ab356:                                  ; preds = %block_4ab339
  store i64 ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64), i64* %RAX.i2610, align 8
  store i64 %5495, i64* %RCX.i3977, align 8
  %5572 = add i64 %5495, 2468
  %5573 = add i64 %5538, 25
  store i64 %5573, i64* %3, align 8
  %5574 = inttoptr i64 %5572 to i32*
  %5575 = load i32, i32* %5574, align 4
  %5576 = sext i32 %5575 to i64
  %5577 = shl nsw i64 %5576, 6
  store i64 %5577, i64* %RCX.i3977, align 8
  %5578 = add i64 %5577, ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64)
  store i64 %5578, i64* %RAX.i2610, align 8
  %5579 = icmp ult i64 %5578, ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64)
  %5580 = icmp ult i64 %5578, %5577
  %5581 = or i1 %5579, %5580
  %5582 = zext i1 %5581 to i8
  store i8 %5582, i8* %12, align 1
  %5583 = trunc i64 %5578 to i32
  %5584 = and i32 %5583, 248
  %5585 = tail call i32 @llvm.ctpop.i32(i32 %5584)
  %5586 = trunc i32 %5585 to i8
  %5587 = and i8 %5586, 1
  %5588 = xor i8 %5587, 1
  store i8 %5588, i8* %13, align 1
  %5589 = xor i64 %5578, ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64)
  %5590 = lshr i64 %5589, 4
  %5591 = trunc i64 %5590 to i8
  %5592 = and i8 %5591, 1
  store i8 %5592, i8* %14, align 1
  %5593 = icmp eq i64 %5578, 0
  %5594 = zext i1 %5593 to i8
  store i8 %5594, i8* %15, align 1
  %5595 = lshr i64 %5578, 63
  %5596 = trunc i64 %5595 to i8
  store i8 %5596, i8* %16, align 1
  %5597 = lshr i64 %5576, 57
  %5598 = and i64 %5597, 1
  %5599 = xor i64 %5595, lshr (i64 ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64), i64 63)
  %5600 = xor i64 %5595, %5598
  %5601 = add nuw nsw i64 %5599, %5600
  %5602 = icmp eq i64 %5601, 2
  %5603 = zext i1 %5602 to i8
  store i8 %5603, i8* %17, align 1
  %5604 = add i64 %5475, -36
  %5605 = add i64 %5538, 35
  store i64 %5605, i64* %3, align 8
  %5606 = inttoptr i64 %5604 to i32*
  %5607 = load i32, i32* %5606, align 4
  %5608 = and i32 %5607, 3
  %5609 = zext i32 %5608 to i64
  store i64 %5609, i64* %RDX.i4094, align 8
  store i8 0, i8* %12, align 1
  %5610 = tail call i32 @llvm.ctpop.i32(i32 %5608)
  %5611 = trunc i32 %5610 to i8
  %5612 = and i8 %5611, 1
  %5613 = xor i8 %5612, 1
  store i8 %5613, i8* %13, align 1
  %5614 = icmp eq i32 %5608, 0
  %5615 = zext i1 %5614 to i8
  store i8 %5615, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %5609, i64* %RCX.i3977, align 8
  %5616 = load i64, i64* %RBP.i, align 8
  %5617 = shl nuw nsw i32 %5608, 2
  %5618 = zext i32 %5617 to i64
  %5619 = or i64 %5618, -400
  %5620 = add i64 %5619, %5616
  %5621 = add i64 %5538, 49
  store i64 %5621, i64* %3, align 8
  %5622 = inttoptr i64 %5620 to i32*
  %5623 = load i32, i32* %5622, align 4
  %5624 = sext i32 %5623 to i64
  store i64 %5624, i64* %RCX.i3977, align 8
  %5625 = add i64 %5578, %5624
  %5626 = add i64 %5538, 53
  store i64 %5626, i64* %3, align 8
  %5627 = inttoptr i64 %5625 to i8*
  %5628 = load i8, i8* %5627, align 1
  %5629 = zext i8 %5628 to i64
  store i64 %5629, i64* %RDX.i4094, align 8
  %5630 = add i64 %5616, -16
  %5631 = add i64 %5538, 57
  store i64 %5631, i64* %3, align 8
  %5632 = inttoptr i64 %5630 to i64*
  %5633 = load i64, i64* %5632, align 8
  store i64 %5633, i64* %RAX.i2610, align 8
  %5634 = add i64 %5538, 59
  store i64 %5634, i64* %3, align 8
  %5635 = zext i8 %5628 to i32
  %5636 = inttoptr i64 %5633 to i32*
  %5637 = load i32, i32* %5636, align 4
  %5638 = add i32 %5637, %5635
  %5639 = zext i32 %5638 to i64
  store i64 %5639, i64* %RDX.i4094, align 8
  %5640 = icmp ult i32 %5638, %5635
  %5641 = icmp ult i32 %5638, %5637
  %5642 = or i1 %5640, %5641
  %5643 = zext i1 %5642 to i8
  store i8 %5643, i8* %12, align 1
  %5644 = and i32 %5638, 255
  %5645 = tail call i32 @llvm.ctpop.i32(i32 %5644)
  %5646 = trunc i32 %5645 to i8
  %5647 = and i8 %5646, 1
  %5648 = xor i8 %5647, 1
  store i8 %5648, i8* %13, align 1
  %5649 = xor i32 %5637, %5635
  %5650 = xor i32 %5649, %5638
  %5651 = lshr i32 %5650, 4
  %5652 = trunc i32 %5651 to i8
  %5653 = and i8 %5652, 1
  store i8 %5653, i8* %14, align 1
  %5654 = icmp eq i32 %5638, 0
  %5655 = zext i1 %5654 to i8
  store i8 %5655, i8* %15, align 1
  %5656 = lshr i32 %5638, 31
  %5657 = trunc i32 %5656 to i8
  store i8 %5657, i8* %16, align 1
  %5658 = lshr i32 %5637, 31
  %5659 = xor i32 %5656, %5658
  %5660 = add nuw nsw i32 %5656, %5659
  %5661 = icmp eq i32 %5660, 2
  %5662 = zext i1 %5661 to i8
  store i8 %5662, i8* %17, align 1
  %5663 = add i64 %5538, 61
  store i64 %5663, i64* %3, align 8
  store i32 %5638, i32* %5636, align 4
  %.pre193 = load i64, i64* %3, align 8
  br label %block_.L_4ab393

block_.L_4ab393:                                  ; preds = %block_.L_4ab356, %block_4ab343
  %5664 = phi i64 [ %.pre193, %block_.L_4ab356 ], [ %5571, %block_4ab343 ]
  %5665 = load i64, i64* %RBP.i, align 8
  %5666 = add i64 %5665, -44
  %5667 = add i64 %5664, 3
  store i64 %5667, i64* %3, align 8
  %5668 = inttoptr i64 %5666 to i32*
  %5669 = load i32, i32* %5668, align 4
  %5670 = zext i32 %5669 to i64
  store i64 %5670, i64* %RDI.i4084, align 8
  %5671 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %5672 = add i64 %5671, 13112
  store i64 %5672, i64* %RAX.i2610, align 8
  %5673 = icmp ugt i64 %5671, -13113
  %5674 = zext i1 %5673 to i8
  store i8 %5674, i8* %12, align 1
  %5675 = trunc i64 %5672 to i32
  %5676 = and i32 %5675, 255
  %5677 = tail call i32 @llvm.ctpop.i32(i32 %5676)
  %5678 = trunc i32 %5677 to i8
  %5679 = and i8 %5678, 1
  %5680 = xor i8 %5679, 1
  store i8 %5680, i8* %13, align 1
  %5681 = xor i64 %5671, 16
  %5682 = xor i64 %5681, %5672
  %5683 = lshr i64 %5682, 4
  %5684 = trunc i64 %5683 to i8
  %5685 = and i8 %5684, 1
  store i8 %5685, i8* %14, align 1
  %5686 = icmp eq i64 %5672, 0
  %5687 = zext i1 %5686 to i8
  store i8 %5687, i8* %15, align 1
  %5688 = lshr i64 %5672, 63
  %5689 = trunc i64 %5688 to i8
  store i8 %5689, i8* %16, align 1
  %5690 = lshr i64 %5671, 63
  %5691 = xor i64 %5688, %5690
  %5692 = add nuw nsw i64 %5691, %5688
  %5693 = icmp eq i64 %5692, 2
  %5694 = zext i1 %5693 to i8
  store i8 %5694, i8* %17, align 1
  %5695 = add i64 %5665, -24
  %5696 = add i64 %5664, 21
  store i64 %5696, i64* %3, align 8
  %5697 = inttoptr i64 %5695 to i32*
  %5698 = load i32, i32* %5697, align 4
  %5699 = sext i32 %5698 to i64
  %5700 = shl nsw i64 %5699, 6
  store i64 %5700, i64* %RCX.i3977, align 8
  %5701 = add i64 %5700, %5672
  store i64 %5701, i64* %RAX.i2610, align 8
  %5702 = icmp ult i64 %5701, %5672
  %5703 = icmp ult i64 %5701, %5700
  %5704 = or i1 %5702, %5703
  %5705 = zext i1 %5704 to i8
  store i8 %5705, i8* %12, align 1
  %5706 = trunc i64 %5701 to i32
  %5707 = and i32 %5706, 255
  %5708 = tail call i32 @llvm.ctpop.i32(i32 %5707)
  %5709 = trunc i32 %5708 to i8
  %5710 = and i8 %5709, 1
  %5711 = xor i8 %5710, 1
  store i8 %5711, i8* %13, align 1
  %5712 = xor i64 %5672, %5701
  %5713 = lshr i64 %5712, 4
  %5714 = trunc i64 %5713 to i8
  %5715 = and i8 %5714, 1
  store i8 %5715, i8* %14, align 1
  %5716 = icmp eq i64 %5701, 0
  %5717 = zext i1 %5716 to i8
  store i8 %5717, i8* %15, align 1
  %5718 = lshr i64 %5701, 63
  %5719 = trunc i64 %5718 to i8
  store i8 %5719, i8* %16, align 1
  %5720 = lshr i64 %5699, 57
  %5721 = and i64 %5720, 1
  %5722 = xor i64 %5718, %5688
  %5723 = xor i64 %5718, %5721
  %5724 = add nuw nsw i64 %5722, %5723
  %5725 = icmp eq i64 %5724, 2
  %5726 = zext i1 %5725 to i8
  store i8 %5726, i8* %17, align 1
  %5727 = load i64, i64* %RBP.i, align 8
  %5728 = add i64 %5727, -28
  %5729 = add i64 %5664, 32
  store i64 %5729, i64* %3, align 8
  %5730 = inttoptr i64 %5728 to i32*
  %5731 = load i32, i32* %5730, align 4
  %5732 = sext i32 %5731 to i64
  store i64 %5732, i64* %RCX.i3977, align 8
  %5733 = shl nsw i64 %5732, 2
  %5734 = add i64 %5733, %5701
  %5735 = add i64 %5664, 35
  store i64 %5735, i64* %3, align 8
  %5736 = inttoptr i64 %5734 to i32*
  %5737 = load i32, i32* %5736, align 4
  %5738 = zext i32 %5737 to i64
  store i64 %5738, i64* %RSI.i3950, align 8
  %5739 = add i64 %5664, -221763
  %5740 = add i64 %5664, 40
  %5741 = load i64, i64* %6, align 8
  %5742 = add i64 %5741, -8
  %5743 = inttoptr i64 %5742 to i64*
  store i64 %5740, i64* %5743, align 8
  store i64 %5742, i64* %6, align 8
  store i64 %5739, i64* %3, align 8
  %call2_4ab3b6 = tail call %struct.Memory* @sub_475150.sign(%struct.State* nonnull %0, i64 %5739, %struct.Memory* %MEMORY.12)
  %5744 = load i64, i64* %3, align 8
  %5745 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5745, i64* %RCX.i3977, align 8
  %5746 = add i64 %5745, 14136
  %5747 = add i64 %5744, 15
  store i64 %5747, i64* %3, align 8
  %5748 = inttoptr i64 %5746 to i64*
  %5749 = load i64, i64* %5748, align 8
  store i64 %5749, i64* %RCX.i3977, align 8
  %5750 = load i64, i64* %RBP.i, align 8
  %5751 = add i64 %5750, -4
  %5752 = add i64 %5744, 19
  store i64 %5752, i64* %3, align 8
  %5753 = inttoptr i64 %5751 to i32*
  %5754 = load i32, i32* %5753, align 4
  %5755 = sext i32 %5754 to i64
  store i64 %5755, i64* %RDX.i4094, align 8
  %5756 = shl nsw i64 %5755, 3
  %5757 = add i64 %5756, %5749
  %5758 = add i64 %5744, 23
  store i64 %5758, i64* %3, align 8
  %5759 = inttoptr i64 %5757 to i64*
  %5760 = load i64, i64* %5759, align 8
  store i64 %5760, i64* %RCX.i3977, align 8
  %5761 = add i64 %5750, -36
  %5762 = add i64 %5744, 26
  store i64 %5762, i64* %3, align 8
  %5763 = inttoptr i64 %5761 to i32*
  %5764 = load i32, i32* %5763, align 4
  %5765 = and i32 %5764, 3
  %5766 = zext i32 %5765 to i64
  store i64 %5766, i64* %RSI.i3950, align 8
  store i8 0, i8* %12, align 1
  %5767 = tail call i32 @llvm.ctpop.i32(i32 %5765)
  %5768 = trunc i32 %5767 to i8
  %5769 = and i8 %5768, 1
  %5770 = xor i8 %5769, 1
  store i8 %5770, i8* %13, align 1
  %5771 = icmp eq i32 %5765, 0
  %5772 = zext i1 %5771 to i8
  store i8 %5772, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %5766, i64* %RDX.i4094, align 8
  %5773 = shl nuw nsw i32 %5765, 3
  %5774 = zext i32 %5773 to i64
  %5775 = add i64 %5760, %5774
  %5776 = add i64 %5744, 36
  store i64 %5776, i64* %3, align 8
  %5777 = inttoptr i64 %5775 to i64*
  %5778 = load i64, i64* %5777, align 8
  store i64 %5778, i64* %RCX.i3977, align 8
  %5779 = add i64 %5744, 39
  store i64 %5779, i64* %3, align 8
  %5780 = inttoptr i64 %5778 to i64*
  %5781 = load i64, i64* %5780, align 8
  store i64 %5781, i64* %RCX.i3977, align 8
  %5782 = add i64 %5744, 42
  store i64 %5782, i64* %3, align 8
  %5783 = load i32, i32* %5763, align 4
  %5784 = and i32 %5783, 3
  %5785 = zext i32 %5784 to i64
  store i64 %5785, i64* %RSI.i3950, align 8
  store i8 0, i8* %12, align 1
  %5786 = tail call i32 @llvm.ctpop.i32(i32 %5784)
  %5787 = trunc i32 %5786 to i8
  %5788 = and i8 %5787, 1
  %5789 = xor i8 %5788, 1
  store i8 %5789, i8* %13, align 1
  %5790 = icmp eq i32 %5784, 0
  %5791 = zext i1 %5790 to i8
  store i8 %5791, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %5785, i64* %RDX.i4094, align 8
  %5792 = shl nuw nsw i32 %5784, 2
  %5793 = zext i32 %5792 to i64
  %5794 = or i64 %5793, -384
  %5795 = add i64 %5794, %5750
  %5796 = add i64 %5744, 56
  store i64 %5796, i64* %3, align 8
  %5797 = inttoptr i64 %5795 to i32*
  %5798 = load i32, i32* %5797, align 4
  %5799 = sext i32 %5798 to i64
  store i64 %5799, i64* %RDX.i4094, align 8
  %5800 = shl nsw i64 %5799, 2
  %5801 = add i64 %5800, %5781
  %5802 = load i32, i32* %EAX.i2609, align 4
  %5803 = add i64 %5744, 59
  store i64 %5803, i64* %3, align 8
  %5804 = inttoptr i64 %5801 to i32*
  store i32 %5802, i32* %5804, align 4
  %5805 = load i64, i64* %RBP.i, align 8
  %5806 = add i64 %5805, -36
  %5807 = load i64, i64* %3, align 8
  %5808 = add i64 %5807, 3
  store i64 %5808, i64* %3, align 8
  %5809 = inttoptr i64 %5806 to i32*
  %5810 = load i32, i32* %5809, align 4
  %5811 = and i32 %5810, 3
  %5812 = zext i32 %5811 to i64
  store i64 %5812, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  %5813 = tail call i32 @llvm.ctpop.i32(i32 %5811)
  %5814 = trunc i32 %5813 to i8
  %5815 = and i8 %5814, 1
  %5816 = xor i8 %5815, 1
  store i8 %5816, i8* %13, align 1
  %5817 = icmp eq i32 %5811, 0
  %5818 = zext i1 %5817 to i8
  store i8 %5818, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %5812, i64* %RCX.i3977, align 8
  %5819 = shl nuw nsw i32 %5811, 2
  %5820 = zext i32 %5819 to i64
  %5821 = or i64 %5820, -400
  %5822 = add i64 %5821, %5805
  %5823 = add i64 %5807, 16
  store i64 %5823, i64* %3, align 8
  %5824 = inttoptr i64 %5822 to i32*
  %5825 = load i32, i32* %5824, align 4
  %5826 = zext i32 %5825 to i64
  store i64 %5826, i64* %RAX.i2610, align 8
  %5827 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5827, i64* %RCX.i3977, align 8
  %5828 = add i64 %5827, 14136
  %5829 = add i64 %5807, 31
  store i64 %5829, i64* %3, align 8
  %5830 = inttoptr i64 %5828 to i64*
  %5831 = load i64, i64* %5830, align 8
  store i64 %5831, i64* %RCX.i3977, align 8
  %5832 = add i64 %5805, -4
  %5833 = add i64 %5807, 35
  store i64 %5833, i64* %3, align 8
  %5834 = inttoptr i64 %5832 to i32*
  %5835 = load i32, i32* %5834, align 4
  %5836 = sext i32 %5835 to i64
  store i64 %5836, i64* %RDX.i4094, align 8
  %5837 = shl nsw i64 %5836, 3
  %5838 = add i64 %5837, %5831
  %5839 = add i64 %5807, 39
  store i64 %5839, i64* %3, align 8
  %5840 = inttoptr i64 %5838 to i64*
  %5841 = load i64, i64* %5840, align 8
  store i64 %5841, i64* %RCX.i3977, align 8
  %5842 = add i64 %5807, 42
  store i64 %5842, i64* %3, align 8
  %5843 = load i32, i32* %5809, align 4
  %5844 = and i32 %5843, 3
  %5845 = zext i32 %5844 to i64
  store i64 %5845, i64* %RSI.i3950, align 8
  store i8 0, i8* %12, align 1
  %5846 = tail call i32 @llvm.ctpop.i32(i32 %5844)
  %5847 = trunc i32 %5846 to i8
  %5848 = and i8 %5847, 1
  %5849 = xor i8 %5848, 1
  store i8 %5849, i8* %13, align 1
  %5850 = icmp eq i32 %5844, 0
  %5851 = zext i1 %5850 to i8
  store i8 %5851, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %5845, i64* %RDX.i4094, align 8
  %5852 = shl nuw nsw i32 %5844, 3
  %5853 = zext i32 %5852 to i64
  %5854 = add i64 %5841, %5853
  %5855 = add i64 %5807, 52
  store i64 %5855, i64* %3, align 8
  %5856 = inttoptr i64 %5854 to i64*
  %5857 = load i64, i64* %5856, align 8
  store i64 %5857, i64* %RCX.i3977, align 8
  %5858 = add i64 %5857, 8
  %5859 = add i64 %5807, 56
  store i64 %5859, i64* %3, align 8
  %5860 = inttoptr i64 %5858 to i64*
  %5861 = load i64, i64* %5860, align 8
  store i64 %5861, i64* %RCX.i3977, align 8
  %5862 = load i64, i64* %RBP.i, align 8
  %5863 = add i64 %5862, -36
  %5864 = add i64 %5807, 59
  store i64 %5864, i64* %3, align 8
  %5865 = inttoptr i64 %5863 to i32*
  %5866 = load i32, i32* %5865, align 4
  %5867 = and i32 %5866, 3
  %5868 = zext i32 %5867 to i64
  store i64 %5868, i64* %RSI.i3950, align 8
  store i8 0, i8* %12, align 1
  %5869 = tail call i32 @llvm.ctpop.i32(i32 %5867)
  %5870 = trunc i32 %5869 to i8
  %5871 = and i8 %5870, 1
  %5872 = xor i8 %5871, 1
  store i8 %5872, i8* %13, align 1
  %5873 = icmp eq i32 %5867, 0
  %5874 = zext i1 %5873 to i8
  store i8 %5874, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %5868, i64* %RDX.i4094, align 8
  %5875 = shl nuw nsw i32 %5867, 2
  %5876 = zext i32 %5875 to i64
  %5877 = or i64 %5876, -384
  %5878 = add i64 %5877, %5862
  %5879 = add i64 %5807, 73
  store i64 %5879, i64* %3, align 8
  %5880 = inttoptr i64 %5878 to i32*
  %5881 = load i32, i32* %5880, align 4
  %5882 = sext i32 %5881 to i64
  store i64 %5882, i64* %RDX.i4094, align 8
  %5883 = shl nsw i64 %5882, 2
  %5884 = add i64 %5883, %5861
  %5885 = load i32, i32* %EAX.i2609, align 4
  %5886 = add i64 %5807, 76
  store i64 %5886, i64* %3, align 8
  %5887 = inttoptr i64 %5884 to i32*
  store i32 %5885, i32* %5887, align 4
  %5888 = load i64, i64* %RBP.i, align 8
  %5889 = add i64 %5888, -36
  %5890 = load i64, i64* %3, align 8
  %5891 = add i64 %5890, 3
  store i64 %5891, i64* %3, align 8
  %5892 = inttoptr i64 %5889 to i32*
  %5893 = load i32, i32* %5892, align 4
  %5894 = and i32 %5893, 3
  %5895 = zext i32 %5894 to i64
  store i64 %5895, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  %5896 = tail call i32 @llvm.ctpop.i32(i32 %5894)
  %5897 = trunc i32 %5896 to i8
  %5898 = and i8 %5897, 1
  %5899 = xor i8 %5898, 1
  store i8 %5899, i8* %13, align 1
  %5900 = icmp eq i32 %5894, 0
  %5901 = zext i1 %5900 to i8
  store i8 %5901, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %5895, i64* %RCX.i3977, align 8
  %5902 = shl nuw nsw i32 %5894, 2
  %5903 = zext i32 %5902 to i64
  %5904 = or i64 %5903, -384
  %5905 = add i64 %5904, %5888
  %5906 = add i64 %5890, 16
  store i64 %5906, i64* %3, align 8
  %5907 = inttoptr i64 %5905 to i32*
  %5908 = load i32, i32* %5907, align 4
  %5909 = add i32 %5908, 1
  %5910 = zext i32 %5909 to i64
  store i64 %5910, i64* %RAX.i2610, align 8
  %5911 = icmp eq i32 %5908, -1
  %5912 = icmp eq i32 %5909, 0
  %5913 = or i1 %5911, %5912
  %5914 = zext i1 %5913 to i8
  store i8 %5914, i8* %12, align 1
  %5915 = and i32 %5909, 255
  %5916 = tail call i32 @llvm.ctpop.i32(i32 %5915)
  %5917 = trunc i32 %5916 to i8
  %5918 = and i8 %5917, 1
  %5919 = xor i8 %5918, 1
  store i8 %5919, i8* %13, align 1
  %5920 = xor i32 %5909, %5908
  %5921 = lshr i32 %5920, 4
  %5922 = trunc i32 %5921 to i8
  %5923 = and i8 %5922, 1
  store i8 %5923, i8* %14, align 1
  %5924 = zext i1 %5912 to i8
  store i8 %5924, i8* %15, align 1
  %5925 = lshr i32 %5909, 31
  %5926 = trunc i32 %5925 to i8
  store i8 %5926, i8* %16, align 1
  %5927 = lshr i32 %5908, 31
  %5928 = xor i32 %5925, %5927
  %5929 = add nuw nsw i32 %5928, %5925
  %5930 = icmp eq i32 %5929, 2
  %5931 = zext i1 %5930 to i8
  store i8 %5931, i8* %17, align 1
  %5932 = add i64 %5888, -384
  %5933 = add i64 %5932, %5903
  %5934 = add i64 %5890, 26
  store i64 %5934, i64* %3, align 8
  %5935 = inttoptr i64 %5933 to i32*
  store i32 %5909, i32* %5935, align 4
  %5936 = load i64, i64* %RBP.i, align 8
  %5937 = add i64 %5936, -36
  %5938 = load i64, i64* %3, align 8
  %5939 = add i64 %5938, 3
  store i64 %5939, i64* %3, align 8
  %5940 = inttoptr i64 %5937 to i32*
  %5941 = load i32, i32* %5940, align 4
  %5942 = and i32 %5941, 3
  %5943 = zext i32 %5942 to i64
  store i64 %5943, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  %5944 = tail call i32 @llvm.ctpop.i32(i32 %5942)
  %5945 = trunc i32 %5944 to i8
  %5946 = and i8 %5945, 1
  %5947 = xor i8 %5946, 1
  store i8 %5947, i8* %13, align 1
  %5948 = icmp eq i32 %5942, 0
  %5949 = zext i1 %5948 to i8
  store i8 %5949, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 %5943, i64* %RCX.i3977, align 8
  %5950 = shl nuw nsw i32 %5942, 2
  %5951 = zext i32 %5950 to i64
  %5952 = or i64 %5951, -400
  %5953 = add i64 %5952, %5936
  %5954 = add i64 %5938, 20
  store i64 %5954, i64* %3, align 8
  %5955 = inttoptr i64 %5953 to i32*
  store i32 -1, i32* %5955, align 4
  %5956 = load i64, i64* %3, align 8
  %5957 = add i64 %5956, 163
  store i64 %5957, i64* %3, align 8
  br label %block_.L_4ab513

block_.L_4ab475:                                  ; preds = %block_4ab324, %block_4ab309
  %5958 = phi i64 [ %5509, %block_4ab324 ], [ %5494, %block_4ab309 ]
  %5959 = add i64 %5475, -44
  %5960 = add i64 %5958, 4
  store i64 %5960, i64* %3, align 8
  %5961 = inttoptr i64 %5959 to i32*
  %5962 = load i32, i32* %5961, align 4
  %5963 = add i32 %5962, -1
  %5964 = icmp eq i32 %5962, 0
  %5965 = zext i1 %5964 to i8
  store i8 %5965, i8* %12, align 1
  %5966 = and i32 %5963, 255
  %5967 = tail call i32 @llvm.ctpop.i32(i32 %5966)
  %5968 = trunc i32 %5967 to i8
  %5969 = and i8 %5968, 1
  %5970 = xor i8 %5969, 1
  store i8 %5970, i8* %13, align 1
  %5971 = xor i32 %5963, %5962
  %5972 = lshr i32 %5971, 4
  %5973 = trunc i32 %5972 to i8
  %5974 = and i8 %5973, 1
  store i8 %5974, i8* %14, align 1
  %5975 = icmp eq i32 %5963, 0
  %5976 = zext i1 %5975 to i8
  store i8 %5976, i8* %15, align 1
  %5977 = lshr i32 %5963, 31
  %5978 = trunc i32 %5977 to i8
  store i8 %5978, i8* %16, align 1
  %5979 = lshr i32 %5962, 31
  %5980 = xor i32 %5977, %5979
  %5981 = add nuw nsw i32 %5980, %5979
  %5982 = icmp eq i32 %5981, 2
  %5983 = zext i1 %5982 to i8
  store i8 %5983, i8* %17, align 1
  %5984 = icmp ne i8 %5978, 0
  %5985 = xor i1 %5984, %5982
  %5986 = or i1 %5975, %5985
  %.v226 = select i1 %5986, i64 29, i64 10
  %5987 = add i64 %5958, %.v226
  store i64 %5987, i64* %3, align 8
  br i1 %5986, label %block_.L_4ab492, label %block_4ab47f

block_4ab47f:                                     ; preds = %block_.L_4ab475
  %5988 = add i64 %5475, -16
  %5989 = add i64 %5987, 4
  store i64 %5989, i64* %3, align 8
  %5990 = inttoptr i64 %5988 to i64*
  %5991 = load i64, i64* %5990, align 8
  store i64 %5991, i64* %RAX.i2610, align 8
  %5992 = add i64 %5987, 6
  store i64 %5992, i64* %3, align 8
  %5993 = inttoptr i64 %5991 to i32*
  %5994 = load i32, i32* %5993, align 4
  %5995 = add i32 %5994, 999999
  %5996 = zext i32 %5995 to i64
  store i64 %5996, i64* %RCX.i3977, align 8
  %5997 = icmp ugt i32 %5994, -1000000
  %5998 = zext i1 %5997 to i8
  store i8 %5998, i8* %12, align 1
  %5999 = and i32 %5995, 255
  %6000 = tail call i32 @llvm.ctpop.i32(i32 %5999)
  %6001 = trunc i32 %6000 to i8
  %6002 = and i8 %6001, 1
  %6003 = xor i8 %6002, 1
  store i8 %6003, i8* %13, align 1
  %6004 = xor i32 %5994, 16
  %6005 = xor i32 %6004, %5995
  %6006 = lshr i32 %6005, 4
  %6007 = trunc i32 %6006 to i8
  %6008 = and i8 %6007, 1
  store i8 %6008, i8* %14, align 1
  %6009 = icmp eq i32 %5995, 0
  %6010 = zext i1 %6009 to i8
  store i8 %6010, i8* %15, align 1
  %6011 = lshr i32 %5995, 31
  %6012 = trunc i32 %6011 to i8
  store i8 %6012, i8* %16, align 1
  %6013 = lshr i32 %5994, 31
  %6014 = xor i32 %6011, %6013
  %6015 = add nuw nsw i32 %6014, %6011
  %6016 = icmp eq i32 %6015, 2
  %6017 = zext i1 %6016 to i8
  store i8 %6017, i8* %17, align 1
  %6018 = add i64 %5987, 14
  store i64 %6018, i64* %3, align 8
  store i32 %5995, i32* %5993, align 4
  %6019 = load i64, i64* %3, align 8
  %6020 = add i64 %6019, 53
  store i64 %6020, i64* %3, align 8
  br label %block_.L_4ab4c2

block_.L_4ab492:                                  ; preds = %block_.L_4ab475
  store i64 ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64), i64* %RAX.i2610, align 8
  %6021 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %6021, i64* %RCX.i3977, align 8
  %6022 = add i64 %6021, 2468
  %6023 = add i64 %5987, 25
  store i64 %6023, i64* %3, align 8
  %6024 = inttoptr i64 %6022 to i32*
  %6025 = load i32, i32* %6024, align 4
  %6026 = sext i32 %6025 to i64
  %6027 = shl nsw i64 %6026, 6
  store i64 %6027, i64* %RCX.i3977, align 8
  %6028 = add i64 %6027, ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64)
  store i64 %6028, i64* %RAX.i2610, align 8
  %6029 = icmp ult i64 %6028, ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64)
  %6030 = icmp ult i64 %6028, %6027
  %6031 = or i1 %6029, %6030
  %6032 = zext i1 %6031 to i8
  store i8 %6032, i8* %12, align 1
  %6033 = trunc i64 %6028 to i32
  %6034 = and i32 %6033, 248
  %6035 = tail call i32 @llvm.ctpop.i32(i32 %6034)
  %6036 = trunc i32 %6035 to i8
  %6037 = and i8 %6036, 1
  %6038 = xor i8 %6037, 1
  store i8 %6038, i8* %13, align 1
  %6039 = xor i64 %6028, ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64)
  %6040 = lshr i64 %6039, 4
  %6041 = trunc i64 %6040 to i8
  %6042 = and i8 %6041, 1
  store i8 %6042, i8* %14, align 1
  %6043 = icmp eq i64 %6028, 0
  %6044 = zext i1 %6043 to i8
  store i8 %6044, i8* %15, align 1
  %6045 = lshr i64 %6028, 63
  %6046 = trunc i64 %6045 to i8
  store i8 %6046, i8* %16, align 1
  %6047 = lshr i64 %6026, 57
  %6048 = and i64 %6047, 1
  %6049 = xor i64 %6045, lshr (i64 ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64), i64 63)
  %6050 = xor i64 %6045, %6048
  %6051 = add nuw nsw i64 %6049, %6050
  %6052 = icmp eq i64 %6051, 2
  %6053 = zext i1 %6052 to i8
  store i8 %6053, i8* %17, align 1
  %6054 = add i64 %5475, -52
  %6055 = add i64 %5987, 36
  store i64 %6055, i64* %3, align 8
  %6056 = inttoptr i64 %6054 to i32*
  %6057 = load i32, i32* %6056, align 4
  %6058 = sext i32 %6057 to i64
  store i64 %6058, i64* %RCX.i3977, align 8
  %6059 = add i64 %6028, %6058
  %6060 = add i64 %5987, 40
  store i64 %6060, i64* %3, align 8
  %6061 = inttoptr i64 %6059 to i8*
  %6062 = load i8, i8* %6061, align 1
  %6063 = zext i8 %6062 to i64
  store i64 %6063, i64* %RDX.i4094, align 8
  %6064 = add i64 %5475, -16
  %6065 = add i64 %5987, 44
  store i64 %6065, i64* %3, align 8
  %6066 = inttoptr i64 %6064 to i64*
  %6067 = load i64, i64* %6066, align 8
  store i64 %6067, i64* %RAX.i2610, align 8
  %6068 = add i64 %5987, 46
  store i64 %6068, i64* %3, align 8
  %6069 = zext i8 %6062 to i32
  %6070 = inttoptr i64 %6067 to i32*
  %6071 = load i32, i32* %6070, align 4
  %6072 = add i32 %6071, %6069
  %6073 = zext i32 %6072 to i64
  store i64 %6073, i64* %RDX.i4094, align 8
  %6074 = icmp ult i32 %6072, %6069
  %6075 = icmp ult i32 %6072, %6071
  %6076 = or i1 %6074, %6075
  %6077 = zext i1 %6076 to i8
  store i8 %6077, i8* %12, align 1
  %6078 = and i32 %6072, 255
  %6079 = tail call i32 @llvm.ctpop.i32(i32 %6078)
  %6080 = trunc i32 %6079 to i8
  %6081 = and i8 %6080, 1
  %6082 = xor i8 %6081, 1
  store i8 %6082, i8* %13, align 1
  %6083 = xor i32 %6071, %6069
  %6084 = xor i32 %6083, %6072
  %6085 = lshr i32 %6084, 4
  %6086 = trunc i32 %6085 to i8
  %6087 = and i8 %6086, 1
  store i8 %6087, i8* %14, align 1
  %6088 = icmp eq i32 %6072, 0
  %6089 = zext i1 %6088 to i8
  store i8 %6089, i8* %15, align 1
  %6090 = lshr i32 %6072, 31
  %6091 = trunc i32 %6090 to i8
  store i8 %6091, i8* %16, align 1
  %6092 = lshr i32 %6071, 31
  %6093 = xor i32 %6090, %6092
  %6094 = add nuw nsw i32 %6090, %6093
  %6095 = icmp eq i32 %6094, 2
  %6096 = zext i1 %6095 to i8
  store i8 %6096, i8* %17, align 1
  %6097 = add i64 %5987, 48
  store i64 %6097, i64* %3, align 8
  store i32 %6072, i32* %6070, align 4
  %.pre194 = load i64, i64* %3, align 8
  br label %block_.L_4ab4c2

block_.L_4ab4c2:                                  ; preds = %block_.L_4ab492, %block_4ab47f
  %6098 = phi i64 [ %.pre194, %block_.L_4ab492 ], [ %6020, %block_4ab47f ]
  %6099 = load i64, i64* %RBP.i, align 8
  %6100 = add i64 %6099, -44
  %6101 = add i64 %6098, 3
  store i64 %6101, i64* %3, align 8
  %6102 = inttoptr i64 %6100 to i32*
  %6103 = load i32, i32* %6102, align 4
  %6104 = zext i32 %6103 to i64
  store i64 %6104, i64* %RDI.i4084, align 8
  %6105 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %6106 = add i64 %6105, 13112
  store i64 %6106, i64* %RAX.i2610, align 8
  %6107 = icmp ugt i64 %6105, -13113
  %6108 = zext i1 %6107 to i8
  store i8 %6108, i8* %12, align 1
  %6109 = trunc i64 %6106 to i32
  %6110 = and i32 %6109, 255
  %6111 = tail call i32 @llvm.ctpop.i32(i32 %6110)
  %6112 = trunc i32 %6111 to i8
  %6113 = and i8 %6112, 1
  %6114 = xor i8 %6113, 1
  store i8 %6114, i8* %13, align 1
  %6115 = xor i64 %6105, 16
  %6116 = xor i64 %6115, %6106
  %6117 = lshr i64 %6116, 4
  %6118 = trunc i64 %6117 to i8
  %6119 = and i8 %6118, 1
  store i8 %6119, i8* %14, align 1
  %6120 = icmp eq i64 %6106, 0
  %6121 = zext i1 %6120 to i8
  store i8 %6121, i8* %15, align 1
  %6122 = lshr i64 %6106, 63
  %6123 = trunc i64 %6122 to i8
  store i8 %6123, i8* %16, align 1
  %6124 = lshr i64 %6105, 63
  %6125 = xor i64 %6122, %6124
  %6126 = add nuw nsw i64 %6125, %6122
  %6127 = icmp eq i64 %6126, 2
  %6128 = zext i1 %6127 to i8
  store i8 %6128, i8* %17, align 1
  %6129 = add i64 %6099, -24
  %6130 = add i64 %6098, 21
  store i64 %6130, i64* %3, align 8
  %6131 = inttoptr i64 %6129 to i32*
  %6132 = load i32, i32* %6131, align 4
  %6133 = sext i32 %6132 to i64
  %6134 = shl nsw i64 %6133, 6
  store i64 %6134, i64* %RCX.i3977, align 8
  %6135 = add i64 %6134, %6106
  store i64 %6135, i64* %RAX.i2610, align 8
  %6136 = icmp ult i64 %6135, %6106
  %6137 = icmp ult i64 %6135, %6134
  %6138 = or i1 %6136, %6137
  %6139 = zext i1 %6138 to i8
  store i8 %6139, i8* %12, align 1
  %6140 = trunc i64 %6135 to i32
  %6141 = and i32 %6140, 255
  %6142 = tail call i32 @llvm.ctpop.i32(i32 %6141)
  %6143 = trunc i32 %6142 to i8
  %6144 = and i8 %6143, 1
  %6145 = xor i8 %6144, 1
  store i8 %6145, i8* %13, align 1
  %6146 = xor i64 %6106, %6135
  %6147 = lshr i64 %6146, 4
  %6148 = trunc i64 %6147 to i8
  %6149 = and i8 %6148, 1
  store i8 %6149, i8* %14, align 1
  %6150 = icmp eq i64 %6135, 0
  %6151 = zext i1 %6150 to i8
  store i8 %6151, i8* %15, align 1
  %6152 = lshr i64 %6135, 63
  %6153 = trunc i64 %6152 to i8
  store i8 %6153, i8* %16, align 1
  %6154 = lshr i64 %6133, 57
  %6155 = and i64 %6154, 1
  %6156 = xor i64 %6152, %6122
  %6157 = xor i64 %6152, %6155
  %6158 = add nuw nsw i64 %6156, %6157
  %6159 = icmp eq i64 %6158, 2
  %6160 = zext i1 %6159 to i8
  store i8 %6160, i8* %17, align 1
  %6161 = load i64, i64* %RBP.i, align 8
  %6162 = add i64 %6161, -28
  %6163 = add i64 %6098, 32
  store i64 %6163, i64* %3, align 8
  %6164 = inttoptr i64 %6162 to i32*
  %6165 = load i32, i32* %6164, align 4
  %6166 = sext i32 %6165 to i64
  store i64 %6166, i64* %RCX.i3977, align 8
  %6167 = shl nsw i64 %6166, 2
  %6168 = add i64 %6167, %6135
  %6169 = add i64 %6098, 35
  store i64 %6169, i64* %3, align 8
  %6170 = inttoptr i64 %6168 to i32*
  %6171 = load i32, i32* %6170, align 4
  %6172 = zext i32 %6171 to i64
  store i64 %6172, i64* %RSI.i3950, align 8
  %6173 = add i64 %6098, -222066
  %6174 = add i64 %6098, 40
  %6175 = load i64, i64* %6, align 8
  %6176 = add i64 %6175, -8
  %6177 = inttoptr i64 %6176 to i64*
  store i64 %6174, i64* %6177, align 8
  store i64 %6176, i64* %6, align 8
  store i64 %6173, i64* %3, align 8
  %call2_4ab4e5 = tail call %struct.Memory* @sub_475150.sign(%struct.State* nonnull %0, i64 %6173, %struct.Memory* %MEMORY.12)
  %6178 = load i64, i64* %RBP.i, align 8
  %6179 = add i64 %6178, -96
  %6180 = load i64, i64* %3, align 8
  %6181 = add i64 %6180, 4
  store i64 %6181, i64* %3, align 8
  %6182 = inttoptr i64 %6179 to i64*
  %6183 = load i64, i64* %6182, align 8
  store i64 %6183, i64* %RCX.i3977, align 8
  %6184 = add i64 %6178, -48
  %6185 = add i64 %6180, 8
  store i64 %6185, i64* %3, align 8
  %6186 = inttoptr i64 %6184 to i32*
  %6187 = load i32, i32* %6186, align 4
  %6188 = sext i32 %6187 to i64
  store i64 %6188, i64* %RDX.i4094, align 8
  %6189 = shl nsw i64 %6188, 2
  %6190 = add i64 %6189, %6183
  %6191 = load i32, i32* %EAX.i2609, align 4
  %6192 = add i64 %6180, 11
  store i64 %6192, i64* %3, align 8
  %6193 = inttoptr i64 %6190 to i32*
  store i32 %6191, i32* %6193, align 4
  %6194 = load i64, i64* %RBP.i, align 8
  %6195 = add i64 %6194, -52
  %6196 = load i64, i64* %3, align 8
  %6197 = add i64 %6196, 3
  store i64 %6197, i64* %3, align 8
  %6198 = inttoptr i64 %6195 to i32*
  %6199 = load i32, i32* %6198, align 4
  %6200 = zext i32 %6199 to i64
  store i64 %6200, i64* %RAX.i2610, align 8
  %6201 = add i64 %6194, -104
  %6202 = add i64 %6196, 7
  store i64 %6202, i64* %3, align 8
  %6203 = inttoptr i64 %6201 to i64*
  %6204 = load i64, i64* %6203, align 8
  store i64 %6204, i64* %RCX.i3977, align 8
  %6205 = add i64 %6194, -48
  %6206 = add i64 %6196, 11
  store i64 %6206, i64* %3, align 8
  %6207 = inttoptr i64 %6205 to i32*
  %6208 = load i32, i32* %6207, align 4
  %6209 = sext i32 %6208 to i64
  store i64 %6209, i64* %RDX.i4094, align 8
  %6210 = shl nsw i64 %6209, 2
  %6211 = add i64 %6210, %6204
  %6212 = add i64 %6196, 14
  store i64 %6212, i64* %3, align 8
  %6213 = inttoptr i64 %6211 to i32*
  store i32 %6199, i32* %6213, align 4
  %6214 = load i64, i64* %RBP.i, align 8
  %6215 = add i64 %6214, -48
  %6216 = load i64, i64* %3, align 8
  %6217 = add i64 %6216, 3
  store i64 %6217, i64* %3, align 8
  %6218 = inttoptr i64 %6215 to i32*
  %6219 = load i32, i32* %6218, align 4
  %6220 = add i32 %6219, 1
  %6221 = zext i32 %6220 to i64
  store i64 %6221, i64* %RAX.i2610, align 8
  %6222 = icmp eq i32 %6219, -1
  %6223 = icmp eq i32 %6220, 0
  %6224 = or i1 %6222, %6223
  %6225 = zext i1 %6224 to i8
  store i8 %6225, i8* %12, align 1
  %6226 = and i32 %6220, 255
  %6227 = tail call i32 @llvm.ctpop.i32(i32 %6226)
  %6228 = trunc i32 %6227 to i8
  %6229 = and i8 %6228, 1
  %6230 = xor i8 %6229, 1
  store i8 %6230, i8* %13, align 1
  %6231 = xor i32 %6220, %6219
  %6232 = lshr i32 %6231, 4
  %6233 = trunc i32 %6232 to i8
  %6234 = and i8 %6233, 1
  store i8 %6234, i8* %14, align 1
  %6235 = zext i1 %6223 to i8
  store i8 %6235, i8* %15, align 1
  %6236 = lshr i32 %6220, 31
  %6237 = trunc i32 %6236 to i8
  store i8 %6237, i8* %16, align 1
  %6238 = lshr i32 %6219, 31
  %6239 = xor i32 %6236, %6238
  %6240 = add nuw nsw i32 %6239, %6236
  %6241 = icmp eq i32 %6240, 2
  %6242 = zext i1 %6241 to i8
  store i8 %6242, i8* %17, align 1
  %6243 = add i64 %6216, 9
  store i64 %6243, i64* %3, align 8
  store i32 %6220, i32* %6218, align 4
  %6244 = load i64, i64* %RBP.i, align 8
  %6245 = add i64 %6244, -52
  %6246 = load i64, i64* %3, align 8
  %6247 = add i64 %6246, 7
  store i64 %6247, i64* %3, align 8
  %6248 = inttoptr i64 %6245 to i32*
  store i32 -1, i32* %6248, align 4
  %.pre195 = load i64, i64* %3, align 8
  br label %block_.L_4ab513

block_.L_4ab513:                                  ; preds = %block_.L_4ab4c2, %block_.L_4ab393
  %6249 = phi i64 [ %.pre195, %block_.L_4ab4c2 ], [ %5957, %block_.L_4ab393 ]
  %MEMORY.16 = phi %struct.Memory* [ %call2_4ab4e5, %block_.L_4ab4c2 ], [ %call2_4ab3b6, %block_.L_4ab393 ]
  %6250 = load i64, i64* %RBP.i, align 8
  %6251 = add i64 %6250, -44
  %6252 = add i64 %6249, 3
  store i64 %6252, i64* %3, align 8
  %6253 = inttoptr i64 %6251 to i32*
  %6254 = load i32, i32* %6253, align 4
  %6255 = zext i32 %6254 to i64
  store i64 %6255, i64* %RDI.i4084, align 8
  %6256 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %6257 = add i64 %6256, 13112
  store i64 %6257, i64* %RAX.i2610, align 8
  %6258 = icmp ugt i64 %6256, -13113
  %6259 = zext i1 %6258 to i8
  store i8 %6259, i8* %12, align 1
  %6260 = trunc i64 %6257 to i32
  %6261 = and i32 %6260, 255
  %6262 = tail call i32 @llvm.ctpop.i32(i32 %6261)
  %6263 = trunc i32 %6262 to i8
  %6264 = and i8 %6263, 1
  %6265 = xor i8 %6264, 1
  store i8 %6265, i8* %13, align 1
  %6266 = xor i64 %6256, 16
  %6267 = xor i64 %6266, %6257
  %6268 = lshr i64 %6267, 4
  %6269 = trunc i64 %6268 to i8
  %6270 = and i8 %6269, 1
  store i8 %6270, i8* %14, align 1
  %6271 = icmp eq i64 %6257, 0
  %6272 = zext i1 %6271 to i8
  store i8 %6272, i8* %15, align 1
  %6273 = lshr i64 %6257, 63
  %6274 = trunc i64 %6273 to i8
  store i8 %6274, i8* %16, align 1
  %6275 = lshr i64 %6256, 63
  %6276 = xor i64 %6273, %6275
  %6277 = add nuw nsw i64 %6276, %6273
  %6278 = icmp eq i64 %6277, 2
  %6279 = zext i1 %6278 to i8
  store i8 %6279, i8* %17, align 1
  %6280 = add i64 %6250, -24
  %6281 = add i64 %6249, 21
  store i64 %6281, i64* %3, align 8
  %6282 = inttoptr i64 %6280 to i32*
  %6283 = load i32, i32* %6282, align 4
  %6284 = sext i32 %6283 to i64
  %6285 = shl nsw i64 %6284, 6
  store i64 %6285, i64* %RCX.i3977, align 8
  %6286 = add i64 %6285, %6257
  store i64 %6286, i64* %RAX.i2610, align 8
  %6287 = icmp ult i64 %6286, %6257
  %6288 = icmp ult i64 %6286, %6285
  %6289 = or i1 %6287, %6288
  %6290 = zext i1 %6289 to i8
  store i8 %6290, i8* %12, align 1
  %6291 = trunc i64 %6286 to i32
  %6292 = and i32 %6291, 255
  %6293 = tail call i32 @llvm.ctpop.i32(i32 %6292)
  %6294 = trunc i32 %6293 to i8
  %6295 = and i8 %6294, 1
  %6296 = xor i8 %6295, 1
  store i8 %6296, i8* %13, align 1
  %6297 = xor i64 %6257, %6286
  %6298 = lshr i64 %6297, 4
  %6299 = trunc i64 %6298 to i8
  %6300 = and i8 %6299, 1
  store i8 %6300, i8* %14, align 1
  %6301 = icmp eq i64 %6286, 0
  %6302 = zext i1 %6301 to i8
  store i8 %6302, i8* %15, align 1
  %6303 = lshr i64 %6286, 63
  %6304 = trunc i64 %6303 to i8
  store i8 %6304, i8* %16, align 1
  %6305 = lshr i64 %6284, 57
  %6306 = and i64 %6305, 1
  %6307 = xor i64 %6303, %6273
  %6308 = xor i64 %6303, %6306
  %6309 = add nuw nsw i64 %6307, %6308
  %6310 = icmp eq i64 %6309, 2
  %6311 = zext i1 %6310 to i8
  store i8 %6311, i8* %17, align 1
  %6312 = load i64, i64* %RBP.i, align 8
  %6313 = add i64 %6312, -28
  %6314 = add i64 %6249, 32
  store i64 %6314, i64* %3, align 8
  %6315 = inttoptr i64 %6313 to i32*
  %6316 = load i32, i32* %6315, align 4
  %6317 = sext i32 %6316 to i64
  store i64 %6317, i64* %RCX.i3977, align 8
  %6318 = shl nsw i64 %6317, 2
  %6319 = add i64 %6318, %6286
  %6320 = add i64 %6249, 35
  store i64 %6320, i64* %3, align 8
  %6321 = inttoptr i64 %6319 to i32*
  %6322 = load i32, i32* %6321, align 4
  %6323 = zext i32 %6322 to i64
  store i64 %6323, i64* %RSI.i3950, align 8
  %6324 = add i64 %6249, -222147
  %6325 = add i64 %6249, 40
  %6326 = load i64, i64* %6, align 8
  %6327 = add i64 %6326, -8
  %6328 = inttoptr i64 %6327 to i64*
  store i64 %6325, i64* %6328, align 8
  store i64 %6327, i64* %6, align 8
  store i64 %6324, i64* %3, align 8
  %call2_4ab536 = tail call %struct.Memory* @sub_475150.sign(%struct.State* nonnull %0, i64 %6324, %struct.Memory* %MEMORY.16)
  %6329 = load i64, i64* %RBP.i, align 8
  %6330 = add i64 %6329, -44
  %6331 = load i32, i32* %EAX.i2609, align 4
  %6332 = load i64, i64* %3, align 8
  %6333 = add i64 %6332, 3
  store i64 %6333, i64* %3, align 8
  %6334 = inttoptr i64 %6330 to i32*
  store i32 %6331, i32* %6334, align 4
  %6335 = load i64, i64* %RBP.i, align 8
  %6336 = add i64 %6335, -412
  %6337 = load i64, i64* %3, align 8
  %6338 = add i64 %6337, 7
  store i64 %6338, i64* %3, align 8
  %6339 = inttoptr i64 %6336 to i32*
  %6340 = load i32, i32* %6339, align 4
  store i8 0, i8* %12, align 1
  %6341 = and i32 %6340, 255
  %6342 = tail call i32 @llvm.ctpop.i32(i32 %6341)
  %6343 = trunc i32 %6342 to i8
  %6344 = and i8 %6343, 1
  %6345 = xor i8 %6344, 1
  store i8 %6345, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %6346 = icmp eq i32 %6340, 0
  %6347 = zext i1 %6346 to i8
  store i8 %6347, i8* %15, align 1
  %6348 = lshr i32 %6340, 31
  %6349 = trunc i32 %6348 to i8
  store i8 %6349, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v207 = select i1 %6346, i64 24, i64 13
  %6350 = add i64 %6337, %.v207
  store i64 %6350, i64* %3, align 8
  br i1 %6346, label %block_.L_4ab556, label %block_4ab54b

block_4ab54b:                                     ; preds = %block_.L_4ab513
  %6351 = add i64 %6335, -44
  %6352 = add i64 %6350, 3
  store i64 %6352, i64* %3, align 8
  %6353 = inttoptr i64 %6351 to i32*
  %6354 = load i32, i32* %6353, align 4
  %6355 = zext i32 %6354 to i64
  store i64 %6355, i64* %RAX.i2610, align 8
  %6356 = add i64 %6335, -32
  %6357 = add i64 %6350, 6
  store i64 %6357, i64* %3, align 8
  %6358 = inttoptr i64 %6356 to i32*
  store i32 %6354, i32* %6358, align 4
  %6359 = load i64, i64* %3, align 8
  %6360 = add i64 %6359, 326
  br label %block_.L_4ab697

block_.L_4ab556:                                  ; preds = %block_.L_4ab513
  %6361 = add i64 %6335, -20
  %6362 = add i64 %6350, 4
  store i64 %6362, i64* %3, align 8
  %6363 = inttoptr i64 %6361 to i32*
  %6364 = load i32, i32* %6363, align 4
  %6365 = add i32 %6364, -1
  %6366 = icmp eq i32 %6364, 0
  %6367 = zext i1 %6366 to i8
  store i8 %6367, i8* %12, align 1
  %6368 = and i32 %6365, 255
  %6369 = tail call i32 @llvm.ctpop.i32(i32 %6368)
  %6370 = trunc i32 %6369 to i8
  %6371 = and i8 %6370, 1
  %6372 = xor i8 %6371, 1
  store i8 %6372, i8* %13, align 1
  %6373 = xor i32 %6365, %6364
  %6374 = lshr i32 %6373, 4
  %6375 = trunc i32 %6374 to i8
  %6376 = and i8 %6375, 1
  store i8 %6376, i8* %14, align 1
  %6377 = icmp eq i32 %6365, 0
  %6378 = zext i1 %6377 to i8
  store i8 %6378, i8* %15, align 1
  %6379 = lshr i32 %6365, 31
  %6380 = trunc i32 %6379 to i8
  store i8 %6380, i8* %16, align 1
  %6381 = lshr i32 %6364, 31
  %6382 = xor i32 %6379, %6381
  %6383 = add nuw nsw i32 %6382, %6381
  %6384 = icmp eq i32 %6383, 2
  %6385 = zext i1 %6384 to i8
  store i8 %6385, i8* %17, align 1
  %.v206 = select i1 %6377, i64 10, i64 163
  %6386 = add i64 %6350, %.v206
  %6387 = add i64 %6335, -60
  %6388 = add i64 %6386, 4
  store i64 %6388, i64* %3, align 8
  %6389 = inttoptr i64 %6387 to i32*
  %6390 = load i32, i32* %6389, align 4
  %6391 = add i32 %6390, -6
  %6392 = icmp ult i32 %6390, 6
  %6393 = zext i1 %6392 to i8
  store i8 %6393, i8* %12, align 1
  %6394 = and i32 %6391, 255
  %6395 = tail call i32 @llvm.ctpop.i32(i32 %6394)
  %6396 = trunc i32 %6395 to i8
  %6397 = and i8 %6396, 1
  %6398 = xor i8 %6397, 1
  store i8 %6398, i8* %13, align 1
  %6399 = xor i32 %6391, %6390
  %6400 = lshr i32 %6399, 4
  %6401 = trunc i32 %6400 to i8
  %6402 = and i8 %6401, 1
  store i8 %6402, i8* %14, align 1
  %6403 = icmp eq i32 %6391, 0
  %6404 = zext i1 %6403 to i8
  store i8 %6404, i8* %15, align 1
  %6405 = lshr i32 %6391, 31
  %6406 = trunc i32 %6405 to i8
  store i8 %6406, i8* %16, align 1
  %6407 = lshr i32 %6390, 31
  %6408 = xor i32 %6405, %6407
  %6409 = add nuw nsw i32 %6408, %6407
  %6410 = icmp eq i32 %6409, 2
  %6411 = zext i1 %6410 to i8
  store i8 %6411, i8* %17, align 1
  %6412 = icmp ne i8 %6406, 0
  %6413 = xor i1 %6412, %6410
  %.v228 = select i1 %6413, i64 80, i64 10
  %6414 = add i64 %6386, %.v228
  %6415 = add i64 %6414, 10
  store i64 %6415, i64* %3, align 8
  br i1 %6377, label %block_4ab560, label %block_.L_4ab5f9

block_4ab560:                                     ; preds = %block_.L_4ab556
  store i64 ptrtoint (%G__0x6cfc70_type* @G__0x6cfc70 to i64), i64* %RAX.i2610, align 8
  %6416 = add i64 %6335, -44
  %6417 = add i64 %6414, 13
  store i64 %6417, i64* %3, align 8
  %6418 = inttoptr i64 %6416 to i32*
  %6419 = load i32, i32* %6418, align 4
  %6420 = zext i32 %6419 to i64
  store i64 %6420, i64* %RCX.i3977, align 8
  %6421 = add i64 %6335, -64
  %6422 = add i64 %6414, 17
  store i64 %6422, i64* %3, align 8
  %6423 = inttoptr i64 %6421 to i32*
  %6424 = load i32, i32* %6423, align 4
  %6425 = sext i32 %6424 to i64
  %6426 = shl nsw i64 %6425, 8
  store i64 %6426, i64* %RDX.i4094, align 8
  %6427 = add i64 %6426, ptrtoint (%G__0x6cfc70_type* @G__0x6cfc70 to i64)
  store i64 %6427, i64* %RAX.i2610, align 8
  %6428 = icmp ult i64 %6427, ptrtoint (%G__0x6cfc70_type* @G__0x6cfc70 to i64)
  %6429 = icmp ult i64 %6427, %6426
  %6430 = or i1 %6428, %6429
  %6431 = zext i1 %6430 to i8
  store i8 %6431, i8* %12, align 1
  %6432 = trunc i64 %6427 to i32
  %6433 = and i32 %6432, 248
  %6434 = tail call i32 @llvm.ctpop.i32(i32 %6433)
  %6435 = trunc i32 %6434 to i8
  %6436 = and i8 %6435, 1
  %6437 = xor i8 %6436, 1
  store i8 %6437, i8* %13, align 1
  %6438 = xor i64 %6427, ptrtoint (%G__0x6cfc70_type* @G__0x6cfc70 to i64)
  %6439 = lshr i64 %6438, 4
  %6440 = trunc i64 %6439 to i8
  %6441 = and i8 %6440, 1
  store i8 %6441, i8* %14, align 1
  %6442 = icmp eq i64 %6427, 0
  %6443 = zext i1 %6442 to i8
  store i8 %6443, i8* %15, align 1
  %6444 = lshr i64 %6427, 63
  %6445 = trunc i64 %6444 to i8
  store i8 %6445, i8* %16, align 1
  %6446 = lshr i64 %6425, 55
  %6447 = and i64 %6446, 1
  %6448 = xor i64 %6444, lshr (i64 ptrtoint (%G__0x6cfc70_type* @G__0x6cfc70 to i64), i64 63)
  %6449 = xor i64 %6444, %6447
  %6450 = add nuw nsw i64 %6448, %6449
  %6451 = icmp eq i64 %6450, 2
  %6452 = zext i1 %6451 to i8
  store i8 %6452, i8* %17, align 1
  %6453 = add i64 %6335, -24
  %6454 = add i64 %6414, 28
  store i64 %6454, i64* %3, align 8
  %6455 = inttoptr i64 %6453 to i32*
  %6456 = load i32, i32* %6455, align 4
  %6457 = sext i32 %6456 to i64
  %6458 = shl nsw i64 %6457, 5
  store i64 %6458, i64* %RDX.i4094, align 8
  %6459 = add i64 %6458, %6427
  store i64 %6459, i64* %RAX.i2610, align 8
  %6460 = icmp ult i64 %6459, %6427
  %6461 = icmp ult i64 %6459, %6458
  %6462 = or i1 %6460, %6461
  %6463 = zext i1 %6462 to i8
  store i8 %6463, i8* %12, align 1
  %6464 = trunc i64 %6459 to i32
  %6465 = and i32 %6464, 248
  %6466 = tail call i32 @llvm.ctpop.i32(i32 %6465)
  %6467 = trunc i32 %6466 to i8
  %6468 = and i8 %6467, 1
  %6469 = xor i8 %6468, 1
  store i8 %6469, i8* %13, align 1
  %6470 = xor i64 %6427, %6459
  %6471 = lshr i64 %6470, 4
  %6472 = trunc i64 %6471 to i8
  %6473 = and i8 %6472, 1
  store i8 %6473, i8* %14, align 1
  %6474 = icmp eq i64 %6459, 0
  %6475 = zext i1 %6474 to i8
  store i8 %6475, i8* %15, align 1
  %6476 = lshr i64 %6459, 63
  %6477 = trunc i64 %6476 to i8
  store i8 %6477, i8* %16, align 1
  %6478 = lshr i64 %6457, 58
  %6479 = and i64 %6478, 1
  %6480 = xor i64 %6476, %6444
  %6481 = xor i64 %6476, %6479
  %6482 = add nuw nsw i64 %6480, %6481
  %6483 = icmp eq i64 %6482, 2
  %6484 = zext i1 %6483 to i8
  store i8 %6484, i8* %17, align 1
  %6485 = load i64, i64* %RBP.i, align 8
  %6486 = add i64 %6485, -28
  %6487 = add i64 %6414, 39
  store i64 %6487, i64* %3, align 8
  %6488 = inttoptr i64 %6486 to i32*
  %6489 = load i32, i32* %6488, align 4
  %6490 = sext i32 %6489 to i64
  store i64 %6490, i64* %RDX.i4094, align 8
  %6491 = load i64, i64* %RCX.i3977, align 8
  %6492 = shl nsw i64 %6490, 2
  %6493 = add i64 %6459, %6492
  %6494 = add i64 %6414, 43
  store i64 %6494, i64* %3, align 8
  %6495 = inttoptr i64 %6493 to i32*
  %6496 = load i32, i32* %6495, align 4
  %6497 = shl i64 %6491, 32
  %6498 = ashr exact i64 %6497, 32
  %6499 = sext i32 %6496 to i64
  %6500 = mul nsw i64 %6499, %6498
  %6501 = trunc i64 %6500 to i32
  %6502 = and i64 %6500, 4294967295
  store i64 %6502, i64* %RCX.i3977, align 8
  %6503 = shl i64 %6500, 32
  %6504 = ashr exact i64 %6503, 32
  %6505 = icmp ne i64 %6504, %6500
  %6506 = zext i1 %6505 to i8
  store i8 %6506, i8* %12, align 1
  %6507 = and i32 %6501, 255
  %6508 = tail call i32 @llvm.ctpop.i32(i32 %6507)
  %6509 = trunc i32 %6508 to i8
  %6510 = and i8 %6509, 1
  %6511 = xor i8 %6510, 1
  store i8 %6511, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  %6512 = lshr i32 %6501, 31
  %6513 = trunc i32 %6512 to i8
  store i8 %6513, i8* %16, align 1
  store i8 %6506, i8* %17, align 1
  %6514 = trunc i64 %6500 to i32
  br i1 %6413, label %block_.L_4ab5b0, label %block_4ab56a

block_4ab56a:                                     ; preds = %block_4ab560
  %6515 = add i64 %6485, -72
  %6516 = add i64 %6414, 46
  store i64 %6516, i64* %3, align 8
  %6517 = inttoptr i64 %6515 to i32*
  %6518 = load i32, i32* %6517, align 4
  %6519 = zext i32 %6518 to i64
  store i64 %6519, i64* %RSI.i3950, align 8
  %6520 = add i64 %6485, -704
  %6521 = add i64 %6414, 52
  store i64 %6521, i64* %3, align 8
  %6522 = inttoptr i64 %6520 to i32*
  store i32 %6514, i32* %6522, align 4
  %6523 = load i32, i32* %ESI.i3747.pre-phi, align 4
  %6524 = zext i32 %6523 to i64
  %6525 = load i64, i64* %3, align 8
  store i64 %6524, i64* %RCX.i3977, align 8
  %6526 = load i64, i64* %RBP.i, align 8
  %6527 = add i64 %6526, -704
  %6528 = add i64 %6525, 8
  store i64 %6528, i64* %3, align 8
  %6529 = inttoptr i64 %6527 to i32*
  %6530 = load i32, i32* %6529, align 4
  %6531 = zext i32 %6530 to i64
  store i64 %6531, i64* %RSI.i3950, align 8
  %6532 = add i64 %6525, 10
  store i64 %6532, i64* %3, align 8
  %6533 = trunc i32 %6523 to i5
  switch i5 %6533, label %6539 [
    i5 0, label %routine_shll__cl___esi.exit2047
    i5 1, label %6534
  ]

; <label>:6534:                                   ; preds = %block_4ab56a
  %6535 = shl i32 %6530, 1
  %6536 = icmp slt i32 %6530, 0
  %6537 = icmp slt i32 %6535, 0
  %6538 = xor i1 %6536, %6537
  br label %6548

; <label>:6539:                                   ; preds = %block_4ab56a
  %6540 = and i32 %6523, 31
  %6541 = zext i32 %6540 to i64
  %6542 = add nuw nsw i64 %6541, 4294967295
  %6543 = and i64 %6542, 4294967295
  %6544 = shl i64 %6531, %6543
  %6545 = trunc i64 %6544 to i32
  %6546 = icmp slt i32 %6545, 0
  %6547 = shl i32 %6545, 1
  br label %6548

; <label>:6548:                                   ; preds = %6539, %6534
  %6549 = phi i1 [ %6536, %6534 ], [ %6546, %6539 ]
  %6550 = phi i1 [ %6538, %6534 ], [ false, %6539 ]
  %6551 = phi i32 [ %6535, %6534 ], [ %6547, %6539 ]
  %6552 = zext i32 %6551 to i64
  store i64 %6552, i64* %RSI.i3950, align 8
  %6553 = zext i1 %6549 to i8
  store i8 %6553, i8* %12, align 1
  %6554 = and i32 %6551, 254
  %6555 = tail call i32 @llvm.ctpop.i32(i32 %6554)
  %6556 = trunc i32 %6555 to i8
  %6557 = and i8 %6556, 1
  %6558 = xor i8 %6557, 1
  store i8 %6558, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %6559 = icmp eq i32 %6551, 0
  %6560 = zext i1 %6559 to i8
  store i8 %6560, i8* %15, align 1
  %6561 = lshr i32 %6551, 31
  %6562 = trunc i32 %6561 to i8
  store i8 %6562, i8* %16, align 1
  %6563 = zext i1 %6550 to i8
  store i8 %6563, i8* %17, align 1
  br label %routine_shll__cl___esi.exit2047

routine_shll__cl___esi.exit2047:                  ; preds = %6548, %block_4ab56a
  %6564 = phi i32 [ %6551, %6548 ], [ %6530, %block_4ab56a ]
  %6565 = add i64 %6526, -32
  %6566 = add i64 %6525, 13
  store i64 %6566, i64* %3, align 8
  %6567 = inttoptr i64 %6565 to i32*
  store i32 %6564, i32* %6567, align 4
  %6568 = load i64, i64* %3, align 8
  %6569 = add i64 %6568, 73
  store i64 %6569, i64* %3, align 8
  br label %block_.L_4ab5f4

block_.L_4ab5b0:                                  ; preds = %block_4ab560
  %6570 = add i64 %6485, -80
  %6571 = add i64 %6414, 46
  store i64 %6571, i64* %3, align 8
  %6572 = inttoptr i64 %6570 to i32*
  %6573 = load i32, i32* %6572, align 4
  %6574 = add i32 %6573, %6514
  %6575 = zext i32 %6574 to i64
  store i64 %6575, i64* %RCX.i3977, align 8
  %6576 = icmp ult i32 %6574, %6514
  %6577 = icmp ult i32 %6574, %6573
  %6578 = or i1 %6576, %6577
  %6579 = zext i1 %6578 to i8
  store i8 %6579, i8* %12, align 1
  %6580 = and i32 %6574, 255
  %6581 = tail call i32 @llvm.ctpop.i32(i32 %6580)
  %6582 = trunc i32 %6581 to i8
  %6583 = and i8 %6582, 1
  %6584 = xor i8 %6583, 1
  store i8 %6584, i8* %13, align 1
  %6585 = xor i32 %6573, %6514
  %6586 = xor i32 %6585, %6574
  %6587 = lshr i32 %6586, 4
  %6588 = trunc i32 %6587 to i8
  %6589 = and i8 %6588, 1
  store i8 %6589, i8* %14, align 1
  %6590 = icmp eq i32 %6574, 0
  %6591 = zext i1 %6590 to i8
  store i8 %6591, i8* %15, align 1
  %6592 = lshr i32 %6574, 31
  %6593 = trunc i32 %6592 to i8
  store i8 %6593, i8* %16, align 1
  %6594 = lshr i32 %6514, 31
  %6595 = lshr i32 %6573, 31
  %6596 = xor i32 %6592, %6594
  %6597 = xor i32 %6592, %6595
  %6598 = add nuw nsw i32 %6596, %6597
  %6599 = icmp eq i32 %6598, 2
  %6600 = zext i1 %6599 to i8
  store i8 %6600, i8* %17, align 1
  %6601 = add i64 %6485, -76
  %6602 = add i64 %6414, 49
  store i64 %6602, i64* %3, align 8
  %6603 = inttoptr i64 %6601 to i32*
  %6604 = load i32, i32* %6603, align 4
  %6605 = zext i32 %6604 to i64
  store i64 %6605, i64* %RSI.i3950, align 8
  %6606 = add i64 %6485, -708
  %6607 = add i64 %6414, 55
  store i64 %6607, i64* %3, align 8
  %6608 = inttoptr i64 %6606 to i32*
  store i32 %6574, i32* %6608, align 4
  %6609 = load i32, i32* %ESI.i3747.pre-phi, align 4
  %6610 = zext i32 %6609 to i64
  %6611 = load i64, i64* %3, align 8
  store i64 %6610, i64* %RCX.i3977, align 8
  %6612 = load i64, i64* %RBP.i, align 8
  %6613 = add i64 %6612, -708
  %6614 = add i64 %6611, 8
  store i64 %6614, i64* %3, align 8
  %6615 = inttoptr i64 %6613 to i32*
  %6616 = load i32, i32* %6615, align 4
  %6617 = zext i32 %6616 to i64
  store i64 %6617, i64* %RSI.i3950, align 8
  %6618 = add i64 %6611, 10
  store i64 %6618, i64* %3, align 8
  %6619 = trunc i32 %6609 to i5
  switch i5 %6619, label %6623 [
    i5 0, label %routine_sarl__cl___esi.exit1996
    i5 1, label %6620
  ]

; <label>:6620:                                   ; preds = %block_.L_4ab5b0
  %6621 = shl nuw i64 %6617, 32
  %6622 = ashr i64 %6621, 33
  br label %6630

; <label>:6623:                                   ; preds = %block_.L_4ab5b0
  %6624 = and i32 %6609, 31
  %6625 = zext i32 %6624 to i64
  %6626 = add nsw i64 %6625, -1
  %6627 = sext i32 %6616 to i64
  %6628 = ashr i64 %6627, %6626
  %6629 = lshr i64 %6628, 1
  br label %6630

; <label>:6630:                                   ; preds = %6623, %6620
  %6631 = phi i64 [ %6629, %6623 ], [ %6622, %6620 ]
  %6632 = phi i64 [ %6628, %6623 ], [ %6617, %6620 ]
  %6633 = trunc i64 %6632 to i8
  %6634 = and i8 %6633, 1
  %6635 = trunc i64 %6631 to i32
  %6636 = and i64 %6631, 4294967295
  store i64 %6636, i64* %RSI.i3950, align 8
  store i8 %6634, i8* %12, align 1
  %6637 = and i32 %6635, 255
  %6638 = tail call i32 @llvm.ctpop.i32(i32 %6637)
  %6639 = trunc i32 %6638 to i8
  %6640 = and i8 %6639, 1
  %6641 = xor i8 %6640, 1
  store i8 %6641, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %6642 = icmp eq i32 %6635, 0
  %6643 = zext i1 %6642 to i8
  store i8 %6643, i8* %15, align 1
  %6644 = lshr i32 %6635, 31
  %6645 = trunc i32 %6644 to i8
  store i8 %6645, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %6646 = trunc i64 %6631 to i32
  br label %routine_sarl__cl___esi.exit1996

routine_sarl__cl___esi.exit1996:                  ; preds = %6630, %block_.L_4ab5b0
  %6647 = phi i32 [ %6646, %6630 ], [ %6616, %block_.L_4ab5b0 ]
  %6648 = add i64 %6612, -32
  %6649 = add i64 %6611, 13
  store i64 %6649, i64* %3, align 8
  %6650 = inttoptr i64 %6648 to i32*
  store i32 %6647, i32* %6650, align 4
  %.pre196 = load i64, i64* %3, align 8
  br label %block_.L_4ab5f4

block_.L_4ab5f4:                                  ; preds = %routine_sarl__cl___esi.exit1996, %routine_shll__cl___esi.exit2047
  %6651 = phi i64 [ %.pre196, %routine_sarl__cl___esi.exit1996 ], [ %6569, %routine_shll__cl___esi.exit2047 ]
  %6652 = add i64 %6651, 158
  br label %block_.L_4ab692

block_.L_4ab5f9:                                  ; preds = %block_.L_4ab556
  store i64 ptrtoint (%G__0x6d12c0_type* @G__0x6d12c0 to i64), i64* %RAX.i2610, align 8
  %6653 = add i64 %6335, -44
  %6654 = add i64 %6414, 13
  store i64 %6654, i64* %3, align 8
  %6655 = inttoptr i64 %6653 to i32*
  %6656 = load i32, i32* %6655, align 4
  %6657 = zext i32 %6656 to i64
  store i64 %6657, i64* %RCX.i3977, align 8
  %6658 = add i64 %6335, -64
  %6659 = add i64 %6414, 17
  store i64 %6659, i64* %3, align 8
  %6660 = inttoptr i64 %6658 to i32*
  %6661 = load i32, i32* %6660, align 4
  %6662 = sext i32 %6661 to i64
  %6663 = shl nsw i64 %6662, 8
  store i64 %6663, i64* %RDX.i4094, align 8
  %6664 = add i64 %6663, ptrtoint (%G__0x6d12c0_type* @G__0x6d12c0 to i64)
  store i64 %6664, i64* %RAX.i2610, align 8
  %6665 = icmp ult i64 %6664, ptrtoint (%G__0x6d12c0_type* @G__0x6d12c0 to i64)
  %6666 = icmp ult i64 %6664, %6663
  %6667 = or i1 %6665, %6666
  %6668 = zext i1 %6667 to i8
  store i8 %6668, i8* %12, align 1
  %6669 = trunc i64 %6664 to i32
  %6670 = and i32 %6669, 248
  %6671 = tail call i32 @llvm.ctpop.i32(i32 %6670)
  %6672 = trunc i32 %6671 to i8
  %6673 = and i8 %6672, 1
  %6674 = xor i8 %6673, 1
  store i8 %6674, i8* %13, align 1
  %6675 = xor i64 %6664, ptrtoint (%G__0x6d12c0_type* @G__0x6d12c0 to i64)
  %6676 = lshr i64 %6675, 4
  %6677 = trunc i64 %6676 to i8
  %6678 = and i8 %6677, 1
  store i8 %6678, i8* %14, align 1
  %6679 = icmp eq i64 %6664, 0
  %6680 = zext i1 %6679 to i8
  store i8 %6680, i8* %15, align 1
  %6681 = lshr i64 %6664, 63
  %6682 = trunc i64 %6681 to i8
  store i8 %6682, i8* %16, align 1
  %6683 = lshr i64 %6662, 55
  %6684 = and i64 %6683, 1
  %6685 = xor i64 %6681, lshr (i64 ptrtoint (%G__0x6d12c0_type* @G__0x6d12c0 to i64), i64 63)
  %6686 = xor i64 %6681, %6684
  %6687 = add nuw nsw i64 %6685, %6686
  %6688 = icmp eq i64 %6687, 2
  %6689 = zext i1 %6688 to i8
  store i8 %6689, i8* %17, align 1
  %6690 = add i64 %6335, -24
  %6691 = add i64 %6414, 28
  store i64 %6691, i64* %3, align 8
  %6692 = inttoptr i64 %6690 to i32*
  %6693 = load i32, i32* %6692, align 4
  %6694 = sext i32 %6693 to i64
  %6695 = shl nsw i64 %6694, 5
  store i64 %6695, i64* %RDX.i4094, align 8
  %6696 = add i64 %6695, %6664
  store i64 %6696, i64* %RAX.i2610, align 8
  %6697 = icmp ult i64 %6696, %6664
  %6698 = icmp ult i64 %6696, %6695
  %6699 = or i1 %6697, %6698
  %6700 = zext i1 %6699 to i8
  store i8 %6700, i8* %12, align 1
  %6701 = trunc i64 %6696 to i32
  %6702 = and i32 %6701, 248
  %6703 = tail call i32 @llvm.ctpop.i32(i32 %6702)
  %6704 = trunc i32 %6703 to i8
  %6705 = and i8 %6704, 1
  %6706 = xor i8 %6705, 1
  store i8 %6706, i8* %13, align 1
  %6707 = xor i64 %6664, %6696
  %6708 = lshr i64 %6707, 4
  %6709 = trunc i64 %6708 to i8
  %6710 = and i8 %6709, 1
  store i8 %6710, i8* %14, align 1
  %6711 = icmp eq i64 %6696, 0
  %6712 = zext i1 %6711 to i8
  store i8 %6712, i8* %15, align 1
  %6713 = lshr i64 %6696, 63
  %6714 = trunc i64 %6713 to i8
  store i8 %6714, i8* %16, align 1
  %6715 = lshr i64 %6694, 58
  %6716 = and i64 %6715, 1
  %6717 = xor i64 %6713, %6681
  %6718 = xor i64 %6713, %6716
  %6719 = add nuw nsw i64 %6717, %6718
  %6720 = icmp eq i64 %6719, 2
  %6721 = zext i1 %6720 to i8
  store i8 %6721, i8* %17, align 1
  %6722 = load i64, i64* %RBP.i, align 8
  %6723 = add i64 %6722, -28
  %6724 = add i64 %6414, 39
  store i64 %6724, i64* %3, align 8
  %6725 = inttoptr i64 %6723 to i32*
  %6726 = load i32, i32* %6725, align 4
  %6727 = sext i32 %6726 to i64
  store i64 %6727, i64* %RDX.i4094, align 8
  %6728 = load i64, i64* %RCX.i3977, align 8
  %6729 = shl nsw i64 %6727, 2
  %6730 = add i64 %6696, %6729
  %6731 = add i64 %6414, 43
  store i64 %6731, i64* %3, align 8
  %6732 = inttoptr i64 %6730 to i32*
  %6733 = load i32, i32* %6732, align 4
  %6734 = shl i64 %6728, 32
  %6735 = ashr exact i64 %6734, 32
  %6736 = sext i32 %6733 to i64
  %6737 = mul nsw i64 %6736, %6735
  %6738 = trunc i64 %6737 to i32
  %6739 = and i64 %6737, 4294967295
  store i64 %6739, i64* %RCX.i3977, align 8
  %6740 = shl i64 %6737, 32
  %6741 = ashr exact i64 %6740, 32
  %6742 = icmp ne i64 %6741, %6737
  %6743 = zext i1 %6742 to i8
  store i8 %6743, i8* %12, align 1
  %6744 = and i32 %6738, 255
  %6745 = tail call i32 @llvm.ctpop.i32(i32 %6744)
  %6746 = trunc i32 %6745 to i8
  %6747 = and i8 %6746, 1
  %6748 = xor i8 %6747, 1
  store i8 %6748, i8* %13, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %15, align 1
  %6749 = lshr i32 %6738, 31
  %6750 = trunc i32 %6749 to i8
  store i8 %6750, i8* %16, align 1
  store i8 %6743, i8* %17, align 1
  %6751 = trunc i64 %6737 to i32
  br i1 %6413, label %block_.L_4ab649, label %block_4ab603

block_4ab603:                                     ; preds = %block_.L_4ab5f9
  %6752 = add i64 %6722, -72
  %6753 = add i64 %6414, 46
  store i64 %6753, i64* %3, align 8
  %6754 = inttoptr i64 %6752 to i32*
  %6755 = load i32, i32* %6754, align 4
  %6756 = zext i32 %6755 to i64
  store i64 %6756, i64* %RSI.i3950, align 8
  %6757 = add i64 %6722, -712
  %6758 = add i64 %6414, 52
  store i64 %6758, i64* %3, align 8
  %6759 = inttoptr i64 %6757 to i32*
  store i32 %6751, i32* %6759, align 4
  %6760 = load i32, i32* %ESI.i3747.pre-phi, align 4
  %6761 = zext i32 %6760 to i64
  %6762 = load i64, i64* %3, align 8
  store i64 %6761, i64* %RCX.i3977, align 8
  %6763 = load i64, i64* %RBP.i, align 8
  %6764 = add i64 %6763, -712
  %6765 = add i64 %6762, 8
  store i64 %6765, i64* %3, align 8
  %6766 = inttoptr i64 %6764 to i32*
  %6767 = load i32, i32* %6766, align 4
  %6768 = zext i32 %6767 to i64
  store i64 %6768, i64* %RSI.i3950, align 8
  %6769 = add i64 %6762, 10
  store i64 %6769, i64* %3, align 8
  %6770 = trunc i32 %6760 to i5
  switch i5 %6770, label %6776 [
    i5 0, label %routine_shll__cl___esi.exit
    i5 1, label %6771
  ]

; <label>:6771:                                   ; preds = %block_4ab603
  %6772 = shl i32 %6767, 1
  %6773 = icmp slt i32 %6767, 0
  %6774 = icmp slt i32 %6772, 0
  %6775 = xor i1 %6773, %6774
  br label %6785

; <label>:6776:                                   ; preds = %block_4ab603
  %6777 = and i32 %6760, 31
  %6778 = zext i32 %6777 to i64
  %6779 = add nuw nsw i64 %6778, 4294967295
  %6780 = and i64 %6779, 4294967295
  %6781 = shl i64 %6768, %6780
  %6782 = trunc i64 %6781 to i32
  %6783 = icmp slt i32 %6782, 0
  %6784 = shl i32 %6782, 1
  br label %6785

; <label>:6785:                                   ; preds = %6776, %6771
  %6786 = phi i1 [ %6773, %6771 ], [ %6783, %6776 ]
  %6787 = phi i1 [ %6775, %6771 ], [ false, %6776 ]
  %6788 = phi i32 [ %6772, %6771 ], [ %6784, %6776 ]
  %6789 = zext i32 %6788 to i64
  store i64 %6789, i64* %RSI.i3950, align 8
  %6790 = zext i1 %6786 to i8
  store i8 %6790, i8* %12, align 1
  %6791 = and i32 %6788, 254
  %6792 = tail call i32 @llvm.ctpop.i32(i32 %6791)
  %6793 = trunc i32 %6792 to i8
  %6794 = and i8 %6793, 1
  %6795 = xor i8 %6794, 1
  store i8 %6795, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %6796 = icmp eq i32 %6788, 0
  %6797 = zext i1 %6796 to i8
  store i8 %6797, i8* %15, align 1
  %6798 = lshr i32 %6788, 31
  %6799 = trunc i32 %6798 to i8
  store i8 %6799, i8* %16, align 1
  %6800 = zext i1 %6787 to i8
  store i8 %6800, i8* %17, align 1
  br label %routine_shll__cl___esi.exit

routine_shll__cl___esi.exit:                      ; preds = %6785, %block_4ab603
  %6801 = phi i32 [ %6788, %6785 ], [ %6767, %block_4ab603 ]
  %6802 = add i64 %6763, -32
  %6803 = add i64 %6762, 13
  store i64 %6803, i64* %3, align 8
  %6804 = inttoptr i64 %6802 to i32*
  store i32 %6801, i32* %6804, align 4
  %6805 = load i64, i64* %3, align 8
  %6806 = add i64 %6805, 73
  store i64 %6806, i64* %3, align 8
  br label %block_.L_4ab68d

block_.L_4ab649:                                  ; preds = %block_.L_4ab5f9
  %6807 = add i64 %6722, -80
  %6808 = add i64 %6414, 46
  store i64 %6808, i64* %3, align 8
  %6809 = inttoptr i64 %6807 to i32*
  %6810 = load i32, i32* %6809, align 4
  %6811 = add i32 %6810, %6751
  %6812 = zext i32 %6811 to i64
  store i64 %6812, i64* %RCX.i3977, align 8
  %6813 = icmp ult i32 %6811, %6751
  %6814 = icmp ult i32 %6811, %6810
  %6815 = or i1 %6813, %6814
  %6816 = zext i1 %6815 to i8
  store i8 %6816, i8* %12, align 1
  %6817 = and i32 %6811, 255
  %6818 = tail call i32 @llvm.ctpop.i32(i32 %6817)
  %6819 = trunc i32 %6818 to i8
  %6820 = and i8 %6819, 1
  %6821 = xor i8 %6820, 1
  store i8 %6821, i8* %13, align 1
  %6822 = xor i32 %6810, %6751
  %6823 = xor i32 %6822, %6811
  %6824 = lshr i32 %6823, 4
  %6825 = trunc i32 %6824 to i8
  %6826 = and i8 %6825, 1
  store i8 %6826, i8* %14, align 1
  %6827 = icmp eq i32 %6811, 0
  %6828 = zext i1 %6827 to i8
  store i8 %6828, i8* %15, align 1
  %6829 = lshr i32 %6811, 31
  %6830 = trunc i32 %6829 to i8
  store i8 %6830, i8* %16, align 1
  %6831 = lshr i32 %6751, 31
  %6832 = lshr i32 %6810, 31
  %6833 = xor i32 %6829, %6831
  %6834 = xor i32 %6829, %6832
  %6835 = add nuw nsw i32 %6833, %6834
  %6836 = icmp eq i32 %6835, 2
  %6837 = zext i1 %6836 to i8
  store i8 %6837, i8* %17, align 1
  %6838 = add i64 %6722, -76
  %6839 = add i64 %6414, 49
  store i64 %6839, i64* %3, align 8
  %6840 = inttoptr i64 %6838 to i32*
  %6841 = load i32, i32* %6840, align 4
  %6842 = zext i32 %6841 to i64
  store i64 %6842, i64* %RSI.i3950, align 8
  %6843 = add i64 %6722, -716
  %6844 = add i64 %6414, 55
  store i64 %6844, i64* %3, align 8
  %6845 = inttoptr i64 %6843 to i32*
  store i32 %6811, i32* %6845, align 4
  %6846 = load i32, i32* %ESI.i3747.pre-phi, align 4
  %6847 = zext i32 %6846 to i64
  %6848 = load i64, i64* %3, align 8
  store i64 %6847, i64* %RCX.i3977, align 8
  %6849 = load i64, i64* %RBP.i, align 8
  %6850 = add i64 %6849, -716
  %6851 = add i64 %6848, 8
  store i64 %6851, i64* %3, align 8
  %6852 = inttoptr i64 %6850 to i32*
  %6853 = load i32, i32* %6852, align 4
  %6854 = zext i32 %6853 to i64
  store i64 %6854, i64* %RSI.i3950, align 8
  %6855 = add i64 %6848, 10
  store i64 %6855, i64* %3, align 8
  %6856 = trunc i32 %6846 to i5
  switch i5 %6856, label %6860 [
    i5 0, label %routine_sarl__cl___esi.exit
    i5 1, label %6857
  ]

; <label>:6857:                                   ; preds = %block_.L_4ab649
  %6858 = shl nuw i64 %6854, 32
  %6859 = ashr i64 %6858, 33
  br label %6867

; <label>:6860:                                   ; preds = %block_.L_4ab649
  %6861 = and i32 %6846, 31
  %6862 = zext i32 %6861 to i64
  %6863 = add nsw i64 %6862, -1
  %6864 = sext i32 %6853 to i64
  %6865 = ashr i64 %6864, %6863
  %6866 = lshr i64 %6865, 1
  br label %6867

; <label>:6867:                                   ; preds = %6860, %6857
  %6868 = phi i64 [ %6866, %6860 ], [ %6859, %6857 ]
  %6869 = phi i64 [ %6865, %6860 ], [ %6854, %6857 ]
  %6870 = trunc i64 %6869 to i8
  %6871 = and i8 %6870, 1
  %6872 = trunc i64 %6868 to i32
  %6873 = and i64 %6868, 4294967295
  store i64 %6873, i64* %RSI.i3950, align 8
  store i8 %6871, i8* %12, align 1
  %6874 = and i32 %6872, 255
  %6875 = tail call i32 @llvm.ctpop.i32(i32 %6874)
  %6876 = trunc i32 %6875 to i8
  %6877 = and i8 %6876, 1
  %6878 = xor i8 %6877, 1
  store i8 %6878, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %6879 = icmp eq i32 %6872, 0
  %6880 = zext i1 %6879 to i8
  store i8 %6880, i8* %15, align 1
  %6881 = lshr i32 %6872, 31
  %6882 = trunc i32 %6881 to i8
  store i8 %6882, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %6883 = trunc i64 %6868 to i32
  br label %routine_sarl__cl___esi.exit

routine_sarl__cl___esi.exit:                      ; preds = %6867, %block_.L_4ab649
  %6884 = phi i32 [ %6883, %6867 ], [ %6853, %block_.L_4ab649 ]
  %6885 = add i64 %6849, -32
  %6886 = add i64 %6848, 13
  store i64 %6886, i64* %3, align 8
  %6887 = inttoptr i64 %6885 to i32*
  store i32 %6884, i32* %6887, align 4
  %.pre197 = load i64, i64* %3, align 8
  br label %block_.L_4ab68d

block_.L_4ab68d:                                  ; preds = %routine_sarl__cl___esi.exit, %routine_shll__cl___esi.exit
  %6888 = phi i64 [ %.pre197, %routine_sarl__cl___esi.exit ], [ %6806, %routine_shll__cl___esi.exit ]
  %6889 = add i64 %6888, 5
  store i64 %6889, i64* %3, align 8
  br label %block_.L_4ab692

block_.L_4ab692:                                  ; preds = %block_.L_4ab68d, %block_.L_4ab5f4
  %storemerge48 = phi i64 [ %6652, %block_.L_4ab5f4 ], [ %6889, %block_.L_4ab68d ]
  %6890 = add i64 %storemerge48, 5
  store i64 %6890, i64* %3, align 8
  br label %block_.L_4ab697

block_.L_4ab697:                                  ; preds = %block_.L_4ab692, %block_4ab54b
  %storemerge44 = phi i64 [ %6360, %block_4ab54b ], [ %6890, %block_.L_4ab692 ]
  %6891 = add i64 %storemerge44, 5
  store i64 %6891, i64* %3, align 8
  %.pre198 = load i64, i64* %RBP.i, align 8
  br label %block_.L_4ab69c

block_.L_4ab69c:                                  ; preds = %block_.L_4ab697, %block_.L_4ab2ff
  %6892 = phi i64 [ %5471, %block_.L_4ab2ff ], [ %6891, %block_.L_4ab697 ]
  %6893 = phi i64 [ %5457, %block_.L_4ab2ff ], [ %.pre198, %block_.L_4ab697 ]
  %MEMORY.21 = phi %struct.Memory* [ %MEMORY.12, %block_.L_4ab2ff ], [ %call2_4ab536, %block_.L_4ab697 ]
  %6894 = add i64 %6893, -412
  %6895 = add i64 %6892, 7
  store i64 %6895, i64* %3, align 8
  %6896 = inttoptr i64 %6894 to i32*
  %6897 = load i32, i32* %6896, align 4
  store i8 0, i8* %12, align 1
  %6898 = and i32 %6897, 255
  %6899 = tail call i32 @llvm.ctpop.i32(i32 %6898)
  %6900 = trunc i32 %6899 to i8
  %6901 = and i8 %6900, 1
  %6902 = xor i8 %6901, 1
  store i8 %6902, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %6903 = icmp eq i32 %6897, 0
  %6904 = zext i1 %6903 to i8
  store i8 %6904, i8* %15, align 1
  %6905 = lshr i32 %6897, 31
  %6906 = trunc i32 %6905 to i8
  store i8 %6906, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v227 = select i1 %6903, i64 13, i64 49
  %6907 = add i64 %6892, %.v227
  store i64 %6907, i64* %3, align 8
  br i1 %6903, label %block_4ab6a9, label %block_.L_4ab6cd

block_4ab6a9:                                     ; preds = %block_.L_4ab69c
  %6908 = add i64 %6893, -32
  %6909 = add i64 %6907, 3
  store i64 %6909, i64* %3, align 8
  %6910 = inttoptr i64 %6908 to i32*
  %6911 = load i32, i32* %6910, align 4
  %6912 = zext i32 %6911 to i64
  store i64 %6912, i64* %RAX.i2610, align 8
  %6913 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %6914 = add i64 %6913, 13112
  store i64 %6914, i64* %RCX.i3977, align 8
  %6915 = icmp ugt i64 %6913, -13113
  %6916 = zext i1 %6915 to i8
  store i8 %6916, i8* %12, align 1
  %6917 = trunc i64 %6914 to i32
  %6918 = and i32 %6917, 255
  %6919 = tail call i32 @llvm.ctpop.i32(i32 %6918)
  %6920 = trunc i32 %6919 to i8
  %6921 = and i8 %6920, 1
  %6922 = xor i8 %6921, 1
  store i8 %6922, i8* %13, align 1
  %6923 = xor i64 %6913, 16
  %6924 = xor i64 %6923, %6914
  %6925 = lshr i64 %6924, 4
  %6926 = trunc i64 %6925 to i8
  %6927 = and i8 %6926, 1
  store i8 %6927, i8* %14, align 1
  %6928 = icmp eq i64 %6914, 0
  %6929 = zext i1 %6928 to i8
  store i8 %6929, i8* %15, align 1
  %6930 = lshr i64 %6914, 63
  %6931 = trunc i64 %6930 to i8
  store i8 %6931, i8* %16, align 1
  %6932 = lshr i64 %6913, 63
  %6933 = xor i64 %6930, %6932
  %6934 = add nuw nsw i64 %6933, %6930
  %6935 = icmp eq i64 %6934, 2
  %6936 = zext i1 %6935 to i8
  store i8 %6936, i8* %17, align 1
  %6937 = add i64 %6893, -24
  %6938 = add i64 %6907, 22
  store i64 %6938, i64* %3, align 8
  %6939 = inttoptr i64 %6937 to i32*
  %6940 = load i32, i32* %6939, align 4
  %6941 = sext i32 %6940 to i64
  %6942 = shl nsw i64 %6941, 6
  store i64 %6942, i64* %RDX.i4094, align 8
  %6943 = add i64 %6942, %6914
  store i64 %6943, i64* %RCX.i3977, align 8
  %6944 = icmp ult i64 %6943, %6914
  %6945 = icmp ult i64 %6943, %6942
  %6946 = or i1 %6944, %6945
  %6947 = zext i1 %6946 to i8
  store i8 %6947, i8* %12, align 1
  %6948 = trunc i64 %6943 to i32
  %6949 = and i32 %6948, 255
  %6950 = tail call i32 @llvm.ctpop.i32(i32 %6949)
  %6951 = trunc i32 %6950 to i8
  %6952 = and i8 %6951, 1
  %6953 = xor i8 %6952, 1
  store i8 %6953, i8* %13, align 1
  %6954 = xor i64 %6914, %6943
  %6955 = lshr i64 %6954, 4
  %6956 = trunc i64 %6955 to i8
  %6957 = and i8 %6956, 1
  store i8 %6957, i8* %14, align 1
  %6958 = icmp eq i64 %6943, 0
  %6959 = zext i1 %6958 to i8
  store i8 %6959, i8* %15, align 1
  %6960 = lshr i64 %6943, 63
  %6961 = trunc i64 %6960 to i8
  store i8 %6961, i8* %16, align 1
  %6962 = lshr i64 %6941, 57
  %6963 = and i64 %6962, 1
  %6964 = xor i64 %6960, %6930
  %6965 = xor i64 %6960, %6963
  %6966 = add nuw nsw i64 %6964, %6965
  %6967 = icmp eq i64 %6966, 2
  %6968 = zext i1 %6967 to i8
  store i8 %6968, i8* %17, align 1
  %6969 = load i64, i64* %RBP.i, align 8
  %6970 = add i64 %6969, -28
  %6971 = add i64 %6907, 33
  store i64 %6971, i64* %3, align 8
  %6972 = inttoptr i64 %6970 to i32*
  %6973 = load i32, i32* %6972, align 4
  %6974 = sext i32 %6973 to i64
  store i64 %6974, i64* %RDX.i4094, align 8
  %6975 = shl nsw i64 %6974, 2
  %6976 = add i64 %6975, %6943
  %6977 = load i32, i32* %EAX.i2609, align 4
  %6978 = add i64 %6907, 36
  store i64 %6978, i64* %3, align 8
  %6979 = inttoptr i64 %6976 to i32*
  store i32 %6977, i32* %6979, align 4
  %.pre199 = load i64, i64* %3, align 8
  %.pre200 = load i64, i64* %RBP.i, align 8
  br label %block_.L_4ab6cd

block_.L_4ab6cd:                                  ; preds = %block_.L_4ab69c, %block_4ab6a9
  %6980 = phi i64 [ %.pre200, %block_4ab6a9 ], [ %6893, %block_.L_4ab69c ]
  %6981 = phi i64 [ %.pre199, %block_4ab6a9 ], [ %6907, %block_.L_4ab69c ]
  %6982 = add i64 %6980, -36
  %6983 = add i64 %6981, 8
  store i64 %6983, i64* %3, align 8
  %6984 = inttoptr i64 %6982 to i32*
  %6985 = load i32, i32* %6984, align 4
  %6986 = add i32 %6985, 1
  %6987 = zext i32 %6986 to i64
  store i64 %6987, i64* %RAX.i2610, align 8
  %6988 = icmp eq i32 %6985, -1
  %6989 = icmp eq i32 %6986, 0
  %6990 = or i1 %6988, %6989
  %6991 = zext i1 %6990 to i8
  store i8 %6991, i8* %12, align 1
  %6992 = and i32 %6986, 255
  %6993 = tail call i32 @llvm.ctpop.i32(i32 %6992)
  %6994 = trunc i32 %6993 to i8
  %6995 = and i8 %6994, 1
  %6996 = xor i8 %6995, 1
  store i8 %6996, i8* %13, align 1
  %6997 = xor i32 %6986, %6985
  %6998 = lshr i32 %6997, 4
  %6999 = trunc i32 %6998 to i8
  %7000 = and i8 %6999, 1
  store i8 %7000, i8* %14, align 1
  %7001 = zext i1 %6989 to i8
  store i8 %7001, i8* %15, align 1
  %7002 = lshr i32 %6986, 31
  %7003 = trunc i32 %7002 to i8
  store i8 %7003, i8* %16, align 1
  %7004 = lshr i32 %6985, 31
  %7005 = xor i32 %7002, %7004
  %7006 = add nuw nsw i32 %7005, %7002
  %7007 = icmp eq i32 %7006, 2
  %7008 = zext i1 %7007 to i8
  store i8 %7008, i8* %17, align 1
  %7009 = add i64 %6981, 14
  store i64 %7009, i64* %3, align 8
  store i32 %6986, i32* %6984, align 4
  %7010 = load i64, i64* %3, align 8
  %7011 = add i64 %7010, -1493
  store i64 %7011, i64* %3, align 8
  br label %block_.L_4ab106

block_.L_4ab6e0:                                  ; preds = %block_.L_4ab106
  %7012 = add i64 %4566, -408
  %7013 = add i64 %4594, 7
  store i64 %7013, i64* %3, align 8
  %7014 = inttoptr i64 %7012 to i64*
  %7015 = load i64, i64* %7014, align 8
  store i64 %7015, i64* %RAX.i2610, align 8
  %7016 = add i64 %7015, 572
  %7017 = add i64 %4594, 14
  store i64 %7017, i64* %3, align 8
  %7018 = inttoptr i64 %7016 to i32*
  %7019 = load i32, i32* %7018, align 4
  store i8 0, i8* %12, align 1
  %7020 = and i32 %7019, 255
  %7021 = tail call i32 @llvm.ctpop.i32(i32 %7020)
  %7022 = trunc i32 %7021 to i8
  %7023 = and i8 %7022, 1
  %7024 = xor i8 %7023, 1
  store i8 %7024, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %7025 = icmp eq i32 %7019, 0
  %7026 = zext i1 %7025 to i8
  store i8 %7026, i8* %15, align 1
  %7027 = lshr i32 %7019, 31
  %7028 = trunc i32 %7027 to i8
  store i8 %7028, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v211 = select i1 %7025, i64 41, i64 20
  %7029 = add i64 %4594, %.v211
  store i64 %7029, i64* %3, align 8
  br i1 %7025, label %block_.L_4ab709, label %block_4ab6f4

block_4ab6f4:                                     ; preds = %block_.L_4ab6e0
  %7030 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %7030, i64* %RAX.i2610, align 8
  %7031 = add i64 %7030, 2356
  %7032 = add i64 %7029, 15
  store i64 %7032, i64* %3, align 8
  %7033 = inttoptr i64 %7031 to i32*
  %7034 = load i32, i32* %7033, align 4
  store i8 0, i8* %12, align 1
  %7035 = and i32 %7034, 255
  %7036 = tail call i32 @llvm.ctpop.i32(i32 %7035)
  %7037 = trunc i32 %7036 to i8
  %7038 = and i8 %7037, 1
  %7039 = xor i8 %7038, 1
  store i8 %7039, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %7040 = icmp eq i32 %7034, 0
  %7041 = zext i1 %7040 to i8
  store i8 %7041, i8* %15, align 1
  %7042 = lshr i32 %7034, 31
  %7043 = trunc i32 %7042 to i8
  store i8 %7043, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v212 = select i1 %7040, i64 41, i64 21
  %7044 = add i64 %7029, %.v212
  store i64 %7044, i64* %3, align 8
  br i1 %7040, label %block_.L_4ab71d, label %block_.L_4ab709

block_.L_4ab709:                                  ; preds = %block_4ab6f4, %block_.L_4ab6e0
  %7045 = phi i64 [ %7044, %block_4ab6f4 ], [ %7029, %block_.L_4ab6e0 ]
  %7046 = add i64 %4566, -96
  %7047 = add i64 %7045, 4
  store i64 %7047, i64* %3, align 8
  %7048 = inttoptr i64 %7046 to i64*
  %7049 = load i64, i64* %7048, align 8
  store i64 %7049, i64* %RAX.i2610, align 8
  %7050 = add i64 %4566, -48
  %7051 = add i64 %7045, 8
  store i64 %7051, i64* %3, align 8
  %7052 = inttoptr i64 %7050 to i32*
  %7053 = load i32, i32* %7052, align 4
  %7054 = sext i32 %7053 to i64
  store i64 %7054, i64* %RCX.i3977, align 8
  %7055 = shl nsw i64 %7054, 2
  %7056 = add i64 %7055, %7049
  %7057 = add i64 %7045, 15
  store i64 %7057, i64* %3, align 8
  %7058 = inttoptr i64 %7056 to i32*
  store i32 0, i32* %7058, align 4
  %7059 = load i64, i64* %3, align 8
  %7060 = add i64 %7059, 94
  %.pre178 = load i64, i64* %RBP.i, align 8
  br label %block_.L_4ab776

block_.L_4ab71d:                                  ; preds = %block_4ab6f4
  %7061 = add i64 %4566, -24
  %7062 = add i64 %7044, 7
  store i64 %7062, i64* %3, align 8
  %7063 = inttoptr i64 %7061 to i32*
  store i32 0, i32* %7063, align 4
  %.pre177 = load i64, i64* %3, align 8
  br label %block_.L_4ab724

block_.L_4ab724:                                  ; preds = %block_4ab72e, %block_.L_4ab71d
  %7064 = phi i64 [ %7165, %block_4ab72e ], [ %.pre177, %block_.L_4ab71d ]
  %7065 = load i64, i64* %RBP.i, align 8
  %7066 = add i64 %7065, -24
  %7067 = add i64 %7064, 4
  store i64 %7067, i64* %3, align 8
  %7068 = inttoptr i64 %7066 to i32*
  %7069 = load i32, i32* %7068, align 4
  %7070 = add i32 %7069, -4
  %7071 = icmp ult i32 %7069, 4
  %7072 = zext i1 %7071 to i8
  store i8 %7072, i8* %12, align 1
  %7073 = and i32 %7070, 255
  %7074 = tail call i32 @llvm.ctpop.i32(i32 %7073)
  %7075 = trunc i32 %7074 to i8
  %7076 = and i8 %7075, 1
  %7077 = xor i8 %7076, 1
  store i8 %7077, i8* %13, align 1
  %7078 = xor i32 %7070, %7069
  %7079 = lshr i32 %7078, 4
  %7080 = trunc i32 %7079 to i8
  %7081 = and i8 %7080, 1
  store i8 %7081, i8* %14, align 1
  %7082 = icmp eq i32 %7070, 0
  %7083 = zext i1 %7082 to i8
  store i8 %7083, i8* %15, align 1
  %7084 = lshr i32 %7070, 31
  %7085 = trunc i32 %7084 to i8
  store i8 %7085, i8* %16, align 1
  %7086 = lshr i32 %7069, 31
  %7087 = xor i32 %7084, %7086
  %7088 = add nuw nsw i32 %7087, %7086
  %7089 = icmp eq i32 %7088, 2
  %7090 = zext i1 %7089 to i8
  store i8 %7090, i8* %17, align 1
  %7091 = icmp ne i8 %7085, 0
  %7092 = xor i1 %7091, %7089
  %.v220 = select i1 %7092, i64 10, i64 77
  %7093 = add i64 %7064, %.v220
  store i64 %7093, i64* %3, align 8
  br i1 %7092, label %block_4ab72e, label %block_.L_4ab771

block_4ab72e:                                     ; preds = %block_.L_4ab724
  %7094 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7094, i64* %RAX.i2610, align 8
  %7095 = add i64 %7094, 14136
  %7096 = add i64 %7093, 15
  store i64 %7096, i64* %3, align 8
  %7097 = inttoptr i64 %7095 to i64*
  %7098 = load i64, i64* %7097, align 8
  store i64 %7098, i64* %RAX.i2610, align 8
  %7099 = add i64 %7065, -4
  %7100 = add i64 %7093, 19
  store i64 %7100, i64* %3, align 8
  %7101 = inttoptr i64 %7099 to i32*
  %7102 = load i32, i32* %7101, align 4
  %7103 = sext i32 %7102 to i64
  store i64 %7103, i64* %RCX.i3977, align 8
  %7104 = shl nsw i64 %7103, 3
  %7105 = add i64 %7104, %7098
  %7106 = add i64 %7093, 23
  store i64 %7106, i64* %3, align 8
  %7107 = inttoptr i64 %7105 to i64*
  %7108 = load i64, i64* %7107, align 8
  store i64 %7108, i64* %RAX.i2610, align 8
  %7109 = add i64 %7093, 27
  store i64 %7109, i64* %3, align 8
  %7110 = load i32, i32* %7068, align 4
  %7111 = sext i32 %7110 to i64
  store i64 %7111, i64* %RCX.i3977, align 8
  %7112 = shl nsw i64 %7111, 3
  %7113 = add i64 %7112, %7108
  %7114 = add i64 %7093, 31
  store i64 %7114, i64* %3, align 8
  %7115 = inttoptr i64 %7113 to i64*
  %7116 = load i64, i64* %7115, align 8
  store i64 %7116, i64* %RAX.i2610, align 8
  %7117 = add i64 %7093, 34
  store i64 %7117, i64* %3, align 8
  %7118 = inttoptr i64 %7116 to i64*
  %7119 = load i64, i64* %7118, align 8
  store i64 %7119, i64* %RAX.i2610, align 8
  %7120 = add i64 %7093, 38
  store i64 %7120, i64* %3, align 8
  %7121 = load i32, i32* %7068, align 4
  %7122 = sext i32 %7121 to i64
  store i64 %7122, i64* %RCX.i3977, align 8
  %7123 = shl nsw i64 %7122, 2
  %7124 = add i64 %7065, -384
  %7125 = add i64 %7124, %7123
  %7126 = add i64 %7093, 46
  store i64 %7126, i64* %3, align 8
  %7127 = inttoptr i64 %7125 to i32*
  %7128 = load i32, i32* %7127, align 4
  %7129 = sext i32 %7128 to i64
  store i64 %7129, i64* %RCX.i3977, align 8
  %7130 = shl nsw i64 %7129, 2
  %7131 = add i64 %7130, %7119
  %7132 = add i64 %7093, 53
  store i64 %7132, i64* %3, align 8
  %7133 = inttoptr i64 %7131 to i32*
  store i32 0, i32* %7133, align 4
  %7134 = load i64, i64* %RBP.i, align 8
  %7135 = add i64 %7134, -24
  %7136 = load i64, i64* %3, align 8
  %7137 = add i64 %7136, 3
  store i64 %7137, i64* %3, align 8
  %7138 = inttoptr i64 %7135 to i32*
  %7139 = load i32, i32* %7138, align 4
  %7140 = add i32 %7139, 1
  %7141 = zext i32 %7140 to i64
  store i64 %7141, i64* %RAX.i2610, align 8
  %7142 = icmp eq i32 %7139, -1
  %7143 = icmp eq i32 %7140, 0
  %7144 = or i1 %7142, %7143
  %7145 = zext i1 %7144 to i8
  store i8 %7145, i8* %12, align 1
  %7146 = and i32 %7140, 255
  %7147 = tail call i32 @llvm.ctpop.i32(i32 %7146)
  %7148 = trunc i32 %7147 to i8
  %7149 = and i8 %7148, 1
  %7150 = xor i8 %7149, 1
  store i8 %7150, i8* %13, align 1
  %7151 = xor i32 %7140, %7139
  %7152 = lshr i32 %7151, 4
  %7153 = trunc i32 %7152 to i8
  %7154 = and i8 %7153, 1
  store i8 %7154, i8* %14, align 1
  %7155 = zext i1 %7143 to i8
  store i8 %7155, i8* %15, align 1
  %7156 = lshr i32 %7140, 31
  %7157 = trunc i32 %7156 to i8
  store i8 %7157, i8* %16, align 1
  %7158 = lshr i32 %7139, 31
  %7159 = xor i32 %7156, %7158
  %7160 = add nuw nsw i32 %7159, %7156
  %7161 = icmp eq i32 %7160, 2
  %7162 = zext i1 %7161 to i8
  store i8 %7162, i8* %17, align 1
  %7163 = add i64 %7136, 9
  store i64 %7163, i64* %3, align 8
  store i32 %7140, i32* %7138, align 4
  %7164 = load i64, i64* %3, align 8
  %7165 = add i64 %7164, -72
  store i64 %7165, i64* %3, align 8
  br label %block_.L_4ab724

block_.L_4ab771:                                  ; preds = %block_.L_4ab724
  %7166 = add i64 %7093, 5
  store i64 %7166, i64* %3, align 8
  br label %block_.L_4ab776

block_.L_4ab776:                                  ; preds = %block_.L_4ab771, %block_.L_4ab709
  %7167 = phi i64 [ %.pre178, %block_.L_4ab709 ], [ %7065, %block_.L_4ab771 ]
  %storemerge63 = phi i64 [ %7060, %block_.L_4ab709 ], [ %7166, %block_.L_4ab771 ]
  %7168 = add i64 %7167, -24
  %7169 = add i64 %storemerge63, 7
  store i64 %7169, i64* %3, align 8
  %7170 = inttoptr i64 %7168 to i32*
  store i32 0, i32* %7170, align 4
  %.pre179 = load i64, i64* %3, align 8
  br label %block_.L_4ab77d

block_.L_4ab77d:                                  ; preds = %block_.L_4ab7b6, %block_.L_4ab776
  %7171 = phi i64 [ %8867, %block_.L_4ab7b6 ], [ %.pre179, %block_.L_4ab776 ]
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %CL.i3807, align 1
  %7172 = load i64, i64* %RBP.i, align 8
  %7173 = add i64 %7172, -24
  %7174 = add i64 %7171, 8
  store i64 %7174, i64* %3, align 8
  %7175 = inttoptr i64 %7173 to i32*
  %7176 = load i32, i32* %7175, align 4
  %7177 = add i32 %7176, -8
  %7178 = icmp ult i32 %7176, 8
  %7179 = zext i1 %7178 to i8
  store i8 %7179, i8* %12, align 1
  %7180 = and i32 %7177, 255
  %7181 = tail call i32 @llvm.ctpop.i32(i32 %7180)
  %7182 = trunc i32 %7181 to i8
  %7183 = and i8 %7182, 1
  %7184 = xor i8 %7183, 1
  store i8 %7184, i8* %13, align 1
  %7185 = xor i32 %7177, %7176
  %7186 = lshr i32 %7185, 4
  %7187 = trunc i32 %7186 to i8
  %7188 = and i8 %7187, 1
  store i8 %7188, i8* %14, align 1
  %7189 = icmp eq i32 %7177, 0
  %7190 = zext i1 %7189 to i8
  store i8 %7190, i8* %15, align 1
  %7191 = lshr i32 %7177, 31
  %7192 = trunc i32 %7191 to i8
  store i8 %7192, i8* %16, align 1
  %7193 = lshr i32 %7176, 31
  %7194 = xor i32 %7191, %7193
  %7195 = add nuw nsw i32 %7194, %7193
  %7196 = icmp eq i32 %7195, 2
  %7197 = zext i1 %7196 to i8
  store i8 %7197, i8* %17, align 1
  %7198 = add i64 %7172, -717
  %7199 = add i64 %7171, 14
  store i64 %7199, i64* %3, align 8
  %7200 = inttoptr i64 %7198 to i8*
  store i8 0, i8* %7200, align 1
  %7201 = load i64, i64* %3, align 8
  %7202 = add i64 %7201, 24
  %7203 = add i64 %7201, 6
  %7204 = load i8, i8* %16, align 1
  %7205 = icmp ne i8 %7204, 0
  %7206 = load i8, i8* %17, align 1
  %7207 = icmp ne i8 %7206, 0
  %7208 = xor i1 %7205, %7207
  %7209 = select i1 %7208, i64 %7203, i64 %7202
  store i64 %7209, i64* %3, align 8
  br i1 %7208, label %block_4ab791, label %block_.L_4ab7a3

block_4ab791:                                     ; preds = %block_.L_4ab77d
  %7210 = load i64, i64* %RBP.i, align 8
  %7211 = add i64 %7210, -412
  %7212 = add i64 %7209, 7
  store i64 %7212, i64* %3, align 8
  %7213 = inttoptr i64 %7211 to i32*
  %7214 = load i32, i32* %7213, align 4
  %7215 = icmp ne i32 %7214, 0
  %7216 = zext i1 %7215 to i64
  %7217 = xor i64 %7216, 255
  %7218 = trunc i64 %7217 to i8
  store i8 %7218, i8* %AL.i3806, align 1
  store i8 0, i8* %12, align 1
  %7219 = trunc i64 %7217 to i32
  %7220 = tail call i32 @llvm.ctpop.i32(i32 %7219)
  %7221 = trunc i32 %7220 to i8
  %7222 = and i8 %7221, 1
  %7223 = xor i8 %7222, 1
  store i8 %7223, i8* %13, align 1
  store i8 0, i8* %15, align 1
  store i8 1, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %7224 = add i64 %7210, -717
  %7225 = add i64 %7209, 18
  store i64 %7225, i64* %3, align 8
  %7226 = inttoptr i64 %7224 to i8*
  store i8 %7218, i8* %7226, align 1
  %.pre180 = load i64, i64* %3, align 8
  br label %block_.L_4ab7a3

block_.L_4ab7a3:                                  ; preds = %block_.L_4ab77d, %block_4ab791
  %7227 = phi i64 [ %7202, %block_.L_4ab77d ], [ %.pre180, %block_4ab791 ]
  %7228 = load i64, i64* %RBP.i, align 8
  %7229 = add i64 %7228, -717
  %7230 = add i64 %7227, 6
  store i64 %7230, i64* %3, align 8
  %7231 = inttoptr i64 %7229 to i8*
  %7232 = load i8, i8* %7231, align 1
  store i8 %7232, i8* %AL.i3806, align 1
  %7233 = and i8 %7232, 1
  store i8 0, i8* %12, align 1
  %7234 = zext i8 %7233 to i32
  %7235 = tail call i32 @llvm.ctpop.i32(i32 %7234)
  %7236 = trunc i32 %7235 to i8
  %7237 = xor i8 %7236, 1
  store i8 %7237, i8* %13, align 1
  %7238 = xor i8 %7233, 1
  store i8 %7238, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %7239 = icmp eq i8 %7238, 0
  %.v202 = select i1 %7239, i64 19, i64 14
  %7240 = add i64 %7227, %.v202
  store i64 %7240, i64* %3, align 8
  br i1 %7239, label %block_.L_4ab7b6, label %block_4ab7b1

block_4ab7b1:                                     ; preds = %block_.L_4ab7a3
  %7241 = add i64 %7228, -24
  %7242 = add i64 %7240, 910
  store i64 %7242, i64* %3, align 8
  %7243 = inttoptr i64 %7241 to i32*
  store i32 0, i32* %7243, align 4
  %.pre181 = load i64, i64* %3, align 8
  br label %block_.L_4abb3f

block_.L_4ab7b6:                                  ; preds = %block_.L_4ab7a3
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %7244 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7244, i64* %RCX.i3977, align 8
  %7245 = add i64 %7228, -24
  %7246 = add i64 %7240, 14
  store i64 %7246, i64* %3, align 8
  %7247 = inttoptr i64 %7245 to i32*
  %7248 = load i32, i32* %7247, align 4
  %7249 = sext i32 %7248 to i64
  store i64 %7249, i64* %RDX.i4094, align 8
  %7250 = shl nsw i64 %7249, 2
  %7251 = add i64 %7244, 13112
  %7252 = add i64 %7251, %7250
  %7253 = add i64 %7240, 21
  store i64 %7253, i64* %3, align 8
  %7254 = inttoptr i64 %7252 to i32*
  %7255 = load i32, i32* %7254, align 4
  %7256 = zext i32 %7255 to i64
  store i64 %7256, i64* %RSI.i3950, align 8
  store i64 %7244, i64* %RCX.i3977, align 8
  %7257 = add i64 %7240, 33
  store i64 %7257, i64* %3, align 8
  %7258 = load i32, i32* %7247, align 4
  %7259 = sext i32 %7258 to i64
  store i64 %7259, i64* %RDX.i4094, align 8
  %7260 = shl nsw i64 %7259, 2
  %7261 = add nsw i64 %7260, 13368
  %7262 = add i64 %7261, %7244
  %7263 = add i64 %7240, 40
  store i64 %7263, i64* %3, align 8
  %7264 = inttoptr i64 %7262 to i32*
  %7265 = load i32, i32* %7264, align 4
  %7266 = add i32 %7265, %7255
  %7267 = zext i32 %7266 to i64
  store i64 %7267, i64* %RSI.i3950, align 8
  %7268 = icmp ult i32 %7266, %7255
  %7269 = icmp ult i32 %7266, %7265
  %7270 = or i1 %7268, %7269
  %7271 = zext i1 %7270 to i8
  store i8 %7271, i8* %12, align 1
  %7272 = and i32 %7266, 255
  %7273 = tail call i32 @llvm.ctpop.i32(i32 %7272)
  %7274 = trunc i32 %7273 to i8
  %7275 = and i8 %7274, 1
  %7276 = xor i8 %7275, 1
  store i8 %7276, i8* %13, align 1
  %7277 = xor i32 %7265, %7255
  %7278 = xor i32 %7277, %7266
  %7279 = lshr i32 %7278, 4
  %7280 = trunc i32 %7279 to i8
  %7281 = and i8 %7280, 1
  store i8 %7281, i8* %14, align 1
  %7282 = icmp eq i32 %7266, 0
  %7283 = zext i1 %7282 to i8
  store i8 %7283, i8* %15, align 1
  %7284 = lshr i32 %7266, 31
  %7285 = trunc i32 %7284 to i8
  store i8 %7285, i8* %16, align 1
  %7286 = lshr i32 %7255, 31
  %7287 = lshr i32 %7265, 31
  %7288 = xor i32 %7284, %7286
  %7289 = xor i32 %7284, %7287
  %7290 = add nuw nsw i32 %7288, %7289
  %7291 = icmp eq i32 %7290, 2
  %7292 = zext i1 %7291 to i8
  store i8 %7292, i8* %17, align 1
  %7293 = add i64 %7228, -576
  %7294 = add i64 %7240, 46
  store i64 %7294, i64* %3, align 8
  %7295 = inttoptr i64 %7293 to i32*
  store i32 %7266, i32* %7295, align 4
  %7296 = load i64, i64* %3, align 8
  %7297 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7297, i64* %RCX.i3977, align 8
  %7298 = load i64, i64* %RBP.i, align 8
  %7299 = add i64 %7298, -24
  %7300 = add i64 %7296, 12
  store i64 %7300, i64* %3, align 8
  %7301 = inttoptr i64 %7299 to i32*
  %7302 = load i32, i32* %7301, align 4
  %7303 = sext i32 %7302 to i64
  store i64 %7303, i64* %RDX.i4094, align 8
  %7304 = shl nsw i64 %7303, 2
  %7305 = add i64 %7297, 13112
  %7306 = add i64 %7305, %7304
  %7307 = add i64 %7296, 19
  store i64 %7307, i64* %3, align 8
  %7308 = inttoptr i64 %7306 to i32*
  %7309 = load i32, i32* %7308, align 4
  %7310 = zext i32 %7309 to i64
  store i64 %7310, i64* %RSI.i3950, align 8
  store i64 %7297, i64* %RCX.i3977, align 8
  %7311 = add i64 %7296, 31
  store i64 %7311, i64* %3, align 8
  %7312 = load i32, i32* %7301, align 4
  %7313 = sext i32 %7312 to i64
  store i64 %7313, i64* %RDX.i4094, align 8
  %7314 = shl nsw i64 %7313, 2
  %7315 = add nsw i64 %7314, 13368
  %7316 = add i64 %7315, %7297
  %7317 = add i64 %7296, 38
  store i64 %7317, i64* %3, align 8
  %7318 = inttoptr i64 %7316 to i32*
  %7319 = load i32, i32* %7318, align 4
  %7320 = sub i32 %7309, %7319
  %7321 = zext i32 %7320 to i64
  store i64 %7321, i64* %RSI.i3950, align 8
  %7322 = icmp ult i32 %7309, %7319
  %7323 = zext i1 %7322 to i8
  store i8 %7323, i8* %12, align 1
  %7324 = and i32 %7320, 255
  %7325 = tail call i32 @llvm.ctpop.i32(i32 %7324)
  %7326 = trunc i32 %7325 to i8
  %7327 = and i8 %7326, 1
  %7328 = xor i8 %7327, 1
  store i8 %7328, i8* %13, align 1
  %7329 = xor i32 %7319, %7309
  %7330 = xor i32 %7329, %7320
  %7331 = lshr i32 %7330, 4
  %7332 = trunc i32 %7331 to i8
  %7333 = and i8 %7332, 1
  store i8 %7333, i8* %14, align 1
  %7334 = icmp eq i32 %7320, 0
  %7335 = zext i1 %7334 to i8
  store i8 %7335, i8* %15, align 1
  %7336 = lshr i32 %7320, 31
  %7337 = trunc i32 %7336 to i8
  store i8 %7337, i8* %16, align 1
  %7338 = lshr i32 %7309, 31
  %7339 = lshr i32 %7319, 31
  %7340 = xor i32 %7339, %7338
  %7341 = xor i32 %7336, %7338
  %7342 = add nuw nsw i32 %7341, %7340
  %7343 = icmp eq i32 %7342, 2
  %7344 = zext i1 %7343 to i8
  store i8 %7344, i8* %17, align 1
  %7345 = add i64 %7298, -560
  %7346 = add i64 %7296, 44
  store i64 %7346, i64* %3, align 8
  %7347 = inttoptr i64 %7345 to i32*
  store i32 %7320, i32* %7347, align 4
  %7348 = load i64, i64* %3, align 8
  %7349 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7349, i64* %RCX.i3977, align 8
  %7350 = load i64, i64* %RBP.i, align 8
  %7351 = add i64 %7350, -24
  %7352 = add i64 %7348, 12
  store i64 %7352, i64* %3, align 8
  %7353 = inttoptr i64 %7351 to i32*
  %7354 = load i32, i32* %7353, align 4
  %7355 = sext i32 %7354 to i64
  store i64 %7355, i64* %RDX.i4094, align 8
  %7356 = shl nsw i64 %7355, 2
  %7357 = add i64 %7349, 13240
  %7358 = add i64 %7357, %7356
  %7359 = add i64 %7348, 19
  store i64 %7359, i64* %3, align 8
  %7360 = inttoptr i64 %7358 to i32*
  %7361 = load i32, i32* %7360, align 4
  %7362 = zext i32 %7361 to i64
  %7363 = shl nuw i64 %7362, 32
  %7364 = ashr i64 %7363, 33
  %7365 = trunc i32 %7361 to i8
  %7366 = and i8 %7365, 1
  %7367 = trunc i64 %7364 to i32
  %7368 = and i64 %7364, 4294967295
  store i64 %7368, i64* %RSI.i3950, align 8
  store i8 %7366, i8* %12, align 1
  %7369 = and i32 %7367, 255
  %7370 = tail call i32 @llvm.ctpop.i32(i32 %7369)
  %7371 = trunc i32 %7370 to i8
  %7372 = and i8 %7371, 1
  %7373 = xor i8 %7372, 1
  store i8 %7373, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %7374 = icmp eq i32 %7367, 0
  %7375 = zext i1 %7374 to i8
  store i8 %7375, i8* %15, align 1
  %7376 = lshr i64 %7364, 31
  %7377 = trunc i64 %7376 to i8
  %7378 = and i8 %7377, 1
  store i8 %7378, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i64 %7349, i64* %RCX.i3977, align 8
  %7379 = add i64 %7348, 33
  store i64 %7379, i64* %3, align 8
  %7380 = load i32, i32* %7353, align 4
  %7381 = sext i32 %7380 to i64
  store i64 %7381, i64* %RDX.i4094, align 8
  %7382 = shl nsw i64 %7381, 2
  %7383 = add nsw i64 %7382, 13496
  %7384 = add i64 %7383, %7349
  %7385 = add i64 %7348, 40
  store i64 %7385, i64* %3, align 8
  %7386 = trunc i64 %7364 to i32
  %7387 = inttoptr i64 %7384 to i32*
  %7388 = load i32, i32* %7387, align 4
  %7389 = sub i32 %7386, %7388
  %7390 = zext i32 %7389 to i64
  store i64 %7390, i64* %RSI.i3950, align 8
  %7391 = icmp ult i32 %7386, %7388
  %7392 = zext i1 %7391 to i8
  store i8 %7392, i8* %12, align 1
  %7393 = and i32 %7389, 255
  %7394 = tail call i32 @llvm.ctpop.i32(i32 %7393)
  %7395 = trunc i32 %7394 to i8
  %7396 = and i8 %7395, 1
  %7397 = xor i8 %7396, 1
  store i8 %7397, i8* %13, align 1
  %7398 = xor i32 %7388, %7386
  %7399 = xor i32 %7398, %7389
  %7400 = lshr i32 %7399, 4
  %7401 = trunc i32 %7400 to i8
  %7402 = and i8 %7401, 1
  store i8 %7402, i8* %14, align 1
  %7403 = icmp eq i32 %7389, 0
  %7404 = zext i1 %7403 to i8
  store i8 %7404, i8* %15, align 1
  %7405 = lshr i32 %7389, 31
  %7406 = trunc i32 %7405 to i8
  store i8 %7406, i8* %16, align 1
  %7407 = lshr i64 %7364, 31
  %7408 = trunc i64 %7407 to i32
  %7409 = and i32 %7408, 1
  %7410 = lshr i32 %7388, 31
  %7411 = xor i32 %7410, %7409
  %7412 = xor i32 %7405, %7409
  %7413 = add nuw nsw i32 %7412, %7411
  %7414 = icmp eq i32 %7413, 2
  %7415 = zext i1 %7414 to i8
  store i8 %7415, i8* %17, align 1
  %7416 = add i64 %7350, -568
  %7417 = add i64 %7348, 46
  store i64 %7417, i64* %3, align 8
  %7418 = inttoptr i64 %7416 to i32*
  store i32 %7389, i32* %7418, align 4
  %7419 = load i64, i64* %3, align 8
  %7420 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7420, i64* %RCX.i3977, align 8
  %7421 = load i64, i64* %RBP.i, align 8
  %7422 = add i64 %7421, -24
  %7423 = add i64 %7419, 12
  store i64 %7423, i64* %3, align 8
  %7424 = inttoptr i64 %7422 to i32*
  %7425 = load i32, i32* %7424, align 4
  %7426 = sext i32 %7425 to i64
  store i64 %7426, i64* %RDX.i4094, align 8
  %7427 = shl nsw i64 %7426, 2
  %7428 = add i64 %7420, 13240
  %7429 = add i64 %7428, %7427
  %7430 = add i64 %7419, 19
  store i64 %7430, i64* %3, align 8
  %7431 = inttoptr i64 %7429 to i32*
  %7432 = load i32, i32* %7431, align 4
  %7433 = zext i32 %7432 to i64
  store i64 %7433, i64* %RSI.i3950, align 8
  store i64 %7420, i64* %RCX.i3977, align 8
  %7434 = add i64 %7419, 31
  store i64 %7434, i64* %3, align 8
  %7435 = load i32, i32* %7424, align 4
  %7436 = sext i32 %7435 to i64
  store i64 %7436, i64* %RDX.i4094, align 8
  %7437 = shl nsw i64 %7436, 2
  %7438 = add i64 %7420, 13496
  %7439 = add i64 %7438, %7437
  %7440 = add i64 %7419, 38
  store i64 %7440, i64* %3, align 8
  %7441 = inttoptr i64 %7439 to i32*
  %7442 = load i32, i32* %7441, align 4
  %7443 = zext i32 %7442 to i64
  %7444 = shl nuw i64 %7443, 32
  %7445 = ashr i64 %7444, 33
  %7446 = and i64 %7445, 4294967295
  store i64 %7446, i64* %RDI.i4084, align 8
  %7447 = trunc i64 %7445 to i32
  %7448 = add i32 %7447, %7432
  %7449 = zext i32 %7448 to i64
  store i64 %7449, i64* %RSI.i3950, align 8
  %7450 = icmp ult i32 %7448, %7432
  %7451 = icmp ult i32 %7448, %7447
  %7452 = or i1 %7450, %7451
  %7453 = zext i1 %7452 to i8
  store i8 %7453, i8* %12, align 1
  %7454 = and i32 %7448, 255
  %7455 = tail call i32 @llvm.ctpop.i32(i32 %7454)
  %7456 = trunc i32 %7455 to i8
  %7457 = and i8 %7456, 1
  %7458 = xor i8 %7457, 1
  store i8 %7458, i8* %13, align 1
  %7459 = xor i64 %7445, %7433
  %7460 = trunc i64 %7459 to i32
  %7461 = xor i32 %7460, %7448
  %7462 = lshr i32 %7461, 4
  %7463 = trunc i32 %7462 to i8
  %7464 = and i8 %7463, 1
  store i8 %7464, i8* %14, align 1
  %7465 = icmp eq i32 %7448, 0
  %7466 = zext i1 %7465 to i8
  store i8 %7466, i8* %15, align 1
  %7467 = lshr i32 %7448, 31
  %7468 = trunc i32 %7467 to i8
  store i8 %7468, i8* %16, align 1
  %7469 = lshr i32 %7432, 31
  %7470 = lshr i64 %7445, 31
  %7471 = trunc i64 %7470 to i32
  %7472 = and i32 %7471, 1
  %7473 = xor i32 %7467, %7469
  %7474 = xor i32 %7467, %7472
  %7475 = add nuw nsw i32 %7473, %7474
  %7476 = icmp eq i32 %7475, 2
  %7477 = zext i1 %7476 to i8
  store i8 %7477, i8* %17, align 1
  %7478 = add i64 %7421, -552
  %7479 = add i64 %7419, 48
  store i64 %7479, i64* %3, align 8
  %7480 = inttoptr i64 %7478 to i32*
  store i32 %7448, i32* %7480, align 4
  %7481 = load i64, i64* %RBP.i, align 8
  %7482 = add i64 %7481, -576
  %7483 = load i64, i64* %3, align 8
  %7484 = add i64 %7483, 6
  store i64 %7484, i64* %3, align 8
  %7485 = inttoptr i64 %7482 to i32*
  %7486 = load i32, i32* %7485, align 4
  %7487 = zext i32 %7486 to i64
  store i64 %7487, i64* %RSI.i3950, align 8
  %7488 = add i64 %7481, -552
  %7489 = add i64 %7483, 12
  store i64 %7489, i64* %3, align 8
  %7490 = inttoptr i64 %7488 to i32*
  %7491 = load i32, i32* %7490, align 4
  %7492 = add i32 %7491, %7486
  %7493 = zext i32 %7492 to i64
  store i64 %7493, i64* %RSI.i3950, align 8
  %7494 = icmp ult i32 %7492, %7486
  %7495 = icmp ult i32 %7492, %7491
  %7496 = or i1 %7494, %7495
  %7497 = zext i1 %7496 to i8
  store i8 %7497, i8* %12, align 1
  %7498 = and i32 %7492, 255
  %7499 = tail call i32 @llvm.ctpop.i32(i32 %7498)
  %7500 = trunc i32 %7499 to i8
  %7501 = and i8 %7500, 1
  %7502 = xor i8 %7501, 1
  store i8 %7502, i8* %13, align 1
  %7503 = xor i32 %7491, %7486
  %7504 = xor i32 %7503, %7492
  %7505 = lshr i32 %7504, 4
  %7506 = trunc i32 %7505 to i8
  %7507 = and i8 %7506, 1
  store i8 %7507, i8* %14, align 1
  %7508 = icmp eq i32 %7492, 0
  %7509 = zext i1 %7508 to i8
  store i8 %7509, i8* %15, align 1
  %7510 = lshr i32 %7492, 31
  %7511 = trunc i32 %7510 to i8
  store i8 %7511, i8* %16, align 1
  %7512 = lshr i32 %7486, 31
  %7513 = lshr i32 %7491, 31
  %7514 = xor i32 %7510, %7512
  %7515 = xor i32 %7510, %7513
  %7516 = add nuw nsw i32 %7514, %7515
  %7517 = icmp eq i32 %7516, 2
  %7518 = zext i1 %7517 to i8
  store i8 %7518, i8* %17, align 1
  %7519 = add i64 %7481, -608
  %7520 = add i64 %7483, 18
  store i64 %7520, i64* %3, align 8
  %7521 = inttoptr i64 %7519 to i32*
  store i32 %7492, i32* %7521, align 4
  %7522 = load i64, i64* %RBP.i, align 8
  %7523 = add i64 %7522, -560
  %7524 = load i64, i64* %3, align 8
  %7525 = add i64 %7524, 6
  store i64 %7525, i64* %3, align 8
  %7526 = inttoptr i64 %7523 to i32*
  %7527 = load i32, i32* %7526, align 4
  %7528 = zext i32 %7527 to i64
  store i64 %7528, i64* %RSI.i3950, align 8
  %7529 = add i64 %7522, -568
  %7530 = add i64 %7524, 12
  store i64 %7530, i64* %3, align 8
  %7531 = inttoptr i64 %7529 to i32*
  %7532 = load i32, i32* %7531, align 4
  %7533 = add i32 %7532, %7527
  %7534 = zext i32 %7533 to i64
  store i64 %7534, i64* %RSI.i3950, align 8
  %7535 = icmp ult i32 %7533, %7527
  %7536 = icmp ult i32 %7533, %7532
  %7537 = or i1 %7535, %7536
  %7538 = zext i1 %7537 to i8
  store i8 %7538, i8* %12, align 1
  %7539 = and i32 %7533, 255
  %7540 = tail call i32 @llvm.ctpop.i32(i32 %7539)
  %7541 = trunc i32 %7540 to i8
  %7542 = and i8 %7541, 1
  %7543 = xor i8 %7542, 1
  store i8 %7543, i8* %13, align 1
  %7544 = xor i32 %7532, %7527
  %7545 = xor i32 %7544, %7533
  %7546 = lshr i32 %7545, 4
  %7547 = trunc i32 %7546 to i8
  %7548 = and i8 %7547, 1
  store i8 %7548, i8* %14, align 1
  %7549 = icmp eq i32 %7533, 0
  %7550 = zext i1 %7549 to i8
  store i8 %7550, i8* %15, align 1
  %7551 = lshr i32 %7533, 31
  %7552 = trunc i32 %7551 to i8
  store i8 %7552, i8* %16, align 1
  %7553 = lshr i32 %7527, 31
  %7554 = lshr i32 %7532, 31
  %7555 = xor i32 %7551, %7553
  %7556 = xor i32 %7551, %7554
  %7557 = add nuw nsw i32 %7555, %7556
  %7558 = icmp eq i32 %7557, 2
  %7559 = zext i1 %7558 to i8
  store i8 %7559, i8* %17, align 1
  %7560 = add i64 %7522, -600
  %7561 = add i64 %7524, 18
  store i64 %7561, i64* %3, align 8
  %7562 = inttoptr i64 %7560 to i32*
  store i32 %7533, i32* %7562, align 4
  %7563 = load i64, i64* %RBP.i, align 8
  %7564 = add i64 %7563, -560
  %7565 = load i64, i64* %3, align 8
  %7566 = add i64 %7565, 6
  store i64 %7566, i64* %3, align 8
  %7567 = inttoptr i64 %7564 to i32*
  %7568 = load i32, i32* %7567, align 4
  %7569 = zext i32 %7568 to i64
  store i64 %7569, i64* %RSI.i3950, align 8
  %7570 = add i64 %7563, -568
  %7571 = add i64 %7565, 12
  store i64 %7571, i64* %3, align 8
  %7572 = inttoptr i64 %7570 to i32*
  %7573 = load i32, i32* %7572, align 4
  %7574 = sub i32 %7568, %7573
  %7575 = zext i32 %7574 to i64
  store i64 %7575, i64* %RSI.i3950, align 8
  %7576 = icmp ult i32 %7568, %7573
  %7577 = zext i1 %7576 to i8
  store i8 %7577, i8* %12, align 1
  %7578 = and i32 %7574, 255
  %7579 = tail call i32 @llvm.ctpop.i32(i32 %7578)
  %7580 = trunc i32 %7579 to i8
  %7581 = and i8 %7580, 1
  %7582 = xor i8 %7581, 1
  store i8 %7582, i8* %13, align 1
  %7583 = xor i32 %7573, %7568
  %7584 = xor i32 %7583, %7574
  %7585 = lshr i32 %7584, 4
  %7586 = trunc i32 %7585 to i8
  %7587 = and i8 %7586, 1
  store i8 %7587, i8* %14, align 1
  %7588 = icmp eq i32 %7574, 0
  %7589 = zext i1 %7588 to i8
  store i8 %7589, i8* %15, align 1
  %7590 = lshr i32 %7574, 31
  %7591 = trunc i32 %7590 to i8
  store i8 %7591, i8* %16, align 1
  %7592 = lshr i32 %7568, 31
  %7593 = lshr i32 %7573, 31
  %7594 = xor i32 %7593, %7592
  %7595 = xor i32 %7590, %7592
  %7596 = add nuw nsw i32 %7595, %7594
  %7597 = icmp eq i32 %7596, 2
  %7598 = zext i1 %7597 to i8
  store i8 %7598, i8* %17, align 1
  %7599 = add i64 %7563, -592
  %7600 = add i64 %7565, 18
  store i64 %7600, i64* %3, align 8
  %7601 = inttoptr i64 %7599 to i32*
  store i32 %7574, i32* %7601, align 4
  %7602 = load i64, i64* %RBP.i, align 8
  %7603 = add i64 %7602, -576
  %7604 = load i64, i64* %3, align 8
  %7605 = add i64 %7604, 6
  store i64 %7605, i64* %3, align 8
  %7606 = inttoptr i64 %7603 to i32*
  %7607 = load i32, i32* %7606, align 4
  %7608 = zext i32 %7607 to i64
  store i64 %7608, i64* %RSI.i3950, align 8
  %7609 = add i64 %7602, -552
  %7610 = add i64 %7604, 12
  store i64 %7610, i64* %3, align 8
  %7611 = inttoptr i64 %7609 to i32*
  %7612 = load i32, i32* %7611, align 4
  %7613 = sub i32 %7607, %7612
  %7614 = zext i32 %7613 to i64
  store i64 %7614, i64* %RSI.i3950, align 8
  %7615 = icmp ult i32 %7607, %7612
  %7616 = zext i1 %7615 to i8
  store i8 %7616, i8* %12, align 1
  %7617 = and i32 %7613, 255
  %7618 = tail call i32 @llvm.ctpop.i32(i32 %7617)
  %7619 = trunc i32 %7618 to i8
  %7620 = and i8 %7619, 1
  %7621 = xor i8 %7620, 1
  store i8 %7621, i8* %13, align 1
  %7622 = xor i32 %7612, %7607
  %7623 = xor i32 %7622, %7613
  %7624 = lshr i32 %7623, 4
  %7625 = trunc i32 %7624 to i8
  %7626 = and i8 %7625, 1
  store i8 %7626, i8* %14, align 1
  %7627 = icmp eq i32 %7613, 0
  %7628 = zext i1 %7627 to i8
  store i8 %7628, i8* %15, align 1
  %7629 = lshr i32 %7613, 31
  %7630 = trunc i32 %7629 to i8
  store i8 %7630, i8* %16, align 1
  %7631 = lshr i32 %7607, 31
  %7632 = lshr i32 %7612, 31
  %7633 = xor i32 %7632, %7631
  %7634 = xor i32 %7629, %7631
  %7635 = add nuw nsw i32 %7634, %7633
  %7636 = icmp eq i32 %7635, 2
  %7637 = zext i1 %7636 to i8
  store i8 %7637, i8* %17, align 1
  %7638 = add i64 %7602, -584
  %7639 = add i64 %7604, 18
  store i64 %7639, i64* %3, align 8
  %7640 = inttoptr i64 %7638 to i32*
  store i32 %7613, i32* %7640, align 4
  %7641 = load i64, i64* %3, align 8
  %7642 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7642, i64* %RCX.i3977, align 8
  %7643 = load i64, i64* %RBP.i, align 8
  %7644 = add i64 %7643, -24
  %7645 = add i64 %7641, 12
  store i64 %7645, i64* %3, align 8
  %7646 = inttoptr i64 %7644 to i32*
  %7647 = load i32, i32* %7646, align 4
  %7648 = sext i32 %7647 to i64
  store i64 %7648, i64* %RDX.i4094, align 8
  %7649 = load i32, i32* %EAX.i2609, align 4
  %7650 = zext i32 %7649 to i64
  store i64 %7650, i64* %RSI.i3950, align 8
  %7651 = shl nsw i64 %7648, 2
  %7652 = add i64 %7642, 13304
  %7653 = add i64 %7652, %7651
  %7654 = add i64 %7641, 21
  store i64 %7654, i64* %3, align 8
  %7655 = inttoptr i64 %7653 to i32*
  %7656 = load i32, i32* %7655, align 4
  %7657 = sub i32 %7649, %7656
  %7658 = zext i32 %7657 to i64
  store i64 %7658, i64* %RSI.i3950, align 8
  %7659 = icmp ult i32 %7649, %7656
  %7660 = zext i1 %7659 to i8
  store i8 %7660, i8* %12, align 1
  %7661 = and i32 %7657, 255
  %7662 = tail call i32 @llvm.ctpop.i32(i32 %7661)
  %7663 = trunc i32 %7662 to i8
  %7664 = and i8 %7663, 1
  %7665 = xor i8 %7664, 1
  store i8 %7665, i8* %13, align 1
  %7666 = xor i32 %7656, %7649
  %7667 = xor i32 %7666, %7657
  %7668 = lshr i32 %7667, 4
  %7669 = trunc i32 %7668 to i8
  %7670 = and i8 %7669, 1
  store i8 %7670, i8* %14, align 1
  %7671 = icmp eq i32 %7657, 0
  %7672 = zext i1 %7671 to i8
  store i8 %7672, i8* %15, align 1
  %7673 = lshr i32 %7657, 31
  %7674 = trunc i32 %7673 to i8
  store i8 %7674, i8* %16, align 1
  %7675 = lshr i32 %7649, 31
  %7676 = lshr i32 %7656, 31
  %7677 = xor i32 %7676, %7675
  %7678 = xor i32 %7673, %7675
  %7679 = add nuw nsw i32 %7678, %7677
  %7680 = icmp eq i32 %7679, 2
  %7681 = zext i1 %7680 to i8
  store i8 %7681, i8* %17, align 1
  store i64 %7642, i64* %RCX.i3977, align 8
  %7682 = add i64 %7641, 33
  store i64 %7682, i64* %3, align 8
  %7683 = load i32, i32* %7646, align 4
  %7684 = sext i32 %7683 to i64
  store i64 %7684, i64* %RDX.i4094, align 8
  %7685 = shl nsw i64 %7684, 2
  %7686 = add nsw i64 %7685, 13432
  %7687 = add i64 %7686, %7642
  %7688 = add i64 %7641, 40
  store i64 %7688, i64* %3, align 8
  %7689 = inttoptr i64 %7687 to i32*
  %7690 = load i32, i32* %7689, align 4
  %7691 = add i32 %7690, %7657
  %7692 = zext i32 %7691 to i64
  store i64 %7692, i64* %RSI.i3950, align 8
  %7693 = icmp ult i32 %7691, %7657
  %7694 = icmp ult i32 %7691, %7690
  %7695 = or i1 %7693, %7694
  %7696 = zext i1 %7695 to i8
  store i8 %7696, i8* %12, align 1
  %7697 = and i32 %7691, 255
  %7698 = tail call i32 @llvm.ctpop.i32(i32 %7697)
  %7699 = trunc i32 %7698 to i8
  %7700 = and i8 %7699, 1
  %7701 = xor i8 %7700, 1
  store i8 %7701, i8* %13, align 1
  %7702 = xor i32 %7690, %7657
  %7703 = xor i32 %7702, %7691
  %7704 = lshr i32 %7703, 4
  %7705 = trunc i32 %7704 to i8
  %7706 = and i8 %7705, 1
  store i8 %7706, i8* %14, align 1
  %7707 = icmp eq i32 %7691, 0
  %7708 = zext i1 %7707 to i8
  store i8 %7708, i8* %15, align 1
  %7709 = lshr i32 %7691, 31
  %7710 = trunc i32 %7709 to i8
  store i8 %7710, i8* %16, align 1
  %7711 = lshr i32 %7690, 31
  %7712 = xor i32 %7709, %7673
  %7713 = xor i32 %7709, %7711
  %7714 = add nuw nsw i32 %7712, %7713
  %7715 = icmp eq i32 %7714, 2
  %7716 = zext i1 %7715 to i8
  store i8 %7716, i8* %17, align 1
  %7717 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7717, i64* %RCX.i3977, align 8
  %7718 = load i64, i64* %RBP.i, align 8
  %7719 = add i64 %7718, -24
  %7720 = add i64 %7641, 52
  store i64 %7720, i64* %3, align 8
  %7721 = inttoptr i64 %7719 to i32*
  %7722 = load i32, i32* %7721, align 4
  %7723 = sext i32 %7722 to i64
  store i64 %7723, i64* %RDX.i4094, align 8
  %7724 = shl nsw i64 %7723, 2
  %7725 = add nsw i64 %7724, 13560
  %7726 = add i64 %7725, %7717
  %7727 = add i64 %7641, 59
  store i64 %7727, i64* %3, align 8
  %7728 = inttoptr i64 %7726 to i32*
  %7729 = load i32, i32* %7728, align 4
  %7730 = sub i32 %7691, %7729
  %7731 = zext i32 %7730 to i64
  store i64 %7731, i64* %RSI.i3950, align 8
  %7732 = icmp ult i32 %7691, %7729
  %7733 = zext i1 %7732 to i8
  store i8 %7733, i8* %12, align 1
  %7734 = and i32 %7730, 255
  %7735 = tail call i32 @llvm.ctpop.i32(i32 %7734)
  %7736 = trunc i32 %7735 to i8
  %7737 = and i8 %7736, 1
  %7738 = xor i8 %7737, 1
  store i8 %7738, i8* %13, align 1
  %7739 = xor i32 %7729, %7691
  %7740 = xor i32 %7739, %7730
  %7741 = lshr i32 %7740, 4
  %7742 = trunc i32 %7741 to i8
  %7743 = and i8 %7742, 1
  store i8 %7743, i8* %14, align 1
  %7744 = icmp eq i32 %7730, 0
  %7745 = zext i1 %7744 to i8
  store i8 %7745, i8* %15, align 1
  %7746 = lshr i32 %7730, 31
  %7747 = trunc i32 %7746 to i8
  store i8 %7747, i8* %16, align 1
  %7748 = lshr i32 %7729, 31
  %7749 = xor i32 %7748, %7709
  %7750 = xor i32 %7746, %7709
  %7751 = add nuw nsw i32 %7750, %7749
  %7752 = icmp eq i32 %7751, 2
  %7753 = zext i1 %7752 to i8
  store i8 %7753, i8* %17, align 1
  store i64 %7717, i64* %RCX.i3977, align 8
  %7754 = add i64 %7641, 71
  store i64 %7754, i64* %3, align 8
  %7755 = load i32, i32* %7721, align 4
  %7756 = sext i32 %7755 to i64
  store i64 %7756, i64* %RDX.i4094, align 8
  %7757 = shl nsw i64 %7756, 2
  %7758 = add i64 %7717, 13560
  %7759 = add i64 %7758, %7757
  %7760 = add i64 %7641, 78
  store i64 %7760, i64* %3, align 8
  %7761 = inttoptr i64 %7759 to i32*
  %7762 = load i32, i32* %7761, align 4
  %7763 = zext i32 %7762 to i64
  %7764 = shl nuw i64 %7763, 32
  %7765 = ashr i64 %7764, 33
  %7766 = and i64 %7765, 4294967295
  store i64 %7766, i64* %RDI.i4084, align 8
  %7767 = trunc i64 %7765 to i32
  %7768 = sub i32 %7730, %7767
  %7769 = zext i32 %7768 to i64
  store i64 %7769, i64* %RSI.i3950, align 8
  %7770 = icmp ult i32 %7730, %7767
  %7771 = zext i1 %7770 to i8
  store i8 %7771, i8* %12, align 1
  %7772 = and i32 %7768, 255
  %7773 = tail call i32 @llvm.ctpop.i32(i32 %7772)
  %7774 = trunc i32 %7773 to i8
  %7775 = and i8 %7774, 1
  %7776 = xor i8 %7775, 1
  store i8 %7776, i8* %13, align 1
  %7777 = xor i64 %7765, %7731
  %7778 = trunc i64 %7777 to i32
  %7779 = xor i32 %7778, %7768
  %7780 = lshr i32 %7779, 4
  %7781 = trunc i32 %7780 to i8
  %7782 = and i8 %7781, 1
  store i8 %7782, i8* %14, align 1
  %7783 = icmp eq i32 %7768, 0
  %7784 = zext i1 %7783 to i8
  store i8 %7784, i8* %15, align 1
  %7785 = lshr i32 %7768, 31
  %7786 = trunc i32 %7785 to i8
  store i8 %7786, i8* %16, align 1
  %7787 = lshr i64 %7765, 31
  %7788 = trunc i64 %7787 to i32
  %7789 = and i32 %7788, 1
  %7790 = xor i32 %7789, %7746
  %7791 = xor i32 %7785, %7746
  %7792 = add nuw nsw i32 %7791, %7790
  %7793 = icmp eq i32 %7792, 2
  %7794 = zext i1 %7793 to i8
  store i8 %7794, i8* %17, align 1
  %7795 = load i64, i64* %RBP.i, align 8
  %7796 = add i64 %7795, -572
  %7797 = add i64 %7641, 88
  store i64 %7797, i64* %3, align 8
  %7798 = inttoptr i64 %7796 to i32*
  store i32 %7768, i32* %7798, align 4
  %7799 = load i64, i64* %3, align 8
  %7800 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7800, i64* %RCX.i3977, align 8
  %7801 = load i64, i64* %RBP.i, align 8
  %7802 = add i64 %7801, -24
  %7803 = add i64 %7799, 12
  store i64 %7803, i64* %3, align 8
  %7804 = inttoptr i64 %7802 to i32*
  %7805 = load i32, i32* %7804, align 4
  %7806 = sext i32 %7805 to i64
  store i64 %7806, i64* %RDX.i4094, align 8
  %7807 = shl nsw i64 %7806, 2
  %7808 = add i64 %7800, 13176
  %7809 = add i64 %7808, %7807
  %7810 = add i64 %7799, 19
  store i64 %7810, i64* %3, align 8
  %7811 = inttoptr i64 %7809 to i32*
  %7812 = load i32, i32* %7811, align 4
  %7813 = zext i32 %7812 to i64
  store i64 %7813, i64* %RSI.i3950, align 8
  store i64 %7800, i64* %RCX.i3977, align 8
  %7814 = add i64 %7799, 31
  store i64 %7814, i64* %3, align 8
  %7815 = load i32, i32* %7804, align 4
  %7816 = sext i32 %7815 to i64
  store i64 %7816, i64* %RDX.i4094, align 8
  %7817 = shl nsw i64 %7816, 2
  %7818 = add nsw i64 %7817, 13560
  %7819 = add i64 %7818, %7800
  %7820 = add i64 %7799, 38
  store i64 %7820, i64* %3, align 8
  %7821 = inttoptr i64 %7819 to i32*
  %7822 = load i32, i32* %7821, align 4
  %7823 = add i32 %7822, %7812
  %7824 = zext i32 %7823 to i64
  store i64 %7824, i64* %RSI.i3950, align 8
  %7825 = icmp ult i32 %7823, %7812
  %7826 = icmp ult i32 %7823, %7822
  %7827 = or i1 %7825, %7826
  %7828 = zext i1 %7827 to i8
  store i8 %7828, i8* %12, align 1
  %7829 = and i32 %7823, 255
  %7830 = tail call i32 @llvm.ctpop.i32(i32 %7829)
  %7831 = trunc i32 %7830 to i8
  %7832 = and i8 %7831, 1
  %7833 = xor i8 %7832, 1
  store i8 %7833, i8* %13, align 1
  %7834 = xor i32 %7822, %7812
  %7835 = xor i32 %7834, %7823
  %7836 = lshr i32 %7835, 4
  %7837 = trunc i32 %7836 to i8
  %7838 = and i8 %7837, 1
  store i8 %7838, i8* %14, align 1
  %7839 = icmp eq i32 %7823, 0
  %7840 = zext i1 %7839 to i8
  store i8 %7840, i8* %15, align 1
  %7841 = lshr i32 %7823, 31
  %7842 = trunc i32 %7841 to i8
  store i8 %7842, i8* %16, align 1
  %7843 = lshr i32 %7812, 31
  %7844 = lshr i32 %7822, 31
  %7845 = xor i32 %7841, %7843
  %7846 = xor i32 %7841, %7844
  %7847 = add nuw nsw i32 %7845, %7846
  %7848 = icmp eq i32 %7847, 2
  %7849 = zext i1 %7848 to i8
  store i8 %7849, i8* %17, align 1
  store i64 %7800, i64* %RCX.i3977, align 8
  %7850 = add i64 %7799, 50
  store i64 %7850, i64* %3, align 8
  %7851 = load i32, i32* %7804, align 4
  %7852 = sext i32 %7851 to i64
  store i64 %7852, i64* %RDX.i4094, align 8
  %7853 = shl nsw i64 %7852, 2
  %7854 = add nsw i64 %7853, 13304
  %7855 = add i64 %7854, %7800
  %7856 = add i64 %7799, 57
  store i64 %7856, i64* %3, align 8
  %7857 = inttoptr i64 %7855 to i32*
  %7858 = load i32, i32* %7857, align 4
  %7859 = sub i32 %7823, %7858
  %7860 = zext i32 %7859 to i64
  store i64 %7860, i64* %RSI.i3950, align 8
  %7861 = icmp ult i32 %7823, %7858
  %7862 = zext i1 %7861 to i8
  store i8 %7862, i8* %12, align 1
  %7863 = and i32 %7859, 255
  %7864 = tail call i32 @llvm.ctpop.i32(i32 %7863)
  %7865 = trunc i32 %7864 to i8
  %7866 = and i8 %7865, 1
  %7867 = xor i8 %7866, 1
  store i8 %7867, i8* %13, align 1
  %7868 = xor i32 %7858, %7823
  %7869 = xor i32 %7868, %7859
  %7870 = lshr i32 %7869, 4
  %7871 = trunc i32 %7870 to i8
  %7872 = and i8 %7871, 1
  store i8 %7872, i8* %14, align 1
  %7873 = icmp eq i32 %7859, 0
  %7874 = zext i1 %7873 to i8
  store i8 %7874, i8* %15, align 1
  %7875 = lshr i32 %7859, 31
  %7876 = trunc i32 %7875 to i8
  store i8 %7876, i8* %16, align 1
  %7877 = lshr i32 %7858, 31
  %7878 = xor i32 %7877, %7841
  %7879 = xor i32 %7875, %7841
  %7880 = add nuw nsw i32 %7879, %7878
  %7881 = icmp eq i32 %7880, 2
  %7882 = zext i1 %7881 to i8
  store i8 %7882, i8* %17, align 1
  %7883 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7883, i64* %RCX.i3977, align 8
  %7884 = load i64, i64* %RBP.i, align 8
  %7885 = add i64 %7884, -24
  %7886 = add i64 %7799, 69
  store i64 %7886, i64* %3, align 8
  %7887 = inttoptr i64 %7885 to i32*
  %7888 = load i32, i32* %7887, align 4
  %7889 = sext i32 %7888 to i64
  store i64 %7889, i64* %RDX.i4094, align 8
  %7890 = shl nsw i64 %7889, 2
  %7891 = add i64 %7883, 13304
  %7892 = add i64 %7891, %7890
  %7893 = add i64 %7799, 76
  store i64 %7893, i64* %3, align 8
  %7894 = inttoptr i64 %7892 to i32*
  %7895 = load i32, i32* %7894, align 4
  %7896 = zext i32 %7895 to i64
  %7897 = shl nuw i64 %7896, 32
  %7898 = ashr i64 %7897, 33
  %7899 = and i64 %7898, 4294967295
  store i64 %7899, i64* %RDI.i4084, align 8
  %7900 = trunc i64 %7898 to i32
  %7901 = sub i32 %7859, %7900
  %7902 = zext i32 %7901 to i64
  store i64 %7902, i64* %RSI.i3950, align 8
  %7903 = icmp ult i32 %7859, %7900
  %7904 = zext i1 %7903 to i8
  store i8 %7904, i8* %12, align 1
  %7905 = and i32 %7901, 255
  %7906 = tail call i32 @llvm.ctpop.i32(i32 %7905)
  %7907 = trunc i32 %7906 to i8
  %7908 = and i8 %7907, 1
  %7909 = xor i8 %7908, 1
  store i8 %7909, i8* %13, align 1
  %7910 = xor i64 %7898, %7860
  %7911 = trunc i64 %7910 to i32
  %7912 = xor i32 %7911, %7901
  %7913 = lshr i32 %7912, 4
  %7914 = trunc i32 %7913 to i8
  %7915 = and i8 %7914, 1
  store i8 %7915, i8* %14, align 1
  %7916 = icmp eq i32 %7901, 0
  %7917 = zext i1 %7916 to i8
  store i8 %7917, i8* %15, align 1
  %7918 = lshr i32 %7901, 31
  %7919 = trunc i32 %7918 to i8
  store i8 %7919, i8* %16, align 1
  %7920 = lshr i64 %7898, 31
  %7921 = trunc i64 %7920 to i32
  %7922 = and i32 %7921, 1
  %7923 = xor i32 %7922, %7875
  %7924 = xor i32 %7918, %7875
  %7925 = add nuw nsw i32 %7924, %7923
  %7926 = icmp eq i32 %7925, 2
  %7927 = zext i1 %7926 to i8
  store i8 %7927, i8* %17, align 1
  %7928 = add i64 %7884, -564
  %7929 = add i64 %7799, 86
  store i64 %7929, i64* %3, align 8
  %7930 = inttoptr i64 %7928 to i32*
  store i32 %7901, i32* %7930, align 4
  %7931 = load i64, i64* %3, align 8
  %7932 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7932, i64* %RCX.i3977, align 8
  %7933 = load i64, i64* %RBP.i, align 8
  %7934 = add i64 %7933, -24
  %7935 = add i64 %7931, 12
  store i64 %7935, i64* %3, align 8
  %7936 = inttoptr i64 %7934 to i32*
  %7937 = load i32, i32* %7936, align 4
  %7938 = sext i32 %7937 to i64
  store i64 %7938, i64* %RDX.i4094, align 8
  %7939 = load i32, i32* %EAX.i2609, align 4
  %7940 = zext i32 %7939 to i64
  store i64 %7940, i64* %RSI.i3950, align 8
  %7941 = shl nsw i64 %7938, 2
  %7942 = add i64 %7932, 13176
  %7943 = add i64 %7942, %7941
  %7944 = add i64 %7931, 21
  store i64 %7944, i64* %3, align 8
  %7945 = inttoptr i64 %7943 to i32*
  %7946 = load i32, i32* %7945, align 4
  %7947 = sub i32 %7939, %7946
  %7948 = zext i32 %7947 to i64
  store i64 %7948, i64* %RSI.i3950, align 8
  %7949 = icmp ult i32 %7939, %7946
  %7950 = zext i1 %7949 to i8
  store i8 %7950, i8* %12, align 1
  %7951 = and i32 %7947, 255
  %7952 = tail call i32 @llvm.ctpop.i32(i32 %7951)
  %7953 = trunc i32 %7952 to i8
  %7954 = and i8 %7953, 1
  %7955 = xor i8 %7954, 1
  store i8 %7955, i8* %13, align 1
  %7956 = xor i32 %7946, %7939
  %7957 = xor i32 %7956, %7947
  %7958 = lshr i32 %7957, 4
  %7959 = trunc i32 %7958 to i8
  %7960 = and i8 %7959, 1
  store i8 %7960, i8* %14, align 1
  %7961 = icmp eq i32 %7947, 0
  %7962 = zext i1 %7961 to i8
  store i8 %7962, i8* %15, align 1
  %7963 = lshr i32 %7947, 31
  %7964 = trunc i32 %7963 to i8
  store i8 %7964, i8* %16, align 1
  %7965 = lshr i32 %7939, 31
  %7966 = lshr i32 %7946, 31
  %7967 = xor i32 %7966, %7965
  %7968 = xor i32 %7963, %7965
  %7969 = add nuw nsw i32 %7968, %7967
  %7970 = icmp eq i32 %7969, 2
  %7971 = zext i1 %7970 to i8
  store i8 %7971, i8* %17, align 1
  store i64 %7932, i64* %RCX.i3977, align 8
  %7972 = add i64 %7931, 33
  store i64 %7972, i64* %3, align 8
  %7973 = load i32, i32* %7936, align 4
  %7974 = sext i32 %7973 to i64
  store i64 %7974, i64* %RDX.i4094, align 8
  %7975 = shl nsw i64 %7974, 2
  %7976 = add nsw i64 %7975, 13560
  %7977 = add i64 %7976, %7932
  %7978 = add i64 %7931, 40
  store i64 %7978, i64* %3, align 8
  %7979 = inttoptr i64 %7977 to i32*
  %7980 = load i32, i32* %7979, align 4
  %7981 = add i32 %7980, %7947
  %7982 = zext i32 %7981 to i64
  store i64 %7982, i64* %RSI.i3950, align 8
  %7983 = icmp ult i32 %7981, %7947
  %7984 = icmp ult i32 %7981, %7980
  %7985 = or i1 %7983, %7984
  %7986 = zext i1 %7985 to i8
  store i8 %7986, i8* %12, align 1
  %7987 = and i32 %7981, 255
  %7988 = tail call i32 @llvm.ctpop.i32(i32 %7987)
  %7989 = trunc i32 %7988 to i8
  %7990 = and i8 %7989, 1
  %7991 = xor i8 %7990, 1
  store i8 %7991, i8* %13, align 1
  %7992 = xor i32 %7980, %7947
  %7993 = xor i32 %7992, %7981
  %7994 = lshr i32 %7993, 4
  %7995 = trunc i32 %7994 to i8
  %7996 = and i8 %7995, 1
  store i8 %7996, i8* %14, align 1
  %7997 = icmp eq i32 %7981, 0
  %7998 = zext i1 %7997 to i8
  store i8 %7998, i8* %15, align 1
  %7999 = lshr i32 %7981, 31
  %8000 = trunc i32 %7999 to i8
  store i8 %8000, i8* %16, align 1
  %8001 = lshr i32 %7980, 31
  %8002 = xor i32 %7999, %7963
  %8003 = xor i32 %7999, %8001
  %8004 = add nuw nsw i32 %8002, %8003
  %8005 = icmp eq i32 %8004, 2
  %8006 = zext i1 %8005 to i8
  store i8 %8006, i8* %17, align 1
  %8007 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8007, i64* %RCX.i3977, align 8
  %8008 = load i64, i64* %RBP.i, align 8
  %8009 = add i64 %8008, -24
  %8010 = add i64 %7931, 52
  store i64 %8010, i64* %3, align 8
  %8011 = inttoptr i64 %8009 to i32*
  %8012 = load i32, i32* %8011, align 4
  %8013 = sext i32 %8012 to i64
  store i64 %8013, i64* %RDX.i4094, align 8
  %8014 = shl nsw i64 %8013, 2
  %8015 = add nsw i64 %8014, 13432
  %8016 = add i64 %8015, %8007
  %8017 = add i64 %7931, 59
  store i64 %8017, i64* %3, align 8
  %8018 = inttoptr i64 %8016 to i32*
  %8019 = load i32, i32* %8018, align 4
  %8020 = add i32 %8019, %7981
  %8021 = zext i32 %8020 to i64
  store i64 %8021, i64* %RSI.i3950, align 8
  %8022 = icmp ult i32 %8020, %7981
  %8023 = icmp ult i32 %8020, %8019
  %8024 = or i1 %8022, %8023
  %8025 = zext i1 %8024 to i8
  store i8 %8025, i8* %12, align 1
  %8026 = and i32 %8020, 255
  %8027 = tail call i32 @llvm.ctpop.i32(i32 %8026)
  %8028 = trunc i32 %8027 to i8
  %8029 = and i8 %8028, 1
  %8030 = xor i8 %8029, 1
  store i8 %8030, i8* %13, align 1
  %8031 = xor i32 %8019, %7981
  %8032 = xor i32 %8031, %8020
  %8033 = lshr i32 %8032, 4
  %8034 = trunc i32 %8033 to i8
  %8035 = and i8 %8034, 1
  store i8 %8035, i8* %14, align 1
  %8036 = icmp eq i32 %8020, 0
  %8037 = zext i1 %8036 to i8
  store i8 %8037, i8* %15, align 1
  %8038 = lshr i32 %8020, 31
  %8039 = trunc i32 %8038 to i8
  store i8 %8039, i8* %16, align 1
  %8040 = lshr i32 %8019, 31
  %8041 = xor i32 %8038, %7999
  %8042 = xor i32 %8038, %8040
  %8043 = add nuw nsw i32 %8041, %8042
  %8044 = icmp eq i32 %8043, 2
  %8045 = zext i1 %8044 to i8
  store i8 %8045, i8* %17, align 1
  store i64 %8007, i64* %RCX.i3977, align 8
  %8046 = add i64 %7931, 71
  store i64 %8046, i64* %3, align 8
  %8047 = load i32, i32* %8011, align 4
  %8048 = sext i32 %8047 to i64
  store i64 %8048, i64* %RDX.i4094, align 8
  %8049 = shl nsw i64 %8048, 2
  %8050 = add i64 %8007, 13432
  %8051 = add i64 %8050, %8049
  %8052 = add i64 %7931, 78
  store i64 %8052, i64* %3, align 8
  %8053 = inttoptr i64 %8051 to i32*
  %8054 = load i32, i32* %8053, align 4
  %8055 = zext i32 %8054 to i64
  %8056 = shl nuw i64 %8055, 32
  %8057 = ashr i64 %8056, 33
  %8058 = and i64 %8057, 4294967295
  store i64 %8058, i64* %RDI.i4084, align 8
  %8059 = trunc i64 %8057 to i32
  %8060 = add i32 %8059, %8020
  %8061 = zext i32 %8060 to i64
  store i64 %8061, i64* %RSI.i3950, align 8
  %8062 = icmp ult i32 %8060, %8020
  %8063 = icmp ult i32 %8060, %8059
  %8064 = or i1 %8062, %8063
  %8065 = zext i1 %8064 to i8
  store i8 %8065, i8* %12, align 1
  %8066 = and i32 %8060, 255
  %8067 = tail call i32 @llvm.ctpop.i32(i32 %8066)
  %8068 = trunc i32 %8067 to i8
  %8069 = and i8 %8068, 1
  %8070 = xor i8 %8069, 1
  store i8 %8070, i8* %13, align 1
  %8071 = xor i64 %8057, %8021
  %8072 = trunc i64 %8071 to i32
  %8073 = xor i32 %8072, %8060
  %8074 = lshr i32 %8073, 4
  %8075 = trunc i32 %8074 to i8
  %8076 = and i8 %8075, 1
  store i8 %8076, i8* %14, align 1
  %8077 = icmp eq i32 %8060, 0
  %8078 = zext i1 %8077 to i8
  store i8 %8078, i8* %15, align 1
  %8079 = lshr i32 %8060, 31
  %8080 = trunc i32 %8079 to i8
  store i8 %8080, i8* %16, align 1
  %8081 = lshr i64 %8057, 31
  %8082 = trunc i64 %8081 to i32
  %8083 = and i32 %8082, 1
  %8084 = xor i32 %8079, %8038
  %8085 = xor i32 %8079, %8083
  %8086 = add nuw nsw i32 %8084, %8085
  %8087 = icmp eq i32 %8086, 2
  %8088 = zext i1 %8087 to i8
  store i8 %8088, i8* %17, align 1
  %8089 = load i64, i64* %RBP.i, align 8
  %8090 = add i64 %8089, -556
  %8091 = add i64 %7931, 88
  store i64 %8091, i64* %3, align 8
  %8092 = inttoptr i64 %8090 to i32*
  store i32 %8060, i32* %8092, align 4
  %8093 = load i64, i64* %3, align 8
  %8094 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8094, i64* %RCX.i3977, align 8
  %8095 = load i64, i64* %RBP.i, align 8
  %8096 = add i64 %8095, -24
  %8097 = add i64 %8093, 12
  store i64 %8097, i64* %3, align 8
  %8098 = inttoptr i64 %8096 to i32*
  %8099 = load i32, i32* %8098, align 4
  %8100 = sext i32 %8099 to i64
  store i64 %8100, i64* %RDX.i4094, align 8
  %8101 = shl nsw i64 %8100, 2
  %8102 = add i64 %8094, 13304
  %8103 = add i64 %8102, %8101
  %8104 = add i64 %8093, 19
  store i64 %8104, i64* %3, align 8
  %8105 = inttoptr i64 %8103 to i32*
  %8106 = load i32, i32* %8105, align 4
  %8107 = zext i32 %8106 to i64
  store i64 %8107, i64* %RSI.i3950, align 8
  store i64 %8094, i64* %RCX.i3977, align 8
  %8108 = add i64 %8093, 31
  store i64 %8108, i64* %3, align 8
  %8109 = load i32, i32* %8098, align 4
  %8110 = sext i32 %8109 to i64
  store i64 %8110, i64* %RDX.i4094, align 8
  %8111 = shl nsw i64 %8110, 2
  %8112 = add nsw i64 %8111, 13432
  %8113 = add i64 %8112, %8094
  %8114 = add i64 %8093, 38
  store i64 %8114, i64* %3, align 8
  %8115 = inttoptr i64 %8113 to i32*
  %8116 = load i32, i32* %8115, align 4
  %8117 = add i32 %8116, %8106
  %8118 = zext i32 %8117 to i64
  store i64 %8118, i64* %RSI.i3950, align 8
  %8119 = icmp ult i32 %8117, %8106
  %8120 = icmp ult i32 %8117, %8116
  %8121 = or i1 %8119, %8120
  %8122 = zext i1 %8121 to i8
  store i8 %8122, i8* %12, align 1
  %8123 = and i32 %8117, 255
  %8124 = tail call i32 @llvm.ctpop.i32(i32 %8123)
  %8125 = trunc i32 %8124 to i8
  %8126 = and i8 %8125, 1
  %8127 = xor i8 %8126, 1
  store i8 %8127, i8* %13, align 1
  %8128 = xor i32 %8116, %8106
  %8129 = xor i32 %8128, %8117
  %8130 = lshr i32 %8129, 4
  %8131 = trunc i32 %8130 to i8
  %8132 = and i8 %8131, 1
  store i8 %8132, i8* %14, align 1
  %8133 = icmp eq i32 %8117, 0
  %8134 = zext i1 %8133 to i8
  store i8 %8134, i8* %15, align 1
  %8135 = lshr i32 %8117, 31
  %8136 = trunc i32 %8135 to i8
  store i8 %8136, i8* %16, align 1
  %8137 = lshr i32 %8106, 31
  %8138 = lshr i32 %8116, 31
  %8139 = xor i32 %8135, %8137
  %8140 = xor i32 %8135, %8138
  %8141 = add nuw nsw i32 %8139, %8140
  %8142 = icmp eq i32 %8141, 2
  %8143 = zext i1 %8142 to i8
  store i8 %8143, i8* %17, align 1
  store i64 %8094, i64* %RCX.i3977, align 8
  %8144 = add i64 %8093, 50
  store i64 %8144, i64* %3, align 8
  %8145 = load i32, i32* %8098, align 4
  %8146 = sext i32 %8145 to i64
  store i64 %8146, i64* %RDX.i4094, align 8
  %8147 = shl nsw i64 %8146, 2
  %8148 = add nsw i64 %8147, 13176
  %8149 = add i64 %8148, %8094
  %8150 = add i64 %8093, 57
  store i64 %8150, i64* %3, align 8
  %8151 = inttoptr i64 %8149 to i32*
  %8152 = load i32, i32* %8151, align 4
  %8153 = add i32 %8152, %8117
  %8154 = zext i32 %8153 to i64
  store i64 %8154, i64* %RSI.i3950, align 8
  %8155 = icmp ult i32 %8153, %8117
  %8156 = icmp ult i32 %8153, %8152
  %8157 = or i1 %8155, %8156
  %8158 = zext i1 %8157 to i8
  store i8 %8158, i8* %12, align 1
  %8159 = and i32 %8153, 255
  %8160 = tail call i32 @llvm.ctpop.i32(i32 %8159)
  %8161 = trunc i32 %8160 to i8
  %8162 = and i8 %8161, 1
  %8163 = xor i8 %8162, 1
  store i8 %8163, i8* %13, align 1
  %8164 = xor i32 %8152, %8117
  %8165 = xor i32 %8164, %8153
  %8166 = lshr i32 %8165, 4
  %8167 = trunc i32 %8166 to i8
  %8168 = and i8 %8167, 1
  store i8 %8168, i8* %14, align 1
  %8169 = icmp eq i32 %8153, 0
  %8170 = zext i1 %8169 to i8
  store i8 %8170, i8* %15, align 1
  %8171 = lshr i32 %8153, 31
  %8172 = trunc i32 %8171 to i8
  store i8 %8172, i8* %16, align 1
  %8173 = lshr i32 %8152, 31
  %8174 = xor i32 %8171, %8135
  %8175 = xor i32 %8171, %8173
  %8176 = add nuw nsw i32 %8174, %8175
  %8177 = icmp eq i32 %8176, 2
  %8178 = zext i1 %8177 to i8
  store i8 %8178, i8* %17, align 1
  %8179 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8179, i64* %RCX.i3977, align 8
  %8180 = load i64, i64* %RBP.i, align 8
  %8181 = add i64 %8180, -24
  %8182 = add i64 %8093, 69
  store i64 %8182, i64* %3, align 8
  %8183 = inttoptr i64 %8181 to i32*
  %8184 = load i32, i32* %8183, align 4
  %8185 = sext i32 %8184 to i64
  store i64 %8185, i64* %RDX.i4094, align 8
  %8186 = shl nsw i64 %8185, 2
  %8187 = add i64 %8179, 13176
  %8188 = add i64 %8187, %8186
  %8189 = add i64 %8093, 76
  store i64 %8189, i64* %3, align 8
  %8190 = inttoptr i64 %8188 to i32*
  %8191 = load i32, i32* %8190, align 4
  %8192 = zext i32 %8191 to i64
  %8193 = shl nuw i64 %8192, 32
  %8194 = ashr i64 %8193, 33
  %8195 = and i64 %8194, 4294967295
  store i64 %8195, i64* %RDI.i4084, align 8
  %8196 = trunc i64 %8194 to i32
  %8197 = add i32 %8196, %8153
  %8198 = zext i32 %8197 to i64
  store i64 %8198, i64* %RSI.i3950, align 8
  %8199 = icmp ult i32 %8197, %8153
  %8200 = icmp ult i32 %8197, %8196
  %8201 = or i1 %8199, %8200
  %8202 = zext i1 %8201 to i8
  store i8 %8202, i8* %12, align 1
  %8203 = and i32 %8197, 255
  %8204 = tail call i32 @llvm.ctpop.i32(i32 %8203)
  %8205 = trunc i32 %8204 to i8
  %8206 = and i8 %8205, 1
  %8207 = xor i8 %8206, 1
  store i8 %8207, i8* %13, align 1
  %8208 = xor i64 %8194, %8154
  %8209 = trunc i64 %8208 to i32
  %8210 = xor i32 %8209, %8197
  %8211 = lshr i32 %8210, 4
  %8212 = trunc i32 %8211 to i8
  %8213 = and i8 %8212, 1
  store i8 %8213, i8* %14, align 1
  %8214 = icmp eq i32 %8197, 0
  %8215 = zext i1 %8214 to i8
  store i8 %8215, i8* %15, align 1
  %8216 = lshr i32 %8197, 31
  %8217 = trunc i32 %8216 to i8
  store i8 %8217, i8* %16, align 1
  %8218 = lshr i64 %8194, 31
  %8219 = trunc i64 %8218 to i32
  %8220 = and i32 %8219, 1
  %8221 = xor i32 %8216, %8171
  %8222 = xor i32 %8216, %8220
  %8223 = add nuw nsw i32 %8221, %8222
  %8224 = icmp eq i32 %8223, 2
  %8225 = zext i1 %8224 to i8
  store i8 %8225, i8* %17, align 1
  %8226 = add i64 %8180, -548
  %8227 = add i64 %8093, 86
  store i64 %8227, i64* %3, align 8
  %8228 = inttoptr i64 %8226 to i32*
  store i32 %8197, i32* %8228, align 4
  %8229 = load i64, i64* %RBP.i, align 8
  %8230 = add i64 %8229, -572
  %8231 = load i64, i64* %3, align 8
  %8232 = add i64 %8231, 6
  store i64 %8232, i64* %3, align 8
  %8233 = inttoptr i64 %8230 to i32*
  %8234 = load i32, i32* %8233, align 4
  %8235 = zext i32 %8234 to i64
  store i64 %8235, i64* %RSI.i3950, align 8
  %8236 = add i64 %8229, -548
  %8237 = add i64 %8231, 12
  store i64 %8237, i64* %3, align 8
  %8238 = inttoptr i64 %8236 to i32*
  %8239 = load i32, i32* %8238, align 4
  %8240 = sext i32 %8239 to i64
  %8241 = ashr i64 %8240, 1
  %8242 = lshr i64 %8241, 1
  %8243 = and i64 %8242, 4294967295
  store i64 %8243, i64* %RDI.i4084, align 8
  %8244 = trunc i64 %8242 to i32
  %8245 = add i32 %8244, %8234
  %8246 = zext i32 %8245 to i64
  store i64 %8246, i64* %RSI.i3950, align 8
  %8247 = icmp ult i32 %8245, %8234
  %8248 = icmp ult i32 %8245, %8244
  %8249 = or i1 %8247, %8248
  %8250 = zext i1 %8249 to i8
  store i8 %8250, i8* %12, align 1
  %8251 = and i32 %8245, 255
  %8252 = tail call i32 @llvm.ctpop.i32(i32 %8251)
  %8253 = trunc i32 %8252 to i8
  %8254 = and i8 %8253, 1
  %8255 = xor i8 %8254, 1
  store i8 %8255, i8* %13, align 1
  %8256 = xor i64 %8242, %8235
  %8257 = trunc i64 %8256 to i32
  %8258 = xor i32 %8257, %8245
  %8259 = lshr i32 %8258, 4
  %8260 = trunc i32 %8259 to i8
  %8261 = and i8 %8260, 1
  store i8 %8261, i8* %14, align 1
  %8262 = icmp eq i32 %8245, 0
  %8263 = zext i1 %8262 to i8
  store i8 %8263, i8* %15, align 1
  %8264 = lshr i32 %8245, 31
  %8265 = trunc i32 %8264 to i8
  store i8 %8265, i8* %16, align 1
  %8266 = lshr i32 %8234, 31
  %8267 = lshr i64 %8241, 32
  %8268 = trunc i64 %8267 to i32
  %8269 = and i32 %8268, 1
  %8270 = xor i32 %8264, %8266
  %8271 = xor i32 %8264, %8269
  %8272 = add nuw nsw i32 %8270, %8271
  %8273 = icmp eq i32 %8272, 2
  %8274 = zext i1 %8273 to i8
  store i8 %8274, i8* %17, align 1
  %8275 = add i64 %8229, -604
  %8276 = add i64 %8231, 23
  store i64 %8276, i64* %3, align 8
  %8277 = inttoptr i64 %8275 to i32*
  store i32 %8245, i32* %8277, align 4
  %8278 = load i64, i64* %RBP.i, align 8
  %8279 = add i64 %8278, -572
  %8280 = load i64, i64* %3, align 8
  %8281 = add i64 %8280, 6
  store i64 %8281, i64* %3, align 8
  %8282 = inttoptr i64 %8279 to i32*
  %8283 = load i32, i32* %8282, align 4
  %8284 = sext i32 %8283 to i64
  %8285 = ashr i64 %8284, 1
  %8286 = lshr i64 %8285, 1
  %8287 = and i64 %8286, 4294967295
  store i64 %8287, i64* %RSI.i3950, align 8
  %8288 = load i64, i64* %RAX.i2610, align 8
  %8289 = trunc i64 %8286 to i32
  %8290 = trunc i64 %8288 to i32
  %8291 = sub i32 %8290, %8289
  %8292 = zext i32 %8291 to i64
  store i64 %8292, i64* %RAX.i2610, align 8
  %8293 = icmp ult i32 %8290, %8289
  %8294 = zext i1 %8293 to i8
  store i8 %8294, i8* %12, align 1
  %8295 = and i32 %8291, 255
  %8296 = tail call i32 @llvm.ctpop.i32(i32 %8295)
  %8297 = trunc i32 %8296 to i8
  %8298 = and i8 %8297, 1
  %8299 = xor i8 %8298, 1
  store i8 %8299, i8* %13, align 1
  %8300 = xor i64 %8286, %8288
  %8301 = trunc i64 %8300 to i32
  %8302 = xor i32 %8301, %8291
  %8303 = lshr i32 %8302, 4
  %8304 = trunc i32 %8303 to i8
  %8305 = and i8 %8304, 1
  store i8 %8305, i8* %14, align 1
  %8306 = icmp eq i32 %8291, 0
  %8307 = zext i1 %8306 to i8
  store i8 %8307, i8* %15, align 1
  %8308 = lshr i32 %8291, 31
  %8309 = trunc i32 %8308 to i8
  store i8 %8309, i8* %16, align 1
  %8310 = lshr i32 %8290, 31
  %8311 = lshr i64 %8285, 32
  %8312 = trunc i64 %8311 to i32
  %8313 = and i32 %8312, 1
  %8314 = xor i32 %8313, %8310
  %8315 = xor i32 %8308, %8310
  %8316 = add nuw nsw i32 %8315, %8314
  %8317 = icmp eq i32 %8316, 2
  %8318 = zext i1 %8317 to i8
  store i8 %8318, i8* %17, align 1
  %8319 = add i64 %8278, -548
  %8320 = add i64 %8280, 17
  store i64 %8320, i64* %3, align 8
  %8321 = inttoptr i64 %8319 to i32*
  %8322 = load i32, i32* %8321, align 4
  %8323 = add i32 %8322, %8291
  %8324 = zext i32 %8323 to i64
  store i64 %8324, i64* %RAX.i2610, align 8
  %8325 = icmp ult i32 %8323, %8291
  %8326 = icmp ult i32 %8323, %8322
  %8327 = or i1 %8325, %8326
  %8328 = zext i1 %8327 to i8
  store i8 %8328, i8* %12, align 1
  %8329 = and i32 %8323, 255
  %8330 = tail call i32 @llvm.ctpop.i32(i32 %8329)
  %8331 = trunc i32 %8330 to i8
  %8332 = and i8 %8331, 1
  %8333 = xor i8 %8332, 1
  store i8 %8333, i8* %13, align 1
  %8334 = xor i32 %8322, %8291
  %8335 = xor i32 %8334, %8323
  %8336 = lshr i32 %8335, 4
  %8337 = trunc i32 %8336 to i8
  %8338 = and i8 %8337, 1
  store i8 %8338, i8* %14, align 1
  %8339 = icmp eq i32 %8323, 0
  %8340 = zext i1 %8339 to i8
  store i8 %8340, i8* %15, align 1
  %8341 = lshr i32 %8323, 31
  %8342 = trunc i32 %8341 to i8
  store i8 %8342, i8* %16, align 1
  %8343 = lshr i32 %8322, 31
  %8344 = xor i32 %8341, %8308
  %8345 = xor i32 %8341, %8343
  %8346 = add nuw nsw i32 %8344, %8345
  %8347 = icmp eq i32 %8346, 2
  %8348 = zext i1 %8347 to i8
  store i8 %8348, i8* %17, align 1
  %8349 = load i64, i64* %RBP.i, align 8
  %8350 = add i64 %8349, -580
  %8351 = add i64 %8280, 23
  store i64 %8351, i64* %3, align 8
  %8352 = inttoptr i64 %8350 to i32*
  store i32 %8323, i32* %8352, align 4
  %8353 = load i64, i64* %RBP.i, align 8
  %8354 = add i64 %8353, -564
  %8355 = load i64, i64* %3, align 8
  %8356 = add i64 %8355, 6
  store i64 %8356, i64* %3, align 8
  %8357 = inttoptr i64 %8354 to i32*
  %8358 = load i32, i32* %8357, align 4
  %8359 = zext i32 %8358 to i64
  store i64 %8359, i64* %RAX.i2610, align 8
  %8360 = add i64 %8353, -556
  %8361 = add i64 %8355, 12
  store i64 %8361, i64* %3, align 8
  %8362 = inttoptr i64 %8360 to i32*
  %8363 = load i32, i32* %8362, align 4
  %8364 = sext i32 %8363 to i64
  %8365 = ashr i64 %8364, 1
  %8366 = lshr i64 %8365, 1
  %8367 = and i64 %8366, 4294967295
  store i64 %8367, i64* %RSI.i3950, align 8
  %8368 = trunc i64 %8366 to i32
  %8369 = add i32 %8368, %8358
  %8370 = zext i32 %8369 to i64
  store i64 %8370, i64* %RAX.i2610, align 8
  %8371 = icmp ult i32 %8369, %8358
  %8372 = icmp ult i32 %8369, %8368
  %8373 = or i1 %8371, %8372
  %8374 = zext i1 %8373 to i8
  store i8 %8374, i8* %12, align 1
  %8375 = and i32 %8369, 255
  %8376 = tail call i32 @llvm.ctpop.i32(i32 %8375)
  %8377 = trunc i32 %8376 to i8
  %8378 = and i8 %8377, 1
  %8379 = xor i8 %8378, 1
  store i8 %8379, i8* %13, align 1
  %8380 = xor i64 %8366, %8359
  %8381 = trunc i64 %8380 to i32
  %8382 = xor i32 %8381, %8369
  %8383 = lshr i32 %8382, 4
  %8384 = trunc i32 %8383 to i8
  %8385 = and i8 %8384, 1
  store i8 %8385, i8* %14, align 1
  %8386 = icmp eq i32 %8369, 0
  %8387 = zext i1 %8386 to i8
  store i8 %8387, i8* %15, align 1
  %8388 = lshr i32 %8369, 31
  %8389 = trunc i32 %8388 to i8
  store i8 %8389, i8* %16, align 1
  %8390 = lshr i32 %8358, 31
  %8391 = lshr i64 %8365, 32
  %8392 = trunc i64 %8391 to i32
  %8393 = and i32 %8392, 1
  %8394 = xor i32 %8388, %8390
  %8395 = xor i32 %8388, %8393
  %8396 = add nuw nsw i32 %8394, %8395
  %8397 = icmp eq i32 %8396, 2
  %8398 = zext i1 %8397 to i8
  store i8 %8398, i8* %17, align 1
  %8399 = add i64 %8353, -596
  %8400 = add i64 %8355, 23
  store i64 %8400, i64* %3, align 8
  %8401 = inttoptr i64 %8399 to i32*
  store i32 %8369, i32* %8401, align 4
  %8402 = load i64, i64* %RBP.i, align 8
  %8403 = add i64 %8402, -564
  %8404 = load i64, i64* %3, align 8
  %8405 = add i64 %8404, 6
  store i64 %8405, i64* %3, align 8
  %8406 = inttoptr i64 %8403 to i32*
  %8407 = load i32, i32* %8406, align 4
  %8408 = sext i32 %8407 to i64
  %8409 = ashr i64 %8408, 1
  %8410 = lshr i64 %8409, 1
  %8411 = trunc i64 %8409 to i8
  %8412 = and i8 %8411, 1
  %8413 = trunc i64 %8410 to i32
  %8414 = and i64 %8410, 4294967295
  store i64 %8414, i64* %RAX.i2610, align 8
  store i8 %8412, i8* %12, align 1
  %8415 = and i32 %8413, 255
  %8416 = tail call i32 @llvm.ctpop.i32(i32 %8415)
  %8417 = trunc i32 %8416 to i8
  %8418 = and i8 %8417, 1
  %8419 = xor i8 %8418, 1
  store i8 %8419, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %8420 = icmp eq i32 %8413, 0
  %8421 = zext i1 %8420 to i8
  store i8 %8421, i8* %15, align 1
  %8422 = lshr i64 %8409, 32
  %8423 = trunc i64 %8422 to i8
  %8424 = and i8 %8423, 1
  store i8 %8424, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %8425 = add i64 %8402, -556
  %8426 = add i64 %8404, 15
  store i64 %8426, i64* %3, align 8
  %8427 = trunc i64 %8410 to i32
  %8428 = inttoptr i64 %8425 to i32*
  %8429 = load i32, i32* %8428, align 4
  %8430 = sub i32 %8427, %8429
  %8431 = zext i32 %8430 to i64
  store i64 %8431, i64* %RAX.i2610, align 8
  %8432 = icmp ult i32 %8427, %8429
  %8433 = zext i1 %8432 to i8
  store i8 %8433, i8* %12, align 1
  %8434 = and i32 %8430, 255
  %8435 = tail call i32 @llvm.ctpop.i32(i32 %8434)
  %8436 = trunc i32 %8435 to i8
  %8437 = and i8 %8436, 1
  %8438 = xor i8 %8437, 1
  store i8 %8438, i8* %13, align 1
  %8439 = xor i32 %8429, %8427
  %8440 = xor i32 %8439, %8430
  %8441 = lshr i32 %8440, 4
  %8442 = trunc i32 %8441 to i8
  %8443 = and i8 %8442, 1
  store i8 %8443, i8* %14, align 1
  %8444 = icmp eq i32 %8430, 0
  %8445 = zext i1 %8444 to i8
  store i8 %8445, i8* %15, align 1
  %8446 = lshr i32 %8430, 31
  %8447 = trunc i32 %8446 to i8
  store i8 %8447, i8* %16, align 1
  %8448 = lshr i64 %8409, 32
  %8449 = trunc i64 %8448 to i32
  %8450 = and i32 %8449, 1
  %8451 = lshr i32 %8429, 31
  %8452 = xor i32 %8451, %8450
  %8453 = xor i32 %8446, %8450
  %8454 = add nuw nsw i32 %8453, %8452
  %8455 = icmp eq i32 %8454, 2
  %8456 = zext i1 %8455 to i8
  store i8 %8456, i8* %17, align 1
  %8457 = add i64 %8402, -588
  %8458 = add i64 %8404, 21
  store i64 %8458, i64* %3, align 8
  %8459 = inttoptr i64 %8457 to i32*
  store i32 %8430, i32* %8459, align 4
  %8460 = load i64, i64* %RBP.i, align 8
  %8461 = add i64 %8460, -608
  %8462 = load i64, i64* %3, align 8
  %8463 = add i64 %8462, 6
  store i64 %8463, i64* %3, align 8
  %8464 = inttoptr i64 %8461 to i32*
  %8465 = load i32, i32* %8464, align 4
  %8466 = zext i32 %8465 to i64
  store i64 %8466, i64* %RAX.i2610, align 8
  %8467 = add i64 %8460, -580
  %8468 = add i64 %8462, 12
  store i64 %8468, i64* %3, align 8
  %8469 = inttoptr i64 %8467 to i32*
  %8470 = load i32, i32* %8469, align 4
  %8471 = add i32 %8470, %8465
  %8472 = zext i32 %8471 to i64
  store i64 %8472, i64* %RAX.i2610, align 8
  %8473 = icmp ult i32 %8471, %8465
  %8474 = icmp ult i32 %8471, %8470
  %8475 = or i1 %8473, %8474
  %8476 = zext i1 %8475 to i8
  store i8 %8476, i8* %12, align 1
  %8477 = and i32 %8471, 255
  %8478 = tail call i32 @llvm.ctpop.i32(i32 %8477)
  %8479 = trunc i32 %8478 to i8
  %8480 = and i8 %8479, 1
  %8481 = xor i8 %8480, 1
  store i8 %8481, i8* %13, align 1
  %8482 = xor i32 %8470, %8465
  %8483 = xor i32 %8482, %8471
  %8484 = lshr i32 %8483, 4
  %8485 = trunc i32 %8484 to i8
  %8486 = and i8 %8485, 1
  store i8 %8486, i8* %14, align 1
  %8487 = icmp eq i32 %8471, 0
  %8488 = zext i1 %8487 to i8
  store i8 %8488, i8* %15, align 1
  %8489 = lshr i32 %8471, 31
  %8490 = trunc i32 %8489 to i8
  store i8 %8490, i8* %16, align 1
  %8491 = lshr i32 %8465, 31
  %8492 = lshr i32 %8470, 31
  %8493 = xor i32 %8489, %8491
  %8494 = xor i32 %8489, %8492
  %8495 = add nuw nsw i32 %8493, %8494
  %8496 = icmp eq i32 %8495, 2
  %8497 = zext i1 %8496 to i8
  store i8 %8497, i8* %17, align 1
  %8498 = add i64 %8460, -24
  %8499 = add i64 %8462, 16
  store i64 %8499, i64* %3, align 8
  %8500 = inttoptr i64 %8498 to i32*
  %8501 = load i32, i32* %8500, align 4
  %8502 = sext i32 %8501 to i64
  store i64 %8502, i64* %RCX.i3977, align 8
  %8503 = shl nsw i64 %8502, 2
  %8504 = add i64 %8460, -368
  %8505 = add i64 %8504, %8503
  %8506 = add i64 %8462, 23
  store i64 %8506, i64* %3, align 8
  %8507 = inttoptr i64 %8505 to i32*
  store i32 %8471, i32* %8507, align 4
  %8508 = load i64, i64* %RBP.i, align 8
  %8509 = add i64 %8508, -600
  %8510 = load i64, i64* %3, align 8
  %8511 = add i64 %8510, 6
  store i64 %8511, i64* %3, align 8
  %8512 = inttoptr i64 %8509 to i32*
  %8513 = load i32, i32* %8512, align 4
  %8514 = zext i32 %8513 to i64
  store i64 %8514, i64* %RAX.i2610, align 8
  %8515 = add i64 %8508, -588
  %8516 = add i64 %8510, 12
  store i64 %8516, i64* %3, align 8
  %8517 = inttoptr i64 %8515 to i32*
  %8518 = load i32, i32* %8517, align 4
  %8519 = add i32 %8518, %8513
  %8520 = zext i32 %8519 to i64
  store i64 %8520, i64* %RAX.i2610, align 8
  %8521 = icmp ult i32 %8519, %8513
  %8522 = icmp ult i32 %8519, %8518
  %8523 = or i1 %8521, %8522
  %8524 = zext i1 %8523 to i8
  store i8 %8524, i8* %12, align 1
  %8525 = and i32 %8519, 255
  %8526 = tail call i32 @llvm.ctpop.i32(i32 %8525)
  %8527 = trunc i32 %8526 to i8
  %8528 = and i8 %8527, 1
  %8529 = xor i8 %8528, 1
  store i8 %8529, i8* %13, align 1
  %8530 = xor i32 %8518, %8513
  %8531 = xor i32 %8530, %8519
  %8532 = lshr i32 %8531, 4
  %8533 = trunc i32 %8532 to i8
  %8534 = and i8 %8533, 1
  store i8 %8534, i8* %14, align 1
  %8535 = icmp eq i32 %8519, 0
  %8536 = zext i1 %8535 to i8
  store i8 %8536, i8* %15, align 1
  %8537 = lshr i32 %8519, 31
  %8538 = trunc i32 %8537 to i8
  store i8 %8538, i8* %16, align 1
  %8539 = lshr i32 %8513, 31
  %8540 = lshr i32 %8518, 31
  %8541 = xor i32 %8537, %8539
  %8542 = xor i32 %8537, %8540
  %8543 = add nuw nsw i32 %8541, %8542
  %8544 = icmp eq i32 %8543, 2
  %8545 = zext i1 %8544 to i8
  store i8 %8545, i8* %17, align 1
  %8546 = add i64 %8508, -24
  %8547 = add i64 %8510, 16
  store i64 %8547, i64* %3, align 8
  %8548 = inttoptr i64 %8546 to i32*
  %8549 = load i32, i32* %8548, align 4
  %8550 = sext i32 %8549 to i64
  store i64 %8550, i64* %RCX.i3977, align 8
  %8551 = shl nsw i64 %8550, 2
  %8552 = add i64 %8508, -336
  %8553 = add i64 %8552, %8551
  %8554 = add i64 %8510, 23
  store i64 %8554, i64* %3, align 8
  %8555 = inttoptr i64 %8553 to i32*
  store i32 %8519, i32* %8555, align 4
  %8556 = load i64, i64* %RBP.i, align 8
  %8557 = add i64 %8556, -592
  %8558 = load i64, i64* %3, align 8
  %8559 = add i64 %8558, 6
  store i64 %8559, i64* %3, align 8
  %8560 = inttoptr i64 %8557 to i32*
  %8561 = load i32, i32* %8560, align 4
  %8562 = zext i32 %8561 to i64
  store i64 %8562, i64* %RAX.i2610, align 8
  %8563 = add i64 %8556, -596
  %8564 = add i64 %8558, 12
  store i64 %8564, i64* %3, align 8
  %8565 = inttoptr i64 %8563 to i32*
  %8566 = load i32, i32* %8565, align 4
  %8567 = add i32 %8566, %8561
  %8568 = zext i32 %8567 to i64
  store i64 %8568, i64* %RAX.i2610, align 8
  %8569 = icmp ult i32 %8567, %8561
  %8570 = icmp ult i32 %8567, %8566
  %8571 = or i1 %8569, %8570
  %8572 = zext i1 %8571 to i8
  store i8 %8572, i8* %12, align 1
  %8573 = and i32 %8567, 255
  %8574 = tail call i32 @llvm.ctpop.i32(i32 %8573)
  %8575 = trunc i32 %8574 to i8
  %8576 = and i8 %8575, 1
  %8577 = xor i8 %8576, 1
  store i8 %8577, i8* %13, align 1
  %8578 = xor i32 %8566, %8561
  %8579 = xor i32 %8578, %8567
  %8580 = lshr i32 %8579, 4
  %8581 = trunc i32 %8580 to i8
  %8582 = and i8 %8581, 1
  store i8 %8582, i8* %14, align 1
  %8583 = icmp eq i32 %8567, 0
  %8584 = zext i1 %8583 to i8
  store i8 %8584, i8* %15, align 1
  %8585 = lshr i32 %8567, 31
  %8586 = trunc i32 %8585 to i8
  store i8 %8586, i8* %16, align 1
  %8587 = lshr i32 %8561, 31
  %8588 = lshr i32 %8566, 31
  %8589 = xor i32 %8585, %8587
  %8590 = xor i32 %8585, %8588
  %8591 = add nuw nsw i32 %8589, %8590
  %8592 = icmp eq i32 %8591, 2
  %8593 = zext i1 %8592 to i8
  store i8 %8593, i8* %17, align 1
  %8594 = add i64 %8556, -24
  %8595 = add i64 %8558, 16
  store i64 %8595, i64* %3, align 8
  %8596 = inttoptr i64 %8594 to i32*
  %8597 = load i32, i32* %8596, align 4
  %8598 = sext i32 %8597 to i64
  store i64 %8598, i64* %RCX.i3977, align 8
  %8599 = shl nsw i64 %8598, 2
  %8600 = add i64 %8556, -304
  %8601 = add i64 %8600, %8599
  %8602 = add i64 %8558, 23
  store i64 %8602, i64* %3, align 8
  %8603 = inttoptr i64 %8601 to i32*
  store i32 %8567, i32* %8603, align 4
  %8604 = load i64, i64* %RBP.i, align 8
  %8605 = add i64 %8604, -584
  %8606 = load i64, i64* %3, align 8
  %8607 = add i64 %8606, 6
  store i64 %8607, i64* %3, align 8
  %8608 = inttoptr i64 %8605 to i32*
  %8609 = load i32, i32* %8608, align 4
  %8610 = zext i32 %8609 to i64
  store i64 %8610, i64* %RAX.i2610, align 8
  %8611 = add i64 %8604, -604
  %8612 = add i64 %8606, 12
  store i64 %8612, i64* %3, align 8
  %8613 = inttoptr i64 %8611 to i32*
  %8614 = load i32, i32* %8613, align 4
  %8615 = add i32 %8614, %8609
  %8616 = zext i32 %8615 to i64
  store i64 %8616, i64* %RAX.i2610, align 8
  %8617 = icmp ult i32 %8615, %8609
  %8618 = icmp ult i32 %8615, %8614
  %8619 = or i1 %8617, %8618
  %8620 = zext i1 %8619 to i8
  store i8 %8620, i8* %12, align 1
  %8621 = and i32 %8615, 255
  %8622 = tail call i32 @llvm.ctpop.i32(i32 %8621)
  %8623 = trunc i32 %8622 to i8
  %8624 = and i8 %8623, 1
  %8625 = xor i8 %8624, 1
  store i8 %8625, i8* %13, align 1
  %8626 = xor i32 %8614, %8609
  %8627 = xor i32 %8626, %8615
  %8628 = lshr i32 %8627, 4
  %8629 = trunc i32 %8628 to i8
  %8630 = and i8 %8629, 1
  store i8 %8630, i8* %14, align 1
  %8631 = icmp eq i32 %8615, 0
  %8632 = zext i1 %8631 to i8
  store i8 %8632, i8* %15, align 1
  %8633 = lshr i32 %8615, 31
  %8634 = trunc i32 %8633 to i8
  store i8 %8634, i8* %16, align 1
  %8635 = lshr i32 %8609, 31
  %8636 = lshr i32 %8614, 31
  %8637 = xor i32 %8633, %8635
  %8638 = xor i32 %8633, %8636
  %8639 = add nuw nsw i32 %8637, %8638
  %8640 = icmp eq i32 %8639, 2
  %8641 = zext i1 %8640 to i8
  store i8 %8641, i8* %17, align 1
  %8642 = add i64 %8604, -24
  %8643 = add i64 %8606, 16
  store i64 %8643, i64* %3, align 8
  %8644 = inttoptr i64 %8642 to i32*
  %8645 = load i32, i32* %8644, align 4
  %8646 = sext i32 %8645 to i64
  store i64 %8646, i64* %RCX.i3977, align 8
  %8647 = shl nsw i64 %8646, 2
  %8648 = add i64 %8604, -272
  %8649 = add i64 %8648, %8647
  %8650 = add i64 %8606, 23
  store i64 %8650, i64* %3, align 8
  %8651 = inttoptr i64 %8649 to i32*
  store i32 %8615, i32* %8651, align 4
  %8652 = load i64, i64* %RBP.i, align 8
  %8653 = add i64 %8652, -584
  %8654 = load i64, i64* %3, align 8
  %8655 = add i64 %8654, 6
  store i64 %8655, i64* %3, align 8
  %8656 = inttoptr i64 %8653 to i32*
  %8657 = load i32, i32* %8656, align 4
  %8658 = zext i32 %8657 to i64
  store i64 %8658, i64* %RAX.i2610, align 8
  %8659 = add i64 %8652, -604
  %8660 = add i64 %8654, 12
  store i64 %8660, i64* %3, align 8
  %8661 = inttoptr i64 %8659 to i32*
  %8662 = load i32, i32* %8661, align 4
  %8663 = sub i32 %8657, %8662
  %8664 = zext i32 %8663 to i64
  store i64 %8664, i64* %RAX.i2610, align 8
  %8665 = icmp ult i32 %8657, %8662
  %8666 = zext i1 %8665 to i8
  store i8 %8666, i8* %12, align 1
  %8667 = and i32 %8663, 255
  %8668 = tail call i32 @llvm.ctpop.i32(i32 %8667)
  %8669 = trunc i32 %8668 to i8
  %8670 = and i8 %8669, 1
  %8671 = xor i8 %8670, 1
  store i8 %8671, i8* %13, align 1
  %8672 = xor i32 %8662, %8657
  %8673 = xor i32 %8672, %8663
  %8674 = lshr i32 %8673, 4
  %8675 = trunc i32 %8674 to i8
  %8676 = and i8 %8675, 1
  store i8 %8676, i8* %14, align 1
  %8677 = icmp eq i32 %8663, 0
  %8678 = zext i1 %8677 to i8
  store i8 %8678, i8* %15, align 1
  %8679 = lshr i32 %8663, 31
  %8680 = trunc i32 %8679 to i8
  store i8 %8680, i8* %16, align 1
  %8681 = lshr i32 %8657, 31
  %8682 = lshr i32 %8662, 31
  %8683 = xor i32 %8682, %8681
  %8684 = xor i32 %8679, %8681
  %8685 = add nuw nsw i32 %8684, %8683
  %8686 = icmp eq i32 %8685, 2
  %8687 = zext i1 %8686 to i8
  store i8 %8687, i8* %17, align 1
  %8688 = add i64 %8652, -24
  %8689 = add i64 %8654, 16
  store i64 %8689, i64* %3, align 8
  %8690 = inttoptr i64 %8688 to i32*
  %8691 = load i32, i32* %8690, align 4
  %8692 = sext i32 %8691 to i64
  store i64 %8692, i64* %RCX.i3977, align 8
  %8693 = shl nsw i64 %8692, 2
  %8694 = add i64 %8652, -240
  %8695 = add i64 %8694, %8693
  %8696 = add i64 %8654, 23
  store i64 %8696, i64* %3, align 8
  %8697 = inttoptr i64 %8695 to i32*
  store i32 %8663, i32* %8697, align 4
  %8698 = load i64, i64* %RBP.i, align 8
  %8699 = add i64 %8698, -592
  %8700 = load i64, i64* %3, align 8
  %8701 = add i64 %8700, 6
  store i64 %8701, i64* %3, align 8
  %8702 = inttoptr i64 %8699 to i32*
  %8703 = load i32, i32* %8702, align 4
  %8704 = zext i32 %8703 to i64
  store i64 %8704, i64* %RAX.i2610, align 8
  %8705 = add i64 %8698, -596
  %8706 = add i64 %8700, 12
  store i64 %8706, i64* %3, align 8
  %8707 = inttoptr i64 %8705 to i32*
  %8708 = load i32, i32* %8707, align 4
  %8709 = sub i32 %8703, %8708
  %8710 = zext i32 %8709 to i64
  store i64 %8710, i64* %RAX.i2610, align 8
  %8711 = icmp ult i32 %8703, %8708
  %8712 = zext i1 %8711 to i8
  store i8 %8712, i8* %12, align 1
  %8713 = and i32 %8709, 255
  %8714 = tail call i32 @llvm.ctpop.i32(i32 %8713)
  %8715 = trunc i32 %8714 to i8
  %8716 = and i8 %8715, 1
  %8717 = xor i8 %8716, 1
  store i8 %8717, i8* %13, align 1
  %8718 = xor i32 %8708, %8703
  %8719 = xor i32 %8718, %8709
  %8720 = lshr i32 %8719, 4
  %8721 = trunc i32 %8720 to i8
  %8722 = and i8 %8721, 1
  store i8 %8722, i8* %14, align 1
  %8723 = icmp eq i32 %8709, 0
  %8724 = zext i1 %8723 to i8
  store i8 %8724, i8* %15, align 1
  %8725 = lshr i32 %8709, 31
  %8726 = trunc i32 %8725 to i8
  store i8 %8726, i8* %16, align 1
  %8727 = lshr i32 %8703, 31
  %8728 = lshr i32 %8708, 31
  %8729 = xor i32 %8728, %8727
  %8730 = xor i32 %8725, %8727
  %8731 = add nuw nsw i32 %8730, %8729
  %8732 = icmp eq i32 %8731, 2
  %8733 = zext i1 %8732 to i8
  store i8 %8733, i8* %17, align 1
  %8734 = add i64 %8698, -24
  %8735 = add i64 %8700, 16
  store i64 %8735, i64* %3, align 8
  %8736 = inttoptr i64 %8734 to i32*
  %8737 = load i32, i32* %8736, align 4
  %8738 = sext i32 %8737 to i64
  store i64 %8738, i64* %RCX.i3977, align 8
  %8739 = shl nsw i64 %8738, 2
  %8740 = add i64 %8698, -208
  %8741 = add i64 %8740, %8739
  %8742 = add i64 %8700, 23
  store i64 %8742, i64* %3, align 8
  %8743 = inttoptr i64 %8741 to i32*
  store i32 %8709, i32* %8743, align 4
  %8744 = load i64, i64* %RBP.i, align 8
  %8745 = add i64 %8744, -600
  %8746 = load i64, i64* %3, align 8
  %8747 = add i64 %8746, 6
  store i64 %8747, i64* %3, align 8
  %8748 = inttoptr i64 %8745 to i32*
  %8749 = load i32, i32* %8748, align 4
  %8750 = zext i32 %8749 to i64
  store i64 %8750, i64* %RAX.i2610, align 8
  %8751 = add i64 %8744, -588
  %8752 = add i64 %8746, 12
  store i64 %8752, i64* %3, align 8
  %8753 = inttoptr i64 %8751 to i32*
  %8754 = load i32, i32* %8753, align 4
  %8755 = sub i32 %8749, %8754
  %8756 = zext i32 %8755 to i64
  store i64 %8756, i64* %RAX.i2610, align 8
  %8757 = icmp ult i32 %8749, %8754
  %8758 = zext i1 %8757 to i8
  store i8 %8758, i8* %12, align 1
  %8759 = and i32 %8755, 255
  %8760 = tail call i32 @llvm.ctpop.i32(i32 %8759)
  %8761 = trunc i32 %8760 to i8
  %8762 = and i8 %8761, 1
  %8763 = xor i8 %8762, 1
  store i8 %8763, i8* %13, align 1
  %8764 = xor i32 %8754, %8749
  %8765 = xor i32 %8764, %8755
  %8766 = lshr i32 %8765, 4
  %8767 = trunc i32 %8766 to i8
  %8768 = and i8 %8767, 1
  store i8 %8768, i8* %14, align 1
  %8769 = icmp eq i32 %8755, 0
  %8770 = zext i1 %8769 to i8
  store i8 %8770, i8* %15, align 1
  %8771 = lshr i32 %8755, 31
  %8772 = trunc i32 %8771 to i8
  store i8 %8772, i8* %16, align 1
  %8773 = lshr i32 %8749, 31
  %8774 = lshr i32 %8754, 31
  %8775 = xor i32 %8774, %8773
  %8776 = xor i32 %8771, %8773
  %8777 = add nuw nsw i32 %8776, %8775
  %8778 = icmp eq i32 %8777, 2
  %8779 = zext i1 %8778 to i8
  store i8 %8779, i8* %17, align 1
  %8780 = add i64 %8744, -24
  %8781 = add i64 %8746, 16
  store i64 %8781, i64* %3, align 8
  %8782 = inttoptr i64 %8780 to i32*
  %8783 = load i32, i32* %8782, align 4
  %8784 = sext i32 %8783 to i64
  store i64 %8784, i64* %RCX.i3977, align 8
  %8785 = shl nsw i64 %8784, 2
  %8786 = add i64 %8744, -176
  %8787 = add i64 %8786, %8785
  %8788 = add i64 %8746, 23
  store i64 %8788, i64* %3, align 8
  %8789 = inttoptr i64 %8787 to i32*
  store i32 %8755, i32* %8789, align 4
  %8790 = load i64, i64* %RBP.i, align 8
  %8791 = add i64 %8790, -608
  %8792 = load i64, i64* %3, align 8
  %8793 = add i64 %8792, 6
  store i64 %8793, i64* %3, align 8
  %8794 = inttoptr i64 %8791 to i32*
  %8795 = load i32, i32* %8794, align 4
  %8796 = zext i32 %8795 to i64
  store i64 %8796, i64* %RAX.i2610, align 8
  %8797 = add i64 %8790, -580
  %8798 = add i64 %8792, 12
  store i64 %8798, i64* %3, align 8
  %8799 = inttoptr i64 %8797 to i32*
  %8800 = load i32, i32* %8799, align 4
  %8801 = sub i32 %8795, %8800
  %8802 = zext i32 %8801 to i64
  store i64 %8802, i64* %RAX.i2610, align 8
  %8803 = icmp ult i32 %8795, %8800
  %8804 = zext i1 %8803 to i8
  store i8 %8804, i8* %12, align 1
  %8805 = and i32 %8801, 255
  %8806 = tail call i32 @llvm.ctpop.i32(i32 %8805)
  %8807 = trunc i32 %8806 to i8
  %8808 = and i8 %8807, 1
  %8809 = xor i8 %8808, 1
  store i8 %8809, i8* %13, align 1
  %8810 = xor i32 %8800, %8795
  %8811 = xor i32 %8810, %8801
  %8812 = lshr i32 %8811, 4
  %8813 = trunc i32 %8812 to i8
  %8814 = and i8 %8813, 1
  store i8 %8814, i8* %14, align 1
  %8815 = icmp eq i32 %8801, 0
  %8816 = zext i1 %8815 to i8
  store i8 %8816, i8* %15, align 1
  %8817 = lshr i32 %8801, 31
  %8818 = trunc i32 %8817 to i8
  store i8 %8818, i8* %16, align 1
  %8819 = lshr i32 %8795, 31
  %8820 = lshr i32 %8800, 31
  %8821 = xor i32 %8820, %8819
  %8822 = xor i32 %8817, %8819
  %8823 = add nuw nsw i32 %8822, %8821
  %8824 = icmp eq i32 %8823, 2
  %8825 = zext i1 %8824 to i8
  store i8 %8825, i8* %17, align 1
  %8826 = add i64 %8790, -24
  %8827 = add i64 %8792, 16
  store i64 %8827, i64* %3, align 8
  %8828 = inttoptr i64 %8826 to i32*
  %8829 = load i32, i32* %8828, align 4
  %8830 = sext i32 %8829 to i64
  store i64 %8830, i64* %RCX.i3977, align 8
  %8831 = shl nsw i64 %8830, 2
  %8832 = add i64 %8790, -144
  %8833 = add i64 %8832, %8831
  %8834 = add i64 %8792, 23
  store i64 %8834, i64* %3, align 8
  %8835 = inttoptr i64 %8833 to i32*
  store i32 %8801, i32* %8835, align 4
  %8836 = load i64, i64* %RBP.i, align 8
  %8837 = add i64 %8836, -24
  %8838 = load i64, i64* %3, align 8
  %8839 = add i64 %8838, 3
  store i64 %8839, i64* %3, align 8
  %8840 = inttoptr i64 %8837 to i32*
  %8841 = load i32, i32* %8840, align 4
  %8842 = add i32 %8841, 1
  %8843 = zext i32 %8842 to i64
  store i64 %8843, i64* %RAX.i2610, align 8
  %8844 = icmp eq i32 %8841, -1
  %8845 = icmp eq i32 %8842, 0
  %8846 = or i1 %8844, %8845
  %8847 = zext i1 %8846 to i8
  store i8 %8847, i8* %12, align 1
  %8848 = and i32 %8842, 255
  %8849 = tail call i32 @llvm.ctpop.i32(i32 %8848)
  %8850 = trunc i32 %8849 to i8
  %8851 = and i8 %8850, 1
  %8852 = xor i8 %8851, 1
  store i8 %8852, i8* %13, align 1
  %8853 = xor i32 %8842, %8841
  %8854 = lshr i32 %8853, 4
  %8855 = trunc i32 %8854 to i8
  %8856 = and i8 %8855, 1
  store i8 %8856, i8* %14, align 1
  %8857 = zext i1 %8845 to i8
  store i8 %8857, i8* %15, align 1
  %8858 = lshr i32 %8842, 31
  %8859 = trunc i32 %8858 to i8
  store i8 %8859, i8* %16, align 1
  %8860 = lshr i32 %8841, 31
  %8861 = xor i32 %8858, %8860
  %8862 = add nuw nsw i32 %8861, %8858
  %8863 = icmp eq i32 %8862, 2
  %8864 = zext i1 %8863 to i8
  store i8 %8864, i8* %17, align 1
  %8865 = add i64 %8838, 9
  store i64 %8865, i64* %3, align 8
  store i32 %8842, i32* %8840, align 4
  %8866 = load i64, i64* %3, align 8
  %8867 = add i64 %8866, -950
  store i64 %8867, i64* %3, align 8
  br label %block_.L_4ab77d

block_.L_4abb3f:                                  ; preds = %block_.L_4abb78, %block_4ab7b1
  %8868 = phi i64 [ %11459, %block_.L_4abb78 ], [ %.pre181, %block_4ab7b1 ]
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i8 0, i8* %CL.i3807, align 1
  %8869 = load i64, i64* %RBP.i, align 8
  %8870 = add i64 %8869, -24
  %8871 = add i64 %8868, 8
  store i64 %8871, i64* %3, align 8
  %8872 = inttoptr i64 %8870 to i32*
  %8873 = load i32, i32* %8872, align 4
  %8874 = add i32 %8873, -8
  %8875 = icmp ult i32 %8873, 8
  %8876 = zext i1 %8875 to i8
  store i8 %8876, i8* %12, align 1
  %8877 = and i32 %8874, 255
  %8878 = tail call i32 @llvm.ctpop.i32(i32 %8877)
  %8879 = trunc i32 %8878 to i8
  %8880 = and i8 %8879, 1
  %8881 = xor i8 %8880, 1
  store i8 %8881, i8* %13, align 1
  %8882 = xor i32 %8874, %8873
  %8883 = lshr i32 %8882, 4
  %8884 = trunc i32 %8883 to i8
  %8885 = and i8 %8884, 1
  store i8 %8885, i8* %14, align 1
  %8886 = icmp eq i32 %8874, 0
  %8887 = zext i1 %8886 to i8
  store i8 %8887, i8* %15, align 1
  %8888 = lshr i32 %8874, 31
  %8889 = trunc i32 %8888 to i8
  store i8 %8889, i8* %16, align 1
  %8890 = lshr i32 %8873, 31
  %8891 = xor i32 %8888, %8890
  %8892 = add nuw nsw i32 %8891, %8890
  %8893 = icmp eq i32 %8892, 2
  %8894 = zext i1 %8893 to i8
  store i8 %8894, i8* %17, align 1
  %8895 = add i64 %8869, -718
  %8896 = add i64 %8868, 14
  store i64 %8896, i64* %3, align 8
  %8897 = inttoptr i64 %8895 to i8*
  store i8 0, i8* %8897, align 1
  %8898 = load i64, i64* %3, align 8
  %8899 = add i64 %8898, 24
  %8900 = add i64 %8898, 6
  %8901 = load i8, i8* %16, align 1
  %8902 = icmp ne i8 %8901, 0
  %8903 = load i8, i8* %17, align 1
  %8904 = icmp ne i8 %8903, 0
  %8905 = xor i1 %8902, %8904
  %8906 = select i1 %8905, i64 %8900, i64 %8899
  store i64 %8906, i64* %3, align 8
  br i1 %8905, label %block_4abb53, label %block_.L_4abb65

block_4abb53:                                     ; preds = %block_.L_4abb3f
  %8907 = load i64, i64* %RBP.i, align 8
  %8908 = add i64 %8907, -412
  %8909 = add i64 %8906, 7
  store i64 %8909, i64* %3, align 8
  %8910 = inttoptr i64 %8908 to i32*
  %8911 = load i32, i32* %8910, align 4
  %8912 = icmp ne i32 %8911, 0
  %8913 = zext i1 %8912 to i64
  %8914 = xor i64 %8913, 255
  %8915 = trunc i64 %8914 to i8
  store i8 %8915, i8* %AL.i3806, align 1
  store i8 0, i8* %12, align 1
  %8916 = trunc i64 %8914 to i32
  %8917 = tail call i32 @llvm.ctpop.i32(i32 %8916)
  %8918 = trunc i32 %8917 to i8
  %8919 = and i8 %8918, 1
  %8920 = xor i8 %8919, 1
  store i8 %8920, i8* %13, align 1
  store i8 0, i8* %15, align 1
  store i8 1, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %8921 = add i64 %8907, -718
  %8922 = add i64 %8906, 18
  store i64 %8922, i64* %3, align 8
  %8923 = inttoptr i64 %8921 to i8*
  store i8 %8915, i8* %8923, align 1
  %.pre182 = load i64, i64* %3, align 8
  br label %block_.L_4abb65

block_.L_4abb65:                                  ; preds = %block_.L_4abb3f, %block_4abb53
  %8924 = phi i64 [ %8899, %block_.L_4abb3f ], [ %.pre182, %block_4abb53 ]
  %8925 = load i64, i64* %RBP.i, align 8
  %8926 = add i64 %8925, -718
  %8927 = add i64 %8924, 6
  store i64 %8927, i64* %3, align 8
  %8928 = inttoptr i64 %8926 to i8*
  %8929 = load i8, i8* %8928, align 1
  store i8 %8929, i8* %AL.i3806, align 1
  %8930 = and i8 %8929, 1
  store i8 0, i8* %12, align 1
  %8931 = zext i8 %8930 to i32
  %8932 = tail call i32 @llvm.ctpop.i32(i32 %8931)
  %8933 = trunc i32 %8932 to i8
  %8934 = xor i8 %8933, 1
  store i8 %8934, i8* %13, align 1
  %8935 = xor i8 %8930, 1
  store i8 %8935, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %8936 = icmp eq i8 %8935, 0
  %.v203 = select i1 %8936, i64 19, i64 14
  %8937 = add i64 %8924, %.v203
  store i64 %8937, i64* %3, align 8
  br i1 %8936, label %block_.L_4abb78, label %block_4abb73

block_4abb73:                                     ; preds = %block_.L_4abb65
  %8938 = add i64 %8925, -24
  %8939 = add i64 %8937, 1025
  store i64 %8939, i64* %3, align 8
  %8940 = inttoptr i64 %8938 to i32*
  store i32 0, i32* %8940, align 4
  %.pre183 = load i64, i64* %3, align 8
  br label %block_.L_4abf74

block_.L_4abb78:                                  ; preds = %block_.L_4abb65
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  %8941 = add i64 %8925, -368
  store i64 %8941, i64* %RCX.i3977, align 8
  %8942 = add i64 %8925, -24
  %8943 = add i64 %8937, 13
  store i64 %8943, i64* %3, align 8
  %8944 = inttoptr i64 %8942 to i32*
  %8945 = load i32, i32* %8944, align 4
  %8946 = sext i32 %8945 to i64
  %8947 = shl nsw i64 %8946, 5
  store i64 %8947, i64* %RDX.i4094, align 8
  %8948 = add i64 %8947, %8941
  store i64 %8948, i64* %RSI.i3950, align 8
  %8949 = icmp ult i64 %8948, %8941
  %8950 = icmp ult i64 %8948, %8947
  %8951 = or i1 %8949, %8950
  %8952 = zext i1 %8951 to i8
  store i8 %8952, i8* %12, align 1
  %8953 = trunc i64 %8948 to i32
  %8954 = and i32 %8953, 255
  %8955 = tail call i32 @llvm.ctpop.i32(i32 %8954)
  %8956 = trunc i32 %8955 to i8
  %8957 = and i8 %8956, 1
  %8958 = xor i8 %8957, 1
  store i8 %8958, i8* %13, align 1
  %8959 = xor i64 %8941, %8948
  %8960 = lshr i64 %8959, 4
  %8961 = trunc i64 %8960 to i8
  %8962 = and i8 %8961, 1
  store i8 %8962, i8* %14, align 1
  %8963 = icmp eq i64 %8948, 0
  %8964 = zext i1 %8963 to i8
  store i8 %8964, i8* %15, align 1
  %8965 = lshr i64 %8948, 63
  %8966 = trunc i64 %8965 to i8
  store i8 %8966, i8* %16, align 1
  %8967 = lshr i64 %8941, 63
  %8968 = lshr i64 %8946, 58
  %8969 = and i64 %8968, 1
  %8970 = xor i64 %8965, %8967
  %8971 = xor i64 %8965, %8969
  %8972 = add nuw nsw i64 %8970, %8971
  %8973 = icmp eq i64 %8972, 2
  %8974 = zext i1 %8973 to i8
  store i8 %8974, i8* %17, align 1
  %8975 = inttoptr i64 %8948 to i32*
  %8976 = add i64 %8937, 25
  store i64 %8976, i64* %3, align 8
  %8977 = load i32, i32* %8975, align 4
  %8978 = zext i32 %8977 to i64
  store i64 %8978, i64* %RDI.i4084, align 8
  %8979 = load i64, i64* %RBP.i, align 8
  %8980 = add i64 %8979, -24
  %8981 = add i64 %8937, 29
  store i64 %8981, i64* %3, align 8
  %8982 = inttoptr i64 %8980 to i32*
  %8983 = load i32, i32* %8982, align 4
  %8984 = sext i32 %8983 to i64
  %8985 = shl nsw i64 %8984, 5
  store i64 %8985, i64* %RDX.i4094, align 8
  %8986 = load i64, i64* %RCX.i3977, align 8
  %8987 = add i64 %8985, %8986
  store i64 %8987, i64* %RSI.i3950, align 8
  %8988 = icmp ult i64 %8987, %8986
  %8989 = icmp ult i64 %8987, %8985
  %8990 = or i1 %8988, %8989
  %8991 = zext i1 %8990 to i8
  store i8 %8991, i8* %12, align 1
  %8992 = trunc i64 %8987 to i32
  %8993 = and i32 %8992, 255
  %8994 = tail call i32 @llvm.ctpop.i32(i32 %8993)
  %8995 = trunc i32 %8994 to i8
  %8996 = and i8 %8995, 1
  %8997 = xor i8 %8996, 1
  store i8 %8997, i8* %13, align 1
  %8998 = xor i64 %8986, %8987
  %8999 = lshr i64 %8998, 4
  %9000 = trunc i64 %8999 to i8
  %9001 = and i8 %9000, 1
  store i8 %9001, i8* %14, align 1
  %9002 = icmp eq i64 %8987, 0
  %9003 = zext i1 %9002 to i8
  store i8 %9003, i8* %15, align 1
  %9004 = lshr i64 %8987, 63
  %9005 = trunc i64 %9004 to i8
  store i8 %9005, i8* %16, align 1
  %9006 = lshr i64 %8986, 63
  %9007 = lshr i64 %8984, 58
  %9008 = and i64 %9007, 1
  %9009 = xor i64 %9004, %9006
  %9010 = xor i64 %9004, %9008
  %9011 = add nuw nsw i64 %9009, %9010
  %9012 = icmp eq i64 %9011, 2
  %9013 = zext i1 %9012 to i8
  store i8 %9013, i8* %17, align 1
  %9014 = add i64 %8987, 16
  %9015 = add i64 %8937, 42
  store i64 %9015, i64* %3, align 8
  %9016 = inttoptr i64 %9014 to i32*
  %9017 = load i32, i32* %9016, align 4
  %9018 = add i32 %9017, %8977
  %9019 = zext i32 %9018 to i64
  store i64 %9019, i64* %RDI.i4084, align 8
  %9020 = icmp ult i32 %9018, %8977
  %9021 = icmp ult i32 %9018, %9017
  %9022 = or i1 %9020, %9021
  %9023 = zext i1 %9022 to i8
  store i8 %9023, i8* %12, align 1
  %9024 = and i32 %9018, 255
  %9025 = tail call i32 @llvm.ctpop.i32(i32 %9024)
  %9026 = trunc i32 %9025 to i8
  %9027 = and i8 %9026, 1
  %9028 = xor i8 %9027, 1
  store i8 %9028, i8* %13, align 1
  %9029 = xor i32 %9017, %8977
  %9030 = xor i32 %9029, %9018
  %9031 = lshr i32 %9030, 4
  %9032 = trunc i32 %9031 to i8
  %9033 = and i8 %9032, 1
  store i8 %9033, i8* %14, align 1
  %9034 = icmp eq i32 %9018, 0
  %9035 = zext i1 %9034 to i8
  store i8 %9035, i8* %15, align 1
  %9036 = lshr i32 %9018, 31
  %9037 = trunc i32 %9036 to i8
  store i8 %9037, i8* %16, align 1
  %9038 = lshr i32 %8977, 31
  %9039 = lshr i32 %9017, 31
  %9040 = xor i32 %9036, %9038
  %9041 = xor i32 %9036, %9039
  %9042 = add nuw nsw i32 %9040, %9041
  %9043 = icmp eq i32 %9042, 2
  %9044 = zext i1 %9043 to i8
  store i8 %9044, i8* %17, align 1
  %9045 = load i64, i64* %RBP.i, align 8
  %9046 = add i64 %9045, -640
  %9047 = add i64 %8937, 48
  store i64 %9047, i64* %3, align 8
  %9048 = inttoptr i64 %9046 to i32*
  store i32 %9018, i32* %9048, align 4
  %9049 = load i64, i64* %RBP.i, align 8
  %9050 = add i64 %9049, -24
  %9051 = load i64, i64* %3, align 8
  %9052 = add i64 %9051, 4
  store i64 %9052, i64* %3, align 8
  %9053 = inttoptr i64 %9050 to i32*
  %9054 = load i32, i32* %9053, align 4
  %9055 = sext i32 %9054 to i64
  %9056 = shl nsw i64 %9055, 5
  store i64 %9056, i64* %RDX.i4094, align 8
  %9057 = load i64, i64* %RCX.i3977, align 8
  %9058 = add i64 %9056, %9057
  store i64 %9058, i64* %RSI.i3950, align 8
  %9059 = icmp ult i64 %9058, %9057
  %9060 = icmp ult i64 %9058, %9056
  %9061 = or i1 %9059, %9060
  %9062 = zext i1 %9061 to i8
  store i8 %9062, i8* %12, align 1
  %9063 = trunc i64 %9058 to i32
  %9064 = and i32 %9063, 255
  %9065 = tail call i32 @llvm.ctpop.i32(i32 %9064)
  %9066 = trunc i32 %9065 to i8
  %9067 = and i8 %9066, 1
  %9068 = xor i8 %9067, 1
  store i8 %9068, i8* %13, align 1
  %9069 = xor i64 %9057, %9058
  %9070 = lshr i64 %9069, 4
  %9071 = trunc i64 %9070 to i8
  %9072 = and i8 %9071, 1
  store i8 %9072, i8* %14, align 1
  %9073 = icmp eq i64 %9058, 0
  %9074 = zext i1 %9073 to i8
  store i8 %9074, i8* %15, align 1
  %9075 = lshr i64 %9058, 63
  %9076 = trunc i64 %9075 to i8
  store i8 %9076, i8* %16, align 1
  %9077 = lshr i64 %9057, 63
  %9078 = lshr i64 %9055, 58
  %9079 = and i64 %9078, 1
  %9080 = xor i64 %9075, %9077
  %9081 = xor i64 %9075, %9079
  %9082 = add nuw nsw i64 %9080, %9081
  %9083 = icmp eq i64 %9082, 2
  %9084 = zext i1 %9083 to i8
  store i8 %9084, i8* %17, align 1
  %9085 = inttoptr i64 %9058 to i32*
  %9086 = add i64 %9051, 16
  store i64 %9086, i64* %3, align 8
  %9087 = load i32, i32* %9085, align 4
  %9088 = zext i32 %9087 to i64
  store i64 %9088, i64* %RDI.i4084, align 8
  %9089 = add i64 %9051, 20
  store i64 %9089, i64* %3, align 8
  %9090 = load i32, i32* %9053, align 4
  %9091 = sext i32 %9090 to i64
  %9092 = shl nsw i64 %9091, 5
  store i64 %9092, i64* %RDX.i4094, align 8
  %9093 = add i64 %9092, %9057
  store i64 %9093, i64* %RSI.i3950, align 8
  %9094 = icmp ult i64 %9093, %9057
  %9095 = icmp ult i64 %9093, %9092
  %9096 = or i1 %9094, %9095
  %9097 = zext i1 %9096 to i8
  store i8 %9097, i8* %12, align 1
  %9098 = trunc i64 %9093 to i32
  %9099 = and i32 %9098, 255
  %9100 = tail call i32 @llvm.ctpop.i32(i32 %9099)
  %9101 = trunc i32 %9100 to i8
  %9102 = and i8 %9101, 1
  %9103 = xor i8 %9102, 1
  store i8 %9103, i8* %13, align 1
  %9104 = xor i64 %9057, %9093
  %9105 = lshr i64 %9104, 4
  %9106 = trunc i64 %9105 to i8
  %9107 = and i8 %9106, 1
  store i8 %9107, i8* %14, align 1
  %9108 = icmp eq i64 %9093, 0
  %9109 = zext i1 %9108 to i8
  store i8 %9109, i8* %15, align 1
  %9110 = lshr i64 %9093, 63
  %9111 = trunc i64 %9110 to i8
  store i8 %9111, i8* %16, align 1
  %9112 = lshr i64 %9091, 58
  %9113 = and i64 %9112, 1
  %9114 = xor i64 %9110, %9077
  %9115 = xor i64 %9110, %9113
  %9116 = add nuw nsw i64 %9114, %9115
  %9117 = icmp eq i64 %9116, 2
  %9118 = zext i1 %9117 to i8
  store i8 %9118, i8* %17, align 1
  %9119 = add i64 %9093, 16
  %9120 = add i64 %9051, 33
  store i64 %9120, i64* %3, align 8
  %9121 = inttoptr i64 %9119 to i32*
  %9122 = load i32, i32* %9121, align 4
  %9123 = sub i32 %9087, %9122
  %9124 = zext i32 %9123 to i64
  store i64 %9124, i64* %RDI.i4084, align 8
  %9125 = icmp ult i32 %9087, %9122
  %9126 = zext i1 %9125 to i8
  store i8 %9126, i8* %12, align 1
  %9127 = and i32 %9123, 255
  %9128 = tail call i32 @llvm.ctpop.i32(i32 %9127)
  %9129 = trunc i32 %9128 to i8
  %9130 = and i8 %9129, 1
  %9131 = xor i8 %9130, 1
  store i8 %9131, i8* %13, align 1
  %9132 = xor i32 %9122, %9087
  %9133 = xor i32 %9132, %9123
  %9134 = lshr i32 %9133, 4
  %9135 = trunc i32 %9134 to i8
  %9136 = and i8 %9135, 1
  store i8 %9136, i8* %14, align 1
  %9137 = icmp eq i32 %9123, 0
  %9138 = zext i1 %9137 to i8
  store i8 %9138, i8* %15, align 1
  %9139 = lshr i32 %9123, 31
  %9140 = trunc i32 %9139 to i8
  store i8 %9140, i8* %16, align 1
  %9141 = lshr i32 %9087, 31
  %9142 = lshr i32 %9122, 31
  %9143 = xor i32 %9142, %9141
  %9144 = xor i32 %9139, %9141
  %9145 = add nuw nsw i32 %9144, %9143
  %9146 = icmp eq i32 %9145, 2
  %9147 = zext i1 %9146 to i8
  store i8 %9147, i8* %17, align 1
  %9148 = load i64, i64* %RBP.i, align 8
  %9149 = add i64 %9148, -624
  %9150 = add i64 %9051, 39
  store i64 %9150, i64* %3, align 8
  %9151 = inttoptr i64 %9149 to i32*
  store i32 %9123, i32* %9151, align 4
  %9152 = load i64, i64* %RBP.i, align 8
  %9153 = add i64 %9152, -24
  %9154 = load i64, i64* %3, align 8
  %9155 = add i64 %9154, 4
  store i64 %9155, i64* %3, align 8
  %9156 = inttoptr i64 %9153 to i32*
  %9157 = load i32, i32* %9156, align 4
  %9158 = sext i32 %9157 to i64
  %9159 = shl nsw i64 %9158, 5
  store i64 %9159, i64* %RDX.i4094, align 8
  %9160 = load i64, i64* %RCX.i3977, align 8
  %9161 = add i64 %9159, %9160
  store i64 %9161, i64* %RSI.i3950, align 8
  %9162 = icmp ult i64 %9161, %9160
  %9163 = icmp ult i64 %9161, %9159
  %9164 = or i1 %9162, %9163
  %9165 = zext i1 %9164 to i8
  store i8 %9165, i8* %12, align 1
  %9166 = trunc i64 %9161 to i32
  %9167 = and i32 %9166, 255
  %9168 = tail call i32 @llvm.ctpop.i32(i32 %9167)
  %9169 = trunc i32 %9168 to i8
  %9170 = and i8 %9169, 1
  %9171 = xor i8 %9170, 1
  store i8 %9171, i8* %13, align 1
  %9172 = xor i64 %9160, %9161
  %9173 = lshr i64 %9172, 4
  %9174 = trunc i64 %9173 to i8
  %9175 = and i8 %9174, 1
  store i8 %9175, i8* %14, align 1
  %9176 = icmp eq i64 %9161, 0
  %9177 = zext i1 %9176 to i8
  store i8 %9177, i8* %15, align 1
  %9178 = lshr i64 %9161, 63
  %9179 = trunc i64 %9178 to i8
  store i8 %9179, i8* %16, align 1
  %9180 = lshr i64 %9160, 63
  %9181 = lshr i64 %9158, 58
  %9182 = and i64 %9181, 1
  %9183 = xor i64 %9178, %9180
  %9184 = xor i64 %9178, %9182
  %9185 = add nuw nsw i64 %9183, %9184
  %9186 = icmp eq i64 %9185, 2
  %9187 = zext i1 %9186 to i8
  store i8 %9187, i8* %17, align 1
  %9188 = add i64 %9161, 8
  %9189 = add i64 %9154, 17
  store i64 %9189, i64* %3, align 8
  %9190 = inttoptr i64 %9188 to i32*
  %9191 = load i32, i32* %9190, align 4
  %9192 = zext i32 %9191 to i64
  %9193 = shl nuw i64 %9192, 32
  %9194 = ashr i64 %9193, 33
  %9195 = trunc i32 %9191 to i8
  %9196 = and i8 %9195, 1
  %9197 = trunc i64 %9194 to i32
  %9198 = and i64 %9194, 4294967295
  store i64 %9198, i64* %RDI.i4084, align 8
  store i8 %9196, i8* %12, align 1
  %9199 = and i32 %9197, 255
  %9200 = tail call i32 @llvm.ctpop.i32(i32 %9199)
  %9201 = trunc i32 %9200 to i8
  %9202 = and i8 %9201, 1
  %9203 = xor i8 %9202, 1
  store i8 %9203, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %9204 = icmp eq i32 %9197, 0
  %9205 = zext i1 %9204 to i8
  store i8 %9205, i8* %15, align 1
  %9206 = lshr i64 %9194, 31
  %9207 = trunc i64 %9206 to i8
  %9208 = and i8 %9207, 1
  store i8 %9208, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %9209 = load i64, i64* %RBP.i, align 8
  %9210 = add i64 %9209, -24
  %9211 = add i64 %9154, 23
  store i64 %9211, i64* %3, align 8
  %9212 = inttoptr i64 %9210 to i32*
  %9213 = load i32, i32* %9212, align 4
  %9214 = sext i32 %9213 to i64
  %9215 = shl nsw i64 %9214, 5
  store i64 %9215, i64* %RDX.i4094, align 8
  %9216 = load i64, i64* %RCX.i3977, align 8
  %9217 = add i64 %9215, %9216
  store i64 %9217, i64* %RSI.i3950, align 8
  %9218 = icmp ult i64 %9217, %9216
  %9219 = icmp ult i64 %9217, %9215
  %9220 = or i1 %9218, %9219
  %9221 = zext i1 %9220 to i8
  store i8 %9221, i8* %12, align 1
  %9222 = trunc i64 %9217 to i32
  %9223 = and i32 %9222, 255
  %9224 = tail call i32 @llvm.ctpop.i32(i32 %9223)
  %9225 = trunc i32 %9224 to i8
  %9226 = and i8 %9225, 1
  %9227 = xor i8 %9226, 1
  store i8 %9227, i8* %13, align 1
  %9228 = xor i64 %9216, %9217
  %9229 = lshr i64 %9228, 4
  %9230 = trunc i64 %9229 to i8
  %9231 = and i8 %9230, 1
  store i8 %9231, i8* %14, align 1
  %9232 = icmp eq i64 %9217, 0
  %9233 = zext i1 %9232 to i8
  store i8 %9233, i8* %15, align 1
  %9234 = lshr i64 %9217, 63
  %9235 = trunc i64 %9234 to i8
  store i8 %9235, i8* %16, align 1
  %9236 = lshr i64 %9216, 63
  %9237 = lshr i64 %9214, 58
  %9238 = and i64 %9237, 1
  %9239 = xor i64 %9234, %9236
  %9240 = xor i64 %9234, %9238
  %9241 = add nuw nsw i64 %9239, %9240
  %9242 = icmp eq i64 %9241, 2
  %9243 = zext i1 %9242 to i8
  store i8 %9243, i8* %17, align 1
  %9244 = add i64 %9217, 24
  %9245 = add i64 %9154, 36
  store i64 %9245, i64* %3, align 8
  %9246 = trunc i64 %9194 to i32
  %9247 = inttoptr i64 %9244 to i32*
  %9248 = load i32, i32* %9247, align 4
  %9249 = sub i32 %9246, %9248
  %9250 = zext i32 %9249 to i64
  store i64 %9250, i64* %RDI.i4084, align 8
  %9251 = icmp ult i32 %9246, %9248
  %9252 = zext i1 %9251 to i8
  store i8 %9252, i8* %12, align 1
  %9253 = and i32 %9249, 255
  %9254 = tail call i32 @llvm.ctpop.i32(i32 %9253)
  %9255 = trunc i32 %9254 to i8
  %9256 = and i8 %9255, 1
  %9257 = xor i8 %9256, 1
  store i8 %9257, i8* %13, align 1
  %9258 = xor i32 %9248, %9246
  %9259 = xor i32 %9258, %9249
  %9260 = lshr i32 %9259, 4
  %9261 = trunc i32 %9260 to i8
  %9262 = and i8 %9261, 1
  store i8 %9262, i8* %14, align 1
  %9263 = icmp eq i32 %9249, 0
  %9264 = zext i1 %9263 to i8
  store i8 %9264, i8* %15, align 1
  %9265 = lshr i32 %9249, 31
  %9266 = trunc i32 %9265 to i8
  store i8 %9266, i8* %16, align 1
  %9267 = lshr i64 %9194, 31
  %9268 = trunc i64 %9267 to i32
  %9269 = and i32 %9268, 1
  %9270 = lshr i32 %9248, 31
  %9271 = xor i32 %9270, %9269
  %9272 = xor i32 %9265, %9269
  %9273 = add nuw nsw i32 %9272, %9271
  %9274 = icmp eq i32 %9273, 2
  %9275 = zext i1 %9274 to i8
  store i8 %9275, i8* %17, align 1
  %9276 = load i64, i64* %RBP.i, align 8
  %9277 = add i64 %9276, -632
  %9278 = add i64 %9154, 42
  store i64 %9278, i64* %3, align 8
  %9279 = inttoptr i64 %9277 to i32*
  store i32 %9249, i32* %9279, align 4
  %9280 = load i64, i64* %RBP.i, align 8
  %9281 = add i64 %9280, -24
  %9282 = load i64, i64* %3, align 8
  %9283 = add i64 %9282, 4
  store i64 %9283, i64* %3, align 8
  %9284 = inttoptr i64 %9281 to i32*
  %9285 = load i32, i32* %9284, align 4
  %9286 = sext i32 %9285 to i64
  %9287 = shl nsw i64 %9286, 5
  store i64 %9287, i64* %RDX.i4094, align 8
  %9288 = load i64, i64* %RCX.i3977, align 8
  %9289 = add i64 %9287, %9288
  store i64 %9289, i64* %RSI.i3950, align 8
  %9290 = icmp ult i64 %9289, %9288
  %9291 = icmp ult i64 %9289, %9287
  %9292 = or i1 %9290, %9291
  %9293 = zext i1 %9292 to i8
  store i8 %9293, i8* %12, align 1
  %9294 = trunc i64 %9289 to i32
  %9295 = and i32 %9294, 255
  %9296 = tail call i32 @llvm.ctpop.i32(i32 %9295)
  %9297 = trunc i32 %9296 to i8
  %9298 = and i8 %9297, 1
  %9299 = xor i8 %9298, 1
  store i8 %9299, i8* %13, align 1
  %9300 = xor i64 %9288, %9289
  %9301 = lshr i64 %9300, 4
  %9302 = trunc i64 %9301 to i8
  %9303 = and i8 %9302, 1
  store i8 %9303, i8* %14, align 1
  %9304 = icmp eq i64 %9289, 0
  %9305 = zext i1 %9304 to i8
  store i8 %9305, i8* %15, align 1
  %9306 = lshr i64 %9289, 63
  %9307 = trunc i64 %9306 to i8
  store i8 %9307, i8* %16, align 1
  %9308 = lshr i64 %9288, 63
  %9309 = lshr i64 %9286, 58
  %9310 = and i64 %9309, 1
  %9311 = xor i64 %9306, %9308
  %9312 = xor i64 %9306, %9310
  %9313 = add nuw nsw i64 %9311, %9312
  %9314 = icmp eq i64 %9313, 2
  %9315 = zext i1 %9314 to i8
  store i8 %9315, i8* %17, align 1
  %9316 = add i64 %9289, 8
  %9317 = add i64 %9282, 17
  store i64 %9317, i64* %3, align 8
  %9318 = inttoptr i64 %9316 to i32*
  %9319 = load i32, i32* %9318, align 4
  %9320 = zext i32 %9319 to i64
  store i64 %9320, i64* %RDI.i4084, align 8
  %9321 = add i64 %9282, 21
  store i64 %9321, i64* %3, align 8
  %9322 = load i32, i32* %9284, align 4
  %9323 = sext i32 %9322 to i64
  %9324 = shl nsw i64 %9323, 5
  store i64 %9324, i64* %RDX.i4094, align 8
  %9325 = add i64 %9324, %9288
  store i64 %9325, i64* %RSI.i3950, align 8
  %9326 = icmp ult i64 %9325, %9288
  %9327 = icmp ult i64 %9325, %9324
  %9328 = or i1 %9326, %9327
  %9329 = zext i1 %9328 to i8
  store i8 %9329, i8* %12, align 1
  %9330 = trunc i64 %9325 to i32
  %9331 = and i32 %9330, 255
  %9332 = tail call i32 @llvm.ctpop.i32(i32 %9331)
  %9333 = trunc i32 %9332 to i8
  %9334 = and i8 %9333, 1
  %9335 = xor i8 %9334, 1
  store i8 %9335, i8* %13, align 1
  %9336 = xor i64 %9288, %9325
  %9337 = lshr i64 %9336, 4
  %9338 = trunc i64 %9337 to i8
  %9339 = and i8 %9338, 1
  store i8 %9339, i8* %14, align 1
  %9340 = icmp eq i64 %9325, 0
  %9341 = zext i1 %9340 to i8
  store i8 %9341, i8* %15, align 1
  %9342 = lshr i64 %9325, 63
  %9343 = trunc i64 %9342 to i8
  store i8 %9343, i8* %16, align 1
  %9344 = lshr i64 %9323, 58
  %9345 = and i64 %9344, 1
  %9346 = xor i64 %9342, %9308
  %9347 = xor i64 %9342, %9345
  %9348 = add nuw nsw i64 %9346, %9347
  %9349 = icmp eq i64 %9348, 2
  %9350 = zext i1 %9349 to i8
  store i8 %9350, i8* %17, align 1
  %9351 = add i64 %9325, 24
  %9352 = add i64 %9282, 35
  store i64 %9352, i64* %3, align 8
  %9353 = inttoptr i64 %9351 to i32*
  %9354 = load i32, i32* %9353, align 4
  %9355 = zext i32 %9354 to i64
  %9356 = shl nuw i64 %9355, 32
  %9357 = ashr i64 %9356, 33
  %9358 = and i64 %9357, 4294967295
  store i64 %9358, i64* %R8.i4051, align 8
  %9359 = load i64, i64* %RDI.i4084, align 8
  %9360 = trunc i64 %9357 to i32
  %9361 = trunc i64 %9359 to i32
  %9362 = add i32 %9360, %9361
  %9363 = zext i32 %9362 to i64
  store i64 %9363, i64* %RDI.i4084, align 8
  %9364 = icmp ult i32 %9362, %9361
  %9365 = icmp ult i32 %9362, %9360
  %9366 = or i1 %9364, %9365
  %9367 = zext i1 %9366 to i8
  store i8 %9367, i8* %12, align 1
  %9368 = and i32 %9362, 255
  %9369 = tail call i32 @llvm.ctpop.i32(i32 %9368)
  %9370 = trunc i32 %9369 to i8
  %9371 = and i8 %9370, 1
  %9372 = xor i8 %9371, 1
  store i8 %9372, i8* %13, align 1
  %9373 = xor i64 %9357, %9359
  %9374 = trunc i64 %9373 to i32
  %9375 = xor i32 %9374, %9362
  %9376 = lshr i32 %9375, 4
  %9377 = trunc i32 %9376 to i8
  %9378 = and i8 %9377, 1
  store i8 %9378, i8* %14, align 1
  %9379 = icmp eq i32 %9362, 0
  %9380 = zext i1 %9379 to i8
  store i8 %9380, i8* %15, align 1
  %9381 = lshr i32 %9362, 31
  %9382 = trunc i32 %9381 to i8
  store i8 %9382, i8* %16, align 1
  %9383 = lshr i32 %9361, 31
  %9384 = lshr i64 %9357, 31
  %9385 = trunc i64 %9384 to i32
  %9386 = and i32 %9385, 1
  %9387 = xor i32 %9381, %9383
  %9388 = xor i32 %9381, %9386
  %9389 = add nuw nsw i32 %9387, %9388
  %9390 = icmp eq i32 %9389, 2
  %9391 = zext i1 %9390 to i8
  store i8 %9391, i8* %17, align 1
  %9392 = load i64, i64* %RBP.i, align 8
  %9393 = add i64 %9392, -616
  %9394 = add i64 %9282, 47
  store i64 %9394, i64* %3, align 8
  %9395 = inttoptr i64 %9393 to i32*
  store i32 %9362, i32* %9395, align 4
  %9396 = load i64, i64* %RBP.i, align 8
  %9397 = add i64 %9396, -640
  %9398 = load i64, i64* %3, align 8
  %9399 = add i64 %9398, 6
  store i64 %9399, i64* %3, align 8
  %9400 = inttoptr i64 %9397 to i32*
  %9401 = load i32, i32* %9400, align 4
  %9402 = zext i32 %9401 to i64
  store i64 %9402, i64* %RDI.i4084, align 8
  %9403 = add i64 %9396, -616
  %9404 = add i64 %9398, 12
  store i64 %9404, i64* %3, align 8
  %9405 = inttoptr i64 %9403 to i32*
  %9406 = load i32, i32* %9405, align 4
  %9407 = add i32 %9406, %9401
  %9408 = zext i32 %9407 to i64
  store i64 %9408, i64* %RDI.i4084, align 8
  %9409 = icmp ult i32 %9407, %9401
  %9410 = icmp ult i32 %9407, %9406
  %9411 = or i1 %9409, %9410
  %9412 = zext i1 %9411 to i8
  store i8 %9412, i8* %12, align 1
  %9413 = and i32 %9407, 255
  %9414 = tail call i32 @llvm.ctpop.i32(i32 %9413)
  %9415 = trunc i32 %9414 to i8
  %9416 = and i8 %9415, 1
  %9417 = xor i8 %9416, 1
  store i8 %9417, i8* %13, align 1
  %9418 = xor i32 %9406, %9401
  %9419 = xor i32 %9418, %9407
  %9420 = lshr i32 %9419, 4
  %9421 = trunc i32 %9420 to i8
  %9422 = and i8 %9421, 1
  store i8 %9422, i8* %14, align 1
  %9423 = icmp eq i32 %9407, 0
  %9424 = zext i1 %9423 to i8
  store i8 %9424, i8* %15, align 1
  %9425 = lshr i32 %9407, 31
  %9426 = trunc i32 %9425 to i8
  store i8 %9426, i8* %16, align 1
  %9427 = lshr i32 %9401, 31
  %9428 = lshr i32 %9406, 31
  %9429 = xor i32 %9425, %9427
  %9430 = xor i32 %9425, %9428
  %9431 = add nuw nsw i32 %9429, %9430
  %9432 = icmp eq i32 %9431, 2
  %9433 = zext i1 %9432 to i8
  store i8 %9433, i8* %17, align 1
  %9434 = add i64 %9396, -672
  %9435 = add i64 %9398, 18
  store i64 %9435, i64* %3, align 8
  %9436 = inttoptr i64 %9434 to i32*
  store i32 %9407, i32* %9436, align 4
  %9437 = load i64, i64* %RBP.i, align 8
  %9438 = add i64 %9437, -624
  %9439 = load i64, i64* %3, align 8
  %9440 = add i64 %9439, 6
  store i64 %9440, i64* %3, align 8
  %9441 = inttoptr i64 %9438 to i32*
  %9442 = load i32, i32* %9441, align 4
  %9443 = zext i32 %9442 to i64
  store i64 %9443, i64* %RDI.i4084, align 8
  %9444 = add i64 %9437, -632
  %9445 = add i64 %9439, 12
  store i64 %9445, i64* %3, align 8
  %9446 = inttoptr i64 %9444 to i32*
  %9447 = load i32, i32* %9446, align 4
  %9448 = add i32 %9447, %9442
  %9449 = zext i32 %9448 to i64
  store i64 %9449, i64* %RDI.i4084, align 8
  %9450 = icmp ult i32 %9448, %9442
  %9451 = icmp ult i32 %9448, %9447
  %9452 = or i1 %9450, %9451
  %9453 = zext i1 %9452 to i8
  store i8 %9453, i8* %12, align 1
  %9454 = and i32 %9448, 255
  %9455 = tail call i32 @llvm.ctpop.i32(i32 %9454)
  %9456 = trunc i32 %9455 to i8
  %9457 = and i8 %9456, 1
  %9458 = xor i8 %9457, 1
  store i8 %9458, i8* %13, align 1
  %9459 = xor i32 %9447, %9442
  %9460 = xor i32 %9459, %9448
  %9461 = lshr i32 %9460, 4
  %9462 = trunc i32 %9461 to i8
  %9463 = and i8 %9462, 1
  store i8 %9463, i8* %14, align 1
  %9464 = icmp eq i32 %9448, 0
  %9465 = zext i1 %9464 to i8
  store i8 %9465, i8* %15, align 1
  %9466 = lshr i32 %9448, 31
  %9467 = trunc i32 %9466 to i8
  store i8 %9467, i8* %16, align 1
  %9468 = lshr i32 %9442, 31
  %9469 = lshr i32 %9447, 31
  %9470 = xor i32 %9466, %9468
  %9471 = xor i32 %9466, %9469
  %9472 = add nuw nsw i32 %9470, %9471
  %9473 = icmp eq i32 %9472, 2
  %9474 = zext i1 %9473 to i8
  store i8 %9474, i8* %17, align 1
  %9475 = add i64 %9437, -664
  %9476 = add i64 %9439, 18
  store i64 %9476, i64* %3, align 8
  %9477 = inttoptr i64 %9475 to i32*
  store i32 %9448, i32* %9477, align 4
  %9478 = load i64, i64* %RBP.i, align 8
  %9479 = add i64 %9478, -624
  %9480 = load i64, i64* %3, align 8
  %9481 = add i64 %9480, 6
  store i64 %9481, i64* %3, align 8
  %9482 = inttoptr i64 %9479 to i32*
  %9483 = load i32, i32* %9482, align 4
  %9484 = zext i32 %9483 to i64
  store i64 %9484, i64* %RDI.i4084, align 8
  %9485 = add i64 %9478, -632
  %9486 = add i64 %9480, 12
  store i64 %9486, i64* %3, align 8
  %9487 = inttoptr i64 %9485 to i32*
  %9488 = load i32, i32* %9487, align 4
  %9489 = sub i32 %9483, %9488
  %9490 = zext i32 %9489 to i64
  store i64 %9490, i64* %RDI.i4084, align 8
  %9491 = icmp ult i32 %9483, %9488
  %9492 = zext i1 %9491 to i8
  store i8 %9492, i8* %12, align 1
  %9493 = and i32 %9489, 255
  %9494 = tail call i32 @llvm.ctpop.i32(i32 %9493)
  %9495 = trunc i32 %9494 to i8
  %9496 = and i8 %9495, 1
  %9497 = xor i8 %9496, 1
  store i8 %9497, i8* %13, align 1
  %9498 = xor i32 %9488, %9483
  %9499 = xor i32 %9498, %9489
  %9500 = lshr i32 %9499, 4
  %9501 = trunc i32 %9500 to i8
  %9502 = and i8 %9501, 1
  store i8 %9502, i8* %14, align 1
  %9503 = icmp eq i32 %9489, 0
  %9504 = zext i1 %9503 to i8
  store i8 %9504, i8* %15, align 1
  %9505 = lshr i32 %9489, 31
  %9506 = trunc i32 %9505 to i8
  store i8 %9506, i8* %16, align 1
  %9507 = lshr i32 %9483, 31
  %9508 = lshr i32 %9488, 31
  %9509 = xor i32 %9508, %9507
  %9510 = xor i32 %9505, %9507
  %9511 = add nuw nsw i32 %9510, %9509
  %9512 = icmp eq i32 %9511, 2
  %9513 = zext i1 %9512 to i8
  store i8 %9513, i8* %17, align 1
  %9514 = add i64 %9478, -656
  %9515 = add i64 %9480, 18
  store i64 %9515, i64* %3, align 8
  %9516 = inttoptr i64 %9514 to i32*
  store i32 %9489, i32* %9516, align 4
  %9517 = load i64, i64* %RBP.i, align 8
  %9518 = add i64 %9517, -640
  %9519 = load i64, i64* %3, align 8
  %9520 = add i64 %9519, 6
  store i64 %9520, i64* %3, align 8
  %9521 = inttoptr i64 %9518 to i32*
  %9522 = load i32, i32* %9521, align 4
  %9523 = zext i32 %9522 to i64
  store i64 %9523, i64* %RDI.i4084, align 8
  %9524 = add i64 %9517, -616
  %9525 = add i64 %9519, 12
  store i64 %9525, i64* %3, align 8
  %9526 = inttoptr i64 %9524 to i32*
  %9527 = load i32, i32* %9526, align 4
  %9528 = sub i32 %9522, %9527
  %9529 = zext i32 %9528 to i64
  store i64 %9529, i64* %RDI.i4084, align 8
  %9530 = icmp ult i32 %9522, %9527
  %9531 = zext i1 %9530 to i8
  store i8 %9531, i8* %12, align 1
  %9532 = and i32 %9528, 255
  %9533 = tail call i32 @llvm.ctpop.i32(i32 %9532)
  %9534 = trunc i32 %9533 to i8
  %9535 = and i8 %9534, 1
  %9536 = xor i8 %9535, 1
  store i8 %9536, i8* %13, align 1
  %9537 = xor i32 %9527, %9522
  %9538 = xor i32 %9537, %9528
  %9539 = lshr i32 %9538, 4
  %9540 = trunc i32 %9539 to i8
  %9541 = and i8 %9540, 1
  store i8 %9541, i8* %14, align 1
  %9542 = icmp eq i32 %9528, 0
  %9543 = zext i1 %9542 to i8
  store i8 %9543, i8* %15, align 1
  %9544 = lshr i32 %9528, 31
  %9545 = trunc i32 %9544 to i8
  store i8 %9545, i8* %16, align 1
  %9546 = lshr i32 %9522, 31
  %9547 = lshr i32 %9527, 31
  %9548 = xor i32 %9547, %9546
  %9549 = xor i32 %9544, %9546
  %9550 = add nuw nsw i32 %9549, %9548
  %9551 = icmp eq i32 %9550, 2
  %9552 = zext i1 %9551 to i8
  store i8 %9552, i8* %17, align 1
  %9553 = add i64 %9517, -648
  %9554 = add i64 %9519, 18
  store i64 %9554, i64* %3, align 8
  %9555 = inttoptr i64 %9553 to i32*
  store i32 %9528, i32* %9555, align 4
  %9556 = load i64, i64* %RBP.i, align 8
  %9557 = add i64 %9556, -24
  %9558 = load i64, i64* %3, align 8
  %9559 = add i64 %9558, 4
  store i64 %9559, i64* %3, align 8
  %9560 = inttoptr i64 %9557 to i32*
  %9561 = load i32, i32* %9560, align 4
  %9562 = sext i32 %9561 to i64
  %9563 = shl nsw i64 %9562, 5
  store i64 %9563, i64* %RDX.i4094, align 8
  %9564 = load i64, i64* %RCX.i3977, align 8
  %9565 = add i64 %9563, %9564
  store i64 %9565, i64* %RSI.i3950, align 8
  %9566 = icmp ult i64 %9565, %9564
  %9567 = icmp ult i64 %9565, %9563
  %9568 = or i1 %9566, %9567
  %9569 = zext i1 %9568 to i8
  store i8 %9569, i8* %12, align 1
  %9570 = trunc i64 %9565 to i32
  %9571 = and i32 %9570, 255
  %9572 = tail call i32 @llvm.ctpop.i32(i32 %9571)
  %9573 = trunc i32 %9572 to i8
  %9574 = and i8 %9573, 1
  %9575 = xor i8 %9574, 1
  store i8 %9575, i8* %13, align 1
  %9576 = xor i64 %9564, %9565
  %9577 = lshr i64 %9576, 4
  %9578 = trunc i64 %9577 to i8
  %9579 = and i8 %9578, 1
  store i8 %9579, i8* %14, align 1
  %9580 = icmp eq i64 %9565, 0
  %9581 = zext i1 %9580 to i8
  store i8 %9581, i8* %15, align 1
  %9582 = lshr i64 %9565, 63
  %9583 = trunc i64 %9582 to i8
  store i8 %9583, i8* %16, align 1
  %9584 = lshr i64 %9564, 63
  %9585 = lshr i64 %9562, 58
  %9586 = and i64 %9585, 1
  %9587 = xor i64 %9582, %9584
  %9588 = xor i64 %9582, %9586
  %9589 = add nuw nsw i64 %9587, %9588
  %9590 = icmp eq i64 %9589, 2
  %9591 = zext i1 %9590 to i8
  store i8 %9591, i8* %17, align 1
  %9592 = load i32, i32* %EAX.i2609, align 4
  %9593 = zext i32 %9592 to i64
  store i64 %9593, i64* %RDI.i4084, align 8
  %9594 = add i64 %9565, 12
  %9595 = add i64 %9558, 19
  store i64 %9595, i64* %3, align 8
  %9596 = inttoptr i64 %9594 to i32*
  %9597 = load i32, i32* %9596, align 4
  %9598 = sub i32 %9592, %9597
  %9599 = zext i32 %9598 to i64
  store i64 %9599, i64* %RDI.i4084, align 8
  %9600 = icmp ult i32 %9592, %9597
  %9601 = zext i1 %9600 to i8
  store i8 %9601, i8* %12, align 1
  %9602 = and i32 %9598, 255
  %9603 = tail call i32 @llvm.ctpop.i32(i32 %9602)
  %9604 = trunc i32 %9603 to i8
  %9605 = and i8 %9604, 1
  %9606 = xor i8 %9605, 1
  store i8 %9606, i8* %13, align 1
  %9607 = xor i32 %9597, %9592
  %9608 = xor i32 %9607, %9598
  %9609 = lshr i32 %9608, 4
  %9610 = trunc i32 %9609 to i8
  %9611 = and i8 %9610, 1
  store i8 %9611, i8* %14, align 1
  %9612 = icmp eq i32 %9598, 0
  %9613 = zext i1 %9612 to i8
  store i8 %9613, i8* %15, align 1
  %9614 = lshr i32 %9598, 31
  %9615 = trunc i32 %9614 to i8
  store i8 %9615, i8* %16, align 1
  %9616 = lshr i32 %9592, 31
  %9617 = lshr i32 %9597, 31
  %9618 = xor i32 %9617, %9616
  %9619 = xor i32 %9614, %9616
  %9620 = add nuw nsw i32 %9619, %9618
  %9621 = icmp eq i32 %9620, 2
  %9622 = zext i1 %9621 to i8
  store i8 %9622, i8* %17, align 1
  %9623 = load i64, i64* %RBP.i, align 8
  %9624 = add i64 %9623, -24
  %9625 = add i64 %9558, 23
  store i64 %9625, i64* %3, align 8
  %9626 = inttoptr i64 %9624 to i32*
  %9627 = load i32, i32* %9626, align 4
  %9628 = sext i32 %9627 to i64
  %9629 = shl nsw i64 %9628, 5
  store i64 %9629, i64* %RDX.i4094, align 8
  %9630 = load i64, i64* %RCX.i3977, align 8
  %9631 = add i64 %9629, %9630
  store i64 %9631, i64* %RSI.i3950, align 8
  %9632 = icmp ult i64 %9631, %9630
  %9633 = icmp ult i64 %9631, %9629
  %9634 = or i1 %9632, %9633
  %9635 = zext i1 %9634 to i8
  store i8 %9635, i8* %12, align 1
  %9636 = trunc i64 %9631 to i32
  %9637 = and i32 %9636, 255
  %9638 = tail call i32 @llvm.ctpop.i32(i32 %9637)
  %9639 = trunc i32 %9638 to i8
  %9640 = and i8 %9639, 1
  %9641 = xor i8 %9640, 1
  store i8 %9641, i8* %13, align 1
  %9642 = xor i64 %9630, %9631
  %9643 = lshr i64 %9642, 4
  %9644 = trunc i64 %9643 to i8
  %9645 = and i8 %9644, 1
  store i8 %9645, i8* %14, align 1
  %9646 = icmp eq i64 %9631, 0
  %9647 = zext i1 %9646 to i8
  store i8 %9647, i8* %15, align 1
  %9648 = lshr i64 %9631, 63
  %9649 = trunc i64 %9648 to i8
  store i8 %9649, i8* %16, align 1
  %9650 = lshr i64 %9630, 63
  %9651 = lshr i64 %9628, 58
  %9652 = and i64 %9651, 1
  %9653 = xor i64 %9648, %9650
  %9654 = xor i64 %9648, %9652
  %9655 = add nuw nsw i64 %9653, %9654
  %9656 = icmp eq i64 %9655, 2
  %9657 = zext i1 %9656 to i8
  store i8 %9657, i8* %17, align 1
  %9658 = load i64, i64* %RDI.i4084, align 8
  %9659 = add i64 %9631, 20
  %9660 = add i64 %9558, 36
  store i64 %9660, i64* %3, align 8
  %9661 = trunc i64 %9658 to i32
  %9662 = inttoptr i64 %9659 to i32*
  %9663 = load i32, i32* %9662, align 4
  %9664 = add i32 %9663, %9661
  %9665 = zext i32 %9664 to i64
  store i64 %9665, i64* %RDI.i4084, align 8
  %9666 = icmp ult i32 %9664, %9661
  %9667 = icmp ult i32 %9664, %9663
  %9668 = or i1 %9666, %9667
  %9669 = zext i1 %9668 to i8
  store i8 %9669, i8* %12, align 1
  %9670 = and i32 %9664, 255
  %9671 = tail call i32 @llvm.ctpop.i32(i32 %9670)
  %9672 = trunc i32 %9671 to i8
  %9673 = and i8 %9672, 1
  %9674 = xor i8 %9673, 1
  store i8 %9674, i8* %13, align 1
  %9675 = xor i32 %9663, %9661
  %9676 = xor i32 %9675, %9664
  %9677 = lshr i32 %9676, 4
  %9678 = trunc i32 %9677 to i8
  %9679 = and i8 %9678, 1
  store i8 %9679, i8* %14, align 1
  %9680 = icmp eq i32 %9664, 0
  %9681 = zext i1 %9680 to i8
  store i8 %9681, i8* %15, align 1
  %9682 = lshr i32 %9664, 31
  %9683 = trunc i32 %9682 to i8
  store i8 %9683, i8* %16, align 1
  %9684 = lshr i32 %9661, 31
  %9685 = lshr i32 %9663, 31
  %9686 = xor i32 %9682, %9684
  %9687 = xor i32 %9682, %9685
  %9688 = add nuw nsw i32 %9686, %9687
  %9689 = icmp eq i32 %9688, 2
  %9690 = zext i1 %9689 to i8
  store i8 %9690, i8* %17, align 1
  %9691 = load i64, i64* %RBP.i, align 8
  %9692 = add i64 %9691, -24
  %9693 = add i64 %9558, 40
  store i64 %9693, i64* %3, align 8
  %9694 = inttoptr i64 %9692 to i32*
  %9695 = load i32, i32* %9694, align 4
  %9696 = sext i32 %9695 to i64
  %9697 = shl nsw i64 %9696, 5
  store i64 %9697, i64* %RDX.i4094, align 8
  %9698 = load i64, i64* %RCX.i3977, align 8
  %9699 = add i64 %9697, %9698
  store i64 %9699, i64* %RSI.i3950, align 8
  %9700 = icmp ult i64 %9699, %9698
  %9701 = icmp ult i64 %9699, %9697
  %9702 = or i1 %9700, %9701
  %9703 = zext i1 %9702 to i8
  store i8 %9703, i8* %12, align 1
  %9704 = trunc i64 %9699 to i32
  %9705 = and i32 %9704, 255
  %9706 = tail call i32 @llvm.ctpop.i32(i32 %9705)
  %9707 = trunc i32 %9706 to i8
  %9708 = and i8 %9707, 1
  %9709 = xor i8 %9708, 1
  store i8 %9709, i8* %13, align 1
  %9710 = xor i64 %9698, %9699
  %9711 = lshr i64 %9710, 4
  %9712 = trunc i64 %9711 to i8
  %9713 = and i8 %9712, 1
  store i8 %9713, i8* %14, align 1
  %9714 = icmp eq i64 %9699, 0
  %9715 = zext i1 %9714 to i8
  store i8 %9715, i8* %15, align 1
  %9716 = lshr i64 %9699, 63
  %9717 = trunc i64 %9716 to i8
  store i8 %9717, i8* %16, align 1
  %9718 = lshr i64 %9698, 63
  %9719 = lshr i64 %9696, 58
  %9720 = and i64 %9719, 1
  %9721 = xor i64 %9716, %9718
  %9722 = xor i64 %9716, %9720
  %9723 = add nuw nsw i64 %9721, %9722
  %9724 = icmp eq i64 %9723, 2
  %9725 = zext i1 %9724 to i8
  store i8 %9725, i8* %17, align 1
  %9726 = load i64, i64* %RDI.i4084, align 8
  %9727 = add i64 %9699, 28
  %9728 = add i64 %9558, 53
  store i64 %9728, i64* %3, align 8
  %9729 = trunc i64 %9726 to i32
  %9730 = inttoptr i64 %9727 to i32*
  %9731 = load i32, i32* %9730, align 4
  %9732 = sub i32 %9729, %9731
  %9733 = zext i32 %9732 to i64
  store i64 %9733, i64* %RDI.i4084, align 8
  %9734 = icmp ult i32 %9729, %9731
  %9735 = zext i1 %9734 to i8
  store i8 %9735, i8* %12, align 1
  %9736 = and i32 %9732, 255
  %9737 = tail call i32 @llvm.ctpop.i32(i32 %9736)
  %9738 = trunc i32 %9737 to i8
  %9739 = and i8 %9738, 1
  %9740 = xor i8 %9739, 1
  store i8 %9740, i8* %13, align 1
  %9741 = xor i32 %9731, %9729
  %9742 = xor i32 %9741, %9732
  %9743 = lshr i32 %9742, 4
  %9744 = trunc i32 %9743 to i8
  %9745 = and i8 %9744, 1
  store i8 %9745, i8* %14, align 1
  %9746 = icmp eq i32 %9732, 0
  %9747 = zext i1 %9746 to i8
  store i8 %9747, i8* %15, align 1
  %9748 = lshr i32 %9732, 31
  %9749 = trunc i32 %9748 to i8
  store i8 %9749, i8* %16, align 1
  %9750 = lshr i32 %9729, 31
  %9751 = lshr i32 %9731, 31
  %9752 = xor i32 %9751, %9750
  %9753 = xor i32 %9748, %9750
  %9754 = add nuw nsw i32 %9753, %9752
  %9755 = icmp eq i32 %9754, 2
  %9756 = zext i1 %9755 to i8
  store i8 %9756, i8* %17, align 1
  %9757 = load i64, i64* %RBP.i, align 8
  %9758 = add i64 %9757, -24
  %9759 = add i64 %9558, 57
  store i64 %9759, i64* %3, align 8
  %9760 = inttoptr i64 %9758 to i32*
  %9761 = load i32, i32* %9760, align 4
  %9762 = sext i32 %9761 to i64
  %9763 = shl nsw i64 %9762, 5
  store i64 %9763, i64* %RDX.i4094, align 8
  %9764 = load i64, i64* %RCX.i3977, align 8
  %9765 = add i64 %9763, %9764
  store i64 %9765, i64* %RSI.i3950, align 8
  %9766 = icmp ult i64 %9765, %9764
  %9767 = icmp ult i64 %9765, %9763
  %9768 = or i1 %9766, %9767
  %9769 = zext i1 %9768 to i8
  store i8 %9769, i8* %12, align 1
  %9770 = trunc i64 %9765 to i32
  %9771 = and i32 %9770, 255
  %9772 = tail call i32 @llvm.ctpop.i32(i32 %9771)
  %9773 = trunc i32 %9772 to i8
  %9774 = and i8 %9773, 1
  %9775 = xor i8 %9774, 1
  store i8 %9775, i8* %13, align 1
  %9776 = xor i64 %9764, %9765
  %9777 = lshr i64 %9776, 4
  %9778 = trunc i64 %9777 to i8
  %9779 = and i8 %9778, 1
  store i8 %9779, i8* %14, align 1
  %9780 = icmp eq i64 %9765, 0
  %9781 = zext i1 %9780 to i8
  store i8 %9781, i8* %15, align 1
  %9782 = lshr i64 %9765, 63
  %9783 = trunc i64 %9782 to i8
  store i8 %9783, i8* %16, align 1
  %9784 = lshr i64 %9764, 63
  %9785 = lshr i64 %9762, 58
  %9786 = and i64 %9785, 1
  %9787 = xor i64 %9782, %9784
  %9788 = xor i64 %9782, %9786
  %9789 = add nuw nsw i64 %9787, %9788
  %9790 = icmp eq i64 %9789, 2
  %9791 = zext i1 %9790 to i8
  store i8 %9791, i8* %17, align 1
  %9792 = add i64 %9765, 28
  %9793 = add i64 %9558, 71
  store i64 %9793, i64* %3, align 8
  %9794 = inttoptr i64 %9792 to i32*
  %9795 = load i32, i32* %9794, align 4
  %9796 = zext i32 %9795 to i64
  %9797 = shl nuw i64 %9796, 32
  %9798 = ashr i64 %9797, 33
  %9799 = and i64 %9798, 4294967295
  store i64 %9799, i64* %R8.i4051, align 8
  %9800 = load i64, i64* %RDI.i4084, align 8
  %9801 = trunc i64 %9798 to i32
  %9802 = trunc i64 %9800 to i32
  %9803 = sub i32 %9802, %9801
  %9804 = zext i32 %9803 to i64
  store i64 %9804, i64* %RDI.i4084, align 8
  %9805 = icmp ult i32 %9802, %9801
  %9806 = zext i1 %9805 to i8
  store i8 %9806, i8* %12, align 1
  %9807 = and i32 %9803, 255
  %9808 = tail call i32 @llvm.ctpop.i32(i32 %9807)
  %9809 = trunc i32 %9808 to i8
  %9810 = and i8 %9809, 1
  %9811 = xor i8 %9810, 1
  store i8 %9811, i8* %13, align 1
  %9812 = xor i64 %9798, %9800
  %9813 = trunc i64 %9812 to i32
  %9814 = xor i32 %9813, %9803
  %9815 = lshr i32 %9814, 4
  %9816 = trunc i32 %9815 to i8
  %9817 = and i8 %9816, 1
  store i8 %9817, i8* %14, align 1
  %9818 = icmp eq i32 %9803, 0
  %9819 = zext i1 %9818 to i8
  store i8 %9819, i8* %15, align 1
  %9820 = lshr i32 %9803, 31
  %9821 = trunc i32 %9820 to i8
  store i8 %9821, i8* %16, align 1
  %9822 = lshr i32 %9802, 31
  %9823 = lshr i64 %9798, 31
  %9824 = trunc i64 %9823 to i32
  %9825 = and i32 %9824, 1
  %9826 = xor i32 %9825, %9822
  %9827 = xor i32 %9820, %9822
  %9828 = add nuw nsw i32 %9827, %9826
  %9829 = icmp eq i32 %9828, 2
  %9830 = zext i1 %9829 to i8
  store i8 %9830, i8* %17, align 1
  %9831 = load i64, i64* %RBP.i, align 8
  %9832 = add i64 %9831, -636
  %9833 = add i64 %9558, 83
  store i64 %9833, i64* %3, align 8
  %9834 = inttoptr i64 %9832 to i32*
  store i32 %9803, i32* %9834, align 4
  %9835 = load i64, i64* %RBP.i, align 8
  %9836 = add i64 %9835, -24
  %9837 = load i64, i64* %3, align 8
  %9838 = add i64 %9837, 4
  store i64 %9838, i64* %3, align 8
  %9839 = inttoptr i64 %9836 to i32*
  %9840 = load i32, i32* %9839, align 4
  %9841 = sext i32 %9840 to i64
  %9842 = shl nsw i64 %9841, 5
  store i64 %9842, i64* %RDX.i4094, align 8
  %9843 = load i64, i64* %RCX.i3977, align 8
  %9844 = add i64 %9842, %9843
  store i64 %9844, i64* %RSI.i3950, align 8
  %9845 = icmp ult i64 %9844, %9843
  %9846 = icmp ult i64 %9844, %9842
  %9847 = or i1 %9845, %9846
  %9848 = zext i1 %9847 to i8
  store i8 %9848, i8* %12, align 1
  %9849 = trunc i64 %9844 to i32
  %9850 = and i32 %9849, 255
  %9851 = tail call i32 @llvm.ctpop.i32(i32 %9850)
  %9852 = trunc i32 %9851 to i8
  %9853 = and i8 %9852, 1
  %9854 = xor i8 %9853, 1
  store i8 %9854, i8* %13, align 1
  %9855 = xor i64 %9843, %9844
  %9856 = lshr i64 %9855, 4
  %9857 = trunc i64 %9856 to i8
  %9858 = and i8 %9857, 1
  store i8 %9858, i8* %14, align 1
  %9859 = icmp eq i64 %9844, 0
  %9860 = zext i1 %9859 to i8
  store i8 %9860, i8* %15, align 1
  %9861 = lshr i64 %9844, 63
  %9862 = trunc i64 %9861 to i8
  store i8 %9862, i8* %16, align 1
  %9863 = lshr i64 %9843, 63
  %9864 = lshr i64 %9841, 58
  %9865 = and i64 %9864, 1
  %9866 = xor i64 %9861, %9863
  %9867 = xor i64 %9861, %9865
  %9868 = add nuw nsw i64 %9866, %9867
  %9869 = icmp eq i64 %9868, 2
  %9870 = zext i1 %9869 to i8
  store i8 %9870, i8* %17, align 1
  %9871 = add i64 %9844, 4
  %9872 = add i64 %9837, 17
  store i64 %9872, i64* %3, align 8
  %9873 = inttoptr i64 %9871 to i32*
  %9874 = load i32, i32* %9873, align 4
  %9875 = zext i32 %9874 to i64
  store i64 %9875, i64* %RDI.i4084, align 8
  %9876 = add i64 %9837, 21
  store i64 %9876, i64* %3, align 8
  %9877 = load i32, i32* %9839, align 4
  %9878 = sext i32 %9877 to i64
  %9879 = shl nsw i64 %9878, 5
  store i64 %9879, i64* %RDX.i4094, align 8
  %9880 = add i64 %9879, %9843
  store i64 %9880, i64* %RSI.i3950, align 8
  %9881 = icmp ult i64 %9880, %9843
  %9882 = icmp ult i64 %9880, %9879
  %9883 = or i1 %9881, %9882
  %9884 = zext i1 %9883 to i8
  store i8 %9884, i8* %12, align 1
  %9885 = trunc i64 %9880 to i32
  %9886 = and i32 %9885, 255
  %9887 = tail call i32 @llvm.ctpop.i32(i32 %9886)
  %9888 = trunc i32 %9887 to i8
  %9889 = and i8 %9888, 1
  %9890 = xor i8 %9889, 1
  store i8 %9890, i8* %13, align 1
  %9891 = xor i64 %9843, %9880
  %9892 = lshr i64 %9891, 4
  %9893 = trunc i64 %9892 to i8
  %9894 = and i8 %9893, 1
  store i8 %9894, i8* %14, align 1
  %9895 = icmp eq i64 %9880, 0
  %9896 = zext i1 %9895 to i8
  store i8 %9896, i8* %15, align 1
  %9897 = lshr i64 %9880, 63
  %9898 = trunc i64 %9897 to i8
  store i8 %9898, i8* %16, align 1
  %9899 = lshr i64 %9878, 58
  %9900 = and i64 %9899, 1
  %9901 = xor i64 %9897, %9863
  %9902 = xor i64 %9897, %9900
  %9903 = add nuw nsw i64 %9901, %9902
  %9904 = icmp eq i64 %9903, 2
  %9905 = zext i1 %9904 to i8
  store i8 %9905, i8* %17, align 1
  %9906 = add i64 %9880, 28
  %9907 = add i64 %9837, 34
  store i64 %9907, i64* %3, align 8
  %9908 = inttoptr i64 %9906 to i32*
  %9909 = load i32, i32* %9908, align 4
  %9910 = add i32 %9909, %9874
  %9911 = zext i32 %9910 to i64
  store i64 %9911, i64* %RDI.i4084, align 8
  %9912 = icmp ult i32 %9910, %9874
  %9913 = icmp ult i32 %9910, %9909
  %9914 = or i1 %9912, %9913
  %9915 = zext i1 %9914 to i8
  store i8 %9915, i8* %12, align 1
  %9916 = and i32 %9910, 255
  %9917 = tail call i32 @llvm.ctpop.i32(i32 %9916)
  %9918 = trunc i32 %9917 to i8
  %9919 = and i8 %9918, 1
  %9920 = xor i8 %9919, 1
  store i8 %9920, i8* %13, align 1
  %9921 = xor i32 %9909, %9874
  %9922 = xor i32 %9921, %9910
  %9923 = lshr i32 %9922, 4
  %9924 = trunc i32 %9923 to i8
  %9925 = and i8 %9924, 1
  store i8 %9925, i8* %14, align 1
  %9926 = icmp eq i32 %9910, 0
  %9927 = zext i1 %9926 to i8
  store i8 %9927, i8* %15, align 1
  %9928 = lshr i32 %9910, 31
  %9929 = trunc i32 %9928 to i8
  store i8 %9929, i8* %16, align 1
  %9930 = lshr i32 %9874, 31
  %9931 = lshr i32 %9909, 31
  %9932 = xor i32 %9928, %9930
  %9933 = xor i32 %9928, %9931
  %9934 = add nuw nsw i32 %9932, %9933
  %9935 = icmp eq i32 %9934, 2
  %9936 = zext i1 %9935 to i8
  store i8 %9936, i8* %17, align 1
  %9937 = load i64, i64* %RBP.i, align 8
  %9938 = add i64 %9937, -24
  %9939 = add i64 %9837, 38
  store i64 %9939, i64* %3, align 8
  %9940 = inttoptr i64 %9938 to i32*
  %9941 = load i32, i32* %9940, align 4
  %9942 = sext i32 %9941 to i64
  %9943 = shl nsw i64 %9942, 5
  store i64 %9943, i64* %RDX.i4094, align 8
  %9944 = load i64, i64* %RCX.i3977, align 8
  %9945 = add i64 %9943, %9944
  store i64 %9945, i64* %RSI.i3950, align 8
  %9946 = icmp ult i64 %9945, %9944
  %9947 = icmp ult i64 %9945, %9943
  %9948 = or i1 %9946, %9947
  %9949 = zext i1 %9948 to i8
  store i8 %9949, i8* %12, align 1
  %9950 = trunc i64 %9945 to i32
  %9951 = and i32 %9950, 255
  %9952 = tail call i32 @llvm.ctpop.i32(i32 %9951)
  %9953 = trunc i32 %9952 to i8
  %9954 = and i8 %9953, 1
  %9955 = xor i8 %9954, 1
  store i8 %9955, i8* %13, align 1
  %9956 = xor i64 %9944, %9945
  %9957 = lshr i64 %9956, 4
  %9958 = trunc i64 %9957 to i8
  %9959 = and i8 %9958, 1
  store i8 %9959, i8* %14, align 1
  %9960 = icmp eq i64 %9945, 0
  %9961 = zext i1 %9960 to i8
  store i8 %9961, i8* %15, align 1
  %9962 = lshr i64 %9945, 63
  %9963 = trunc i64 %9962 to i8
  store i8 %9963, i8* %16, align 1
  %9964 = lshr i64 %9944, 63
  %9965 = lshr i64 %9942, 58
  %9966 = and i64 %9965, 1
  %9967 = xor i64 %9962, %9964
  %9968 = xor i64 %9962, %9966
  %9969 = add nuw nsw i64 %9967, %9968
  %9970 = icmp eq i64 %9969, 2
  %9971 = zext i1 %9970 to i8
  store i8 %9971, i8* %17, align 1
  %9972 = load i64, i64* %RDI.i4084, align 8
  %9973 = add i64 %9945, 12
  %9974 = add i64 %9837, 51
  store i64 %9974, i64* %3, align 8
  %9975 = trunc i64 %9972 to i32
  %9976 = inttoptr i64 %9973 to i32*
  %9977 = load i32, i32* %9976, align 4
  %9978 = sub i32 %9975, %9977
  %9979 = zext i32 %9978 to i64
  store i64 %9979, i64* %RDI.i4084, align 8
  %9980 = icmp ult i32 %9975, %9977
  %9981 = zext i1 %9980 to i8
  store i8 %9981, i8* %12, align 1
  %9982 = and i32 %9978, 255
  %9983 = tail call i32 @llvm.ctpop.i32(i32 %9982)
  %9984 = trunc i32 %9983 to i8
  %9985 = and i8 %9984, 1
  %9986 = xor i8 %9985, 1
  store i8 %9986, i8* %13, align 1
  %9987 = xor i32 %9977, %9975
  %9988 = xor i32 %9987, %9978
  %9989 = lshr i32 %9988, 4
  %9990 = trunc i32 %9989 to i8
  %9991 = and i8 %9990, 1
  store i8 %9991, i8* %14, align 1
  %9992 = icmp eq i32 %9978, 0
  %9993 = zext i1 %9992 to i8
  store i8 %9993, i8* %15, align 1
  %9994 = lshr i32 %9978, 31
  %9995 = trunc i32 %9994 to i8
  store i8 %9995, i8* %16, align 1
  %9996 = lshr i32 %9975, 31
  %9997 = lshr i32 %9977, 31
  %9998 = xor i32 %9997, %9996
  %9999 = xor i32 %9994, %9996
  %10000 = add nuw nsw i32 %9999, %9998
  %10001 = icmp eq i32 %10000, 2
  %10002 = zext i1 %10001 to i8
  store i8 %10002, i8* %17, align 1
  %10003 = load i64, i64* %RBP.i, align 8
  %10004 = add i64 %10003, -24
  %10005 = add i64 %9837, 55
  store i64 %10005, i64* %3, align 8
  %10006 = inttoptr i64 %10004 to i32*
  %10007 = load i32, i32* %10006, align 4
  %10008 = sext i32 %10007 to i64
  %10009 = shl nsw i64 %10008, 5
  store i64 %10009, i64* %RDX.i4094, align 8
  %10010 = load i64, i64* %RCX.i3977, align 8
  %10011 = add i64 %10009, %10010
  store i64 %10011, i64* %RSI.i3950, align 8
  %10012 = icmp ult i64 %10011, %10010
  %10013 = icmp ult i64 %10011, %10009
  %10014 = or i1 %10012, %10013
  %10015 = zext i1 %10014 to i8
  store i8 %10015, i8* %12, align 1
  %10016 = trunc i64 %10011 to i32
  %10017 = and i32 %10016, 255
  %10018 = tail call i32 @llvm.ctpop.i32(i32 %10017)
  %10019 = trunc i32 %10018 to i8
  %10020 = and i8 %10019, 1
  %10021 = xor i8 %10020, 1
  store i8 %10021, i8* %13, align 1
  %10022 = xor i64 %10010, %10011
  %10023 = lshr i64 %10022, 4
  %10024 = trunc i64 %10023 to i8
  %10025 = and i8 %10024, 1
  store i8 %10025, i8* %14, align 1
  %10026 = icmp eq i64 %10011, 0
  %10027 = zext i1 %10026 to i8
  store i8 %10027, i8* %15, align 1
  %10028 = lshr i64 %10011, 63
  %10029 = trunc i64 %10028 to i8
  store i8 %10029, i8* %16, align 1
  %10030 = lshr i64 %10010, 63
  %10031 = lshr i64 %10008, 58
  %10032 = and i64 %10031, 1
  %10033 = xor i64 %10028, %10030
  %10034 = xor i64 %10028, %10032
  %10035 = add nuw nsw i64 %10033, %10034
  %10036 = icmp eq i64 %10035, 2
  %10037 = zext i1 %10036 to i8
  store i8 %10037, i8* %17, align 1
  %10038 = add i64 %10011, 12
  %10039 = add i64 %9837, 69
  store i64 %10039, i64* %3, align 8
  %10040 = inttoptr i64 %10038 to i32*
  %10041 = load i32, i32* %10040, align 4
  %10042 = zext i32 %10041 to i64
  %10043 = shl nuw i64 %10042, 32
  %10044 = ashr i64 %10043, 33
  %10045 = and i64 %10044, 4294967295
  store i64 %10045, i64* %R8.i4051, align 8
  %10046 = load i64, i64* %RDI.i4084, align 8
  %10047 = trunc i64 %10044 to i32
  %10048 = trunc i64 %10046 to i32
  %10049 = sub i32 %10048, %10047
  %10050 = zext i32 %10049 to i64
  store i64 %10050, i64* %RDI.i4084, align 8
  %10051 = icmp ult i32 %10048, %10047
  %10052 = zext i1 %10051 to i8
  store i8 %10052, i8* %12, align 1
  %10053 = and i32 %10049, 255
  %10054 = tail call i32 @llvm.ctpop.i32(i32 %10053)
  %10055 = trunc i32 %10054 to i8
  %10056 = and i8 %10055, 1
  %10057 = xor i8 %10056, 1
  store i8 %10057, i8* %13, align 1
  %10058 = xor i64 %10044, %10046
  %10059 = trunc i64 %10058 to i32
  %10060 = xor i32 %10059, %10049
  %10061 = lshr i32 %10060, 4
  %10062 = trunc i32 %10061 to i8
  %10063 = and i8 %10062, 1
  store i8 %10063, i8* %14, align 1
  %10064 = icmp eq i32 %10049, 0
  %10065 = zext i1 %10064 to i8
  store i8 %10065, i8* %15, align 1
  %10066 = lshr i32 %10049, 31
  %10067 = trunc i32 %10066 to i8
  store i8 %10067, i8* %16, align 1
  %10068 = lshr i32 %10048, 31
  %10069 = lshr i64 %10044, 31
  %10070 = trunc i64 %10069 to i32
  %10071 = and i32 %10070, 1
  %10072 = xor i32 %10071, %10068
  %10073 = xor i32 %10066, %10068
  %10074 = add nuw nsw i32 %10073, %10072
  %10075 = icmp eq i32 %10074, 2
  %10076 = zext i1 %10075 to i8
  store i8 %10076, i8* %17, align 1
  %10077 = load i64, i64* %RBP.i, align 8
  %10078 = add i64 %10077, -628
  %10079 = add i64 %9837, 81
  store i64 %10079, i64* %3, align 8
  %10080 = inttoptr i64 %10078 to i32*
  store i32 %10049, i32* %10080, align 4
  %10081 = load i64, i64* %RBP.i, align 8
  %10082 = add i64 %10081, -24
  %10083 = load i64, i64* %3, align 8
  %10084 = add i64 %10083, 4
  store i64 %10084, i64* %3, align 8
  %10085 = inttoptr i64 %10082 to i32*
  %10086 = load i32, i32* %10085, align 4
  %10087 = sext i32 %10086 to i64
  %10088 = shl nsw i64 %10087, 5
  store i64 %10088, i64* %RDX.i4094, align 8
  %10089 = load i64, i64* %RCX.i3977, align 8
  %10090 = add i64 %10088, %10089
  store i64 %10090, i64* %RSI.i3950, align 8
  %10091 = icmp ult i64 %10090, %10089
  %10092 = icmp ult i64 %10090, %10088
  %10093 = or i1 %10091, %10092
  %10094 = zext i1 %10093 to i8
  store i8 %10094, i8* %12, align 1
  %10095 = trunc i64 %10090 to i32
  %10096 = and i32 %10095, 255
  %10097 = tail call i32 @llvm.ctpop.i32(i32 %10096)
  %10098 = trunc i32 %10097 to i8
  %10099 = and i8 %10098, 1
  %10100 = xor i8 %10099, 1
  store i8 %10100, i8* %13, align 1
  %10101 = xor i64 %10089, %10090
  %10102 = lshr i64 %10101, 4
  %10103 = trunc i64 %10102 to i8
  %10104 = and i8 %10103, 1
  store i8 %10104, i8* %14, align 1
  %10105 = icmp eq i64 %10090, 0
  %10106 = zext i1 %10105 to i8
  store i8 %10106, i8* %15, align 1
  %10107 = lshr i64 %10090, 63
  %10108 = trunc i64 %10107 to i8
  store i8 %10108, i8* %16, align 1
  %10109 = lshr i64 %10089, 63
  %10110 = lshr i64 %10087, 58
  %10111 = and i64 %10110, 1
  %10112 = xor i64 %10107, %10109
  %10113 = xor i64 %10107, %10111
  %10114 = add nuw nsw i64 %10112, %10113
  %10115 = icmp eq i64 %10114, 2
  %10116 = zext i1 %10115 to i8
  store i8 %10116, i8* %17, align 1
  %10117 = load i32, i32* %EAX.i2609, align 4
  %10118 = zext i32 %10117 to i64
  store i64 %10118, i64* %RDI.i4084, align 8
  %10119 = add i64 %10090, 4
  %10120 = add i64 %10083, 19
  store i64 %10120, i64* %3, align 8
  %10121 = inttoptr i64 %10119 to i32*
  %10122 = load i32, i32* %10121, align 4
  %10123 = sub i32 %10117, %10122
  %10124 = zext i32 %10123 to i64
  store i64 %10124, i64* %RDI.i4084, align 8
  %10125 = icmp ult i32 %10117, %10122
  %10126 = zext i1 %10125 to i8
  store i8 %10126, i8* %12, align 1
  %10127 = and i32 %10123, 255
  %10128 = tail call i32 @llvm.ctpop.i32(i32 %10127)
  %10129 = trunc i32 %10128 to i8
  %10130 = and i8 %10129, 1
  %10131 = xor i8 %10130, 1
  store i8 %10131, i8* %13, align 1
  %10132 = xor i32 %10122, %10117
  %10133 = xor i32 %10132, %10123
  %10134 = lshr i32 %10133, 4
  %10135 = trunc i32 %10134 to i8
  %10136 = and i8 %10135, 1
  store i8 %10136, i8* %14, align 1
  %10137 = icmp eq i32 %10123, 0
  %10138 = zext i1 %10137 to i8
  store i8 %10138, i8* %15, align 1
  %10139 = lshr i32 %10123, 31
  %10140 = trunc i32 %10139 to i8
  store i8 %10140, i8* %16, align 1
  %10141 = lshr i32 %10117, 31
  %10142 = lshr i32 %10122, 31
  %10143 = xor i32 %10142, %10141
  %10144 = xor i32 %10139, %10141
  %10145 = add nuw nsw i32 %10144, %10143
  %10146 = icmp eq i32 %10145, 2
  %10147 = zext i1 %10146 to i8
  store i8 %10147, i8* %17, align 1
  %10148 = load i64, i64* %RBP.i, align 8
  %10149 = add i64 %10148, -24
  %10150 = add i64 %10083, 23
  store i64 %10150, i64* %3, align 8
  %10151 = inttoptr i64 %10149 to i32*
  %10152 = load i32, i32* %10151, align 4
  %10153 = sext i32 %10152 to i64
  %10154 = shl nsw i64 %10153, 5
  store i64 %10154, i64* %RDX.i4094, align 8
  %10155 = load i64, i64* %RCX.i3977, align 8
  %10156 = add i64 %10154, %10155
  store i64 %10156, i64* %RSI.i3950, align 8
  %10157 = icmp ult i64 %10156, %10155
  %10158 = icmp ult i64 %10156, %10154
  %10159 = or i1 %10157, %10158
  %10160 = zext i1 %10159 to i8
  store i8 %10160, i8* %12, align 1
  %10161 = trunc i64 %10156 to i32
  %10162 = and i32 %10161, 255
  %10163 = tail call i32 @llvm.ctpop.i32(i32 %10162)
  %10164 = trunc i32 %10163 to i8
  %10165 = and i8 %10164, 1
  %10166 = xor i8 %10165, 1
  store i8 %10166, i8* %13, align 1
  %10167 = xor i64 %10155, %10156
  %10168 = lshr i64 %10167, 4
  %10169 = trunc i64 %10168 to i8
  %10170 = and i8 %10169, 1
  store i8 %10170, i8* %14, align 1
  %10171 = icmp eq i64 %10156, 0
  %10172 = zext i1 %10171 to i8
  store i8 %10172, i8* %15, align 1
  %10173 = lshr i64 %10156, 63
  %10174 = trunc i64 %10173 to i8
  store i8 %10174, i8* %16, align 1
  %10175 = lshr i64 %10155, 63
  %10176 = lshr i64 %10153, 58
  %10177 = and i64 %10176, 1
  %10178 = xor i64 %10173, %10175
  %10179 = xor i64 %10173, %10177
  %10180 = add nuw nsw i64 %10178, %10179
  %10181 = icmp eq i64 %10180, 2
  %10182 = zext i1 %10181 to i8
  store i8 %10182, i8* %17, align 1
  %10183 = load i64, i64* %RDI.i4084, align 8
  %10184 = add i64 %10156, 28
  %10185 = add i64 %10083, 36
  store i64 %10185, i64* %3, align 8
  %10186 = trunc i64 %10183 to i32
  %10187 = inttoptr i64 %10184 to i32*
  %10188 = load i32, i32* %10187, align 4
  %10189 = add i32 %10188, %10186
  %10190 = zext i32 %10189 to i64
  store i64 %10190, i64* %RDI.i4084, align 8
  %10191 = icmp ult i32 %10189, %10186
  %10192 = icmp ult i32 %10189, %10188
  %10193 = or i1 %10191, %10192
  %10194 = zext i1 %10193 to i8
  store i8 %10194, i8* %12, align 1
  %10195 = and i32 %10189, 255
  %10196 = tail call i32 @llvm.ctpop.i32(i32 %10195)
  %10197 = trunc i32 %10196 to i8
  %10198 = and i8 %10197, 1
  %10199 = xor i8 %10198, 1
  store i8 %10199, i8* %13, align 1
  %10200 = xor i32 %10188, %10186
  %10201 = xor i32 %10200, %10189
  %10202 = lshr i32 %10201, 4
  %10203 = trunc i32 %10202 to i8
  %10204 = and i8 %10203, 1
  store i8 %10204, i8* %14, align 1
  %10205 = icmp eq i32 %10189, 0
  %10206 = zext i1 %10205 to i8
  store i8 %10206, i8* %15, align 1
  %10207 = lshr i32 %10189, 31
  %10208 = trunc i32 %10207 to i8
  store i8 %10208, i8* %16, align 1
  %10209 = lshr i32 %10186, 31
  %10210 = lshr i32 %10188, 31
  %10211 = xor i32 %10207, %10209
  %10212 = xor i32 %10207, %10210
  %10213 = add nuw nsw i32 %10211, %10212
  %10214 = icmp eq i32 %10213, 2
  %10215 = zext i1 %10214 to i8
  store i8 %10215, i8* %17, align 1
  %10216 = load i64, i64* %RBP.i, align 8
  %10217 = add i64 %10216, -24
  %10218 = add i64 %10083, 40
  store i64 %10218, i64* %3, align 8
  %10219 = inttoptr i64 %10217 to i32*
  %10220 = load i32, i32* %10219, align 4
  %10221 = sext i32 %10220 to i64
  %10222 = shl nsw i64 %10221, 5
  store i64 %10222, i64* %RDX.i4094, align 8
  %10223 = load i64, i64* %RCX.i3977, align 8
  %10224 = add i64 %10222, %10223
  store i64 %10224, i64* %RSI.i3950, align 8
  %10225 = icmp ult i64 %10224, %10223
  %10226 = icmp ult i64 %10224, %10222
  %10227 = or i1 %10225, %10226
  %10228 = zext i1 %10227 to i8
  store i8 %10228, i8* %12, align 1
  %10229 = trunc i64 %10224 to i32
  %10230 = and i32 %10229, 255
  %10231 = tail call i32 @llvm.ctpop.i32(i32 %10230)
  %10232 = trunc i32 %10231 to i8
  %10233 = and i8 %10232, 1
  %10234 = xor i8 %10233, 1
  store i8 %10234, i8* %13, align 1
  %10235 = xor i64 %10223, %10224
  %10236 = lshr i64 %10235, 4
  %10237 = trunc i64 %10236 to i8
  %10238 = and i8 %10237, 1
  store i8 %10238, i8* %14, align 1
  %10239 = icmp eq i64 %10224, 0
  %10240 = zext i1 %10239 to i8
  store i8 %10240, i8* %15, align 1
  %10241 = lshr i64 %10224, 63
  %10242 = trunc i64 %10241 to i8
  store i8 %10242, i8* %16, align 1
  %10243 = lshr i64 %10223, 63
  %10244 = lshr i64 %10221, 58
  %10245 = and i64 %10244, 1
  %10246 = xor i64 %10241, %10243
  %10247 = xor i64 %10241, %10245
  %10248 = add nuw nsw i64 %10246, %10247
  %10249 = icmp eq i64 %10248, 2
  %10250 = zext i1 %10249 to i8
  store i8 %10250, i8* %17, align 1
  %10251 = load i64, i64* %RDI.i4084, align 8
  %10252 = add i64 %10224, 20
  %10253 = add i64 %10083, 53
  store i64 %10253, i64* %3, align 8
  %10254 = trunc i64 %10251 to i32
  %10255 = inttoptr i64 %10252 to i32*
  %10256 = load i32, i32* %10255, align 4
  %10257 = add i32 %10256, %10254
  %10258 = zext i32 %10257 to i64
  store i64 %10258, i64* %RDI.i4084, align 8
  %10259 = icmp ult i32 %10257, %10254
  %10260 = icmp ult i32 %10257, %10256
  %10261 = or i1 %10259, %10260
  %10262 = zext i1 %10261 to i8
  store i8 %10262, i8* %12, align 1
  %10263 = and i32 %10257, 255
  %10264 = tail call i32 @llvm.ctpop.i32(i32 %10263)
  %10265 = trunc i32 %10264 to i8
  %10266 = and i8 %10265, 1
  %10267 = xor i8 %10266, 1
  store i8 %10267, i8* %13, align 1
  %10268 = xor i32 %10256, %10254
  %10269 = xor i32 %10268, %10257
  %10270 = lshr i32 %10269, 4
  %10271 = trunc i32 %10270 to i8
  %10272 = and i8 %10271, 1
  store i8 %10272, i8* %14, align 1
  %10273 = icmp eq i32 %10257, 0
  %10274 = zext i1 %10273 to i8
  store i8 %10274, i8* %15, align 1
  %10275 = lshr i32 %10257, 31
  %10276 = trunc i32 %10275 to i8
  store i8 %10276, i8* %16, align 1
  %10277 = lshr i32 %10254, 31
  %10278 = lshr i32 %10256, 31
  %10279 = xor i32 %10275, %10277
  %10280 = xor i32 %10275, %10278
  %10281 = add nuw nsw i32 %10279, %10280
  %10282 = icmp eq i32 %10281, 2
  %10283 = zext i1 %10282 to i8
  store i8 %10283, i8* %17, align 1
  %10284 = load i64, i64* %RBP.i, align 8
  %10285 = add i64 %10284, -24
  %10286 = add i64 %10083, 57
  store i64 %10286, i64* %3, align 8
  %10287 = inttoptr i64 %10285 to i32*
  %10288 = load i32, i32* %10287, align 4
  %10289 = sext i32 %10288 to i64
  %10290 = shl nsw i64 %10289, 5
  store i64 %10290, i64* %RDX.i4094, align 8
  %10291 = load i64, i64* %RCX.i3977, align 8
  %10292 = add i64 %10290, %10291
  store i64 %10292, i64* %RSI.i3950, align 8
  %10293 = icmp ult i64 %10292, %10291
  %10294 = icmp ult i64 %10292, %10290
  %10295 = or i1 %10293, %10294
  %10296 = zext i1 %10295 to i8
  store i8 %10296, i8* %12, align 1
  %10297 = trunc i64 %10292 to i32
  %10298 = and i32 %10297, 255
  %10299 = tail call i32 @llvm.ctpop.i32(i32 %10298)
  %10300 = trunc i32 %10299 to i8
  %10301 = and i8 %10300, 1
  %10302 = xor i8 %10301, 1
  store i8 %10302, i8* %13, align 1
  %10303 = xor i64 %10291, %10292
  %10304 = lshr i64 %10303, 4
  %10305 = trunc i64 %10304 to i8
  %10306 = and i8 %10305, 1
  store i8 %10306, i8* %14, align 1
  %10307 = icmp eq i64 %10292, 0
  %10308 = zext i1 %10307 to i8
  store i8 %10308, i8* %15, align 1
  %10309 = lshr i64 %10292, 63
  %10310 = trunc i64 %10309 to i8
  store i8 %10310, i8* %16, align 1
  %10311 = lshr i64 %10291, 63
  %10312 = lshr i64 %10289, 58
  %10313 = and i64 %10312, 1
  %10314 = xor i64 %10309, %10311
  %10315 = xor i64 %10309, %10313
  %10316 = add nuw nsw i64 %10314, %10315
  %10317 = icmp eq i64 %10316, 2
  %10318 = zext i1 %10317 to i8
  store i8 %10318, i8* %17, align 1
  %10319 = add i64 %10292, 20
  %10320 = add i64 %10083, 71
  store i64 %10320, i64* %3, align 8
  %10321 = inttoptr i64 %10319 to i32*
  %10322 = load i32, i32* %10321, align 4
  %10323 = zext i32 %10322 to i64
  %10324 = shl nuw i64 %10323, 32
  %10325 = ashr i64 %10324, 33
  %10326 = and i64 %10325, 4294967295
  store i64 %10326, i64* %R8.i4051, align 8
  %10327 = load i64, i64* %RDI.i4084, align 8
  %10328 = trunc i64 %10325 to i32
  %10329 = trunc i64 %10327 to i32
  %10330 = add i32 %10328, %10329
  %10331 = zext i32 %10330 to i64
  store i64 %10331, i64* %RDI.i4084, align 8
  %10332 = icmp ult i32 %10330, %10329
  %10333 = icmp ult i32 %10330, %10328
  %10334 = or i1 %10332, %10333
  %10335 = zext i1 %10334 to i8
  store i8 %10335, i8* %12, align 1
  %10336 = and i32 %10330, 255
  %10337 = tail call i32 @llvm.ctpop.i32(i32 %10336)
  %10338 = trunc i32 %10337 to i8
  %10339 = and i8 %10338, 1
  %10340 = xor i8 %10339, 1
  store i8 %10340, i8* %13, align 1
  %10341 = xor i64 %10325, %10327
  %10342 = trunc i64 %10341 to i32
  %10343 = xor i32 %10342, %10330
  %10344 = lshr i32 %10343, 4
  %10345 = trunc i32 %10344 to i8
  %10346 = and i8 %10345, 1
  store i8 %10346, i8* %14, align 1
  %10347 = icmp eq i32 %10330, 0
  %10348 = zext i1 %10347 to i8
  store i8 %10348, i8* %15, align 1
  %10349 = lshr i32 %10330, 31
  %10350 = trunc i32 %10349 to i8
  store i8 %10350, i8* %16, align 1
  %10351 = lshr i32 %10329, 31
  %10352 = lshr i64 %10325, 31
  %10353 = trunc i64 %10352 to i32
  %10354 = and i32 %10353, 1
  %10355 = xor i32 %10349, %10351
  %10356 = xor i32 %10349, %10354
  %10357 = add nuw nsw i32 %10355, %10356
  %10358 = icmp eq i32 %10357, 2
  %10359 = zext i1 %10358 to i8
  store i8 %10359, i8* %17, align 1
  %10360 = load i64, i64* %RBP.i, align 8
  %10361 = add i64 %10360, -620
  %10362 = add i64 %10083, 83
  store i64 %10362, i64* %3, align 8
  %10363 = inttoptr i64 %10361 to i32*
  store i32 %10330, i32* %10363, align 4
  %10364 = load i64, i64* %RBP.i, align 8
  %10365 = add i64 %10364, -24
  %10366 = load i64, i64* %3, align 8
  %10367 = add i64 %10366, 4
  store i64 %10367, i64* %3, align 8
  %10368 = inttoptr i64 %10365 to i32*
  %10369 = load i32, i32* %10368, align 4
  %10370 = sext i32 %10369 to i64
  %10371 = shl nsw i64 %10370, 5
  store i64 %10371, i64* %RDX.i4094, align 8
  %10372 = load i64, i64* %RCX.i3977, align 8
  %10373 = add i64 %10371, %10372
  store i64 %10373, i64* %RSI.i3950, align 8
  %10374 = icmp ult i64 %10373, %10372
  %10375 = icmp ult i64 %10373, %10371
  %10376 = or i1 %10374, %10375
  %10377 = zext i1 %10376 to i8
  store i8 %10377, i8* %12, align 1
  %10378 = trunc i64 %10373 to i32
  %10379 = and i32 %10378, 255
  %10380 = tail call i32 @llvm.ctpop.i32(i32 %10379)
  %10381 = trunc i32 %10380 to i8
  %10382 = and i8 %10381, 1
  %10383 = xor i8 %10382, 1
  store i8 %10383, i8* %13, align 1
  %10384 = xor i64 %10372, %10373
  %10385 = lshr i64 %10384, 4
  %10386 = trunc i64 %10385 to i8
  %10387 = and i8 %10386, 1
  store i8 %10387, i8* %14, align 1
  %10388 = icmp eq i64 %10373, 0
  %10389 = zext i1 %10388 to i8
  store i8 %10389, i8* %15, align 1
  %10390 = lshr i64 %10373, 63
  %10391 = trunc i64 %10390 to i8
  store i8 %10391, i8* %16, align 1
  %10392 = lshr i64 %10372, 63
  %10393 = lshr i64 %10370, 58
  %10394 = and i64 %10393, 1
  %10395 = xor i64 %10390, %10392
  %10396 = xor i64 %10390, %10394
  %10397 = add nuw nsw i64 %10395, %10396
  %10398 = icmp eq i64 %10397, 2
  %10399 = zext i1 %10398 to i8
  store i8 %10399, i8* %17, align 1
  %10400 = add i64 %10373, 12
  %10401 = add i64 %10366, 17
  store i64 %10401, i64* %3, align 8
  %10402 = inttoptr i64 %10400 to i32*
  %10403 = load i32, i32* %10402, align 4
  %10404 = zext i32 %10403 to i64
  store i64 %10404, i64* %RDI.i4084, align 8
  %10405 = add i64 %10366, 21
  store i64 %10405, i64* %3, align 8
  %10406 = load i32, i32* %10368, align 4
  %10407 = sext i32 %10406 to i64
  %10408 = shl nsw i64 %10407, 5
  store i64 %10408, i64* %RDX.i4094, align 8
  %10409 = add i64 %10408, %10372
  store i64 %10409, i64* %RSI.i3950, align 8
  %10410 = icmp ult i64 %10409, %10372
  %10411 = icmp ult i64 %10409, %10408
  %10412 = or i1 %10410, %10411
  %10413 = zext i1 %10412 to i8
  store i8 %10413, i8* %12, align 1
  %10414 = trunc i64 %10409 to i32
  %10415 = and i32 %10414, 255
  %10416 = tail call i32 @llvm.ctpop.i32(i32 %10415)
  %10417 = trunc i32 %10416 to i8
  %10418 = and i8 %10417, 1
  %10419 = xor i8 %10418, 1
  store i8 %10419, i8* %13, align 1
  %10420 = xor i64 %10372, %10409
  %10421 = lshr i64 %10420, 4
  %10422 = trunc i64 %10421 to i8
  %10423 = and i8 %10422, 1
  store i8 %10423, i8* %14, align 1
  %10424 = icmp eq i64 %10409, 0
  %10425 = zext i1 %10424 to i8
  store i8 %10425, i8* %15, align 1
  %10426 = lshr i64 %10409, 63
  %10427 = trunc i64 %10426 to i8
  store i8 %10427, i8* %16, align 1
  %10428 = lshr i64 %10407, 58
  %10429 = and i64 %10428, 1
  %10430 = xor i64 %10426, %10392
  %10431 = xor i64 %10426, %10429
  %10432 = add nuw nsw i64 %10430, %10431
  %10433 = icmp eq i64 %10432, 2
  %10434 = zext i1 %10433 to i8
  store i8 %10434, i8* %17, align 1
  %10435 = add i64 %10409, 20
  %10436 = add i64 %10366, 34
  store i64 %10436, i64* %3, align 8
  %10437 = inttoptr i64 %10435 to i32*
  %10438 = load i32, i32* %10437, align 4
  %10439 = add i32 %10438, %10403
  %10440 = zext i32 %10439 to i64
  store i64 %10440, i64* %RDI.i4084, align 8
  %10441 = icmp ult i32 %10439, %10403
  %10442 = icmp ult i32 %10439, %10438
  %10443 = or i1 %10441, %10442
  %10444 = zext i1 %10443 to i8
  store i8 %10444, i8* %12, align 1
  %10445 = and i32 %10439, 255
  %10446 = tail call i32 @llvm.ctpop.i32(i32 %10445)
  %10447 = trunc i32 %10446 to i8
  %10448 = and i8 %10447, 1
  %10449 = xor i8 %10448, 1
  store i8 %10449, i8* %13, align 1
  %10450 = xor i32 %10438, %10403
  %10451 = xor i32 %10450, %10439
  %10452 = lshr i32 %10451, 4
  %10453 = trunc i32 %10452 to i8
  %10454 = and i8 %10453, 1
  store i8 %10454, i8* %14, align 1
  %10455 = icmp eq i32 %10439, 0
  %10456 = zext i1 %10455 to i8
  store i8 %10456, i8* %15, align 1
  %10457 = lshr i32 %10439, 31
  %10458 = trunc i32 %10457 to i8
  store i8 %10458, i8* %16, align 1
  %10459 = lshr i32 %10403, 31
  %10460 = lshr i32 %10438, 31
  %10461 = xor i32 %10457, %10459
  %10462 = xor i32 %10457, %10460
  %10463 = add nuw nsw i32 %10461, %10462
  %10464 = icmp eq i32 %10463, 2
  %10465 = zext i1 %10464 to i8
  store i8 %10465, i8* %17, align 1
  %10466 = load i64, i64* %RBP.i, align 8
  %10467 = add i64 %10466, -24
  %10468 = add i64 %10366, 38
  store i64 %10468, i64* %3, align 8
  %10469 = inttoptr i64 %10467 to i32*
  %10470 = load i32, i32* %10469, align 4
  %10471 = sext i32 %10470 to i64
  %10472 = shl nsw i64 %10471, 5
  store i64 %10472, i64* %RDX.i4094, align 8
  %10473 = load i64, i64* %RCX.i3977, align 8
  %10474 = add i64 %10472, %10473
  store i64 %10474, i64* %RSI.i3950, align 8
  %10475 = icmp ult i64 %10474, %10473
  %10476 = icmp ult i64 %10474, %10472
  %10477 = or i1 %10475, %10476
  %10478 = zext i1 %10477 to i8
  store i8 %10478, i8* %12, align 1
  %10479 = trunc i64 %10474 to i32
  %10480 = and i32 %10479, 255
  %10481 = tail call i32 @llvm.ctpop.i32(i32 %10480)
  %10482 = trunc i32 %10481 to i8
  %10483 = and i8 %10482, 1
  %10484 = xor i8 %10483, 1
  store i8 %10484, i8* %13, align 1
  %10485 = xor i64 %10473, %10474
  %10486 = lshr i64 %10485, 4
  %10487 = trunc i64 %10486 to i8
  %10488 = and i8 %10487, 1
  store i8 %10488, i8* %14, align 1
  %10489 = icmp eq i64 %10474, 0
  %10490 = zext i1 %10489 to i8
  store i8 %10490, i8* %15, align 1
  %10491 = lshr i64 %10474, 63
  %10492 = trunc i64 %10491 to i8
  store i8 %10492, i8* %16, align 1
  %10493 = lshr i64 %10473, 63
  %10494 = lshr i64 %10471, 58
  %10495 = and i64 %10494, 1
  %10496 = xor i64 %10491, %10493
  %10497 = xor i64 %10491, %10495
  %10498 = add nuw nsw i64 %10496, %10497
  %10499 = icmp eq i64 %10498, 2
  %10500 = zext i1 %10499 to i8
  store i8 %10500, i8* %17, align 1
  %10501 = load i64, i64* %RDI.i4084, align 8
  %10502 = add i64 %10474, 4
  %10503 = add i64 %10366, 51
  store i64 %10503, i64* %3, align 8
  %10504 = trunc i64 %10501 to i32
  %10505 = inttoptr i64 %10502 to i32*
  %10506 = load i32, i32* %10505, align 4
  %10507 = add i32 %10506, %10504
  %10508 = zext i32 %10507 to i64
  store i64 %10508, i64* %RDI.i4084, align 8
  %10509 = icmp ult i32 %10507, %10504
  %10510 = icmp ult i32 %10507, %10506
  %10511 = or i1 %10509, %10510
  %10512 = zext i1 %10511 to i8
  store i8 %10512, i8* %12, align 1
  %10513 = and i32 %10507, 255
  %10514 = tail call i32 @llvm.ctpop.i32(i32 %10513)
  %10515 = trunc i32 %10514 to i8
  %10516 = and i8 %10515, 1
  %10517 = xor i8 %10516, 1
  store i8 %10517, i8* %13, align 1
  %10518 = xor i32 %10506, %10504
  %10519 = xor i32 %10518, %10507
  %10520 = lshr i32 %10519, 4
  %10521 = trunc i32 %10520 to i8
  %10522 = and i8 %10521, 1
  store i8 %10522, i8* %14, align 1
  %10523 = icmp eq i32 %10507, 0
  %10524 = zext i1 %10523 to i8
  store i8 %10524, i8* %15, align 1
  %10525 = lshr i32 %10507, 31
  %10526 = trunc i32 %10525 to i8
  store i8 %10526, i8* %16, align 1
  %10527 = lshr i32 %10504, 31
  %10528 = lshr i32 %10506, 31
  %10529 = xor i32 %10525, %10527
  %10530 = xor i32 %10525, %10528
  %10531 = add nuw nsw i32 %10529, %10530
  %10532 = icmp eq i32 %10531, 2
  %10533 = zext i1 %10532 to i8
  store i8 %10533, i8* %17, align 1
  %10534 = load i64, i64* %RBP.i, align 8
  %10535 = add i64 %10534, -24
  %10536 = add i64 %10366, 55
  store i64 %10536, i64* %3, align 8
  %10537 = inttoptr i64 %10535 to i32*
  %10538 = load i32, i32* %10537, align 4
  %10539 = sext i32 %10538 to i64
  %10540 = shl nsw i64 %10539, 5
  store i64 %10540, i64* %RDX.i4094, align 8
  %10541 = load i64, i64* %RCX.i3977, align 8
  %10542 = add i64 %10540, %10541
  store i64 %10542, i64* %RCX.i3977, align 8
  %10543 = icmp ult i64 %10542, %10541
  %10544 = icmp ult i64 %10542, %10540
  %10545 = or i1 %10543, %10544
  %10546 = zext i1 %10545 to i8
  store i8 %10546, i8* %12, align 1
  %10547 = trunc i64 %10542 to i32
  %10548 = and i32 %10547, 255
  %10549 = tail call i32 @llvm.ctpop.i32(i32 %10548)
  %10550 = trunc i32 %10549 to i8
  %10551 = and i8 %10550, 1
  %10552 = xor i8 %10551, 1
  store i8 %10552, i8* %13, align 1
  %10553 = xor i64 %10541, %10542
  %10554 = lshr i64 %10553, 4
  %10555 = trunc i64 %10554 to i8
  %10556 = and i8 %10555, 1
  store i8 %10556, i8* %14, align 1
  %10557 = icmp eq i64 %10542, 0
  %10558 = zext i1 %10557 to i8
  store i8 %10558, i8* %15, align 1
  %10559 = lshr i64 %10542, 63
  %10560 = trunc i64 %10559 to i8
  store i8 %10560, i8* %16, align 1
  %10561 = lshr i64 %10541, 63
  %10562 = lshr i64 %10539, 58
  %10563 = and i64 %10562, 1
  %10564 = xor i64 %10559, %10561
  %10565 = xor i64 %10559, %10563
  %10566 = add nuw nsw i64 %10564, %10565
  %10567 = icmp eq i64 %10566, 2
  %10568 = zext i1 %10567 to i8
  store i8 %10568, i8* %17, align 1
  %10569 = add i64 %10542, 4
  %10570 = add i64 %10366, 66
  store i64 %10570, i64* %3, align 8
  %10571 = inttoptr i64 %10569 to i32*
  %10572 = load i32, i32* %10571, align 4
  %10573 = zext i32 %10572 to i64
  %10574 = shl nuw i64 %10573, 32
  %10575 = ashr i64 %10574, 33
  %10576 = and i64 %10575, 4294967295
  store i64 %10576, i64* %R8.i4051, align 8
  %10577 = load i64, i64* %RDI.i4084, align 8
  %10578 = trunc i64 %10575 to i32
  %10579 = trunc i64 %10577 to i32
  %10580 = add i32 %10578, %10579
  %10581 = zext i32 %10580 to i64
  store i64 %10581, i64* %RDI.i4084, align 8
  %10582 = icmp ult i32 %10580, %10579
  %10583 = icmp ult i32 %10580, %10578
  %10584 = or i1 %10582, %10583
  %10585 = zext i1 %10584 to i8
  store i8 %10585, i8* %12, align 1
  %10586 = and i32 %10580, 255
  %10587 = tail call i32 @llvm.ctpop.i32(i32 %10586)
  %10588 = trunc i32 %10587 to i8
  %10589 = and i8 %10588, 1
  %10590 = xor i8 %10589, 1
  store i8 %10590, i8* %13, align 1
  %10591 = xor i64 %10575, %10577
  %10592 = trunc i64 %10591 to i32
  %10593 = xor i32 %10592, %10580
  %10594 = lshr i32 %10593, 4
  %10595 = trunc i32 %10594 to i8
  %10596 = and i8 %10595, 1
  store i8 %10596, i8* %14, align 1
  %10597 = icmp eq i32 %10580, 0
  %10598 = zext i1 %10597 to i8
  store i8 %10598, i8* %15, align 1
  %10599 = lshr i32 %10580, 31
  %10600 = trunc i32 %10599 to i8
  store i8 %10600, i8* %16, align 1
  %10601 = lshr i32 %10579, 31
  %10602 = lshr i64 %10575, 31
  %10603 = trunc i64 %10602 to i32
  %10604 = and i32 %10603, 1
  %10605 = xor i32 %10599, %10601
  %10606 = xor i32 %10599, %10604
  %10607 = add nuw nsw i32 %10605, %10606
  %10608 = icmp eq i32 %10607, 2
  %10609 = zext i1 %10608 to i8
  store i8 %10609, i8* %17, align 1
  %10610 = load i64, i64* %RBP.i, align 8
  %10611 = add i64 %10610, -612
  %10612 = add i64 %10366, 78
  store i64 %10612, i64* %3, align 8
  %10613 = inttoptr i64 %10611 to i32*
  store i32 %10580, i32* %10613, align 4
  %10614 = load i64, i64* %RBP.i, align 8
  %10615 = add i64 %10614, -636
  %10616 = load i64, i64* %3, align 8
  %10617 = add i64 %10616, 6
  store i64 %10617, i64* %3, align 8
  %10618 = inttoptr i64 %10615 to i32*
  %10619 = load i32, i32* %10618, align 4
  %10620 = zext i32 %10619 to i64
  store i64 %10620, i64* %RDI.i4084, align 8
  %10621 = add i64 %10614, -612
  %10622 = add i64 %10616, 13
  store i64 %10622, i64* %3, align 8
  %10623 = inttoptr i64 %10621 to i32*
  %10624 = load i32, i32* %10623, align 4
  %10625 = sext i32 %10624 to i64
  %10626 = ashr i64 %10625, 1
  %10627 = lshr i64 %10626, 1
  %10628 = and i64 %10627, 4294967295
  store i64 %10628, i64* %R8.i4051, align 8
  %10629 = trunc i64 %10627 to i32
  %10630 = add i32 %10629, %10619
  %10631 = zext i32 %10630 to i64
  store i64 %10631, i64* %RDI.i4084, align 8
  %10632 = icmp ult i32 %10630, %10619
  %10633 = icmp ult i32 %10630, %10629
  %10634 = or i1 %10632, %10633
  %10635 = zext i1 %10634 to i8
  store i8 %10635, i8* %12, align 1
  %10636 = and i32 %10630, 255
  %10637 = tail call i32 @llvm.ctpop.i32(i32 %10636)
  %10638 = trunc i32 %10637 to i8
  %10639 = and i8 %10638, 1
  %10640 = xor i8 %10639, 1
  store i8 %10640, i8* %13, align 1
  %10641 = xor i64 %10627, %10620
  %10642 = trunc i64 %10641 to i32
  %10643 = xor i32 %10642, %10630
  %10644 = lshr i32 %10643, 4
  %10645 = trunc i32 %10644 to i8
  %10646 = and i8 %10645, 1
  store i8 %10646, i8* %14, align 1
  %10647 = icmp eq i32 %10630, 0
  %10648 = zext i1 %10647 to i8
  store i8 %10648, i8* %15, align 1
  %10649 = lshr i32 %10630, 31
  %10650 = trunc i32 %10649 to i8
  store i8 %10650, i8* %16, align 1
  %10651 = lshr i32 %10619, 31
  %10652 = lshr i64 %10626, 32
  %10653 = trunc i64 %10652 to i32
  %10654 = and i32 %10653, 1
  %10655 = xor i32 %10649, %10651
  %10656 = xor i32 %10649, %10654
  %10657 = add nuw nsw i32 %10655, %10656
  %10658 = icmp eq i32 %10657, 2
  %10659 = zext i1 %10658 to i8
  store i8 %10659, i8* %17, align 1
  %10660 = add i64 %10614, -668
  %10661 = add i64 %10616, 26
  store i64 %10661, i64* %3, align 8
  %10662 = inttoptr i64 %10660 to i32*
  store i32 %10630, i32* %10662, align 4
  %10663 = load i64, i64* %RBP.i, align 8
  %10664 = add i64 %10663, -636
  %10665 = load i64, i64* %3, align 8
  %10666 = add i64 %10665, 6
  store i64 %10666, i64* %3, align 8
  %10667 = inttoptr i64 %10664 to i32*
  %10668 = load i32, i32* %10667, align 4
  %10669 = sext i32 %10668 to i64
  %10670 = ashr i64 %10669, 1
  %10671 = lshr i64 %10670, 1
  %10672 = and i64 %10671, 4294967295
  store i64 %10672, i64* %RDI.i4084, align 8
  %10673 = load i64, i64* %RAX.i2610, align 8
  %10674 = trunc i64 %10671 to i32
  %10675 = trunc i64 %10673 to i32
  %10676 = sub i32 %10675, %10674
  %10677 = zext i32 %10676 to i64
  store i64 %10677, i64* %RAX.i2610, align 8
  %10678 = icmp ult i32 %10675, %10674
  %10679 = zext i1 %10678 to i8
  store i8 %10679, i8* %12, align 1
  %10680 = and i32 %10676, 255
  %10681 = tail call i32 @llvm.ctpop.i32(i32 %10680)
  %10682 = trunc i32 %10681 to i8
  %10683 = and i8 %10682, 1
  %10684 = xor i8 %10683, 1
  store i8 %10684, i8* %13, align 1
  %10685 = xor i64 %10671, %10673
  %10686 = trunc i64 %10685 to i32
  %10687 = xor i32 %10686, %10676
  %10688 = lshr i32 %10687, 4
  %10689 = trunc i32 %10688 to i8
  %10690 = and i8 %10689, 1
  store i8 %10690, i8* %14, align 1
  %10691 = icmp eq i32 %10676, 0
  %10692 = zext i1 %10691 to i8
  store i8 %10692, i8* %15, align 1
  %10693 = lshr i32 %10676, 31
  %10694 = trunc i32 %10693 to i8
  store i8 %10694, i8* %16, align 1
  %10695 = lshr i32 %10675, 31
  %10696 = lshr i64 %10670, 32
  %10697 = trunc i64 %10696 to i32
  %10698 = and i32 %10697, 1
  %10699 = xor i32 %10698, %10695
  %10700 = xor i32 %10693, %10695
  %10701 = add nuw nsw i32 %10700, %10699
  %10702 = icmp eq i32 %10701, 2
  %10703 = zext i1 %10702 to i8
  store i8 %10703, i8* %17, align 1
  %10704 = add i64 %10663, -612
  %10705 = add i64 %10665, 17
  store i64 %10705, i64* %3, align 8
  %10706 = inttoptr i64 %10704 to i32*
  %10707 = load i32, i32* %10706, align 4
  %10708 = add i32 %10707, %10676
  %10709 = zext i32 %10708 to i64
  store i64 %10709, i64* %RAX.i2610, align 8
  %10710 = icmp ult i32 %10708, %10676
  %10711 = icmp ult i32 %10708, %10707
  %10712 = or i1 %10710, %10711
  %10713 = zext i1 %10712 to i8
  store i8 %10713, i8* %12, align 1
  %10714 = and i32 %10708, 255
  %10715 = tail call i32 @llvm.ctpop.i32(i32 %10714)
  %10716 = trunc i32 %10715 to i8
  %10717 = and i8 %10716, 1
  %10718 = xor i8 %10717, 1
  store i8 %10718, i8* %13, align 1
  %10719 = xor i32 %10707, %10676
  %10720 = xor i32 %10719, %10708
  %10721 = lshr i32 %10720, 4
  %10722 = trunc i32 %10721 to i8
  %10723 = and i8 %10722, 1
  store i8 %10723, i8* %14, align 1
  %10724 = icmp eq i32 %10708, 0
  %10725 = zext i1 %10724 to i8
  store i8 %10725, i8* %15, align 1
  %10726 = lshr i32 %10708, 31
  %10727 = trunc i32 %10726 to i8
  store i8 %10727, i8* %16, align 1
  %10728 = lshr i32 %10707, 31
  %10729 = xor i32 %10726, %10693
  %10730 = xor i32 %10726, %10728
  %10731 = add nuw nsw i32 %10729, %10730
  %10732 = icmp eq i32 %10731, 2
  %10733 = zext i1 %10732 to i8
  store i8 %10733, i8* %17, align 1
  %10734 = load i64, i64* %RBP.i, align 8
  %10735 = add i64 %10734, -644
  %10736 = add i64 %10665, 23
  store i64 %10736, i64* %3, align 8
  %10737 = inttoptr i64 %10735 to i32*
  store i32 %10708, i32* %10737, align 4
  %10738 = load i64, i64* %RBP.i, align 8
  %10739 = add i64 %10738, -628
  %10740 = load i64, i64* %3, align 8
  %10741 = add i64 %10740, 6
  store i64 %10741, i64* %3, align 8
  %10742 = inttoptr i64 %10739 to i32*
  %10743 = load i32, i32* %10742, align 4
  %10744 = zext i32 %10743 to i64
  store i64 %10744, i64* %RAX.i2610, align 8
  %10745 = add i64 %10738, -620
  %10746 = add i64 %10740, 12
  store i64 %10746, i64* %3, align 8
  %10747 = inttoptr i64 %10745 to i32*
  %10748 = load i32, i32* %10747, align 4
  %10749 = sext i32 %10748 to i64
  %10750 = ashr i64 %10749, 1
  %10751 = lshr i64 %10750, 1
  %10752 = and i64 %10751, 4294967295
  store i64 %10752, i64* %RDI.i4084, align 8
  %10753 = trunc i64 %10751 to i32
  %10754 = add i32 %10753, %10743
  %10755 = zext i32 %10754 to i64
  store i64 %10755, i64* %RAX.i2610, align 8
  %10756 = icmp ult i32 %10754, %10743
  %10757 = icmp ult i32 %10754, %10753
  %10758 = or i1 %10756, %10757
  %10759 = zext i1 %10758 to i8
  store i8 %10759, i8* %12, align 1
  %10760 = and i32 %10754, 255
  %10761 = tail call i32 @llvm.ctpop.i32(i32 %10760)
  %10762 = trunc i32 %10761 to i8
  %10763 = and i8 %10762, 1
  %10764 = xor i8 %10763, 1
  store i8 %10764, i8* %13, align 1
  %10765 = xor i64 %10751, %10744
  %10766 = trunc i64 %10765 to i32
  %10767 = xor i32 %10766, %10754
  %10768 = lshr i32 %10767, 4
  %10769 = trunc i32 %10768 to i8
  %10770 = and i8 %10769, 1
  store i8 %10770, i8* %14, align 1
  %10771 = icmp eq i32 %10754, 0
  %10772 = zext i1 %10771 to i8
  store i8 %10772, i8* %15, align 1
  %10773 = lshr i32 %10754, 31
  %10774 = trunc i32 %10773 to i8
  store i8 %10774, i8* %16, align 1
  %10775 = lshr i32 %10743, 31
  %10776 = lshr i64 %10750, 32
  %10777 = trunc i64 %10776 to i32
  %10778 = and i32 %10777, 1
  %10779 = xor i32 %10773, %10775
  %10780 = xor i32 %10773, %10778
  %10781 = add nuw nsw i32 %10779, %10780
  %10782 = icmp eq i32 %10781, 2
  %10783 = zext i1 %10782 to i8
  store i8 %10783, i8* %17, align 1
  %10784 = add i64 %10738, -660
  %10785 = add i64 %10740, 23
  store i64 %10785, i64* %3, align 8
  %10786 = inttoptr i64 %10784 to i32*
  store i32 %10754, i32* %10786, align 4
  %10787 = load i64, i64* %RBP.i, align 8
  %10788 = add i64 %10787, -628
  %10789 = load i64, i64* %3, align 8
  %10790 = add i64 %10789, 6
  store i64 %10790, i64* %3, align 8
  %10791 = inttoptr i64 %10788 to i32*
  %10792 = load i32, i32* %10791, align 4
  %10793 = sext i32 %10792 to i64
  %10794 = ashr i64 %10793, 1
  %10795 = lshr i64 %10794, 1
  %10796 = trunc i64 %10794 to i8
  %10797 = and i8 %10796, 1
  %10798 = trunc i64 %10795 to i32
  %10799 = and i64 %10795, 4294967295
  store i64 %10799, i64* %RAX.i2610, align 8
  store i8 %10797, i8* %12, align 1
  %10800 = and i32 %10798, 255
  %10801 = tail call i32 @llvm.ctpop.i32(i32 %10800)
  %10802 = trunc i32 %10801 to i8
  %10803 = and i8 %10802, 1
  %10804 = xor i8 %10803, 1
  store i8 %10804, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %10805 = icmp eq i32 %10798, 0
  %10806 = zext i1 %10805 to i8
  store i8 %10806, i8* %15, align 1
  %10807 = lshr i64 %10794, 32
  %10808 = trunc i64 %10807 to i8
  %10809 = and i8 %10808, 1
  store i8 %10809, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %10810 = add i64 %10787, -620
  %10811 = add i64 %10789, 15
  store i64 %10811, i64* %3, align 8
  %10812 = trunc i64 %10795 to i32
  %10813 = inttoptr i64 %10810 to i32*
  %10814 = load i32, i32* %10813, align 4
  %10815 = sub i32 %10812, %10814
  %10816 = zext i32 %10815 to i64
  store i64 %10816, i64* %RAX.i2610, align 8
  %10817 = icmp ult i32 %10812, %10814
  %10818 = zext i1 %10817 to i8
  store i8 %10818, i8* %12, align 1
  %10819 = and i32 %10815, 255
  %10820 = tail call i32 @llvm.ctpop.i32(i32 %10819)
  %10821 = trunc i32 %10820 to i8
  %10822 = and i8 %10821, 1
  %10823 = xor i8 %10822, 1
  store i8 %10823, i8* %13, align 1
  %10824 = xor i32 %10814, %10812
  %10825 = xor i32 %10824, %10815
  %10826 = lshr i32 %10825, 4
  %10827 = trunc i32 %10826 to i8
  %10828 = and i8 %10827, 1
  store i8 %10828, i8* %14, align 1
  %10829 = icmp eq i32 %10815, 0
  %10830 = zext i1 %10829 to i8
  store i8 %10830, i8* %15, align 1
  %10831 = lshr i32 %10815, 31
  %10832 = trunc i32 %10831 to i8
  store i8 %10832, i8* %16, align 1
  %10833 = lshr i64 %10794, 32
  %10834 = trunc i64 %10833 to i32
  %10835 = and i32 %10834, 1
  %10836 = lshr i32 %10814, 31
  %10837 = xor i32 %10836, %10835
  %10838 = xor i32 %10831, %10835
  %10839 = add nuw nsw i32 %10838, %10837
  %10840 = icmp eq i32 %10839, 2
  %10841 = zext i1 %10840 to i8
  store i8 %10841, i8* %17, align 1
  %10842 = add i64 %10787, -652
  %10843 = add i64 %10789, 21
  store i64 %10843, i64* %3, align 8
  %10844 = inttoptr i64 %10842 to i32*
  store i32 %10815, i32* %10844, align 4
  %10845 = load i64, i64* %RBP.i, align 8
  %10846 = add i64 %10845, -672
  %10847 = load i64, i64* %3, align 8
  %10848 = add i64 %10847, 6
  store i64 %10848, i64* %3, align 8
  %10849 = inttoptr i64 %10846 to i32*
  %10850 = load i32, i32* %10849, align 4
  %10851 = zext i32 %10850 to i64
  store i64 %10851, i64* %RAX.i2610, align 8
  %10852 = add i64 %10845, -644
  %10853 = add i64 %10847, 12
  store i64 %10853, i64* %3, align 8
  %10854 = inttoptr i64 %10852 to i32*
  %10855 = load i32, i32* %10854, align 4
  %10856 = add i32 %10855, %10850
  %10857 = zext i32 %10856 to i64
  store i64 %10857, i64* %RAX.i2610, align 8
  %10858 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %10859 = add i64 %10858, 13112
  store i64 %10859, i64* %RCX.i3977, align 8
  %10860 = icmp ugt i64 %10858, -13113
  %10861 = zext i1 %10860 to i8
  store i8 %10861, i8* %12, align 1
  %10862 = trunc i64 %10859 to i32
  %10863 = and i32 %10862, 255
  %10864 = tail call i32 @llvm.ctpop.i32(i32 %10863)
  %10865 = trunc i32 %10864 to i8
  %10866 = and i8 %10865, 1
  %10867 = xor i8 %10866, 1
  store i8 %10867, i8* %13, align 1
  %10868 = xor i64 %10858, 16
  %10869 = xor i64 %10868, %10859
  %10870 = lshr i64 %10869, 4
  %10871 = trunc i64 %10870 to i8
  %10872 = and i8 %10871, 1
  store i8 %10872, i8* %14, align 1
  %10873 = icmp eq i64 %10859, 0
  %10874 = zext i1 %10873 to i8
  store i8 %10874, i8* %15, align 1
  %10875 = lshr i64 %10859, 63
  %10876 = trunc i64 %10875 to i8
  store i8 %10876, i8* %16, align 1
  %10877 = lshr i64 %10858, 63
  %10878 = xor i64 %10875, %10877
  %10879 = add nuw nsw i64 %10878, %10875
  %10880 = icmp eq i64 %10879, 2
  %10881 = zext i1 %10880 to i8
  store i8 %10881, i8* %17, align 1
  %10882 = add i64 %10845, -24
  %10883 = add i64 %10847, 31
  store i64 %10883, i64* %3, align 8
  %10884 = inttoptr i64 %10882 to i32*
  %10885 = load i32, i32* %10884, align 4
  %10886 = sext i32 %10885 to i64
  %10887 = shl nsw i64 %10886, 6
  store i64 %10887, i64* %RDX.i4094, align 8
  %10888 = add i64 %10887, %10859
  store i64 %10888, i64* %RCX.i3977, align 8
  %10889 = icmp ult i64 %10888, %10859
  %10890 = icmp ult i64 %10888, %10887
  %10891 = or i1 %10889, %10890
  %10892 = zext i1 %10891 to i8
  store i8 %10892, i8* %12, align 1
  %10893 = trunc i64 %10888 to i32
  %10894 = and i32 %10893, 255
  %10895 = tail call i32 @llvm.ctpop.i32(i32 %10894)
  %10896 = trunc i32 %10895 to i8
  %10897 = and i8 %10896, 1
  %10898 = xor i8 %10897, 1
  store i8 %10898, i8* %13, align 1
  %10899 = xor i64 %10859, %10888
  %10900 = lshr i64 %10899, 4
  %10901 = trunc i64 %10900 to i8
  %10902 = and i8 %10901, 1
  store i8 %10902, i8* %14, align 1
  %10903 = icmp eq i64 %10888, 0
  %10904 = zext i1 %10903 to i8
  store i8 %10904, i8* %15, align 1
  %10905 = lshr i64 %10888, 63
  %10906 = trunc i64 %10905 to i8
  store i8 %10906, i8* %16, align 1
  %10907 = lshr i64 %10886, 57
  %10908 = and i64 %10907, 1
  %10909 = xor i64 %10905, %10875
  %10910 = xor i64 %10905, %10908
  %10911 = add nuw nsw i64 %10909, %10910
  %10912 = icmp eq i64 %10911, 2
  %10913 = zext i1 %10912 to i8
  store i8 %10913, i8* %17, align 1
  %10914 = inttoptr i64 %10888 to i32*
  %10915 = load i32, i32* %EAX.i2609, align 4
  %10916 = add i64 %10847, 40
  store i64 %10916, i64* %3, align 8
  store i32 %10915, i32* %10914, align 4
  %10917 = load i64, i64* %RBP.i, align 8
  %10918 = add i64 %10917, -664
  %10919 = load i64, i64* %3, align 8
  %10920 = add i64 %10919, 6
  store i64 %10920, i64* %3, align 8
  %10921 = inttoptr i64 %10918 to i32*
  %10922 = load i32, i32* %10921, align 4
  %10923 = zext i32 %10922 to i64
  store i64 %10923, i64* %RAX.i2610, align 8
  %10924 = add i64 %10917, -652
  %10925 = add i64 %10919, 12
  store i64 %10925, i64* %3, align 8
  %10926 = inttoptr i64 %10924 to i32*
  %10927 = load i32, i32* %10926, align 4
  %10928 = add i32 %10927, %10922
  %10929 = zext i32 %10928 to i64
  store i64 %10929, i64* %RAX.i2610, align 8
  %10930 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %10931 = add i64 %10930, 13112
  store i64 %10931, i64* %RCX.i3977, align 8
  %10932 = icmp ugt i64 %10930, -13113
  %10933 = zext i1 %10932 to i8
  store i8 %10933, i8* %12, align 1
  %10934 = trunc i64 %10931 to i32
  %10935 = and i32 %10934, 255
  %10936 = tail call i32 @llvm.ctpop.i32(i32 %10935)
  %10937 = trunc i32 %10936 to i8
  %10938 = and i8 %10937, 1
  %10939 = xor i8 %10938, 1
  store i8 %10939, i8* %13, align 1
  %10940 = xor i64 %10930, 16
  %10941 = xor i64 %10940, %10931
  %10942 = lshr i64 %10941, 4
  %10943 = trunc i64 %10942 to i8
  %10944 = and i8 %10943, 1
  store i8 %10944, i8* %14, align 1
  %10945 = icmp eq i64 %10931, 0
  %10946 = zext i1 %10945 to i8
  store i8 %10946, i8* %15, align 1
  %10947 = lshr i64 %10931, 63
  %10948 = trunc i64 %10947 to i8
  store i8 %10948, i8* %16, align 1
  %10949 = lshr i64 %10930, 63
  %10950 = xor i64 %10947, %10949
  %10951 = add nuw nsw i64 %10950, %10947
  %10952 = icmp eq i64 %10951, 2
  %10953 = zext i1 %10952 to i8
  store i8 %10953, i8* %17, align 1
  %10954 = add i64 %10917, -24
  %10955 = add i64 %10919, 31
  store i64 %10955, i64* %3, align 8
  %10956 = inttoptr i64 %10954 to i32*
  %10957 = load i32, i32* %10956, align 4
  %10958 = sext i32 %10957 to i64
  %10959 = shl nsw i64 %10958, 6
  store i64 %10959, i64* %RDX.i4094, align 8
  %10960 = add i64 %10959, %10931
  store i64 %10960, i64* %RCX.i3977, align 8
  %10961 = icmp ult i64 %10960, %10931
  %10962 = icmp ult i64 %10960, %10959
  %10963 = or i1 %10961, %10962
  %10964 = zext i1 %10963 to i8
  store i8 %10964, i8* %12, align 1
  %10965 = trunc i64 %10960 to i32
  %10966 = and i32 %10965, 255
  %10967 = tail call i32 @llvm.ctpop.i32(i32 %10966)
  %10968 = trunc i32 %10967 to i8
  %10969 = and i8 %10968, 1
  %10970 = xor i8 %10969, 1
  store i8 %10970, i8* %13, align 1
  %10971 = xor i64 %10931, %10960
  %10972 = lshr i64 %10971, 4
  %10973 = trunc i64 %10972 to i8
  %10974 = and i8 %10973, 1
  store i8 %10974, i8* %14, align 1
  %10975 = icmp eq i64 %10960, 0
  %10976 = zext i1 %10975 to i8
  store i8 %10976, i8* %15, align 1
  %10977 = lshr i64 %10960, 63
  %10978 = trunc i64 %10977 to i8
  store i8 %10978, i8* %16, align 1
  %10979 = lshr i64 %10958, 57
  %10980 = and i64 %10979, 1
  %10981 = xor i64 %10977, %10947
  %10982 = xor i64 %10977, %10980
  %10983 = add nuw nsw i64 %10981, %10982
  %10984 = icmp eq i64 %10983, 2
  %10985 = zext i1 %10984 to i8
  store i8 %10985, i8* %17, align 1
  %10986 = add i64 %10960, 4
  %10987 = load i32, i32* %EAX.i2609, align 4
  %10988 = add i64 %10919, 41
  store i64 %10988, i64* %3, align 8
  %10989 = inttoptr i64 %10986 to i32*
  store i32 %10987, i32* %10989, align 4
  %10990 = load i64, i64* %RBP.i, align 8
  %10991 = add i64 %10990, -656
  %10992 = load i64, i64* %3, align 8
  %10993 = add i64 %10992, 6
  store i64 %10993, i64* %3, align 8
  %10994 = inttoptr i64 %10991 to i32*
  %10995 = load i32, i32* %10994, align 4
  %10996 = zext i32 %10995 to i64
  store i64 %10996, i64* %RAX.i2610, align 8
  %10997 = add i64 %10990, -660
  %10998 = add i64 %10992, 12
  store i64 %10998, i64* %3, align 8
  %10999 = inttoptr i64 %10997 to i32*
  %11000 = load i32, i32* %10999, align 4
  %11001 = add i32 %11000, %10995
  %11002 = zext i32 %11001 to i64
  store i64 %11002, i64* %RAX.i2610, align 8
  %11003 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11004 = add i64 %11003, 13112
  store i64 %11004, i64* %RCX.i3977, align 8
  %11005 = icmp ugt i64 %11003, -13113
  %11006 = zext i1 %11005 to i8
  store i8 %11006, i8* %12, align 1
  %11007 = trunc i64 %11004 to i32
  %11008 = and i32 %11007, 255
  %11009 = tail call i32 @llvm.ctpop.i32(i32 %11008)
  %11010 = trunc i32 %11009 to i8
  %11011 = and i8 %11010, 1
  %11012 = xor i8 %11011, 1
  store i8 %11012, i8* %13, align 1
  %11013 = xor i64 %11003, 16
  %11014 = xor i64 %11013, %11004
  %11015 = lshr i64 %11014, 4
  %11016 = trunc i64 %11015 to i8
  %11017 = and i8 %11016, 1
  store i8 %11017, i8* %14, align 1
  %11018 = icmp eq i64 %11004, 0
  %11019 = zext i1 %11018 to i8
  store i8 %11019, i8* %15, align 1
  %11020 = lshr i64 %11004, 63
  %11021 = trunc i64 %11020 to i8
  store i8 %11021, i8* %16, align 1
  %11022 = lshr i64 %11003, 63
  %11023 = xor i64 %11020, %11022
  %11024 = add nuw nsw i64 %11023, %11020
  %11025 = icmp eq i64 %11024, 2
  %11026 = zext i1 %11025 to i8
  store i8 %11026, i8* %17, align 1
  %11027 = add i64 %10990, -24
  %11028 = add i64 %10992, 31
  store i64 %11028, i64* %3, align 8
  %11029 = inttoptr i64 %11027 to i32*
  %11030 = load i32, i32* %11029, align 4
  %11031 = sext i32 %11030 to i64
  %11032 = shl nsw i64 %11031, 6
  store i64 %11032, i64* %RDX.i4094, align 8
  %11033 = add i64 %11032, %11004
  store i64 %11033, i64* %RCX.i3977, align 8
  %11034 = icmp ult i64 %11033, %11004
  %11035 = icmp ult i64 %11033, %11032
  %11036 = or i1 %11034, %11035
  %11037 = zext i1 %11036 to i8
  store i8 %11037, i8* %12, align 1
  %11038 = trunc i64 %11033 to i32
  %11039 = and i32 %11038, 255
  %11040 = tail call i32 @llvm.ctpop.i32(i32 %11039)
  %11041 = trunc i32 %11040 to i8
  %11042 = and i8 %11041, 1
  %11043 = xor i8 %11042, 1
  store i8 %11043, i8* %13, align 1
  %11044 = xor i64 %11004, %11033
  %11045 = lshr i64 %11044, 4
  %11046 = trunc i64 %11045 to i8
  %11047 = and i8 %11046, 1
  store i8 %11047, i8* %14, align 1
  %11048 = icmp eq i64 %11033, 0
  %11049 = zext i1 %11048 to i8
  store i8 %11049, i8* %15, align 1
  %11050 = lshr i64 %11033, 63
  %11051 = trunc i64 %11050 to i8
  store i8 %11051, i8* %16, align 1
  %11052 = lshr i64 %11031, 57
  %11053 = and i64 %11052, 1
  %11054 = xor i64 %11050, %11020
  %11055 = xor i64 %11050, %11053
  %11056 = add nuw nsw i64 %11054, %11055
  %11057 = icmp eq i64 %11056, 2
  %11058 = zext i1 %11057 to i8
  store i8 %11058, i8* %17, align 1
  %11059 = add i64 %11033, 8
  %11060 = load i32, i32* %EAX.i2609, align 4
  %11061 = add i64 %10992, 41
  store i64 %11061, i64* %3, align 8
  %11062 = inttoptr i64 %11059 to i32*
  store i32 %11060, i32* %11062, align 4
  %11063 = load i64, i64* %RBP.i, align 8
  %11064 = add i64 %11063, -648
  %11065 = load i64, i64* %3, align 8
  %11066 = add i64 %11065, 6
  store i64 %11066, i64* %3, align 8
  %11067 = inttoptr i64 %11064 to i32*
  %11068 = load i32, i32* %11067, align 4
  %11069 = zext i32 %11068 to i64
  store i64 %11069, i64* %RAX.i2610, align 8
  %11070 = add i64 %11063, -668
  %11071 = add i64 %11065, 12
  store i64 %11071, i64* %3, align 8
  %11072 = inttoptr i64 %11070 to i32*
  %11073 = load i32, i32* %11072, align 4
  %11074 = add i32 %11073, %11068
  %11075 = zext i32 %11074 to i64
  store i64 %11075, i64* %RAX.i2610, align 8
  %11076 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11077 = add i64 %11076, 13112
  store i64 %11077, i64* %RCX.i3977, align 8
  %11078 = icmp ugt i64 %11076, -13113
  %11079 = zext i1 %11078 to i8
  store i8 %11079, i8* %12, align 1
  %11080 = trunc i64 %11077 to i32
  %11081 = and i32 %11080, 255
  %11082 = tail call i32 @llvm.ctpop.i32(i32 %11081)
  %11083 = trunc i32 %11082 to i8
  %11084 = and i8 %11083, 1
  %11085 = xor i8 %11084, 1
  store i8 %11085, i8* %13, align 1
  %11086 = xor i64 %11076, 16
  %11087 = xor i64 %11086, %11077
  %11088 = lshr i64 %11087, 4
  %11089 = trunc i64 %11088 to i8
  %11090 = and i8 %11089, 1
  store i8 %11090, i8* %14, align 1
  %11091 = icmp eq i64 %11077, 0
  %11092 = zext i1 %11091 to i8
  store i8 %11092, i8* %15, align 1
  %11093 = lshr i64 %11077, 63
  %11094 = trunc i64 %11093 to i8
  store i8 %11094, i8* %16, align 1
  %11095 = lshr i64 %11076, 63
  %11096 = xor i64 %11093, %11095
  %11097 = add nuw nsw i64 %11096, %11093
  %11098 = icmp eq i64 %11097, 2
  %11099 = zext i1 %11098 to i8
  store i8 %11099, i8* %17, align 1
  %11100 = add i64 %11063, -24
  %11101 = add i64 %11065, 31
  store i64 %11101, i64* %3, align 8
  %11102 = inttoptr i64 %11100 to i32*
  %11103 = load i32, i32* %11102, align 4
  %11104 = sext i32 %11103 to i64
  %11105 = shl nsw i64 %11104, 6
  store i64 %11105, i64* %RDX.i4094, align 8
  %11106 = add i64 %11105, %11077
  store i64 %11106, i64* %RCX.i3977, align 8
  %11107 = icmp ult i64 %11106, %11077
  %11108 = icmp ult i64 %11106, %11105
  %11109 = or i1 %11107, %11108
  %11110 = zext i1 %11109 to i8
  store i8 %11110, i8* %12, align 1
  %11111 = trunc i64 %11106 to i32
  %11112 = and i32 %11111, 255
  %11113 = tail call i32 @llvm.ctpop.i32(i32 %11112)
  %11114 = trunc i32 %11113 to i8
  %11115 = and i8 %11114, 1
  %11116 = xor i8 %11115, 1
  store i8 %11116, i8* %13, align 1
  %11117 = xor i64 %11077, %11106
  %11118 = lshr i64 %11117, 4
  %11119 = trunc i64 %11118 to i8
  %11120 = and i8 %11119, 1
  store i8 %11120, i8* %14, align 1
  %11121 = icmp eq i64 %11106, 0
  %11122 = zext i1 %11121 to i8
  store i8 %11122, i8* %15, align 1
  %11123 = lshr i64 %11106, 63
  %11124 = trunc i64 %11123 to i8
  store i8 %11124, i8* %16, align 1
  %11125 = lshr i64 %11104, 57
  %11126 = and i64 %11125, 1
  %11127 = xor i64 %11123, %11093
  %11128 = xor i64 %11123, %11126
  %11129 = add nuw nsw i64 %11127, %11128
  %11130 = icmp eq i64 %11129, 2
  %11131 = zext i1 %11130 to i8
  store i8 %11131, i8* %17, align 1
  %11132 = add i64 %11106, 12
  %11133 = load i32, i32* %EAX.i2609, align 4
  %11134 = add i64 %11065, 41
  store i64 %11134, i64* %3, align 8
  %11135 = inttoptr i64 %11132 to i32*
  store i32 %11133, i32* %11135, align 4
  %11136 = load i64, i64* %RBP.i, align 8
  %11137 = add i64 %11136, -648
  %11138 = load i64, i64* %3, align 8
  %11139 = add i64 %11138, 6
  store i64 %11139, i64* %3, align 8
  %11140 = inttoptr i64 %11137 to i32*
  %11141 = load i32, i32* %11140, align 4
  %11142 = zext i32 %11141 to i64
  store i64 %11142, i64* %RAX.i2610, align 8
  %11143 = add i64 %11136, -668
  %11144 = add i64 %11138, 12
  store i64 %11144, i64* %3, align 8
  %11145 = inttoptr i64 %11143 to i32*
  %11146 = load i32, i32* %11145, align 4
  %11147 = sub i32 %11141, %11146
  %11148 = zext i32 %11147 to i64
  store i64 %11148, i64* %RAX.i2610, align 8
  %11149 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11150 = add i64 %11149, 13112
  store i64 %11150, i64* %RCX.i3977, align 8
  %11151 = icmp ugt i64 %11149, -13113
  %11152 = zext i1 %11151 to i8
  store i8 %11152, i8* %12, align 1
  %11153 = trunc i64 %11150 to i32
  %11154 = and i32 %11153, 255
  %11155 = tail call i32 @llvm.ctpop.i32(i32 %11154)
  %11156 = trunc i32 %11155 to i8
  %11157 = and i8 %11156, 1
  %11158 = xor i8 %11157, 1
  store i8 %11158, i8* %13, align 1
  %11159 = xor i64 %11149, 16
  %11160 = xor i64 %11159, %11150
  %11161 = lshr i64 %11160, 4
  %11162 = trunc i64 %11161 to i8
  %11163 = and i8 %11162, 1
  store i8 %11163, i8* %14, align 1
  %11164 = icmp eq i64 %11150, 0
  %11165 = zext i1 %11164 to i8
  store i8 %11165, i8* %15, align 1
  %11166 = lshr i64 %11150, 63
  %11167 = trunc i64 %11166 to i8
  store i8 %11167, i8* %16, align 1
  %11168 = lshr i64 %11149, 63
  %11169 = xor i64 %11166, %11168
  %11170 = add nuw nsw i64 %11169, %11166
  %11171 = icmp eq i64 %11170, 2
  %11172 = zext i1 %11171 to i8
  store i8 %11172, i8* %17, align 1
  %11173 = add i64 %11136, -24
  %11174 = add i64 %11138, 31
  store i64 %11174, i64* %3, align 8
  %11175 = inttoptr i64 %11173 to i32*
  %11176 = load i32, i32* %11175, align 4
  %11177 = sext i32 %11176 to i64
  %11178 = shl nsw i64 %11177, 6
  store i64 %11178, i64* %RDX.i4094, align 8
  %11179 = add i64 %11178, %11150
  store i64 %11179, i64* %RCX.i3977, align 8
  %11180 = icmp ult i64 %11179, %11150
  %11181 = icmp ult i64 %11179, %11178
  %11182 = or i1 %11180, %11181
  %11183 = zext i1 %11182 to i8
  store i8 %11183, i8* %12, align 1
  %11184 = trunc i64 %11179 to i32
  %11185 = and i32 %11184, 255
  %11186 = tail call i32 @llvm.ctpop.i32(i32 %11185)
  %11187 = trunc i32 %11186 to i8
  %11188 = and i8 %11187, 1
  %11189 = xor i8 %11188, 1
  store i8 %11189, i8* %13, align 1
  %11190 = xor i64 %11150, %11179
  %11191 = lshr i64 %11190, 4
  %11192 = trunc i64 %11191 to i8
  %11193 = and i8 %11192, 1
  store i8 %11193, i8* %14, align 1
  %11194 = icmp eq i64 %11179, 0
  %11195 = zext i1 %11194 to i8
  store i8 %11195, i8* %15, align 1
  %11196 = lshr i64 %11179, 63
  %11197 = trunc i64 %11196 to i8
  store i8 %11197, i8* %16, align 1
  %11198 = lshr i64 %11177, 57
  %11199 = and i64 %11198, 1
  %11200 = xor i64 %11196, %11166
  %11201 = xor i64 %11196, %11199
  %11202 = add nuw nsw i64 %11200, %11201
  %11203 = icmp eq i64 %11202, 2
  %11204 = zext i1 %11203 to i8
  store i8 %11204, i8* %17, align 1
  %11205 = add i64 %11179, 16
  %11206 = load i32, i32* %EAX.i2609, align 4
  %11207 = add i64 %11138, 41
  store i64 %11207, i64* %3, align 8
  %11208 = inttoptr i64 %11205 to i32*
  store i32 %11206, i32* %11208, align 4
  %11209 = load i64, i64* %RBP.i, align 8
  %11210 = add i64 %11209, -656
  %11211 = load i64, i64* %3, align 8
  %11212 = add i64 %11211, 6
  store i64 %11212, i64* %3, align 8
  %11213 = inttoptr i64 %11210 to i32*
  %11214 = load i32, i32* %11213, align 4
  %11215 = zext i32 %11214 to i64
  store i64 %11215, i64* %RAX.i2610, align 8
  %11216 = add i64 %11209, -660
  %11217 = add i64 %11211, 12
  store i64 %11217, i64* %3, align 8
  %11218 = inttoptr i64 %11216 to i32*
  %11219 = load i32, i32* %11218, align 4
  %11220 = sub i32 %11214, %11219
  %11221 = zext i32 %11220 to i64
  store i64 %11221, i64* %RAX.i2610, align 8
  %11222 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11223 = add i64 %11222, 13112
  store i64 %11223, i64* %RCX.i3977, align 8
  %11224 = icmp ugt i64 %11222, -13113
  %11225 = zext i1 %11224 to i8
  store i8 %11225, i8* %12, align 1
  %11226 = trunc i64 %11223 to i32
  %11227 = and i32 %11226, 255
  %11228 = tail call i32 @llvm.ctpop.i32(i32 %11227)
  %11229 = trunc i32 %11228 to i8
  %11230 = and i8 %11229, 1
  %11231 = xor i8 %11230, 1
  store i8 %11231, i8* %13, align 1
  %11232 = xor i64 %11222, 16
  %11233 = xor i64 %11232, %11223
  %11234 = lshr i64 %11233, 4
  %11235 = trunc i64 %11234 to i8
  %11236 = and i8 %11235, 1
  store i8 %11236, i8* %14, align 1
  %11237 = icmp eq i64 %11223, 0
  %11238 = zext i1 %11237 to i8
  store i8 %11238, i8* %15, align 1
  %11239 = lshr i64 %11223, 63
  %11240 = trunc i64 %11239 to i8
  store i8 %11240, i8* %16, align 1
  %11241 = lshr i64 %11222, 63
  %11242 = xor i64 %11239, %11241
  %11243 = add nuw nsw i64 %11242, %11239
  %11244 = icmp eq i64 %11243, 2
  %11245 = zext i1 %11244 to i8
  store i8 %11245, i8* %17, align 1
  %11246 = add i64 %11209, -24
  %11247 = add i64 %11211, 31
  store i64 %11247, i64* %3, align 8
  %11248 = inttoptr i64 %11246 to i32*
  %11249 = load i32, i32* %11248, align 4
  %11250 = sext i32 %11249 to i64
  %11251 = shl nsw i64 %11250, 6
  store i64 %11251, i64* %RDX.i4094, align 8
  %11252 = add i64 %11251, %11223
  store i64 %11252, i64* %RCX.i3977, align 8
  %11253 = icmp ult i64 %11252, %11223
  %11254 = icmp ult i64 %11252, %11251
  %11255 = or i1 %11253, %11254
  %11256 = zext i1 %11255 to i8
  store i8 %11256, i8* %12, align 1
  %11257 = trunc i64 %11252 to i32
  %11258 = and i32 %11257, 255
  %11259 = tail call i32 @llvm.ctpop.i32(i32 %11258)
  %11260 = trunc i32 %11259 to i8
  %11261 = and i8 %11260, 1
  %11262 = xor i8 %11261, 1
  store i8 %11262, i8* %13, align 1
  %11263 = xor i64 %11223, %11252
  %11264 = lshr i64 %11263, 4
  %11265 = trunc i64 %11264 to i8
  %11266 = and i8 %11265, 1
  store i8 %11266, i8* %14, align 1
  %11267 = icmp eq i64 %11252, 0
  %11268 = zext i1 %11267 to i8
  store i8 %11268, i8* %15, align 1
  %11269 = lshr i64 %11252, 63
  %11270 = trunc i64 %11269 to i8
  store i8 %11270, i8* %16, align 1
  %11271 = lshr i64 %11250, 57
  %11272 = and i64 %11271, 1
  %11273 = xor i64 %11269, %11239
  %11274 = xor i64 %11269, %11272
  %11275 = add nuw nsw i64 %11273, %11274
  %11276 = icmp eq i64 %11275, 2
  %11277 = zext i1 %11276 to i8
  store i8 %11277, i8* %17, align 1
  %11278 = add i64 %11252, 20
  %11279 = load i32, i32* %EAX.i2609, align 4
  %11280 = add i64 %11211, 41
  store i64 %11280, i64* %3, align 8
  %11281 = inttoptr i64 %11278 to i32*
  store i32 %11279, i32* %11281, align 4
  %11282 = load i64, i64* %RBP.i, align 8
  %11283 = add i64 %11282, -664
  %11284 = load i64, i64* %3, align 8
  %11285 = add i64 %11284, 6
  store i64 %11285, i64* %3, align 8
  %11286 = inttoptr i64 %11283 to i32*
  %11287 = load i32, i32* %11286, align 4
  %11288 = zext i32 %11287 to i64
  store i64 %11288, i64* %RAX.i2610, align 8
  %11289 = add i64 %11282, -652
  %11290 = add i64 %11284, 12
  store i64 %11290, i64* %3, align 8
  %11291 = inttoptr i64 %11289 to i32*
  %11292 = load i32, i32* %11291, align 4
  %11293 = sub i32 %11287, %11292
  %11294 = zext i32 %11293 to i64
  store i64 %11294, i64* %RAX.i2610, align 8
  %11295 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11296 = add i64 %11295, 13112
  store i64 %11296, i64* %RCX.i3977, align 8
  %11297 = icmp ugt i64 %11295, -13113
  %11298 = zext i1 %11297 to i8
  store i8 %11298, i8* %12, align 1
  %11299 = trunc i64 %11296 to i32
  %11300 = and i32 %11299, 255
  %11301 = tail call i32 @llvm.ctpop.i32(i32 %11300)
  %11302 = trunc i32 %11301 to i8
  %11303 = and i8 %11302, 1
  %11304 = xor i8 %11303, 1
  store i8 %11304, i8* %13, align 1
  %11305 = xor i64 %11295, 16
  %11306 = xor i64 %11305, %11296
  %11307 = lshr i64 %11306, 4
  %11308 = trunc i64 %11307 to i8
  %11309 = and i8 %11308, 1
  store i8 %11309, i8* %14, align 1
  %11310 = icmp eq i64 %11296, 0
  %11311 = zext i1 %11310 to i8
  store i8 %11311, i8* %15, align 1
  %11312 = lshr i64 %11296, 63
  %11313 = trunc i64 %11312 to i8
  store i8 %11313, i8* %16, align 1
  %11314 = lshr i64 %11295, 63
  %11315 = xor i64 %11312, %11314
  %11316 = add nuw nsw i64 %11315, %11312
  %11317 = icmp eq i64 %11316, 2
  %11318 = zext i1 %11317 to i8
  store i8 %11318, i8* %17, align 1
  %11319 = add i64 %11282, -24
  %11320 = add i64 %11284, 31
  store i64 %11320, i64* %3, align 8
  %11321 = inttoptr i64 %11319 to i32*
  %11322 = load i32, i32* %11321, align 4
  %11323 = sext i32 %11322 to i64
  %11324 = shl nsw i64 %11323, 6
  store i64 %11324, i64* %RDX.i4094, align 8
  %11325 = add i64 %11324, %11296
  store i64 %11325, i64* %RCX.i3977, align 8
  %11326 = icmp ult i64 %11325, %11296
  %11327 = icmp ult i64 %11325, %11324
  %11328 = or i1 %11326, %11327
  %11329 = zext i1 %11328 to i8
  store i8 %11329, i8* %12, align 1
  %11330 = trunc i64 %11325 to i32
  %11331 = and i32 %11330, 255
  %11332 = tail call i32 @llvm.ctpop.i32(i32 %11331)
  %11333 = trunc i32 %11332 to i8
  %11334 = and i8 %11333, 1
  %11335 = xor i8 %11334, 1
  store i8 %11335, i8* %13, align 1
  %11336 = xor i64 %11296, %11325
  %11337 = lshr i64 %11336, 4
  %11338 = trunc i64 %11337 to i8
  %11339 = and i8 %11338, 1
  store i8 %11339, i8* %14, align 1
  %11340 = icmp eq i64 %11325, 0
  %11341 = zext i1 %11340 to i8
  store i8 %11341, i8* %15, align 1
  %11342 = lshr i64 %11325, 63
  %11343 = trunc i64 %11342 to i8
  store i8 %11343, i8* %16, align 1
  %11344 = lshr i64 %11323, 57
  %11345 = and i64 %11344, 1
  %11346 = xor i64 %11342, %11312
  %11347 = xor i64 %11342, %11345
  %11348 = add nuw nsw i64 %11346, %11347
  %11349 = icmp eq i64 %11348, 2
  %11350 = zext i1 %11349 to i8
  store i8 %11350, i8* %17, align 1
  %11351 = add i64 %11325, 24
  %11352 = load i32, i32* %EAX.i2609, align 4
  %11353 = add i64 %11284, 41
  store i64 %11353, i64* %3, align 8
  %11354 = inttoptr i64 %11351 to i32*
  store i32 %11352, i32* %11354, align 4
  %11355 = load i64, i64* %RBP.i, align 8
  %11356 = add i64 %11355, -672
  %11357 = load i64, i64* %3, align 8
  %11358 = add i64 %11357, 6
  store i64 %11358, i64* %3, align 8
  %11359 = inttoptr i64 %11356 to i32*
  %11360 = load i32, i32* %11359, align 4
  %11361 = zext i32 %11360 to i64
  store i64 %11361, i64* %RAX.i2610, align 8
  %11362 = add i64 %11355, -644
  %11363 = add i64 %11357, 12
  store i64 %11363, i64* %3, align 8
  %11364 = inttoptr i64 %11362 to i32*
  %11365 = load i32, i32* %11364, align 4
  %11366 = sub i32 %11360, %11365
  %11367 = zext i32 %11366 to i64
  store i64 %11367, i64* %RAX.i2610, align 8
  %11368 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11369 = add i64 %11368, 13112
  store i64 %11369, i64* %RCX.i3977, align 8
  %11370 = icmp ugt i64 %11368, -13113
  %11371 = zext i1 %11370 to i8
  store i8 %11371, i8* %12, align 1
  %11372 = trunc i64 %11369 to i32
  %11373 = and i32 %11372, 255
  %11374 = tail call i32 @llvm.ctpop.i32(i32 %11373)
  %11375 = trunc i32 %11374 to i8
  %11376 = and i8 %11375, 1
  %11377 = xor i8 %11376, 1
  store i8 %11377, i8* %13, align 1
  %11378 = xor i64 %11368, 16
  %11379 = xor i64 %11378, %11369
  %11380 = lshr i64 %11379, 4
  %11381 = trunc i64 %11380 to i8
  %11382 = and i8 %11381, 1
  store i8 %11382, i8* %14, align 1
  %11383 = icmp eq i64 %11369, 0
  %11384 = zext i1 %11383 to i8
  store i8 %11384, i8* %15, align 1
  %11385 = lshr i64 %11369, 63
  %11386 = trunc i64 %11385 to i8
  store i8 %11386, i8* %16, align 1
  %11387 = lshr i64 %11368, 63
  %11388 = xor i64 %11385, %11387
  %11389 = add nuw nsw i64 %11388, %11385
  %11390 = icmp eq i64 %11389, 2
  %11391 = zext i1 %11390 to i8
  store i8 %11391, i8* %17, align 1
  %11392 = add i64 %11355, -24
  %11393 = add i64 %11357, 31
  store i64 %11393, i64* %3, align 8
  %11394 = inttoptr i64 %11392 to i32*
  %11395 = load i32, i32* %11394, align 4
  %11396 = sext i32 %11395 to i64
  %11397 = shl nsw i64 %11396, 6
  store i64 %11397, i64* %RDX.i4094, align 8
  %11398 = add i64 %11397, %11369
  store i64 %11398, i64* %RCX.i3977, align 8
  %11399 = icmp ult i64 %11398, %11369
  %11400 = icmp ult i64 %11398, %11397
  %11401 = or i1 %11399, %11400
  %11402 = zext i1 %11401 to i8
  store i8 %11402, i8* %12, align 1
  %11403 = trunc i64 %11398 to i32
  %11404 = and i32 %11403, 255
  %11405 = tail call i32 @llvm.ctpop.i32(i32 %11404)
  %11406 = trunc i32 %11405 to i8
  %11407 = and i8 %11406, 1
  %11408 = xor i8 %11407, 1
  store i8 %11408, i8* %13, align 1
  %11409 = xor i64 %11369, %11398
  %11410 = lshr i64 %11409, 4
  %11411 = trunc i64 %11410 to i8
  %11412 = and i8 %11411, 1
  store i8 %11412, i8* %14, align 1
  %11413 = icmp eq i64 %11398, 0
  %11414 = zext i1 %11413 to i8
  store i8 %11414, i8* %15, align 1
  %11415 = lshr i64 %11398, 63
  %11416 = trunc i64 %11415 to i8
  store i8 %11416, i8* %16, align 1
  %11417 = lshr i64 %11396, 57
  %11418 = and i64 %11417, 1
  %11419 = xor i64 %11415, %11385
  %11420 = xor i64 %11415, %11418
  %11421 = add nuw nsw i64 %11419, %11420
  %11422 = icmp eq i64 %11421, 2
  %11423 = zext i1 %11422 to i8
  store i8 %11423, i8* %17, align 1
  %11424 = add i64 %11398, 28
  %11425 = load i32, i32* %EAX.i2609, align 4
  %11426 = add i64 %11357, 41
  store i64 %11426, i64* %3, align 8
  %11427 = inttoptr i64 %11424 to i32*
  store i32 %11425, i32* %11427, align 4
  %11428 = load i64, i64* %RBP.i, align 8
  %11429 = add i64 %11428, -24
  %11430 = load i64, i64* %3, align 8
  %11431 = add i64 %11430, 3
  store i64 %11431, i64* %3, align 8
  %11432 = inttoptr i64 %11429 to i32*
  %11433 = load i32, i32* %11432, align 4
  %11434 = add i32 %11433, 1
  %11435 = zext i32 %11434 to i64
  store i64 %11435, i64* %RAX.i2610, align 8
  %11436 = icmp eq i32 %11433, -1
  %11437 = icmp eq i32 %11434, 0
  %11438 = or i1 %11436, %11437
  %11439 = zext i1 %11438 to i8
  store i8 %11439, i8* %12, align 1
  %11440 = and i32 %11434, 255
  %11441 = tail call i32 @llvm.ctpop.i32(i32 %11440)
  %11442 = trunc i32 %11441 to i8
  %11443 = and i8 %11442, 1
  %11444 = xor i8 %11443, 1
  store i8 %11444, i8* %13, align 1
  %11445 = xor i32 %11434, %11433
  %11446 = lshr i32 %11445, 4
  %11447 = trunc i32 %11446 to i8
  %11448 = and i8 %11447, 1
  store i8 %11448, i8* %14, align 1
  %11449 = zext i1 %11437 to i8
  store i8 %11449, i8* %15, align 1
  %11450 = lshr i32 %11434, 31
  %11451 = trunc i32 %11450 to i8
  store i8 %11451, i8* %16, align 1
  %11452 = lshr i32 %11433, 31
  %11453 = xor i32 %11450, %11452
  %11454 = add nuw nsw i32 %11453, %11450
  %11455 = icmp eq i32 %11454, 2
  %11456 = zext i1 %11455 to i8
  store i8 %11456, i8* %17, align 1
  %11457 = add i64 %11430, 9
  store i64 %11457, i64* %3, align 8
  store i32 %11434, i32* %11432, align 4
  %11458 = load i64, i64* %3, align 8
  %11459 = add i64 %11458, -1065
  store i64 %11459, i64* %3, align 8
  br label %block_.L_4abb3f

block_.L_4abf74:                                  ; preds = %block_.L_4ac2c8, %block_4abb73
  %11460 = phi i64 [ %12990, %block_.L_4ac2c8 ], [ %.pre183, %block_4abb73 ]
  %11461 = load i64, i64* %RBP.i, align 8
  %11462 = add i64 %11461, -24
  %11463 = add i64 %11460, 4
  store i64 %11463, i64* %3, align 8
  %11464 = inttoptr i64 %11462 to i32*
  %11465 = load i32, i32* %11464, align 4
  %11466 = add i32 %11465, -8
  %11467 = icmp ult i32 %11465, 8
  %11468 = zext i1 %11467 to i8
  store i8 %11468, i8* %12, align 1
  %11469 = and i32 %11466, 255
  %11470 = tail call i32 @llvm.ctpop.i32(i32 %11469)
  %11471 = trunc i32 %11470 to i8
  %11472 = and i8 %11471, 1
  %11473 = xor i8 %11472, 1
  store i8 %11473, i8* %13, align 1
  %11474 = xor i32 %11466, %11465
  %11475 = lshr i32 %11474, 4
  %11476 = trunc i32 %11475 to i8
  %11477 = and i8 %11476, 1
  store i8 %11477, i8* %14, align 1
  %11478 = icmp eq i32 %11466, 0
  %11479 = zext i1 %11478 to i8
  store i8 %11479, i8* %15, align 1
  %11480 = lshr i32 %11466, 31
  %11481 = trunc i32 %11480 to i8
  store i8 %11481, i8* %16, align 1
  %11482 = lshr i32 %11465, 31
  %11483 = xor i32 %11480, %11482
  %11484 = add nuw nsw i32 %11483, %11482
  %11485 = icmp eq i32 %11484, 2
  %11486 = zext i1 %11485 to i8
  store i8 %11486, i8* %17, align 1
  %11487 = icmp ne i8 %11481, 0
  %11488 = xor i1 %11487, %11485
  %.v213 = select i1 %11488, i64 10, i64 871
  %11489 = add i64 %11460, %.v213
  store i64 %11489, i64* %3, align 8
  br i1 %11488, label %block_4abf7e, label %block_.L_4ac2db

block_4abf7e:                                     ; preds = %block_.L_4abf74
  %11490 = add i64 %11461, -28
  %11491 = add i64 %11489, 7
  store i64 %11491, i64* %3, align 8
  %11492 = inttoptr i64 %11490 to i32*
  store i32 0, i32* %11492, align 4
  %.pre186 = load i64, i64* %3, align 8
  br label %block_.L_4abf85

block_.L_4abf85:                                  ; preds = %block_.L_4ac2b5, %block_4abf7e
  %11493 = phi i64 [ %12960, %block_.L_4ac2b5 ], [ %.pre186, %block_4abf7e ]
  %11494 = load i64, i64* %RBP.i, align 8
  %11495 = add i64 %11494, -28
  %11496 = add i64 %11493, 4
  store i64 %11496, i64* %3, align 8
  %11497 = inttoptr i64 %11495 to i32*
  %11498 = load i32, i32* %11497, align 4
  %11499 = add i32 %11498, -8
  %11500 = icmp ult i32 %11498, 8
  %11501 = zext i1 %11500 to i8
  store i8 %11501, i8* %12, align 1
  %11502 = and i32 %11499, 255
  %11503 = tail call i32 @llvm.ctpop.i32(i32 %11502)
  %11504 = trunc i32 %11503 to i8
  %11505 = and i8 %11504, 1
  %11506 = xor i8 %11505, 1
  store i8 %11506, i8* %13, align 1
  %11507 = xor i32 %11499, %11498
  %11508 = lshr i32 %11507, 4
  %11509 = trunc i32 %11508 to i8
  %11510 = and i8 %11509, 1
  store i8 %11510, i8* %14, align 1
  %11511 = icmp eq i32 %11499, 0
  %11512 = zext i1 %11511 to i8
  store i8 %11512, i8* %15, align 1
  %11513 = lshr i32 %11499, 31
  %11514 = trunc i32 %11513 to i8
  store i8 %11514, i8* %16, align 1
  %11515 = lshr i32 %11498, 31
  %11516 = xor i32 %11513, %11515
  %11517 = add nuw nsw i32 %11516, %11515
  %11518 = icmp eq i32 %11517, 2
  %11519 = zext i1 %11518 to i8
  store i8 %11519, i8* %17, align 1
  %11520 = icmp ne i8 %11514, 0
  %11521 = xor i1 %11520, %11518
  %.v205 = select i1 %11521, i64 10, i64 835
  %11522 = add i64 %11493, %.v205
  store i64 %11522, i64* %3, align 8
  br i1 %11521, label %block_4abf8f, label %block_.L_4ac2c8

block_4abf8f:                                     ; preds = %block_.L_4abf85
  %11523 = add i64 %11494, -412
  %11524 = add i64 %11522, 7
  store i64 %11524, i64* %3, align 8
  %11525 = inttoptr i64 %11523 to i32*
  %11526 = load i32, i32* %11525, align 4
  store i8 0, i8* %12, align 1
  %11527 = and i32 %11526, 255
  %11528 = tail call i32 @llvm.ctpop.i32(i32 %11527)
  %11529 = trunc i32 %11528 to i8
  %11530 = and i8 %11529, 1
  %11531 = xor i8 %11530, 1
  store i8 %11531, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %11532 = icmp eq i32 %11526, 0
  %11533 = zext i1 %11532 to i8
  store i8 %11533, i8* %15, align 1
  %11534 = lshr i32 %11526, 31
  %11535 = trunc i32 %11534 to i8
  store i8 %11535, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v216 = select i1 %11532, i64 127, i64 13
  %11536 = add i64 %11522, %.v216
  %11537 = add i64 %11536, 8
  store i64 %11537, i64* %3, align 8
  %11538 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %11538, i64* %RAX.i2610, align 8
  br i1 %11532, label %block_.L_4ac00e, label %block_4abf9c

block_4abf9c:                                     ; preds = %block_4abf8f
  %11539 = add i64 %11538, 13112
  store i64 %11539, i64* %RAX.i2610, align 8
  %11540 = icmp ugt i64 %11538, -13113
  %11541 = zext i1 %11540 to i8
  store i8 %11541, i8* %12, align 1
  %11542 = trunc i64 %11539 to i32
  %11543 = and i32 %11542, 255
  %11544 = tail call i32 @llvm.ctpop.i32(i32 %11543)
  %11545 = trunc i32 %11544 to i8
  %11546 = and i8 %11545, 1
  %11547 = xor i8 %11546, 1
  store i8 %11547, i8* %13, align 1
  %11548 = xor i64 %11538, 16
  %11549 = xor i64 %11548, %11539
  %11550 = lshr i64 %11549, 4
  %11551 = trunc i64 %11550 to i8
  %11552 = and i8 %11551, 1
  store i8 %11552, i8* %14, align 1
  %11553 = icmp eq i64 %11539, 0
  %11554 = zext i1 %11553 to i8
  store i8 %11554, i8* %15, align 1
  %11555 = lshr i64 %11539, 63
  %11556 = trunc i64 %11555 to i8
  store i8 %11556, i8* %16, align 1
  %11557 = lshr i64 %11538, 63
  %11558 = xor i64 %11555, %11557
  %11559 = add nuw nsw i64 %11558, %11555
  %11560 = icmp eq i64 %11559, 2
  %11561 = zext i1 %11560 to i8
  store i8 %11561, i8* %17, align 1
  %11562 = add i64 %11494, -24
  %11563 = add i64 %11536, 18
  store i64 %11563, i64* %3, align 8
  %11564 = inttoptr i64 %11562 to i32*
  %11565 = load i32, i32* %11564, align 4
  %11566 = sext i32 %11565 to i64
  %11567 = shl nsw i64 %11566, 6
  store i64 %11567, i64* %RCX.i3977, align 8
  %11568 = add i64 %11567, %11539
  store i64 %11568, i64* %RAX.i2610, align 8
  %11569 = icmp ult i64 %11568, %11539
  %11570 = icmp ult i64 %11568, %11567
  %11571 = or i1 %11569, %11570
  %11572 = zext i1 %11571 to i8
  store i8 %11572, i8* %12, align 1
  %11573 = trunc i64 %11568 to i32
  %11574 = and i32 %11573, 255
  %11575 = tail call i32 @llvm.ctpop.i32(i32 %11574)
  %11576 = trunc i32 %11575 to i8
  %11577 = and i8 %11576, 1
  %11578 = xor i8 %11577, 1
  store i8 %11578, i8* %13, align 1
  %11579 = xor i64 %11539, %11568
  %11580 = lshr i64 %11579, 4
  %11581 = trunc i64 %11580 to i8
  %11582 = and i8 %11581, 1
  store i8 %11582, i8* %14, align 1
  %11583 = icmp eq i64 %11568, 0
  %11584 = zext i1 %11583 to i8
  store i8 %11584, i8* %15, align 1
  %11585 = lshr i64 %11568, 63
  %11586 = trunc i64 %11585 to i8
  store i8 %11586, i8* %16, align 1
  %11587 = lshr i64 %11566, 57
  %11588 = and i64 %11587, 1
  %11589 = xor i64 %11585, %11555
  %11590 = xor i64 %11585, %11588
  %11591 = add nuw nsw i64 %11589, %11590
  %11592 = icmp eq i64 %11591, 2
  %11593 = zext i1 %11592 to i8
  store i8 %11593, i8* %17, align 1
  %11594 = add i64 %11536, 29
  store i64 %11594, i64* %3, align 8
  %11595 = load i32, i32* %11497, align 4
  %11596 = sext i32 %11595 to i64
  store i64 %11596, i64* %RCX.i3977, align 8
  %11597 = shl nsw i64 %11596, 2
  %11598 = add i64 %11597, %11568
  %11599 = add i64 %11536, 32
  store i64 %11599, i64* %3, align 8
  %11600 = inttoptr i64 %11598 to i32*
  %11601 = load i32, i32* %11600, align 4
  %11602 = zext i32 %11601 to i64
  store i64 %11602, i64* %RDX.i4094, align 8
  %11603 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11604 = add i64 %11603, 12600
  store i64 %11604, i64* %RAX.i2610, align 8
  %11605 = icmp ugt i64 %11603, -12601
  %11606 = zext i1 %11605 to i8
  store i8 %11606, i8* %12, align 1
  %11607 = trunc i64 %11604 to i32
  %11608 = and i32 %11607, 255
  %11609 = tail call i32 @llvm.ctpop.i32(i32 %11608)
  %11610 = trunc i32 %11609 to i8
  %11611 = and i8 %11610, 1
  %11612 = xor i8 %11611, 1
  store i8 %11612, i8* %13, align 1
  %11613 = xor i64 %11603, 16
  %11614 = xor i64 %11613, %11604
  %11615 = lshr i64 %11614, 4
  %11616 = trunc i64 %11615 to i8
  %11617 = and i8 %11616, 1
  store i8 %11617, i8* %14, align 1
  %11618 = icmp eq i64 %11604, 0
  %11619 = zext i1 %11618 to i8
  store i8 %11619, i8* %15, align 1
  %11620 = lshr i64 %11604, 63
  %11621 = trunc i64 %11620 to i8
  store i8 %11621, i8* %16, align 1
  %11622 = lshr i64 %11603, 63
  %11623 = xor i64 %11620, %11622
  %11624 = add nuw nsw i64 %11623, %11620
  %11625 = icmp eq i64 %11624, 2
  %11626 = zext i1 %11625 to i8
  store i8 %11626, i8* %17, align 1
  %11627 = load i64, i64* %RBP.i, align 8
  %11628 = add i64 %11627, -24
  %11629 = add i64 %11536, 49
  store i64 %11629, i64* %3, align 8
  %11630 = inttoptr i64 %11628 to i32*
  %11631 = load i32, i32* %11630, align 4
  %11632 = zext i32 %11631 to i64
  store i64 %11632, i64* %RSI.i3950, align 8
  %11633 = add i64 %11627, -84
  %11634 = add i64 %11536, 52
  store i64 %11634, i64* %3, align 8
  %11635 = inttoptr i64 %11633 to i32*
  %11636 = load i32, i32* %11635, align 4
  %11637 = add i32 %11636, %11631
  %11638 = zext i32 %11637 to i64
  store i64 %11638, i64* %RSI.i3950, align 8
  %11639 = sext i32 %11637 to i64
  %11640 = shl nsw i64 %11639, 5
  store i64 %11640, i64* %RCX.i3977, align 8
  %11641 = load i64, i64* %RAX.i2610, align 8
  %11642 = add i64 %11640, %11641
  store i64 %11642, i64* %RAX.i2610, align 8
  %11643 = icmp ult i64 %11642, %11641
  %11644 = icmp ult i64 %11642, %11640
  %11645 = or i1 %11643, %11644
  %11646 = zext i1 %11645 to i8
  store i8 %11646, i8* %12, align 1
  %11647 = trunc i64 %11642 to i32
  %11648 = and i32 %11647, 255
  %11649 = tail call i32 @llvm.ctpop.i32(i32 %11648)
  %11650 = trunc i32 %11649 to i8
  %11651 = and i8 %11650, 1
  %11652 = xor i8 %11651, 1
  store i8 %11652, i8* %13, align 1
  %11653 = xor i64 %11641, %11642
  %11654 = lshr i64 %11653, 4
  %11655 = trunc i64 %11654 to i8
  %11656 = and i8 %11655, 1
  store i8 %11656, i8* %14, align 1
  %11657 = icmp eq i64 %11642, 0
  %11658 = zext i1 %11657 to i8
  store i8 %11658, i8* %15, align 1
  %11659 = lshr i64 %11642, 63
  %11660 = trunc i64 %11659 to i8
  store i8 %11660, i8* %16, align 1
  %11661 = lshr i64 %11641, 63
  %11662 = lshr i64 %11639, 58
  %11663 = and i64 %11662, 1
  %11664 = xor i64 %11659, %11661
  %11665 = xor i64 %11659, %11663
  %11666 = add nuw nsw i64 %11664, %11665
  %11667 = icmp eq i64 %11666, 2
  %11668 = zext i1 %11667 to i8
  store i8 %11668, i8* %17, align 1
  %11669 = load i64, i64* %RBP.i, align 8
  %11670 = add i64 %11669, -28
  %11671 = add i64 %11536, 65
  store i64 %11671, i64* %3, align 8
  %11672 = inttoptr i64 %11670 to i32*
  %11673 = load i32, i32* %11672, align 4
  %11674 = zext i32 %11673 to i64
  store i64 %11674, i64* %RSI.i3950, align 8
  %11675 = add i64 %11669, -88
  %11676 = add i64 %11536, 68
  store i64 %11676, i64* %3, align 8
  %11677 = inttoptr i64 %11675 to i32*
  %11678 = load i32, i32* %11677, align 4
  %11679 = add i32 %11678, %11673
  %11680 = zext i32 %11679 to i64
  store i64 %11680, i64* %RSI.i3950, align 8
  %11681 = icmp ult i32 %11679, %11673
  %11682 = icmp ult i32 %11679, %11678
  %11683 = or i1 %11681, %11682
  %11684 = zext i1 %11683 to i8
  store i8 %11684, i8* %12, align 1
  %11685 = and i32 %11679, 255
  %11686 = tail call i32 @llvm.ctpop.i32(i32 %11685)
  %11687 = trunc i32 %11686 to i8
  %11688 = and i8 %11687, 1
  %11689 = xor i8 %11688, 1
  store i8 %11689, i8* %13, align 1
  %11690 = xor i32 %11678, %11673
  %11691 = xor i32 %11690, %11679
  %11692 = lshr i32 %11691, 4
  %11693 = trunc i32 %11692 to i8
  %11694 = and i8 %11693, 1
  store i8 %11694, i8* %14, align 1
  %11695 = icmp eq i32 %11679, 0
  %11696 = zext i1 %11695 to i8
  store i8 %11696, i8* %15, align 1
  %11697 = lshr i32 %11679, 31
  %11698 = trunc i32 %11697 to i8
  store i8 %11698, i8* %16, align 1
  %11699 = lshr i32 %11673, 31
  %11700 = lshr i32 %11678, 31
  %11701 = xor i32 %11697, %11699
  %11702 = xor i32 %11697, %11700
  %11703 = add nuw nsw i32 %11701, %11702
  %11704 = icmp eq i32 %11703, 2
  %11705 = zext i1 %11704 to i8
  store i8 %11705, i8* %17, align 1
  %11706 = sext i32 %11679 to i64
  store i64 %11706, i64* %RCX.i3977, align 8
  %11707 = shl nsw i64 %11706, 1
  %11708 = add i64 %11642, %11707
  %11709 = add i64 %11536, 75
  store i64 %11709, i64* %3, align 8
  %11710 = inttoptr i64 %11708 to i16*
  %11711 = load i16, i16* %11710, align 2
  %11712 = zext i16 %11711 to i64
  store i64 %11712, i64* %RSI.i3950, align 8
  %11713 = load i64, i64* %RDX.i4094, align 8
  %11714 = zext i16 %11711 to i64
  %11715 = add i64 %11714, %11713
  %11716 = and i64 %11715, 4294967295
  store i64 %11716, i64* %RDX.i4094, align 8
  %11717 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11718 = add i64 %11717, 13112
  store i64 %11718, i64* %RAX.i2610, align 8
  %11719 = icmp ugt i64 %11717, -13113
  %11720 = zext i1 %11719 to i8
  store i8 %11720, i8* %12, align 1
  %11721 = trunc i64 %11718 to i32
  %11722 = and i32 %11721, 255
  %11723 = tail call i32 @llvm.ctpop.i32(i32 %11722)
  %11724 = trunc i32 %11723 to i8
  %11725 = and i8 %11724, 1
  %11726 = xor i8 %11725, 1
  store i8 %11726, i8* %13, align 1
  %11727 = xor i64 %11717, 16
  %11728 = xor i64 %11727, %11718
  %11729 = lshr i64 %11728, 4
  %11730 = trunc i64 %11729 to i8
  %11731 = and i8 %11730, 1
  store i8 %11731, i8* %14, align 1
  %11732 = icmp eq i64 %11718, 0
  %11733 = zext i1 %11732 to i8
  store i8 %11733, i8* %15, align 1
  %11734 = lshr i64 %11718, 63
  %11735 = trunc i64 %11734 to i8
  store i8 %11735, i8* %16, align 1
  %11736 = lshr i64 %11717, 63
  %11737 = xor i64 %11734, %11736
  %11738 = add nuw nsw i64 %11737, %11734
  %11739 = icmp eq i64 %11738, 2
  %11740 = zext i1 %11739 to i8
  store i8 %11740, i8* %17, align 1
  %11741 = load i64, i64* %RBP.i, align 8
  %11742 = add i64 %11741, -24
  %11743 = add i64 %11536, 95
  store i64 %11743, i64* %3, align 8
  %11744 = inttoptr i64 %11742 to i32*
  %11745 = load i32, i32* %11744, align 4
  %11746 = sext i32 %11745 to i64
  %11747 = shl nsw i64 %11746, 6
  store i64 %11747, i64* %RCX.i3977, align 8
  %11748 = add i64 %11747, %11718
  store i64 %11748, i64* %RAX.i2610, align 8
  %11749 = icmp ult i64 %11748, %11718
  %11750 = icmp ult i64 %11748, %11747
  %11751 = or i1 %11749, %11750
  %11752 = zext i1 %11751 to i8
  store i8 %11752, i8* %12, align 1
  %11753 = trunc i64 %11748 to i32
  %11754 = and i32 %11753, 255
  %11755 = tail call i32 @llvm.ctpop.i32(i32 %11754)
  %11756 = trunc i32 %11755 to i8
  %11757 = and i8 %11756, 1
  %11758 = xor i8 %11757, 1
  store i8 %11758, i8* %13, align 1
  %11759 = xor i64 %11718, %11748
  %11760 = lshr i64 %11759, 4
  %11761 = trunc i64 %11760 to i8
  %11762 = and i8 %11761, 1
  store i8 %11762, i8* %14, align 1
  %11763 = icmp eq i64 %11748, 0
  %11764 = zext i1 %11763 to i8
  store i8 %11764, i8* %15, align 1
  %11765 = lshr i64 %11748, 63
  %11766 = trunc i64 %11765 to i8
  store i8 %11766, i8* %16, align 1
  %11767 = lshr i64 %11746, 57
  %11768 = and i64 %11767, 1
  %11769 = xor i64 %11765, %11734
  %11770 = xor i64 %11765, %11768
  %11771 = add nuw nsw i64 %11769, %11770
  %11772 = icmp eq i64 %11771, 2
  %11773 = zext i1 %11772 to i8
  store i8 %11773, i8* %17, align 1
  %11774 = add i64 %11741, -28
  %11775 = add i64 %11536, 106
  store i64 %11775, i64* %3, align 8
  %11776 = inttoptr i64 %11774 to i32*
  %11777 = load i32, i32* %11776, align 4
  %11778 = sext i32 %11777 to i64
  store i64 %11778, i64* %RCX.i3977, align 8
  %11779 = shl nsw i64 %11778, 2
  %11780 = add i64 %11779, %11748
  %11781 = load i32, i32* %EDX.i4064, align 4
  %11782 = add i64 %11536, 109
  store i64 %11782, i64* %3, align 8
  %11783 = inttoptr i64 %11780 to i32*
  store i32 %11781, i32* %11783, align 4
  %11784 = load i64, i64* %3, align 8
  %11785 = add i64 %11784, 684
  br label %block_.L_4ac2b5

block_.L_4ac00e:                                  ; preds = %block_4abf8f
  %11786 = add i64 %11538, 72724
  %11787 = add i64 %11536, 15
  store i64 %11787, i64* %3, align 8
  %11788 = inttoptr i64 %11786 to i32*
  %11789 = load i32, i32* %11788, align 4
  store i8 0, i8* %12, align 1
  %11790 = and i32 %11789, 255
  %11791 = tail call i32 @llvm.ctpop.i32(i32 %11790)
  %11792 = trunc i32 %11791 to i8
  %11793 = and i8 %11792, 1
  %11794 = xor i8 %11793, 1
  store i8 %11794, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %11795 = icmp eq i32 %11789, 0
  %11796 = zext i1 %11795 to i8
  store i8 %11796, i8* %15, align 1
  %11797 = lshr i32 %11789, 31
  %11798 = trunc i32 %11797 to i8
  store i8 %11798, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v217 = select i1 %11795, i64 21, i64 604
  %11799 = add i64 %11536, %.v217
  store i64 %11799, i64* %3, align 8
  br i1 %11795, label %block_4ac023, label %block_.L_4ac26a

block_4ac023:                                     ; preds = %block_.L_4ac00e
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 0, i64* %RCX.i3977, align 8
  store i64 %11538, i64* %RDX.i4094, align 8
  %11800 = add i64 %11538, 72684
  %11801 = add i64 %11799, 19
  store i64 %11801, i64* %3, align 8
  %11802 = inttoptr i64 %11800 to i32*
  %11803 = load i32, i32* %11802, align 4
  %11804 = sext i32 %11803 to i64
  store i64 %11804, i64* %RDX.i4094, align 8
  %11805 = add i64 %11538, 13112
  store i64 %11805, i64* %RSI.i3950, align 8
  %11806 = icmp ugt i64 %11538, -13113
  %11807 = zext i1 %11806 to i8
  store i8 %11807, i8* %12, align 1
  %11808 = trunc i64 %11805 to i32
  %11809 = and i32 %11808, 255
  %11810 = tail call i32 @llvm.ctpop.i32(i32 %11809)
  %11811 = trunc i32 %11810 to i8
  %11812 = and i8 %11811, 1
  %11813 = xor i8 %11812, 1
  store i8 %11813, i8* %13, align 1
  %11814 = xor i64 %11538, 16
  %11815 = xor i64 %11814, %11805
  %11816 = lshr i64 %11815, 4
  %11817 = trunc i64 %11816 to i8
  %11818 = and i8 %11817, 1
  store i8 %11818, i8* %14, align 1
  %11819 = icmp eq i64 %11805, 0
  %11820 = zext i1 %11819 to i8
  store i8 %11820, i8* %15, align 1
  %11821 = lshr i64 %11805, 63
  %11822 = trunc i64 %11821 to i8
  store i8 %11822, i8* %16, align 1
  %11823 = lshr i64 %11538, 63
  %11824 = xor i64 %11821, %11823
  %11825 = add nuw nsw i64 %11824, %11821
  %11826 = icmp eq i64 %11825, 2
  %11827 = zext i1 %11826 to i8
  store i8 %11827, i8* %17, align 1
  %11828 = add i64 %11494, -24
  %11829 = add i64 %11799, 38
  store i64 %11829, i64* %3, align 8
  %11830 = inttoptr i64 %11828 to i32*
  %11831 = load i32, i32* %11830, align 4
  %11832 = sext i32 %11831 to i64
  %11833 = shl nsw i64 %11832, 6
  store i64 %11833, i64* %RDI.i4084, align 8
  %11834 = add i64 %11833, %11805
  store i64 %11834, i64* %RSI.i3950, align 8
  %11835 = icmp ult i64 %11834, %11805
  %11836 = icmp ult i64 %11834, %11833
  %11837 = or i1 %11835, %11836
  %11838 = zext i1 %11837 to i8
  store i8 %11838, i8* %12, align 1
  %11839 = trunc i64 %11834 to i32
  %11840 = and i32 %11839, 255
  %11841 = tail call i32 @llvm.ctpop.i32(i32 %11840)
  %11842 = trunc i32 %11841 to i8
  %11843 = and i8 %11842, 1
  %11844 = xor i8 %11843, 1
  store i8 %11844, i8* %13, align 1
  %11845 = xor i64 %11805, %11834
  %11846 = lshr i64 %11845, 4
  %11847 = trunc i64 %11846 to i8
  %11848 = and i8 %11847, 1
  store i8 %11848, i8* %14, align 1
  %11849 = icmp eq i64 %11834, 0
  %11850 = zext i1 %11849 to i8
  store i8 %11850, i8* %15, align 1
  %11851 = lshr i64 %11834, 63
  %11852 = trunc i64 %11851 to i8
  store i8 %11852, i8* %16, align 1
  %11853 = lshr i64 %11832, 57
  %11854 = and i64 %11853, 1
  %11855 = xor i64 %11851, %11821
  %11856 = xor i64 %11851, %11854
  %11857 = add nuw nsw i64 %11855, %11856
  %11858 = icmp eq i64 %11857, 2
  %11859 = zext i1 %11858 to i8
  store i8 %11859, i8* %17, align 1
  %11860 = load i64, i64* %RBP.i, align 8
  %11861 = add i64 %11860, -28
  %11862 = add i64 %11799, 49
  store i64 %11862, i64* %3, align 8
  %11863 = inttoptr i64 %11861 to i32*
  %11864 = load i32, i32* %11863, align 4
  %11865 = sext i32 %11864 to i64
  store i64 %11865, i64* %RDI.i4084, align 8
  %11866 = shl nsw i64 %11865, 2
  %11867 = add i64 %11866, %11834
  %11868 = add i64 %11799, 53
  store i64 %11868, i64* %3, align 8
  %11869 = inttoptr i64 %11867 to i32*
  %11870 = load i32, i32* %11869, align 4
  %11871 = sext i32 %11870 to i64
  store i64 %11871, i64* %RSI.i3950, align 8
  %11872 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %11873 = add i64 %11872, 12600
  store i64 %11873, i64* %RDI.i4084, align 8
  %11874 = icmp ugt i64 %11872, -12601
  %11875 = zext i1 %11874 to i8
  store i8 %11875, i8* %12, align 1
  %11876 = trunc i64 %11873 to i32
  %11877 = and i32 %11876, 255
  %11878 = tail call i32 @llvm.ctpop.i32(i32 %11877)
  %11879 = trunc i32 %11878 to i8
  %11880 = and i8 %11879, 1
  %11881 = xor i8 %11880, 1
  store i8 %11881, i8* %13, align 1
  %11882 = xor i64 %11872, 16
  %11883 = xor i64 %11882, %11873
  %11884 = lshr i64 %11883, 4
  %11885 = trunc i64 %11884 to i8
  %11886 = and i8 %11885, 1
  store i8 %11886, i8* %14, align 1
  %11887 = icmp eq i64 %11873, 0
  %11888 = zext i1 %11887 to i8
  store i8 %11888, i8* %15, align 1
  %11889 = lshr i64 %11873, 63
  %11890 = trunc i64 %11889 to i8
  store i8 %11890, i8* %16, align 1
  %11891 = lshr i64 %11872, 63
  %11892 = xor i64 %11889, %11891
  %11893 = add nuw nsw i64 %11892, %11889
  %11894 = icmp eq i64 %11893, 2
  %11895 = zext i1 %11894 to i8
  store i8 %11895, i8* %17, align 1
  %11896 = add i64 %11860, -24
  %11897 = add i64 %11799, 71
  store i64 %11897, i64* %3, align 8
  %11898 = inttoptr i64 %11896 to i32*
  %11899 = load i32, i32* %11898, align 4
  %11900 = zext i32 %11899 to i64
  store i64 %11900, i64* %RAX.i2610, align 8
  %11901 = add i64 %11860, -84
  %11902 = add i64 %11799, 74
  store i64 %11902, i64* %3, align 8
  %11903 = inttoptr i64 %11901 to i32*
  %11904 = load i32, i32* %11903, align 4
  %11905 = add i32 %11904, %11899
  %11906 = zext i32 %11905 to i64
  store i64 %11906, i64* %RAX.i2610, align 8
  %11907 = sext i32 %11905 to i64
  %11908 = shl nsw i64 %11907, 5
  store i64 %11908, i64* %R8.i4051, align 8
  %11909 = load i64, i64* %RDI.i4084, align 8
  %11910 = add i64 %11908, %11909
  store i64 %11910, i64* %RDI.i4084, align 8
  %11911 = icmp ult i64 %11910, %11909
  %11912 = icmp ult i64 %11910, %11908
  %11913 = or i1 %11911, %11912
  %11914 = zext i1 %11913 to i8
  store i8 %11914, i8* %12, align 1
  %11915 = trunc i64 %11910 to i32
  %11916 = and i32 %11915, 255
  %11917 = tail call i32 @llvm.ctpop.i32(i32 %11916)
  %11918 = trunc i32 %11917 to i8
  %11919 = and i8 %11918, 1
  %11920 = xor i8 %11919, 1
  store i8 %11920, i8* %13, align 1
  %11921 = xor i64 %11909, %11910
  %11922 = lshr i64 %11921, 4
  %11923 = trunc i64 %11922 to i8
  %11924 = and i8 %11923, 1
  store i8 %11924, i8* %14, align 1
  %11925 = icmp eq i64 %11910, 0
  %11926 = zext i1 %11925 to i8
  store i8 %11926, i8* %15, align 1
  %11927 = lshr i64 %11910, 63
  %11928 = trunc i64 %11927 to i8
  store i8 %11928, i8* %16, align 1
  %11929 = lshr i64 %11909, 63
  %11930 = lshr i64 %11907, 58
  %11931 = and i64 %11930, 1
  %11932 = xor i64 %11927, %11929
  %11933 = xor i64 %11927, %11931
  %11934 = add nuw nsw i64 %11932, %11933
  %11935 = icmp eq i64 %11934, 2
  %11936 = zext i1 %11935 to i8
  store i8 %11936, i8* %17, align 1
  %11937 = load i64, i64* %RBP.i, align 8
  %11938 = add i64 %11937, -28
  %11939 = add i64 %11799, 87
  store i64 %11939, i64* %3, align 8
  %11940 = inttoptr i64 %11938 to i32*
  %11941 = load i32, i32* %11940, align 4
  %11942 = zext i32 %11941 to i64
  store i64 %11942, i64* %RAX.i2610, align 8
  %11943 = add i64 %11937, -88
  %11944 = add i64 %11799, 90
  store i64 %11944, i64* %3, align 8
  %11945 = inttoptr i64 %11943 to i32*
  %11946 = load i32, i32* %11945, align 4
  %11947 = add i32 %11946, %11941
  %11948 = zext i32 %11947 to i64
  store i64 %11948, i64* %RAX.i2610, align 8
  %11949 = icmp ult i32 %11947, %11941
  %11950 = icmp ult i32 %11947, %11946
  %11951 = or i1 %11949, %11950
  %11952 = zext i1 %11951 to i8
  store i8 %11952, i8* %12, align 1
  %11953 = and i32 %11947, 255
  %11954 = tail call i32 @llvm.ctpop.i32(i32 %11953)
  %11955 = trunc i32 %11954 to i8
  %11956 = and i8 %11955, 1
  %11957 = xor i8 %11956, 1
  store i8 %11957, i8* %13, align 1
  %11958 = xor i32 %11946, %11941
  %11959 = xor i32 %11958, %11947
  %11960 = lshr i32 %11959, 4
  %11961 = trunc i32 %11960 to i8
  %11962 = and i8 %11961, 1
  store i8 %11962, i8* %14, align 1
  %11963 = icmp eq i32 %11947, 0
  %11964 = zext i1 %11963 to i8
  store i8 %11964, i8* %15, align 1
  %11965 = lshr i32 %11947, 31
  %11966 = trunc i32 %11965 to i8
  store i8 %11966, i8* %16, align 1
  %11967 = lshr i32 %11941, 31
  %11968 = lshr i32 %11946, 31
  %11969 = xor i32 %11965, %11967
  %11970 = xor i32 %11965, %11968
  %11971 = add nuw nsw i32 %11969, %11970
  %11972 = icmp eq i32 %11971, 2
  %11973 = zext i1 %11972 to i8
  store i8 %11973, i8* %17, align 1
  %11974 = sext i32 %11947 to i64
  store i64 %11974, i64* %R8.i4051, align 8
  %11975 = shl nsw i64 %11974, 1
  %11976 = add i64 %11910, %11975
  %11977 = add i64 %11799, 98
  store i64 %11977, i64* %3, align 8
  %11978 = inttoptr i64 %11976 to i16*
  %11979 = load i16, i16* %11978, align 2
  %11980 = zext i16 %11979 to i64
  store i64 %11980, i64* %RAX.i2610, align 8
  %11981 = zext i16 %11979 to i64
  %11982 = shl nuw nsw i64 %11981, 6
  store i64 %11982, i64* %RDI.i4084, align 8
  %11983 = load i64, i64* %RSI.i3950, align 8
  %11984 = add i64 %11982, %11983
  %11985 = add i64 %11984, 32
  %11986 = ashr i64 %11985, 6
  store i64 %11986, i64* %RSI.i3950, align 8
  %11987 = lshr i64 %11986, 63
  %11988 = load i64, i64* %RCX.i3977, align 8
  %11989 = sub i64 %11988, %11986
  %11990 = icmp ult i64 %11988, %11986
  %11991 = zext i1 %11990 to i8
  store i8 %11991, i8* %12, align 1
  %11992 = trunc i64 %11989 to i32
  %11993 = and i32 %11992, 255
  %11994 = tail call i32 @llvm.ctpop.i32(i32 %11993)
  %11995 = trunc i32 %11994 to i8
  %11996 = and i8 %11995, 1
  %11997 = xor i8 %11996, 1
  store i8 %11997, i8* %13, align 1
  %11998 = xor i64 %11986, %11988
  %11999 = xor i64 %11998, %11989
  %12000 = lshr i64 %11999, 4
  %12001 = trunc i64 %12000 to i8
  %12002 = and i8 %12001, 1
  store i8 %12002, i8* %14, align 1
  %12003 = icmp eq i64 %11989, 0
  %12004 = zext i1 %12003 to i8
  store i8 %12004, i8* %15, align 1
  %12005 = lshr i64 %11989, 63
  %12006 = trunc i64 %12005 to i8
  store i8 %12006, i8* %16, align 1
  %12007 = lshr i64 %11988, 63
  %12008 = xor i64 %11987, %12007
  %12009 = xor i64 %12005, %12007
  %12010 = add nuw nsw i64 %12009, %12008
  %12011 = icmp eq i64 %12010, 2
  %12012 = zext i1 %12011 to i8
  store i8 %12012, i8* %17, align 1
  %12013 = load i64, i64* %RBP.i, align 8
  %12014 = add i64 %12013, -728
  %12015 = load i64, i64* %RDX.i4094, align 8
  %12016 = add i64 %11799, 125
  store i64 %12016, i64* %3, align 8
  %12017 = inttoptr i64 %12014 to i64*
  store i64 %12015, i64* %12017, align 8
  %12018 = load i64, i64* %3, align 8
  %12019 = load i8, i8* %15, align 1
  %12020 = icmp ne i8 %12019, 0
  %12021 = load i8, i8* %16, align 1
  %12022 = icmp ne i8 %12021, 0
  %12023 = load i8, i8* %17, align 1
  %12024 = icmp ne i8 %12023, 0
  %12025 = xor i1 %12022, %12024
  %12026 = or i1 %12020, %12025
  %.v252 = select i1 %12026, i64 22, i64 6
  %12027 = add i64 %12018, %.v252
  store i64 %12027, i64* %3, align 8
  br i1 %12026, label %block_.L_4ac0b6, label %block_4ac0a6

block_4ac0a6:                                     ; preds = %block_4ac023
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 0, i64* %RCX.i3977, align 8
  %12028 = load i64, i64* %RBP.i, align 8
  %12029 = add i64 %12028, -736
  %12030 = add i64 %12027, 11
  store i64 %12030, i64* %3, align 8
  %12031 = inttoptr i64 %12029 to i64*
  store i64 0, i64* %12031, align 8
  %12032 = load i64, i64* %3, align 8
  %12033 = add i64 %12032, 106
  store i64 %12033, i64* %3, align 8
  br label %block_.L_4ac11b

block_.L_4ac0b6:                                  ; preds = %block_4ac023
  %12034 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %12035 = add i64 %12034, 13112
  store i64 %12035, i64* %RAX.i2610, align 8
  %12036 = icmp ugt i64 %12034, -13113
  %12037 = zext i1 %12036 to i8
  store i8 %12037, i8* %12, align 1
  %12038 = trunc i64 %12035 to i32
  %12039 = and i32 %12038, 255
  %12040 = tail call i32 @llvm.ctpop.i32(i32 %12039)
  %12041 = trunc i32 %12040 to i8
  %12042 = and i8 %12041, 1
  %12043 = xor i8 %12042, 1
  store i8 %12043, i8* %13, align 1
  %12044 = xor i64 %12034, 16
  %12045 = xor i64 %12044, %12035
  %12046 = lshr i64 %12045, 4
  %12047 = trunc i64 %12046 to i8
  %12048 = and i8 %12047, 1
  store i8 %12048, i8* %14, align 1
  %12049 = icmp eq i64 %12035, 0
  %12050 = zext i1 %12049 to i8
  store i8 %12050, i8* %15, align 1
  %12051 = lshr i64 %12035, 63
  %12052 = trunc i64 %12051 to i8
  store i8 %12052, i8* %16, align 1
  %12053 = lshr i64 %12034, 63
  %12054 = xor i64 %12051, %12053
  %12055 = add nuw nsw i64 %12054, %12051
  %12056 = icmp eq i64 %12055, 2
  %12057 = zext i1 %12056 to i8
  store i8 %12057, i8* %17, align 1
  %12058 = load i64, i64* %RBP.i, align 8
  %12059 = add i64 %12058, -24
  %12060 = add i64 %12027, 18
  store i64 %12060, i64* %3, align 8
  %12061 = inttoptr i64 %12059 to i32*
  %12062 = load i32, i32* %12061, align 4
  %12063 = sext i32 %12062 to i64
  %12064 = shl nsw i64 %12063, 6
  store i64 %12064, i64* %RCX.i3977, align 8
  %12065 = add i64 %12064, %12035
  store i64 %12065, i64* %RAX.i2610, align 8
  %12066 = icmp ult i64 %12065, %12035
  %12067 = icmp ult i64 %12065, %12064
  %12068 = or i1 %12066, %12067
  %12069 = zext i1 %12068 to i8
  store i8 %12069, i8* %12, align 1
  %12070 = trunc i64 %12065 to i32
  %12071 = and i32 %12070, 255
  %12072 = tail call i32 @llvm.ctpop.i32(i32 %12071)
  %12073 = trunc i32 %12072 to i8
  %12074 = and i8 %12073, 1
  %12075 = xor i8 %12074, 1
  store i8 %12075, i8* %13, align 1
  %12076 = xor i64 %12035, %12065
  %12077 = lshr i64 %12076, 4
  %12078 = trunc i64 %12077 to i8
  %12079 = and i8 %12078, 1
  store i8 %12079, i8* %14, align 1
  %12080 = icmp eq i64 %12065, 0
  %12081 = zext i1 %12080 to i8
  store i8 %12081, i8* %15, align 1
  %12082 = lshr i64 %12065, 63
  %12083 = trunc i64 %12082 to i8
  store i8 %12083, i8* %16, align 1
  %12084 = lshr i64 %12063, 57
  %12085 = and i64 %12084, 1
  %12086 = xor i64 %12082, %12051
  %12087 = xor i64 %12082, %12085
  %12088 = add nuw nsw i64 %12086, %12087
  %12089 = icmp eq i64 %12088, 2
  %12090 = zext i1 %12089 to i8
  store i8 %12090, i8* %17, align 1
  %12091 = add i64 %12058, -28
  %12092 = add i64 %12027, 29
  store i64 %12092, i64* %3, align 8
  %12093 = inttoptr i64 %12091 to i32*
  %12094 = load i32, i32* %12093, align 4
  %12095 = sext i32 %12094 to i64
  store i64 %12095, i64* %RCX.i3977, align 8
  %12096 = shl nsw i64 %12095, 2
  %12097 = add i64 %12096, %12065
  %12098 = add i64 %12027, 33
  store i64 %12098, i64* %3, align 8
  %12099 = inttoptr i64 %12097 to i32*
  %12100 = load i32, i32* %12099, align 4
  %12101 = sext i32 %12100 to i64
  store i64 %12101, i64* %RAX.i2610, align 8
  %12102 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %12103 = add i64 %12102, 12600
  store i64 %12103, i64* %RCX.i3977, align 8
  %12104 = icmp ugt i64 %12102, -12601
  %12105 = zext i1 %12104 to i8
  store i8 %12105, i8* %12, align 1
  %12106 = trunc i64 %12103 to i32
  %12107 = and i32 %12106, 255
  %12108 = tail call i32 @llvm.ctpop.i32(i32 %12107)
  %12109 = trunc i32 %12108 to i8
  %12110 = and i8 %12109, 1
  %12111 = xor i8 %12110, 1
  store i8 %12111, i8* %13, align 1
  %12112 = xor i64 %12102, 16
  %12113 = xor i64 %12112, %12103
  %12114 = lshr i64 %12113, 4
  %12115 = trunc i64 %12114 to i8
  %12116 = and i8 %12115, 1
  store i8 %12116, i8* %14, align 1
  %12117 = icmp eq i64 %12103, 0
  %12118 = zext i1 %12117 to i8
  store i8 %12118, i8* %15, align 1
  %12119 = lshr i64 %12103, 63
  %12120 = trunc i64 %12119 to i8
  store i8 %12120, i8* %16, align 1
  %12121 = lshr i64 %12102, 63
  %12122 = xor i64 %12119, %12121
  %12123 = add nuw nsw i64 %12122, %12119
  %12124 = icmp eq i64 %12123, 2
  %12125 = zext i1 %12124 to i8
  store i8 %12125, i8* %17, align 1
  %12126 = load i64, i64* %RBP.i, align 8
  %12127 = add i64 %12126, -24
  %12128 = add i64 %12027, 51
  store i64 %12128, i64* %3, align 8
  %12129 = inttoptr i64 %12127 to i32*
  %12130 = load i32, i32* %12129, align 4
  %12131 = zext i32 %12130 to i64
  store i64 %12131, i64* %RDX.i4094, align 8
  %12132 = add i64 %12126, -84
  %12133 = add i64 %12027, 54
  store i64 %12133, i64* %3, align 8
  %12134 = inttoptr i64 %12132 to i32*
  %12135 = load i32, i32* %12134, align 4
  %12136 = add i32 %12135, %12130
  %12137 = zext i32 %12136 to i64
  store i64 %12137, i64* %RDX.i4094, align 8
  %12138 = sext i32 %12136 to i64
  %12139 = shl nsw i64 %12138, 5
  store i64 %12139, i64* %RSI.i3950, align 8
  %12140 = load i64, i64* %RCX.i3977, align 8
  %12141 = add i64 %12139, %12140
  store i64 %12141, i64* %RCX.i3977, align 8
  %12142 = icmp ult i64 %12141, %12140
  %12143 = icmp ult i64 %12141, %12139
  %12144 = or i1 %12142, %12143
  %12145 = zext i1 %12144 to i8
  store i8 %12145, i8* %12, align 1
  %12146 = trunc i64 %12141 to i32
  %12147 = and i32 %12146, 255
  %12148 = tail call i32 @llvm.ctpop.i32(i32 %12147)
  %12149 = trunc i32 %12148 to i8
  %12150 = and i8 %12149, 1
  %12151 = xor i8 %12150, 1
  store i8 %12151, i8* %13, align 1
  %12152 = xor i64 %12140, %12141
  %12153 = lshr i64 %12152, 4
  %12154 = trunc i64 %12153 to i8
  %12155 = and i8 %12154, 1
  store i8 %12155, i8* %14, align 1
  %12156 = icmp eq i64 %12141, 0
  %12157 = zext i1 %12156 to i8
  store i8 %12157, i8* %15, align 1
  %12158 = lshr i64 %12141, 63
  %12159 = trunc i64 %12158 to i8
  store i8 %12159, i8* %16, align 1
  %12160 = lshr i64 %12140, 63
  %12161 = lshr i64 %12138, 58
  %12162 = and i64 %12161, 1
  %12163 = xor i64 %12158, %12160
  %12164 = xor i64 %12158, %12162
  %12165 = add nuw nsw i64 %12163, %12164
  %12166 = icmp eq i64 %12165, 2
  %12167 = zext i1 %12166 to i8
  store i8 %12167, i8* %17, align 1
  %12168 = load i64, i64* %RBP.i, align 8
  %12169 = add i64 %12168, -28
  %12170 = add i64 %12027, 67
  store i64 %12170, i64* %3, align 8
  %12171 = inttoptr i64 %12169 to i32*
  %12172 = load i32, i32* %12171, align 4
  %12173 = zext i32 %12172 to i64
  store i64 %12173, i64* %RDX.i4094, align 8
  %12174 = add i64 %12168, -88
  %12175 = add i64 %12027, 70
  store i64 %12175, i64* %3, align 8
  %12176 = inttoptr i64 %12174 to i32*
  %12177 = load i32, i32* %12176, align 4
  %12178 = add i32 %12177, %12172
  %12179 = zext i32 %12178 to i64
  store i64 %12179, i64* %RDX.i4094, align 8
  %12180 = icmp ult i32 %12178, %12172
  %12181 = icmp ult i32 %12178, %12177
  %12182 = or i1 %12180, %12181
  %12183 = zext i1 %12182 to i8
  store i8 %12183, i8* %12, align 1
  %12184 = and i32 %12178, 255
  %12185 = tail call i32 @llvm.ctpop.i32(i32 %12184)
  %12186 = trunc i32 %12185 to i8
  %12187 = and i8 %12186, 1
  %12188 = xor i8 %12187, 1
  store i8 %12188, i8* %13, align 1
  %12189 = xor i32 %12177, %12172
  %12190 = xor i32 %12189, %12178
  %12191 = lshr i32 %12190, 4
  %12192 = trunc i32 %12191 to i8
  %12193 = and i8 %12192, 1
  store i8 %12193, i8* %14, align 1
  %12194 = icmp eq i32 %12178, 0
  %12195 = zext i1 %12194 to i8
  store i8 %12195, i8* %15, align 1
  %12196 = lshr i32 %12178, 31
  %12197 = trunc i32 %12196 to i8
  store i8 %12197, i8* %16, align 1
  %12198 = lshr i32 %12172, 31
  %12199 = lshr i32 %12177, 31
  %12200 = xor i32 %12196, %12198
  %12201 = xor i32 %12196, %12199
  %12202 = add nuw nsw i32 %12200, %12201
  %12203 = icmp eq i32 %12202, 2
  %12204 = zext i1 %12203 to i8
  store i8 %12204, i8* %17, align 1
  %12205 = sext i32 %12178 to i64
  store i64 %12205, i64* %RSI.i3950, align 8
  %12206 = shl nsw i64 %12205, 1
  %12207 = add i64 %12141, %12206
  %12208 = add i64 %12027, 77
  store i64 %12208, i64* %3, align 8
  %12209 = inttoptr i64 %12207 to i16*
  %12210 = load i16, i16* %12209, align 2
  %12211 = zext i16 %12210 to i64
  store i64 %12211, i64* %RDX.i4094, align 8
  %12212 = zext i16 %12210 to i64
  %12213 = shl nuw nsw i64 %12212, 6
  store i64 %12213, i64* %RCX.i3977, align 8
  %12214 = load i64, i64* %RAX.i2610, align 8
  %12215 = add i64 %12213, %12214
  %12216 = add i64 %12215, 32
  %12217 = lshr i64 %12216, 5
  %12218 = trunc i64 %12217 to i8
  %12219 = and i8 %12218, 1
  %12220 = ashr i64 %12216, 6
  store i64 %12220, i64* %RAX.i2610, align 8
  store i8 %12219, i8* %12, align 1
  %12221 = trunc i64 %12220 to i32
  %12222 = and i32 %12221, 255
  %12223 = tail call i32 @llvm.ctpop.i32(i32 %12222)
  %12224 = trunc i32 %12223 to i8
  %12225 = and i8 %12224, 1
  %12226 = xor i8 %12225, 1
  store i8 %12226, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %12227 = icmp eq i64 %12220, 0
  %12228 = zext i1 %12227 to i8
  store i8 %12228, i8* %15, align 1
  %12229 = lshr i64 %12220, 63
  %12230 = trunc i64 %12229 to i8
  store i8 %12230, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %12231 = load i64, i64* %RBP.i, align 8
  %12232 = add i64 %12231, -736
  %12233 = add i64 %12027, 101
  store i64 %12233, i64* %3, align 8
  %12234 = inttoptr i64 %12232 to i64*
  store i64 %12220, i64* %12234, align 8
  %.pre187 = load i64, i64* %3, align 8
  br label %block_.L_4ac11b

block_.L_4ac11b:                                  ; preds = %block_.L_4ac0b6, %block_4ac0a6
  %12235 = phi i64 [ %.pre187, %block_.L_4ac0b6 ], [ %12033, %block_4ac0a6 ]
  %12236 = load i64, i64* %RBP.i, align 8
  %12237 = add i64 %12236, -736
  %12238 = add i64 %12235, 7
  store i64 %12238, i64* %3, align 8
  %12239 = inttoptr i64 %12237 to i64*
  %12240 = load i64, i64* %12239, align 8
  store i64 %12240, i64* %RAX.i2610, align 8
  %12241 = add i64 %12236, -728
  %12242 = add i64 %12235, 14
  store i64 %12242, i64* %3, align 8
  %12243 = inttoptr i64 %12241 to i64*
  %12244 = load i64, i64* %12243, align 8
  store i64 %12244, i64* %RCX.i3977, align 8
  %12245 = sub i64 %12244, %12240
  %12246 = icmp ult i64 %12244, %12240
  %12247 = zext i1 %12246 to i8
  store i8 %12247, i8* %12, align 1
  %12248 = trunc i64 %12245 to i32
  %12249 = and i32 %12248, 255
  %12250 = tail call i32 @llvm.ctpop.i32(i32 %12249)
  %12251 = trunc i32 %12250 to i8
  %12252 = and i8 %12251, 1
  %12253 = xor i8 %12252, 1
  store i8 %12253, i8* %13, align 1
  %12254 = xor i64 %12240, %12244
  %12255 = xor i64 %12254, %12245
  %12256 = lshr i64 %12255, 4
  %12257 = trunc i64 %12256 to i8
  %12258 = and i8 %12257, 1
  store i8 %12258, i8* %14, align 1
  %12259 = icmp eq i64 %12245, 0
  %12260 = zext i1 %12259 to i8
  store i8 %12260, i8* %15, align 1
  %12261 = lshr i64 %12245, 63
  %12262 = trunc i64 %12261 to i8
  store i8 %12262, i8* %16, align 1
  %12263 = lshr i64 %12244, 63
  %12264 = lshr i64 %12240, 63
  %12265 = xor i64 %12264, %12263
  %12266 = xor i64 %12261, %12263
  %12267 = add nuw nsw i64 %12266, %12265
  %12268 = icmp eq i64 %12267, 2
  %12269 = zext i1 %12268 to i8
  store i8 %12269, i8* %17, align 1
  %12270 = icmp ne i8 %12262, 0
  %12271 = xor i1 %12270, %12268
  %.v218 = select i1 %12271, i64 23, i64 50
  %12272 = add i64 %12235, %.v218
  store i64 %12272, i64* %3, align 8
  br i1 %12271, label %block_4ac132, label %block_.L_4ac14d

block_4ac132:                                     ; preds = %block_.L_4ac11b
  %12273 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %12273, i64* %RAX.i2610, align 8
  %12274 = add i64 %12273, 72684
  %12275 = add i64 %12272, 15
  store i64 %12275, i64* %3, align 8
  %12276 = inttoptr i64 %12274 to i32*
  %12277 = load i32, i32* %12276, align 4
  %12278 = sext i32 %12277 to i64
  store i64 %12278, i64* %RAX.i2610, align 8
  %12279 = add i64 %12236, -744
  %12280 = add i64 %12272, 22
  store i64 %12280, i64* %3, align 8
  %12281 = inttoptr i64 %12279 to i64*
  store i64 %12278, i64* %12281, align 8
  %12282 = load i64, i64* %3, align 8
  %12283 = add i64 %12282, 244
  store i64 %12283, i64* %3, align 8
  br label %block_.L_4ac23c

block_.L_4ac14d:                                  ; preds = %block_.L_4ac11b
  store i64 0, i64* %RAX.i2610, align 8
  store i64 0, i64* %RCX.i3977, align 8
  %12284 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %12285 = add i64 %12284, 13112
  store i64 %12285, i64* %RDX.i4094, align 8
  %12286 = icmp ugt i64 %12284, -13113
  %12287 = zext i1 %12286 to i8
  store i8 %12287, i8* %12, align 1
  %12288 = trunc i64 %12285 to i32
  %12289 = and i32 %12288, 255
  %12290 = tail call i32 @llvm.ctpop.i32(i32 %12289)
  %12291 = trunc i32 %12290 to i8
  %12292 = and i8 %12291, 1
  %12293 = xor i8 %12292, 1
  store i8 %12293, i8* %13, align 1
  %12294 = xor i64 %12284, 16
  %12295 = xor i64 %12294, %12285
  %12296 = lshr i64 %12295, 4
  %12297 = trunc i64 %12296 to i8
  %12298 = and i8 %12297, 1
  store i8 %12298, i8* %14, align 1
  %12299 = icmp eq i64 %12285, 0
  %12300 = zext i1 %12299 to i8
  store i8 %12300, i8* %15, align 1
  %12301 = lshr i64 %12285, 63
  %12302 = trunc i64 %12301 to i8
  store i8 %12302, i8* %16, align 1
  %12303 = lshr i64 %12284, 63
  %12304 = xor i64 %12301, %12303
  %12305 = add nuw nsw i64 %12304, %12301
  %12306 = icmp eq i64 %12305, 2
  %12307 = zext i1 %12306 to i8
  store i8 %12307, i8* %17, align 1
  %12308 = add i64 %12236, -24
  %12309 = add i64 %12272, 23
  store i64 %12309, i64* %3, align 8
  %12310 = inttoptr i64 %12308 to i32*
  %12311 = load i32, i32* %12310, align 4
  %12312 = sext i32 %12311 to i64
  %12313 = shl nsw i64 %12312, 6
  store i64 %12313, i64* %RSI.i3950, align 8
  %12314 = add i64 %12313, %12285
  store i64 %12314, i64* %RDX.i4094, align 8
  %12315 = icmp ult i64 %12314, %12285
  %12316 = icmp ult i64 %12314, %12313
  %12317 = or i1 %12315, %12316
  %12318 = zext i1 %12317 to i8
  store i8 %12318, i8* %12, align 1
  %12319 = trunc i64 %12314 to i32
  %12320 = and i32 %12319, 255
  %12321 = tail call i32 @llvm.ctpop.i32(i32 %12320)
  %12322 = trunc i32 %12321 to i8
  %12323 = and i8 %12322, 1
  %12324 = xor i8 %12323, 1
  store i8 %12324, i8* %13, align 1
  %12325 = xor i64 %12285, %12314
  %12326 = lshr i64 %12325, 4
  %12327 = trunc i64 %12326 to i8
  %12328 = and i8 %12327, 1
  store i8 %12328, i8* %14, align 1
  %12329 = icmp eq i64 %12314, 0
  %12330 = zext i1 %12329 to i8
  store i8 %12330, i8* %15, align 1
  %12331 = lshr i64 %12314, 63
  %12332 = trunc i64 %12331 to i8
  store i8 %12332, i8* %16, align 1
  %12333 = lshr i64 %12312, 57
  %12334 = and i64 %12333, 1
  %12335 = xor i64 %12331, %12301
  %12336 = xor i64 %12331, %12334
  %12337 = add nuw nsw i64 %12335, %12336
  %12338 = icmp eq i64 %12337, 2
  %12339 = zext i1 %12338 to i8
  store i8 %12339, i8* %17, align 1
  %12340 = load i64, i64* %RBP.i, align 8
  %12341 = add i64 %12340, -28
  %12342 = add i64 %12272, 34
  store i64 %12342, i64* %3, align 8
  %12343 = inttoptr i64 %12341 to i32*
  %12344 = load i32, i32* %12343, align 4
  %12345 = sext i32 %12344 to i64
  store i64 %12345, i64* %RSI.i3950, align 8
  %12346 = shl nsw i64 %12345, 2
  %12347 = add i64 %12346, %12314
  %12348 = add i64 %12272, 38
  store i64 %12348, i64* %3, align 8
  %12349 = inttoptr i64 %12347 to i32*
  %12350 = load i32, i32* %12349, align 4
  %12351 = sext i32 %12350 to i64
  store i64 %12351, i64* %RDX.i4094, align 8
  %12352 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %12353 = add i64 %12352, 12600
  store i64 %12353, i64* %RSI.i3950, align 8
  %12354 = icmp ugt i64 %12352, -12601
  %12355 = zext i1 %12354 to i8
  store i8 %12355, i8* %12, align 1
  %12356 = trunc i64 %12353 to i32
  %12357 = and i32 %12356, 255
  %12358 = tail call i32 @llvm.ctpop.i32(i32 %12357)
  %12359 = trunc i32 %12358 to i8
  %12360 = and i8 %12359, 1
  %12361 = xor i8 %12360, 1
  store i8 %12361, i8* %13, align 1
  %12362 = xor i64 %12352, 16
  %12363 = xor i64 %12362, %12353
  %12364 = lshr i64 %12363, 4
  %12365 = trunc i64 %12364 to i8
  %12366 = and i8 %12365, 1
  store i8 %12366, i8* %14, align 1
  %12367 = icmp eq i64 %12353, 0
  %12368 = zext i1 %12367 to i8
  store i8 %12368, i8* %15, align 1
  %12369 = lshr i64 %12353, 63
  %12370 = trunc i64 %12369 to i8
  store i8 %12370, i8* %16, align 1
  %12371 = lshr i64 %12352, 63
  %12372 = xor i64 %12369, %12371
  %12373 = add nuw nsw i64 %12372, %12369
  %12374 = icmp eq i64 %12373, 2
  %12375 = zext i1 %12374 to i8
  store i8 %12375, i8* %17, align 1
  %12376 = add i64 %12340, -24
  %12377 = add i64 %12272, 56
  store i64 %12377, i64* %3, align 8
  %12378 = inttoptr i64 %12376 to i32*
  %12379 = load i32, i32* %12378, align 4
  %12380 = zext i32 %12379 to i64
  store i64 %12380, i64* %RAX.i2610, align 8
  %12381 = add i64 %12340, -84
  %12382 = add i64 %12272, 59
  store i64 %12382, i64* %3, align 8
  %12383 = inttoptr i64 %12381 to i32*
  %12384 = load i32, i32* %12383, align 4
  %12385 = add i32 %12384, %12379
  %12386 = zext i32 %12385 to i64
  store i64 %12386, i64* %RAX.i2610, align 8
  %12387 = sext i32 %12385 to i64
  %12388 = shl nsw i64 %12387, 5
  store i64 %12388, i64* %RDI.i4084, align 8
  %12389 = load i64, i64* %RSI.i3950, align 8
  %12390 = add i64 %12388, %12389
  store i64 %12390, i64* %RSI.i3950, align 8
  %12391 = icmp ult i64 %12390, %12389
  %12392 = icmp ult i64 %12390, %12388
  %12393 = or i1 %12391, %12392
  %12394 = zext i1 %12393 to i8
  store i8 %12394, i8* %12, align 1
  %12395 = trunc i64 %12390 to i32
  %12396 = and i32 %12395, 255
  %12397 = tail call i32 @llvm.ctpop.i32(i32 %12396)
  %12398 = trunc i32 %12397 to i8
  %12399 = and i8 %12398, 1
  %12400 = xor i8 %12399, 1
  store i8 %12400, i8* %13, align 1
  %12401 = xor i64 %12389, %12390
  %12402 = lshr i64 %12401, 4
  %12403 = trunc i64 %12402 to i8
  %12404 = and i8 %12403, 1
  store i8 %12404, i8* %14, align 1
  %12405 = icmp eq i64 %12390, 0
  %12406 = zext i1 %12405 to i8
  store i8 %12406, i8* %15, align 1
  %12407 = lshr i64 %12390, 63
  %12408 = trunc i64 %12407 to i8
  store i8 %12408, i8* %16, align 1
  %12409 = lshr i64 %12389, 63
  %12410 = lshr i64 %12387, 58
  %12411 = and i64 %12410, 1
  %12412 = xor i64 %12407, %12409
  %12413 = xor i64 %12407, %12411
  %12414 = add nuw nsw i64 %12412, %12413
  %12415 = icmp eq i64 %12414, 2
  %12416 = zext i1 %12415 to i8
  store i8 %12416, i8* %17, align 1
  %12417 = load i64, i64* %RBP.i, align 8
  %12418 = add i64 %12417, -28
  %12419 = add i64 %12272, 72
  store i64 %12419, i64* %3, align 8
  %12420 = inttoptr i64 %12418 to i32*
  %12421 = load i32, i32* %12420, align 4
  %12422 = zext i32 %12421 to i64
  store i64 %12422, i64* %RAX.i2610, align 8
  %12423 = add i64 %12417, -88
  %12424 = add i64 %12272, 75
  store i64 %12424, i64* %3, align 8
  %12425 = inttoptr i64 %12423 to i32*
  %12426 = load i32, i32* %12425, align 4
  %12427 = add i32 %12426, %12421
  %12428 = zext i32 %12427 to i64
  store i64 %12428, i64* %RAX.i2610, align 8
  %12429 = icmp ult i32 %12427, %12421
  %12430 = icmp ult i32 %12427, %12426
  %12431 = or i1 %12429, %12430
  %12432 = zext i1 %12431 to i8
  store i8 %12432, i8* %12, align 1
  %12433 = and i32 %12427, 255
  %12434 = tail call i32 @llvm.ctpop.i32(i32 %12433)
  %12435 = trunc i32 %12434 to i8
  %12436 = and i8 %12435, 1
  %12437 = xor i8 %12436, 1
  store i8 %12437, i8* %13, align 1
  %12438 = xor i32 %12426, %12421
  %12439 = xor i32 %12438, %12427
  %12440 = lshr i32 %12439, 4
  %12441 = trunc i32 %12440 to i8
  %12442 = and i8 %12441, 1
  store i8 %12442, i8* %14, align 1
  %12443 = icmp eq i32 %12427, 0
  %12444 = zext i1 %12443 to i8
  store i8 %12444, i8* %15, align 1
  %12445 = lshr i32 %12427, 31
  %12446 = trunc i32 %12445 to i8
  store i8 %12446, i8* %16, align 1
  %12447 = lshr i32 %12421, 31
  %12448 = lshr i32 %12426, 31
  %12449 = xor i32 %12445, %12447
  %12450 = xor i32 %12445, %12448
  %12451 = add nuw nsw i32 %12449, %12450
  %12452 = icmp eq i32 %12451, 2
  %12453 = zext i1 %12452 to i8
  store i8 %12453, i8* %17, align 1
  %12454 = sext i32 %12427 to i64
  store i64 %12454, i64* %RDI.i4084, align 8
  %12455 = shl nsw i64 %12454, 1
  %12456 = add i64 %12390, %12455
  %12457 = add i64 %12272, 82
  store i64 %12457, i64* %3, align 8
  %12458 = inttoptr i64 %12456 to i16*
  %12459 = load i16, i16* %12458, align 2
  %12460 = zext i16 %12459 to i64
  store i64 %12460, i64* %RAX.i2610, align 8
  %12461 = zext i16 %12459 to i64
  %12462 = shl nuw nsw i64 %12461, 6
  store i64 %12462, i64* %RSI.i3950, align 8
  %12463 = load i64, i64* %RDX.i4094, align 8
  %12464 = add i64 %12462, %12463
  %12465 = add i64 %12464, 32
  %12466 = ashr i64 %12465, 6
  store i64 %12466, i64* %RDX.i4094, align 8
  %12467 = lshr i64 %12466, 63
  %12468 = load i64, i64* %RCX.i3977, align 8
  %12469 = sub i64 %12468, %12466
  %12470 = icmp ult i64 %12468, %12466
  %12471 = zext i1 %12470 to i8
  store i8 %12471, i8* %12, align 1
  %12472 = trunc i64 %12469 to i32
  %12473 = and i32 %12472, 255
  %12474 = tail call i32 @llvm.ctpop.i32(i32 %12473)
  %12475 = trunc i32 %12474 to i8
  %12476 = and i8 %12475, 1
  %12477 = xor i8 %12476, 1
  store i8 %12477, i8* %13, align 1
  %12478 = xor i64 %12466, %12468
  %12479 = xor i64 %12478, %12469
  %12480 = lshr i64 %12479, 4
  %12481 = trunc i64 %12480 to i8
  %12482 = and i8 %12481, 1
  store i8 %12482, i8* %14, align 1
  %12483 = icmp eq i64 %12469, 0
  %12484 = zext i1 %12483 to i8
  store i8 %12484, i8* %15, align 1
  %12485 = lshr i64 %12469, 63
  %12486 = trunc i64 %12485 to i8
  store i8 %12486, i8* %16, align 1
  %12487 = lshr i64 %12468, 63
  %12488 = xor i64 %12467, %12487
  %12489 = xor i64 %12485, %12487
  %12490 = add nuw nsw i64 %12489, %12488
  %12491 = icmp eq i64 %12490, 2
  %12492 = zext i1 %12491 to i8
  store i8 %12492, i8* %17, align 1
  %12493 = icmp ne i8 %12486, 0
  %12494 = xor i1 %12493, %12491
  %12495 = or i1 %12483, %12494
  %.v219 = select i1 %12495, i64 124, i64 108
  %12496 = add i64 %12272, %.v219
  store i64 %12496, i64* %3, align 8
  br i1 %12495, label %block_.L_4ac1c9, label %block_4ac1b9

block_4ac1b9:                                     ; preds = %block_.L_4ac14d
  store i64 0, i64* %RAX.i2610, align 8
  store i8 0, i8* %12, align 1
  store i8 1, i8* %13, align 1
  store i8 1, i8* %15, align 1
  store i8 0, i8* %16, align 1
  store i8 0, i8* %17, align 1
  store i8 0, i8* %14, align 1
  store i64 0, i64* %RCX.i3977, align 8
  %12497 = load i64, i64* %RBP.i, align 8
  %12498 = add i64 %12497, -752
  %12499 = add i64 %12496, 11
  store i64 %12499, i64* %3, align 8
  %12500 = inttoptr i64 %12498 to i64*
  store i64 0, i64* %12500, align 8
  %12501 = load i64, i64* %3, align 8
  %12502 = add i64 %12501, 106
  store i64 %12502, i64* %3, align 8
  br label %block_.L_4ac22e

block_.L_4ac1c9:                                  ; preds = %block_.L_4ac14d
  %12503 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %12504 = add i64 %12503, 13112
  store i64 %12504, i64* %RAX.i2610, align 8
  %12505 = icmp ugt i64 %12503, -13113
  %12506 = zext i1 %12505 to i8
  store i8 %12506, i8* %12, align 1
  %12507 = trunc i64 %12504 to i32
  %12508 = and i32 %12507, 255
  %12509 = tail call i32 @llvm.ctpop.i32(i32 %12508)
  %12510 = trunc i32 %12509 to i8
  %12511 = and i8 %12510, 1
  %12512 = xor i8 %12511, 1
  store i8 %12512, i8* %13, align 1
  %12513 = xor i64 %12503, 16
  %12514 = xor i64 %12513, %12504
  %12515 = lshr i64 %12514, 4
  %12516 = trunc i64 %12515 to i8
  %12517 = and i8 %12516, 1
  store i8 %12517, i8* %14, align 1
  %12518 = icmp eq i64 %12504, 0
  %12519 = zext i1 %12518 to i8
  store i8 %12519, i8* %15, align 1
  %12520 = lshr i64 %12504, 63
  %12521 = trunc i64 %12520 to i8
  store i8 %12521, i8* %16, align 1
  %12522 = lshr i64 %12503, 63
  %12523 = xor i64 %12520, %12522
  %12524 = add nuw nsw i64 %12523, %12520
  %12525 = icmp eq i64 %12524, 2
  %12526 = zext i1 %12525 to i8
  store i8 %12526, i8* %17, align 1
  %12527 = load i64, i64* %RBP.i, align 8
  %12528 = add i64 %12527, -24
  %12529 = add i64 %12496, 18
  store i64 %12529, i64* %3, align 8
  %12530 = inttoptr i64 %12528 to i32*
  %12531 = load i32, i32* %12530, align 4
  %12532 = sext i32 %12531 to i64
  %12533 = shl nsw i64 %12532, 6
  store i64 %12533, i64* %RCX.i3977, align 8
  %12534 = add i64 %12533, %12504
  store i64 %12534, i64* %RAX.i2610, align 8
  %12535 = icmp ult i64 %12534, %12504
  %12536 = icmp ult i64 %12534, %12533
  %12537 = or i1 %12535, %12536
  %12538 = zext i1 %12537 to i8
  store i8 %12538, i8* %12, align 1
  %12539 = trunc i64 %12534 to i32
  %12540 = and i32 %12539, 255
  %12541 = tail call i32 @llvm.ctpop.i32(i32 %12540)
  %12542 = trunc i32 %12541 to i8
  %12543 = and i8 %12542, 1
  %12544 = xor i8 %12543, 1
  store i8 %12544, i8* %13, align 1
  %12545 = xor i64 %12504, %12534
  %12546 = lshr i64 %12545, 4
  %12547 = trunc i64 %12546 to i8
  %12548 = and i8 %12547, 1
  store i8 %12548, i8* %14, align 1
  %12549 = icmp eq i64 %12534, 0
  %12550 = zext i1 %12549 to i8
  store i8 %12550, i8* %15, align 1
  %12551 = lshr i64 %12534, 63
  %12552 = trunc i64 %12551 to i8
  store i8 %12552, i8* %16, align 1
  %12553 = lshr i64 %12532, 57
  %12554 = and i64 %12553, 1
  %12555 = xor i64 %12551, %12520
  %12556 = xor i64 %12551, %12554
  %12557 = add nuw nsw i64 %12555, %12556
  %12558 = icmp eq i64 %12557, 2
  %12559 = zext i1 %12558 to i8
  store i8 %12559, i8* %17, align 1
  %12560 = add i64 %12527, -28
  %12561 = add i64 %12496, 29
  store i64 %12561, i64* %3, align 8
  %12562 = inttoptr i64 %12560 to i32*
  %12563 = load i32, i32* %12562, align 4
  %12564 = sext i32 %12563 to i64
  store i64 %12564, i64* %RCX.i3977, align 8
  %12565 = shl nsw i64 %12564, 2
  %12566 = add i64 %12565, %12534
  %12567 = add i64 %12496, 33
  store i64 %12567, i64* %3, align 8
  %12568 = inttoptr i64 %12566 to i32*
  %12569 = load i32, i32* %12568, align 4
  %12570 = sext i32 %12569 to i64
  store i64 %12570, i64* %RAX.i2610, align 8
  %12571 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %12572 = add i64 %12571, 12600
  store i64 %12572, i64* %RCX.i3977, align 8
  %12573 = icmp ugt i64 %12571, -12601
  %12574 = zext i1 %12573 to i8
  store i8 %12574, i8* %12, align 1
  %12575 = trunc i64 %12572 to i32
  %12576 = and i32 %12575, 255
  %12577 = tail call i32 @llvm.ctpop.i32(i32 %12576)
  %12578 = trunc i32 %12577 to i8
  %12579 = and i8 %12578, 1
  %12580 = xor i8 %12579, 1
  store i8 %12580, i8* %13, align 1
  %12581 = xor i64 %12571, 16
  %12582 = xor i64 %12581, %12572
  %12583 = lshr i64 %12582, 4
  %12584 = trunc i64 %12583 to i8
  %12585 = and i8 %12584, 1
  store i8 %12585, i8* %14, align 1
  %12586 = icmp eq i64 %12572, 0
  %12587 = zext i1 %12586 to i8
  store i8 %12587, i8* %15, align 1
  %12588 = lshr i64 %12572, 63
  %12589 = trunc i64 %12588 to i8
  store i8 %12589, i8* %16, align 1
  %12590 = lshr i64 %12571, 63
  %12591 = xor i64 %12588, %12590
  %12592 = add nuw nsw i64 %12591, %12588
  %12593 = icmp eq i64 %12592, 2
  %12594 = zext i1 %12593 to i8
  store i8 %12594, i8* %17, align 1
  %12595 = load i64, i64* %RBP.i, align 8
  %12596 = add i64 %12595, -24
  %12597 = add i64 %12496, 51
  store i64 %12597, i64* %3, align 8
  %12598 = inttoptr i64 %12596 to i32*
  %12599 = load i32, i32* %12598, align 4
  %12600 = zext i32 %12599 to i64
  store i64 %12600, i64* %RDX.i4094, align 8
  %12601 = add i64 %12595, -84
  %12602 = add i64 %12496, 54
  store i64 %12602, i64* %3, align 8
  %12603 = inttoptr i64 %12601 to i32*
  %12604 = load i32, i32* %12603, align 4
  %12605 = add i32 %12604, %12599
  %12606 = zext i32 %12605 to i64
  store i64 %12606, i64* %RDX.i4094, align 8
  %12607 = sext i32 %12605 to i64
  %12608 = shl nsw i64 %12607, 5
  store i64 %12608, i64* %RSI.i3950, align 8
  %12609 = load i64, i64* %RCX.i3977, align 8
  %12610 = add i64 %12608, %12609
  store i64 %12610, i64* %RCX.i3977, align 8
  %12611 = icmp ult i64 %12610, %12609
  %12612 = icmp ult i64 %12610, %12608
  %12613 = or i1 %12611, %12612
  %12614 = zext i1 %12613 to i8
  store i8 %12614, i8* %12, align 1
  %12615 = trunc i64 %12610 to i32
  %12616 = and i32 %12615, 255
  %12617 = tail call i32 @llvm.ctpop.i32(i32 %12616)
  %12618 = trunc i32 %12617 to i8
  %12619 = and i8 %12618, 1
  %12620 = xor i8 %12619, 1
  store i8 %12620, i8* %13, align 1
  %12621 = xor i64 %12609, %12610
  %12622 = lshr i64 %12621, 4
  %12623 = trunc i64 %12622 to i8
  %12624 = and i8 %12623, 1
  store i8 %12624, i8* %14, align 1
  %12625 = icmp eq i64 %12610, 0
  %12626 = zext i1 %12625 to i8
  store i8 %12626, i8* %15, align 1
  %12627 = lshr i64 %12610, 63
  %12628 = trunc i64 %12627 to i8
  store i8 %12628, i8* %16, align 1
  %12629 = lshr i64 %12609, 63
  %12630 = lshr i64 %12607, 58
  %12631 = and i64 %12630, 1
  %12632 = xor i64 %12627, %12629
  %12633 = xor i64 %12627, %12631
  %12634 = add nuw nsw i64 %12632, %12633
  %12635 = icmp eq i64 %12634, 2
  %12636 = zext i1 %12635 to i8
  store i8 %12636, i8* %17, align 1
  %12637 = load i64, i64* %RBP.i, align 8
  %12638 = add i64 %12637, -28
  %12639 = add i64 %12496, 67
  store i64 %12639, i64* %3, align 8
  %12640 = inttoptr i64 %12638 to i32*
  %12641 = load i32, i32* %12640, align 4
  %12642 = zext i32 %12641 to i64
  store i64 %12642, i64* %RDX.i4094, align 8
  %12643 = add i64 %12637, -88
  %12644 = add i64 %12496, 70
  store i64 %12644, i64* %3, align 8
  %12645 = inttoptr i64 %12643 to i32*
  %12646 = load i32, i32* %12645, align 4
  %12647 = add i32 %12646, %12641
  %12648 = zext i32 %12647 to i64
  store i64 %12648, i64* %RDX.i4094, align 8
  %12649 = icmp ult i32 %12647, %12641
  %12650 = icmp ult i32 %12647, %12646
  %12651 = or i1 %12649, %12650
  %12652 = zext i1 %12651 to i8
  store i8 %12652, i8* %12, align 1
  %12653 = and i32 %12647, 255
  %12654 = tail call i32 @llvm.ctpop.i32(i32 %12653)
  %12655 = trunc i32 %12654 to i8
  %12656 = and i8 %12655, 1
  %12657 = xor i8 %12656, 1
  store i8 %12657, i8* %13, align 1
  %12658 = xor i32 %12646, %12641
  %12659 = xor i32 %12658, %12647
  %12660 = lshr i32 %12659, 4
  %12661 = trunc i32 %12660 to i8
  %12662 = and i8 %12661, 1
  store i8 %12662, i8* %14, align 1
  %12663 = icmp eq i32 %12647, 0
  %12664 = zext i1 %12663 to i8
  store i8 %12664, i8* %15, align 1
  %12665 = lshr i32 %12647, 31
  %12666 = trunc i32 %12665 to i8
  store i8 %12666, i8* %16, align 1
  %12667 = lshr i32 %12641, 31
  %12668 = lshr i32 %12646, 31
  %12669 = xor i32 %12665, %12667
  %12670 = xor i32 %12665, %12668
  %12671 = add nuw nsw i32 %12669, %12670
  %12672 = icmp eq i32 %12671, 2
  %12673 = zext i1 %12672 to i8
  store i8 %12673, i8* %17, align 1
  %12674 = sext i32 %12647 to i64
  store i64 %12674, i64* %RSI.i3950, align 8
  %12675 = shl nsw i64 %12674, 1
  %12676 = add i64 %12610, %12675
  %12677 = add i64 %12496, 77
  store i64 %12677, i64* %3, align 8
  %12678 = inttoptr i64 %12676 to i16*
  %12679 = load i16, i16* %12678, align 2
  %12680 = zext i16 %12679 to i64
  store i64 %12680, i64* %RDX.i4094, align 8
  %12681 = zext i16 %12679 to i64
  %12682 = shl nuw nsw i64 %12681, 6
  store i64 %12682, i64* %RCX.i3977, align 8
  %12683 = load i64, i64* %RAX.i2610, align 8
  %12684 = add i64 %12682, %12683
  %12685 = add i64 %12684, 32
  %12686 = lshr i64 %12685, 5
  %12687 = trunc i64 %12686 to i8
  %12688 = and i8 %12687, 1
  %12689 = ashr i64 %12685, 6
  store i64 %12689, i64* %RAX.i2610, align 8
  store i8 %12688, i8* %12, align 1
  %12690 = trunc i64 %12689 to i32
  %12691 = and i32 %12690, 255
  %12692 = tail call i32 @llvm.ctpop.i32(i32 %12691)
  %12693 = trunc i32 %12692 to i8
  %12694 = and i8 %12693, 1
  %12695 = xor i8 %12694, 1
  store i8 %12695, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %12696 = icmp eq i64 %12689, 0
  %12697 = zext i1 %12696 to i8
  store i8 %12697, i8* %15, align 1
  %12698 = lshr i64 %12689, 63
  %12699 = trunc i64 %12698 to i8
  store i8 %12699, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %12700 = load i64, i64* %RBP.i, align 8
  %12701 = add i64 %12700, -752
  %12702 = add i64 %12496, 101
  store i64 %12702, i64* %3, align 8
  %12703 = inttoptr i64 %12701 to i64*
  store i64 %12689, i64* %12703, align 8
  %.pre188 = load i64, i64* %3, align 8
  br label %block_.L_4ac22e

block_.L_4ac22e:                                  ; preds = %block_.L_4ac1c9, %block_4ac1b9
  %12704 = phi i64 [ %.pre188, %block_.L_4ac1c9 ], [ %12502, %block_4ac1b9 ]
  %12705 = load i64, i64* %RBP.i, align 8
  %12706 = add i64 %12705, -752
  %12707 = add i64 %12704, 7
  store i64 %12707, i64* %3, align 8
  %12708 = inttoptr i64 %12706 to i64*
  %12709 = load i64, i64* %12708, align 8
  store i64 %12709, i64* %RAX.i2610, align 8
  %12710 = add i64 %12705, -744
  %12711 = add i64 %12704, 14
  store i64 %12711, i64* %3, align 8
  %12712 = inttoptr i64 %12710 to i64*
  store i64 %12709, i64* %12712, align 8
  %.pre189 = load i64, i64* %3, align 8
  br label %block_.L_4ac23c

block_.L_4ac23c:                                  ; preds = %block_.L_4ac22e, %block_4ac132
  %12713 = phi i64 [ %.pre189, %block_.L_4ac22e ], [ %12283, %block_4ac132 ]
  %12714 = load i64, i64* %RBP.i, align 8
  %12715 = add i64 %12714, -744
  %12716 = add i64 %12713, 7
  store i64 %12716, i64* %3, align 8
  %12717 = inttoptr i64 %12715 to i64*
  %12718 = load i64, i64* %12717, align 8
  %12719 = and i64 %12718, 4294967295
  store i64 %12719, i64* %RCX.i3977, align 8
  %12720 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %12721 = add i64 %12720, 13112
  store i64 %12721, i64* %RAX.i2610, align 8
  %12722 = icmp ugt i64 %12720, -13113
  %12723 = zext i1 %12722 to i8
  store i8 %12723, i8* %12, align 1
  %12724 = trunc i64 %12721 to i32
  %12725 = and i32 %12724, 255
  %12726 = tail call i32 @llvm.ctpop.i32(i32 %12725)
  %12727 = trunc i32 %12726 to i8
  %12728 = and i8 %12727, 1
  %12729 = xor i8 %12728, 1
  store i8 %12729, i8* %13, align 1
  %12730 = xor i64 %12720, 16
  %12731 = xor i64 %12730, %12721
  %12732 = lshr i64 %12731, 4
  %12733 = trunc i64 %12732 to i8
  %12734 = and i8 %12733, 1
  store i8 %12734, i8* %14, align 1
  %12735 = icmp eq i64 %12721, 0
  %12736 = zext i1 %12735 to i8
  store i8 %12736, i8* %15, align 1
  %12737 = lshr i64 %12721, 63
  %12738 = trunc i64 %12737 to i8
  store i8 %12738, i8* %16, align 1
  %12739 = lshr i64 %12720, 63
  %12740 = xor i64 %12737, %12739
  %12741 = add nuw nsw i64 %12740, %12737
  %12742 = icmp eq i64 %12741, 2
  %12743 = zext i1 %12742 to i8
  store i8 %12743, i8* %17, align 1
  %12744 = add i64 %12714, -24
  %12745 = add i64 %12713, 27
  store i64 %12745, i64* %3, align 8
  %12746 = inttoptr i64 %12744 to i32*
  %12747 = load i32, i32* %12746, align 4
  %12748 = sext i32 %12747 to i64
  %12749 = shl nsw i64 %12748, 6
  store i64 %12749, i64* %RDX.i4094, align 8
  %12750 = add i64 %12749, %12721
  store i64 %12750, i64* %RAX.i2610, align 8
  %12751 = icmp ult i64 %12750, %12721
  %12752 = icmp ult i64 %12750, %12749
  %12753 = or i1 %12751, %12752
  %12754 = zext i1 %12753 to i8
  store i8 %12754, i8* %12, align 1
  %12755 = trunc i64 %12750 to i32
  %12756 = and i32 %12755, 255
  %12757 = tail call i32 @llvm.ctpop.i32(i32 %12756)
  %12758 = trunc i32 %12757 to i8
  %12759 = and i8 %12758, 1
  %12760 = xor i8 %12759, 1
  store i8 %12760, i8* %13, align 1
  %12761 = xor i64 %12721, %12750
  %12762 = lshr i64 %12761, 4
  %12763 = trunc i64 %12762 to i8
  %12764 = and i8 %12763, 1
  store i8 %12764, i8* %14, align 1
  %12765 = icmp eq i64 %12750, 0
  %12766 = zext i1 %12765 to i8
  store i8 %12766, i8* %15, align 1
  %12767 = lshr i64 %12750, 63
  %12768 = trunc i64 %12767 to i8
  store i8 %12768, i8* %16, align 1
  %12769 = lshr i64 %12748, 57
  %12770 = and i64 %12769, 1
  %12771 = xor i64 %12767, %12737
  %12772 = xor i64 %12767, %12770
  %12773 = add nuw nsw i64 %12771, %12772
  %12774 = icmp eq i64 %12773, 2
  %12775 = zext i1 %12774 to i8
  store i8 %12775, i8* %17, align 1
  %12776 = load i64, i64* %RBP.i, align 8
  %12777 = add i64 %12776, -28
  %12778 = add i64 %12713, 38
  store i64 %12778, i64* %3, align 8
  %12779 = inttoptr i64 %12777 to i32*
  %12780 = load i32, i32* %12779, align 4
  %12781 = sext i32 %12780 to i64
  store i64 %12781, i64* %RDX.i4094, align 8
  %12782 = shl nsw i64 %12781, 2
  %12783 = add i64 %12782, %12750
  %12784 = load i32, i32* %ECX.i3947, align 4
  %12785 = add i64 %12713, 41
  store i64 %12785, i64* %3, align 8
  %12786 = inttoptr i64 %12783 to i32*
  store i32 %12784, i32* %12786, align 4
  %12787 = load i64, i64* %3, align 8
  %12788 = add i64 %12787, 75
  store i64 %12788, i64* %3, align 8
  br label %block_.L_4ac2b0

block_.L_4ac26a:                                  ; preds = %block_.L_4ac00e
  %12789 = add i64 %11538, 13112
  store i64 %12789, i64* %RAX.i2610, align 8
  %12790 = icmp ugt i64 %11538, -13113
  %12791 = zext i1 %12790 to i8
  store i8 %12791, i8* %12, align 1
  %12792 = trunc i64 %12789 to i32
  %12793 = and i32 %12792, 255
  %12794 = tail call i32 @llvm.ctpop.i32(i32 %12793)
  %12795 = trunc i32 %12794 to i8
  %12796 = and i8 %12795, 1
  %12797 = xor i8 %12796, 1
  store i8 %12797, i8* %13, align 1
  %12798 = xor i64 %11538, 16
  %12799 = xor i64 %12798, %12789
  %12800 = lshr i64 %12799, 4
  %12801 = trunc i64 %12800 to i8
  %12802 = and i8 %12801, 1
  store i8 %12802, i8* %14, align 1
  %12803 = icmp eq i64 %12789, 0
  %12804 = zext i1 %12803 to i8
  store i8 %12804, i8* %15, align 1
  %12805 = lshr i64 %12789, 63
  %12806 = trunc i64 %12805 to i8
  store i8 %12806, i8* %16, align 1
  %12807 = lshr i64 %11538, 63
  %12808 = xor i64 %12805, %12807
  %12809 = add nuw nsw i64 %12808, %12805
  %12810 = icmp eq i64 %12809, 2
  %12811 = zext i1 %12810 to i8
  store i8 %12811, i8* %17, align 1
  %12812 = add i64 %11494, -24
  %12813 = add i64 %11799, 18
  store i64 %12813, i64* %3, align 8
  %12814 = inttoptr i64 %12812 to i32*
  %12815 = load i32, i32* %12814, align 4
  %12816 = sext i32 %12815 to i64
  %12817 = shl nsw i64 %12816, 6
  store i64 %12817, i64* %RCX.i3977, align 8
  %12818 = add i64 %12817, %12789
  store i64 %12818, i64* %RAX.i2610, align 8
  %12819 = icmp ult i64 %12818, %12789
  %12820 = icmp ult i64 %12818, %12817
  %12821 = or i1 %12819, %12820
  %12822 = zext i1 %12821 to i8
  store i8 %12822, i8* %12, align 1
  %12823 = trunc i64 %12818 to i32
  %12824 = and i32 %12823, 255
  %12825 = tail call i32 @llvm.ctpop.i32(i32 %12824)
  %12826 = trunc i32 %12825 to i8
  %12827 = and i8 %12826, 1
  %12828 = xor i8 %12827, 1
  store i8 %12828, i8* %13, align 1
  %12829 = xor i64 %12789, %12818
  %12830 = lshr i64 %12829, 4
  %12831 = trunc i64 %12830 to i8
  %12832 = and i8 %12831, 1
  store i8 %12832, i8* %14, align 1
  %12833 = icmp eq i64 %12818, 0
  %12834 = zext i1 %12833 to i8
  store i8 %12834, i8* %15, align 1
  %12835 = lshr i64 %12818, 63
  %12836 = trunc i64 %12835 to i8
  store i8 %12836, i8* %16, align 1
  %12837 = lshr i64 %12816, 57
  %12838 = and i64 %12837, 1
  %12839 = xor i64 %12835, %12805
  %12840 = xor i64 %12835, %12838
  %12841 = add nuw nsw i64 %12839, %12840
  %12842 = icmp eq i64 %12841, 2
  %12843 = zext i1 %12842 to i8
  store i8 %12843, i8* %17, align 1
  %12844 = load i64, i64* %RBP.i, align 8
  %12845 = add i64 %12844, -28
  %12846 = add i64 %11799, 29
  store i64 %12846, i64* %3, align 8
  %12847 = inttoptr i64 %12845 to i32*
  %12848 = load i32, i32* %12847, align 4
  %12849 = sext i32 %12848 to i64
  store i64 %12849, i64* %RCX.i3977, align 8
  %12850 = shl nsw i64 %12849, 2
  %12851 = add i64 %12850, %12818
  %12852 = add i64 %11799, 32
  store i64 %12852, i64* %3, align 8
  %12853 = inttoptr i64 %12851 to i32*
  %12854 = load i32, i32* %12853, align 4
  %12855 = add i32 %12854, 32
  %12856 = zext i32 %12855 to i64
  %12857 = shl nuw i64 %12856, 32
  %12858 = ashr i64 %12857, 37
  %12859 = lshr i64 %12858, 1
  %12860 = and i64 %12859, 4294967295
  store i64 %12860, i64* %RDX.i4094, align 8
  %12861 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %12862 = add i64 %12861, 13112
  store i64 %12862, i64* %RAX.i2610, align 8
  %12863 = icmp ugt i64 %12861, -13113
  %12864 = zext i1 %12863 to i8
  store i8 %12864, i8* %12, align 1
  %12865 = trunc i64 %12862 to i32
  %12866 = and i32 %12865, 255
  %12867 = tail call i32 @llvm.ctpop.i32(i32 %12866)
  %12868 = trunc i32 %12867 to i8
  %12869 = and i8 %12868, 1
  %12870 = xor i8 %12869, 1
  store i8 %12870, i8* %13, align 1
  %12871 = xor i64 %12861, 16
  %12872 = xor i64 %12871, %12862
  %12873 = lshr i64 %12872, 4
  %12874 = trunc i64 %12873 to i8
  %12875 = and i8 %12874, 1
  store i8 %12875, i8* %14, align 1
  %12876 = icmp eq i64 %12862, 0
  %12877 = zext i1 %12876 to i8
  store i8 %12877, i8* %15, align 1
  %12878 = lshr i64 %12862, 63
  %12879 = trunc i64 %12878 to i8
  store i8 %12879, i8* %16, align 1
  %12880 = lshr i64 %12861, 63
  %12881 = xor i64 %12878, %12880
  %12882 = add nuw nsw i64 %12881, %12878
  %12883 = icmp eq i64 %12882, 2
  %12884 = zext i1 %12883 to i8
  store i8 %12884, i8* %17, align 1
  %12885 = load i64, i64* %RBP.i, align 8
  %12886 = add i64 %12885, -24
  %12887 = add i64 %11799, 56
  store i64 %12887, i64* %3, align 8
  %12888 = inttoptr i64 %12886 to i32*
  %12889 = load i32, i32* %12888, align 4
  %12890 = sext i32 %12889 to i64
  %12891 = shl nsw i64 %12890, 6
  store i64 %12891, i64* %RCX.i3977, align 8
  %12892 = add i64 %12891, %12862
  store i64 %12892, i64* %RAX.i2610, align 8
  %12893 = icmp ult i64 %12892, %12862
  %12894 = icmp ult i64 %12892, %12891
  %12895 = or i1 %12893, %12894
  %12896 = zext i1 %12895 to i8
  store i8 %12896, i8* %12, align 1
  %12897 = trunc i64 %12892 to i32
  %12898 = and i32 %12897, 255
  %12899 = tail call i32 @llvm.ctpop.i32(i32 %12898)
  %12900 = trunc i32 %12899 to i8
  %12901 = and i8 %12900, 1
  %12902 = xor i8 %12901, 1
  store i8 %12902, i8* %13, align 1
  %12903 = xor i64 %12862, %12892
  %12904 = lshr i64 %12903, 4
  %12905 = trunc i64 %12904 to i8
  %12906 = and i8 %12905, 1
  store i8 %12906, i8* %14, align 1
  %12907 = icmp eq i64 %12892, 0
  %12908 = zext i1 %12907 to i8
  store i8 %12908, i8* %15, align 1
  %12909 = lshr i64 %12892, 63
  %12910 = trunc i64 %12909 to i8
  store i8 %12910, i8* %16, align 1
  %12911 = lshr i64 %12890, 57
  %12912 = and i64 %12911, 1
  %12913 = xor i64 %12909, %12878
  %12914 = xor i64 %12909, %12912
  %12915 = add nuw nsw i64 %12913, %12914
  %12916 = icmp eq i64 %12915, 2
  %12917 = zext i1 %12916 to i8
  store i8 %12917, i8* %17, align 1
  %12918 = add i64 %12885, -28
  %12919 = add i64 %11799, 67
  store i64 %12919, i64* %3, align 8
  %12920 = inttoptr i64 %12918 to i32*
  %12921 = load i32, i32* %12920, align 4
  %12922 = sext i32 %12921 to i64
  store i64 %12922, i64* %RCX.i3977, align 8
  %12923 = shl nsw i64 %12922, 2
  %12924 = add i64 %12923, %12892
  %12925 = load i32, i32* %EDX.i4064, align 4
  %12926 = add i64 %11799, 70
  store i64 %12926, i64* %3, align 8
  %12927 = inttoptr i64 %12924 to i32*
  store i32 %12925, i32* %12927, align 4
  %.pre190 = load i64, i64* %3, align 8
  br label %block_.L_4ac2b0

block_.L_4ac2b0:                                  ; preds = %block_.L_4ac26a, %block_.L_4ac23c
  %12928 = phi i64 [ %.pre190, %block_.L_4ac26a ], [ %12788, %block_.L_4ac23c ]
  %12929 = add i64 %12928, 5
  store i64 %12929, i64* %3, align 8
  br label %block_.L_4ac2b5

block_.L_4ac2b5:                                  ; preds = %block_.L_4ac2b0, %block_4abf9c
  %storemerge67 = phi i64 [ %11785, %block_4abf9c ], [ %12929, %block_.L_4ac2b0 ]
  %12930 = load i64, i64* %RBP.i, align 8
  %12931 = add i64 %12930, -28
  %12932 = add i64 %storemerge67, 8
  store i64 %12932, i64* %3, align 8
  %12933 = inttoptr i64 %12931 to i32*
  %12934 = load i32, i32* %12933, align 4
  %12935 = add i32 %12934, 1
  %12936 = zext i32 %12935 to i64
  store i64 %12936, i64* %RAX.i2610, align 8
  %12937 = icmp eq i32 %12934, -1
  %12938 = icmp eq i32 %12935, 0
  %12939 = or i1 %12937, %12938
  %12940 = zext i1 %12939 to i8
  store i8 %12940, i8* %12, align 1
  %12941 = and i32 %12935, 255
  %12942 = tail call i32 @llvm.ctpop.i32(i32 %12941)
  %12943 = trunc i32 %12942 to i8
  %12944 = and i8 %12943, 1
  %12945 = xor i8 %12944, 1
  store i8 %12945, i8* %13, align 1
  %12946 = xor i32 %12935, %12934
  %12947 = lshr i32 %12946, 4
  %12948 = trunc i32 %12947 to i8
  %12949 = and i8 %12948, 1
  store i8 %12949, i8* %14, align 1
  %12950 = zext i1 %12938 to i8
  store i8 %12950, i8* %15, align 1
  %12951 = lshr i32 %12935, 31
  %12952 = trunc i32 %12951 to i8
  store i8 %12952, i8* %16, align 1
  %12953 = lshr i32 %12934, 31
  %12954 = xor i32 %12951, %12953
  %12955 = add nuw nsw i32 %12954, %12951
  %12956 = icmp eq i32 %12955, 2
  %12957 = zext i1 %12956 to i8
  store i8 %12957, i8* %17, align 1
  %12958 = add i64 %storemerge67, 14
  store i64 %12958, i64* %3, align 8
  store i32 %12935, i32* %12933, align 4
  %12959 = load i64, i64* %3, align 8
  %12960 = add i64 %12959, -830
  store i64 %12960, i64* %3, align 8
  br label %block_.L_4abf85

block_.L_4ac2c8:                                  ; preds = %block_.L_4abf85
  %12961 = add i64 %11494, -24
  %12962 = add i64 %11522, 8
  store i64 %12962, i64* %3, align 8
  %12963 = inttoptr i64 %12961 to i32*
  %12964 = load i32, i32* %12963, align 4
  %12965 = add i32 %12964, 1
  %12966 = zext i32 %12965 to i64
  store i64 %12966, i64* %RAX.i2610, align 8
  %12967 = icmp eq i32 %12964, -1
  %12968 = icmp eq i32 %12965, 0
  %12969 = or i1 %12967, %12968
  %12970 = zext i1 %12969 to i8
  store i8 %12970, i8* %12, align 1
  %12971 = and i32 %12965, 255
  %12972 = tail call i32 @llvm.ctpop.i32(i32 %12971)
  %12973 = trunc i32 %12972 to i8
  %12974 = and i8 %12973, 1
  %12975 = xor i8 %12974, 1
  store i8 %12975, i8* %13, align 1
  %12976 = xor i32 %12965, %12964
  %12977 = lshr i32 %12976, 4
  %12978 = trunc i32 %12977 to i8
  %12979 = and i8 %12978, 1
  store i8 %12979, i8* %14, align 1
  %12980 = zext i1 %12968 to i8
  store i8 %12980, i8* %15, align 1
  %12981 = lshr i32 %12965, 31
  %12982 = trunc i32 %12981 to i8
  store i8 %12982, i8* %16, align 1
  %12983 = lshr i32 %12964, 31
  %12984 = xor i32 %12981, %12983
  %12985 = add nuw nsw i32 %12984, %12981
  %12986 = icmp eq i32 %12985, 2
  %12987 = zext i1 %12986 to i8
  store i8 %12987, i8* %17, align 1
  %12988 = add i64 %11522, 14
  store i64 %12988, i64* %3, align 8
  store i32 %12965, i32* %12963, align 4
  %12989 = load i64, i64* %3, align 8
  %12990 = add i64 %12989, -866
  store i64 %12990, i64* %3, align 8
  br label %block_.L_4abf74

block_.L_4ac2db:                                  ; preds = %block_.L_4abf74
  %12991 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %12991, i64* %RAX.i2610, align 8
  %12992 = add i64 %12991, 72724
  %12993 = add i64 %11489, 15
  store i64 %12993, i64* %3, align 8
  %12994 = inttoptr i64 %12992 to i32*
  %12995 = load i32, i32* %12994, align 4
  store i8 0, i8* %12, align 1
  %12996 = and i32 %12995, 255
  %12997 = tail call i32 @llvm.ctpop.i32(i32 %12996)
  %12998 = trunc i32 %12997 to i8
  %12999 = and i8 %12998, 1
  %13000 = xor i8 %12999, 1
  store i8 %13000, i8* %13, align 1
  store i8 0, i8* %14, align 1
  %13001 = icmp eq i32 %12995, 0
  %13002 = zext i1 %13001 to i8
  store i8 %13002, i8* %15, align 1
  %13003 = lshr i32 %12995, 31
  %13004 = trunc i32 %13003 to i8
  store i8 %13004, i8* %16, align 1
  store i8 0, i8* %17, align 1
  %.v214 = select i1 %13001, i64 21, i64 197
  %13005 = add i64 %11489, %.v214
  store i64 %13005, i64* %3, align 8
  br i1 %13001, label %block_4ac2f0, label %block_.L_4ac3a0

block_4ac2f0:                                     ; preds = %block_.L_4ac2db
  %13006 = add i64 %11461, -28
  %13007 = add i64 %13005, 7
  store i64 %13007, i64* %3, align 8
  %13008 = inttoptr i64 %13006 to i32*
  store i32 0, i32* %13008, align 4
  %SI.i62 = bitcast %union.anon* %25 to i16*
  %.pre184 = load i64, i64* %3, align 8
  br label %block_.L_4ac2f7

block_.L_4ac2f7:                                  ; preds = %block_.L_4ac388, %block_4ac2f0
  %13009 = phi i64 [ %13352, %block_.L_4ac388 ], [ %.pre184, %block_4ac2f0 ]
  %13010 = load i64, i64* %RBP.i, align 8
  %13011 = add i64 %13010, -28
  %13012 = add i64 %13009, 4
  store i64 %13012, i64* %3, align 8
  %13013 = inttoptr i64 %13011 to i32*
  %13014 = load i32, i32* %13013, align 4
  %13015 = add i32 %13014, -8
  %13016 = icmp ult i32 %13014, 8
  %13017 = zext i1 %13016 to i8
  store i8 %13017, i8* %12, align 1
  %13018 = and i32 %13015, 255
  %13019 = tail call i32 @llvm.ctpop.i32(i32 %13018)
  %13020 = trunc i32 %13019 to i8
  %13021 = and i8 %13020, 1
  %13022 = xor i8 %13021, 1
  store i8 %13022, i8* %13, align 1
  %13023 = xor i32 %13015, %13014
  %13024 = lshr i32 %13023, 4
  %13025 = trunc i32 %13024 to i8
  %13026 = and i8 %13025, 1
  store i8 %13026, i8* %14, align 1
  %13027 = icmp eq i32 %13015, 0
  %13028 = zext i1 %13027 to i8
  store i8 %13028, i8* %15, align 1
  %13029 = lshr i32 %13015, 31
  %13030 = trunc i32 %13029 to i8
  store i8 %13030, i8* %16, align 1
  %13031 = lshr i32 %13014, 31
  %13032 = xor i32 %13029, %13031
  %13033 = add nuw nsw i32 %13032, %13031
  %13034 = icmp eq i32 %13033, 2
  %13035 = zext i1 %13034 to i8
  store i8 %13035, i8* %17, align 1
  %13036 = icmp ne i8 %13030, 0
  %13037 = xor i1 %13036, %13034
  %.v215 = select i1 %13037, i64 10, i64 164
  %13038 = add i64 %13009, %.v215
  store i64 %13038, i64* %3, align 8
  br i1 %13037, label %block_4ac301, label %block_.L_4ac39b

block_4ac301:                                     ; preds = %block_.L_4ac2f7
  %13039 = add i64 %13010, -24
  %13040 = add i64 %13038, 7
  store i64 %13040, i64* %3, align 8
  %13041 = inttoptr i64 %13039 to i32*
  store i32 0, i32* %13041, align 4
  %.pre185 = load i64, i64* %3, align 8
  br label %block_.L_4ac308

block_.L_4ac308:                                  ; preds = %block_4ac312, %block_4ac301
  %13042 = phi i64 [ %13322, %block_4ac312 ], [ %.pre185, %block_4ac301 ]
  %13043 = load i64, i64* %RBP.i, align 8
  %13044 = add i64 %13043, -24
  %13045 = add i64 %13042, 4
  store i64 %13045, i64* %3, align 8
  %13046 = inttoptr i64 %13044 to i32*
  %13047 = load i32, i32* %13046, align 4
  %13048 = add i32 %13047, -8
  %13049 = icmp ult i32 %13047, 8
  %13050 = zext i1 %13049 to i8
  store i8 %13050, i8* %12, align 1
  %13051 = and i32 %13048, 255
  %13052 = tail call i32 @llvm.ctpop.i32(i32 %13051)
  %13053 = trunc i32 %13052 to i8
  %13054 = and i8 %13053, 1
  %13055 = xor i8 %13054, 1
  store i8 %13055, i8* %13, align 1
  %13056 = xor i32 %13048, %13047
  %13057 = lshr i32 %13056, 4
  %13058 = trunc i32 %13057 to i8
  %13059 = and i8 %13058, 1
  store i8 %13059, i8* %14, align 1
  %13060 = icmp eq i32 %13048, 0
  %13061 = zext i1 %13060 to i8
  store i8 %13061, i8* %15, align 1
  %13062 = lshr i32 %13048, 31
  %13063 = trunc i32 %13062 to i8
  store i8 %13063, i8* %16, align 1
  %13064 = lshr i32 %13047, 31
  %13065 = xor i32 %13062, %13064
  %13066 = add nuw nsw i32 %13065, %13064
  %13067 = icmp eq i32 %13066, 2
  %13068 = zext i1 %13067 to i8
  store i8 %13068, i8* %17, align 1
  %13069 = icmp ne i8 %13063, 0
  %13070 = xor i1 %13069, %13067
  %.v204 = select i1 %13070, i64 10, i64 128
  %13071 = add i64 %13042, %.v204
  store i64 %13071, i64* %3, align 8
  br i1 %13070, label %block_4ac312, label %block_.L_4ac388

block_4ac312:                                     ; preds = %block_.L_4ac308
  %13072 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  %13073 = add i64 %13072, 13112
  store i64 %13073, i64* %RAX.i2610, align 8
  %13074 = icmp ugt i64 %13072, -13113
  %13075 = zext i1 %13074 to i8
  store i8 %13075, i8* %12, align 1
  %13076 = trunc i64 %13073 to i32
  %13077 = and i32 %13076, 255
  %13078 = tail call i32 @llvm.ctpop.i32(i32 %13077)
  %13079 = trunc i32 %13078 to i8
  %13080 = and i8 %13079, 1
  %13081 = xor i8 %13080, 1
  store i8 %13081, i8* %13, align 1
  %13082 = xor i64 %13072, 16
  %13083 = xor i64 %13082, %13073
  %13084 = lshr i64 %13083, 4
  %13085 = trunc i64 %13084 to i8
  %13086 = and i8 %13085, 1
  store i8 %13086, i8* %14, align 1
  %13087 = icmp eq i64 %13073, 0
  %13088 = zext i1 %13087 to i8
  store i8 %13088, i8* %15, align 1
  %13089 = lshr i64 %13073, 63
  %13090 = trunc i64 %13089 to i8
  store i8 %13090, i8* %16, align 1
  %13091 = lshr i64 %13072, 63
  %13092 = xor i64 %13089, %13091
  %13093 = add nuw nsw i64 %13092, %13089
  %13094 = icmp eq i64 %13093, 2
  %13095 = zext i1 %13094 to i8
  store i8 %13095, i8* %17, align 1
  %13096 = add i64 %13071, 18
  store i64 %13096, i64* %3, align 8
  %13097 = load i32, i32* %13046, align 4
  %13098 = sext i32 %13097 to i64
  %13099 = shl nsw i64 %13098, 6
  store i64 %13099, i64* %RCX.i3977, align 8
  %13100 = add i64 %13099, %13073
  store i64 %13100, i64* %RAX.i2610, align 8
  %13101 = icmp ult i64 %13100, %13073
  %13102 = icmp ult i64 %13100, %13099
  %13103 = or i1 %13101, %13102
  %13104 = zext i1 %13103 to i8
  store i8 %13104, i8* %12, align 1
  %13105 = trunc i64 %13100 to i32
  %13106 = and i32 %13105, 255
  %13107 = tail call i32 @llvm.ctpop.i32(i32 %13106)
  %13108 = trunc i32 %13107 to i8
  %13109 = and i8 %13108, 1
  %13110 = xor i8 %13109, 1
  store i8 %13110, i8* %13, align 1
  %13111 = xor i64 %13073, %13100
  %13112 = lshr i64 %13111, 4
  %13113 = trunc i64 %13112 to i8
  %13114 = and i8 %13113, 1
  store i8 %13114, i8* %14, align 1
  %13115 = icmp eq i64 %13100, 0
  %13116 = zext i1 %13115 to i8
  store i8 %13116, i8* %15, align 1
  %13117 = lshr i64 %13100, 63
  %13118 = trunc i64 %13117 to i8
  store i8 %13118, i8* %16, align 1
  %13119 = lshr i64 %13098, 57
  %13120 = and i64 %13119, 1
  %13121 = xor i64 %13117, %13089
  %13122 = xor i64 %13117, %13120
  %13123 = add nuw nsw i64 %13121, %13122
  %13124 = icmp eq i64 %13123, 2
  %13125 = zext i1 %13124 to i8
  store i8 %13125, i8* %17, align 1
  %13126 = add i64 %13043, -28
  %13127 = add i64 %13071, 29
  store i64 %13127, i64* %3, align 8
  %13128 = inttoptr i64 %13126 to i32*
  %13129 = load i32, i32* %13128, align 4
  %13130 = sext i32 %13129 to i64
  store i64 %13130, i64* %RCX.i3977, align 8
  %13131 = shl nsw i64 %13130, 2
  %13132 = add i64 %13131, %13100
  %13133 = add i64 %13071, 32
  store i64 %13133, i64* %3, align 8
  %13134 = inttoptr i64 %13132 to i32*
  %13135 = load i32, i32* %13134, align 4
  %13136 = zext i32 %13135 to i64
  store i64 %13136, i64* %RDX.i4094, align 8
  %13137 = trunc i32 %13135 to i16
  store i16 %13137, i16* %SI.i62, align 2
  %13138 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %13138, i64* %RAX.i2610, align 8
  %13139 = add i64 %13138, 6424
  %13140 = add i64 %13071, 50
  store i64 %13140, i64* %3, align 8
  %13141 = inttoptr i64 %13139 to i64*
  %13142 = load i64, i64* %13141, align 8
  store i64 %13142, i64* %RAX.i2610, align 8
  %13143 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %13143, i64* %RCX.i3977, align 8
  %13144 = add i64 %13143, 156
  %13145 = add i64 %13071, 64
  store i64 %13145, i64* %3, align 8
  %13146 = inttoptr i64 %13144 to i32*
  %13147 = load i32, i32* %13146, align 4
  %13148 = zext i32 %13147 to i64
  store i64 %13148, i64* %RDX.i4094, align 8
  %13149 = load i64, i64* %RBP.i, align 8
  %13150 = add i64 %13149, -88
  %13151 = add i64 %13071, 67
  store i64 %13151, i64* %3, align 8
  %13152 = inttoptr i64 %13150 to i32*
  %13153 = load i32, i32* %13152, align 4
  %13154 = add i32 %13153, %13147
  %13155 = zext i32 %13154 to i64
  store i64 %13155, i64* %RDX.i4094, align 8
  %13156 = icmp ult i32 %13154, %13147
  %13157 = icmp ult i32 %13154, %13153
  %13158 = or i1 %13156, %13157
  %13159 = zext i1 %13158 to i8
  store i8 %13159, i8* %12, align 1
  %13160 = and i32 %13154, 255
  %13161 = tail call i32 @llvm.ctpop.i32(i32 %13160)
  %13162 = trunc i32 %13161 to i8
  %13163 = and i8 %13162, 1
  %13164 = xor i8 %13163, 1
  store i8 %13164, i8* %13, align 1
  %13165 = xor i32 %13153, %13147
  %13166 = xor i32 %13165, %13154
  %13167 = lshr i32 %13166, 4
  %13168 = trunc i32 %13167 to i8
  %13169 = and i8 %13168, 1
  store i8 %13169, i8* %14, align 1
  %13170 = icmp eq i32 %13154, 0
  %13171 = zext i1 %13170 to i8
  store i8 %13171, i8* %15, align 1
  %13172 = lshr i32 %13154, 31
  %13173 = trunc i32 %13172 to i8
  store i8 %13173, i8* %16, align 1
  %13174 = lshr i32 %13147, 31
  %13175 = lshr i32 %13153, 31
  %13176 = xor i32 %13172, %13174
  %13177 = xor i32 %13172, %13175
  %13178 = add nuw nsw i32 %13176, %13177
  %13179 = icmp eq i32 %13178, 2
  %13180 = zext i1 %13179 to i8
  store i8 %13180, i8* %17, align 1
  %13181 = add i64 %13149, -28
  %13182 = add i64 %13071, 70
  store i64 %13182, i64* %3, align 8
  %13183 = inttoptr i64 %13181 to i32*
  %13184 = load i32, i32* %13183, align 4
  %13185 = add i32 %13184, %13154
  %13186 = zext i32 %13185 to i64
  store i64 %13186, i64* %RDX.i4094, align 8
  %13187 = icmp ult i32 %13185, %13154
  %13188 = icmp ult i32 %13185, %13184
  %13189 = or i1 %13187, %13188
  %13190 = zext i1 %13189 to i8
  store i8 %13190, i8* %12, align 1
  %13191 = and i32 %13185, 255
  %13192 = tail call i32 @llvm.ctpop.i32(i32 %13191)
  %13193 = trunc i32 %13192 to i8
  %13194 = and i8 %13193, 1
  %13195 = xor i8 %13194, 1
  store i8 %13195, i8* %13, align 1
  %13196 = xor i32 %13184, %13154
  %13197 = xor i32 %13196, %13185
  %13198 = lshr i32 %13197, 4
  %13199 = trunc i32 %13198 to i8
  %13200 = and i8 %13199, 1
  store i8 %13200, i8* %14, align 1
  %13201 = icmp eq i32 %13185, 0
  %13202 = zext i1 %13201 to i8
  store i8 %13202, i8* %15, align 1
  %13203 = lshr i32 %13185, 31
  %13204 = trunc i32 %13203 to i8
  store i8 %13204, i8* %16, align 1
  %13205 = lshr i32 %13184, 31
  %13206 = xor i32 %13203, %13172
  %13207 = xor i32 %13203, %13205
  %13208 = add nuw nsw i32 %13206, %13207
  %13209 = icmp eq i32 %13208, 2
  %13210 = zext i1 %13209 to i8
  store i8 %13210, i8* %17, align 1
  %13211 = sext i32 %13185 to i64
  store i64 %13211, i64* %RCX.i3977, align 8
  %13212 = shl nsw i64 %13211, 3
  %13213 = add i64 %13142, %13212
  %13214 = add i64 %13071, 77
  store i64 %13214, i64* %3, align 8
  %13215 = inttoptr i64 %13213 to i64*
  %13216 = load i64, i64* %13215, align 8
  store i64 %13216, i64* %RAX.i2610, align 8
  %13217 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %13217, i64* %RCX.i3977, align 8
  %13218 = add i64 %13217, 152
  %13219 = add i64 %13071, 91
  store i64 %13219, i64* %3, align 8
  %13220 = inttoptr i64 %13218 to i32*
  %13221 = load i32, i32* %13220, align 4
  %13222 = zext i32 %13221 to i64
  store i64 %13222, i64* %RDX.i4094, align 8
  %13223 = load i64, i64* %RBP.i, align 8
  %13224 = add i64 %13223, -84
  %13225 = add i64 %13071, 94
  store i64 %13225, i64* %3, align 8
  %13226 = inttoptr i64 %13224 to i32*
  %13227 = load i32, i32* %13226, align 4
  %13228 = add i32 %13227, %13221
  %13229 = zext i32 %13228 to i64
  store i64 %13229, i64* %RDX.i4094, align 8
  %13230 = icmp ult i32 %13228, %13221
  %13231 = icmp ult i32 %13228, %13227
  %13232 = or i1 %13230, %13231
  %13233 = zext i1 %13232 to i8
  store i8 %13233, i8* %12, align 1
  %13234 = and i32 %13228, 255
  %13235 = tail call i32 @llvm.ctpop.i32(i32 %13234)
  %13236 = trunc i32 %13235 to i8
  %13237 = and i8 %13236, 1
  %13238 = xor i8 %13237, 1
  store i8 %13238, i8* %13, align 1
  %13239 = xor i32 %13227, %13221
  %13240 = xor i32 %13239, %13228
  %13241 = lshr i32 %13240, 4
  %13242 = trunc i32 %13241 to i8
  %13243 = and i8 %13242, 1
  store i8 %13243, i8* %14, align 1
  %13244 = icmp eq i32 %13228, 0
  %13245 = zext i1 %13244 to i8
  store i8 %13245, i8* %15, align 1
  %13246 = lshr i32 %13228, 31
  %13247 = trunc i32 %13246 to i8
  store i8 %13247, i8* %16, align 1
  %13248 = lshr i32 %13221, 31
  %13249 = lshr i32 %13227, 31
  %13250 = xor i32 %13246, %13248
  %13251 = xor i32 %13246, %13249
  %13252 = add nuw nsw i32 %13250, %13251
  %13253 = icmp eq i32 %13252, 2
  %13254 = zext i1 %13253 to i8
  store i8 %13254, i8* %17, align 1
  %13255 = add i64 %13223, -24
  %13256 = add i64 %13071, 97
  store i64 %13256, i64* %3, align 8
  %13257 = inttoptr i64 %13255 to i32*
  %13258 = load i32, i32* %13257, align 4
  %13259 = add i32 %13258, %13228
  %13260 = zext i32 %13259 to i64
  store i64 %13260, i64* %RDX.i4094, align 8
  %13261 = icmp ult i32 %13259, %13228
  %13262 = icmp ult i32 %13259, %13258
  %13263 = or i1 %13261, %13262
  %13264 = zext i1 %13263 to i8
  store i8 %13264, i8* %12, align 1
  %13265 = and i32 %13259, 255
  %13266 = tail call i32 @llvm.ctpop.i32(i32 %13265)
  %13267 = trunc i32 %13266 to i8
  %13268 = and i8 %13267, 1
  %13269 = xor i8 %13268, 1
  store i8 %13269, i8* %13, align 1
  %13270 = xor i32 %13258, %13228
  %13271 = xor i32 %13270, %13259
  %13272 = lshr i32 %13271, 4
  %13273 = trunc i32 %13272 to i8
  %13274 = and i8 %13273, 1
  store i8 %13274, i8* %14, align 1
  %13275 = icmp eq i32 %13259, 0
  %13276 = zext i1 %13275 to i8
  store i8 %13276, i8* %15, align 1
  %13277 = lshr i32 %13259, 31
  %13278 = trunc i32 %13277 to i8
  store i8 %13278, i8* %16, align 1
  %13279 = lshr i32 %13258, 31
  %13280 = xor i32 %13277, %13246
  %13281 = xor i32 %13277, %13279
  %13282 = add nuw nsw i32 %13280, %13281
  %13283 = icmp eq i32 %13282, 2
  %13284 = zext i1 %13283 to i8
  store i8 %13284, i8* %17, align 1
  %13285 = sext i32 %13259 to i64
  store i64 %13285, i64* %RCX.i3977, align 8
  %13286 = shl nsw i64 %13285, 1
  %13287 = add i64 %13216, %13286
  %13288 = load i16, i16* %SI.i62, align 2
  %13289 = add i64 %13071, 104
  store i64 %13289, i64* %3, align 8
  %13290 = inttoptr i64 %13287 to i16*
  store i16 %13288, i16* %13290, align 2
  %13291 = load i64, i64* %RBP.i, align 8
  %13292 = add i64 %13291, -24
  %13293 = load i64, i64* %3, align 8
  %13294 = add i64 %13293, 3
  store i64 %13294, i64* %3, align 8
  %13295 = inttoptr i64 %13292 to i32*
  %13296 = load i32, i32* %13295, align 4
  %13297 = add i32 %13296, 1
  %13298 = zext i32 %13297 to i64
  store i64 %13298, i64* %RAX.i2610, align 8
  %13299 = icmp eq i32 %13296, -1
  %13300 = icmp eq i32 %13297, 0
  %13301 = or i1 %13299, %13300
  %13302 = zext i1 %13301 to i8
  store i8 %13302, i8* %12, align 1
  %13303 = and i32 %13297, 255
  %13304 = tail call i32 @llvm.ctpop.i32(i32 %13303)
  %13305 = trunc i32 %13304 to i8
  %13306 = and i8 %13305, 1
  %13307 = xor i8 %13306, 1
  store i8 %13307, i8* %13, align 1
  %13308 = xor i32 %13297, %13296
  %13309 = lshr i32 %13308, 4
  %13310 = trunc i32 %13309 to i8
  %13311 = and i8 %13310, 1
  store i8 %13311, i8* %14, align 1
  %13312 = zext i1 %13300 to i8
  store i8 %13312, i8* %15, align 1
  %13313 = lshr i32 %13297, 31
  %13314 = trunc i32 %13313 to i8
  store i8 %13314, i8* %16, align 1
  %13315 = lshr i32 %13296, 31
  %13316 = xor i32 %13313, %13315
  %13317 = add nuw nsw i32 %13316, %13313
  %13318 = icmp eq i32 %13317, 2
  %13319 = zext i1 %13318 to i8
  store i8 %13319, i8* %17, align 1
  %13320 = add i64 %13293, 9
  store i64 %13320, i64* %3, align 8
  store i32 %13297, i32* %13295, align 4
  %13321 = load i64, i64* %3, align 8
  %13322 = add i64 %13321, -123
  store i64 %13322, i64* %3, align 8
  br label %block_.L_4ac308

block_.L_4ac388:                                  ; preds = %block_.L_4ac308
  %13323 = add i64 %13043, -28
  %13324 = add i64 %13071, 8
  store i64 %13324, i64* %3, align 8
  %13325 = inttoptr i64 %13323 to i32*
  %13326 = load i32, i32* %13325, align 4
  %13327 = add i32 %13326, 1
  %13328 = zext i32 %13327 to i64
  store i64 %13328, i64* %RAX.i2610, align 8
  %13329 = icmp eq i32 %13326, -1
  %13330 = icmp eq i32 %13327, 0
  %13331 = or i1 %13329, %13330
  %13332 = zext i1 %13331 to i8
  store i8 %13332, i8* %12, align 1
  %13333 = and i32 %13327, 255
  %13334 = tail call i32 @llvm.ctpop.i32(i32 %13333)
  %13335 = trunc i32 %13334 to i8
  %13336 = and i8 %13335, 1
  %13337 = xor i8 %13336, 1
  store i8 %13337, i8* %13, align 1
  %13338 = xor i32 %13327, %13326
  %13339 = lshr i32 %13338, 4
  %13340 = trunc i32 %13339 to i8
  %13341 = and i8 %13340, 1
  store i8 %13341, i8* %14, align 1
  %13342 = zext i1 %13330 to i8
  store i8 %13342, i8* %15, align 1
  %13343 = lshr i32 %13327, 31
  %13344 = trunc i32 %13343 to i8
  store i8 %13344, i8* %16, align 1
  %13345 = lshr i32 %13326, 31
  %13346 = xor i32 %13343, %13345
  %13347 = add nuw nsw i32 %13346, %13343
  %13348 = icmp eq i32 %13347, 2
  %13349 = zext i1 %13348 to i8
  store i8 %13349, i8* %17, align 1
  %13350 = add i64 %13071, 14
  store i64 %13350, i64* %3, align 8
  store i32 %13327, i32* %13325, align 4
  %13351 = load i64, i64* %3, align 8
  %13352 = add i64 %13351, -159
  store i64 %13352, i64* %3, align 8
  br label %block_.L_4ac2f7

block_.L_4ac39b:                                  ; preds = %block_.L_4ac2f7
  %13353 = add i64 %13038, 5
  store i64 %13353, i64* %3, align 8
  br label %block_.L_4ac3a0

block_.L_4ac3a0:                                  ; preds = %block_.L_4ac2db, %block_.L_4ac39b
  %13354 = phi i64 [ %13353, %block_.L_4ac39b ], [ %13005, %block_.L_4ac2db ]
  %13355 = phi i64 [ %13010, %block_.L_4ac39b ], [ %11461, %block_.L_4ac2db ]
  %13356 = add i64 %13355, -56
  %13357 = add i64 %13354, 3
  store i64 %13357, i64* %3, align 8
  %13358 = inttoptr i64 %13356 to i32*
  %13359 = load i32, i32* %13358, align 4
  %13360 = zext i32 %13359 to i64
  store i64 %13360, i64* %RAX.i2610, align 8
  %13361 = load i64, i64* %6, align 8
  %13362 = add i64 %13361, 752
  store i64 %13362, i64* %6, align 8
  %13363 = icmp ugt i64 %13361, -753
  %13364 = zext i1 %13363 to i8
  store i8 %13364, i8* %12, align 1
  %13365 = trunc i64 %13362 to i32
  %13366 = and i32 %13365, 255
  %13367 = tail call i32 @llvm.ctpop.i32(i32 %13366)
  %13368 = trunc i32 %13367 to i8
  %13369 = and i8 %13368, 1
  %13370 = xor i8 %13369, 1
  store i8 %13370, i8* %13, align 1
  %13371 = xor i64 %13361, 16
  %13372 = xor i64 %13371, %13362
  %13373 = lshr i64 %13372, 4
  %13374 = trunc i64 %13373 to i8
  %13375 = and i8 %13374, 1
  store i8 %13375, i8* %14, align 1
  %13376 = icmp eq i64 %13362, 0
  %13377 = zext i1 %13376 to i8
  store i8 %13377, i8* %15, align 1
  %13378 = lshr i64 %13362, 63
  %13379 = trunc i64 %13378 to i8
  store i8 %13379, i8* %16, align 1
  %13380 = lshr i64 %13361, 63
  %13381 = xor i64 %13378, %13380
  %13382 = add nuw nsw i64 %13381, %13378
  %13383 = icmp eq i64 %13382, 2
  %13384 = zext i1 %13383 to i8
  store i8 %13384, i8* %17, align 1
  %13385 = add i64 %13354, 11
  store i64 %13385, i64* %3, align 8
  %13386 = add i64 %13361, 760
  %13387 = inttoptr i64 %13362 to i64*
  %13388 = load i64, i64* %13387, align 8
  store i64 %13388, i64* %RBP.i, align 8
  store i64 %13386, i64* %6, align 8
  %13389 = add i64 %13354, 12
  store i64 %13389, i64* %3, align 8
  %13390 = inttoptr i64 %13386 to i64*
  %13391 = load i64, i64* %13390, align 8
  store i64 %13391, i64* %3, align 8
  %13392 = add i64 %13361, 768
  store i64 %13392, i64* %6, align 8
  ret %struct.Memory* %MEMORY.7
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_pushq__rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %3, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsp___rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RBP, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subq__0x2f0___rsp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, -752
  store i64 %6, i64* %RSP, align 8
  %7 = icmp ult i64 %3, 752
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %29
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__eax___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__al___cl(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %4 to i8*
  %5 = load i8, i8* %AL, align 1
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i8 %5, i8* %CL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 2, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -4
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsi__MINUS0x10__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %RSI, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x14__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -20
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x48__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x4c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -76
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x50__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -80
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2a4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -676
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cltd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %7 = bitcast %union.anon* %6 to i32*
  %8 = load i32, i32* %7, align 8
  %9 = sext i32 %8 to i64
  %10 = lshr i64 %9, 32
  store i64 %10, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2a4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -676
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__edi(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x3___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 3
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RDX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 29
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 28
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x54__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -84
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x3___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %.tr = trunc i64 %3 to i32
  %6 = shl i32 %.tr, 3
  %7 = zext i32 %6 to i64
  store i64 %7, i64* %RAX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %9 = lshr i64 %3, 29
  %10 = trunc i64 %9 to i8
  %11 = and i8 %10, 1
  store i8 %11, i8* %8, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = and i32 %6, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %12, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i32 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i32 %.tr, 28
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x58__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -88
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3738__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x4__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi__r8_8____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = bitcast i64* %RSI to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsi__MINUS0x60__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -96
  %5 = load i64, i64* %RSI, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsi__MINUS0x68__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -104
  %5 = load i64, i64* %RSI, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3758__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 14168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0xc__r8____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x278___r8___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 632
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %R8, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r8___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsi__MINUS0x198__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -408
  %5 = load i64, i64* %RSI, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x28__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x11bdc__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 72668
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %7, align 1
  %8 = and i32 %4, 255
  %9 = tail call i32 @llvm.ctpop.i32(i32 %8)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %14, align 1
  %15 = icmp eq i32 %4, 0
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %16, i8* %17, align 1
  %18 = lshr i32 %4, 31
  %19 = trunc i32 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %19, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %21, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__cl__MINUS0x2a5__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -677
  %6 = load i8, i8* %CL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4aa84a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__0x11c00__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72704
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -1
  %10 = icmp eq i32 %8, 0
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_sete__cl(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %7 = load i8, i8* %6, align 1
  store i8 %7, i8* %CL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb_MINUS0x2a5__rbp____al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -677
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  store i8 %9, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x6___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 6, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_andb__0x1___al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = load i8, i8* %AL, align 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = and i8 %4, 1
  store i8 %7, i8* %AL, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = zext i8 %7 to i32
  %10 = tail call i32 @llvm.ctpop.i32(i32 %9)
  %11 = trunc i32 %10 to i8
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = xor i8 %7, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %16, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzbl__al___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i8, i8* %AL, align 1
  %5 = zext i8 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x19c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -412
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x28__rsi____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x11bdc__rsi____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 72668
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__0x0___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = and i64 %3, 4294967295
  store i64 %7, i64* %RDX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = and i32 %6, 255
  %10 = tail call i32 @llvm.ctpop.i32(i32 %9)
  %11 = trunc i32 %10 to i8
  %12 = and i8 %11, 1
  %13 = xor i8 %12, 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %13, i8* %14, align 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %15, align 1
  %16 = icmp eq i32 %6, 0
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %17, i8* %18, align 1
  %19 = lshr i32 %6, 31
  %20 = trunc i32 %19 to i8
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %20, i8* %21, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %22, align 1
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__ecx(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %ECX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__0x0___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = and i64 %3, 4294967295
  store i64 %7, i64* %RAX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = and i32 %6, 255
  %10 = tail call i32 @llvm.ctpop.i32(i32 %9)
  %11 = trunc i32 %10 to i8
  %12 = and i8 %11, 1
  %13 = xor i8 %12, 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %13, i8* %14, align 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %15, align 1
  %16 = icmp eq i32 %6, 0
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %17, i8* %18, align 1
  %19 = lshr i32 %6, 31
  %20 = trunc i32 %19 to i8
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %20, i8* %21, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %22, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x40__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -64
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x3c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x10___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 16
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RCX, align 8
  %9 = icmp ugt i32 %6, -17
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %6, 16
  %19 = xor i32 %18, %7
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %7, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %7, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %6, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %27
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x44__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -68
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x6__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -6
  %10 = icmp ult i32 %8, 6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4aa8db(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 1, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x5___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x6___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 6, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x3c__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x4c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -76
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x3c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__cl___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i8, i8* %CL, align 1
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  %8 = trunc i8 %5 to i5
  switch i5 %8, label %15 [
    i5 0, label %_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit
    i5 1, label %9
  ]

; <label>:9:                                      ; preds = %block_400488
  %10 = trunc i64 %4 to i32
  %11 = shl i32 %10, 1
  %12 = icmp slt i32 %10, 0
  %13 = icmp slt i32 %11, 0
  %14 = xor i1 %12, %13
  br label %25

; <label>:15:                                     ; preds = %block_400488
  %16 = and i8 %5, 31
  %17 = zext i8 %16 to i64
  %18 = add nuw nsw i64 %17, 4294967295
  %19 = and i64 %4, 4294967295
  %20 = and i64 %18, 4294967295
  %21 = shl i64 %19, %20
  %22 = trunc i64 %21 to i32
  %23 = icmp slt i32 %22, 0
  %24 = shl i32 %22, 1
  br label %25

; <label>:25:                                     ; preds = %15, %9
  %26 = phi i1 [ %12, %9 ], [ %23, %15 ]
  %27 = phi i1 [ %14, %9 ], [ false, %15 ]
  %28 = phi i32 [ %11, %9 ], [ %24, %15 ]
  %29 = zext i32 %28 to i64
  store i64 %29, i64* %RAX, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %31 = zext i1 %26 to i8
  store i8 %31, i8* %30, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %33 = and i32 %28, 254
  %34 = tail call i32 @llvm.ctpop.i32(i32 %33)
  %35 = trunc i32 %34 to i8
  %36 = and i8 %35, 1
  %37 = xor i8 %36, 1
  store i8 %37, i8* %32, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %38, align 1
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %40 = icmp eq i32 %28, 0
  %41 = zext i1 %40 to i8
  store i8 %41, i8* %39, align 1
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %43 = lshr i32 %28, 31
  %44 = trunc i32 %43 to i8
  store i8 %44, i8* %42, align 1
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %46 = zext i1 %27 to i8
  store i8 %46, i8* %45, align 1
  br label %_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit

_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit: ; preds = %25, %block_400488
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x50__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -80
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4aa8e4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x3c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__0x6___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, -6
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp ult i32 %6, 6
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %29
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x48__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -72
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__0x18__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4aa92c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x3___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 3, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 1, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x44__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -68
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x2ac__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -684
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2ac__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -684
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__cl___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i8, i8* %CL, align 1
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  %8 = trunc i8 %5 to i5
  switch i5 %8, label %15 [
    i5 0, label %_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit
    i5 1, label %9
  ]

; <label>:9:                                      ; preds = %block_400488
  %10 = trunc i64 %4 to i32
  %11 = shl i32 %10, 1
  %12 = icmp slt i32 %10, 0
  %13 = icmp slt i32 %11, 0
  %14 = xor i1 %12, %13
  br label %25

; <label>:15:                                     ; preds = %block_400488
  %16 = and i8 %5, 31
  %17 = zext i8 %16 to i64
  %18 = add nuw nsw i64 %17, 4294967295
  %19 = and i64 %4, 4294967295
  %20 = and i64 %18, 4294967295
  %21 = shl i64 %19, %20
  %22 = trunc i64 %21 to i32
  %23 = icmp slt i32 %22, 0
  %24 = shl i32 %22, 1
  br label %25

; <label>:25:                                     ; preds = %15, %9
  %26 = phi i1 [ %12, %9 ], [ %23, %15 ]
  %27 = phi i1 [ %14, %9 ], [ false, %15 ]
  %28 = phi i32 [ %11, %9 ], [ %24, %15 ]
  %29 = zext i32 %28 to i64
  store i64 %29, i64* %RDX, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %31 = zext i1 %26 to i8
  store i8 %31, i8* %30, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %33 = and i32 %28, 254
  %34 = tail call i32 @llvm.ctpop.i32(i32 %33)
  %35 = trunc i32 %34 to i8
  %36 = and i8 %35, 1
  %37 = xor i8 %36, 1
  store i8 %37, i8* %32, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %38, align 1
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %40 = icmp eq i32 %28, 0
  %41 = zext i1 %40 to i8
  store i8 %41, i8* %39, align 1
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %43 = lshr i32 %28, 31
  %44 = trunc i32 %43 to i8
  store i8 %44, i8* %42, align 1
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %46 = zext i1 %27 to i8
  store i8 %46, i8* %45, align 1
  br label %_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit

_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit: ; preds = %25, %block_400488
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2b0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -688
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2b0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -688
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__esi(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x28__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -40
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4aa95d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x6___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 6, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x2b4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -692
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2b4__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -692
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2b8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -696
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2b8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -696
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x18__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x18__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__cl__MINUS0x2b9__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -697
  %6 = load i8, i8* %CL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4aa98a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x19c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -412
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_setne__al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %7 = load i8, i8* %6, align 1
  %8 = icmp eq i8 %7, 0
  %9 = zext i1 %8 to i8
  store i8 %9, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorb__0xff___al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = load i8, i8* %AL, align 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = xor i8 %4, -1
  store i8 %7, i8* %AL, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = zext i8 %7 to i32
  %10 = tail call i32 @llvm.ctpop.i32(i32 %9)
  %11 = trunc i32 %10 to i8
  %12 = and i8 %11, 1
  %13 = xor i8 %12, 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %13, i8* %14, align 1
  %15 = icmp eq i8 %4, -1
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %16, i8* %17, align 1
  %18 = lshr i8 %7, 7
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %18, i8* %19, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %21, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__al__MINUS0x2b9__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -697
  %6 = load i8, i8* %AL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb_MINUS0x2b9__rbp____al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -697
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  store i8 %9, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_testb__0x1___al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = load i8, i8* %AL, align 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = and i8 %4, 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = zext i8 %7 to i32
  %10 = tail call i32 @llvm.ctpop.i32(i32 %9)
  %11 = trunc i32 %10 to i8
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = xor i8 %7, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %16, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4aa99d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4aacb5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x18__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x3338__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13112
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x34f8__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13560
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i32 %13, %11
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %14, %11
  %17 = icmp ult i32 %14, %13
  %18 = or i1 %16, %17
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1
  %21 = and i32 %14, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21)
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1
  %27 = xor i32 %13, %11
  %28 = xor i32 %27, %14
  %29 = lshr i32 %28, 4
  %30 = trunc i32 %29 to i8
  %31 = and i8 %30, 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %31, i8* %32, align 1
  %33 = icmp eq i32 %14, 0
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %14, 31
  %37 = trunc i32 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %37, i8* %38, align 1
  %39 = lshr i32 %11, 31
  %40 = lshr i32 %13, 31
  %41 = xor i32 %36, %39
  %42 = xor i32 %36, %40
  %43 = add nuw nsw i32 %41, %42
  %44 = icmp eq i32 %43, 2
  %45 = zext i1 %44 to i8
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %45, i8* %46, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1c0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -448
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x3378__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13176
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x34b8__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13496
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i32 %13, %11
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %14, %11
  %17 = icmp ult i32 %14, %13
  %18 = or i1 %16, %17
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1
  %21 = and i32 %14, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21)
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1
  %27 = xor i32 %13, %11
  %28 = xor i32 %27, %14
  %29 = lshr i32 %28, 4
  %30 = trunc i32 %29 to i8
  %31 = and i8 %30, 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %31, i8* %32, align 1
  %33 = icmp eq i32 %14, 0
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %14, 31
  %37 = trunc i32 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %37, i8* %38, align 1
  %39 = lshr i32 %11, 31
  %40 = lshr i32 %13, 31
  %41 = xor i32 %36, %39
  %42 = xor i32 %36, %40
  %43 = add nuw nsw i32 %41, %42
  %44 = icmp eq i32 %43, 2
  %45 = zext i1 %44 to i8
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %45, i8* %46, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1bc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -444
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x33b8__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13240
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x3478__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13432
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i32 %13, %11
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %14, %11
  %17 = icmp ult i32 %14, %13
  %18 = or i1 %16, %17
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1
  %21 = and i32 %14, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21)
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1
  %27 = xor i32 %13, %11
  %28 = xor i32 %27, %14
  %29 = lshr i32 %28, 4
  %30 = trunc i32 %29 to i8
  %31 = and i8 %30, 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %31, i8* %32, align 1
  %33 = icmp eq i32 %14, 0
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %14, 31
  %37 = trunc i32 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %37, i8* %38, align 1
  %39 = lshr i32 %11, 31
  %40 = lshr i32 %13, 31
  %41 = xor i32 %36, %39
  %42 = xor i32 %36, %40
  %43 = add nuw nsw i32 %41, %42
  %44 = icmp eq i32 %43, 2
  %45 = zext i1 %44 to i8
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %45, i8* %46, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1b8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -440
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x33f8__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13304
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x3438__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13368
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i32 %13, %11
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %14, %11
  %17 = icmp ult i32 %14, %13
  %18 = or i1 %16, %17
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1
  %21 = and i32 %14, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21)
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1
  %27 = xor i32 %13, %11
  %28 = xor i32 %27, %14
  %29 = lshr i32 %28, 4
  %30 = trunc i32 %29 to i8
  %31 = and i8 %30, 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %31, i8* %32, align 1
  %33 = icmp eq i32 %14, 0
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %14, 31
  %37 = trunc i32 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %37, i8* %38, align 1
  %39 = lshr i32 %11, 31
  %40 = lshr i32 %13, 31
  %41 = xor i32 %36, %39
  %42 = xor i32 %36, %40
  %43 = add nuw nsw i32 %41, %42
  %44 = icmp eq i32 %43, 2
  %45 = zext i1 %44 to i8
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %45, i8* %46, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1b4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -436
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1c0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -448
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1b4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -436
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1e0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -480
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1bc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -444
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1b8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -440
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1dc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -476
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1b4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -436
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1d8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -472
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1b8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -440
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1d4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -468
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x34f8__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13560
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = sub i32 %11, %13
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %11, %13
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %14, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %13, %11
  %26 = xor i32 %25, %14
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %14, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %14, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %11, 31
  %38 = lshr i32 %13, 31
  %39 = xor i32 %38, %37
  %40 = xor i32 %34, %37
  %41 = add nuw nsw i32 %40, %39
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1b0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -432
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x34b8__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13496
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = sub i32 %11, %13
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %11, %13
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %14, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %13, %11
  %26 = xor i32 %25, %14
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %14, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %14, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %11, 31
  %38 = lshr i32 %13, 31
  %39 = xor i32 %38, %37
  %40 = xor i32 %34, %37
  %41 = add nuw nsw i32 %40, %39
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1ac__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -428
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x3478__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13432
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = sub i32 %11, %13
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %11, %13
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %14, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %13, %11
  %26 = xor i32 %25, %14
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %14, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %14, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %11, 31
  %38 = lshr i32 %13, 31
  %39 = xor i32 %38, %37
  %40 = xor i32 %34, %37
  %41 = add nuw nsw i32 %40, %39
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1a8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -424
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x3438__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13368
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = sub i32 %11, %13
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %11, %13
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %14, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %13, %11
  %26 = xor i32 %25, %14
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %14, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %14, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %11, 31
  %38 = lshr i32 %13, 31
  %39 = xor i32 %38, %37
  %40 = xor i32 %34, %37
  %41 = add nuw nsw i32 %40, %39
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1a4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -420
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ac__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -428
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1a8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -424
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1b0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -432
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x1___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 32
  %7 = ashr i64 %6, 33
  %8 = trunc i64 %3 to i8
  %9 = and i8 %8, 1
  %10 = trunc i64 %7 to i32
  %11 = and i64 %7, 4294967295
  store i64 %11, i64* %RDI, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %9, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %14 = and i32 %10, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  store i8 %18, i8* %13, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %19, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %21 = icmp eq i32 %10, 0
  %22 = zext i1 %21 to i8
  store i8 %22, i8* %20, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %24 = lshr i64 %7, 31
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  store i8 %26, i8* %23, align 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %27, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1b0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -432
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edi___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EDI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1d0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -464
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1b0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -432
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1a4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -420
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1a8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1a8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -424
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__edi___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EDI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1cc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -460
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1a4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -420
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ac__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -428
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1ac__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -428
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1c8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -456
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1a8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -424
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1a4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -420
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1a4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -420
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x1c4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -452
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -480
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1dc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -476
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x18__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x170__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -368
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ESI, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1d8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -472
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1d4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -468
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x130__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -304
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ESI, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1dc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -476
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0xf0__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -240
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ESI, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x1___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 32
  %7 = ashr i64 %6, 33
  %8 = trunc i64 %3 to i8
  %9 = and i8 %8, 1
  %10 = trunc i64 %7 to i32
  %11 = and i64 %7, 4294967295
  store i64 %11, i64* %RSI, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %9, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %14 = and i32 %10, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  store i8 %18, i8* %13, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %19, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %21 = icmp eq i32 %10, 0
  %22 = zext i1 %21 to i8
  store i8 %22, i8* %20, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %24 = lshr i64 %7, 31
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  store i8 %26, i8* %23, align 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %27, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1d4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -468
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0xb0__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -176
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ESI, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1d0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1c4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -452
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x2___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 32
  %7 = ashr i64 %6, 33
  %8 = lshr i64 %7, 1
  %9 = trunc i64 %7 to i8
  %10 = and i8 %9, 1
  %11 = trunc i64 %8 to i32
  %12 = and i64 %8, 4294967295
  store i64 %12, i64* %RDI, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %11, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i64 %7, 32
  %26 = trunc i64 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x150__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -336
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ESI, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1cc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -460
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1c8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -456
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x110__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -272
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ESI, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1c8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -456
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1cc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -460
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0xd0__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -208
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ESI, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1c4__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -452
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x2___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 32
  %7 = ashr i64 %6, 33
  %8 = lshr i64 %7, 1
  %9 = trunc i64 %7 to i8
  %10 = and i8 %9, 1
  %11 = trunc i64 %8 to i32
  %12 = and i64 %8, 4294967295
  store i64 %12, i64* %RSI, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %11, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i64 %7, 32
  %26 = trunc i64 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__esi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x90__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -144
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x18__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 1
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp eq i32 %6, -1
  %10 = icmp eq i32 %7, 0
  %11 = or i1 %9, %10
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1
  %14 = and i32 %7, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i32 %7, %6
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = zext i1 %10 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %7, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %6, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %27
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x18__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -24
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4aa964(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__cl__MINUS0x2ba__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -698
  %6 = load i8, i8* %CL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4aace2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__al__MINUS0x2ba__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -698
  %6 = load i8, i8* %AL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb_MINUS0x2ba__rbp____al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -698
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  store i8 %9, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4aacf5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab09a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_leaq_MINUS0x170__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -368
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  store i64 %4, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rcx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = bitcast i64* %RSI to i32**
  %4 = load i32*, i32** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = load i32, i32* %4, align 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x1c__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 28
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x200__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -512
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x4__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x18__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 24
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x1fc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -508
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x8__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x14__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 20
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x1f8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -504
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xc__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x10__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x1f4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -500
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x200__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -512
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1f4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -500
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x220__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -544
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1fc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -508
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1f8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -504
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x21c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -540
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1f4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -500
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x218__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -536
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1f8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -504
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x214__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -532
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x1c__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 28
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x1f0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -496
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x18__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 24
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x1ec__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -492
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x14__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 20
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x1e8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -488
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x10__rcx____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x1e4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -484
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ec__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -492
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -488
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f0__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -496
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x1___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = shl nuw i64 %6, 32
  %10 = ashr i64 %9, 33
  %11 = trunc i32 %5 to i8
  %12 = and i8 %11, 1
  %13 = trunc i64 %10 to i32
  %14 = and i64 %10, 4294967295
  store i64 %14, i64* %4, align 8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %17 = and i32 %13, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  store i8 %21, i8* %16, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %24 = icmp eq i32 %13, 0
  %25 = zext i1 %24 to i8
  store i8 %25, i8* %23, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %27 = lshr i64 %10, 31
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  store i8 %29, i8* %26, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %30, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1f0__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -496
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__r8d___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %R8D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x210__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -528
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1f0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -496
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1e4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -484
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e8__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -488
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e8__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -488
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__r8d___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %R8D, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x20c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -524
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e4__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -484
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1ec__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -492
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1ec__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -492
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x208__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -520
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x1e8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -488
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1e4__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -484
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1e4__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -484
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x204__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -516
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x220__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -544
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x21c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -540
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi____rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = bitcast i64* %RCX to i32**
  %5 = load i32*, i32** %4, align 8
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  store i32 %6, i32* %5, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x218__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -536
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x214__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -532
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__0x8__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 8
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x21c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -540
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__0x10__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 16
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x214__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -532
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__0x18__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 24
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x210__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -528
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x204__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -516
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x2___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = sext i32 %5 to i64
  %9 = ashr i64 %8, 1
  %10 = lshr i64 %9, 1
  %11 = trunc i64 %9 to i8
  %12 = and i8 %11, 1
  %13 = trunc i64 %10 to i32
  %14 = and i64 %10, 4294967295
  store i64 %14, i64* %4, align 8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %17 = and i32 %13, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  store i8 %21, i8* %16, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %24 = icmp eq i32 %13, 0
  %25 = zext i1 %24 to i8
  store i8 %25, i8* %23, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %27 = lshr i64 %9, 32
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  store i8 %29, i8* %26, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %30, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__0x4__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 4
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x20c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -524
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x208__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -520
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__0xc__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 12
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x208__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -520
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x20c__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -524
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__0x14__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 20
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x204__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -516
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__edi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i32, i32* %EDI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x1c__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 28
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4aacbc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff__MINUS0x34__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 -1, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff__MINUS0x184__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -388
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 -1, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff__MINUS0x188__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -392
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 -1, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff__MINUS0x18c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -396
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 -1, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff__MINUS0x190__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -400
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 -1, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x174__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -372
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x178__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -376
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x17c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -380
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x180__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -384
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x40__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -64
  %10 = icmp ult i32 %8, 64
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4ab6e0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11afc__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72444
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4ab14e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11ad0__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72400
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4ab171(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x198__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -408
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x214__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 532
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x24__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzbl_0x4ba3d0___rax_2____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 1
  %5 = add i64 %4, 4957136
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 2
  %10 = zext i8 %9 to i64
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x18__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -24
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzbl_0x4ba3d1___rax_2____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 1
  %5 = add i64 %4, 4957137
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i64
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x1c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -28
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab18f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzbl_0x4ba350___rax_2____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 1
  %5 = add i64 %4, 4957008
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 2
  %10 = zext i8 %9 to i64
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzbl_0x4ba351___rax_2____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 1
  %5 = add i64 %4, 4957009
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i64
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x34__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x34__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -52
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x20__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x24__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_andl__0x3___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = and i64 %3, 3
  %7 = trunc i64 %6 to i32
  store i64 %6, i64* %RAX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = tail call i32 @llvm.ctpop.i32(i32 %7)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = icmp eq i32 %7, 0
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %15, i8* %16, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %19, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x190__rbp__rcx_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, -400
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x190__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -400
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4ab1f3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rcx___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RAX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x1c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rcx_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.abs_plt(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab2ff(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__MINUS0x14__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -20
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -1
  %10 = icmp eq i32 %8, 0
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4ab27e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d33f0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 7156720, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d0bc0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d0bc0_type* @G__0x6d0bc0 to i64), i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x40__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -64
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x8___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 8
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 56
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 55
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x18__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x1c__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imull___rdx__rsi_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = shl i64 %3, 32
  %13 = ashr exact i64 %12, 32
  %14 = sext i32 %11 to i64
  %15 = mul nsw i64 %14, %13
  %16 = trunc i64 %15 to i32
  %17 = and i64 %15, 4294967295
  store i64 %17, i64* %RAX, align 8
  %18 = shl i64 %15, 32
  %19 = ashr exact i64 %18, 32
  %20 = icmp ne i64 %19, %15
  %21 = zext i1 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %21, i8* %22, align 1
  %23 = and i32 %16, 255
  %24 = tail call i32 @llvm.ctpop.i32(i32 %23)
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = xor i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %27, i8* %28, align 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %29, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %30, align 1
  %31 = lshr i32 %16, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %21, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x3c__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_shlq__0x8___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 8
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 56
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %14 = icmp eq i64 %6, 0
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %13, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = lshr i64 %3, 55
  %18 = trunc i64 %17 to i8
  %19 = and i8 %18, 1
  store i8 %19, i8* %16, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x1c__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl___rcx__rdx_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = trunc i64 %3 to i32
  %11 = inttoptr i64 %7 to i32*
  %12 = load i32, i32* %11, align 4
  %13 = add i32 %12, %10
  %14 = zext i32 %13 to i64
  store i64 %14, i64* %RAX, align 8
  %15 = icmp ult i32 %13, %10
  %16 = icmp ult i32 %13, %12
  %17 = or i1 %15, %16
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %18, i8* %19, align 1
  %20 = and i32 %13, 255
  %21 = tail call i32 @llvm.ctpop.i32(i32 %20)
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = xor i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %24, i8* %25, align 1
  %26 = xor i32 %12, %10
  %27 = xor i32 %26, %13
  %28 = lshr i32 %27, 4
  %29 = trunc i32 %28 to i8
  %30 = and i8 %29, 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %30, i8* %31, align 1
  %32 = icmp eq i32 %13, 0
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %13, 31
  %36 = trunc i32 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %36, i8* %37, align 1
  %38 = lshr i32 %10, 31
  %39 = lshr i32 %12, 31
  %40 = xor i32 %35, %38
  %41 = xor i32 %35, %39
  %42 = add nuw nsw i32 %40, %41
  %43 = icmp eq i32 %42, 2
  %44 = zext i1 %43 to i8
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %44, i8* %45, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x44__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -68
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__cl___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i8, i8* %CL, align 1
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  %8 = trunc i8 %5 to i5
  switch i5 %8, label %12 [
    i5 0, label %_ZN12_GLOBAL__N_1L3SARI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit
    i5 1, label %9
  ]

; <label>:9:                                      ; preds = %block_400488
  %10 = shl i64 %4, 32
  %11 = ashr i64 %10, 33
  br label %20

; <label>:12:                                     ; preds = %block_400488
  %13 = and i8 %5, 31
  %14 = zext i8 %13 to i64
  %15 = add nsw i64 %14, -1
  %16 = shl i64 %4, 32
  %17 = ashr exact i64 %16, 32
  %18 = ashr i64 %17, %15
  %19 = lshr i64 %18, 1
  br label %20

; <label>:20:                                     ; preds = %12, %9
  %21 = phi i64 [ %19, %12 ], [ %11, %9 ]
  %22 = phi i64 [ %18, %12 ], [ %4, %9 ]
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = trunc i64 %21 to i32
  %26 = and i64 %21, 4294967295
  store i64 %26, i64* %RAX, align 8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %24, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %29 = and i32 %25, 255
  %30 = tail call i32 @llvm.ctpop.i32(i32 %29)
  %31 = trunc i32 %30 to i8
  %32 = and i8 %31, 1
  %33 = xor i8 %32, 1
  store i8 %33, i8* %28, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %36 = icmp eq i32 %25, 0
  %37 = zext i1 %36 to i8
  store i8 %37, i8* %35, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %39 = lshr i32 %25, 31
  %40 = trunc i32 %39 to i8
  store i8 %40, i8* %38, align 1
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %41, align 1
  br label %_ZN12_GLOBAL__N_1L3SARI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit

_ZN12_GLOBAL__N_1L3SARI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit: ; preds = %20, %block_400488
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab2fa(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x720d90___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 7474576, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x70f6e0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x70f6e0_type* @G__0x70f6e0 to i64), i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4ab69c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 1, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x23c__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 572
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4ab475(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x934__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 2356
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4ab475(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -1
  %10 = icmp eq i32 %8, 0
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4ab356(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x10__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = bitcast i64* %RAX to i32**
  %4 = load i32*, i32** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = load i32, i32* %4, align 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0xf423f___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 999999
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RCX, align 8
  %9 = icmp ugt i32 %6, -1000000
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %6, 16
  %19 = xor i32 %18, %7
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %7, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %7, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %6, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %27
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx____rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = bitcast i64* %RAX to i32**
  %5 = load i32*, i32** %4, align 8
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  store i32 %6, i32* %5, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab393(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x4ba450___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x4ba450_type* @G__0x4ba450 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x9a4__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 2468
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x24__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_andl__0x3___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = and i64 %3, 3
  %7 = trunc i64 %6 to i32
  store i64 %6, i64* %RDX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = tail call i32 @llvm.ctpop.i32(i32 %7)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = icmp eq i32 %7, 0
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %15, i8* %16, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %19, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x190__rbp__rcx_4____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, -400
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 8
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzbl___rax__rcx_1____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, %3
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i64
  store i64 %10, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl___rax____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = bitcast i64* %RAX to i32**
  %5 = load i32*, i32** %4, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = load i32, i32* %5, align 4
  %10 = add i32 %9, %8
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  %12 = icmp ult i32 %10, %8
  %13 = icmp ult i32 %10, %9
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %9, %8
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %8, 31
  %36 = lshr i32 %9, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx____rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = bitcast i64* %RAX to i32**
  %5 = load i32*, i32** %4, align 8
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  store i32 %6, i32* %5, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rcx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.sign(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3738__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x4__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx__rdx_8____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x24__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -36
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_andl__0x3___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = and i64 %3, 3
  %7 = trunc i64 %6 to i32
  store i64 %6, i64* %RSI, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = tail call i32 @llvm.ctpop.i32(i32 %7)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = icmp eq i32 %7, 0
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %15, i8* %16, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %19, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = bitcast i64* %RCX to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x180__rbp__rdx_4____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, -384
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 8
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EAX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x180__rbp__rcx_4____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, -384
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x180__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -384
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0xffffffff__MINUS0x190__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, -400
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 11
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  store i32 -1, i32* %10, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab513(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4ab492(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab4c2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x34__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -52
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x60__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -96
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x68__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -104
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x30__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x30__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -48
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4ab556(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x20__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -32
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab697(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4ab5f9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jl_.L_4ab5b0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = zext i1 %10 to i8
  store i8 %11, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off1, i64 %rel_off2
  %12 = add i64 %.v, %3
  store i64 %12, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6cfc70___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6cfc70_type* @G__0x6cfc70 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x40__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -64
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RAX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imull___rax__rdx_4____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = shl i64 %3, 32
  %13 = ashr exact i64 %12, 32
  %14 = sext i32 %11 to i64
  %15 = mul nsw i64 %14, %13
  %16 = trunc i64 %15 to i32
  %17 = and i64 %15, 4294967295
  store i64 %17, i64* %RCX, align 8
  %18 = shl i64 %15, 32
  %19 = ashr exact i64 %18, 32
  %20 = icmp ne i64 %19, %15
  %21 = zext i1 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %21, i8* %22, align 1
  %23 = and i32 %16, 255
  %24 = tail call i32 @llvm.ctpop.i32(i32 %23)
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = xor i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %27, i8* %28, align 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %29, align 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %30, align 1
  %31 = lshr i32 %16, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %21, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x48__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x2c0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -704
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c0__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -704
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__cl___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i8, i8* %CL, align 1
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  %8 = trunc i8 %5 to i5
  switch i5 %8, label %15 [
    i5 0, label %_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit
    i5 1, label %9
  ]

; <label>:9:                                      ; preds = %block_400488
  %10 = trunc i64 %4 to i32
  %11 = shl i32 %10, 1
  %12 = icmp slt i32 %10, 0
  %13 = icmp slt i32 %11, 0
  %14 = xor i1 %12, %13
  br label %25

; <label>:15:                                     ; preds = %block_400488
  %16 = and i8 %5, 31
  %17 = zext i8 %16 to i64
  %18 = add nuw nsw i64 %17, 4294967295
  %19 = and i64 %4, 4294967295
  %20 = and i64 %18, 4294967295
  %21 = shl i64 %19, %20
  %22 = trunc i64 %21 to i32
  %23 = icmp slt i32 %22, 0
  %24 = shl i32 %22, 1
  br label %25

; <label>:25:                                     ; preds = %15, %9
  %26 = phi i1 [ %12, %9 ], [ %23, %15 ]
  %27 = phi i1 [ %14, %9 ], [ false, %15 ]
  %28 = phi i32 [ %11, %9 ], [ %24, %15 ]
  %29 = zext i32 %28 to i64
  store i64 %29, i64* %RSI, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %31 = zext i1 %26 to i8
  store i8 %31, i8* %30, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %33 = and i32 %28, 254
  %34 = tail call i32 @llvm.ctpop.i32(i32 %33)
  %35 = trunc i32 %34 to i8
  %36 = and i8 %35, 1
  %37 = xor i8 %36, 1
  store i8 %37, i8* %32, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %38, align 1
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %40 = icmp eq i32 %28, 0
  %41 = zext i1 %40 to i8
  store i8 %41, i8* %39, align 1
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %43 = lshr i32 %28, 31
  %44 = trunc i32 %43 to i8
  store i8 %44, i8* %42, align 1
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %46 = zext i1 %27 to i8
  store i8 %46, i8* %45, align 1
  br label %_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit

_ZN12_GLOBAL__N_1L3SHLI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit: ; preds = %25, %block_400488
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x20__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -32
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab5f4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x50__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -80
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x4c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -76
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x2c4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -708
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -708
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__cl___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i8, i8* %CL, align 1
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  %8 = trunc i8 %5 to i5
  switch i5 %8, label %12 [
    i5 0, label %_ZN12_GLOBAL__N_1L3SARI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit
    i5 1, label %9
  ]

; <label>:9:                                      ; preds = %block_400488
  %10 = shl i64 %4, 32
  %11 = ashr i64 %10, 33
  br label %20

; <label>:12:                                     ; preds = %block_400488
  %13 = and i8 %5, 31
  %14 = zext i8 %13 to i64
  %15 = add nsw i64 %14, -1
  %16 = shl i64 %4, 32
  %17 = ashr exact i64 %16, 32
  %18 = ashr i64 %17, %15
  %19 = lshr i64 %18, 1
  br label %20

; <label>:20:                                     ; preds = %12, %9
  %21 = phi i64 [ %19, %12 ], [ %11, %9 ]
  %22 = phi i64 [ %18, %12 ], [ %4, %9 ]
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = trunc i64 %21 to i32
  %26 = and i64 %21, 4294967295
  store i64 %26, i64* %RSI, align 8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %24, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %29 = and i32 %25, 255
  %30 = tail call i32 @llvm.ctpop.i32(i32 %29)
  %31 = trunc i32 %30 to i8
  %32 = and i8 %31, 1
  %33 = xor i8 %32, 1
  store i8 %33, i8* %28, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %36 = icmp eq i32 %25, 0
  %37 = zext i1 %36 to i8
  store i8 %37, i8* %35, align 1
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %39 = lshr i32 %25, 31
  %40 = trunc i32 %39 to i8
  store i8 %40, i8* %38, align 1
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %41, align 1
  br label %_ZN12_GLOBAL__N_1L3SARI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit

_ZN12_GLOBAL__N_1L3SARI3RnWImE2RnIjES4_EEP6MemoryS6_R5StateT_T0_T1_.exit: ; preds = %20, %block_400488
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab692(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jl_.L_4ab649(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = zext i1 %10 to i8
  store i8 %11, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off1, i64 %rel_off2
  %12 = add i64 %.v, %3
  store i64 %12, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d12c0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d12c0_type* @G__0x6d12c0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x2c8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -712
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c8__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -712
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab68d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x2cc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -716
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2cc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -716
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab69c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4ab6cd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x20__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab6d2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x24__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -36
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab106(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4ab709(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4ab71d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x60__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -96
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x30__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  store i32 0, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab776(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x18__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4ab771(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3738__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x4__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax__rcx_8____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = bitcast i64* %RAX to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x180__rbp__rcx_4____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, -384
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 8
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sext i32 %11 to i64
  store i64 %12, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab724(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__cl__MINUS0x2cd__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -717
  %6 = load i8, i8* %CL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4ab7a3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__al__MINUS0x2cd__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -717
  %6 = load i8, i8* %AL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb_MINUS0x2cd__rbp____al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -717
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  store i8 %9, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4ab7b6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4abb38(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x240__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -576
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x230__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -560
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x238__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -568
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x34b8__rcx__rdx_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13496
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x228__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -552
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x240__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -576
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x228__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -552
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x260__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -608
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x230__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -560
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x238__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -568
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x258__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -600
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x238__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -568
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x250__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -592
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x228__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -552
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x248__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -584
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x33f8__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13304
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = sub i32 %11, %13
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %11, %13
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %14, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %13, %11
  %26 = xor i32 %25, %14
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %14, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %14, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %11, 31
  %38 = lshr i32 %13, 31
  %39 = xor i32 %38, %37
  %40 = xor i32 %34, %37
  %41 = add nuw nsw i32 %40, %39
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x34f8__rcx__rdx_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13560
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x23c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -572
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x33f8__rcx__rdx_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13304
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x234__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -564
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x3378__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13176
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = sub i32 %11, %13
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %11, %13
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %14, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %13, %11
  %26 = xor i32 %25, %14
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %14, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %14, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %11, 31
  %38 = lshr i32 %13, 31
  %39 = xor i32 %38, %37
  %40 = xor i32 %34, %37
  %41 = add nuw nsw i32 %40, %39
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x3478__rcx__rdx_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13432
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x22c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -556
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x3378__rcx__rdx_4____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 13176
  %8 = add i64 %7, %6
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 7
  store i64 %10, i64* %PC, align 8
  %11 = trunc i64 %3 to i32
  %12 = inttoptr i64 %8 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i32 %13, %11
  %15 = zext i32 %14 to i64
  store i64 %15, i64* %RSI, align 8
  %16 = icmp ult i32 %14, %11
  %17 = icmp ult i32 %14, %13
  %18 = or i1 %16, %17
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1
  %21 = and i32 %14, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21)
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1
  %27 = xor i32 %13, %11
  %28 = xor i32 %27, %14
  %29 = lshr i32 %28, 4
  %30 = trunc i32 %29 to i8
  %31 = and i8 %30, 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %31, i8* %32, align 1
  %33 = icmp eq i32 %14, 0
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %14, 31
  %37 = trunc i32 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %37, i8* %38, align 1
  %39 = lshr i32 %11, 31
  %40 = lshr i32 %13, 31
  %41 = xor i32 %36, %39
  %42 = xor i32 %36, %40
  %43 = add nuw nsw i32 %41, %42
  %44 = icmp eq i32 %43, 2
  %45 = zext i1 %44 to i8
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %45, i8* %46, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x3378__rcx__rdx_4____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 13176
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x224__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -548
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x23c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -572
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x224__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -548
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x25c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__esi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x224__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -548
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x244__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -580
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x234__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -564
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x22c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -556
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x254__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -596
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x2___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 32
  %7 = ashr i64 %6, 33
  %8 = lshr i64 %7, 1
  %9 = trunc i64 %7 to i8
  %10 = and i8 %9, 1
  %11 = trunc i64 %8 to i32
  %12 = and i64 %8, 4294967295
  store i64 %12, i64* %RAX, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %11, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i64 %7, 32
  %26 = trunc i64 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x22c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -556
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x24c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -588
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x260__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -608
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x244__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -580
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x170__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -368
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x258__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -600
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x24c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -588
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x150__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -336
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x250__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -592
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x254__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -596
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x130__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -304
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x248__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -584
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x25c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x110__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -272
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x25c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -604
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xf0__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -240
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x254__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -596
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xd0__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -208
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x24c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -588
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xb0__rbp__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, -176
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EAX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x244__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -580
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ab77d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__cl__MINUS0x2ce__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -718
  %6 = load i8, i8* %CL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4abb65(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__al__MINUS0x2ce__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -718
  %6 = load i8, i8* %AL, align 1
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i8*
  store i8 %6, i8* %9, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb_MINUS0x2ce__rbp____al(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -718
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i8*
  %9 = load i8, i8* %8, align 1
  store i8 %9, i8* %AL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4abb78(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4abf6d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x280__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -640
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x10__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x270__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -624
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x278__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -632
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x18__rsi____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 24
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x268__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -616
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x280__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -640
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x268__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -616
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x2a0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -672
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x270__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -624
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x278__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -632
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x298__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -664
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x278__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -632
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x290__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -656
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x268__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -616
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x288__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -648
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0xc__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x1c__rsi____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 28
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x27c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -636
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xc__rsi____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x274__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -628
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_0x4__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x14__rsi____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 20
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x26c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -620
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_0x4__rsi____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x4__rcx____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x264__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x27c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -636
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x264__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi__MINUS0x29c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -668
  %6 = load i32, i32* %EDI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl__edi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i32, i32* %EDI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = sub i32 %9, %5
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = icmp ult i32 %9, %5
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %10, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i64 %6, %4
  %22 = trunc i64 %21 to i32
  %23 = xor i32 %22, %10
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %10, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %10, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %9, 31
  %35 = lshr i32 %5, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x264__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -612
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x284__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -644
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x274__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -628
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x26c__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -620
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x294__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -660
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x26c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -620
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x28c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -652
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2a0__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -672
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x284__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -644
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax____rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = bitcast i64* %RCX to i32**
  %5 = load i32*, i32** %4, align 8
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  store i32 %6, i32* %5, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x298__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -664
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x28c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -652
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x4__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 4
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x290__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -656
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x294__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -660
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x8__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 8
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x288__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -648
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x29c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -668
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0xc__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 12
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x29c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -668
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x10__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 16
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x294__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -660
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x14__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 20
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x28c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -652
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x18__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 24
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subl_MINUS0x284__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -644
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 6
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %8, %10
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %8, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %11, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %10, %8
  %23 = xor i32 %22, %11
  %24 = lshr i32 %23, 4
  %25 = trunc i32 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1
  %28 = icmp eq i32 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %11, 31
  %32 = trunc i32 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %8, 31
  %35 = lshr i32 %10, 31
  %36 = xor i32 %35, %34
  %37 = xor i32 %31, %34
  %38 = add nuw nsw i32 %37, %36
  %39 = icmp eq i32 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4abb3f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4ac2db(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x1c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x1c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4ac2c8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_4ac00e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rcx_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3138___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 12600
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -12601
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x18__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x54__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -84
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x58__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -88
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rcx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__esi___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i32, i32* %ESI, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac2b5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11c14__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72724
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4ac26a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x11bec__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 72684
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x18__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdi___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x1c__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq___rsi__rdi_4____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3138___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 12600
  store i64 %6, i64* %RDI, align 8
  %7 = icmp ugt i64 %3, -12601
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x54__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -84
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %R8, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r8___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x58__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -88
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rdi__r8_2____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 5
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x20___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 32
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -33
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarq__0x6___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = lshr i64 %3, 5
  %7 = trunc i64 %6 to i8
  %8 = and i8 %7, 1
  %9 = ashr i64 %3, 6
  store i64 %9, i64* %RSI, align 8
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %10, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %9 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %9, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %9, 63
  %24 = trunc i64 %23 to i8
  store i8 %24, i8* %22, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpq__rsi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sub i64 %3, %4
  %8 = icmp ult i64 %3, %4
  %9 = zext i1 %8 to i8
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %9, i8* %10, align 1
  %11 = trunc i64 %7 to i32
  %12 = and i32 %11, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i64 %4, %3
  %19 = xor i64 %18, %7
  %20 = lshr i64 %19, 4
  %21 = trunc i64 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i64 %7, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i64 %7, 63
  %28 = trunc i64 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i64 %3, 63
  %31 = lshr i64 %4, 63
  %32 = xor i64 %31, %30
  %33 = xor i64 %27, %30
  %34 = add nuw nsw i64 %33, %32
  %35 = icmp eq i64 %34, 2
  %36 = zext i1 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %36, i8* %37, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0x2d8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -728
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4ac0b6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rcx__MINUS0x2e0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -736
  %5 = load i64, i64* %RCX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac11b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq___rax__rcx_4____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sext i32 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3138___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 12600
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -12601
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x18__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x54__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -84
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x1c__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -28
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x58__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -88
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rcx__rsi_2____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x20___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 32
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -33
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarq__0x6___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = lshr i64 %3, 5
  %7 = trunc i64 %6 to i8
  %8 = and i8 %7, 1
  %9 = ashr i64 %3, 6
  store i64 %9, i64* %RAX, align 8
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %10, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %9 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %9, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %9, 63
  %24 = trunc i64 %23 to i8
  store i8 %24, i8* %22, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x2e0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -736
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x2e0__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -736
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x2d8__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -728
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpq__rax___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sub i64 %3, %4
  %8 = icmp ult i64 %3, %4
  %9 = zext i1 %8 to i8
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %9, i8* %10, align 1
  %11 = trunc i64 %7 to i32
  %12 = and i32 %11, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i64 %4, %3
  %19 = xor i64 %18, %7
  %20 = lshr i64 %19, 4
  %21 = trunc i64 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i64 %7, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i64 %7, 63
  %28 = trunc i64 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i64 %3, 63
  %31 = lshr i64 %4, 63
  %32 = xor i64 %31, %30
  %33 = xor i64 %27, %30
  %34 = add nuw nsw i64 %33, %32
  %35 = icmp eq i64 %34, 2
  %36 = zext i1 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %36, i8* %37, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4ac14d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x11bec__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72684
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x2e8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -744
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac23c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3338___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 13112
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -13113
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq___rdx__rsi_4____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x3138___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 12600
  store i64 %6, i64* %RSI, align 8
  %7 = icmp ugt i64 %3, -12601
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RDI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rsi__rdi_2____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x20___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 32
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -33
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarq__0x6___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = lshr i64 %3, 5
  %7 = trunc i64 %6 to i8
  %8 = and i8 %7, 1
  %9 = ashr i64 %3, 6
  store i64 %9, i64* %RDX, align 8
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %10, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %9 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %9, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %9, 63
  %24 = trunc i64 %23 to i8
  store i8 %24, i8* %22, align 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %25, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpq__rdx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sub i64 %3, %4
  %8 = icmp ult i64 %3, %4
  %9 = zext i1 %8 to i8
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %9, i8* %10, align 1
  %11 = trunc i64 %7 to i32
  %12 = and i32 %11, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i64 %4, %3
  %19 = xor i64 %18, %7
  %20 = lshr i64 %19, 4
  %21 = trunc i64 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i64 %7, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i64 %7, 63
  %28 = trunc i64 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i64 %3, 63
  %31 = lshr i64 %4, 63
  %32 = xor i64 %31, %30
  %33 = xor i64 %27, %30
  %34 = add nuw nsw i64 %33, %32
  %35 = icmp eq i64 %34, 2
  %36 = zext i1 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %36, i8* %37, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jle_.L_4ac1c9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i8, i8* %10, align 1
  %12 = icmp ne i8 %11, 0
  %13 = xor i1 %9, %12
  %14 = or i1 %6, %13
  %15 = zext i1 %14 to i8
  store i8 %15, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %14, i64 %rel_off1, i64 %rel_off2
  %16 = add i64 %.v, %3
  store i64 %16, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rcx__MINUS0x2f0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -752
  %5 = load i64, i64* %RCX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac22e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x2f0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -752
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x2f0__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -752
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x2e8__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -744
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx____rax__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %ECX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac2b0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x20___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 32
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RDX, align 8
  %9 = icmp ugt i32 %6, -33
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_sarl__0x6___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 32
  %7 = ashr i64 %6, 37
  %8 = lshr i64 %7, 1
  %9 = trunc i64 %7 to i8
  %10 = and i8 %9, 1
  %11 = trunc i64 %8 to i32
  %12 = and i64 %8, 4294967295
  store i64 %12, i64* %RDX, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %11, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i64 %7, 32
  %26 = trunc i64 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac2ba(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x1c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -28
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4abf85(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac2cd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4abf74(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_4ac3a0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4ac39b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_4ac388(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__dx___si(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %4 to i16*
  %5 = load i16, i16* %DX, align 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i16 %5, i16* %SI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1918__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x9c__rcx____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 156
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x1c__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -28
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x98__rcx____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 152
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x18__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -24
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__si____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %SI, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac308(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac38d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac2f7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_4ac3a0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x38__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x2f0___rsp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 752
  store i64 %6, i64* %RSP, align 8
  %7 = icmp ugt i64 %3, -753
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_popq__rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 8
  %8 = inttoptr i64 %6 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %RBP, align 8
  store i64 %7, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_retq(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = inttoptr i64 %6 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %PC, align 8
  %9 = add i64 %6, 8
  store i64 %9, i64* %5, align 8
  ret %struct.Memory* %2
}

attributes #0 = { nounwind readnone }
attributes #1 = { alwaysinline }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
