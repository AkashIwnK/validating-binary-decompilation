; ModuleID = 'mcsema/test.proposed.inline.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%__bss_start_type = type <{ [8 x i8] }>
%G_0x6cb8f8_type = type <{ [8 x i8] }>
%G_0x6cb900_type = type <{ [8 x i8] }>
%G_0x6cb918_type = type <{ [8 x i8] }>
%G_0x6cc5f0_type = type <{ [8 x i8] }>
%G_0x6cc600_type = type <{ [8 x i8] }>
%G_0x6d2080_type = type <{ [4 x i8] }>
%G_0x6d4518_type = type <{ [8 x i8] }>
%G_0x6d4688_type = type <{ [4 x i8] }>
%G_0x6f8f10_type = type <{ [8 x i8] }>
%G_0x70fcf0_type = type <{ [8 x i8] }>
%G_0x70fd50_type = type <{ [4 x i8] }>
%G_0x710a58_type = type <{ [4 x i8] }>
%G_0x723710_type = type <{ [4 x i8] }>
%G_0x7247a0_type = type <{ [4 x i8] }>
%G__0x6d1290_type = type <{ [8 x i8] }>
%G__0x6f9360_type = type <{ [8 x i8] }>
%G__0x7236a0_type = type <{ [8 x i8] }>
%G__0x7242b0_type = type <{ [8 x i8] }>
%G__0x725320_type = type <{ [8 x i8] }>
%G__0x726210_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.anon = type { i64 }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque

@__bss_start = local_unnamed_addr global %__bss_start_type zeroinitializer
@G_0x6cb8f8 = local_unnamed_addr global %G_0x6cb8f8_type zeroinitializer
@G_0x6cb900 = local_unnamed_addr global %G_0x6cb900_type zeroinitializer
@G_0x6cb918 = local_unnamed_addr global %G_0x6cb918_type zeroinitializer
@G_0x6cc5f0 = local_unnamed_addr global %G_0x6cc5f0_type zeroinitializer
@G_0x6cc600 = local_unnamed_addr global %G_0x6cc600_type zeroinitializer
@G_0x6d2080 = local_unnamed_addr global %G_0x6d2080_type zeroinitializer
@G_0x6d4518 = local_unnamed_addr global %G_0x6d4518_type zeroinitializer
@G_0x6d4688 = local_unnamed_addr global %G_0x6d4688_type zeroinitializer
@G_0x6f8f10 = local_unnamed_addr global %G_0x6f8f10_type zeroinitializer
@G_0x70fcf0 = local_unnamed_addr global %G_0x70fcf0_type zeroinitializer
@G_0x70fd50 = local_unnamed_addr global %G_0x70fd50_type zeroinitializer
@G_0x710a58 = local_unnamed_addr global %G_0x710a58_type zeroinitializer
@G_0x723710 = local_unnamed_addr global %G_0x723710_type zeroinitializer
@G_0x7247a0 = local_unnamed_addr global %G_0x7247a0_type zeroinitializer
@G__0x6d1290 = global %G__0x6d1290_type zeroinitializer
@G__0x6f9360 = global %G__0x6f9360_type zeroinitializer
@G__0x7236a0 = global %G__0x7236a0_type zeroinitializer
@G__0x7242b0 = global %G__0x7242b0_type zeroinitializer
@G__0x725320 = global %G__0x725320_type zeroinitializer
@G__0x726210 = global %G__0x726210_type zeroinitializer

declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

declare %struct.Memory* @sub_48aaa0.RestoreMV8x8(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_48bbd0.SetMotionVectorsMB(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: alwaysinline
define %struct.Memory* @set_stored_macroblock_parameters(%struct.State* noalias, i64, %struct.Memory* noalias) local_unnamed_addr #1 {
entry:
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP.i = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP.i, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %3, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  %10 = load i64, i64* %3, align 8
  store i64 %8, i64* %RBP.i, align 8
  %RBX.i772 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %11 = load i64, i64* %RBX.i772, align 8
  %12 = add i64 %10, 4
  store i64 %12, i64* %3, align 8
  %13 = add i64 %7, -16
  %14 = inttoptr i64 %13 to i64*
  store i64 %11, i64* %14, align 8
  %15 = load i64, i64* %3, align 8
  %16 = add i64 %7, -280
  store i64 %16, i64* %6, align 8
  %17 = icmp ult i64 %13, 264
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %18, i8* %19, align 1
  %20 = trunc i64 %16 to i32
  %21 = and i32 %20, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21)
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1
  %27 = xor i64 %13, %16
  %28 = lshr i64 %27, 4
  %29 = trunc i64 %28 to i8
  %30 = and i8 %29, 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %30, i8* %31, align 1
  %32 = icmp eq i64 %16, 0
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %33, i8* %34, align 1
  %35 = lshr i64 %16, 63
  %36 = trunc i64 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %36, i8* %37, align 1
  %38 = lshr i64 %13, 63
  %39 = xor i64 %35, %38
  %40 = add nuw nsw i64 %39, %38
  %41 = icmp eq i64 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %RAX.i893 = getelementptr inbounds %union.anon, %union.anon* %44, i64 0, i32 0
  %45 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %45, i64* %RAX.i893, align 8
  %46 = add i64 %45, 14168
  %47 = add i64 %15, 22
  store i64 %47, i64* %3, align 8
  %48 = inttoptr i64 %46 to i64*
  %49 = load i64, i64* %48, align 8
  store i64 %49, i64* %RAX.i893, align 8
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %RCX.i1197 = getelementptr inbounds %union.anon, %union.anon* %50, i64 0, i32 0
  store i64 %45, i64* %RCX.i1197, align 8
  %51 = add i64 %45, 12
  %52 = add i64 %15, 34
  store i64 %52, i64* %3, align 8
  %53 = inttoptr i64 %51 to i32*
  %54 = load i32, i32* %53, align 4
  %55 = sext i32 %54 to i64
  %56 = mul nsw i64 %55, 632
  store i64 %56, i64* %RCX.i1197, align 8
  %57 = lshr i64 %56, 63
  %58 = add i64 %56, %49
  %59 = icmp ult i64 %58, %49
  %60 = icmp ult i64 %58, %56
  %61 = or i1 %59, %60
  %62 = zext i1 %61 to i8
  store i8 %62, i8* %19, align 1
  %63 = trunc i64 %58 to i32
  %64 = and i32 %63, 255
  %65 = tail call i32 @llvm.ctpop.i32(i32 %64)
  %66 = trunc i32 %65 to i8
  %67 = and i8 %66, 1
  %68 = xor i8 %67, 1
  store i8 %68, i8* %26, align 1
  %69 = xor i64 %56, %49
  %70 = xor i64 %69, %58
  %71 = lshr i64 %70, 4
  %72 = trunc i64 %71 to i8
  %73 = and i8 %72, 1
  store i8 %73, i8* %31, align 1
  %74 = icmp eq i64 %58, 0
  %75 = zext i1 %74 to i8
  store i8 %75, i8* %34, align 1
  %76 = lshr i64 %58, 63
  %77 = trunc i64 %76 to i8
  store i8 %77, i8* %37, align 1
  %78 = lshr i64 %49, 63
  %79 = xor i64 %76, %78
  %80 = xor i64 %76, %57
  %81 = add nuw nsw i64 %79, %80
  %82 = icmp eq i64 %81, 2
  %83 = zext i1 %82 to i8
  store i8 %83, i8* %43, align 1
  %84 = load i64, i64* %RBP.i, align 8
  %85 = add i64 %84, -56
  %86 = add i64 %15, 48
  store i64 %86, i64* %3, align 8
  %87 = inttoptr i64 %85 to i64*
  store i64 %58, i64* %87, align 8
  %88 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %RDX.i1708 = getelementptr inbounds %union.anon, %union.anon* %88, i64 0, i32 0
  %89 = load i64, i64* %3, align 8
  %90 = load i32, i32* bitcast (%G_0x7247a0_type* @G_0x7247a0 to i32*), align 8
  %91 = zext i32 %90 to i64
  store i64 %91, i64* %RDX.i1708, align 8
  %EDX.i1723 = bitcast %union.anon* %88 to i32*
  %92 = load i64, i64* %RBP.i, align 8
  %93 = add i64 %92, -60
  %94 = add i64 %89, 10
  store i64 %94, i64* %3, align 8
  %95 = inttoptr i64 %93 to i32*
  store i32 %90, i32* %95, align 4
  %96 = load i64, i64* %3, align 8
  %97 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %97, i64* %RAX.i893, align 8
  %98 = add i64 %97, 24
  %99 = add i64 %96, 12
  store i64 %99, i64* %3, align 8
  %100 = inttoptr i64 %98 to i32*
  %101 = load i32, i32* %100, align 4
  %102 = icmp eq i32 %101, 1
  %103 = zext i1 %102 to i8
  %104 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SIL.i = bitcast %union.anon* %104 to i8*
  store i8 %103, i8* %SIL.i, align 1
  store i8 0, i8* %19, align 1
  %105 = zext i1 %102 to i32
  %106 = tail call i32 @llvm.ctpop.i32(i32 %105)
  %107 = trunc i32 %106 to i8
  %108 = xor i8 %107, 1
  store i8 %108, i8* %26, align 1
  %109 = xor i8 %103, 1
  store i8 %109, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  store i8 0, i8* %31, align 1
  %110 = zext i1 %102 to i64
  store i64 %110, i64* %RDX.i1708, align 8
  %111 = load i64, i64* %RBP.i, align 8
  %112 = add i64 %111, -64
  %113 = zext i1 %102 to i32
  %114 = add i64 %96, 27
  store i64 %114, i64* %3, align 8
  %115 = inttoptr i64 %112 to i32*
  store i32 %113, i32* %115, align 4
  %116 = load i64, i64* %3, align 8
  %117 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %117, i64* %RAX.i893, align 8
  %118 = add i64 %117, 104
  %119 = add i64 %116, 12
  store i64 %119, i64* %3, align 8
  %120 = inttoptr i64 %118 to i64*
  %121 = load i64, i64* %120, align 8
  %122 = load i64, i64* %RBP.i, align 8
  %123 = add i64 %122, -72
  %124 = add i64 %116, 16
  store i64 %124, i64* %3, align 8
  %125 = inttoptr i64 %123 to i64*
  store i64 %121, i64* %125, align 8
  %126 = load i64, i64* %3, align 8
  %127 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %127, i64* %RAX.i893, align 8
  %128 = add i64 %127, 6424
  %129 = add i64 %126, 15
  store i64 %129, i64* %3, align 8
  %130 = inttoptr i64 %128 to i64*
  %131 = load i64, i64* %130, align 8
  %132 = load i64, i64* %RBP.i, align 8
  %133 = add i64 %132, -80
  %134 = add i64 %126, 19
  store i64 %134, i64* %3, align 8
  %135 = inttoptr i64 %133 to i64*
  store i64 %131, i64* %135, align 8
  %136 = load i64, i64* %3, align 8
  %137 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %137, i64* %RAX.i893, align 8
  %138 = add i64 %137, 6464
  %139 = add i64 %136, 15
  store i64 %139, i64* %3, align 8
  %140 = inttoptr i64 %138 to i64*
  %141 = load i64, i64* %140, align 8
  %142 = load i64, i64* %RBP.i, align 8
  %143 = add i64 %142, -88
  %144 = add i64 %136, 19
  store i64 %144, i64* %3, align 8
  %145 = inttoptr i64 %143 to i64*
  store i64 %141, i64* %145, align 8
  %146 = load i64, i64* %3, align 8
  %147 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %147, i64* %RAX.i893, align 8
  %148 = add i64 %147, 72400
  %149 = add i64 %146, 15
  store i64 %149, i64* %3, align 8
  %150 = inttoptr i64 %148 to i32*
  %151 = load i32, i32* %150, align 4
  store i8 0, i8* %19, align 1
  %152 = and i32 %151, 255
  %153 = tail call i32 @llvm.ctpop.i32(i32 %152)
  %154 = trunc i32 %153 to i8
  %155 = and i8 %154, 1
  %156 = xor i8 %155, 1
  store i8 %156, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %157 = icmp eq i32 %151, 0
  %158 = zext i1 %157 to i8
  store i8 %158, i8* %34, align 1
  %159 = lshr i32 %151, 31
  %160 = trunc i32 %159 to i8
  store i8 %160, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v303 = select i1 %157, i64 84, i64 21
  %161 = add i64 %146, %.v303
  store i64 %161, i64* %3, align 8
  %.pre178 = load i64, i64* %RBP.i, align 8
  br i1 %157, label %block_.L_48dc64, label %block_48dc25

block_48dc25:                                     ; preds = %entry
  %162 = add i64 %.pre178, -56
  %163 = add i64 %161, 4
  store i64 %163, i64* %3, align 8
  %164 = inttoptr i64 %162 to i64*
  %165 = load i64, i64* %164, align 8
  store i64 %165, i64* %RAX.i893, align 8
  %166 = add i64 %165, 532
  %167 = add i64 %161, 11
  store i64 %167, i64* %3, align 8
  %168 = inttoptr i64 %166 to i32*
  %169 = load i32, i32* %168, align 4
  store i8 0, i8* %19, align 1
  %170 = and i32 %169, 255
  %171 = tail call i32 @llvm.ctpop.i32(i32 %170)
  %172 = trunc i32 %171 to i8
  %173 = and i8 %172, 1
  %174 = xor i8 %173, 1
  store i8 %174, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %175 = icmp eq i32 %169, 0
  %176 = zext i1 %175 to i8
  store i8 %176, i8* %34, align 1
  %177 = lshr i32 %169, 31
  %178 = trunc i32 %177 to i8
  store i8 %178, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v304 = select i1 %175, i64 63, i64 17
  %179 = add i64 %161, %.v304
  store i64 %179, i64* %3, align 8
  br i1 %175, label %block_.L_48dc64, label %block_48dc36

block_48dc36:                                     ; preds = %block_48dc25
  store i64 2, i64* %RAX.i893, align 8
  store i64 4, i64* %RCX.i1197, align 8
  store i64 %147, i64* %RDX.i1708, align 8
  %RSI.i4093 = getelementptr inbounds %union.anon, %union.anon* %104, i64 0, i32 0
  %180 = add i64 %147, 12
  %181 = add i64 %179, 21
  store i64 %181, i64* %3, align 8
  %182 = inttoptr i64 %180 to i32*
  %183 = load i32, i32* %182, align 4
  %184 = zext i32 %183 to i64
  store i64 %184, i64* %RSI.i4093, align 8
  %185 = add i64 %.pre178, -116
  %186 = add i64 %179, 24
  store i64 %186, i64* %3, align 8
  %187 = inttoptr i64 %185 to i32*
  store i32 2, i32* %187, align 4
  %ESI.i4086 = bitcast %union.anon* %104 to i32*
  %188 = load i32, i32* %ESI.i4086, align 4
  %189 = zext i32 %188 to i64
  %190 = load i64, i64* %3, align 8
  store i64 %189, i64* %RAX.i893, align 8
  %191 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %192 = sext i32 %188 to i64
  %193 = lshr i64 %192, 32
  store i64 %193, i64* %191, align 8
  %194 = load i64, i64* %RBP.i, align 8
  %195 = add i64 %194, -116
  %196 = add i64 %190, 6
  store i64 %196, i64* %3, align 8
  %197 = inttoptr i64 %195 to i32*
  %198 = load i32, i32* %197, align 4
  %199 = zext i32 %198 to i64
  store i64 %199, i64* %RSI.i4093, align 8
  %200 = add i64 %190, 8
  store i64 %200, i64* %3, align 8
  %201 = sext i32 %198 to i64
  %202 = shl nuw i64 %193, 32
  %203 = or i64 %202, %189
  %204 = sdiv i64 %203, %201
  %205 = shl i64 %204, 32
  %206 = ashr exact i64 %205, 32
  %207 = icmp eq i64 %204, %206
  br i1 %207, label %210, label %208

; <label>:208:                                    ; preds = %block_48dc36
  %209 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %200, %struct.Memory* %2)
  %.pre = load i32, i32* %EDX.i1723, align 4
  %.pre175 = load i64, i64* %3, align 8
  %.pre176 = load i64, i64* %RSI.i4093, align 8
  %.pre177 = load i64, i64* %RBP.i, align 8
  br label %routine_idivl__esi.exit4077

; <label>:210:                                    ; preds = %block_48dc36
  %211 = srem i64 %203, %201
  %212 = and i64 %204, 4294967295
  store i64 %212, i64* %RAX.i893, align 8
  %213 = and i64 %211, 4294967295
  store i64 %213, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %214 = trunc i64 %211 to i32
  br label %routine_idivl__esi.exit4077

routine_idivl__esi.exit4077:                      ; preds = %210, %208
  %215 = phi i64 [ %.pre177, %208 ], [ %194, %210 ]
  %216 = phi i64 [ %.pre176, %208 ], [ %199, %210 ]
  %217 = phi i64 [ %.pre175, %208 ], [ %200, %210 ]
  %218 = phi i32 [ %.pre, %208 ], [ %214, %210 ]
  %219 = phi %struct.Memory* [ %209, %208 ], [ %2, %210 ]
  store i8 0, i8* %19, align 1
  %220 = and i32 %218, 255
  %221 = tail call i32 @llvm.ctpop.i32(i32 %220)
  %222 = trunc i32 %221 to i8
  %223 = and i8 %222, 1
  %224 = xor i8 %223, 1
  store i8 %224, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %225 = icmp eq i32 %218, 0
  %226 = zext i1 %225 to i8
  store i8 %226, i8* %34, align 1
  %227 = lshr i32 %218, 31
  %228 = trunc i32 %227 to i8
  store i8 %228, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %ECX.i4071 = bitcast %union.anon* %50 to i32*
  %229 = load i32, i32* %ECX.i4071, align 4
  %230 = zext i32 %229 to i64
  %231 = select i1 %225, i64 %216, i64 %230
  %232 = and i64 %231, 4294967295
  store i64 %232, i64* %RSI.i4093, align 8
  %233 = add i64 %215, -120
  %234 = trunc i64 %231 to i32
  %235 = add i64 %217, 9
  store i64 %235, i64* %3, align 8
  %236 = inttoptr i64 %233 to i32*
  store i32 %234, i32* %236, align 4
  %237 = load i64, i64* %3, align 8
  %238 = add i64 %237, 15
  br label %block_.L_48dc6e

block_.L_48dc64:                                  ; preds = %entry, %block_48dc25
  %239 = phi i64 [ %179, %block_48dc25 ], [ %161, %entry ]
  store i64 0, i64* %RAX.i893, align 8
  store i8 0, i8* %19, align 1
  store i8 1, i8* %26, align 1
  store i8 1, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  store i8 0, i8* %31, align 1
  %240 = add i64 %.pre178, -120
  %241 = add i64 %239, 5
  store i64 %241, i64* %3, align 8
  %242 = inttoptr i64 %240 to i32*
  store i32 0, i32* %242, align 4
  %243 = load i64, i64* %3, align 8
  %244 = add i64 %243, 5
  store i64 %244, i64* %3, align 8
  %.pre289 = getelementptr inbounds %union.anon, %union.anon* %104, i64 0, i32 0
  %.pre290 = bitcast %union.anon* %104 to i32*
  br label %block_.L_48dc6e

block_.L_48dc6e:                                  ; preds = %block_.L_48dc64, %routine_idivl__esi.exit4077
  %ESI.i4013.pre-phi = phi i32* [ %.pre290, %block_.L_48dc64 ], [ %ESI.i4086, %routine_idivl__esi.exit4077 ]
  %RSI.i4020.pre-phi = phi i64* [ %.pre289, %block_.L_48dc64 ], [ %RSI.i4093, %routine_idivl__esi.exit4077 ]
  %storemerge = phi i64 [ %244, %block_.L_48dc64 ], [ %238, %routine_idivl__esi.exit4077 ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_.L_48dc64 ], [ %219, %routine_idivl__esi.exit4077 ]
  %EAX.i4054.pre-phi = bitcast %union.anon* %44 to i32*
  %245 = load i64, i64* %RBP.i, align 8
  %246 = add i64 %245, -120
  %247 = add i64 %storemerge, 3
  store i64 %247, i64* %3, align 8
  %248 = inttoptr i64 %246 to i32*
  %249 = load i32, i32* %248, align 4
  %250 = zext i32 %249 to i64
  store i64 %250, i64* %RAX.i893, align 8
  %251 = add i64 %245, -92
  %252 = add i64 %storemerge, 6
  store i64 %252, i64* %3, align 8
  %253 = inttoptr i64 %251 to i32*
  store i32 %249, i32* %253, align 4
  %254 = load i64, i64* %RBP.i, align 8
  %255 = add i64 %254, -16
  %256 = load i64, i64* %3, align 8
  %257 = add i64 %256, 7
  store i64 %257, i64* %3, align 8
  %258 = inttoptr i64 %255 to i32*
  store i32 0, i32* %258, align 4
  %DX.i4027 = bitcast %union.anon* %88 to i16*
  %.pre179 = load i64, i64* %3, align 8
  br label %block_.L_48dc7b

block_.L_48dc7b:                                  ; preds = %block_.L_48dd4a, %block_.L_48dc6e
  %259 = phi i64 [ %639, %block_.L_48dd4a ], [ %.pre179, %block_.L_48dc6e ]
  %260 = load i64, i64* %RBP.i, align 8
  %261 = add i64 %260, -16
  %262 = add i64 %259, 4
  store i64 %262, i64* %3, align 8
  %263 = inttoptr i64 %261 to i32*
  %264 = load i32, i32* %263, align 4
  %265 = add i32 %264, -16
  %266 = icmp ult i32 %264, 16
  %267 = zext i1 %266 to i8
  store i8 %267, i8* %19, align 1
  %268 = and i32 %265, 255
  %269 = tail call i32 @llvm.ctpop.i32(i32 %268)
  %270 = trunc i32 %269 to i8
  %271 = and i8 %270, 1
  %272 = xor i8 %271, 1
  store i8 %272, i8* %26, align 1
  %273 = xor i32 %264, 16
  %274 = xor i32 %273, %265
  %275 = lshr i32 %274, 4
  %276 = trunc i32 %275 to i8
  %277 = and i8 %276, 1
  store i8 %277, i8* %31, align 1
  %278 = icmp eq i32 %265, 0
  %279 = zext i1 %278 to i8
  store i8 %279, i8* %34, align 1
  %280 = lshr i32 %265, 31
  %281 = trunc i32 %280 to i8
  store i8 %281, i8* %37, align 1
  %282 = lshr i32 %264, 31
  %283 = xor i32 %280, %282
  %284 = add nuw nsw i32 %283, %282
  %285 = icmp eq i32 %284, 2
  %286 = zext i1 %285 to i8
  store i8 %286, i8* %43, align 1
  %287 = icmp ne i8 %281, 0
  %288 = xor i1 %287, %285
  %.v305 = select i1 %288, i64 10, i64 226
  %289 = add i64 %259, %.v305
  store i64 %289, i64* %3, align 8
  br i1 %288, label %block_48dc85, label %block_.L_48dd5d

block_48dc85:                                     ; preds = %block_.L_48dc7b
  %290 = add i64 %260, -12
  %291 = add i64 %289, 7
  store i64 %291, i64* %3, align 8
  %292 = inttoptr i64 %290 to i32*
  store i32 0, i32* %292, align 4
  %.pre287 = load i64, i64* %3, align 8
  br label %block_.L_48dc8c

block_.L_48dc8c:                                  ; preds = %block_.L_48dd37, %block_48dc85
  %293 = phi i64 [ %609, %block_.L_48dd37 ], [ %.pre287, %block_48dc85 ]
  %294 = load i64, i64* %RBP.i, align 8
  %295 = add i64 %294, -12
  %296 = add i64 %293, 4
  store i64 %296, i64* %3, align 8
  %297 = inttoptr i64 %295 to i32*
  %298 = load i32, i32* %297, align 4
  %299 = add i32 %298, -16
  %300 = icmp ult i32 %298, 16
  %301 = zext i1 %300 to i8
  store i8 %301, i8* %19, align 1
  %302 = and i32 %299, 255
  %303 = tail call i32 @llvm.ctpop.i32(i32 %302)
  %304 = trunc i32 %303 to i8
  %305 = and i8 %304, 1
  %306 = xor i8 %305, 1
  store i8 %306, i8* %26, align 1
  %307 = xor i32 %298, 16
  %308 = xor i32 %307, %299
  %309 = lshr i32 %308, 4
  %310 = trunc i32 %309 to i8
  %311 = and i8 %310, 1
  store i8 %311, i8* %31, align 1
  %312 = icmp eq i32 %299, 0
  %313 = zext i1 %312 to i8
  store i8 %313, i8* %34, align 1
  %314 = lshr i32 %299, 31
  %315 = trunc i32 %314 to i8
  store i8 %315, i8* %37, align 1
  %316 = lshr i32 %298, 31
  %317 = xor i32 %314, %316
  %318 = add nuw nsw i32 %317, %316
  %319 = icmp eq i32 %318, 2
  %320 = zext i1 %319 to i8
  store i8 %320, i8* %43, align 1
  %321 = icmp ne i8 %315, 0
  %322 = xor i1 %321, %319
  %.v302 = select i1 %322, i64 10, i64 190
  %323 = add i64 %293, %.v302
  store i64 %323, i64* %3, align 8
  br i1 %322, label %block_48dc96, label %block_.L_48dd4a

block_48dc96:                                     ; preds = %block_.L_48dc8c
  store i64 ptrtoint (%G__0x725320_type* @G__0x725320 to i64), i64* %RAX.i893, align 8
  %324 = add i64 %294, -16
  %325 = add i64 %323, 14
  store i64 %325, i64* %3, align 8
  %326 = inttoptr i64 %324 to i32*
  %327 = load i32, i32* %326, align 4
  %328 = sext i32 %327 to i64
  %329 = shl nsw i64 %328, 5
  store i64 %329, i64* %RCX.i1197, align 8
  %330 = add i64 %329, ptrtoint (%G__0x725320_type* @G__0x725320 to i64)
  store i64 %330, i64* %RAX.i893, align 8
  %331 = icmp ult i64 %330, ptrtoint (%G__0x725320_type* @G__0x725320 to i64)
  %332 = icmp ult i64 %330, %329
  %333 = or i1 %331, %332
  %334 = zext i1 %333 to i8
  store i8 %334, i8* %19, align 1
  %335 = trunc i64 %330 to i32
  %336 = and i32 %335, 248
  %337 = tail call i32 @llvm.ctpop.i32(i32 %336)
  %338 = trunc i32 %337 to i8
  %339 = and i8 %338, 1
  %340 = xor i8 %339, 1
  store i8 %340, i8* %26, align 1
  %341 = xor i64 %330, ptrtoint (%G__0x725320_type* @G__0x725320 to i64)
  %342 = lshr i64 %341, 4
  %343 = trunc i64 %342 to i8
  %344 = and i8 %343, 1
  store i8 %344, i8* %31, align 1
  %345 = icmp eq i64 %330, 0
  %346 = zext i1 %345 to i8
  store i8 %346, i8* %34, align 1
  %347 = lshr i64 %330, 63
  %348 = trunc i64 %347 to i8
  store i8 %348, i8* %37, align 1
  %349 = lshr i64 %328, 58
  %350 = and i64 %349, 1
  %351 = xor i64 %347, lshr (i64 ptrtoint (%G__0x725320_type* @G__0x725320 to i64), i64 63)
  %352 = xor i64 %347, %350
  %353 = add nuw nsw i64 %351, %352
  %354 = icmp eq i64 %353, 2
  %355 = zext i1 %354 to i8
  store i8 %355, i8* %43, align 1
  %356 = add i64 %323, 25
  store i64 %356, i64* %3, align 8
  %357 = load i32, i32* %297, align 4
  %358 = sext i32 %357 to i64
  store i64 %358, i64* %RCX.i1197, align 8
  %359 = shl nsw i64 %358, 1
  %360 = add i64 %359, %330
  %361 = add i64 %323, 29
  store i64 %361, i64* %3, align 8
  %362 = inttoptr i64 %360 to i16*
  %363 = load i16, i16* %362, align 2
  store i16 %363, i16* %DX.i4027, align 2
  %364 = add i64 %294, -80
  %365 = add i64 %323, 33
  store i64 %365, i64* %3, align 8
  %366 = inttoptr i64 %364 to i64*
  %367 = load i64, i64* %366, align 8
  store i64 %367, i64* %RAX.i893, align 8
  %368 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %368, i64* %RCX.i1197, align 8
  %369 = add i64 %368, 156
  %370 = add i64 %323, 47
  store i64 %370, i64* %3, align 8
  %371 = inttoptr i64 %369 to i32*
  %372 = load i32, i32* %371, align 4
  %373 = zext i32 %372 to i64
  store i64 %373, i64* %RSI.i4020.pre-phi, align 8
  %374 = add i64 %323, 50
  store i64 %374, i64* %3, align 8
  %375 = load i32, i32* %326, align 4
  %376 = add i32 %375, %372
  %377 = zext i32 %376 to i64
  store i64 %377, i64* %RSI.i4020.pre-phi, align 8
  %378 = icmp ult i32 %376, %372
  %379 = icmp ult i32 %376, %375
  %380 = or i1 %378, %379
  %381 = zext i1 %380 to i8
  store i8 %381, i8* %19, align 1
  %382 = and i32 %376, 255
  %383 = tail call i32 @llvm.ctpop.i32(i32 %382)
  %384 = trunc i32 %383 to i8
  %385 = and i8 %384, 1
  %386 = xor i8 %385, 1
  store i8 %386, i8* %26, align 1
  %387 = xor i32 %375, %372
  %388 = xor i32 %387, %376
  %389 = lshr i32 %388, 4
  %390 = trunc i32 %389 to i8
  %391 = and i8 %390, 1
  store i8 %391, i8* %31, align 1
  %392 = icmp eq i32 %376, 0
  %393 = zext i1 %392 to i8
  store i8 %393, i8* %34, align 1
  %394 = lshr i32 %376, 31
  %395 = trunc i32 %394 to i8
  store i8 %395, i8* %37, align 1
  %396 = lshr i32 %372, 31
  %397 = lshr i32 %375, 31
  %398 = xor i32 %394, %396
  %399 = xor i32 %394, %397
  %400 = add nuw nsw i32 %398, %399
  %401 = icmp eq i32 %400, 2
  %402 = zext i1 %401 to i8
  store i8 %402, i8* %43, align 1
  %403 = sext i32 %376 to i64
  store i64 %403, i64* %RCX.i1197, align 8
  %404 = shl nsw i64 %403, 3
  %405 = add i64 %367, %404
  %406 = add i64 %323, 57
  store i64 %406, i64* %3, align 8
  %407 = inttoptr i64 %405 to i64*
  %408 = load i64, i64* %407, align 8
  store i64 %408, i64* %RAX.i893, align 8
  store i64 %368, i64* %RCX.i1197, align 8
  %409 = add i64 %368, 152
  %410 = add i64 %323, 71
  store i64 %410, i64* %3, align 8
  %411 = inttoptr i64 %409 to i32*
  %412 = load i32, i32* %411, align 4
  %413 = zext i32 %412 to i64
  store i64 %413, i64* %RSI.i4020.pre-phi, align 8
  %414 = load i64, i64* %RBP.i, align 8
  %415 = add i64 %414, -12
  %416 = add i64 %323, 74
  store i64 %416, i64* %3, align 8
  %417 = inttoptr i64 %415 to i32*
  %418 = load i32, i32* %417, align 4
  %419 = add i32 %418, %412
  %420 = zext i32 %419 to i64
  store i64 %420, i64* %RSI.i4020.pre-phi, align 8
  %421 = icmp ult i32 %419, %412
  %422 = icmp ult i32 %419, %418
  %423 = or i1 %421, %422
  %424 = zext i1 %423 to i8
  store i8 %424, i8* %19, align 1
  %425 = and i32 %419, 255
  %426 = tail call i32 @llvm.ctpop.i32(i32 %425)
  %427 = trunc i32 %426 to i8
  %428 = and i8 %427, 1
  %429 = xor i8 %428, 1
  store i8 %429, i8* %26, align 1
  %430 = xor i32 %418, %412
  %431 = xor i32 %430, %419
  %432 = lshr i32 %431, 4
  %433 = trunc i32 %432 to i8
  %434 = and i8 %433, 1
  store i8 %434, i8* %31, align 1
  %435 = icmp eq i32 %419, 0
  %436 = zext i1 %435 to i8
  store i8 %436, i8* %34, align 1
  %437 = lshr i32 %419, 31
  %438 = trunc i32 %437 to i8
  store i8 %438, i8* %37, align 1
  %439 = lshr i32 %412, 31
  %440 = lshr i32 %418, 31
  %441 = xor i32 %437, %439
  %442 = xor i32 %437, %440
  %443 = add nuw nsw i32 %441, %442
  %444 = icmp eq i32 %443, 2
  %445 = zext i1 %444 to i8
  store i8 %445, i8* %43, align 1
  %446 = sext i32 %419 to i64
  store i64 %446, i64* %RCX.i1197, align 8
  %447 = shl nsw i64 %446, 1
  %448 = add i64 %408, %447
  %449 = load i16, i16* %DX.i4027, align 2
  %450 = add i64 %323, 81
  store i64 %450, i64* %3, align 8
  %451 = inttoptr i64 %448 to i16*
  store i16 %449, i16* %451, align 2
  %452 = load i64, i64* %3, align 8
  %453 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %453, i64* %RAX.i893, align 8
  %454 = add i64 %453, 72400
  %455 = add i64 %452, 15
  store i64 %455, i64* %3, align 8
  %456 = inttoptr i64 %454 to i32*
  %457 = load i32, i32* %456, align 4
  store i8 0, i8* %19, align 1
  %458 = and i32 %457, 255
  %459 = tail call i32 @llvm.ctpop.i32(i32 %458)
  %460 = trunc i32 %459 to i8
  %461 = and i8 %460, 1
  %462 = xor i8 %461, 1
  store i8 %462, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %463 = icmp eq i32 %457, 0
  %464 = zext i1 %463 to i8
  store i8 %464, i8* %34, align 1
  %465 = lshr i32 %457, 31
  %466 = trunc i32 %465 to i8
  store i8 %466, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v365 = select i1 %463, i64 80, i64 21
  %467 = add i64 %452, %.v365
  store i64 %467, i64* %3, align 8
  br i1 %463, label %block_.L_48dd37, label %block_48dcfc

block_48dcfc:                                     ; preds = %block_48dc96
  store i64 ptrtoint (%G__0x725320_type* @G__0x725320 to i64), i64* %RAX.i893, align 8
  %468 = load i64, i64* %RBP.i, align 8
  %469 = add i64 %468, -16
  %470 = add i64 %467, 14
  store i64 %470, i64* %3, align 8
  %471 = inttoptr i64 %469 to i32*
  %472 = load i32, i32* %471, align 4
  %473 = sext i32 %472 to i64
  %474 = shl nsw i64 %473, 5
  store i64 %474, i64* %RCX.i1197, align 8
  %475 = add i64 %474, ptrtoint (%G__0x725320_type* @G__0x725320 to i64)
  store i64 %475, i64* %RAX.i893, align 8
  %476 = icmp ult i64 %475, ptrtoint (%G__0x725320_type* @G__0x725320 to i64)
  %477 = icmp ult i64 %475, %474
  %478 = or i1 %476, %477
  %479 = zext i1 %478 to i8
  store i8 %479, i8* %19, align 1
  %480 = trunc i64 %475 to i32
  %481 = and i32 %480, 248
  %482 = tail call i32 @llvm.ctpop.i32(i32 %481)
  %483 = trunc i32 %482 to i8
  %484 = and i8 %483, 1
  %485 = xor i8 %484, 1
  store i8 %485, i8* %26, align 1
  %486 = xor i64 %475, ptrtoint (%G__0x725320_type* @G__0x725320 to i64)
  %487 = lshr i64 %486, 4
  %488 = trunc i64 %487 to i8
  %489 = and i8 %488, 1
  store i8 %489, i8* %31, align 1
  %490 = icmp eq i64 %475, 0
  %491 = zext i1 %490 to i8
  store i8 %491, i8* %34, align 1
  %492 = lshr i64 %475, 63
  %493 = trunc i64 %492 to i8
  store i8 %493, i8* %37, align 1
  %494 = lshr i64 %473, 58
  %495 = and i64 %494, 1
  %496 = xor i64 %492, lshr (i64 ptrtoint (%G__0x725320_type* @G__0x725320 to i64), i64 63)
  %497 = xor i64 %492, %495
  %498 = add nuw nsw i64 %496, %497
  %499 = icmp eq i64 %498, 2
  %500 = zext i1 %499 to i8
  store i8 %500, i8* %43, align 1
  %501 = add i64 %468, -12
  %502 = add i64 %467, 25
  store i64 %502, i64* %3, align 8
  %503 = inttoptr i64 %501 to i32*
  %504 = load i32, i32* %503, align 4
  %505 = sext i32 %504 to i64
  store i64 %505, i64* %RCX.i1197, align 8
  %506 = shl nsw i64 %505, 1
  %507 = add i64 %506, %475
  %508 = add i64 %467, 29
  store i64 %508, i64* %3, align 8
  %509 = inttoptr i64 %507 to i16*
  %510 = load i16, i16* %509, align 2
  %511 = zext i16 %510 to i64
  store i64 %511, i64* %RDX.i1708, align 8
  %512 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %513 = add i64 %512, 8
  store i64 %513, i64* %RAX.i893, align 8
  %514 = icmp ugt i64 %512, -9
  %515 = zext i1 %514 to i8
  store i8 %515, i8* %19, align 1
  %516 = trunc i64 %513 to i32
  %517 = and i32 %516, 255
  %518 = tail call i32 @llvm.ctpop.i32(i32 %517)
  %519 = trunc i32 %518 to i8
  %520 = and i8 %519, 1
  %521 = xor i8 %520, 1
  store i8 %521, i8* %26, align 1
  %522 = xor i64 %513, %512
  %523 = lshr i64 %522, 4
  %524 = trunc i64 %523 to i8
  %525 = and i8 %524, 1
  store i8 %525, i8* %31, align 1
  %526 = icmp eq i64 %513, 0
  %527 = zext i1 %526 to i8
  store i8 %527, i8* %34, align 1
  %528 = lshr i64 %513, 63
  %529 = trunc i64 %528 to i8
  store i8 %529, i8* %37, align 1
  %530 = lshr i64 %512, 63
  %531 = xor i64 %528, %530
  %532 = add nuw nsw i64 %531, %528
  %533 = icmp eq i64 %532, 2
  %534 = zext i1 %533 to i8
  store i8 %534, i8* %43, align 1
  %535 = load i64, i64* %RBP.i, align 8
  %536 = add i64 %535, -16
  %537 = add i64 %467, 45
  store i64 %537, i64* %3, align 8
  %538 = inttoptr i64 %536 to i32*
  %539 = load i32, i32* %538, align 4
  %540 = sext i32 %539 to i64
  %541 = shl nsw i64 %540, 6
  store i64 %541, i64* %RCX.i1197, align 8
  %542 = add i64 %541, %513
  store i64 %542, i64* %RAX.i893, align 8
  %543 = icmp ult i64 %542, %513
  %544 = icmp ult i64 %542, %541
  %545 = or i1 %543, %544
  %546 = zext i1 %545 to i8
  store i8 %546, i8* %19, align 1
  %547 = trunc i64 %542 to i32
  %548 = and i32 %547, 255
  %549 = tail call i32 @llvm.ctpop.i32(i32 %548)
  %550 = trunc i32 %549 to i8
  %551 = and i8 %550, 1
  %552 = xor i8 %551, 1
  store i8 %552, i8* %26, align 1
  %553 = xor i64 %513, %542
  %554 = lshr i64 %553, 4
  %555 = trunc i64 %554 to i8
  %556 = and i8 %555, 1
  store i8 %556, i8* %31, align 1
  %557 = icmp eq i64 %542, 0
  %558 = zext i1 %557 to i8
  store i8 %558, i8* %34, align 1
  %559 = lshr i64 %542, 63
  %560 = trunc i64 %559 to i8
  store i8 %560, i8* %37, align 1
  %561 = lshr i64 %540, 57
  %562 = and i64 %561, 1
  %563 = xor i64 %559, %528
  %564 = xor i64 %559, %562
  %565 = add nuw nsw i64 %563, %564
  %566 = icmp eq i64 %565, 2
  %567 = zext i1 %566 to i8
  store i8 %567, i8* %43, align 1
  %568 = add i64 %535, -12
  %569 = add i64 %467, 56
  store i64 %569, i64* %3, align 8
  %570 = inttoptr i64 %568 to i32*
  %571 = load i32, i32* %570, align 4
  %572 = sext i32 %571 to i64
  store i64 %572, i64* %RCX.i1197, align 8
  %573 = shl nsw i64 %572, 2
  %574 = add i64 %573, %542
  %575 = load i32, i32* %EDX.i1723, align 4
  %576 = add i64 %467, 59
  store i64 %576, i64* %3, align 8
  %577 = inttoptr i64 %574 to i32*
  store i32 %575, i32* %577, align 4
  %.pre288 = load i64, i64* %3, align 8
  br label %block_.L_48dd37

block_.L_48dd37:                                  ; preds = %block_48dcfc, %block_48dc96
  %578 = phi i64 [ %.pre288, %block_48dcfc ], [ %467, %block_48dc96 ]
  %579 = load i64, i64* %RBP.i, align 8
  %580 = add i64 %579, -12
  %581 = add i64 %578, 8
  store i64 %581, i64* %3, align 8
  %582 = inttoptr i64 %580 to i32*
  %583 = load i32, i32* %582, align 4
  %584 = add i32 %583, 1
  %585 = zext i32 %584 to i64
  store i64 %585, i64* %RAX.i893, align 8
  %586 = icmp eq i32 %583, -1
  %587 = icmp eq i32 %584, 0
  %588 = or i1 %586, %587
  %589 = zext i1 %588 to i8
  store i8 %589, i8* %19, align 1
  %590 = and i32 %584, 255
  %591 = tail call i32 @llvm.ctpop.i32(i32 %590)
  %592 = trunc i32 %591 to i8
  %593 = and i8 %592, 1
  %594 = xor i8 %593, 1
  store i8 %594, i8* %26, align 1
  %595 = xor i32 %584, %583
  %596 = lshr i32 %595, 4
  %597 = trunc i32 %596 to i8
  %598 = and i8 %597, 1
  store i8 %598, i8* %31, align 1
  %599 = zext i1 %587 to i8
  store i8 %599, i8* %34, align 1
  %600 = lshr i32 %584, 31
  %601 = trunc i32 %600 to i8
  store i8 %601, i8* %37, align 1
  %602 = lshr i32 %583, 31
  %603 = xor i32 %600, %602
  %604 = add nuw nsw i32 %603, %600
  %605 = icmp eq i32 %604, 2
  %606 = zext i1 %605 to i8
  store i8 %606, i8* %43, align 1
  %607 = add i64 %578, 14
  store i64 %607, i64* %3, align 8
  store i32 %584, i32* %582, align 4
  %608 = load i64, i64* %3, align 8
  %609 = add i64 %608, -185
  store i64 %609, i64* %3, align 8
  br label %block_.L_48dc8c

block_.L_48dd4a:                                  ; preds = %block_.L_48dc8c
  %610 = add i64 %294, -16
  %611 = add i64 %323, 8
  store i64 %611, i64* %3, align 8
  %612 = inttoptr i64 %610 to i32*
  %613 = load i32, i32* %612, align 4
  %614 = add i32 %613, 1
  %615 = zext i32 %614 to i64
  store i64 %615, i64* %RAX.i893, align 8
  %616 = icmp eq i32 %613, -1
  %617 = icmp eq i32 %614, 0
  %618 = or i1 %616, %617
  %619 = zext i1 %618 to i8
  store i8 %619, i8* %19, align 1
  %620 = and i32 %614, 255
  %621 = tail call i32 @llvm.ctpop.i32(i32 %620)
  %622 = trunc i32 %621 to i8
  %623 = and i8 %622, 1
  %624 = xor i8 %623, 1
  store i8 %624, i8* %26, align 1
  %625 = xor i32 %614, %613
  %626 = lshr i32 %625, 4
  %627 = trunc i32 %626 to i8
  %628 = and i8 %627, 1
  store i8 %628, i8* %31, align 1
  %629 = zext i1 %617 to i8
  store i8 %629, i8* %34, align 1
  %630 = lshr i32 %614, 31
  %631 = trunc i32 %630 to i8
  store i8 %631, i8* %37, align 1
  %632 = lshr i32 %613, 31
  %633 = xor i32 %630, %632
  %634 = add nuw nsw i32 %633, %630
  %635 = icmp eq i32 %634, 2
  %636 = zext i1 %635 to i8
  store i8 %636, i8* %43, align 1
  %637 = add i64 %323, 14
  store i64 %637, i64* %3, align 8
  store i32 %614, i32* %612, align 4
  %638 = load i64, i64* %3, align 8
  %639 = add i64 %638, -221
  store i64 %639, i64* %3, align 8
  br label %block_.L_48dc7b

block_.L_48dd5d:                                  ; preds = %block_.L_48dc7b
  %640 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %640, i64* %RAX.i893, align 8
  %641 = add i64 %640, 72700
  %642 = add i64 %289, 15
  store i64 %642, i64* %3, align 8
  %643 = inttoptr i64 %641 to i32*
  %644 = load i32, i32* %643, align 4
  store i8 0, i8* %19, align 1
  %645 = and i32 %644, 255
  %646 = tail call i32 @llvm.ctpop.i32(i32 %645)
  %647 = trunc i32 %646 to i8
  %648 = and i8 %647, 1
  %649 = xor i8 %648, 1
  store i8 %649, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %650 = icmp eq i32 %644, 0
  %651 = zext i1 %650 to i8
  store i8 %651, i8* %34, align 1
  %652 = lshr i32 %644, 31
  %653 = trunc i32 %652 to i8
  store i8 %653, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v306 = select i1 %650, i64 437, i64 21
  %654 = add i64 %289, %.v306
  store i64 %654, i64* %3, align 8
  br i1 %650, label %block_.L_48df12, label %block_48dd72

block_48dd72:                                     ; preds = %block_.L_48dd5d
  %655 = add i64 %654, 7
  store i64 %655, i64* %3, align 8
  store i32 0, i32* %263, align 4
  %SI.i3888 = bitcast %union.anon* %104 to i16*
  %RDI.i3879 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %.pre180 = load i64, i64* %3, align 8
  br label %block_.L_48dd79

block_.L_48dd79:                                  ; preds = %block_.L_48defa, %block_48dd72
  %656 = phi i64 [ %1310, %block_.L_48defa ], [ %.pre180, %block_48dd72 ]
  %657 = load i64, i64* %RBP.i, align 8
  %658 = add i64 %657, -16
  %659 = add i64 %656, 3
  store i64 %659, i64* %3, align 8
  %660 = inttoptr i64 %658 to i32*
  %661 = load i32, i32* %660, align 4
  %662 = zext i32 %661 to i64
  store i64 %662, i64* %RAX.i893, align 8
  %663 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %663, i64* %RCX.i1197, align 8
  %664 = add i64 %663, 72712
  %665 = add i64 %656, 17
  store i64 %665, i64* %3, align 8
  %666 = inttoptr i64 %664 to i32*
  %667 = load i32, i32* %666, align 4
  %668 = sub i32 %661, %667
  %669 = icmp ult i32 %661, %667
  %670 = zext i1 %669 to i8
  store i8 %670, i8* %19, align 1
  %671 = and i32 %668, 255
  %672 = tail call i32 @llvm.ctpop.i32(i32 %671)
  %673 = trunc i32 %672 to i8
  %674 = and i8 %673, 1
  %675 = xor i8 %674, 1
  store i8 %675, i8* %26, align 1
  %676 = xor i32 %667, %661
  %677 = xor i32 %676, %668
  %678 = lshr i32 %677, 4
  %679 = trunc i32 %678 to i8
  %680 = and i8 %679, 1
  store i8 %680, i8* %31, align 1
  %681 = icmp eq i32 %668, 0
  %682 = zext i1 %681 to i8
  store i8 %682, i8* %34, align 1
  %683 = lshr i32 %668, 31
  %684 = trunc i32 %683 to i8
  store i8 %684, i8* %37, align 1
  %685 = lshr i32 %661, 31
  %686 = lshr i32 %667, 31
  %687 = xor i32 %686, %685
  %688 = xor i32 %683, %685
  %689 = add nuw nsw i32 %688, %687
  %690 = icmp eq i32 %689, 2
  %691 = zext i1 %690 to i8
  store i8 %691, i8* %43, align 1
  %692 = icmp ne i8 %684, 0
  %693 = xor i1 %692, %690
  %.v307 = select i1 %693, i64 23, i64 404
  %694 = add i64 %656, %.v307
  store i64 %694, i64* %3, align 8
  br i1 %693, label %block_48dd90, label %block_.L_48df0d

block_48dd90:                                     ; preds = %block_.L_48dd79
  %695 = add i64 %657, -12
  %696 = add i64 %694, 7
  store i64 %696, i64* %3, align 8
  %697 = inttoptr i64 %695 to i32*
  store i32 0, i32* %697, align 4
  %.pre181 = load i64, i64* %3, align 8
  br label %block_.L_48dd97

block_.L_48dd97:                                  ; preds = %block_.L_48dee7, %block_48dd90
  %698 = phi i64 [ %1280, %block_.L_48dee7 ], [ %.pre181, %block_48dd90 ]
  %699 = load i64, i64* %RBP.i, align 8
  %700 = add i64 %699, -12
  %701 = add i64 %698, 3
  store i64 %701, i64* %3, align 8
  %702 = inttoptr i64 %700 to i32*
  %703 = load i32, i32* %702, align 4
  %704 = zext i32 %703 to i64
  store i64 %704, i64* %RAX.i893, align 8
  %705 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %705, i64* %RCX.i1197, align 8
  %706 = add i64 %705, 72708
  %707 = add i64 %698, 17
  store i64 %707, i64* %3, align 8
  %708 = inttoptr i64 %706 to i32*
  %709 = load i32, i32* %708, align 4
  %710 = sub i32 %703, %709
  %711 = icmp ult i32 %703, %709
  %712 = zext i1 %711 to i8
  store i8 %712, i8* %19, align 1
  %713 = and i32 %710, 255
  %714 = tail call i32 @llvm.ctpop.i32(i32 %713)
  %715 = trunc i32 %714 to i8
  %716 = and i8 %715, 1
  %717 = xor i8 %716, 1
  store i8 %717, i8* %26, align 1
  %718 = xor i32 %709, %703
  %719 = xor i32 %718, %710
  %720 = lshr i32 %719, 4
  %721 = trunc i32 %720 to i8
  %722 = and i8 %721, 1
  store i8 %722, i8* %31, align 1
  %723 = icmp eq i32 %710, 0
  %724 = zext i1 %723 to i8
  store i8 %724, i8* %34, align 1
  %725 = lshr i32 %710, 31
  %726 = trunc i32 %725 to i8
  store i8 %726, i8* %37, align 1
  %727 = lshr i32 %703, 31
  %728 = lshr i32 %709, 31
  %729 = xor i32 %728, %727
  %730 = xor i32 %725, %727
  %731 = add nuw nsw i32 %730, %729
  %732 = icmp eq i32 %731, 2
  %733 = zext i1 %732 to i8
  store i8 %733, i8* %43, align 1
  %734 = icmp ne i8 %726, 0
  %735 = xor i1 %734, %732
  %.v301 = select i1 %735, i64 23, i64 355
  %736 = add i64 %698, %.v301
  store i64 %736, i64* %3, align 8
  br i1 %735, label %block_48ddae, label %block_.L_48defa

block_48ddae:                                     ; preds = %block_.L_48dd97
  store i64 ptrtoint (%G__0x6f9360_type* @G__0x6f9360 to i64), i64* %RAX.i893, align 8
  store i64 ptrtoint (%G__0x726210_type* @G__0x726210 to i64), i64* %RCX.i1197, align 8
  %737 = add i64 %699, -16
  %738 = add i64 %736, 24
  store i64 %738, i64* %3, align 8
  %739 = inttoptr i64 %737 to i32*
  %740 = load i32, i32* %739, align 4
  %741 = sext i32 %740 to i64
  %742 = shl nsw i64 %741, 5
  store i64 %742, i64* %RDX.i1708, align 8
  %743 = add i64 %742, ptrtoint (%G__0x726210_type* @G__0x726210 to i64)
  store i64 %743, i64* %RCX.i1197, align 8
  %744 = icmp ult i64 %743, ptrtoint (%G__0x726210_type* @G__0x726210 to i64)
  %745 = icmp ult i64 %743, %742
  %746 = or i1 %744, %745
  %747 = zext i1 %746 to i8
  store i8 %747, i8* %19, align 1
  %748 = trunc i64 %743 to i32
  %749 = and i32 %748, 248
  %750 = tail call i32 @llvm.ctpop.i32(i32 %749)
  %751 = trunc i32 %750 to i8
  %752 = and i8 %751, 1
  %753 = xor i8 %752, 1
  store i8 %753, i8* %26, align 1
  %754 = xor i64 %743, ptrtoint (%G__0x726210_type* @G__0x726210 to i64)
  %755 = lshr i64 %754, 4
  %756 = trunc i64 %755 to i8
  %757 = and i8 %756, 1
  store i8 %757, i8* %31, align 1
  %758 = icmp eq i64 %743, 0
  %759 = zext i1 %758 to i8
  store i8 %759, i8* %34, align 1
  %760 = lshr i64 %743, 63
  %761 = trunc i64 %760 to i8
  store i8 %761, i8* %37, align 1
  %762 = lshr i64 %741, 58
  %763 = and i64 %762, 1
  %764 = xor i64 %760, lshr (i64 ptrtoint (%G__0x726210_type* @G__0x726210 to i64), i64 63)
  %765 = xor i64 %760, %763
  %766 = add nuw nsw i64 %764, %765
  %767 = icmp eq i64 %766, 2
  %768 = zext i1 %767 to i8
  store i8 %768, i8* %43, align 1
  %769 = add i64 %736, 35
  store i64 %769, i64* %3, align 8
  %770 = load i32, i32* %702, align 4
  %771 = sext i32 %770 to i64
  store i64 %771, i64* %RDX.i1708, align 8
  %772 = shl nsw i64 %771, 1
  %773 = add i64 %772, %743
  %774 = add i64 %736, 39
  store i64 %774, i64* %3, align 8
  %775 = inttoptr i64 %773 to i16*
  %776 = load i16, i16* %775, align 2
  store i16 %776, i16* %SI.i3888, align 2
  %777 = add i64 %699, -88
  %778 = add i64 %736, 43
  store i64 %778, i64* %3, align 8
  %779 = inttoptr i64 %777 to i64*
  %780 = load i64, i64* %779, align 8
  store i64 %780, i64* %RCX.i1197, align 8
  %781 = add i64 %736, 46
  store i64 %781, i64* %3, align 8
  %782 = inttoptr i64 %780 to i64*
  %783 = load i64, i64* %782, align 8
  store i64 %783, i64* %RCX.i1197, align 8
  store i64 %705, i64* %RDX.i1708, align 8
  %784 = add i64 %705, 164
  %785 = add i64 %736, 60
  store i64 %785, i64* %3, align 8
  %786 = inttoptr i64 %784 to i32*
  %787 = load i32, i32* %786, align 4
  %788 = zext i32 %787 to i64
  store i64 %788, i64* %RDI.i3879, align 8
  %789 = load i64, i64* %RBP.i, align 8
  %790 = add i64 %789, -16
  %791 = add i64 %736, 63
  store i64 %791, i64* %3, align 8
  %792 = inttoptr i64 %790 to i32*
  %793 = load i32, i32* %792, align 4
  %794 = add i32 %793, %787
  %795 = zext i32 %794 to i64
  store i64 %795, i64* %RDI.i3879, align 8
  %796 = icmp ult i32 %794, %787
  %797 = icmp ult i32 %794, %793
  %798 = or i1 %796, %797
  %799 = zext i1 %798 to i8
  store i8 %799, i8* %19, align 1
  %800 = and i32 %794, 255
  %801 = tail call i32 @llvm.ctpop.i32(i32 %800)
  %802 = trunc i32 %801 to i8
  %803 = and i8 %802, 1
  %804 = xor i8 %803, 1
  store i8 %804, i8* %26, align 1
  %805 = xor i32 %793, %787
  %806 = xor i32 %805, %794
  %807 = lshr i32 %806, 4
  %808 = trunc i32 %807 to i8
  %809 = and i8 %808, 1
  store i8 %809, i8* %31, align 1
  %810 = icmp eq i32 %794, 0
  %811 = zext i1 %810 to i8
  store i8 %811, i8* %34, align 1
  %812 = lshr i32 %794, 31
  %813 = trunc i32 %812 to i8
  store i8 %813, i8* %37, align 1
  %814 = lshr i32 %787, 31
  %815 = lshr i32 %793, 31
  %816 = xor i32 %812, %814
  %817 = xor i32 %812, %815
  %818 = add nuw nsw i32 %816, %817
  %819 = icmp eq i32 %818, 2
  %820 = zext i1 %819 to i8
  store i8 %820, i8* %43, align 1
  %821 = sext i32 %794 to i64
  store i64 %821, i64* %RDX.i1708, align 8
  %822 = shl nsw i64 %821, 3
  %823 = add i64 %783, %822
  %824 = add i64 %736, 70
  store i64 %824, i64* %3, align 8
  %825 = inttoptr i64 %823 to i64*
  %826 = load i64, i64* %825, align 8
  store i64 %826, i64* %RCX.i1197, align 8
  %827 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %827, i64* %RDX.i1708, align 8
  %828 = add i64 %827, 160
  %829 = add i64 %736, 84
  store i64 %829, i64* %3, align 8
  %830 = inttoptr i64 %828 to i32*
  %831 = load i32, i32* %830, align 4
  %832 = zext i32 %831 to i64
  store i64 %832, i64* %RDI.i3879, align 8
  %833 = add i64 %789, -12
  %834 = add i64 %736, 87
  store i64 %834, i64* %3, align 8
  %835 = inttoptr i64 %833 to i32*
  %836 = load i32, i32* %835, align 4
  %837 = add i32 %836, %831
  %838 = zext i32 %837 to i64
  store i64 %838, i64* %RDI.i3879, align 8
  %839 = icmp ult i32 %837, %831
  %840 = icmp ult i32 %837, %836
  %841 = or i1 %839, %840
  %842 = zext i1 %841 to i8
  store i8 %842, i8* %19, align 1
  %843 = and i32 %837, 255
  %844 = tail call i32 @llvm.ctpop.i32(i32 %843)
  %845 = trunc i32 %844 to i8
  %846 = and i8 %845, 1
  %847 = xor i8 %846, 1
  store i8 %847, i8* %26, align 1
  %848 = xor i32 %836, %831
  %849 = xor i32 %848, %837
  %850 = lshr i32 %849, 4
  %851 = trunc i32 %850 to i8
  %852 = and i8 %851, 1
  store i8 %852, i8* %31, align 1
  %853 = icmp eq i32 %837, 0
  %854 = zext i1 %853 to i8
  store i8 %854, i8* %34, align 1
  %855 = lshr i32 %837, 31
  %856 = trunc i32 %855 to i8
  store i8 %856, i8* %37, align 1
  %857 = lshr i32 %831, 31
  %858 = lshr i32 %836, 31
  %859 = xor i32 %855, %857
  %860 = xor i32 %855, %858
  %861 = add nuw nsw i32 %859, %860
  %862 = icmp eq i32 %861, 2
  %863 = zext i1 %862 to i8
  store i8 %863, i8* %43, align 1
  %864 = sext i32 %837 to i64
  store i64 %864, i64* %RDX.i1708, align 8
  %865 = shl nsw i64 %864, 1
  %866 = add i64 %826, %865
  %867 = load i16, i16* %SI.i3888, align 2
  %868 = add i64 %736, 94
  store i64 %868, i64* %3, align 8
  %869 = inttoptr i64 %866 to i16*
  store i16 %867, i16* %869, align 2
  %870 = load i64, i64* %RBP.i, align 8
  %871 = add i64 %870, -16
  %872 = load i64, i64* %3, align 8
  %873 = add i64 %872, 4
  store i64 %873, i64* %3, align 8
  %874 = inttoptr i64 %871 to i32*
  %875 = load i32, i32* %874, align 4
  %876 = sext i32 %875 to i64
  %877 = shl nsw i64 %876, 5
  store i64 %877, i64* %RCX.i1197, align 8
  %878 = load i64, i64* %RAX.i893, align 8
  %879 = add i64 %877, %878
  store i64 %879, i64* %RAX.i893, align 8
  %880 = icmp ult i64 %879, %878
  %881 = icmp ult i64 %879, %877
  %882 = or i1 %880, %881
  %883 = zext i1 %882 to i8
  store i8 %883, i8* %19, align 1
  %884 = trunc i64 %879 to i32
  %885 = and i32 %884, 255
  %886 = tail call i32 @llvm.ctpop.i32(i32 %885)
  %887 = trunc i32 %886 to i8
  %888 = and i8 %887, 1
  %889 = xor i8 %888, 1
  store i8 %889, i8* %26, align 1
  %890 = xor i64 %878, %879
  %891 = lshr i64 %890, 4
  %892 = trunc i64 %891 to i8
  %893 = and i8 %892, 1
  store i8 %893, i8* %31, align 1
  %894 = icmp eq i64 %879, 0
  %895 = zext i1 %894 to i8
  store i8 %895, i8* %34, align 1
  %896 = lshr i64 %879, 63
  %897 = trunc i64 %896 to i8
  store i8 %897, i8* %37, align 1
  %898 = lshr i64 %878, 63
  %899 = lshr i64 %876, 58
  %900 = and i64 %899, 1
  %901 = xor i64 %896, %898
  %902 = xor i64 %896, %900
  %903 = add nuw nsw i64 %901, %902
  %904 = icmp eq i64 %903, 2
  %905 = zext i1 %904 to i8
  store i8 %905, i8* %43, align 1
  %906 = add i64 %870, -12
  %907 = add i64 %872, 15
  store i64 %907, i64* %3, align 8
  %908 = inttoptr i64 %906 to i32*
  %909 = load i32, i32* %908, align 4
  %910 = sext i32 %909 to i64
  store i64 %910, i64* %RCX.i1197, align 8
  %911 = shl nsw i64 %910, 1
  %912 = add i64 %911, %879
  %913 = add i64 %872, 19
  store i64 %913, i64* %3, align 8
  %914 = inttoptr i64 %912 to i16*
  %915 = load i16, i16* %914, align 2
  store i16 %915, i16* %SI.i3888, align 2
  %916 = add i64 %870, -88
  %917 = add i64 %872, 23
  store i64 %917, i64* %3, align 8
  %918 = inttoptr i64 %916 to i64*
  %919 = load i64, i64* %918, align 8
  store i64 %919, i64* %RAX.i893, align 8
  %920 = add i64 %919, 8
  %921 = add i64 %872, 27
  store i64 %921, i64* %3, align 8
  %922 = inttoptr i64 %920 to i64*
  %923 = load i64, i64* %922, align 8
  store i64 %923, i64* %RAX.i893, align 8
  %924 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %924, i64* %RCX.i1197, align 8
  %925 = add i64 %924, 164
  %926 = add i64 %872, 41
  store i64 %926, i64* %3, align 8
  %927 = inttoptr i64 %925 to i32*
  %928 = load i32, i32* %927, align 4
  %929 = zext i32 %928 to i64
  store i64 %929, i64* %RDI.i3879, align 8
  %930 = load i64, i64* %RBP.i, align 8
  %931 = add i64 %930, -16
  %932 = add i64 %872, 44
  store i64 %932, i64* %3, align 8
  %933 = inttoptr i64 %931 to i32*
  %934 = load i32, i32* %933, align 4
  %935 = add i32 %934, %928
  %936 = zext i32 %935 to i64
  store i64 %936, i64* %RDI.i3879, align 8
  %937 = icmp ult i32 %935, %928
  %938 = icmp ult i32 %935, %934
  %939 = or i1 %937, %938
  %940 = zext i1 %939 to i8
  store i8 %940, i8* %19, align 1
  %941 = and i32 %935, 255
  %942 = tail call i32 @llvm.ctpop.i32(i32 %941)
  %943 = trunc i32 %942 to i8
  %944 = and i8 %943, 1
  %945 = xor i8 %944, 1
  store i8 %945, i8* %26, align 1
  %946 = xor i32 %934, %928
  %947 = xor i32 %946, %935
  %948 = lshr i32 %947, 4
  %949 = trunc i32 %948 to i8
  %950 = and i8 %949, 1
  store i8 %950, i8* %31, align 1
  %951 = icmp eq i32 %935, 0
  %952 = zext i1 %951 to i8
  store i8 %952, i8* %34, align 1
  %953 = lshr i32 %935, 31
  %954 = trunc i32 %953 to i8
  store i8 %954, i8* %37, align 1
  %955 = lshr i32 %928, 31
  %956 = lshr i32 %934, 31
  %957 = xor i32 %953, %955
  %958 = xor i32 %953, %956
  %959 = add nuw nsw i32 %957, %958
  %960 = icmp eq i32 %959, 2
  %961 = zext i1 %960 to i8
  store i8 %961, i8* %43, align 1
  %962 = sext i32 %935 to i64
  store i64 %962, i64* %RCX.i1197, align 8
  %963 = shl nsw i64 %962, 3
  %964 = add i64 %923, %963
  %965 = add i64 %872, 51
  store i64 %965, i64* %3, align 8
  %966 = inttoptr i64 %964 to i64*
  %967 = load i64, i64* %966, align 8
  store i64 %967, i64* %RAX.i893, align 8
  store i64 %924, i64* %RCX.i1197, align 8
  %968 = add i64 %924, 160
  %969 = add i64 %872, 65
  store i64 %969, i64* %3, align 8
  %970 = inttoptr i64 %968 to i32*
  %971 = load i32, i32* %970, align 4
  %972 = zext i32 %971 to i64
  store i64 %972, i64* %RDI.i3879, align 8
  %973 = add i64 %930, -12
  %974 = add i64 %872, 68
  store i64 %974, i64* %3, align 8
  %975 = inttoptr i64 %973 to i32*
  %976 = load i32, i32* %975, align 4
  %977 = add i32 %976, %971
  %978 = zext i32 %977 to i64
  store i64 %978, i64* %RDI.i3879, align 8
  %979 = icmp ult i32 %977, %971
  %980 = icmp ult i32 %977, %976
  %981 = or i1 %979, %980
  %982 = zext i1 %981 to i8
  store i8 %982, i8* %19, align 1
  %983 = and i32 %977, 255
  %984 = tail call i32 @llvm.ctpop.i32(i32 %983)
  %985 = trunc i32 %984 to i8
  %986 = and i8 %985, 1
  %987 = xor i8 %986, 1
  store i8 %987, i8* %26, align 1
  %988 = xor i32 %976, %971
  %989 = xor i32 %988, %977
  %990 = lshr i32 %989, 4
  %991 = trunc i32 %990 to i8
  %992 = and i8 %991, 1
  store i8 %992, i8* %31, align 1
  %993 = icmp eq i32 %977, 0
  %994 = zext i1 %993 to i8
  store i8 %994, i8* %34, align 1
  %995 = lshr i32 %977, 31
  %996 = trunc i32 %995 to i8
  store i8 %996, i8* %37, align 1
  %997 = lshr i32 %971, 31
  %998 = lshr i32 %976, 31
  %999 = xor i32 %995, %997
  %1000 = xor i32 %995, %998
  %1001 = add nuw nsw i32 %999, %1000
  %1002 = icmp eq i32 %1001, 2
  %1003 = zext i1 %1002 to i8
  store i8 %1003, i8* %43, align 1
  %1004 = sext i32 %977 to i64
  store i64 %1004, i64* %RCX.i1197, align 8
  %1005 = shl nsw i64 %1004, 1
  %1006 = add i64 %967, %1005
  %1007 = load i16, i16* %SI.i3888, align 2
  %1008 = add i64 %872, 75
  store i64 %1008, i64* %3, align 8
  %1009 = inttoptr i64 %1006 to i16*
  store i16 %1007, i16* %1009, align 2
  %1010 = load i64, i64* %3, align 8
  %1011 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1011, i64* %RAX.i893, align 8
  %1012 = add i64 %1011, 72400
  %1013 = add i64 %1010, 15
  store i64 %1013, i64* %3, align 8
  %1014 = inttoptr i64 %1012 to i32*
  %1015 = load i32, i32* %1014, align 4
  store i8 0, i8* %19, align 1
  %1016 = and i32 %1015, 255
  %1017 = tail call i32 @llvm.ctpop.i32(i32 %1016)
  %1018 = trunc i32 %1017 to i8
  %1019 = and i8 %1018, 1
  %1020 = xor i8 %1019, 1
  store i8 %1020, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %1021 = icmp eq i32 %1015, 0
  %1022 = zext i1 %1021 to i8
  store i8 %1022, i8* %34, align 1
  %1023 = lshr i32 %1015, 31
  %1024 = trunc i32 %1023 to i8
  store i8 %1024, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v364 = select i1 %1021, i64 144, i64 21
  %1025 = add i64 %1010, %.v364
  store i64 %1025, i64* %3, align 8
  br i1 %1021, label %block_.L_48dee7, label %block_48de6c

block_48de6c:                                     ; preds = %block_48ddae
  store i64 ptrtoint (%G__0x6f9360_type* @G__0x6f9360 to i64), i64* %RAX.i893, align 8
  store i64 ptrtoint (%G__0x726210_type* @G__0x726210 to i64), i64* %RCX.i1197, align 8
  %1026 = load i64, i64* %RBP.i, align 8
  %1027 = add i64 %1026, -16
  %1028 = add i64 %1025, 24
  store i64 %1028, i64* %3, align 8
  %1029 = inttoptr i64 %1027 to i32*
  %1030 = load i32, i32* %1029, align 4
  %1031 = sext i32 %1030 to i64
  %1032 = shl nsw i64 %1031, 5
  store i64 %1032, i64* %RDX.i1708, align 8
  %1033 = add i64 %1032, ptrtoint (%G__0x726210_type* @G__0x726210 to i64)
  store i64 %1033, i64* %RCX.i1197, align 8
  %1034 = icmp ult i64 %1033, ptrtoint (%G__0x726210_type* @G__0x726210 to i64)
  %1035 = icmp ult i64 %1033, %1032
  %1036 = or i1 %1034, %1035
  %1037 = zext i1 %1036 to i8
  store i8 %1037, i8* %19, align 1
  %1038 = trunc i64 %1033 to i32
  %1039 = and i32 %1038, 248
  %1040 = tail call i32 @llvm.ctpop.i32(i32 %1039)
  %1041 = trunc i32 %1040 to i8
  %1042 = and i8 %1041, 1
  %1043 = xor i8 %1042, 1
  store i8 %1043, i8* %26, align 1
  %1044 = xor i64 %1033, ptrtoint (%G__0x726210_type* @G__0x726210 to i64)
  %1045 = lshr i64 %1044, 4
  %1046 = trunc i64 %1045 to i8
  %1047 = and i8 %1046, 1
  store i8 %1047, i8* %31, align 1
  %1048 = icmp eq i64 %1033, 0
  %1049 = zext i1 %1048 to i8
  store i8 %1049, i8* %34, align 1
  %1050 = lshr i64 %1033, 63
  %1051 = trunc i64 %1050 to i8
  store i8 %1051, i8* %37, align 1
  %1052 = lshr i64 %1031, 58
  %1053 = and i64 %1052, 1
  %1054 = xor i64 %1050, lshr (i64 ptrtoint (%G__0x726210_type* @G__0x726210 to i64), i64 63)
  %1055 = xor i64 %1050, %1053
  %1056 = add nuw nsw i64 %1054, %1055
  %1057 = icmp eq i64 %1056, 2
  %1058 = zext i1 %1057 to i8
  store i8 %1058, i8* %43, align 1
  %1059 = add i64 %1026, -12
  %1060 = add i64 %1025, 35
  store i64 %1060, i64* %3, align 8
  %1061 = inttoptr i64 %1059 to i32*
  %1062 = load i32, i32* %1061, align 4
  %1063 = sext i32 %1062 to i64
  store i64 %1063, i64* %RDX.i1708, align 8
  %1064 = shl nsw i64 %1063, 1
  %1065 = add i64 %1064, %1033
  %1066 = add i64 %1025, 39
  store i64 %1066, i64* %3, align 8
  %1067 = inttoptr i64 %1065 to i16*
  %1068 = load i16, i16* %1067, align 2
  %1069 = zext i16 %1068 to i64
  store i64 %1069, i64* %RSI.i4020.pre-phi, align 8
  %1070 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %1071 = add i64 %1070, 1032
  store i64 %1071, i64* %RCX.i1197, align 8
  %1072 = icmp ugt i64 %1070, -1033
  %1073 = zext i1 %1072 to i8
  store i8 %1073, i8* %19, align 1
  %1074 = trunc i64 %1071 to i32
  %1075 = and i32 %1074, 255
  %1076 = tail call i32 @llvm.ctpop.i32(i32 %1075)
  %1077 = trunc i32 %1076 to i8
  %1078 = and i8 %1077, 1
  %1079 = xor i8 %1078, 1
  store i8 %1079, i8* %26, align 1
  %1080 = xor i64 %1071, %1070
  %1081 = lshr i64 %1080, 4
  %1082 = trunc i64 %1081 to i8
  %1083 = and i8 %1082, 1
  store i8 %1083, i8* %31, align 1
  %1084 = icmp eq i64 %1071, 0
  %1085 = zext i1 %1084 to i8
  store i8 %1085, i8* %34, align 1
  %1086 = lshr i64 %1071, 63
  %1087 = trunc i64 %1086 to i8
  store i8 %1087, i8* %37, align 1
  %1088 = lshr i64 %1070, 63
  %1089 = xor i64 %1086, %1088
  %1090 = add nuw nsw i64 %1089, %1086
  %1091 = icmp eq i64 %1090, 2
  %1092 = zext i1 %1091 to i8
  store i8 %1092, i8* %43, align 1
  %1093 = load i64, i64* %RBP.i, align 8
  %1094 = add i64 %1093, -16
  %1095 = add i64 %1025, 58
  store i64 %1095, i64* %3, align 8
  %1096 = inttoptr i64 %1094 to i32*
  %1097 = load i32, i32* %1096, align 4
  %1098 = sext i32 %1097 to i64
  %1099 = shl nsw i64 %1098, 6
  store i64 %1099, i64* %RDX.i1708, align 8
  %1100 = add i64 %1099, %1071
  store i64 %1100, i64* %RCX.i1197, align 8
  %1101 = icmp ult i64 %1100, %1071
  %1102 = icmp ult i64 %1100, %1099
  %1103 = or i1 %1101, %1102
  %1104 = zext i1 %1103 to i8
  store i8 %1104, i8* %19, align 1
  %1105 = trunc i64 %1100 to i32
  %1106 = and i32 %1105, 255
  %1107 = tail call i32 @llvm.ctpop.i32(i32 %1106)
  %1108 = trunc i32 %1107 to i8
  %1109 = and i8 %1108, 1
  %1110 = xor i8 %1109, 1
  store i8 %1110, i8* %26, align 1
  %1111 = xor i64 %1071, %1100
  %1112 = lshr i64 %1111, 4
  %1113 = trunc i64 %1112 to i8
  %1114 = and i8 %1113, 1
  store i8 %1114, i8* %31, align 1
  %1115 = icmp eq i64 %1100, 0
  %1116 = zext i1 %1115 to i8
  store i8 %1116, i8* %34, align 1
  %1117 = lshr i64 %1100, 63
  %1118 = trunc i64 %1117 to i8
  store i8 %1118, i8* %37, align 1
  %1119 = lshr i64 %1098, 57
  %1120 = and i64 %1119, 1
  %1121 = xor i64 %1117, %1086
  %1122 = xor i64 %1117, %1120
  %1123 = add nuw nsw i64 %1121, %1122
  %1124 = icmp eq i64 %1123, 2
  %1125 = zext i1 %1124 to i8
  store i8 %1125, i8* %43, align 1
  %1126 = add i64 %1093, -12
  %1127 = add i64 %1025, 69
  store i64 %1127, i64* %3, align 8
  %1128 = inttoptr i64 %1126 to i32*
  %1129 = load i32, i32* %1128, align 4
  %1130 = sext i32 %1129 to i64
  store i64 %1130, i64* %RDX.i1708, align 8
  %1131 = shl nsw i64 %1130, 2
  %1132 = add i64 %1131, %1100
  %1133 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %1134 = add i64 %1025, 72
  store i64 %1134, i64* %3, align 8
  %1135 = inttoptr i64 %1132 to i32*
  store i32 %1133, i32* %1135, align 4
  %1136 = load i64, i64* %RBP.i, align 8
  %1137 = add i64 %1136, -16
  %1138 = load i64, i64* %3, align 8
  %1139 = add i64 %1138, 4
  store i64 %1139, i64* %3, align 8
  %1140 = inttoptr i64 %1137 to i32*
  %1141 = load i32, i32* %1140, align 4
  %1142 = sext i32 %1141 to i64
  %1143 = shl nsw i64 %1142, 5
  store i64 %1143, i64* %RCX.i1197, align 8
  %1144 = load i64, i64* %RAX.i893, align 8
  %1145 = add i64 %1143, %1144
  store i64 %1145, i64* %RAX.i893, align 8
  %1146 = icmp ult i64 %1145, %1144
  %1147 = icmp ult i64 %1145, %1143
  %1148 = or i1 %1146, %1147
  %1149 = zext i1 %1148 to i8
  store i8 %1149, i8* %19, align 1
  %1150 = trunc i64 %1145 to i32
  %1151 = and i32 %1150, 255
  %1152 = tail call i32 @llvm.ctpop.i32(i32 %1151)
  %1153 = trunc i32 %1152 to i8
  %1154 = and i8 %1153, 1
  %1155 = xor i8 %1154, 1
  store i8 %1155, i8* %26, align 1
  %1156 = xor i64 %1144, %1145
  %1157 = lshr i64 %1156, 4
  %1158 = trunc i64 %1157 to i8
  %1159 = and i8 %1158, 1
  store i8 %1159, i8* %31, align 1
  %1160 = icmp eq i64 %1145, 0
  %1161 = zext i1 %1160 to i8
  store i8 %1161, i8* %34, align 1
  %1162 = lshr i64 %1145, 63
  %1163 = trunc i64 %1162 to i8
  store i8 %1163, i8* %37, align 1
  %1164 = lshr i64 %1144, 63
  %1165 = lshr i64 %1142, 58
  %1166 = and i64 %1165, 1
  %1167 = xor i64 %1162, %1164
  %1168 = xor i64 %1162, %1166
  %1169 = add nuw nsw i64 %1167, %1168
  %1170 = icmp eq i64 %1169, 2
  %1171 = zext i1 %1170 to i8
  store i8 %1171, i8* %43, align 1
  %1172 = add i64 %1136, -12
  %1173 = add i64 %1138, 15
  store i64 %1173, i64* %3, align 8
  %1174 = inttoptr i64 %1172 to i32*
  %1175 = load i32, i32* %1174, align 4
  %1176 = sext i32 %1175 to i64
  store i64 %1176, i64* %RCX.i1197, align 8
  %1177 = shl nsw i64 %1176, 1
  %1178 = add i64 %1177, %1145
  %1179 = add i64 %1138, 19
  store i64 %1179, i64* %3, align 8
  %1180 = inttoptr i64 %1178 to i16*
  %1181 = load i16, i16* %1180, align 2
  %1182 = zext i16 %1181 to i64
  store i64 %1182, i64* %RSI.i4020.pre-phi, align 8
  %1183 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %1184 = add i64 %1183, 2056
  store i64 %1184, i64* %RAX.i893, align 8
  %1185 = icmp ugt i64 %1183, -2057
  %1186 = zext i1 %1185 to i8
  store i8 %1186, i8* %19, align 1
  %1187 = trunc i64 %1184 to i32
  %1188 = and i32 %1187, 255
  %1189 = tail call i32 @llvm.ctpop.i32(i32 %1188)
  %1190 = trunc i32 %1189 to i8
  %1191 = and i8 %1190, 1
  %1192 = xor i8 %1191, 1
  store i8 %1192, i8* %26, align 1
  %1193 = xor i64 %1184, %1183
  %1194 = lshr i64 %1193, 4
  %1195 = trunc i64 %1194 to i8
  %1196 = and i8 %1195, 1
  store i8 %1196, i8* %31, align 1
  %1197 = icmp eq i64 %1184, 0
  %1198 = zext i1 %1197 to i8
  store i8 %1198, i8* %34, align 1
  %1199 = lshr i64 %1184, 63
  %1200 = trunc i64 %1199 to i8
  store i8 %1200, i8* %37, align 1
  %1201 = lshr i64 %1183, 63
  %1202 = xor i64 %1199, %1201
  %1203 = add nuw nsw i64 %1202, %1199
  %1204 = icmp eq i64 %1203, 2
  %1205 = zext i1 %1204 to i8
  store i8 %1205, i8* %43, align 1
  %1206 = load i64, i64* %RBP.i, align 8
  %1207 = add i64 %1206, -16
  %1208 = add i64 %1138, 37
  store i64 %1208, i64* %3, align 8
  %1209 = inttoptr i64 %1207 to i32*
  %1210 = load i32, i32* %1209, align 4
  %1211 = sext i32 %1210 to i64
  %1212 = shl nsw i64 %1211, 6
  store i64 %1212, i64* %RCX.i1197, align 8
  %1213 = add i64 %1212, %1184
  store i64 %1213, i64* %RAX.i893, align 8
  %1214 = icmp ult i64 %1213, %1184
  %1215 = icmp ult i64 %1213, %1212
  %1216 = or i1 %1214, %1215
  %1217 = zext i1 %1216 to i8
  store i8 %1217, i8* %19, align 1
  %1218 = trunc i64 %1213 to i32
  %1219 = and i32 %1218, 255
  %1220 = tail call i32 @llvm.ctpop.i32(i32 %1219)
  %1221 = trunc i32 %1220 to i8
  %1222 = and i8 %1221, 1
  %1223 = xor i8 %1222, 1
  store i8 %1223, i8* %26, align 1
  %1224 = xor i64 %1184, %1213
  %1225 = lshr i64 %1224, 4
  %1226 = trunc i64 %1225 to i8
  %1227 = and i8 %1226, 1
  store i8 %1227, i8* %31, align 1
  %1228 = icmp eq i64 %1213, 0
  %1229 = zext i1 %1228 to i8
  store i8 %1229, i8* %34, align 1
  %1230 = lshr i64 %1213, 63
  %1231 = trunc i64 %1230 to i8
  store i8 %1231, i8* %37, align 1
  %1232 = lshr i64 %1211, 57
  %1233 = and i64 %1232, 1
  %1234 = xor i64 %1230, %1199
  %1235 = xor i64 %1230, %1233
  %1236 = add nuw nsw i64 %1234, %1235
  %1237 = icmp eq i64 %1236, 2
  %1238 = zext i1 %1237 to i8
  store i8 %1238, i8* %43, align 1
  %1239 = add i64 %1206, -12
  %1240 = add i64 %1138, 48
  store i64 %1240, i64* %3, align 8
  %1241 = inttoptr i64 %1239 to i32*
  %1242 = load i32, i32* %1241, align 4
  %1243 = sext i32 %1242 to i64
  store i64 %1243, i64* %RCX.i1197, align 8
  %1244 = shl nsw i64 %1243, 2
  %1245 = add i64 %1244, %1213
  %1246 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %1247 = add i64 %1138, 51
  store i64 %1247, i64* %3, align 8
  %1248 = inttoptr i64 %1245 to i32*
  store i32 %1246, i32* %1248, align 4
  %.pre182 = load i64, i64* %3, align 8
  br label %block_.L_48dee7

block_.L_48dee7:                                  ; preds = %block_48de6c, %block_48ddae
  %1249 = phi i64 [ %.pre182, %block_48de6c ], [ %1025, %block_48ddae ]
  %1250 = load i64, i64* %RBP.i, align 8
  %1251 = add i64 %1250, -12
  %1252 = add i64 %1249, 8
  store i64 %1252, i64* %3, align 8
  %1253 = inttoptr i64 %1251 to i32*
  %1254 = load i32, i32* %1253, align 4
  %1255 = add i32 %1254, 1
  %1256 = zext i32 %1255 to i64
  store i64 %1256, i64* %RAX.i893, align 8
  %1257 = icmp eq i32 %1254, -1
  %1258 = icmp eq i32 %1255, 0
  %1259 = or i1 %1257, %1258
  %1260 = zext i1 %1259 to i8
  store i8 %1260, i8* %19, align 1
  %1261 = and i32 %1255, 255
  %1262 = tail call i32 @llvm.ctpop.i32(i32 %1261)
  %1263 = trunc i32 %1262 to i8
  %1264 = and i8 %1263, 1
  %1265 = xor i8 %1264, 1
  store i8 %1265, i8* %26, align 1
  %1266 = xor i32 %1255, %1254
  %1267 = lshr i32 %1266, 4
  %1268 = trunc i32 %1267 to i8
  %1269 = and i8 %1268, 1
  store i8 %1269, i8* %31, align 1
  %1270 = zext i1 %1258 to i8
  store i8 %1270, i8* %34, align 1
  %1271 = lshr i32 %1255, 31
  %1272 = trunc i32 %1271 to i8
  store i8 %1272, i8* %37, align 1
  %1273 = lshr i32 %1254, 31
  %1274 = xor i32 %1271, %1273
  %1275 = add nuw nsw i32 %1274, %1271
  %1276 = icmp eq i32 %1275, 2
  %1277 = zext i1 %1276 to i8
  store i8 %1277, i8* %43, align 1
  %1278 = add i64 %1249, 14
  store i64 %1278, i64* %3, align 8
  store i32 %1255, i32* %1253, align 4
  %1279 = load i64, i64* %3, align 8
  %1280 = add i64 %1279, -350
  store i64 %1280, i64* %3, align 8
  br label %block_.L_48dd97

block_.L_48defa:                                  ; preds = %block_.L_48dd97
  %1281 = add i64 %699, -16
  %1282 = add i64 %736, 8
  store i64 %1282, i64* %3, align 8
  %1283 = inttoptr i64 %1281 to i32*
  %1284 = load i32, i32* %1283, align 4
  %1285 = add i32 %1284, 1
  %1286 = zext i32 %1285 to i64
  store i64 %1286, i64* %RAX.i893, align 8
  %1287 = icmp eq i32 %1284, -1
  %1288 = icmp eq i32 %1285, 0
  %1289 = or i1 %1287, %1288
  %1290 = zext i1 %1289 to i8
  store i8 %1290, i8* %19, align 1
  %1291 = and i32 %1285, 255
  %1292 = tail call i32 @llvm.ctpop.i32(i32 %1291)
  %1293 = trunc i32 %1292 to i8
  %1294 = and i8 %1293, 1
  %1295 = xor i8 %1294, 1
  store i8 %1295, i8* %26, align 1
  %1296 = xor i32 %1285, %1284
  %1297 = lshr i32 %1296, 4
  %1298 = trunc i32 %1297 to i8
  %1299 = and i8 %1298, 1
  store i8 %1299, i8* %31, align 1
  %1300 = zext i1 %1288 to i8
  store i8 %1300, i8* %34, align 1
  %1301 = lshr i32 %1285, 31
  %1302 = trunc i32 %1301 to i8
  store i8 %1302, i8* %37, align 1
  %1303 = lshr i32 %1284, 31
  %1304 = xor i32 %1301, %1303
  %1305 = add nuw nsw i32 %1304, %1301
  %1306 = icmp eq i32 %1305, 2
  %1307 = zext i1 %1306 to i8
  store i8 %1307, i8* %43, align 1
  %1308 = add i64 %736, 14
  store i64 %1308, i64* %3, align 8
  store i32 %1285, i32* %1283, align 4
  %1309 = load i64, i64* %3, align 8
  %1310 = add i64 %1309, -399
  store i64 %1310, i64* %3, align 8
  br label %block_.L_48dd79

block_.L_48df0d:                                  ; preds = %block_.L_48dd79
  %1311 = add i64 %694, 5
  store i64 %1311, i64* %3, align 8
  br label %block_.L_48df12

block_.L_48df12:                                  ; preds = %block_.L_48df0d, %block_.L_48dd5d
  %1312 = phi i64 [ %657, %block_.L_48df0d ], [ %260, %block_.L_48dd5d ]
  %1313 = phi i64 [ %1311, %block_.L_48df0d ], [ %654, %block_.L_48dd5d ]
  %1314 = load i64, i64* bitcast (%G_0x6cc5f0_type* @G_0x6cc5f0 to i64*), align 8
  %1315 = add i64 %1312, -32
  %1316 = add i64 %1313, 12
  store i64 %1316, i64* %3, align 8
  %1317 = inttoptr i64 %1315 to i64*
  store i64 %1314, i64* %1317, align 8
  %1318 = load i64, i64* %3, align 8
  %1319 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1319, i64* %RAX.i893, align 8
  %1320 = add i64 %1319, 14136
  %1321 = add i64 %1318, 15
  store i64 %1321, i64* %3, align 8
  %1322 = inttoptr i64 %1320 to i64*
  %1323 = load i64, i64* %1322, align 8
  store i64 %1323, i64* %RAX.i893, align 8
  store i64 %1323, i64* bitcast (%G_0x6cc5f0_type* @G_0x6cc5f0 to i64*), align 8
  %1324 = load i64, i64* %RBP.i, align 8
  %1325 = add i64 %1324, -32
  %1326 = add i64 %1318, 27
  store i64 %1326, i64* %3, align 8
  %1327 = inttoptr i64 %1325 to i64*
  %1328 = load i64, i64* %1327, align 8
  store i64 %1319, i64* %RCX.i1197, align 8
  %1329 = add i64 %1318, 42
  store i64 %1329, i64* %3, align 8
  store i64 %1328, i64* %1322, align 8
  %1330 = load i64, i64* %3, align 8
  %1331 = load i64, i64* bitcast (%G_0x6cc600_type* @G_0x6cc600 to i64*), align 8
  %1332 = load i64, i64* %RBP.i, align 8
  %1333 = add i64 %1332, -40
  %1334 = add i64 %1330, 12
  store i64 %1334, i64* %3, align 8
  %1335 = inttoptr i64 %1333 to i64*
  store i64 %1331, i64* %1335, align 8
  %1336 = load i64, i64* %3, align 8
  %1337 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1337, i64* %RAX.i893, align 8
  %1338 = add i64 %1337, 14144
  %1339 = add i64 %1336, 15
  store i64 %1339, i64* %3, align 8
  %1340 = inttoptr i64 %1338 to i64*
  %1341 = load i64, i64* %1340, align 8
  store i64 %1341, i64* %RAX.i893, align 8
  store i64 %1341, i64* bitcast (%G_0x6cc600_type* @G_0x6cc600 to i64*), align 8
  %1342 = load i64, i64* %RBP.i, align 8
  %1343 = add i64 %1342, -40
  %1344 = add i64 %1336, 27
  store i64 %1344, i64* %3, align 8
  %1345 = inttoptr i64 %1343 to i64*
  %1346 = load i64, i64* %1345, align 8
  store i64 %1346, i64* %RAX.i893, align 8
  store i64 %1337, i64* %RCX.i1197, align 8
  %1347 = add i64 %1336, 42
  store i64 %1347, i64* %3, align 8
  store i64 %1346, i64* %1340, align 8
  %1348 = load i64, i64* %3, align 8
  %1349 = load i32, i32* bitcast (%G_0x6d4688_type* @G_0x6d4688 to i32*), align 8
  %1350 = zext i32 %1349 to i64
  store i64 %1350, i64* %RDX.i1708, align 8
  %1351 = load i64, i64* %RBP.i, align 8
  %1352 = add i64 %1351, -56
  %1353 = add i64 %1348, 11
  store i64 %1353, i64* %3, align 8
  %1354 = inttoptr i64 %1352 to i64*
  %1355 = load i64, i64* %1354, align 8
  %1356 = add i64 %1355, 460
  %1357 = add i64 %1348, 17
  store i64 %1357, i64* %3, align 8
  %1358 = inttoptr i64 %1356 to i32*
  store i32 %1349, i32* %1358, align 4
  %1359 = load i64, i64* %3, align 8
  %1360 = load i64, i64* bitcast (%G_0x6f8f10_type* @G_0x6f8f10 to i64*), align 8
  store i64 %1360, i64* %RAX.i893, align 8
  %1361 = load i64, i64* %RBP.i, align 8
  %1362 = add i64 %1361, -56
  %1363 = add i64 %1359, 12
  store i64 %1363, i64* %3, align 8
  %1364 = inttoptr i64 %1362 to i64*
  %1365 = load i64, i64* %1364, align 8
  store i64 %1365, i64* %RCX.i1197, align 8
  %1366 = add i64 %1365, 464
  %1367 = add i64 %1359, 19
  store i64 %1367, i64* %3, align 8
  %1368 = inttoptr i64 %1366 to i64*
  store i64 %1360, i64* %1368, align 8
  %1369 = load i64, i64* %RBP.i, align 8
  %1370 = add i64 %1369, -60
  %1371 = load i64, i64* %3, align 8
  %1372 = add i64 %1371, 3
  store i64 %1372, i64* %3, align 8
  %1373 = inttoptr i64 %1370 to i32*
  %1374 = load i32, i32* %1373, align 4
  %1375 = zext i32 %1374 to i64
  store i64 %1375, i64* %RDX.i1708, align 8
  %1376 = add i64 %1369, -56
  %1377 = add i64 %1371, 7
  store i64 %1377, i64* %3, align 8
  %1378 = inttoptr i64 %1376 to i64*
  %1379 = load i64, i64* %1378, align 8
  %1380 = add i64 %1379, 72
  %1381 = add i64 %1371, 10
  store i64 %1381, i64* %3, align 8
  %1382 = inttoptr i64 %1380 to i32*
  store i32 %1374, i32* %1382, align 4
  %1383 = load i64, i64* %3, align 8
  %1384 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1384, i64* %RAX.i893, align 8
  %1385 = add i64 %1384, 72400
  %1386 = add i64 %1383, 15
  store i64 %1386, i64* %3, align 8
  %1387 = inttoptr i64 %1385 to i32*
  %1388 = load i32, i32* %1387, align 4
  store i8 0, i8* %19, align 1
  %1389 = and i32 %1388, 255
  %1390 = tail call i32 @llvm.ctpop.i32(i32 %1389)
  %1391 = trunc i32 %1390 to i8
  %1392 = and i8 %1391, 1
  %1393 = xor i8 %1392, 1
  store i8 %1393, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %1394 = icmp eq i32 %1388, 0
  %1395 = zext i1 %1394 to i8
  store i8 %1395, i8* %34, align 1
  %1396 = lshr i32 %1388, 31
  %1397 = trunc i32 %1396 to i8
  store i8 %1397, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v308 = select i1 %1394, i64 629, i64 21
  %1398 = add i64 %1383, %.v308
  store i64 %1398, i64* %3, align 8
  %.pre190 = load i64, i64* %RBP.i, align 8
  br i1 %1394, label %block_.L_48e221, label %block_48dfc1

block_48dfc1:                                     ; preds = %block_.L_48df12
  %1399 = add i64 %.pre190, -60
  %1400 = add i64 %1398, 3
  store i64 %1400, i64* %3, align 8
  %1401 = inttoptr i64 %1399 to i32*
  %1402 = load i32, i32* %1401, align 4
  %1403 = zext i32 %1402 to i64
  store i64 %1403, i64* %RAX.i893, align 8
  %1404 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %1405 = add i64 %1404, 3224
  %1406 = add i64 %1398, 17
  store i64 %1406, i64* %3, align 8
  %1407 = inttoptr i64 %1405 to i32*
  store i32 %1402, i32* %1407, align 4
  %1408 = load i64, i64* %3, align 8
  %1409 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1409, i64* %RCX.i1197, align 8
  %1410 = add i64 %1409, 72380
  %1411 = add i64 %1408, 14
  store i64 %1411, i64* %3, align 8
  %1412 = inttoptr i64 %1410 to i32*
  %1413 = load i32, i32* %1412, align 4
  %1414 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %1415 = add i64 %1414, 3328
  %1416 = add i64 %1408, 28
  store i64 %1416, i64* %3, align 8
  %1417 = inttoptr i64 %1415 to i32*
  store i32 %1413, i32* %1417, align 4
  %1418 = load i64, i64* %3, align 8
  %1419 = load i32, i32* bitcast (%G_0x6d4688_type* @G_0x6d4688 to i32*), align 8
  %1420 = zext i32 %1419 to i64
  store i64 %1420, i64* %RAX.i893, align 8
  %1421 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %1422 = add i64 %1421, 3208
  %1423 = add i64 %1418, 21
  store i64 %1423, i64* %3, align 8
  %1424 = inttoptr i64 %1422 to i32*
  store i32 %1419, i32* %1424, align 4
  %1425 = load i64, i64* %3, align 8
  %1426 = load i64, i64* bitcast (%G_0x6f8f10_type* @G_0x6f8f10 to i64*), align 8
  store i64 %1426, i64* %RCX.i1197, align 8
  %1427 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %1427, i64* %RDX.i1708, align 8
  %1428 = add i64 %1427, 3216
  %1429 = add i64 %1425, 23
  store i64 %1429, i64* %3, align 8
  %1430 = inttoptr i64 %1428 to i64*
  store i64 %1426, i64* %1430, align 8
  %1431 = load i64, i64* %RBP.i, align 8
  %1432 = add i64 %1431, -60
  %1433 = load i64, i64* %3, align 8
  %1434 = add i64 %1433, 3
  store i64 %1434, i64* %3, align 8
  %1435 = inttoptr i64 %1432 to i32*
  %1436 = load i32, i32* %1435, align 4
  %1437 = zext i32 %1436 to i64
  store i64 %1437, i64* %RAX.i893, align 8
  %1438 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %1438, i64* %RCX.i1197, align 8
  %1439 = add i64 %1438, 3096
  %1440 = add i64 %1433, 17
  store i64 %1440, i64* %3, align 8
  %1441 = inttoptr i64 %1439 to i32*
  store i32 %1436, i32* %1441, align 4
  %1442 = load i64, i64* %RBP.i, align 8
  %1443 = add i64 %1442, -56
  %1444 = load i64, i64* %3, align 8
  %1445 = add i64 %1444, 4
  store i64 %1445, i64* %3, align 8
  %1446 = inttoptr i64 %1443 to i64*
  %1447 = load i64, i64* %1446, align 8
  store i64 %1447, i64* %RCX.i1197, align 8
  %1448 = add i64 %1447, 592
  %1449 = add i64 %1444, 10
  store i64 %1449, i64* %3, align 8
  %1450 = inttoptr i64 %1448 to i32*
  %1451 = load i32, i32* %1450, align 4
  %1452 = zext i32 %1451 to i64
  store i64 %1452, i64* %RAX.i893, align 8
  %1453 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %1453, i64* %RCX.i1197, align 8
  %1454 = add i64 %1453, 3348
  %1455 = add i64 %1444, 24
  store i64 %1455, i64* %3, align 8
  %1456 = inttoptr i64 %1454 to i32*
  store i32 %1451, i32* %1456, align 4
  %1457 = load i64, i64* %RBP.i, align 8
  %1458 = add i64 %1457, -56
  %1459 = load i64, i64* %3, align 8
  %1460 = add i64 %1459, 4
  store i64 %1460, i64* %3, align 8
  %1461 = inttoptr i64 %1458 to i64*
  %1462 = load i64, i64* %1461, align 8
  store i64 %1462, i64* %RCX.i1197, align 8
  %1463 = add i64 %1462, 596
  %1464 = add i64 %1459, 10
  store i64 %1464, i64* %3, align 8
  %1465 = inttoptr i64 %1463 to i32*
  %1466 = load i32, i32* %1465, align 4
  %1467 = zext i32 %1466 to i64
  store i64 %1467, i64* %RAX.i893, align 8
  %1468 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %1468, i64* %RCX.i1197, align 8
  %1469 = add i64 %1468, 3352
  %1470 = add i64 %1459, 24
  store i64 %1470, i64* %3, align 8
  %1471 = inttoptr i64 %1469 to i32*
  store i32 %1466, i32* %1471, align 4
  %1472 = load i64, i64* %RBP.i, align 8
  %1473 = add i64 %1472, -56
  %1474 = load i64, i64* %3, align 8
  %1475 = add i64 %1474, 4
  store i64 %1475, i64* %3, align 8
  %1476 = inttoptr i64 %1473 to i64*
  %1477 = load i64, i64* %1476, align 8
  store i64 %1477, i64* %RCX.i1197, align 8
  %1478 = add i64 %1477, 12
  %1479 = add i64 %1474, 7
  store i64 %1479, i64* %3, align 8
  %1480 = inttoptr i64 %1478 to i32*
  %1481 = load i32, i32* %1480, align 4
  %1482 = zext i32 %1481 to i64
  store i64 %1482, i64* %RAX.i893, align 8
  %1483 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %1483, i64* %RCX.i1197, align 8
  %1484 = add i64 %1483, 3344
  %1485 = add i64 %1474, 21
  store i64 %1485, i64* %3, align 8
  %1486 = inttoptr i64 %1484 to i32*
  store i32 %1481, i32* %1486, align 4
  %1487 = load i64, i64* %RBP.i, align 8
  %1488 = add i64 %1487, -12
  %1489 = load i64, i64* %3, align 8
  %1490 = add i64 %1489, 7
  store i64 %1490, i64* %3, align 8
  %1491 = inttoptr i64 %1488 to i32*
  store i32 0, i32* %1491, align 4
  %.pre183 = load i64, i64* %3, align 8
  br label %block_.L_48e077

block_.L_48e077:                                  ; preds = %block_.L_48e156, %block_48dfc1
  %1492 = phi i64 [ %1836, %block_.L_48e156 ], [ %.pre183, %block_48dfc1 ]
  %1493 = load i64, i64* %RBP.i, align 8
  %1494 = add i64 %1493, -12
  %1495 = add i64 %1492, 3
  store i64 %1495, i64* %3, align 8
  %1496 = inttoptr i64 %1494 to i32*
  %1497 = load i32, i32* %1496, align 4
  %1498 = zext i32 %1497 to i64
  store i64 %1498, i64* %RAX.i893, align 8
  %1499 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1499, i64* %RCX.i1197, align 8
  %1500 = add i64 %1499, 72692
  %1501 = add i64 %1492, 17
  store i64 %1501, i64* %3, align 8
  %1502 = inttoptr i64 %1500 to i32*
  %1503 = load i32, i32* %1502, align 4
  %1504 = add i32 %1503, 4
  %1505 = zext i32 %1504 to i64
  store i64 %1505, i64* %RDX.i1708, align 8
  %1506 = lshr i32 %1504, 31
  %1507 = sub i32 %1497, %1504
  %1508 = icmp ult i32 %1497, %1504
  %1509 = zext i1 %1508 to i8
  store i8 %1509, i8* %19, align 1
  %1510 = and i32 %1507, 255
  %1511 = tail call i32 @llvm.ctpop.i32(i32 %1510)
  %1512 = trunc i32 %1511 to i8
  %1513 = and i8 %1512, 1
  %1514 = xor i8 %1513, 1
  store i8 %1514, i8* %26, align 1
  %1515 = xor i32 %1504, %1497
  %1516 = xor i32 %1515, %1507
  %1517 = lshr i32 %1516, 4
  %1518 = trunc i32 %1517 to i8
  %1519 = and i8 %1518, 1
  store i8 %1519, i8* %31, align 1
  %1520 = icmp eq i32 %1507, 0
  %1521 = zext i1 %1520 to i8
  store i8 %1521, i8* %34, align 1
  %1522 = lshr i32 %1507, 31
  %1523 = trunc i32 %1522 to i8
  store i8 %1523, i8* %37, align 1
  %1524 = lshr i32 %1497, 31
  %1525 = xor i32 %1506, %1524
  %1526 = xor i32 %1522, %1524
  %1527 = add nuw nsw i32 %1526, %1525
  %1528 = icmp eq i32 %1527, 2
  %1529 = zext i1 %1528 to i8
  store i8 %1529, i8* %43, align 1
  %1530 = icmp ne i8 %1523, 0
  %1531 = xor i1 %1530, %1528
  %.v309 = select i1 %1531, i64 28, i64 242
  %1532 = add i64 %1492, %.v309
  store i64 %1532, i64* %3, align 8
  br i1 %1531, label %block_48e093, label %block_.L_48e169

block_48e093:                                     ; preds = %block_.L_48e077
  %1533 = add i64 %1493, -16
  %1534 = add i64 %1532, 7
  store i64 %1534, i64* %3, align 8
  %1535 = inttoptr i64 %1533 to i32*
  store i32 0, i32* %1535, align 4
  %.pre187 = load i64, i64* %3, align 8
  br label %block_.L_48e09a

block_.L_48e09a:                                  ; preds = %block_.L_48e143, %block_48e093
  %1536 = phi i64 [ %1806, %block_.L_48e143 ], [ %.pre187, %block_48e093 ]
  %1537 = load i64, i64* %RBP.i, align 8
  %1538 = add i64 %1537, -16
  %1539 = add i64 %1536, 4
  store i64 %1539, i64* %3, align 8
  %1540 = inttoptr i64 %1538 to i32*
  %1541 = load i32, i32* %1540, align 4
  %1542 = add i32 %1541, -4
  %1543 = icmp ult i32 %1541, 4
  %1544 = zext i1 %1543 to i8
  store i8 %1544, i8* %19, align 1
  %1545 = and i32 %1542, 255
  %1546 = tail call i32 @llvm.ctpop.i32(i32 %1545)
  %1547 = trunc i32 %1546 to i8
  %1548 = and i8 %1547, 1
  %1549 = xor i8 %1548, 1
  store i8 %1549, i8* %26, align 1
  %1550 = xor i32 %1542, %1541
  %1551 = lshr i32 %1550, 4
  %1552 = trunc i32 %1551 to i8
  %1553 = and i8 %1552, 1
  store i8 %1553, i8* %31, align 1
  %1554 = icmp eq i32 %1542, 0
  %1555 = zext i1 %1554 to i8
  store i8 %1555, i8* %34, align 1
  %1556 = lshr i32 %1542, 31
  %1557 = trunc i32 %1556 to i8
  store i8 %1557, i8* %37, align 1
  %1558 = lshr i32 %1541, 31
  %1559 = xor i32 %1556, %1558
  %1560 = add nuw nsw i32 %1559, %1558
  %1561 = icmp eq i32 %1560, 2
  %1562 = zext i1 %1561 to i8
  store i8 %1562, i8* %43, align 1
  %1563 = icmp ne i8 %1557, 0
  %1564 = xor i1 %1563, %1561
  %.v298 = select i1 %1564, i64 10, i64 188
  %1565 = add i64 %1536, %.v298
  store i64 %1565, i64* %3, align 8
  br i1 %1564, label %block_48e0a4, label %block_.L_48e156

block_48e0a4:                                     ; preds = %block_.L_48e09a
  %1566 = add i64 %1537, -20
  %1567 = add i64 %1565, 7
  store i64 %1567, i64* %3, align 8
  %1568 = inttoptr i64 %1566 to i32*
  store i32 0, i32* %1568, align 4
  %.pre188 = load i64, i64* %3, align 8
  br label %block_.L_48e0ab

block_.L_48e0ab:                                  ; preds = %block_.L_48e130, %block_48e0a4
  %1569 = phi i64 [ %1776, %block_.L_48e130 ], [ %.pre188, %block_48e0a4 ]
  %1570 = load i64, i64* %RBP.i, align 8
  %1571 = add i64 %1570, -20
  %1572 = add i64 %1569, 4
  store i64 %1572, i64* %3, align 8
  %1573 = inttoptr i64 %1571 to i32*
  %1574 = load i32, i32* %1573, align 4
  %1575 = add i32 %1574, -2
  %1576 = icmp ult i32 %1574, 2
  %1577 = zext i1 %1576 to i8
  store i8 %1577, i8* %19, align 1
  %1578 = and i32 %1575, 255
  %1579 = tail call i32 @llvm.ctpop.i32(i32 %1578)
  %1580 = trunc i32 %1579 to i8
  %1581 = and i8 %1580, 1
  %1582 = xor i8 %1581, 1
  store i8 %1582, i8* %26, align 1
  %1583 = xor i32 %1575, %1574
  %1584 = lshr i32 %1583, 4
  %1585 = trunc i32 %1584 to i8
  %1586 = and i8 %1585, 1
  store i8 %1586, i8* %31, align 1
  %1587 = icmp eq i32 %1575, 0
  %1588 = zext i1 %1587 to i8
  store i8 %1588, i8* %34, align 1
  %1589 = lshr i32 %1575, 31
  %1590 = trunc i32 %1589 to i8
  store i8 %1590, i8* %37, align 1
  %1591 = lshr i32 %1574, 31
  %1592 = xor i32 %1589, %1591
  %1593 = add nuw nsw i32 %1592, %1591
  %1594 = icmp eq i32 %1593, 2
  %1595 = zext i1 %1594 to i8
  store i8 %1595, i8* %43, align 1
  %1596 = icmp ne i8 %1590, 0
  %1597 = xor i1 %1596, %1594
  %.v299 = select i1 %1597, i64 10, i64 152
  %1598 = add i64 %1569, %.v299
  store i64 %1598, i64* %3, align 8
  br i1 %1597, label %block_48e0b5, label %block_.L_48e143

block_48e0b5:                                     ; preds = %block_.L_48e0ab
  %1599 = add i64 %1570, -44
  %1600 = add i64 %1598, 7
  store i64 %1600, i64* %3, align 8
  %1601 = inttoptr i64 %1599 to i32*
  store i32 0, i32* %1601, align 4
  %.pre189 = load i64, i64* %3, align 8
  br label %block_.L_48e0bc

block_.L_48e0bc:                                  ; preds = %block_48e0c6, %block_48e0b5
  %1602 = phi i64 [ %1746, %block_48e0c6 ], [ %.pre189, %block_48e0b5 ]
  %1603 = load i64, i64* %RBP.i, align 8
  %1604 = add i64 %1603, -44
  %1605 = add i64 %1602, 4
  store i64 %1605, i64* %3, align 8
  %1606 = inttoptr i64 %1604 to i32*
  %1607 = load i32, i32* %1606, align 4
  %1608 = add i32 %1607, -65
  %1609 = icmp ult i32 %1607, 65
  %1610 = zext i1 %1609 to i8
  store i8 %1610, i8* %19, align 1
  %1611 = and i32 %1608, 255
  %1612 = tail call i32 @llvm.ctpop.i32(i32 %1611)
  %1613 = trunc i32 %1612 to i8
  %1614 = and i8 %1613, 1
  %1615 = xor i8 %1614, 1
  store i8 %1615, i8* %26, align 1
  %1616 = xor i32 %1608, %1607
  %1617 = lshr i32 %1616, 4
  %1618 = trunc i32 %1617 to i8
  %1619 = and i8 %1618, 1
  store i8 %1619, i8* %31, align 1
  %1620 = icmp eq i32 %1608, 0
  %1621 = zext i1 %1620 to i8
  store i8 %1621, i8* %34, align 1
  %1622 = lshr i32 %1608, 31
  %1623 = trunc i32 %1622 to i8
  store i8 %1623, i8* %37, align 1
  %1624 = lshr i32 %1607, 31
  %1625 = xor i32 %1622, %1624
  %1626 = add nuw nsw i32 %1625, %1624
  %1627 = icmp eq i32 %1626, 2
  %1628 = zext i1 %1627 to i8
  store i8 %1628, i8* %43, align 1
  %1629 = icmp ne i8 %1623, 0
  %1630 = xor i1 %1629, %1627
  %.v300 = select i1 %1630, i64 10, i64 116
  %1631 = add i64 %1602, %.v300
  store i64 %1631, i64* %3, align 8
  br i1 %1630, label %block_48e0c6, label %block_.L_48e130

block_48e0c6:                                     ; preds = %block_.L_48e0bc
  %1632 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1632, i64* %RAX.i893, align 8
  %1633 = add i64 %1632, 14136
  %1634 = add i64 %1631, 15
  store i64 %1634, i64* %3, align 8
  %1635 = inttoptr i64 %1633 to i64*
  %1636 = load i64, i64* %1635, align 8
  store i64 %1636, i64* %RAX.i893, align 8
  %1637 = add i64 %1603, -12
  %1638 = add i64 %1631, 19
  store i64 %1638, i64* %3, align 8
  %1639 = inttoptr i64 %1637 to i32*
  %1640 = load i32, i32* %1639, align 4
  %1641 = sext i32 %1640 to i64
  store i64 %1641, i64* %RCX.i1197, align 8
  %1642 = shl nsw i64 %1641, 3
  %1643 = add i64 %1642, %1636
  %1644 = add i64 %1631, 23
  store i64 %1644, i64* %3, align 8
  %1645 = inttoptr i64 %1643 to i64*
  %1646 = load i64, i64* %1645, align 8
  store i64 %1646, i64* %RAX.i893, align 8
  %1647 = add i64 %1603, -16
  %1648 = add i64 %1631, 27
  store i64 %1648, i64* %3, align 8
  %1649 = inttoptr i64 %1647 to i32*
  %1650 = load i32, i32* %1649, align 4
  %1651 = sext i32 %1650 to i64
  store i64 %1651, i64* %RCX.i1197, align 8
  %1652 = shl nsw i64 %1651, 3
  %1653 = add i64 %1652, %1646
  %1654 = add i64 %1631, 31
  store i64 %1654, i64* %3, align 8
  %1655 = inttoptr i64 %1653 to i64*
  %1656 = load i64, i64* %1655, align 8
  store i64 %1656, i64* %RAX.i893, align 8
  %1657 = add i64 %1603, -20
  %1658 = add i64 %1631, 35
  store i64 %1658, i64* %3, align 8
  %1659 = inttoptr i64 %1657 to i32*
  %1660 = load i32, i32* %1659, align 4
  %1661 = sext i32 %1660 to i64
  store i64 %1661, i64* %RCX.i1197, align 8
  %1662 = shl nsw i64 %1661, 3
  %1663 = add i64 %1662, %1656
  %1664 = add i64 %1631, 39
  store i64 %1664, i64* %3, align 8
  %1665 = inttoptr i64 %1663 to i64*
  %1666 = load i64, i64* %1665, align 8
  store i64 %1666, i64* %RAX.i893, align 8
  %1667 = add i64 %1631, 43
  store i64 %1667, i64* %3, align 8
  %1668 = load i32, i32* %1606, align 4
  %1669 = sext i32 %1668 to i64
  store i64 %1669, i64* %RCX.i1197, align 8
  %1670 = shl nsw i64 %1669, 2
  %1671 = add i64 %1670, %1666
  %1672 = add i64 %1631, 46
  store i64 %1672, i64* %3, align 8
  %1673 = inttoptr i64 %1671 to i32*
  %1674 = load i32, i32* %1673, align 4
  %1675 = zext i32 %1674 to i64
  store i64 %1675, i64* %RDX.i1708, align 8
  %1676 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %1676, i64* %RAX.i893, align 8
  %1677 = add i64 %1676, 3080
  %1678 = add i64 %1631, 61
  store i64 %1678, i64* %3, align 8
  %1679 = inttoptr i64 %1677 to i64*
  %1680 = load i64, i64* %1679, align 8
  store i64 %1680, i64* %RAX.i893, align 8
  %1681 = add i64 %1631, 65
  store i64 %1681, i64* %3, align 8
  %1682 = load i32, i32* %1639, align 4
  %1683 = sext i32 %1682 to i64
  store i64 %1683, i64* %RCX.i1197, align 8
  %1684 = shl nsw i64 %1683, 3
  %1685 = add i64 %1684, %1680
  %1686 = add i64 %1631, 69
  store i64 %1686, i64* %3, align 8
  %1687 = inttoptr i64 %1685 to i64*
  %1688 = load i64, i64* %1687, align 8
  store i64 %1688, i64* %RAX.i893, align 8
  %1689 = add i64 %1631, 73
  store i64 %1689, i64* %3, align 8
  %1690 = load i32, i32* %1649, align 4
  %1691 = sext i32 %1690 to i64
  store i64 %1691, i64* %RCX.i1197, align 8
  %1692 = shl nsw i64 %1691, 3
  %1693 = add i64 %1692, %1688
  %1694 = add i64 %1631, 77
  store i64 %1694, i64* %3, align 8
  %1695 = inttoptr i64 %1693 to i64*
  %1696 = load i64, i64* %1695, align 8
  store i64 %1696, i64* %RAX.i893, align 8
  %1697 = add i64 %1631, 81
  store i64 %1697, i64* %3, align 8
  %1698 = load i32, i32* %1659, align 4
  %1699 = sext i32 %1698 to i64
  store i64 %1699, i64* %RCX.i1197, align 8
  %1700 = shl nsw i64 %1699, 3
  %1701 = add i64 %1700, %1696
  %1702 = add i64 %1631, 85
  store i64 %1702, i64* %3, align 8
  %1703 = inttoptr i64 %1701 to i64*
  %1704 = load i64, i64* %1703, align 8
  store i64 %1704, i64* %RAX.i893, align 8
  %1705 = load i64, i64* %RBP.i, align 8
  %1706 = add i64 %1705, -44
  %1707 = add i64 %1631, 89
  store i64 %1707, i64* %3, align 8
  %1708 = inttoptr i64 %1706 to i32*
  %1709 = load i32, i32* %1708, align 4
  %1710 = sext i32 %1709 to i64
  store i64 %1710, i64* %RCX.i1197, align 8
  %1711 = shl nsw i64 %1710, 2
  %1712 = add i64 %1711, %1704
  %1713 = add i64 %1631, 92
  store i64 %1713, i64* %3, align 8
  %1714 = inttoptr i64 %1712 to i32*
  store i32 %1674, i32* %1714, align 4
  %1715 = load i64, i64* %RBP.i, align 8
  %1716 = add i64 %1715, -44
  %1717 = load i64, i64* %3, align 8
  %1718 = add i64 %1717, 3
  store i64 %1718, i64* %3, align 8
  %1719 = inttoptr i64 %1716 to i32*
  %1720 = load i32, i32* %1719, align 4
  %1721 = add i32 %1720, 1
  %1722 = zext i32 %1721 to i64
  store i64 %1722, i64* %RAX.i893, align 8
  %1723 = icmp eq i32 %1720, -1
  %1724 = icmp eq i32 %1721, 0
  %1725 = or i1 %1723, %1724
  %1726 = zext i1 %1725 to i8
  store i8 %1726, i8* %19, align 1
  %1727 = and i32 %1721, 255
  %1728 = tail call i32 @llvm.ctpop.i32(i32 %1727)
  %1729 = trunc i32 %1728 to i8
  %1730 = and i8 %1729, 1
  %1731 = xor i8 %1730, 1
  store i8 %1731, i8* %26, align 1
  %1732 = xor i32 %1721, %1720
  %1733 = lshr i32 %1732, 4
  %1734 = trunc i32 %1733 to i8
  %1735 = and i8 %1734, 1
  store i8 %1735, i8* %31, align 1
  %1736 = zext i1 %1724 to i8
  store i8 %1736, i8* %34, align 1
  %1737 = lshr i32 %1721, 31
  %1738 = trunc i32 %1737 to i8
  store i8 %1738, i8* %37, align 1
  %1739 = lshr i32 %1720, 31
  %1740 = xor i32 %1737, %1739
  %1741 = add nuw nsw i32 %1740, %1737
  %1742 = icmp eq i32 %1741, 2
  %1743 = zext i1 %1742 to i8
  store i8 %1743, i8* %43, align 1
  %1744 = add i64 %1717, 9
  store i64 %1744, i64* %3, align 8
  store i32 %1721, i32* %1719, align 4
  %1745 = load i64, i64* %3, align 8
  %1746 = add i64 %1745, -111
  store i64 %1746, i64* %3, align 8
  br label %block_.L_48e0bc

block_.L_48e130:                                  ; preds = %block_.L_48e0bc
  %1747 = add i64 %1603, -20
  %1748 = add i64 %1631, 8
  store i64 %1748, i64* %3, align 8
  %1749 = inttoptr i64 %1747 to i32*
  %1750 = load i32, i32* %1749, align 4
  %1751 = add i32 %1750, 1
  %1752 = zext i32 %1751 to i64
  store i64 %1752, i64* %RAX.i893, align 8
  %1753 = icmp eq i32 %1750, -1
  %1754 = icmp eq i32 %1751, 0
  %1755 = or i1 %1753, %1754
  %1756 = zext i1 %1755 to i8
  store i8 %1756, i8* %19, align 1
  %1757 = and i32 %1751, 255
  %1758 = tail call i32 @llvm.ctpop.i32(i32 %1757)
  %1759 = trunc i32 %1758 to i8
  %1760 = and i8 %1759, 1
  %1761 = xor i8 %1760, 1
  store i8 %1761, i8* %26, align 1
  %1762 = xor i32 %1751, %1750
  %1763 = lshr i32 %1762, 4
  %1764 = trunc i32 %1763 to i8
  %1765 = and i8 %1764, 1
  store i8 %1765, i8* %31, align 1
  %1766 = zext i1 %1754 to i8
  store i8 %1766, i8* %34, align 1
  %1767 = lshr i32 %1751, 31
  %1768 = trunc i32 %1767 to i8
  store i8 %1768, i8* %37, align 1
  %1769 = lshr i32 %1750, 31
  %1770 = xor i32 %1767, %1769
  %1771 = add nuw nsw i32 %1770, %1767
  %1772 = icmp eq i32 %1771, 2
  %1773 = zext i1 %1772 to i8
  store i8 %1773, i8* %43, align 1
  %1774 = add i64 %1631, 14
  store i64 %1774, i64* %3, align 8
  store i32 %1751, i32* %1749, align 4
  %1775 = load i64, i64* %3, align 8
  %1776 = add i64 %1775, -147
  store i64 %1776, i64* %3, align 8
  br label %block_.L_48e0ab

block_.L_48e143:                                  ; preds = %block_.L_48e0ab
  %1777 = add i64 %1570, -16
  %1778 = add i64 %1598, 8
  store i64 %1778, i64* %3, align 8
  %1779 = inttoptr i64 %1777 to i32*
  %1780 = load i32, i32* %1779, align 4
  %1781 = add i32 %1780, 1
  %1782 = zext i32 %1781 to i64
  store i64 %1782, i64* %RAX.i893, align 8
  %1783 = icmp eq i32 %1780, -1
  %1784 = icmp eq i32 %1781, 0
  %1785 = or i1 %1783, %1784
  %1786 = zext i1 %1785 to i8
  store i8 %1786, i8* %19, align 1
  %1787 = and i32 %1781, 255
  %1788 = tail call i32 @llvm.ctpop.i32(i32 %1787)
  %1789 = trunc i32 %1788 to i8
  %1790 = and i8 %1789, 1
  %1791 = xor i8 %1790, 1
  store i8 %1791, i8* %26, align 1
  %1792 = xor i32 %1781, %1780
  %1793 = lshr i32 %1792, 4
  %1794 = trunc i32 %1793 to i8
  %1795 = and i8 %1794, 1
  store i8 %1795, i8* %31, align 1
  %1796 = zext i1 %1784 to i8
  store i8 %1796, i8* %34, align 1
  %1797 = lshr i32 %1781, 31
  %1798 = trunc i32 %1797 to i8
  store i8 %1798, i8* %37, align 1
  %1799 = lshr i32 %1780, 31
  %1800 = xor i32 %1797, %1799
  %1801 = add nuw nsw i32 %1800, %1797
  %1802 = icmp eq i32 %1801, 2
  %1803 = zext i1 %1802 to i8
  store i8 %1803, i8* %43, align 1
  %1804 = add i64 %1598, 14
  store i64 %1804, i64* %3, align 8
  store i32 %1781, i32* %1779, align 4
  %1805 = load i64, i64* %3, align 8
  %1806 = add i64 %1805, -183
  store i64 %1806, i64* %3, align 8
  br label %block_.L_48e09a

block_.L_48e156:                                  ; preds = %block_.L_48e09a
  %1807 = add i64 %1537, -12
  %1808 = add i64 %1565, 8
  store i64 %1808, i64* %3, align 8
  %1809 = inttoptr i64 %1807 to i32*
  %1810 = load i32, i32* %1809, align 4
  %1811 = add i32 %1810, 1
  %1812 = zext i32 %1811 to i64
  store i64 %1812, i64* %RAX.i893, align 8
  %1813 = icmp eq i32 %1810, -1
  %1814 = icmp eq i32 %1811, 0
  %1815 = or i1 %1813, %1814
  %1816 = zext i1 %1815 to i8
  store i8 %1816, i8* %19, align 1
  %1817 = and i32 %1811, 255
  %1818 = tail call i32 @llvm.ctpop.i32(i32 %1817)
  %1819 = trunc i32 %1818 to i8
  %1820 = and i8 %1819, 1
  %1821 = xor i8 %1820, 1
  store i8 %1821, i8* %26, align 1
  %1822 = xor i32 %1811, %1810
  %1823 = lshr i32 %1822, 4
  %1824 = trunc i32 %1823 to i8
  %1825 = and i8 %1824, 1
  store i8 %1825, i8* %31, align 1
  %1826 = zext i1 %1814 to i8
  store i8 %1826, i8* %34, align 1
  %1827 = lshr i32 %1811, 31
  %1828 = trunc i32 %1827 to i8
  store i8 %1828, i8* %37, align 1
  %1829 = lshr i32 %1810, 31
  %1830 = xor i32 %1827, %1829
  %1831 = add nuw nsw i32 %1830, %1827
  %1832 = icmp eq i32 %1831, 2
  %1833 = zext i1 %1832 to i8
  store i8 %1833, i8* %43, align 1
  %1834 = add i64 %1565, 14
  store i64 %1834, i64* %3, align 8
  store i32 %1811, i32* %1809, align 4
  %1835 = load i64, i64* %3, align 8
  %1836 = add i64 %1835, -237
  store i64 %1836, i64* %3, align 8
  br label %block_.L_48e077

block_.L_48e169:                                  ; preds = %block_.L_48e077
  %1837 = add i64 %1532, 7
  store i64 %1837, i64* %3, align 8
  store i32 0, i32* %1496, align 4
  %.pre184 = load i64, i64* %3, align 8
  br label %block_.L_48e170

block_.L_48e170:                                  ; preds = %block_.L_48e209, %block_.L_48e169
  %1838 = phi i64 [ %2088, %block_.L_48e209 ], [ %.pre184, %block_.L_48e169 ]
  %1839 = load i64, i64* %RBP.i, align 8
  %1840 = add i64 %1839, -12
  %1841 = add i64 %1838, 4
  store i64 %1841, i64* %3, align 8
  %1842 = inttoptr i64 %1840 to i32*
  %1843 = load i32, i32* %1842, align 4
  %1844 = add i32 %1843, -3
  %1845 = icmp ult i32 %1843, 3
  %1846 = zext i1 %1845 to i8
  store i8 %1846, i8* %19, align 1
  %1847 = and i32 %1844, 255
  %1848 = tail call i32 @llvm.ctpop.i32(i32 %1847)
  %1849 = trunc i32 %1848 to i8
  %1850 = and i8 %1849, 1
  %1851 = xor i8 %1850, 1
  store i8 %1851, i8* %26, align 1
  %1852 = xor i32 %1844, %1843
  %1853 = lshr i32 %1852, 4
  %1854 = trunc i32 %1853 to i8
  %1855 = and i8 %1854, 1
  store i8 %1855, i8* %31, align 1
  %1856 = icmp eq i32 %1844, 0
  %1857 = zext i1 %1856 to i8
  store i8 %1857, i8* %34, align 1
  %1858 = lshr i32 %1844, 31
  %1859 = trunc i32 %1858 to i8
  store i8 %1859, i8* %37, align 1
  %1860 = lshr i32 %1843, 31
  %1861 = xor i32 %1858, %1860
  %1862 = add nuw nsw i32 %1861, %1860
  %1863 = icmp eq i32 %1862, 2
  %1864 = zext i1 %1863 to i8
  store i8 %1864, i8* %43, align 1
  %1865 = icmp ne i8 %1859, 0
  %1866 = xor i1 %1865, %1863
  %.v310 = select i1 %1866, i64 10, i64 172
  %1867 = add i64 %1838, %.v310
  store i64 %1867, i64* %3, align 8
  br i1 %1866, label %block_48e17a, label %block_.L_48e21c

block_48e17a:                                     ; preds = %block_.L_48e170
  %1868 = add i64 %1839, -20
  %1869 = add i64 %1867, 7
  store i64 %1869, i64* %3, align 8
  %1870 = inttoptr i64 %1868 to i32*
  store i32 0, i32* %1870, align 4
  %.pre185 = load i64, i64* %3, align 8
  br label %block_.L_48e181

block_.L_48e181:                                  ; preds = %block_.L_48e1f6, %block_48e17a
  %1871 = phi i64 [ %2058, %block_.L_48e1f6 ], [ %.pre185, %block_48e17a ]
  %1872 = load i64, i64* %RBP.i, align 8
  %1873 = add i64 %1872, -20
  %1874 = add i64 %1871, 4
  store i64 %1874, i64* %3, align 8
  %1875 = inttoptr i64 %1873 to i32*
  %1876 = load i32, i32* %1875, align 4
  %1877 = add i32 %1876, -2
  %1878 = icmp ult i32 %1876, 2
  %1879 = zext i1 %1878 to i8
  store i8 %1879, i8* %19, align 1
  %1880 = and i32 %1877, 255
  %1881 = tail call i32 @llvm.ctpop.i32(i32 %1880)
  %1882 = trunc i32 %1881 to i8
  %1883 = and i8 %1882, 1
  %1884 = xor i8 %1883, 1
  store i8 %1884, i8* %26, align 1
  %1885 = xor i32 %1877, %1876
  %1886 = lshr i32 %1885, 4
  %1887 = trunc i32 %1886 to i8
  %1888 = and i8 %1887, 1
  store i8 %1888, i8* %31, align 1
  %1889 = icmp eq i32 %1877, 0
  %1890 = zext i1 %1889 to i8
  store i8 %1890, i8* %34, align 1
  %1891 = lshr i32 %1877, 31
  %1892 = trunc i32 %1891 to i8
  store i8 %1892, i8* %37, align 1
  %1893 = lshr i32 %1876, 31
  %1894 = xor i32 %1891, %1893
  %1895 = add nuw nsw i32 %1894, %1893
  %1896 = icmp eq i32 %1895, 2
  %1897 = zext i1 %1896 to i8
  store i8 %1897, i8* %43, align 1
  %1898 = icmp ne i8 %1892, 0
  %1899 = xor i1 %1898, %1896
  %.v296 = select i1 %1899, i64 10, i64 136
  %1900 = add i64 %1871, %.v296
  store i64 %1900, i64* %3, align 8
  br i1 %1899, label %block_48e18b, label %block_.L_48e209

block_48e18b:                                     ; preds = %block_.L_48e181
  %1901 = add i64 %1872, -44
  %1902 = add i64 %1900, 7
  store i64 %1902, i64* %3, align 8
  %1903 = inttoptr i64 %1901 to i32*
  store i32 0, i32* %1903, align 4
  %.pre186 = load i64, i64* %3, align 8
  br label %block_.L_48e192

block_.L_48e192:                                  ; preds = %block_48e19c, %block_48e18b
  %1904 = phi i64 [ %2028, %block_48e19c ], [ %.pre186, %block_48e18b ]
  %1905 = load i64, i64* %RBP.i, align 8
  %1906 = add i64 %1905, -44
  %1907 = add i64 %1904, 4
  store i64 %1907, i64* %3, align 8
  %1908 = inttoptr i64 %1906 to i32*
  %1909 = load i32, i32* %1908, align 4
  %1910 = add i32 %1909, -18
  %1911 = icmp ult i32 %1909, 18
  %1912 = zext i1 %1911 to i8
  store i8 %1912, i8* %19, align 1
  %1913 = and i32 %1910, 255
  %1914 = tail call i32 @llvm.ctpop.i32(i32 %1913)
  %1915 = trunc i32 %1914 to i8
  %1916 = and i8 %1915, 1
  %1917 = xor i8 %1916, 1
  store i8 %1917, i8* %26, align 1
  %1918 = xor i32 %1909, 16
  %1919 = xor i32 %1918, %1910
  %1920 = lshr i32 %1919, 4
  %1921 = trunc i32 %1920 to i8
  %1922 = and i8 %1921, 1
  store i8 %1922, i8* %31, align 1
  %1923 = icmp eq i32 %1910, 0
  %1924 = zext i1 %1923 to i8
  store i8 %1924, i8* %34, align 1
  %1925 = lshr i32 %1910, 31
  %1926 = trunc i32 %1925 to i8
  store i8 %1926, i8* %37, align 1
  %1927 = lshr i32 %1909, 31
  %1928 = xor i32 %1925, %1927
  %1929 = add nuw nsw i32 %1928, %1927
  %1930 = icmp eq i32 %1929, 2
  %1931 = zext i1 %1930 to i8
  store i8 %1931, i8* %43, align 1
  %1932 = icmp ne i8 %1926, 0
  %1933 = xor i1 %1932, %1930
  %.v297 = select i1 %1933, i64 10, i64 100
  %1934 = add i64 %1904, %.v297
  store i64 %1934, i64* %3, align 8
  br i1 %1933, label %block_48e19c, label %block_.L_48e1f6

block_48e19c:                                     ; preds = %block_.L_48e192
  %1935 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %1935, i64* %RAX.i893, align 8
  %1936 = add i64 %1935, 14144
  %1937 = add i64 %1934, 15
  store i64 %1937, i64* %3, align 8
  %1938 = inttoptr i64 %1936 to i64*
  %1939 = load i64, i64* %1938, align 8
  store i64 %1939, i64* %RAX.i893, align 8
  %1940 = add i64 %1905, -12
  %1941 = add i64 %1934, 19
  store i64 %1941, i64* %3, align 8
  %1942 = inttoptr i64 %1940 to i32*
  %1943 = load i32, i32* %1942, align 4
  %1944 = sext i32 %1943 to i64
  store i64 %1944, i64* %RCX.i1197, align 8
  %1945 = shl nsw i64 %1944, 3
  %1946 = add i64 %1945, %1939
  %1947 = add i64 %1934, 23
  store i64 %1947, i64* %3, align 8
  %1948 = inttoptr i64 %1946 to i64*
  %1949 = load i64, i64* %1948, align 8
  store i64 %1949, i64* %RAX.i893, align 8
  %1950 = add i64 %1905, -20
  %1951 = add i64 %1934, 27
  store i64 %1951, i64* %3, align 8
  %1952 = inttoptr i64 %1950 to i32*
  %1953 = load i32, i32* %1952, align 4
  %1954 = sext i32 %1953 to i64
  store i64 %1954, i64* %RCX.i1197, align 8
  %1955 = shl nsw i64 %1954, 3
  %1956 = add i64 %1955, %1949
  %1957 = add i64 %1934, 31
  store i64 %1957, i64* %3, align 8
  %1958 = inttoptr i64 %1956 to i64*
  %1959 = load i64, i64* %1958, align 8
  store i64 %1959, i64* %RAX.i893, align 8
  %1960 = add i64 %1934, 35
  store i64 %1960, i64* %3, align 8
  %1961 = load i32, i32* %1908, align 4
  %1962 = sext i32 %1961 to i64
  store i64 %1962, i64* %RCX.i1197, align 8
  %1963 = shl nsw i64 %1962, 2
  %1964 = add i64 %1963, %1959
  %1965 = add i64 %1934, 38
  store i64 %1965, i64* %3, align 8
  %1966 = inttoptr i64 %1964 to i32*
  %1967 = load i32, i32* %1966, align 4
  %1968 = zext i32 %1967 to i64
  store i64 %1968, i64* %RDX.i1708, align 8
  %1969 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %1969, i64* %RAX.i893, align 8
  %1970 = add i64 %1969, 3088
  %1971 = add i64 %1934, 53
  store i64 %1971, i64* %3, align 8
  %1972 = inttoptr i64 %1970 to i64*
  %1973 = load i64, i64* %1972, align 8
  store i64 %1973, i64* %RAX.i893, align 8
  %1974 = add i64 %1934, 57
  store i64 %1974, i64* %3, align 8
  %1975 = load i32, i32* %1942, align 4
  %1976 = sext i32 %1975 to i64
  store i64 %1976, i64* %RCX.i1197, align 8
  %1977 = shl nsw i64 %1976, 3
  %1978 = add i64 %1977, %1973
  %1979 = add i64 %1934, 61
  store i64 %1979, i64* %3, align 8
  %1980 = inttoptr i64 %1978 to i64*
  %1981 = load i64, i64* %1980, align 8
  store i64 %1981, i64* %RAX.i893, align 8
  %1982 = add i64 %1934, 65
  store i64 %1982, i64* %3, align 8
  %1983 = load i32, i32* %1952, align 4
  %1984 = sext i32 %1983 to i64
  store i64 %1984, i64* %RCX.i1197, align 8
  %1985 = shl nsw i64 %1984, 3
  %1986 = add i64 %1985, %1981
  %1987 = add i64 %1934, 69
  store i64 %1987, i64* %3, align 8
  %1988 = inttoptr i64 %1986 to i64*
  %1989 = load i64, i64* %1988, align 8
  store i64 %1989, i64* %RAX.i893, align 8
  %1990 = add i64 %1934, 73
  store i64 %1990, i64* %3, align 8
  %1991 = load i32, i32* %1908, align 4
  %1992 = sext i32 %1991 to i64
  store i64 %1992, i64* %RCX.i1197, align 8
  %1993 = shl nsw i64 %1992, 2
  %1994 = add i64 %1993, %1989
  %1995 = add i64 %1934, 76
  store i64 %1995, i64* %3, align 8
  %1996 = inttoptr i64 %1994 to i32*
  store i32 %1967, i32* %1996, align 4
  %1997 = load i64, i64* %RBP.i, align 8
  %1998 = add i64 %1997, -44
  %1999 = load i64, i64* %3, align 8
  %2000 = add i64 %1999, 3
  store i64 %2000, i64* %3, align 8
  %2001 = inttoptr i64 %1998 to i32*
  %2002 = load i32, i32* %2001, align 4
  %2003 = add i32 %2002, 1
  %2004 = zext i32 %2003 to i64
  store i64 %2004, i64* %RAX.i893, align 8
  %2005 = icmp eq i32 %2002, -1
  %2006 = icmp eq i32 %2003, 0
  %2007 = or i1 %2005, %2006
  %2008 = zext i1 %2007 to i8
  store i8 %2008, i8* %19, align 1
  %2009 = and i32 %2003, 255
  %2010 = tail call i32 @llvm.ctpop.i32(i32 %2009)
  %2011 = trunc i32 %2010 to i8
  %2012 = and i8 %2011, 1
  %2013 = xor i8 %2012, 1
  store i8 %2013, i8* %26, align 1
  %2014 = xor i32 %2003, %2002
  %2015 = lshr i32 %2014, 4
  %2016 = trunc i32 %2015 to i8
  %2017 = and i8 %2016, 1
  store i8 %2017, i8* %31, align 1
  %2018 = zext i1 %2006 to i8
  store i8 %2018, i8* %34, align 1
  %2019 = lshr i32 %2003, 31
  %2020 = trunc i32 %2019 to i8
  store i8 %2020, i8* %37, align 1
  %2021 = lshr i32 %2002, 31
  %2022 = xor i32 %2019, %2021
  %2023 = add nuw nsw i32 %2022, %2019
  %2024 = icmp eq i32 %2023, 2
  %2025 = zext i1 %2024 to i8
  store i8 %2025, i8* %43, align 1
  %2026 = add i64 %1999, 9
  store i64 %2026, i64* %3, align 8
  store i32 %2003, i32* %2001, align 4
  %2027 = load i64, i64* %3, align 8
  %2028 = add i64 %2027, -95
  store i64 %2028, i64* %3, align 8
  br label %block_.L_48e192

block_.L_48e1f6:                                  ; preds = %block_.L_48e192
  %2029 = add i64 %1905, -20
  %2030 = add i64 %1934, 8
  store i64 %2030, i64* %3, align 8
  %2031 = inttoptr i64 %2029 to i32*
  %2032 = load i32, i32* %2031, align 4
  %2033 = add i32 %2032, 1
  %2034 = zext i32 %2033 to i64
  store i64 %2034, i64* %RAX.i893, align 8
  %2035 = icmp eq i32 %2032, -1
  %2036 = icmp eq i32 %2033, 0
  %2037 = or i1 %2035, %2036
  %2038 = zext i1 %2037 to i8
  store i8 %2038, i8* %19, align 1
  %2039 = and i32 %2033, 255
  %2040 = tail call i32 @llvm.ctpop.i32(i32 %2039)
  %2041 = trunc i32 %2040 to i8
  %2042 = and i8 %2041, 1
  %2043 = xor i8 %2042, 1
  store i8 %2043, i8* %26, align 1
  %2044 = xor i32 %2033, %2032
  %2045 = lshr i32 %2044, 4
  %2046 = trunc i32 %2045 to i8
  %2047 = and i8 %2046, 1
  store i8 %2047, i8* %31, align 1
  %2048 = zext i1 %2036 to i8
  store i8 %2048, i8* %34, align 1
  %2049 = lshr i32 %2033, 31
  %2050 = trunc i32 %2049 to i8
  store i8 %2050, i8* %37, align 1
  %2051 = lshr i32 %2032, 31
  %2052 = xor i32 %2049, %2051
  %2053 = add nuw nsw i32 %2052, %2049
  %2054 = icmp eq i32 %2053, 2
  %2055 = zext i1 %2054 to i8
  store i8 %2055, i8* %43, align 1
  %2056 = add i64 %1934, 14
  store i64 %2056, i64* %3, align 8
  store i32 %2033, i32* %2031, align 4
  %2057 = load i64, i64* %3, align 8
  %2058 = add i64 %2057, -131
  store i64 %2058, i64* %3, align 8
  br label %block_.L_48e181

block_.L_48e209:                                  ; preds = %block_.L_48e181
  %2059 = add i64 %1872, -12
  %2060 = add i64 %1900, 8
  store i64 %2060, i64* %3, align 8
  %2061 = inttoptr i64 %2059 to i32*
  %2062 = load i32, i32* %2061, align 4
  %2063 = add i32 %2062, 1
  %2064 = zext i32 %2063 to i64
  store i64 %2064, i64* %RAX.i893, align 8
  %2065 = icmp eq i32 %2062, -1
  %2066 = icmp eq i32 %2063, 0
  %2067 = or i1 %2065, %2066
  %2068 = zext i1 %2067 to i8
  store i8 %2068, i8* %19, align 1
  %2069 = and i32 %2063, 255
  %2070 = tail call i32 @llvm.ctpop.i32(i32 %2069)
  %2071 = trunc i32 %2070 to i8
  %2072 = and i8 %2071, 1
  %2073 = xor i8 %2072, 1
  store i8 %2073, i8* %26, align 1
  %2074 = xor i32 %2063, %2062
  %2075 = lshr i32 %2074, 4
  %2076 = trunc i32 %2075 to i8
  %2077 = and i8 %2076, 1
  store i8 %2077, i8* %31, align 1
  %2078 = zext i1 %2066 to i8
  store i8 %2078, i8* %34, align 1
  %2079 = lshr i32 %2063, 31
  %2080 = trunc i32 %2079 to i8
  store i8 %2080, i8* %37, align 1
  %2081 = lshr i32 %2062, 31
  %2082 = xor i32 %2079, %2081
  %2083 = add nuw nsw i32 %2082, %2079
  %2084 = icmp eq i32 %2083, 2
  %2085 = zext i1 %2084 to i8
  store i8 %2085, i8* %43, align 1
  %2086 = add i64 %1900, 14
  store i64 %2086, i64* %3, align 8
  store i32 %2063, i32* %2061, align 4
  %2087 = load i64, i64* %3, align 8
  %2088 = add i64 %2087, -167
  store i64 %2088, i64* %3, align 8
  br label %block_.L_48e170

block_.L_48e21c:                                  ; preds = %block_.L_48e170
  %2089 = add i64 %1867, 5
  store i64 %2089, i64* %3, align 8
  br label %block_.L_48e221

block_.L_48e221:                                  ; preds = %block_.L_48df12, %block_.L_48e21c
  %2090 = phi i64 [ %2089, %block_.L_48e21c ], [ %1398, %block_.L_48df12 ]
  %2091 = phi i64 [ %1839, %block_.L_48e21c ], [ %.pre190, %block_.L_48df12 ]
  %2092 = add i64 %2091, -12
  %2093 = add i64 %2090, 7
  store i64 %2093, i64* %3, align 8
  %2094 = inttoptr i64 %2092 to i32*
  store i32 0, i32* %2094, align 4
  %ECX.i3327 = bitcast %union.anon* %50 to i32*
  %.pre191 = load i64, i64* %3, align 8
  br label %block_.L_48e228

block_.L_48e228:                                  ; preds = %block_.L_48e2bb, %block_.L_48e221
  %2095 = phi i64 [ %2269, %block_.L_48e2bb ], [ %.pre191, %block_.L_48e221 ]
  %2096 = load i64, i64* %RBP.i, align 8
  %2097 = add i64 %2096, -12
  %2098 = add i64 %2095, 4
  store i64 %2098, i64* %3, align 8
  %2099 = inttoptr i64 %2097 to i32*
  %2100 = load i32, i32* %2099, align 4
  %2101 = add i32 %2100, -4
  %2102 = icmp ult i32 %2100, 4
  %2103 = zext i1 %2102 to i8
  store i8 %2103, i8* %19, align 1
  %2104 = and i32 %2101, 255
  %2105 = tail call i32 @llvm.ctpop.i32(i32 %2104)
  %2106 = trunc i32 %2105 to i8
  %2107 = and i8 %2106, 1
  %2108 = xor i8 %2107, 1
  store i8 %2108, i8* %26, align 1
  %2109 = xor i32 %2101, %2100
  %2110 = lshr i32 %2109, 4
  %2111 = trunc i32 %2110 to i8
  %2112 = and i8 %2111, 1
  store i8 %2112, i8* %31, align 1
  %2113 = icmp eq i32 %2101, 0
  %2114 = zext i1 %2113 to i8
  store i8 %2114, i8* %34, align 1
  %2115 = lshr i32 %2101, 31
  %2116 = trunc i32 %2115 to i8
  store i8 %2116, i8* %37, align 1
  %2117 = lshr i32 %2100, 31
  %2118 = xor i32 %2115, %2117
  %2119 = add nuw nsw i32 %2118, %2117
  %2120 = icmp eq i32 %2119, 2
  %2121 = zext i1 %2120 to i8
  store i8 %2121, i8* %43, align 1
  %2122 = icmp ne i8 %2116, 0
  %2123 = xor i1 %2122, %2120
  %.v311 = select i1 %2123, i64 10, i64 166
  %2124 = add i64 %2095, %.v311
  store i64 %2124, i64* %3, align 8
  br i1 %2123, label %block_48e232, label %block_.L_48e2ce

block_48e232:                                     ; preds = %block_.L_48e228
  %2125 = add i64 %2124, 4
  store i64 %2125, i64* %3, align 8
  %2126 = load i32, i32* %2099, align 4
  %2127 = sext i32 %2126 to i64
  store i64 %2127, i64* %RAX.i893, align 8
  %2128 = shl nsw i64 %2127, 1
  %2129 = add nsw i64 %2128, 7137824
  %2130 = add i64 %2124, 12
  store i64 %2130, i64* %3, align 8
  %2131 = inttoptr i64 %2129 to i16*
  %2132 = load i16, i16* %2131, align 2
  %2133 = sext i16 %2132 to i64
  %2134 = and i64 %2133, 4294967295
  store i64 %2134, i64* %RCX.i1197, align 8
  %2135 = add i64 %2096, -56
  %2136 = add i64 %2124, 16
  store i64 %2136, i64* %3, align 8
  %2137 = inttoptr i64 %2135 to i64*
  %2138 = load i64, i64* %2137, align 8
  store i64 %2138, i64* %RAX.i893, align 8
  %2139 = add i64 %2124, 20
  store i64 %2139, i64* %3, align 8
  %2140 = load i32, i32* %2099, align 4
  %2141 = sext i32 %2140 to i64
  store i64 %2141, i64* %RDX.i1708, align 8
  %2142 = shl nsw i64 %2141, 2
  %2143 = add i64 %2138, 472
  %2144 = add i64 %2143, %2142
  %2145 = sext i16 %2132 to i32
  %2146 = add i64 %2124, 27
  store i64 %2146, i64* %3, align 8
  %2147 = inttoptr i64 %2144 to i32*
  store i32 %2145, i32* %2147, align 4
  %2148 = load i64, i64* %RBP.i, align 8
  %2149 = add i64 %2148, -12
  %2150 = load i64, i64* %3, align 8
  %2151 = add i64 %2150, 4
  store i64 %2151, i64* %3, align 8
  %2152 = inttoptr i64 %2149 to i32*
  %2153 = load i32, i32* %2152, align 4
  %2154 = sext i32 %2153 to i64
  store i64 %2154, i64* %RAX.i893, align 8
  %2155 = shl nsw i64 %2154, 1
  %2156 = add nsw i64 %2155, 7161132
  %2157 = add i64 %2150, 12
  store i64 %2157, i64* %3, align 8
  %2158 = inttoptr i64 %2156 to i16*
  %2159 = load i16, i16* %2158, align 2
  %2160 = sext i16 %2159 to i64
  %2161 = and i64 %2160, 4294967295
  store i64 %2161, i64* %RCX.i1197, align 8
  %2162 = add i64 %2148, -56
  %2163 = add i64 %2150, 16
  store i64 %2163, i64* %3, align 8
  %2164 = inttoptr i64 %2162 to i64*
  %2165 = load i64, i64* %2164, align 8
  store i64 %2165, i64* %RAX.i893, align 8
  %2166 = add i64 %2150, 20
  store i64 %2166, i64* %3, align 8
  %2167 = load i32, i32* %2152, align 4
  %2168 = sext i32 %2167 to i64
  store i64 %2168, i64* %RDX.i1708, align 8
  %2169 = shl nsw i64 %2168, 2
  %2170 = add i64 %2165, 488
  %2171 = add i64 %2170, %2169
  %2172 = sext i16 %2159 to i32
  %2173 = add i64 %2150, 27
  store i64 %2173, i64* %3, align 8
  %2174 = inttoptr i64 %2171 to i32*
  store i32 %2172, i32* %2174, align 4
  %2175 = load i64, i64* %3, align 8
  %2176 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %2176, i64* %RAX.i893, align 8
  %2177 = add i64 %2176, 72400
  %2178 = add i64 %2175, 15
  store i64 %2178, i64* %3, align 8
  %2179 = inttoptr i64 %2177 to i32*
  %2180 = load i32, i32* %2179, align 4
  store i8 0, i8* %19, align 1
  %2181 = and i32 %2180, 255
  %2182 = tail call i32 @llvm.ctpop.i32(i32 %2181)
  %2183 = trunc i32 %2182 to i8
  %2184 = and i8 %2183, 1
  %2185 = xor i8 %2184, 1
  store i8 %2185, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %2186 = icmp eq i32 %2180, 0
  %2187 = zext i1 %2186 to i8
  store i8 %2187, i8* %34, align 1
  %2188 = lshr i32 %2180, 31
  %2189 = trunc i32 %2188 to i8
  store i8 %2189, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v363 = select i1 %2186, i64 83, i64 21
  %2190 = add i64 %2175, %.v363
  store i64 %2190, i64* %3, align 8
  br i1 %2186, label %block_.L_48e2bb, label %block_48e27d

block_48e27d:                                     ; preds = %block_48e232
  %2191 = load i64, i64* %RBP.i, align 8
  %2192 = add i64 %2191, -12
  %2193 = add i64 %2190, 4
  store i64 %2193, i64* %3, align 8
  %2194 = inttoptr i64 %2192 to i32*
  %2195 = load i32, i32* %2194, align 4
  %2196 = sext i32 %2195 to i64
  store i64 %2196, i64* %RAX.i893, align 8
  %2197 = shl nsw i64 %2196, 1
  %2198 = add nsw i64 %2197, 7137824
  %2199 = add i64 %2190, 12
  store i64 %2199, i64* %3, align 8
  %2200 = inttoptr i64 %2198 to i16*
  %2201 = load i16, i16* %2200, align 2
  %2202 = sext i16 %2201 to i64
  %2203 = and i64 %2202, 4294967295
  store i64 %2203, i64* %RCX.i1197, align 8
  %2204 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %2204, i64* %RAX.i893, align 8
  %2205 = add i64 %2190, 24
  store i64 %2205, i64* %3, align 8
  %2206 = load i32, i32* %2194, align 4
  %2207 = sext i32 %2206 to i64
  store i64 %2207, i64* %RDX.i1708, align 8
  %2208 = shl nsw i64 %2207, 2
  %2209 = add i64 %2204, 3104
  %2210 = add i64 %2209, %2208
  %2211 = sext i16 %2201 to i32
  %2212 = add i64 %2190, 31
  store i64 %2212, i64* %3, align 8
  %2213 = inttoptr i64 %2210 to i32*
  store i32 %2211, i32* %2213, align 4
  %2214 = load i64, i64* %RBP.i, align 8
  %2215 = add i64 %2214, -12
  %2216 = load i64, i64* %3, align 8
  %2217 = add i64 %2216, 4
  store i64 %2217, i64* %3, align 8
  %2218 = inttoptr i64 %2215 to i32*
  %2219 = load i32, i32* %2218, align 4
  %2220 = sext i32 %2219 to i64
  store i64 %2220, i64* %RAX.i893, align 8
  %2221 = shl nsw i64 %2220, 1
  %2222 = add nsw i64 %2221, 7161132
  %2223 = add i64 %2216, 12
  store i64 %2223, i64* %3, align 8
  %2224 = inttoptr i64 %2222 to i16*
  %2225 = load i16, i16* %2224, align 2
  %2226 = sext i16 %2225 to i64
  %2227 = and i64 %2226, 4294967295
  store i64 %2227, i64* %RCX.i1197, align 8
  %2228 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %2228, i64* %RAX.i893, align 8
  %2229 = add i64 %2216, 24
  store i64 %2229, i64* %3, align 8
  %2230 = load i32, i32* %2218, align 4
  %2231 = sext i32 %2230 to i64
  store i64 %2231, i64* %RDX.i1708, align 8
  %2232 = shl nsw i64 %2231, 2
  %2233 = add i64 %2228, 3120
  %2234 = add i64 %2233, %2232
  %2235 = sext i16 %2225 to i32
  %2236 = add i64 %2216, 31
  store i64 %2236, i64* %3, align 8
  %2237 = inttoptr i64 %2234 to i32*
  store i32 %2235, i32* %2237, align 4
  %.pre286 = load i64, i64* %3, align 8
  br label %block_.L_48e2bb

block_.L_48e2bb:                                  ; preds = %block_48e27d, %block_48e232
  %2238 = phi i64 [ %.pre286, %block_48e27d ], [ %2190, %block_48e232 ]
  %2239 = load i64, i64* %RBP.i, align 8
  %2240 = add i64 %2239, -12
  %2241 = add i64 %2238, 8
  store i64 %2241, i64* %3, align 8
  %2242 = inttoptr i64 %2240 to i32*
  %2243 = load i32, i32* %2242, align 4
  %2244 = add i32 %2243, 1
  %2245 = zext i32 %2244 to i64
  store i64 %2245, i64* %RAX.i893, align 8
  %2246 = icmp eq i32 %2243, -1
  %2247 = icmp eq i32 %2244, 0
  %2248 = or i1 %2246, %2247
  %2249 = zext i1 %2248 to i8
  store i8 %2249, i8* %19, align 1
  %2250 = and i32 %2244, 255
  %2251 = tail call i32 @llvm.ctpop.i32(i32 %2250)
  %2252 = trunc i32 %2251 to i8
  %2253 = and i8 %2252, 1
  %2254 = xor i8 %2253, 1
  store i8 %2254, i8* %26, align 1
  %2255 = xor i32 %2244, %2243
  %2256 = lshr i32 %2255, 4
  %2257 = trunc i32 %2256 to i8
  %2258 = and i8 %2257, 1
  store i8 %2258, i8* %31, align 1
  %2259 = zext i1 %2247 to i8
  store i8 %2259, i8* %34, align 1
  %2260 = lshr i32 %2244, 31
  %2261 = trunc i32 %2260 to i8
  store i8 %2261, i8* %37, align 1
  %2262 = lshr i32 %2243, 31
  %2263 = xor i32 %2260, %2262
  %2264 = add nuw nsw i32 %2263, %2260
  %2265 = icmp eq i32 %2264, 2
  %2266 = zext i1 %2265 to i8
  store i8 %2266, i8* %43, align 1
  %2267 = add i64 %2238, 14
  store i64 %2267, i64* %3, align 8
  store i32 %2244, i32* %2242, align 4
  %2268 = load i64, i64* %3, align 8
  %2269 = add i64 %2268, -161
  store i64 %2269, i64* %3, align 8
  br label %block_.L_48e228

block_.L_48e2ce:                                  ; preds = %block_.L_48e228
  %2270 = add i64 %2096, -56
  %2271 = add i64 %2124, 4
  store i64 %2271, i64* %3, align 8
  %2272 = inttoptr i64 %2270 to i64*
  %2273 = load i64, i64* %2272, align 8
  store i64 %2273, i64* %RAX.i893, align 8
  %2274 = add i64 %2273, 72
  %2275 = add i64 %2124, 8
  store i64 %2275, i64* %3, align 8
  %2276 = inttoptr i64 %2274 to i32*
  %2277 = load i32, i32* %2276, align 4
  %2278 = add i32 %2277, -1
  %2279 = icmp eq i32 %2277, 0
  %2280 = zext i1 %2279 to i8
  store i8 %2280, i8* %19, align 1
  %2281 = and i32 %2278, 255
  %2282 = tail call i32 @llvm.ctpop.i32(i32 %2281)
  %2283 = trunc i32 %2282 to i8
  %2284 = and i8 %2283, 1
  %2285 = xor i8 %2284, 1
  store i8 %2285, i8* %26, align 1
  %2286 = xor i32 %2278, %2277
  %2287 = lshr i32 %2286, 4
  %2288 = trunc i32 %2287 to i8
  %2289 = and i8 %2288, 1
  store i8 %2289, i8* %31, align 1
  %2290 = icmp eq i32 %2278, 0
  %2291 = zext i1 %2290 to i8
  store i8 %2291, i8* %34, align 1
  %2292 = lshr i32 %2278, 31
  %2293 = trunc i32 %2292 to i8
  store i8 %2293, i8* %37, align 1
  %2294 = lshr i32 %2277, 31
  %2295 = xor i32 %2292, %2294
  %2296 = add nuw nsw i32 %2295, %2294
  %2297 = icmp eq i32 %2296, 2
  %2298 = zext i1 %2297 to i8
  store i8 %2298, i8* %43, align 1
  %.v312 = select i1 %2290, i64 14, i64 36
  %2299 = add i64 %2124, %.v312
  store i64 %2299, i64* %3, align 8
  br i1 %2290, label %block_48e2dc, label %block_.L_48e2f2

block_48e2dc:                                     ; preds = %block_.L_48e2ce
  %2300 = load i32, i32* bitcast (%G_0x6d2080_type* @G_0x6d2080 to i32*), align 8
  %2301 = zext i32 %2300 to i64
  store i64 %2301, i64* %RAX.i893, align 8
  %2302 = add i64 %2299, 11
  store i64 %2302, i64* %3, align 8
  %2303 = load i64, i64* %2272, align 8
  store i64 %2303, i64* %RCX.i1197, align 8
  %2304 = add i64 %2303, 580
  %2305 = add i64 %2299, 17
  store i64 %2305, i64* %3, align 8
  %2306 = inttoptr i64 %2304 to i32*
  store i32 %2300, i32* %2306, align 4
  %2307 = load i64, i64* %3, align 8
  %2308 = add i64 %2307, 19
  store i64 %2308, i64* %3, align 8
  br label %block_.L_48e300

block_.L_48e2f2:                                  ; preds = %block_.L_48e2ce
  %2309 = add i64 %2299, 4
  store i64 %2309, i64* %3, align 8
  %2310 = load i64, i64* %2272, align 8
  store i64 %2310, i64* %RAX.i893, align 8
  %2311 = add i64 %2310, 580
  %2312 = add i64 %2299, 14
  store i64 %2312, i64* %3, align 8
  %2313 = inttoptr i64 %2311 to i32*
  store i32 0, i32* %2313, align 4
  %.pre192 = load i64, i64* %3, align 8
  br label %block_.L_48e300

block_.L_48e300:                                  ; preds = %block_.L_48e2f2, %block_48e2dc
  %2314 = phi i64 [ %.pre192, %block_.L_48e2f2 ], [ %2308, %block_48e2dc ]
  %2315 = load i64, i64* %RBP.i, align 8
  %2316 = add i64 %2315, -60
  %2317 = add i64 %2314, 4
  store i64 %2317, i64* %3, align 8
  %2318 = inttoptr i64 %2316 to i32*
  %2319 = load i32, i32* %2318, align 4
  %2320 = add i32 %2319, -8
  %2321 = icmp ult i32 %2319, 8
  %2322 = zext i1 %2321 to i8
  store i8 %2322, i8* %19, align 1
  %2323 = and i32 %2320, 255
  %2324 = tail call i32 @llvm.ctpop.i32(i32 %2323)
  %2325 = trunc i32 %2324 to i8
  %2326 = and i8 %2325, 1
  %2327 = xor i8 %2326, 1
  store i8 %2327, i8* %26, align 1
  %2328 = xor i32 %2320, %2319
  %2329 = lshr i32 %2328, 4
  %2330 = trunc i32 %2329 to i8
  %2331 = and i8 %2330, 1
  store i8 %2331, i8* %31, align 1
  %2332 = icmp eq i32 %2320, 0
  %2333 = zext i1 %2332 to i8
  store i8 %2333, i8* %34, align 1
  %2334 = lshr i32 %2320, 31
  %2335 = trunc i32 %2334 to i8
  store i8 %2335, i8* %37, align 1
  %2336 = lshr i32 %2319, 31
  %2337 = xor i32 %2334, %2336
  %2338 = add nuw nsw i32 %2337, %2336
  %2339 = icmp eq i32 %2338, 2
  %2340 = zext i1 %2339 to i8
  store i8 %2340, i8* %43, align 1
  %.v313 = select i1 %2332, i64 10, i64 55
  %2341 = add i64 %2314, %.v313
  store i64 %2341, i64* %3, align 8
  br i1 %2332, label %block_48e30a, label %block_.L_48e337

block_48e30a:                                     ; preds = %block_.L_48e300
  %2342 = load i32, i32* bitcast (%G_0x723710_type* @G_0x723710 to i32*), align 8
  store i8 0, i8* %19, align 1
  %2343 = and i32 %2342, 255
  %2344 = tail call i32 @llvm.ctpop.i32(i32 %2343)
  %2345 = trunc i32 %2344 to i8
  %2346 = and i8 %2345, 1
  %2347 = xor i8 %2346, 1
  store i8 %2347, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %2348 = icmp eq i32 %2342, 0
  %2349 = zext i1 %2348 to i8
  store i8 %2349, i8* %34, align 1
  %2350 = lshr i32 %2342, 31
  %2351 = trunc i32 %2350 to i8
  store i8 %2351, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v361 = select i1 %2348, i64 14, i64 45
  %2352 = add i64 %2341, %.v361
  store i64 %2352, i64* %3, align 8
  br i1 %2348, label %block_48e318, label %block_.L_48e337

block_48e318:                                     ; preds = %block_48e30a
  %2353 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %2353, i64* %RAX.i893, align 8
  %2354 = add i64 %2353, 3220
  %2355 = add i64 %2352, 15
  store i64 %2355, i64* %3, align 8
  %2356 = inttoptr i64 %2354 to i32*
  %2357 = load i32, i32* %2356, align 4
  store i8 0, i8* %19, align 1
  %2358 = and i32 %2357, 255
  %2359 = tail call i32 @llvm.ctpop.i32(i32 %2358)
  %2360 = trunc i32 %2359 to i8
  %2361 = and i8 %2360, 1
  %2362 = xor i8 %2361, 1
  store i8 %2362, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %2363 = icmp eq i32 %2357, 0
  %2364 = zext i1 %2363 to i8
  store i8 %2364, i8* %34, align 1
  %2365 = lshr i32 %2357, 31
  %2366 = trunc i32 %2365 to i8
  store i8 %2366, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v362 = select i1 %2363, i64 31, i64 21
  %2367 = add i64 %2352, %.v362
  store i64 %2367, i64* %3, align 8
  br i1 %2363, label %block_.L_48e337, label %block_48e32d

block_48e32d:                                     ; preds = %block_48e318
  %RDI.i3234 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  store i64 1, i64* %RDI.i3234, align 8
  %2368 = add i64 %2367, -14477
  %2369 = add i64 %2367, 10
  %2370 = load i64, i64* %6, align 8
  %2371 = add i64 %2370, -8
  %2372 = inttoptr i64 %2371 to i64*
  store i64 %2369, i64* %2372, align 8
  store i64 %2371, i64* %6, align 8
  store i64 %2368, i64* %3, align 8
  %call2_48e332 = tail call %struct.Memory* @sub_48aaa0.RestoreMV8x8(%struct.State* nonnull %0, i64 %2368, %struct.Memory* %MEMORY.1)
  %.pre193 = load i64, i64* %RBP.i, align 8
  %.pre194 = load i64, i64* %3, align 8
  br label %block_.L_48e337

block_.L_48e337:                                  ; preds = %block_48e30a, %block_.L_48e300, %block_48e32d, %block_48e318
  %2373 = phi i64 [ %2341, %block_.L_48e300 ], [ %2352, %block_48e30a ], [ %2367, %block_48e318 ], [ %.pre194, %block_48e32d ]
  %2374 = phi i64 [ %2315, %block_.L_48e300 ], [ %2315, %block_48e30a ], [ %2315, %block_48e318 ], [ %.pre193, %block_48e32d ]
  %MEMORY.20 = phi %struct.Memory* [ %MEMORY.1, %block_.L_48e300 ], [ %MEMORY.1, %block_48e30a ], [ %MEMORY.1, %block_48e318 ], [ %call2_48e332, %block_48e32d ]
  %2375 = add i64 %2374, -56
  %2376 = add i64 %2373, 4
  store i64 %2376, i64* %3, align 8
  %2377 = inttoptr i64 %2375 to i64*
  %2378 = load i64, i64* %2377, align 8
  store i64 %2378, i64* %RAX.i893, align 8
  %2379 = add i64 %2378, 460
  %2380 = add i64 %2373, 10
  store i64 %2380, i64* %3, align 8
  %2381 = inttoptr i64 %2379 to i32*
  %2382 = load i32, i32* %2381, align 4
  %2383 = and i32 %2382, 15
  %2384 = zext i32 %2383 to i64
  store i64 %2384, i64* %RCX.i1197, align 8
  %2385 = icmp eq i32 %2383, 0
  %2386 = zext i1 %2385 to i8
  store i8 0, i8* %19, align 1
  %2387 = tail call i32 @llvm.ctpop.i32(i32 %2383)
  %2388 = trunc i32 %2387 to i8
  %2389 = and i8 %2388, 1
  %2390 = xor i8 %2389, 1
  store i8 %2390, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 %2386, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v314 = select i1 %2385, i64 22, i64 69
  %2391 = add i64 %2373, %.v314
  store i64 %2391, i64* %3, align 8
  br i1 %2385, label %block_48e34d, label %block_.L_48e37c

block_48e34d:                                     ; preds = %block_.L_48e337
  %2392 = add i64 %2391, 4
  store i64 %2392, i64* %3, align 8
  %2393 = load i64, i64* %2377, align 8
  store i64 %2393, i64* %RAX.i893, align 8
  %2394 = add i64 %2393, 72
  %2395 = add i64 %2391, 8
  store i64 %2395, i64* %3, align 8
  %2396 = inttoptr i64 %2394 to i32*
  %2397 = load i32, i32* %2396, align 4
  %2398 = add i32 %2397, -9
  %2399 = icmp ult i32 %2397, 9
  %2400 = zext i1 %2399 to i8
  store i8 %2400, i8* %19, align 1
  %2401 = and i32 %2398, 255
  %2402 = tail call i32 @llvm.ctpop.i32(i32 %2401)
  %2403 = trunc i32 %2402 to i8
  %2404 = and i8 %2403, 1
  %2405 = xor i8 %2404, 1
  store i8 %2405, i8* %26, align 1
  %2406 = xor i32 %2398, %2397
  %2407 = lshr i32 %2406, 4
  %2408 = trunc i32 %2407 to i8
  %2409 = and i8 %2408, 1
  store i8 %2409, i8* %31, align 1
  %2410 = icmp eq i32 %2398, 0
  %2411 = zext i1 %2410 to i8
  store i8 %2411, i8* %34, align 1
  %2412 = lshr i32 %2398, 31
  %2413 = trunc i32 %2412 to i8
  store i8 %2413, i8* %37, align 1
  %2414 = lshr i32 %2397, 31
  %2415 = xor i32 %2412, %2414
  %2416 = add nuw nsw i32 %2415, %2414
  %2417 = icmp eq i32 %2416, 2
  %2418 = zext i1 %2417 to i8
  store i8 %2418, i8* %43, align 1
  %.v359 = select i1 %2410, i64 47, i64 14
  %2419 = add i64 %2391, %.v359
  store i64 %2419, i64* %3, align 8
  br i1 %2410, label %block_.L_48e37c, label %block_48e35b

block_48e35b:                                     ; preds = %block_48e34d
  %2420 = add i64 %2419, 4
  store i64 %2420, i64* %3, align 8
  %2421 = load i64, i64* %2377, align 8
  store i64 %2421, i64* %RAX.i893, align 8
  %2422 = add i64 %2421, 72
  %2423 = add i64 %2419, 8
  store i64 %2423, i64* %3, align 8
  %2424 = inttoptr i64 %2422 to i32*
  %2425 = load i32, i32* %2424, align 4
  %2426 = add i32 %2425, -13
  %2427 = icmp ult i32 %2425, 13
  %2428 = zext i1 %2427 to i8
  store i8 %2428, i8* %19, align 1
  %2429 = and i32 %2426, 255
  %2430 = tail call i32 @llvm.ctpop.i32(i32 %2429)
  %2431 = trunc i32 %2430 to i8
  %2432 = and i8 %2431, 1
  %2433 = xor i8 %2432, 1
  store i8 %2433, i8* %26, align 1
  %2434 = xor i32 %2426, %2425
  %2435 = lshr i32 %2434, 4
  %2436 = trunc i32 %2435 to i8
  %2437 = and i8 %2436, 1
  store i8 %2437, i8* %31, align 1
  %2438 = icmp eq i32 %2426, 0
  %2439 = zext i1 %2438 to i8
  store i8 %2439, i8* %34, align 1
  %2440 = lshr i32 %2426, 31
  %2441 = trunc i32 %2440 to i8
  store i8 %2441, i8* %37, align 1
  %2442 = lshr i32 %2425, 31
  %2443 = xor i32 %2440, %2442
  %2444 = add nuw nsw i32 %2443, %2442
  %2445 = icmp eq i32 %2444, 2
  %2446 = zext i1 %2445 to i8
  store i8 %2446, i8* %43, align 1
  %.v360 = select i1 %2438, i64 33, i64 14
  %2447 = add i64 %2419, %.v360
  store i64 %2447, i64* %3, align 8
  br i1 %2438, label %block_.L_48e37c, label %block_48e369

block_48e369:                                     ; preds = %block_48e35b
  %2448 = add i64 %2447, 4
  store i64 %2448, i64* %3, align 8
  %2449 = load i64, i64* %2377, align 8
  store i64 %2449, i64* %RAX.i893, align 8
  %2450 = add i64 %2449, 572
  %2451 = add i64 %2447, 14
  store i64 %2451, i64* %3, align 8
  %2452 = inttoptr i64 %2450 to i32*
  store i32 0, i32* %2452, align 4
  %2453 = load i64, i64* %3, align 8
  %2454 = add i64 %2453, 22
  store i64 %2454, i64* %3, align 8
  br label %block_.L_48e38d

block_.L_48e37c:                                  ; preds = %block_.L_48e337, %block_48e35b, %block_48e34d
  %2455 = phi i64 [ %2447, %block_48e35b ], [ %2419, %block_48e34d ], [ %2391, %block_.L_48e337 ]
  %2456 = load i32, i32* bitcast (%G_0x723710_type* @G_0x723710 to i32*), align 8
  %2457 = zext i32 %2456 to i64
  store i64 %2457, i64* %RAX.i893, align 8
  %2458 = add i64 %2455, 11
  store i64 %2458, i64* %3, align 8
  %2459 = load i64, i64* %2377, align 8
  store i64 %2459, i64* %RCX.i1197, align 8
  %2460 = add i64 %2459, 572
  %2461 = add i64 %2455, 17
  store i64 %2461, i64* %3, align 8
  %2462 = inttoptr i64 %2460 to i32*
  store i32 %2456, i32* %2462, align 4
  %.pre195 = load i64, i64* %3, align 8
  br label %block_.L_48e38d

block_.L_48e38d:                                  ; preds = %block_.L_48e37c, %block_48e369
  %2463 = phi i64 [ %.pre195, %block_.L_48e37c ], [ %2454, %block_48e369 ]
  %2464 = load i64, i64* %RBP.i, align 8
  %2465 = add i64 %2464, -56
  %2466 = add i64 %2463, 4
  store i64 %2466, i64* %3, align 8
  %2467 = inttoptr i64 %2465 to i64*
  %2468 = load i64, i64* %2467, align 8
  store i64 %2468, i64* %RAX.i893, align 8
  %2469 = add i64 %2468, 572
  %2470 = add i64 %2463, 10
  store i64 %2470, i64* %3, align 8
  %2471 = inttoptr i64 %2469 to i32*
  %2472 = load i32, i32* %2471, align 4
  %2473 = zext i32 %2472 to i64
  store i64 %2473, i64* %RCX.i1197, align 8
  %2474 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %2475 = add i64 %2474, 3336
  %2476 = add i64 %2463, 24
  store i64 %2476, i64* %3, align 8
  %2477 = inttoptr i64 %2475 to i32*
  store i32 %2472, i32* %2477, align 4
  %2478 = load i64, i64* %3, align 8
  %2479 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %2479, i64* %RAX.i893, align 8
  %2480 = add i64 %2479, 2464
  %2481 = add i64 %2478, 15
  store i64 %2481, i64* %3, align 8
  %2482 = inttoptr i64 %2480 to i32*
  %2483 = load i32, i32* %2482, align 4
  %2484 = add i32 %2483, -2
  %2485 = icmp ult i32 %2483, 2
  %2486 = zext i1 %2485 to i8
  store i8 %2486, i8* %19, align 1
  %2487 = and i32 %2484, 255
  %2488 = tail call i32 @llvm.ctpop.i32(i32 %2487)
  %2489 = trunc i32 %2488 to i8
  %2490 = and i8 %2489, 1
  %2491 = xor i8 %2490, 1
  store i8 %2491, i8* %26, align 1
  %2492 = xor i32 %2484, %2483
  %2493 = lshr i32 %2492, 4
  %2494 = trunc i32 %2493 to i8
  %2495 = and i8 %2494, 1
  store i8 %2495, i8* %31, align 1
  %2496 = icmp eq i32 %2484, 0
  %2497 = zext i1 %2496 to i8
  store i8 %2497, i8* %34, align 1
  %2498 = lshr i32 %2484, 31
  %2499 = trunc i32 %2498 to i8
  store i8 %2499, i8* %37, align 1
  %2500 = lshr i32 %2483, 31
  %2501 = xor i32 %2498, %2500
  %2502 = add nuw nsw i32 %2501, %2500
  %2503 = icmp eq i32 %2502, 2
  %2504 = zext i1 %2503 to i8
  store i8 %2504, i8* %43, align 1
  %.v315 = select i1 %2496, i64 21, i64 93
  %2505 = add i64 %2478, %.v315
  store i64 %2505, i64* %3, align 8
  br i1 %2496, label %block_48e3ba, label %block_.L_48e402

block_48e3ba:                                     ; preds = %block_.L_48e38d
  %2506 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %2506, i64* %RAX.i893, align 8
  %2507 = add i64 %2506, 24
  %2508 = add i64 %2505, 12
  store i64 %2508, i64* %3, align 8
  %2509 = inttoptr i64 %2507 to i32*
  %2510 = load i32, i32* %2509, align 4
  %2511 = add i32 %2510, -1
  %2512 = icmp eq i32 %2510, 0
  %2513 = zext i1 %2512 to i8
  store i8 %2513, i8* %19, align 1
  %2514 = and i32 %2511, 255
  %2515 = tail call i32 @llvm.ctpop.i32(i32 %2514)
  %2516 = trunc i32 %2515 to i8
  %2517 = and i8 %2516, 1
  %2518 = xor i8 %2517, 1
  store i8 %2518, i8* %26, align 1
  %2519 = xor i32 %2511, %2510
  %2520 = lshr i32 %2519, 4
  %2521 = trunc i32 %2520 to i8
  %2522 = and i8 %2521, 1
  store i8 %2522, i8* %31, align 1
  %2523 = icmp eq i32 %2511, 0
  %2524 = zext i1 %2523 to i8
  store i8 %2524, i8* %34, align 1
  %2525 = lshr i32 %2511, 31
  %2526 = trunc i32 %2525 to i8
  store i8 %2526, i8* %37, align 1
  %2527 = lshr i32 %2510, 31
  %2528 = xor i32 %2525, %2527
  %2529 = add nuw nsw i32 %2528, %2527
  %2530 = icmp eq i32 %2529, 2
  %2531 = zext i1 %2530 to i8
  store i8 %2531, i8* %43, align 1
  %.v358 = select i1 %2523, i64 72, i64 18
  %2532 = add i64 %2505, %.v358
  store i64 %2532, i64* %3, align 8
  br i1 %2523, label %block_.L_48e402, label %block_48e3cc

block_48e3cc:                                     ; preds = %block_48e3ba
  %2533 = load i64, i64* %RBP.i, align 8
  %2534 = add i64 %2533, -60
  %2535 = add i64 %2532, 3
  store i64 %2535, i64* %3, align 8
  %2536 = inttoptr i64 %2534 to i32*
  %2537 = load i32, i32* %2536, align 4
  %2538 = zext i32 %2537 to i64
  store i64 %2538, i64* %RAX.i893, align 8
  %CL.i3170 = bitcast %union.anon* %50 to i8*
  %2539 = trunc i32 %2537 to i8
  store i8 %2539, i8* %CL.i3170, align 1
  %2540 = load i64, i64* bitcast (%G_0x6cb918_type* @G_0x6cb918 to i64*), align 8
  store i64 %2540, i64* %RDX.i1708, align 8
  %2541 = add i64 %2540, 48
  %2542 = add i64 %2532, 17
  store i64 %2542, i64* %3, align 8
  %2543 = inttoptr i64 %2541 to i64*
  %2544 = load i64, i64* %2543, align 8
  store i64 %2544, i64* %RDX.i1708, align 8
  store i64 %2506, i64* %RSI.i4020.pre-phi, align 8
  %2545 = add i64 %2506, 136
  %2546 = add i64 %2532, 32
  store i64 %2546, i64* %3, align 8
  %2547 = inttoptr i64 %2545 to i32*
  %2548 = load i32, i32* %2547, align 4
  %2549 = sext i32 %2548 to i64
  store i64 %2549, i64* %RSI.i4020.pre-phi, align 8
  %2550 = shl nsw i64 %2549, 3
  %2551 = add i64 %2550, %2544
  %2552 = add i64 %2532, 36
  store i64 %2552, i64* %3, align 8
  %2553 = inttoptr i64 %2551 to i64*
  %2554 = load i64, i64* %2553, align 8
  store i64 %2554, i64* %RDX.i1708, align 8
  store i64 %2506, i64* %RSI.i4020.pre-phi, align 8
  %2555 = add i64 %2506, 140
  %2556 = add i64 %2532, 51
  store i64 %2556, i64* %3, align 8
  %2557 = inttoptr i64 %2555 to i32*
  %2558 = load i32, i32* %2557, align 4
  %2559 = sext i32 %2558 to i64
  store i64 %2559, i64* %RSI.i4020.pre-phi, align 8
  %2560 = add i64 %2554, %2559
  %2561 = add i64 %2532, 54
  store i64 %2561, i64* %3, align 8
  %2562 = inttoptr i64 %2560 to i8*
  store i8 %2539, i8* %2562, align 1
  %.pre196 = load i64, i64* %3, align 8
  br label %block_.L_48e402

block_.L_48e402:                                  ; preds = %block_.L_48e38d, %block_48e3cc, %block_48e3ba
  %2563 = phi i64 [ %.pre196, %block_48e3cc ], [ %2532, %block_48e3ba ], [ %2505, %block_.L_48e38d ]
  %2564 = load i64, i64* %RBP.i, align 8
  %2565 = add i64 %2564, -16
  %2566 = add i64 %2563, 7
  store i64 %2566, i64* %3, align 8
  %2567 = inttoptr i64 %2565 to i32*
  store i32 0, i32* %2567, align 4
  %2568 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %2569 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %RDI.i3116 = getelementptr inbounds %union.anon, %union.anon* %2569, i64 0, i32 0
  %EDI.i3110 = bitcast %union.anon* %2569 to i32*
  %2570 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8.i3094 = getelementptr inbounds %union.anon, %union.anon* %2570, i64 0, i32 0
  %DI.i2456 = bitcast %union.anon* %2569 to i16*
  %R8D.i2445 = bitcast %union.anon* %2570 to i32*
  %R9.i2396 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %2571 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D.i2266 = bitcast %union.anon* %2571 to i32*
  %2572 = getelementptr inbounds %union.anon, %union.anon* %2571, i64 0, i32 0
  %R11.i2222 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %R10W.i2642 = bitcast %union.anon* %2571 to i16*
  %.pre197 = load i64, i64* %3, align 8
  br label %block_.L_48e409

block_.L_48e409:                                  ; preds = %block_.L_48edc5, %block_.L_48e402
  %2573 = phi i64 [ %.pre197, %block_.L_48e402 ], [ %6334, %block_.L_48edc5 ]
  %MEMORY.24 = phi %struct.Memory* [ %MEMORY.20, %block_.L_48e402 ], [ %MEMORY.25, %block_.L_48edc5 ]
  %2574 = load i64, i64* %RBP.i, align 8
  %2575 = add i64 %2574, -16
  %2576 = add i64 %2573, 4
  store i64 %2576, i64* %3, align 8
  %2577 = inttoptr i64 %2575 to i32*
  %2578 = load i32, i32* %2577, align 4
  %2579 = add i32 %2578, -4
  %2580 = icmp ult i32 %2578, 4
  %2581 = zext i1 %2580 to i8
  store i8 %2581, i8* %19, align 1
  %2582 = and i32 %2579, 255
  %2583 = tail call i32 @llvm.ctpop.i32(i32 %2582)
  %2584 = trunc i32 %2583 to i8
  %2585 = and i8 %2584, 1
  %2586 = xor i8 %2585, 1
  store i8 %2586, i8* %26, align 1
  %2587 = xor i32 %2579, %2578
  %2588 = lshr i32 %2587, 4
  %2589 = trunc i32 %2588 to i8
  %2590 = and i8 %2589, 1
  store i8 %2590, i8* %31, align 1
  %2591 = icmp eq i32 %2579, 0
  %2592 = zext i1 %2591 to i8
  store i8 %2592, i8* %34, align 1
  %2593 = lshr i32 %2579, 31
  %2594 = trunc i32 %2593 to i8
  store i8 %2594, i8* %37, align 1
  %2595 = lshr i32 %2578, 31
  %2596 = xor i32 %2593, %2595
  %2597 = add nuw nsw i32 %2596, %2595
  %2598 = icmp eq i32 %2597, 2
  %2599 = zext i1 %2598 to i8
  store i8 %2599, i8* %43, align 1
  %2600 = icmp ne i8 %2594, 0
  %2601 = xor i1 %2600, %2598
  %.v316 = select i1 %2601, i64 10, i64 2511
  %2602 = add i64 %2573, %.v316
  store i64 %2602, i64* %3, align 8
  br i1 %2601, label %block_48e413, label %block_.L_48edd8

block_48e413:                                     ; preds = %block_.L_48e409
  %2603 = add i64 %2574, -12
  %2604 = add i64 %2602, 7
  store i64 %2604, i64* %3, align 8
  %2605 = inttoptr i64 %2603 to i32*
  store i32 0, i32* %2605, align 4
  %.pre245 = load i64, i64* %3, align 8
  br label %block_.L_48e41a

block_.L_48e41a:                                  ; preds = %block_.L_48edb2, %block_48e413
  %2606 = phi i64 [ %.pre245, %block_48e413 ], [ %6304, %block_.L_48edb2 ]
  %MEMORY.25 = phi %struct.Memory* [ %MEMORY.24, %block_48e413 ], [ %5647, %block_.L_48edb2 ]
  %2607 = load i64, i64* %RBP.i, align 8
  %2608 = add i64 %2607, -12
  %2609 = add i64 %2606, 4
  store i64 %2609, i64* %3, align 8
  %2610 = inttoptr i64 %2608 to i32*
  %2611 = load i32, i32* %2610, align 4
  %2612 = add i32 %2611, -4
  %2613 = icmp ult i32 %2611, 4
  %2614 = zext i1 %2613 to i8
  store i8 %2614, i8* %19, align 1
  %2615 = and i32 %2612, 255
  %2616 = tail call i32 @llvm.ctpop.i32(i32 %2615)
  %2617 = trunc i32 %2616 to i8
  %2618 = and i8 %2617, 1
  %2619 = xor i8 %2618, 1
  store i8 %2619, i8* %26, align 1
  %2620 = xor i32 %2612, %2611
  %2621 = lshr i32 %2620, 4
  %2622 = trunc i32 %2621 to i8
  %2623 = and i8 %2622, 1
  store i8 %2623, i8* %31, align 1
  %2624 = icmp eq i32 %2612, 0
  %2625 = zext i1 %2624 to i8
  store i8 %2625, i8* %34, align 1
  %2626 = lshr i32 %2612, 31
  %2627 = trunc i32 %2626 to i8
  store i8 %2627, i8* %37, align 1
  %2628 = lshr i32 %2611, 31
  %2629 = xor i32 %2626, %2628
  %2630 = add nuw nsw i32 %2629, %2628
  %2631 = icmp eq i32 %2630, 2
  %2632 = zext i1 %2631 to i8
  store i8 %2632, i8* %43, align 1
  %2633 = icmp ne i8 %2627, 0
  %2634 = xor i1 %2633, %2631
  %.v341 = select i1 %2634, i64 10, i64 2475
  %2635 = add i64 %2606, %.v341
  %2636 = add i64 %2635, 5
  store i64 %2636, i64* %3, align 8
  br i1 %2634, label %block_48e424, label %block_.L_48edc5

block_48e424:                                     ; preds = %block_.L_48e41a
  store i64 2, i64* %RAX.i893, align 8
  %2637 = add i64 %2607, -56
  %2638 = add i64 %2635, 9
  store i64 %2638, i64* %3, align 8
  %2639 = inttoptr i64 %2637 to i64*
  %2640 = load i64, i64* %2639, align 8
  store i64 %2640, i64* %RCX.i1197, align 8
  %2641 = add i64 %2635, 12
  store i64 %2641, i64* %3, align 8
  %2642 = load i32, i32* %2610, align 4
  %2643 = zext i32 %2642 to i64
  store i64 %2643, i64* %RDX.i1708, align 8
  %2644 = add i64 %2607, -124
  %2645 = add i64 %2635, 15
  store i64 %2645, i64* %3, align 8
  %2646 = inttoptr i64 %2644 to i32*
  store i32 2, i32* %2646, align 4
  %2647 = load i32, i32* %EDX.i1723, align 4
  %2648 = zext i32 %2647 to i64
  %2649 = load i64, i64* %3, align 8
  store i64 %2648, i64* %RAX.i893, align 8
  %2650 = sext i32 %2647 to i64
  %2651 = lshr i64 %2650, 32
  store i64 %2651, i64* %2568, align 8
  %2652 = load i64, i64* %RBP.i, align 8
  %2653 = add i64 %2652, -124
  %2654 = add i64 %2649, 6
  store i64 %2654, i64* %3, align 8
  %2655 = inttoptr i64 %2653 to i32*
  %2656 = load i32, i32* %2655, align 4
  %2657 = zext i32 %2656 to i64
  store i64 %2657, i64* %RSI.i4020.pre-phi, align 8
  %2658 = add i64 %2649, 8
  store i64 %2658, i64* %3, align 8
  %2659 = sext i32 %2656 to i64
  %2660 = shl nuw i64 %2651, 32
  %2661 = or i64 %2660, %2648
  %2662 = sdiv i64 %2661, %2659
  %2663 = shl i64 %2662, 32
  %2664 = ashr exact i64 %2663, 32
  %2665 = icmp eq i64 %2662, %2664
  br i1 %2665, label %2668, label %2666

; <label>:2666:                                   ; preds = %block_48e424
  %2667 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %2658, %struct.Memory* %MEMORY.25)
  %.pre246 = load i64, i64* %RBP.i, align 8
  %.pre247 = load i64, i64* %3, align 8
  %.pre248 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__esi.exit3120

; <label>:2668:                                   ; preds = %block_48e424
  %2669 = srem i64 %2661, %2659
  %2670 = and i64 %2662, 4294967295
  store i64 %2670, i64* %RAX.i893, align 8
  %2671 = and i64 %2669, 4294967295
  store i64 %2671, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %2672 = trunc i64 %2662 to i32
  br label %routine_idivl__esi.exit3120

routine_idivl__esi.exit3120:                      ; preds = %2668, %2666
  %2673 = phi i32 [ %.pre248, %2666 ], [ %2672, %2668 ]
  %2674 = phi i64 [ %.pre247, %2666 ], [ %2658, %2668 ]
  %2675 = phi i64 [ %.pre246, %2666 ], [ %2652, %2668 ]
  %2676 = phi %struct.Memory* [ %2667, %2666 ], [ %MEMORY.25, %2668 ]
  %2677 = add i64 %2675, -16
  %2678 = add i64 %2674, 3
  store i64 %2678, i64* %3, align 8
  %2679 = inttoptr i64 %2677 to i32*
  %2680 = load i32, i32* %2679, align 4
  %2681 = zext i32 %2680 to i64
  store i64 %2681, i64* %RDI.i3116, align 8
  %2682 = add i64 %2675, -128
  %2683 = add i64 %2674, 6
  store i64 %2683, i64* %3, align 8
  %2684 = inttoptr i64 %2682 to i32*
  store i32 %2673, i32* %2684, align 4
  %2685 = load i32, i32* %EDI.i3110, align 4
  %2686 = zext i32 %2685 to i64
  %2687 = load i64, i64* %3, align 8
  store i64 %2686, i64* %RAX.i893, align 8
  %2688 = sext i32 %2685 to i64
  %2689 = lshr i64 %2688, 32
  store i64 %2689, i64* %2568, align 8
  %2690 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %2691 = add i64 %2687, 5
  store i64 %2691, i64* %3, align 8
  %2692 = sext i32 %2690 to i64
  %2693 = shl nuw i64 %2689, 32
  %2694 = or i64 %2693, %2686
  %2695 = sdiv i64 %2694, %2692
  %2696 = shl i64 %2695, 32
  %2697 = ashr exact i64 %2696, 32
  %2698 = icmp eq i64 %2695, %2697
  br i1 %2698, label %2701, label %2699

; <label>:2699:                                   ; preds = %routine_idivl__esi.exit3120
  %2700 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %2691, %struct.Memory* %2676)
  %.pre249 = load i64, i64* %RAX.i893, align 8
  %.pre250 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit3105

; <label>:2701:                                   ; preds = %routine_idivl__esi.exit3120
  %2702 = srem i64 %2694, %2692
  %2703 = and i64 %2695, 4294967295
  store i64 %2703, i64* %RAX.i893, align 8
  %2704 = and i64 %2702, 4294967295
  store i64 %2704, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__esi.exit3105

routine_idivl__esi.exit3105:                      ; preds = %2701, %2699
  %2705 = phi i64 [ %.pre250, %2699 ], [ %2691, %2701 ]
  %2706 = phi i64 [ %.pre249, %2699 ], [ %2703, %2701 ]
  %2707 = phi %struct.Memory* [ %2700, %2699 ], [ %2676, %2701 ]
  %2708 = trunc i64 %2706 to i32
  %2709 = shl i32 %2708, 1
  %2710 = icmp slt i32 %2708, 0
  %2711 = icmp slt i32 %2709, 0
  %2712 = xor i1 %2710, %2711
  %2713 = zext i32 %2709 to i64
  store i64 %2713, i64* %RAX.i893, align 8
  %.lobit84 = lshr i32 %2708, 31
  %2714 = trunc i32 %.lobit84 to i8
  store i8 %2714, i8* %19, align 1
  %2715 = and i32 %2709, 254
  %2716 = tail call i32 @llvm.ctpop.i32(i32 %2715)
  %2717 = trunc i32 %2716 to i8
  %2718 = and i8 %2717, 1
  %2719 = xor i8 %2718, 1
  store i8 %2719, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %2720 = icmp eq i32 %2709, 0
  %2721 = zext i1 %2720 to i8
  store i8 %2721, i8* %34, align 1
  %2722 = lshr i32 %2708, 30
  %2723 = trunc i32 %2722 to i8
  %2724 = and i8 %2723, 1
  store i8 %2724, i8* %37, align 1
  %2725 = zext i1 %2712 to i8
  store i8 %2725, i8* %43, align 1
  %2726 = load i64, i64* %RBP.i, align 8
  %2727 = add i64 %2726, -128
  %2728 = add i64 %2705, 5
  store i64 %2728, i64* %3, align 8
  %2729 = inttoptr i64 %2727 to i32*
  %2730 = load i32, i32* %2729, align 4
  %2731 = add i32 %2709, %2730
  %2732 = zext i32 %2731 to i64
  store i64 %2732, i64* %RDI.i3116, align 8
  %2733 = icmp ult i32 %2731, %2730
  %2734 = icmp ult i32 %2731, %2709
  %2735 = or i1 %2733, %2734
  %2736 = zext i1 %2735 to i8
  store i8 %2736, i8* %19, align 1
  %2737 = and i32 %2731, 255
  %2738 = tail call i32 @llvm.ctpop.i32(i32 %2737)
  %2739 = trunc i32 %2738 to i8
  %2740 = and i8 %2739, 1
  %2741 = xor i8 %2740, 1
  store i8 %2741, i8* %26, align 1
  %2742 = xor i32 %2709, %2730
  %2743 = xor i32 %2742, %2731
  %2744 = lshr i32 %2743, 4
  %2745 = trunc i32 %2744 to i8
  %2746 = and i8 %2745, 1
  store i8 %2746, i8* %31, align 1
  %2747 = icmp eq i32 %2731, 0
  %2748 = zext i1 %2747 to i8
  store i8 %2748, i8* %34, align 1
  %2749 = lshr i32 %2731, 31
  %2750 = trunc i32 %2749 to i8
  store i8 %2750, i8* %37, align 1
  %2751 = lshr i32 %2730, 31
  %2752 = lshr i32 %2708, 30
  %2753 = and i32 %2752, 1
  %2754 = xor i32 %2749, %2751
  %2755 = xor i32 %2749, %2753
  %2756 = add nuw nsw i32 %2754, %2755
  %2757 = icmp eq i32 %2756, 2
  %2758 = zext i1 %2757 to i8
  store i8 %2758, i8* %43, align 1
  %2759 = sext i32 %2731 to i64
  store i64 %2759, i64* %R8.i3094, align 8
  %2760 = load i64, i64* %RCX.i1197, align 8
  %2761 = shl nsw i64 %2759, 2
  %2762 = add nsw i64 %2761, 488
  %2763 = add i64 %2762, %2760
  %2764 = add i64 %2705, 19
  store i64 %2764, i64* %3, align 8
  %2765 = inttoptr i64 %2763 to i32*
  %2766 = load i32, i32* %2765, align 4
  %2767 = add i32 %2766, -1
  %2768 = icmp eq i32 %2766, 0
  %2769 = zext i1 %2768 to i8
  store i8 %2769, i8* %19, align 1
  %2770 = and i32 %2767, 255
  %2771 = tail call i32 @llvm.ctpop.i32(i32 %2770)
  %2772 = trunc i32 %2771 to i8
  %2773 = and i8 %2772, 1
  %2774 = xor i8 %2773, 1
  store i8 %2774, i8* %26, align 1
  %2775 = xor i32 %2767, %2766
  %2776 = lshr i32 %2775, 4
  %2777 = trunc i32 %2776 to i8
  %2778 = and i8 %2777, 1
  store i8 %2778, i8* %31, align 1
  %2779 = icmp eq i32 %2767, 0
  %2780 = zext i1 %2779 to i8
  store i8 %2780, i8* %34, align 1
  %2781 = lshr i32 %2767, 31
  %2782 = trunc i32 %2781 to i8
  store i8 %2782, i8* %37, align 1
  %2783 = lshr i32 %2766, 31
  %2784 = xor i32 %2781, %2783
  %2785 = add nuw nsw i32 %2784, %2783
  %2786 = icmp eq i32 %2785, 2
  %2787 = zext i1 %2786 to i8
  store i8 %2787, i8* %43, align 1
  %.v342 = select i1 %2779, i64 67, i64 25
  %2788 = add i64 %2705, %.v342
  store i64 %2788, i64* %3, align 8
  br i1 %2779, label %block_.L_48e48a, label %block_48e460

block_48e460:                                     ; preds = %routine_idivl__esi.exit3105
  %2789 = add i64 %2726, -56
  %2790 = add i64 %2788, 4
  store i64 %2790, i64* %3, align 8
  %2791 = inttoptr i64 %2789 to i64*
  %2792 = load i64, i64* %2791, align 8
  store i64 %2792, i64* %RAX.i893, align 8
  %2793 = add i64 %2792, 72
  %2794 = add i64 %2788, 8
  store i64 %2794, i64* %3, align 8
  %2795 = inttoptr i64 %2793 to i32*
  %2796 = load i32, i32* %2795, align 4
  %2797 = add i32 %2796, -9
  %2798 = icmp ult i32 %2796, 9
  %2799 = zext i1 %2798 to i8
  store i8 %2799, i8* %19, align 1
  %2800 = and i32 %2797, 255
  %2801 = tail call i32 @llvm.ctpop.i32(i32 %2800)
  %2802 = trunc i32 %2801 to i8
  %2803 = and i8 %2802, 1
  %2804 = xor i8 %2803, 1
  store i8 %2804, i8* %26, align 1
  %2805 = xor i32 %2797, %2796
  %2806 = lshr i32 %2805, 4
  %2807 = trunc i32 %2806 to i8
  %2808 = and i8 %2807, 1
  store i8 %2808, i8* %31, align 1
  %2809 = icmp eq i32 %2797, 0
  %2810 = zext i1 %2809 to i8
  store i8 %2810, i8* %34, align 1
  %2811 = lshr i32 %2797, 31
  %2812 = trunc i32 %2811 to i8
  store i8 %2812, i8* %37, align 1
  %2813 = lshr i32 %2796, 31
  %2814 = xor i32 %2811, %2813
  %2815 = add nuw nsw i32 %2814, %2813
  %2816 = icmp eq i32 %2815, 2
  %2817 = zext i1 %2816 to i8
  store i8 %2817, i8* %43, align 1
  %.v343 = select i1 %2809, i64 42, i64 14
  %2818 = add i64 %2788, %.v343
  store i64 %2818, i64* %3, align 8
  br i1 %2809, label %block_.L_48e48a, label %block_48e46e

block_48e46e:                                     ; preds = %block_48e460
  %2819 = add i64 %2818, 4
  store i64 %2819, i64* %3, align 8
  %2820 = load i64, i64* %2791, align 8
  store i64 %2820, i64* %RAX.i893, align 8
  %2821 = add i64 %2820, 72
  %2822 = add i64 %2818, 8
  store i64 %2822, i64* %3, align 8
  %2823 = inttoptr i64 %2821 to i32*
  %2824 = load i32, i32* %2823, align 4
  %2825 = add i32 %2824, -10
  %2826 = icmp ult i32 %2824, 10
  %2827 = zext i1 %2826 to i8
  store i8 %2827, i8* %19, align 1
  %2828 = and i32 %2825, 255
  %2829 = tail call i32 @llvm.ctpop.i32(i32 %2828)
  %2830 = trunc i32 %2829 to i8
  %2831 = and i8 %2830, 1
  %2832 = xor i8 %2831, 1
  store i8 %2832, i8* %26, align 1
  %2833 = xor i32 %2825, %2824
  %2834 = lshr i32 %2833, 4
  %2835 = trunc i32 %2834 to i8
  %2836 = and i8 %2835, 1
  store i8 %2836, i8* %31, align 1
  %2837 = icmp eq i32 %2825, 0
  %2838 = zext i1 %2837 to i8
  store i8 %2838, i8* %34, align 1
  %2839 = lshr i32 %2825, 31
  %2840 = trunc i32 %2839 to i8
  store i8 %2840, i8* %37, align 1
  %2841 = lshr i32 %2824, 31
  %2842 = xor i32 %2839, %2841
  %2843 = add nuw nsw i32 %2842, %2841
  %2844 = icmp eq i32 %2843, 2
  %2845 = zext i1 %2844 to i8
  store i8 %2845, i8* %43, align 1
  %.v344 = select i1 %2837, i64 28, i64 14
  %2846 = add i64 %2818, %.v344
  store i64 %2846, i64* %3, align 8
  br i1 %2837, label %block_.L_48e48a, label %block_48e47c

block_48e47c:                                     ; preds = %block_48e46e
  %2847 = add i64 %2846, 4
  store i64 %2847, i64* %3, align 8
  %2848 = load i64, i64* %2791, align 8
  store i64 %2848, i64* %RAX.i893, align 8
  %2849 = add i64 %2848, 72
  %2850 = add i64 %2846, 8
  store i64 %2850, i64* %3, align 8
  %2851 = inttoptr i64 %2849 to i32*
  %2852 = load i32, i32* %2851, align 4
  %2853 = add i32 %2852, -13
  %2854 = icmp ult i32 %2852, 13
  %2855 = zext i1 %2854 to i8
  store i8 %2855, i8* %19, align 1
  %2856 = and i32 %2853, 255
  %2857 = tail call i32 @llvm.ctpop.i32(i32 %2856)
  %2858 = trunc i32 %2857 to i8
  %2859 = and i8 %2858, 1
  %2860 = xor i8 %2859, 1
  store i8 %2860, i8* %26, align 1
  %2861 = xor i32 %2853, %2852
  %2862 = lshr i32 %2861, 4
  %2863 = trunc i32 %2862 to i8
  %2864 = and i8 %2863, 1
  store i8 %2864, i8* %31, align 1
  %2865 = icmp eq i32 %2853, 0
  %2866 = zext i1 %2865 to i8
  store i8 %2866, i8* %34, align 1
  %2867 = lshr i32 %2853, 31
  %2868 = trunc i32 %2867 to i8
  store i8 %2868, i8* %37, align 1
  %2869 = lshr i32 %2852, 31
  %2870 = xor i32 %2867, %2869
  %2871 = add nuw nsw i32 %2870, %2869
  %2872 = icmp eq i32 %2871, 2
  %2873 = zext i1 %2872 to i8
  store i8 %2873, i8* %43, align 1
  %.v345 = select i1 %2865, i64 14, i64 356
  %2874 = add i64 %2846, %.v345
  store i64 %2874, i64* %3, align 8
  br i1 %2865, label %block_.L_48e48a, label %block_.L_48e5e0

block_.L_48e48a:                                  ; preds = %block_48e47c, %block_48e46e, %block_48e460, %routine_idivl__esi.exit3105
  %2875 = phi i64 [ %2874, %block_48e47c ], [ %2846, %block_48e46e ], [ %2818, %block_48e460 ], [ %2788, %routine_idivl__esi.exit3105 ]
  %2876 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %2876, i64* %RAX.i893, align 8
  %2877 = add i64 %2876, 6480
  %2878 = add i64 %2875, 15
  store i64 %2878, i64* %3, align 8
  %2879 = inttoptr i64 %2877 to i64*
  %2880 = load i64, i64* %2879, align 8
  store i64 %2880, i64* %RAX.i893, align 8
  %2881 = add i64 %2875, 18
  store i64 %2881, i64* %3, align 8
  %2882 = inttoptr i64 %2880 to i64*
  %2883 = load i64, i64* %2882, align 8
  store i64 %2883, i64* %RAX.i893, align 8
  %2884 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %2884, i64* %RCX.i1197, align 8
  %2885 = add i64 %2884, 144
  %2886 = add i64 %2875, 32
  store i64 %2886, i64* %3, align 8
  %2887 = inttoptr i64 %2885 to i32*
  %2888 = load i32, i32* %2887, align 4
  %2889 = zext i32 %2888 to i64
  store i64 %2889, i64* %RDX.i1708, align 8
  %2890 = add i64 %2726, -12
  %2891 = add i64 %2875, 35
  store i64 %2891, i64* %3, align 8
  %2892 = inttoptr i64 %2890 to i32*
  %2893 = load i32, i32* %2892, align 4
  %2894 = add i32 %2893, %2888
  %2895 = zext i32 %2894 to i64
  store i64 %2895, i64* %RDX.i1708, align 8
  %2896 = icmp ult i32 %2894, %2888
  %2897 = icmp ult i32 %2894, %2893
  %2898 = or i1 %2896, %2897
  %2899 = zext i1 %2898 to i8
  store i8 %2899, i8* %19, align 1
  %2900 = and i32 %2894, 255
  %2901 = tail call i32 @llvm.ctpop.i32(i32 %2900)
  %2902 = trunc i32 %2901 to i8
  %2903 = and i8 %2902, 1
  %2904 = xor i8 %2903, 1
  store i8 %2904, i8* %26, align 1
  %2905 = xor i32 %2893, %2888
  %2906 = xor i32 %2905, %2894
  %2907 = lshr i32 %2906, 4
  %2908 = trunc i32 %2907 to i8
  %2909 = and i8 %2908, 1
  store i8 %2909, i8* %31, align 1
  %2910 = icmp eq i32 %2894, 0
  %2911 = zext i1 %2910 to i8
  store i8 %2911, i8* %34, align 1
  %2912 = lshr i32 %2894, 31
  %2913 = trunc i32 %2912 to i8
  store i8 %2913, i8* %37, align 1
  %2914 = lshr i32 %2888, 31
  %2915 = lshr i32 %2893, 31
  %2916 = xor i32 %2912, %2914
  %2917 = xor i32 %2912, %2915
  %2918 = add nuw nsw i32 %2916, %2917
  %2919 = icmp eq i32 %2918, 2
  %2920 = zext i1 %2919 to i8
  store i8 %2920, i8* %43, align 1
  %2921 = sext i32 %2894 to i64
  store i64 %2921, i64* %RCX.i1197, align 8
  %2922 = shl nsw i64 %2921, 3
  %2923 = add i64 %2883, %2922
  %2924 = add i64 %2875, 42
  store i64 %2924, i64* %3, align 8
  %2925 = inttoptr i64 %2923 to i64*
  %2926 = load i64, i64* %2925, align 8
  store i64 %2926, i64* %RAX.i893, align 8
  store i64 %2884, i64* %RCX.i1197, align 8
  %2927 = add i64 %2884, 148
  %2928 = add i64 %2875, 56
  store i64 %2928, i64* %3, align 8
  %2929 = inttoptr i64 %2927 to i32*
  %2930 = load i32, i32* %2929, align 4
  %2931 = zext i32 %2930 to i64
  store i64 %2931, i64* %RDX.i1708, align 8
  %2932 = add i64 %2726, -16
  %2933 = add i64 %2875, 59
  store i64 %2933, i64* %3, align 8
  %2934 = inttoptr i64 %2932 to i32*
  %2935 = load i32, i32* %2934, align 4
  %2936 = add i32 %2935, %2930
  %2937 = zext i32 %2936 to i64
  store i64 %2937, i64* %RDX.i1708, align 8
  %2938 = icmp ult i32 %2936, %2930
  %2939 = icmp ult i32 %2936, %2935
  %2940 = or i1 %2938, %2939
  %2941 = zext i1 %2940 to i8
  store i8 %2941, i8* %19, align 1
  %2942 = and i32 %2936, 255
  %2943 = tail call i32 @llvm.ctpop.i32(i32 %2942)
  %2944 = trunc i32 %2943 to i8
  %2945 = and i8 %2944, 1
  %2946 = xor i8 %2945, 1
  store i8 %2946, i8* %26, align 1
  %2947 = xor i32 %2935, %2930
  %2948 = xor i32 %2947, %2936
  %2949 = lshr i32 %2948, 4
  %2950 = trunc i32 %2949 to i8
  %2951 = and i8 %2950, 1
  store i8 %2951, i8* %31, align 1
  %2952 = icmp eq i32 %2936, 0
  %2953 = zext i1 %2952 to i8
  store i8 %2953, i8* %34, align 1
  %2954 = lshr i32 %2936, 31
  %2955 = trunc i32 %2954 to i8
  store i8 %2955, i8* %37, align 1
  %2956 = lshr i32 %2930, 31
  %2957 = lshr i32 %2935, 31
  %2958 = xor i32 %2954, %2956
  %2959 = xor i32 %2954, %2957
  %2960 = add nuw nsw i32 %2958, %2959
  %2961 = icmp eq i32 %2960, 2
  %2962 = zext i1 %2961 to i8
  store i8 %2962, i8* %43, align 1
  %2963 = sext i32 %2936 to i64
  store i64 %2963, i64* %RCX.i1197, align 8
  %2964 = shl nsw i64 %2963, 1
  %2965 = add i64 %2926, %2964
  %2966 = add i64 %2875, 68
  store i64 %2966, i64* %3, align 8
  %2967 = inttoptr i64 %2965 to i16*
  store i16 -1, i16* %2967, align 2
  %2968 = load i64, i64* %3, align 8
  %2969 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %2969, i64* %RAX.i893, align 8
  %2970 = add i64 %2969, 6488
  %2971 = add i64 %2968, 15
  store i64 %2971, i64* %3, align 8
  %2972 = inttoptr i64 %2970 to i64*
  %2973 = load i64, i64* %2972, align 8
  store i64 %2973, i64* %RAX.i893, align 8
  %2974 = add i64 %2968, 18
  store i64 %2974, i64* %3, align 8
  %2975 = inttoptr i64 %2973 to i64*
  %2976 = load i64, i64* %2975, align 8
  store i64 %2976, i64* %RAX.i893, align 8
  %2977 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %2977, i64* %RCX.i1197, align 8
  %2978 = add i64 %2977, 144
  %2979 = add i64 %2968, 32
  store i64 %2979, i64* %3, align 8
  %2980 = inttoptr i64 %2978 to i32*
  %2981 = load i32, i32* %2980, align 4
  %2982 = zext i32 %2981 to i64
  store i64 %2982, i64* %RDX.i1708, align 8
  %2983 = load i64, i64* %RBP.i, align 8
  %2984 = add i64 %2983, -12
  %2985 = add i64 %2968, 35
  store i64 %2985, i64* %3, align 8
  %2986 = inttoptr i64 %2984 to i32*
  %2987 = load i32, i32* %2986, align 4
  %2988 = add i32 %2987, %2981
  %2989 = zext i32 %2988 to i64
  store i64 %2989, i64* %RDX.i1708, align 8
  %2990 = icmp ult i32 %2988, %2981
  %2991 = icmp ult i32 %2988, %2987
  %2992 = or i1 %2990, %2991
  %2993 = zext i1 %2992 to i8
  store i8 %2993, i8* %19, align 1
  %2994 = and i32 %2988, 255
  %2995 = tail call i32 @llvm.ctpop.i32(i32 %2994)
  %2996 = trunc i32 %2995 to i8
  %2997 = and i8 %2996, 1
  %2998 = xor i8 %2997, 1
  store i8 %2998, i8* %26, align 1
  %2999 = xor i32 %2987, %2981
  %3000 = xor i32 %2999, %2988
  %3001 = lshr i32 %3000, 4
  %3002 = trunc i32 %3001 to i8
  %3003 = and i8 %3002, 1
  store i8 %3003, i8* %31, align 1
  %3004 = icmp eq i32 %2988, 0
  %3005 = zext i1 %3004 to i8
  store i8 %3005, i8* %34, align 1
  %3006 = lshr i32 %2988, 31
  %3007 = trunc i32 %3006 to i8
  store i8 %3007, i8* %37, align 1
  %3008 = lshr i32 %2981, 31
  %3009 = lshr i32 %2987, 31
  %3010 = xor i32 %3006, %3008
  %3011 = xor i32 %3006, %3009
  %3012 = add nuw nsw i32 %3010, %3011
  %3013 = icmp eq i32 %3012, 2
  %3014 = zext i1 %3013 to i8
  store i8 %3014, i8* %43, align 1
  %3015 = sext i32 %2988 to i64
  store i64 %3015, i64* %RCX.i1197, align 8
  %3016 = shl nsw i64 %3015, 3
  %3017 = add i64 %2976, %3016
  %3018 = add i64 %2968, 42
  store i64 %3018, i64* %3, align 8
  %3019 = inttoptr i64 %3017 to i64*
  %3020 = load i64, i64* %3019, align 8
  store i64 %3020, i64* %RAX.i893, align 8
  store i64 %2977, i64* %RCX.i1197, align 8
  %3021 = add i64 %2977, 148
  %3022 = add i64 %2968, 56
  store i64 %3022, i64* %3, align 8
  %3023 = inttoptr i64 %3021 to i32*
  %3024 = load i32, i32* %3023, align 4
  %3025 = zext i32 %3024 to i64
  store i64 %3025, i64* %RDX.i1708, align 8
  %3026 = add i64 %2983, -16
  %3027 = add i64 %2968, 59
  store i64 %3027, i64* %3, align 8
  %3028 = inttoptr i64 %3026 to i32*
  %3029 = load i32, i32* %3028, align 4
  %3030 = add i32 %3029, %3024
  %3031 = zext i32 %3030 to i64
  store i64 %3031, i64* %RDX.i1708, align 8
  %3032 = icmp ult i32 %3030, %3024
  %3033 = icmp ult i32 %3030, %3029
  %3034 = or i1 %3032, %3033
  %3035 = zext i1 %3034 to i8
  store i8 %3035, i8* %19, align 1
  %3036 = and i32 %3030, 255
  %3037 = tail call i32 @llvm.ctpop.i32(i32 %3036)
  %3038 = trunc i32 %3037 to i8
  %3039 = and i8 %3038, 1
  %3040 = xor i8 %3039, 1
  store i8 %3040, i8* %26, align 1
  %3041 = xor i32 %3029, %3024
  %3042 = xor i32 %3041, %3030
  %3043 = lshr i32 %3042, 4
  %3044 = trunc i32 %3043 to i8
  %3045 = and i8 %3044, 1
  store i8 %3045, i8* %31, align 1
  %3046 = icmp eq i32 %3030, 0
  %3047 = zext i1 %3046 to i8
  store i8 %3047, i8* %34, align 1
  %3048 = lshr i32 %3030, 31
  %3049 = trunc i32 %3048 to i8
  store i8 %3049, i8* %37, align 1
  %3050 = lshr i32 %3024, 31
  %3051 = lshr i32 %3029, 31
  %3052 = xor i32 %3048, %3050
  %3053 = xor i32 %3048, %3051
  %3054 = add nuw nsw i32 %3052, %3053
  %3055 = icmp eq i32 %3054, 2
  %3056 = zext i1 %3055 to i8
  store i8 %3056, i8* %43, align 1
  %3057 = sext i32 %3030 to i64
  store i64 %3057, i64* %RCX.i1197, align 8
  %3058 = shl nsw i64 %3057, 3
  %3059 = add i64 %3020, %3058
  %3060 = add i64 %2968, 70
  store i64 %3060, i64* %3, align 8
  %3061 = inttoptr i64 %3059 to i64*
  store i64 -1, i64* %3061, align 8
  %3062 = load i64, i64* %3, align 8
  %3063 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %3063, i64* %RAX.i893, align 8
  %3064 = add i64 %3063, 6504
  %3065 = add i64 %3062, 15
  store i64 %3065, i64* %3, align 8
  %3066 = inttoptr i64 %3064 to i64*
  %3067 = load i64, i64* %3066, align 8
  store i64 %3067, i64* %RAX.i893, align 8
  %3068 = add i64 %3062, 18
  store i64 %3068, i64* %3, align 8
  %3069 = inttoptr i64 %3067 to i64*
  %3070 = load i64, i64* %3069, align 8
  store i64 %3070, i64* %RAX.i893, align 8
  %3071 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %3071, i64* %RCX.i1197, align 8
  %3072 = add i64 %3071, 144
  %3073 = add i64 %3062, 32
  store i64 %3073, i64* %3, align 8
  %3074 = inttoptr i64 %3072 to i32*
  %3075 = load i32, i32* %3074, align 4
  %3076 = zext i32 %3075 to i64
  store i64 %3076, i64* %RDX.i1708, align 8
  %3077 = load i64, i64* %RBP.i, align 8
  %3078 = add i64 %3077, -12
  %3079 = add i64 %3062, 35
  store i64 %3079, i64* %3, align 8
  %3080 = inttoptr i64 %3078 to i32*
  %3081 = load i32, i32* %3080, align 4
  %3082 = add i32 %3081, %3075
  %3083 = zext i32 %3082 to i64
  store i64 %3083, i64* %RDX.i1708, align 8
  %3084 = icmp ult i32 %3082, %3075
  %3085 = icmp ult i32 %3082, %3081
  %3086 = or i1 %3084, %3085
  %3087 = zext i1 %3086 to i8
  store i8 %3087, i8* %19, align 1
  %3088 = and i32 %3082, 255
  %3089 = tail call i32 @llvm.ctpop.i32(i32 %3088)
  %3090 = trunc i32 %3089 to i8
  %3091 = and i8 %3090, 1
  %3092 = xor i8 %3091, 1
  store i8 %3092, i8* %26, align 1
  %3093 = xor i32 %3081, %3075
  %3094 = xor i32 %3093, %3082
  %3095 = lshr i32 %3094, 4
  %3096 = trunc i32 %3095 to i8
  %3097 = and i8 %3096, 1
  store i8 %3097, i8* %31, align 1
  %3098 = icmp eq i32 %3082, 0
  %3099 = zext i1 %3098 to i8
  store i8 %3099, i8* %34, align 1
  %3100 = lshr i32 %3082, 31
  %3101 = trunc i32 %3100 to i8
  store i8 %3101, i8* %37, align 1
  %3102 = lshr i32 %3075, 31
  %3103 = lshr i32 %3081, 31
  %3104 = xor i32 %3100, %3102
  %3105 = xor i32 %3100, %3103
  %3106 = add nuw nsw i32 %3104, %3105
  %3107 = icmp eq i32 %3106, 2
  %3108 = zext i1 %3107 to i8
  store i8 %3108, i8* %43, align 1
  %3109 = sext i32 %3082 to i64
  store i64 %3109, i64* %RCX.i1197, align 8
  %3110 = shl nsw i64 %3109, 3
  %3111 = add i64 %3070, %3110
  %3112 = add i64 %3062, 42
  store i64 %3112, i64* %3, align 8
  %3113 = inttoptr i64 %3111 to i64*
  %3114 = load i64, i64* %3113, align 8
  store i64 %3114, i64* %RAX.i893, align 8
  store i64 %3071, i64* %RCX.i1197, align 8
  %3115 = add i64 %3071, 148
  %3116 = add i64 %3062, 56
  store i64 %3116, i64* %3, align 8
  %3117 = inttoptr i64 %3115 to i32*
  %3118 = load i32, i32* %3117, align 4
  %3119 = zext i32 %3118 to i64
  store i64 %3119, i64* %RDX.i1708, align 8
  %3120 = add i64 %3077, -16
  %3121 = add i64 %3062, 59
  store i64 %3121, i64* %3, align 8
  %3122 = inttoptr i64 %3120 to i32*
  %3123 = load i32, i32* %3122, align 4
  %3124 = add i32 %3123, %3118
  %3125 = zext i32 %3124 to i64
  store i64 %3125, i64* %RDX.i1708, align 8
  %3126 = icmp ult i32 %3124, %3118
  %3127 = icmp ult i32 %3124, %3123
  %3128 = or i1 %3126, %3127
  %3129 = zext i1 %3128 to i8
  store i8 %3129, i8* %19, align 1
  %3130 = and i32 %3124, 255
  %3131 = tail call i32 @llvm.ctpop.i32(i32 %3130)
  %3132 = trunc i32 %3131 to i8
  %3133 = and i8 %3132, 1
  %3134 = xor i8 %3133, 1
  store i8 %3134, i8* %26, align 1
  %3135 = xor i32 %3123, %3118
  %3136 = xor i32 %3135, %3124
  %3137 = lshr i32 %3136, 4
  %3138 = trunc i32 %3137 to i8
  %3139 = and i8 %3138, 1
  store i8 %3139, i8* %31, align 1
  %3140 = icmp eq i32 %3124, 0
  %3141 = zext i1 %3140 to i8
  store i8 %3141, i8* %34, align 1
  %3142 = lshr i32 %3124, 31
  %3143 = trunc i32 %3142 to i8
  store i8 %3143, i8* %37, align 1
  %3144 = lshr i32 %3118, 31
  %3145 = lshr i32 %3123, 31
  %3146 = xor i32 %3142, %3144
  %3147 = xor i32 %3142, %3145
  %3148 = add nuw nsw i32 %3146, %3147
  %3149 = icmp eq i32 %3148, 2
  %3150 = zext i1 %3149 to i8
  store i8 %3150, i8* %43, align 1
  %3151 = sext i32 %3124 to i64
  store i64 %3151, i64* %RCX.i1197, align 8
  %3152 = shl nsw i64 %3151, 3
  %3153 = add i64 %3114, %3152
  %3154 = add i64 %3062, 66
  store i64 %3154, i64* %3, align 8
  %3155 = inttoptr i64 %3153 to i16**
  %3156 = load i16*, i16** %3155, align 8
  %3157 = add i64 %3062, 71
  store i64 %3157, i64* %3, align 8
  store i16 0, i16* %3156, align 2
  %3158 = load i64, i64* %3, align 8
  %3159 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %3159, i64* %RAX.i893, align 8
  %3160 = add i64 %3159, 6504
  %3161 = add i64 %3158, 15
  store i64 %3161, i64* %3, align 8
  %3162 = inttoptr i64 %3160 to i64*
  %3163 = load i64, i64* %3162, align 8
  store i64 %3163, i64* %RAX.i893, align 8
  %3164 = add i64 %3158, 18
  store i64 %3164, i64* %3, align 8
  %3165 = inttoptr i64 %3163 to i64*
  %3166 = load i64, i64* %3165, align 8
  store i64 %3166, i64* %RAX.i893, align 8
  %3167 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %3167, i64* %RCX.i1197, align 8
  %3168 = add i64 %3167, 144
  %3169 = add i64 %3158, 32
  store i64 %3169, i64* %3, align 8
  %3170 = inttoptr i64 %3168 to i32*
  %3171 = load i32, i32* %3170, align 4
  %3172 = zext i32 %3171 to i64
  store i64 %3172, i64* %RDX.i1708, align 8
  %3173 = load i64, i64* %RBP.i, align 8
  %3174 = add i64 %3173, -12
  %3175 = add i64 %3158, 35
  store i64 %3175, i64* %3, align 8
  %3176 = inttoptr i64 %3174 to i32*
  %3177 = load i32, i32* %3176, align 4
  %3178 = add i32 %3177, %3171
  %3179 = zext i32 %3178 to i64
  store i64 %3179, i64* %RDX.i1708, align 8
  %3180 = icmp ult i32 %3178, %3171
  %3181 = icmp ult i32 %3178, %3177
  %3182 = or i1 %3180, %3181
  %3183 = zext i1 %3182 to i8
  store i8 %3183, i8* %19, align 1
  %3184 = and i32 %3178, 255
  %3185 = tail call i32 @llvm.ctpop.i32(i32 %3184)
  %3186 = trunc i32 %3185 to i8
  %3187 = and i8 %3186, 1
  %3188 = xor i8 %3187, 1
  store i8 %3188, i8* %26, align 1
  %3189 = xor i32 %3177, %3171
  %3190 = xor i32 %3189, %3178
  %3191 = lshr i32 %3190, 4
  %3192 = trunc i32 %3191 to i8
  %3193 = and i8 %3192, 1
  store i8 %3193, i8* %31, align 1
  %3194 = icmp eq i32 %3178, 0
  %3195 = zext i1 %3194 to i8
  store i8 %3195, i8* %34, align 1
  %3196 = lshr i32 %3178, 31
  %3197 = trunc i32 %3196 to i8
  store i8 %3197, i8* %37, align 1
  %3198 = lshr i32 %3171, 31
  %3199 = lshr i32 %3177, 31
  %3200 = xor i32 %3196, %3198
  %3201 = xor i32 %3196, %3199
  %3202 = add nuw nsw i32 %3200, %3201
  %3203 = icmp eq i32 %3202, 2
  %3204 = zext i1 %3203 to i8
  store i8 %3204, i8* %43, align 1
  %3205 = sext i32 %3178 to i64
  store i64 %3205, i64* %RCX.i1197, align 8
  %3206 = shl nsw i64 %3205, 3
  %3207 = add i64 %3166, %3206
  %3208 = add i64 %3158, 42
  store i64 %3208, i64* %3, align 8
  %3209 = inttoptr i64 %3207 to i64*
  %3210 = load i64, i64* %3209, align 8
  store i64 %3210, i64* %RAX.i893, align 8
  store i64 %3167, i64* %RCX.i1197, align 8
  %3211 = add i64 %3167, 148
  %3212 = add i64 %3158, 56
  store i64 %3212, i64* %3, align 8
  %3213 = inttoptr i64 %3211 to i32*
  %3214 = load i32, i32* %3213, align 4
  %3215 = zext i32 %3214 to i64
  store i64 %3215, i64* %RDX.i1708, align 8
  %3216 = add i64 %3173, -16
  %3217 = add i64 %3158, 59
  store i64 %3217, i64* %3, align 8
  %3218 = inttoptr i64 %3216 to i32*
  %3219 = load i32, i32* %3218, align 4
  %3220 = add i32 %3219, %3214
  %3221 = zext i32 %3220 to i64
  store i64 %3221, i64* %RDX.i1708, align 8
  %3222 = icmp ult i32 %3220, %3214
  %3223 = icmp ult i32 %3220, %3219
  %3224 = or i1 %3222, %3223
  %3225 = zext i1 %3224 to i8
  store i8 %3225, i8* %19, align 1
  %3226 = and i32 %3220, 255
  %3227 = tail call i32 @llvm.ctpop.i32(i32 %3226)
  %3228 = trunc i32 %3227 to i8
  %3229 = and i8 %3228, 1
  %3230 = xor i8 %3229, 1
  store i8 %3230, i8* %26, align 1
  %3231 = xor i32 %3219, %3214
  %3232 = xor i32 %3231, %3220
  %3233 = lshr i32 %3232, 4
  %3234 = trunc i32 %3233 to i8
  %3235 = and i8 %3234, 1
  store i8 %3235, i8* %31, align 1
  %3236 = icmp eq i32 %3220, 0
  %3237 = zext i1 %3236 to i8
  store i8 %3237, i8* %34, align 1
  %3238 = lshr i32 %3220, 31
  %3239 = trunc i32 %3238 to i8
  store i8 %3239, i8* %37, align 1
  %3240 = lshr i32 %3214, 31
  %3241 = lshr i32 %3219, 31
  %3242 = xor i32 %3238, %3240
  %3243 = xor i32 %3238, %3241
  %3244 = add nuw nsw i32 %3242, %3243
  %3245 = icmp eq i32 %3244, 2
  %3246 = zext i1 %3245 to i8
  store i8 %3246, i8* %43, align 1
  %3247 = sext i32 %3220 to i64
  store i64 %3247, i64* %RCX.i1197, align 8
  %3248 = shl nsw i64 %3247, 3
  %3249 = add i64 %3210, %3248
  %3250 = add i64 %3158, 66
  store i64 %3250, i64* %3, align 8
  %3251 = inttoptr i64 %3249 to i64*
  %3252 = load i64, i64* %3251, align 8
  %3253 = add i64 %3252, 2
  %3254 = add i64 %3158, 72
  store i64 %3254, i64* %3, align 8
  %3255 = inttoptr i64 %3253 to i16*
  store i16 0, i16* %3255, align 2
  %3256 = load i64, i64* %3, align 8
  %3257 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %3257, i64* %RAX.i893, align 8
  %3258 = add i64 %3257, 72400
  %3259 = add i64 %3256, 15
  store i64 %3259, i64* %3, align 8
  %3260 = inttoptr i64 %3258 to i32*
  %3261 = load i32, i32* %3260, align 4
  store i8 0, i8* %19, align 1
  %3262 = and i32 %3261, 255
  %3263 = tail call i32 @llvm.ctpop.i32(i32 %3262)
  %3264 = trunc i32 %3263 to i8
  %3265 = and i8 %3264, 1
  %3266 = xor i8 %3265, 1
  store i8 %3266, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %3267 = icmp eq i32 %3261, 0
  %3268 = zext i1 %3267 to i8
  store i8 %3268, i8* %34, align 1
  %3269 = lshr i32 %3261, 31
  %3270 = trunc i32 %3269 to i8
  store i8 %3270, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v357 = select i1 %3267, i64 56, i64 21
  %3271 = add i64 %3256, %.v357
  store i64 %3271, i64* %3, align 8
  br i1 %3267, label %block_.L_48e5db, label %block_48e5b8

block_48e5b8:                                     ; preds = %block_.L_48e48a
  %3272 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %3273 = add i64 %3272, 3264
  store i64 %3273, i64* %RAX.i893, align 8
  %3274 = icmp ugt i64 %3272, -3265
  %3275 = zext i1 %3274 to i8
  store i8 %3275, i8* %19, align 1
  %3276 = trunc i64 %3273 to i32
  %3277 = and i32 %3276, 255
  %3278 = tail call i32 @llvm.ctpop.i32(i32 %3277)
  %3279 = trunc i32 %3278 to i8
  %3280 = and i8 %3279, 1
  %3281 = xor i8 %3280, 1
  store i8 %3281, i8* %26, align 1
  %3282 = xor i64 %3273, %3272
  %3283 = lshr i64 %3282, 4
  %3284 = trunc i64 %3283 to i8
  %3285 = and i8 %3284, 1
  store i8 %3285, i8* %31, align 1
  %3286 = icmp eq i64 %3273, 0
  %3287 = zext i1 %3286 to i8
  store i8 %3287, i8* %34, align 1
  %3288 = lshr i64 %3273, 63
  %3289 = trunc i64 %3288 to i8
  store i8 %3289, i8* %37, align 1
  %3290 = lshr i64 %3272, 63
  %3291 = xor i64 %3288, %3290
  %3292 = add nuw nsw i64 %3291, %3288
  %3293 = icmp eq i64 %3292, 2
  %3294 = zext i1 %3293 to i8
  store i8 %3294, i8* %43, align 1
  %3295 = load i64, i64* %RBP.i, align 8
  %3296 = add i64 %3295, -16
  %3297 = add i64 %3271, 18
  store i64 %3297, i64* %3, align 8
  %3298 = inttoptr i64 %3296 to i32*
  %3299 = load i32, i32* %3298, align 4
  %3300 = sext i32 %3299 to i64
  %3301 = shl nsw i64 %3300, 3
  store i64 %3301, i64* %RCX.i1197, align 8
  %3302 = add i64 %3301, %3273
  store i64 %3302, i64* %RAX.i893, align 8
  %3303 = icmp ult i64 %3302, %3273
  %3304 = icmp ult i64 %3302, %3301
  %3305 = or i1 %3303, %3304
  %3306 = zext i1 %3305 to i8
  store i8 %3306, i8* %19, align 1
  %3307 = trunc i64 %3302 to i32
  %3308 = and i32 %3307, 255
  %3309 = tail call i32 @llvm.ctpop.i32(i32 %3308)
  %3310 = trunc i32 %3309 to i8
  %3311 = and i8 %3310, 1
  %3312 = xor i8 %3311, 1
  store i8 %3312, i8* %26, align 1
  %3313 = xor i64 %3301, %3273
  %3314 = xor i64 %3313, %3302
  %3315 = lshr i64 %3314, 4
  %3316 = trunc i64 %3315 to i8
  %3317 = and i8 %3316, 1
  store i8 %3317, i8* %31, align 1
  %3318 = icmp eq i64 %3302, 0
  %3319 = zext i1 %3318 to i8
  store i8 %3319, i8* %34, align 1
  %3320 = lshr i64 %3302, 63
  %3321 = trunc i64 %3320 to i8
  store i8 %3321, i8* %37, align 1
  %3322 = lshr i64 %3300, 60
  %3323 = and i64 %3322, 1
  %3324 = xor i64 %3320, %3288
  %3325 = xor i64 %3320, %3323
  %3326 = add nuw nsw i64 %3324, %3325
  %3327 = icmp eq i64 %3326, 2
  %3328 = zext i1 %3327 to i8
  store i8 %3328, i8* %43, align 1
  %3329 = add i64 %3295, -12
  %3330 = add i64 %3271, 29
  store i64 %3330, i64* %3, align 8
  %3331 = inttoptr i64 %3329 to i32*
  %3332 = load i32, i32* %3331, align 4
  %3333 = sext i32 %3332 to i64
  store i64 %3333, i64* %RCX.i1197, align 8
  %3334 = shl nsw i64 %3333, 1
  %3335 = add i64 %3334, %3302
  %3336 = add i64 %3271, 35
  store i64 %3336, i64* %3, align 8
  %3337 = inttoptr i64 %3335 to i16*
  store i16 -1, i16* %3337, align 2
  %.pre278 = load i64, i64* %3, align 8
  br label %block_.L_48e5db

block_.L_48e5db:                                  ; preds = %block_48e5b8, %block_.L_48e48a
  %3338 = phi i64 [ %.pre278, %block_48e5b8 ], [ %3271, %block_.L_48e48a ]
  %3339 = add i64 %3338, 1543
  br label %block_.L_48ebe2

block_.L_48e5e0:                                  ; preds = %block_48e47c
  %3340 = add i64 %2874, 4
  store i64 %3340, i64* %3, align 8
  %3341 = load i64, i64* %2791, align 8
  store i64 %3341, i64* %RAX.i893, align 8
  %3342 = add i64 %3341, 580
  %3343 = add i64 %2874, 11
  store i64 %3343, i64* %3, align 8
  %3344 = inttoptr i64 %3342 to i32*
  %3345 = load i32, i32* %3344, align 4
  store i8 0, i8* %19, align 1
  %3346 = and i32 %3345, 255
  %3347 = tail call i32 @llvm.ctpop.i32(i32 %3346)
  %3348 = trunc i32 %3347 to i8
  %3349 = and i8 %3348, 1
  %3350 = xor i8 %3349, 1
  store i8 %3350, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %3351 = icmp eq i32 %3345, 0
  %3352 = zext i1 %3351 to i8
  store i8 %3352, i8* %34, align 1
  %3353 = lshr i32 %3345, 31
  %3354 = trunc i32 %3353 to i8
  store i8 %3354, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v346 = select i1 %3351, i64 750, i64 17
  %3355 = add i64 %2874, %.v346
  store i64 %3355, i64* %3, align 8
  br i1 %3351, label %block_.L_48e8ce, label %block_48e5f1

block_48e5f1:                                     ; preds = %block_.L_48e5e0
  store i64 2, i64* %RAX.i893, align 8
  %3356 = add i64 %3355, 9
  store i64 %3356, i64* %3, align 8
  %3357 = load i64, i64* %2791, align 8
  store i64 %3357, i64* %RCX.i1197, align 8
  %3358 = add i64 %2726, -12
  %3359 = add i64 %3355, 12
  store i64 %3359, i64* %3, align 8
  %3360 = inttoptr i64 %3358 to i32*
  %3361 = load i32, i32* %3360, align 4
  %3362 = zext i32 %3361 to i64
  store i64 %3362, i64* %RDX.i1708, align 8
  %3363 = add i64 %2726, -132
  %3364 = add i64 %3355, 18
  store i64 %3364, i64* %3, align 8
  %3365 = inttoptr i64 %3363 to i32*
  store i32 2, i32* %3365, align 4
  %3366 = load i32, i32* %EDX.i1723, align 4
  %3367 = zext i32 %3366 to i64
  %3368 = load i64, i64* %3, align 8
  store i64 %3367, i64* %RAX.i893, align 8
  %3369 = sext i32 %3366 to i64
  %3370 = lshr i64 %3369, 32
  store i64 %3370, i64* %2568, align 8
  %3371 = load i64, i64* %RBP.i, align 8
  %3372 = add i64 %3371, -132
  %3373 = add i64 %3368, 9
  store i64 %3373, i64* %3, align 8
  %3374 = inttoptr i64 %3372 to i32*
  %3375 = load i32, i32* %3374, align 4
  %3376 = zext i32 %3375 to i64
  store i64 %3376, i64* %RSI.i4020.pre-phi, align 8
  %3377 = add i64 %3368, 11
  store i64 %3377, i64* %3, align 8
  %3378 = sext i32 %3375 to i64
  %3379 = shl nuw i64 %3370, 32
  %3380 = or i64 %3379, %3367
  %3381 = sdiv i64 %3380, %3378
  %3382 = shl i64 %3381, 32
  %3383 = ashr exact i64 %3382, 32
  %3384 = icmp eq i64 %3381, %3383
  br i1 %3384, label %3387, label %3385

; <label>:3385:                                   ; preds = %block_48e5f1
  %3386 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %3377, %struct.Memory* %2707)
  %.pre251 = load i64, i64* %RBP.i, align 8
  %.pre252 = load i64, i64* %3, align 8
  %.pre253 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__esi.exit2878

; <label>:3387:                                   ; preds = %block_48e5f1
  %3388 = srem i64 %3380, %3378
  %3389 = and i64 %3381, 4294967295
  store i64 %3389, i64* %RAX.i893, align 8
  %3390 = and i64 %3388, 4294967295
  store i64 %3390, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %3391 = trunc i64 %3381 to i32
  br label %routine_idivl__esi.exit2878

routine_idivl__esi.exit2878:                      ; preds = %3387, %3385
  %3392 = phi i32 [ %.pre253, %3385 ], [ %3391, %3387 ]
  %3393 = phi i64 [ %.pre252, %3385 ], [ %3377, %3387 ]
  %3394 = phi i64 [ %.pre251, %3385 ], [ %3371, %3387 ]
  %3395 = phi %struct.Memory* [ %3386, %3385 ], [ %2707, %3387 ]
  %3396 = add i64 %3394, -16
  %3397 = add i64 %3393, 3
  store i64 %3397, i64* %3, align 8
  %3398 = inttoptr i64 %3396 to i32*
  %3399 = load i32, i32* %3398, align 4
  %3400 = zext i32 %3399 to i64
  store i64 %3400, i64* %RDI.i3116, align 8
  %3401 = add i64 %3394, -136
  %3402 = add i64 %3393, 9
  store i64 %3402, i64* %3, align 8
  %3403 = inttoptr i64 %3401 to i32*
  store i32 %3392, i32* %3403, align 4
  %3404 = load i32, i32* %EDI.i3110, align 4
  %3405 = zext i32 %3404 to i64
  %3406 = load i64, i64* %3, align 8
  store i64 %3405, i64* %RAX.i893, align 8
  %3407 = sext i32 %3404 to i64
  %3408 = lshr i64 %3407, 32
  store i64 %3408, i64* %2568, align 8
  %3409 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %3410 = add i64 %3406, 5
  store i64 %3410, i64* %3, align 8
  %3411 = sext i32 %3409 to i64
  %3412 = shl nuw i64 %3408, 32
  %3413 = or i64 %3412, %3405
  %3414 = sdiv i64 %3413, %3411
  %3415 = shl i64 %3414, 32
  %3416 = ashr exact i64 %3415, 32
  %3417 = icmp eq i64 %3414, %3416
  br i1 %3417, label %3420, label %3418

; <label>:3418:                                   ; preds = %routine_idivl__esi.exit2878
  %3419 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %3410, %struct.Memory* %3395)
  %.pre254 = load i64, i64* %RAX.i893, align 8
  %.pre255 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit2863

; <label>:3420:                                   ; preds = %routine_idivl__esi.exit2878
  %3421 = srem i64 %3413, %3411
  %3422 = and i64 %3414, 4294967295
  store i64 %3422, i64* %RAX.i893, align 8
  %3423 = and i64 %3421, 4294967295
  store i64 %3423, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__esi.exit2863

routine_idivl__esi.exit2863:                      ; preds = %3420, %3418
  %3424 = phi i64 [ %.pre255, %3418 ], [ %3410, %3420 ]
  %3425 = phi i64 [ %.pre254, %3418 ], [ %3422, %3420 ]
  %3426 = phi %struct.Memory* [ %3419, %3418 ], [ %3395, %3420 ]
  %3427 = trunc i64 %3425 to i32
  %3428 = shl i32 %3427, 1
  %3429 = icmp slt i32 %3427, 0
  %3430 = icmp slt i32 %3428, 0
  %3431 = xor i1 %3429, %3430
  %3432 = zext i32 %3428 to i64
  store i64 %3432, i64* %RAX.i893, align 8
  %.lobit89 = lshr i32 %3427, 31
  %3433 = trunc i32 %.lobit89 to i8
  store i8 %3433, i8* %19, align 1
  %3434 = and i32 %3428, 254
  %3435 = tail call i32 @llvm.ctpop.i32(i32 %3434)
  %3436 = trunc i32 %3435 to i8
  %3437 = and i8 %3436, 1
  %3438 = xor i8 %3437, 1
  store i8 %3438, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %3439 = icmp eq i32 %3428, 0
  %3440 = zext i1 %3439 to i8
  store i8 %3440, i8* %34, align 1
  %3441 = lshr i32 %3427, 30
  %3442 = trunc i32 %3441 to i8
  %3443 = and i8 %3442, 1
  store i8 %3443, i8* %37, align 1
  %3444 = zext i1 %3431 to i8
  store i8 %3444, i8* %43, align 1
  %3445 = load i64, i64* %RBP.i, align 8
  %3446 = add i64 %3445, -136
  %3447 = add i64 %3424, 8
  store i64 %3447, i64* %3, align 8
  %3448 = inttoptr i64 %3446 to i32*
  %3449 = load i32, i32* %3448, align 4
  %3450 = add i32 %3428, %3449
  %3451 = zext i32 %3450 to i64
  store i64 %3451, i64* %RDI.i3116, align 8
  %3452 = icmp ult i32 %3450, %3449
  %3453 = icmp ult i32 %3450, %3428
  %3454 = or i1 %3452, %3453
  %3455 = zext i1 %3454 to i8
  store i8 %3455, i8* %19, align 1
  %3456 = and i32 %3450, 255
  %3457 = tail call i32 @llvm.ctpop.i32(i32 %3456)
  %3458 = trunc i32 %3457 to i8
  %3459 = and i8 %3458, 1
  %3460 = xor i8 %3459, 1
  store i8 %3460, i8* %26, align 1
  %3461 = xor i32 %3428, %3449
  %3462 = xor i32 %3461, %3450
  %3463 = lshr i32 %3462, 4
  %3464 = trunc i32 %3463 to i8
  %3465 = and i8 %3464, 1
  store i8 %3465, i8* %31, align 1
  %3466 = icmp eq i32 %3450, 0
  %3467 = zext i1 %3466 to i8
  store i8 %3467, i8* %34, align 1
  %3468 = lshr i32 %3450, 31
  %3469 = trunc i32 %3468 to i8
  store i8 %3469, i8* %37, align 1
  %3470 = lshr i32 %3449, 31
  %3471 = lshr i32 %3427, 30
  %3472 = and i32 %3471, 1
  %3473 = xor i32 %3468, %3470
  %3474 = xor i32 %3468, %3472
  %3475 = add nuw nsw i32 %3473, %3474
  %3476 = icmp eq i32 %3475, 2
  %3477 = zext i1 %3476 to i8
  store i8 %3477, i8* %43, align 1
  %3478 = sext i32 %3450 to i64
  store i64 %3478, i64* %R8.i3094, align 8
  %3479 = load i64, i64* %RCX.i1197, align 8
  %3480 = shl nsw i64 %3478, 2
  %3481 = add nsw i64 %3480, 488
  %3482 = add i64 %3481, %3479
  %3483 = add i64 %3424, 22
  store i64 %3483, i64* %3, align 8
  %3484 = inttoptr i64 %3482 to i32*
  %3485 = load i32, i32* %3484, align 4
  %3486 = add i32 %3485, -2
  %3487 = icmp ult i32 %3485, 2
  %3488 = zext i1 %3487 to i8
  store i8 %3488, i8* %19, align 1
  %3489 = and i32 %3486, 255
  %3490 = tail call i32 @llvm.ctpop.i32(i32 %3489)
  %3491 = trunc i32 %3490 to i8
  %3492 = and i8 %3491, 1
  %3493 = xor i8 %3492, 1
  store i8 %3493, i8* %26, align 1
  %3494 = xor i32 %3486, %3485
  %3495 = lshr i32 %3494, 4
  %3496 = trunc i32 %3495 to i8
  %3497 = and i8 %3496, 1
  store i8 %3497, i8* %31, align 1
  %3498 = icmp eq i32 %3486, 0
  %3499 = zext i1 %3498 to i8
  store i8 %3499, i8* %34, align 1
  %3500 = lshr i32 %3486, 31
  %3501 = trunc i32 %3500 to i8
  store i8 %3501, i8* %37, align 1
  %3502 = lshr i32 %3485, 31
  %3503 = xor i32 %3500, %3502
  %3504 = add nuw nsw i32 %3503, %3502
  %3505 = icmp eq i32 %3504, 2
  %3506 = zext i1 %3505 to i8
  store i8 %3506, i8* %43, align 1
  %.v347 = select i1 %3498, i64 28, i64 689
  %3507 = add i64 %3424, %.v347
  store i64 %3507, i64* %3, align 8
  br i1 %3498, label %block_48e639, label %block_.L_48e8ce

block_48e639:                                     ; preds = %routine_idivl__esi.exit2863
  %3508 = add i64 %3445, -56
  %3509 = add i64 %3507, 4
  store i64 %3509, i64* %3, align 8
  %3510 = inttoptr i64 %3508 to i64*
  %3511 = load i64, i64* %3510, align 8
  store i64 %3511, i64* %RAX.i893, align 8
  %3512 = add i64 %3511, 72
  %3513 = add i64 %3507, 8
  store i64 %3513, i64* %3, align 8
  %3514 = inttoptr i64 %3512 to i32*
  %3515 = load i32, i32* %3514, align 4
  %3516 = add i32 %3515, -1
  %3517 = icmp eq i32 %3515, 0
  %3518 = zext i1 %3517 to i8
  store i8 %3518, i8* %19, align 1
  %3519 = and i32 %3516, 255
  %3520 = tail call i32 @llvm.ctpop.i32(i32 %3519)
  %3521 = trunc i32 %3520 to i8
  %3522 = and i8 %3521, 1
  %3523 = xor i8 %3522, 1
  store i8 %3523, i8* %26, align 1
  %3524 = xor i32 %3516, %3515
  %3525 = lshr i32 %3524, 4
  %3526 = trunc i32 %3525 to i8
  %3527 = and i8 %3526, 1
  store i8 %3527, i8* %31, align 1
  %3528 = icmp eq i32 %3516, 0
  %3529 = zext i1 %3528 to i8
  store i8 %3529, i8* %34, align 1
  %3530 = lshr i32 %3516, 31
  %3531 = trunc i32 %3530 to i8
  store i8 %3531, i8* %37, align 1
  %3532 = lshr i32 %3515, 31
  %3533 = xor i32 %3530, %3532
  %3534 = add nuw nsw i32 %3533, %3532
  %3535 = icmp eq i32 %3534, 2
  %3536 = zext i1 %3535 to i8
  store i8 %3536, i8* %43, align 1
  %.v354 = select i1 %3528, i64 14, i64 661
  %3537 = add i64 %3507, %.v354
  store i64 %3537, i64* %3, align 8
  br i1 %3528, label %block_48e647, label %block_.L_48e8ce

block_48e647:                                     ; preds = %block_48e639
  %3538 = add i64 %3537, 4
  store i64 %3538, i64* %3, align 8
  %3539 = load i64, i64* %3510, align 8
  store i64 %3539, i64* %RAX.i893, align 8
  %3540 = add i64 %3539, 580
  %3541 = add i64 %3537, 11
  store i64 %3541, i64* %3, align 8
  %3542 = inttoptr i64 %3540 to i32*
  %3543 = load i32, i32* %3542, align 4
  %3544 = add i32 %3543, -1
  %3545 = icmp eq i32 %3543, 0
  %3546 = zext i1 %3545 to i8
  store i8 %3546, i8* %19, align 1
  %3547 = and i32 %3544, 255
  %3548 = tail call i32 @llvm.ctpop.i32(i32 %3547)
  %3549 = trunc i32 %3548 to i8
  %3550 = and i8 %3549, 1
  %3551 = xor i8 %3550, 1
  store i8 %3551, i8* %26, align 1
  %3552 = xor i32 %3544, %3543
  %3553 = lshr i32 %3552, 4
  %3554 = trunc i32 %3553 to i8
  %3555 = and i8 %3554, 1
  store i8 %3555, i8* %31, align 1
  %3556 = icmp eq i32 %3544, 0
  %3557 = zext i1 %3556 to i8
  store i8 %3557, i8* %34, align 1
  %3558 = lshr i32 %3544, 31
  %3559 = trunc i32 %3558 to i8
  store i8 %3559, i8* %37, align 1
  %3560 = lshr i32 %3543, 31
  %3561 = xor i32 %3558, %3560
  %3562 = add nuw nsw i32 %3561, %3560
  %3563 = icmp eq i32 %3562, 2
  %3564 = zext i1 %3563 to i8
  store i8 %3564, i8* %43, align 1
  %.v355 = select i1 %3556, i64 17, i64 44
  %3565 = add i64 %3537, %.v355
  %3566 = add i64 %3565, 8
  store i64 %3566, i64* %3, align 8
  %3567 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %3567, i64* %RAX.i893, align 8
  br i1 %3556, label %block_48e658, label %block_.L_48e673

block_48e658:                                     ; preds = %block_48e647
  %3568 = add i64 %3567, 71936
  %3569 = add i64 %3565, 15
  store i64 %3569, i64* %3, align 8
  %3570 = inttoptr i64 %3568 to i64*
  %3571 = load i64, i64* %3570, align 8
  store i64 %3571, i64* %RAX.i893, align 8
  %3572 = add i64 %3445, -144
  %3573 = add i64 %3565, 22
  store i64 %3573, i64* %3, align 8
  %3574 = inttoptr i64 %3572 to i64*
  store i64 %3571, i64* %3574, align 8
  %3575 = load i64, i64* %3, align 8
  %3576 = add i64 %3575, 27
  store i64 %3576, i64* %3, align 8
  br label %block_.L_48e689

block_.L_48e673:                                  ; preds = %block_48e647
  %3577 = add i64 %3567, 71944
  %3578 = add i64 %3565, 15
  store i64 %3578, i64* %3, align 8
  %3579 = inttoptr i64 %3577 to i64*
  %3580 = load i64, i64* %3579, align 8
  store i64 %3580, i64* %RAX.i893, align 8
  %3581 = add i64 %3445, -144
  %3582 = add i64 %3565, 22
  store i64 %3582, i64* %3, align 8
  %3583 = inttoptr i64 %3581 to i64*
  store i64 %3580, i64* %3583, align 8
  %.pre256 = load i64, i64* %3, align 8
  br label %block_.L_48e689

block_.L_48e689:                                  ; preds = %block_.L_48e673, %block_48e658
  %3584 = phi i64 [ %.pre256, %block_.L_48e673 ], [ %3576, %block_48e658 ]
  %3585 = load i64, i64* %RBP.i, align 8
  %3586 = add i64 %3585, -144
  %3587 = add i64 %3584, 7
  store i64 %3587, i64* %3, align 8
  %3588 = inttoptr i64 %3586 to i64*
  %3589 = load i64, i64* %3588, align 8
  store i64 2, i64* %RCX.i1197, align 8
  %3590 = add i64 %3585, -104
  %3591 = add i64 %3584, 16
  store i64 %3591, i64* %3, align 8
  %3592 = inttoptr i64 %3590 to i64*
  store i64 %3589, i64* %3592, align 8
  %3593 = load i64, i64* %3, align 8
  %3594 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %3594, i64* %RAX.i893, align 8
  %3595 = add i64 %3594, 6480
  %3596 = add i64 %3593, 15
  store i64 %3596, i64* %3, align 8
  %3597 = inttoptr i64 %3595 to i64*
  %3598 = load i64, i64* %3597, align 8
  store i64 %3598, i64* %RAX.i893, align 8
  %3599 = add i64 %3593, 18
  store i64 %3599, i64* %3, align 8
  %3600 = inttoptr i64 %3598 to i64*
  %3601 = load i64, i64* %3600, align 8
  store i64 %3601, i64* %RAX.i893, align 8
  %3602 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %3602, i64* %RDX.i1708, align 8
  %3603 = add i64 %3602, 144
  %3604 = add i64 %3593, 32
  store i64 %3604, i64* %3, align 8
  %3605 = inttoptr i64 %3603 to i32*
  %3606 = load i32, i32* %3605, align 4
  %3607 = zext i32 %3606 to i64
  store i64 %3607, i64* %RSI.i4020.pre-phi, align 8
  %3608 = load i64, i64* %RBP.i, align 8
  %3609 = add i64 %3608, -12
  %3610 = add i64 %3593, 35
  store i64 %3610, i64* %3, align 8
  %3611 = inttoptr i64 %3609 to i32*
  %3612 = load i32, i32* %3611, align 4
  %3613 = add i32 %3612, %3606
  %3614 = zext i32 %3613 to i64
  store i64 %3614, i64* %RSI.i4020.pre-phi, align 8
  %3615 = icmp ult i32 %3613, %3606
  %3616 = icmp ult i32 %3613, %3612
  %3617 = or i1 %3615, %3616
  %3618 = zext i1 %3617 to i8
  store i8 %3618, i8* %19, align 1
  %3619 = and i32 %3613, 255
  %3620 = tail call i32 @llvm.ctpop.i32(i32 %3619)
  %3621 = trunc i32 %3620 to i8
  %3622 = and i8 %3621, 1
  %3623 = xor i8 %3622, 1
  store i8 %3623, i8* %26, align 1
  %3624 = xor i32 %3612, %3606
  %3625 = xor i32 %3624, %3613
  %3626 = lshr i32 %3625, 4
  %3627 = trunc i32 %3626 to i8
  %3628 = and i8 %3627, 1
  store i8 %3628, i8* %31, align 1
  %3629 = icmp eq i32 %3613, 0
  %3630 = zext i1 %3629 to i8
  store i8 %3630, i8* %34, align 1
  %3631 = lshr i32 %3613, 31
  %3632 = trunc i32 %3631 to i8
  store i8 %3632, i8* %37, align 1
  %3633 = lshr i32 %3606, 31
  %3634 = lshr i32 %3612, 31
  %3635 = xor i32 %3631, %3633
  %3636 = xor i32 %3631, %3634
  %3637 = add nuw nsw i32 %3635, %3636
  %3638 = icmp eq i32 %3637, 2
  %3639 = zext i1 %3638 to i8
  store i8 %3639, i8* %43, align 1
  %3640 = sext i32 %3613 to i64
  store i64 %3640, i64* %RDX.i1708, align 8
  %3641 = shl nsw i64 %3640, 3
  %3642 = add i64 %3601, %3641
  %3643 = add i64 %3593, 42
  store i64 %3643, i64* %3, align 8
  %3644 = inttoptr i64 %3642 to i64*
  %3645 = load i64, i64* %3644, align 8
  store i64 %3645, i64* %RAX.i893, align 8
  store i64 %3602, i64* %RDX.i1708, align 8
  %3646 = add i64 %3602, 148
  %3647 = add i64 %3593, 56
  store i64 %3647, i64* %3, align 8
  %3648 = inttoptr i64 %3646 to i32*
  %3649 = load i32, i32* %3648, align 4
  %3650 = zext i32 %3649 to i64
  store i64 %3650, i64* %RSI.i4020.pre-phi, align 8
  %3651 = add i64 %3608, -16
  %3652 = add i64 %3593, 59
  store i64 %3652, i64* %3, align 8
  %3653 = inttoptr i64 %3651 to i32*
  %3654 = load i32, i32* %3653, align 4
  %3655 = add i32 %3654, %3649
  %3656 = zext i32 %3655 to i64
  store i64 %3656, i64* %RSI.i4020.pre-phi, align 8
  %3657 = sext i32 %3655 to i64
  store i64 %3657, i64* %RDX.i1708, align 8
  %3658 = shl nsw i64 %3657, 1
  %3659 = add i64 %3645, %3658
  %3660 = add i64 %3593, 68
  store i64 %3660, i64* %3, align 8
  %3661 = inttoptr i64 %3659 to i16*
  store i16 0, i16* %3661, align 2
  %3662 = load i64, i64* %3, align 8
  %3663 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  %3664 = add i64 %3663, 24
  store i64 %3664, i64* %RAX.i893, align 8
  %3665 = icmp ugt i64 %3663, -25
  %3666 = zext i1 %3665 to i8
  store i8 %3666, i8* %19, align 1
  %3667 = trunc i64 %3664 to i32
  %3668 = and i32 %3667, 255
  %3669 = tail call i32 @llvm.ctpop.i32(i32 %3668)
  %3670 = trunc i32 %3669 to i8
  %3671 = and i8 %3670, 1
  %3672 = xor i8 %3671, 1
  store i8 %3672, i8* %26, align 1
  %3673 = xor i64 %3663, 16
  %3674 = xor i64 %3673, %3664
  %3675 = lshr i64 %3674, 4
  %3676 = trunc i64 %3675 to i8
  %3677 = and i8 %3676, 1
  store i8 %3677, i8* %31, align 1
  %3678 = icmp eq i64 %3664, 0
  %3679 = zext i1 %3678 to i8
  store i8 %3679, i8* %34, align 1
  %3680 = lshr i64 %3664, 63
  %3681 = trunc i64 %3680 to i8
  store i8 %3681, i8* %37, align 1
  %3682 = lshr i64 %3663, 63
  %3683 = xor i64 %3680, %3682
  %3684 = add nuw nsw i64 %3683, %3680
  %3685 = icmp eq i64 %3684, 2
  %3686 = zext i1 %3685 to i8
  store i8 %3686, i8* %43, align 1
  %3687 = load i64, i64* %RBP.i, align 8
  %3688 = add i64 %3687, -92
  %3689 = add i64 %3662, 15
  store i64 %3689, i64* %3, align 8
  %3690 = inttoptr i64 %3688 to i32*
  %3691 = load i32, i32* %3690, align 4
  %3692 = zext i32 %3691 to i64
  store i64 %3692, i64* %RSI.i4020.pre-phi, align 8
  %3693 = sext i32 %3691 to i64
  %3694 = mul nsw i64 %3693, 264
  store i64 %3694, i64* %RDX.i1708, align 8
  %3695 = lshr i64 %3694, 63
  %3696 = add i64 %3694, %3664
  store i64 %3696, i64* %RAX.i893, align 8
  %3697 = icmp ult i64 %3696, %3664
  %3698 = icmp ult i64 %3696, %3694
  %3699 = or i1 %3697, %3698
  %3700 = zext i1 %3699 to i8
  store i8 %3700, i8* %19, align 1
  %3701 = trunc i64 %3696 to i32
  %3702 = and i32 %3701, 255
  %3703 = tail call i32 @llvm.ctpop.i32(i32 %3702)
  %3704 = trunc i32 %3703 to i8
  %3705 = and i8 %3704, 1
  %3706 = xor i8 %3705, 1
  store i8 %3706, i8* %26, align 1
  %3707 = xor i64 %3694, %3664
  %3708 = xor i64 %3707, %3696
  %3709 = lshr i64 %3708, 4
  %3710 = trunc i64 %3709 to i8
  %3711 = and i8 %3710, 1
  store i8 %3711, i8* %31, align 1
  %3712 = icmp eq i64 %3696, 0
  %3713 = zext i1 %3712 to i8
  store i8 %3713, i8* %34, align 1
  %3714 = lshr i64 %3696, 63
  %3715 = trunc i64 %3714 to i8
  store i8 %3715, i8* %37, align 1
  %3716 = xor i64 %3714, %3680
  %3717 = xor i64 %3714, %3695
  %3718 = add nuw nsw i64 %3716, %3717
  %3719 = icmp eq i64 %3718, 2
  %3720 = zext i1 %3719 to i8
  store i8 %3720, i8* %43, align 1
  %3721 = inttoptr i64 %3696 to i64*
  %3722 = add i64 %3662, 34
  store i64 %3722, i64* %3, align 8
  %3723 = load i64, i64* %3721, align 8
  store i64 %3723, i64* %RAX.i893, align 8
  %3724 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %3724, i64* %RDX.i1708, align 8
  %3725 = add i64 %3724, 6488
  %3726 = add i64 %3662, 49
  store i64 %3726, i64* %3, align 8
  %3727 = inttoptr i64 %3725 to i64*
  %3728 = load i64, i64* %3727, align 8
  store i64 %3728, i64* %RDX.i1708, align 8
  %3729 = add i64 %3662, 52
  store i64 %3729, i64* %3, align 8
  %3730 = inttoptr i64 %3728 to i64*
  %3731 = load i64, i64* %3730, align 8
  store i64 %3731, i64* %RDX.i1708, align 8
  %3732 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %3732, i64* %RDI.i3116, align 8
  %3733 = add i64 %3732, 144
  %3734 = add i64 %3662, 66
  store i64 %3734, i64* %3, align 8
  %3735 = inttoptr i64 %3733 to i32*
  %3736 = load i32, i32* %3735, align 4
  %3737 = zext i32 %3736 to i64
  store i64 %3737, i64* %RSI.i4020.pre-phi, align 8
  %3738 = load i64, i64* %RBP.i, align 8
  %3739 = add i64 %3738, -12
  %3740 = add i64 %3662, 69
  store i64 %3740, i64* %3, align 8
  %3741 = inttoptr i64 %3739 to i32*
  %3742 = load i32, i32* %3741, align 4
  %3743 = add i32 %3742, %3736
  %3744 = zext i32 %3743 to i64
  store i64 %3744, i64* %RSI.i4020.pre-phi, align 8
  %3745 = icmp ult i32 %3743, %3736
  %3746 = icmp ult i32 %3743, %3742
  %3747 = or i1 %3745, %3746
  %3748 = zext i1 %3747 to i8
  store i8 %3748, i8* %19, align 1
  %3749 = and i32 %3743, 255
  %3750 = tail call i32 @llvm.ctpop.i32(i32 %3749)
  %3751 = trunc i32 %3750 to i8
  %3752 = and i8 %3751, 1
  %3753 = xor i8 %3752, 1
  store i8 %3753, i8* %26, align 1
  %3754 = xor i32 %3742, %3736
  %3755 = xor i32 %3754, %3743
  %3756 = lshr i32 %3755, 4
  %3757 = trunc i32 %3756 to i8
  %3758 = and i8 %3757, 1
  store i8 %3758, i8* %31, align 1
  %3759 = icmp eq i32 %3743, 0
  %3760 = zext i1 %3759 to i8
  store i8 %3760, i8* %34, align 1
  %3761 = lshr i32 %3743, 31
  %3762 = trunc i32 %3761 to i8
  store i8 %3762, i8* %37, align 1
  %3763 = lshr i32 %3736, 31
  %3764 = lshr i32 %3742, 31
  %3765 = xor i32 %3761, %3763
  %3766 = xor i32 %3761, %3764
  %3767 = add nuw nsw i32 %3765, %3766
  %3768 = icmp eq i32 %3767, 2
  %3769 = zext i1 %3768 to i8
  store i8 %3769, i8* %43, align 1
  %3770 = sext i32 %3743 to i64
  store i64 %3770, i64* %RDI.i3116, align 8
  %3771 = shl nsw i64 %3770, 3
  %3772 = add i64 %3731, %3771
  %3773 = add i64 %3662, 76
  store i64 %3773, i64* %3, align 8
  %3774 = inttoptr i64 %3772 to i64*
  %3775 = load i64, i64* %3774, align 8
  store i64 %3775, i64* %RDX.i1708, align 8
  store i64 %3732, i64* %RDI.i3116, align 8
  %3776 = add i64 %3732, 148
  %3777 = add i64 %3662, 90
  store i64 %3777, i64* %3, align 8
  %3778 = inttoptr i64 %3776 to i32*
  %3779 = load i32, i32* %3778, align 4
  %3780 = zext i32 %3779 to i64
  store i64 %3780, i64* %RSI.i4020.pre-phi, align 8
  %3781 = add i64 %3738, -16
  %3782 = add i64 %3662, 93
  store i64 %3782, i64* %3, align 8
  %3783 = inttoptr i64 %3781 to i32*
  %3784 = load i32, i32* %3783, align 4
  %3785 = add i32 %3784, %3779
  %3786 = zext i32 %3785 to i64
  store i64 %3786, i64* %RSI.i4020.pre-phi, align 8
  %3787 = icmp ult i32 %3785, %3779
  %3788 = icmp ult i32 %3785, %3784
  %3789 = or i1 %3787, %3788
  %3790 = zext i1 %3789 to i8
  store i8 %3790, i8* %19, align 1
  %3791 = and i32 %3785, 255
  %3792 = tail call i32 @llvm.ctpop.i32(i32 %3791)
  %3793 = trunc i32 %3792 to i8
  %3794 = and i8 %3793, 1
  %3795 = xor i8 %3794, 1
  store i8 %3795, i8* %26, align 1
  %3796 = xor i32 %3784, %3779
  %3797 = xor i32 %3796, %3785
  %3798 = lshr i32 %3797, 4
  %3799 = trunc i32 %3798 to i8
  %3800 = and i8 %3799, 1
  store i8 %3800, i8* %31, align 1
  %3801 = icmp eq i32 %3785, 0
  %3802 = zext i1 %3801 to i8
  store i8 %3802, i8* %34, align 1
  %3803 = lshr i32 %3785, 31
  %3804 = trunc i32 %3803 to i8
  store i8 %3804, i8* %37, align 1
  %3805 = lshr i32 %3779, 31
  %3806 = lshr i32 %3784, 31
  %3807 = xor i32 %3803, %3805
  %3808 = xor i32 %3803, %3806
  %3809 = add nuw nsw i32 %3807, %3808
  %3810 = icmp eq i32 %3809, 2
  %3811 = zext i1 %3810 to i8
  store i8 %3811, i8* %43, align 1
  %3812 = sext i32 %3785 to i64
  store i64 %3812, i64* %RDI.i3116, align 8
  %3813 = shl nsw i64 %3812, 3
  %3814 = add i64 %3775, %3813
  %3815 = load i64, i64* %RAX.i893, align 8
  %3816 = add i64 %3662, 100
  store i64 %3816, i64* %3, align 8
  %3817 = inttoptr i64 %3814 to i64*
  store i64 %3815, i64* %3817, align 8
  %3818 = load i64, i64* %RBP.i, align 8
  %3819 = add i64 %3818, -104
  %3820 = load i64, i64* %3, align 8
  %3821 = add i64 %3820, 4
  store i64 %3821, i64* %3, align 8
  %3822 = inttoptr i64 %3819 to i64*
  %3823 = load i64, i64* %3822, align 8
  store i64 %3823, i64* %RAX.i893, align 8
  %3824 = add i64 %3818, -12
  %3825 = add i64 %3820, 8
  store i64 %3825, i64* %3, align 8
  %3826 = inttoptr i64 %3824 to i32*
  %3827 = load i32, i32* %3826, align 4
  %3828 = sext i32 %3827 to i64
  store i64 %3828, i64* %RDX.i1708, align 8
  %3829 = shl nsw i64 %3828, 3
  %3830 = add i64 %3829, %3823
  %3831 = add i64 %3820, 12
  store i64 %3831, i64* %3, align 8
  %3832 = inttoptr i64 %3830 to i64*
  %3833 = load i64, i64* %3832, align 8
  store i64 %3833, i64* %RAX.i893, align 8
  %3834 = add i64 %3818, -16
  %3835 = add i64 %3820, 16
  store i64 %3835, i64* %3, align 8
  %3836 = inttoptr i64 %3834 to i32*
  %3837 = load i32, i32* %3836, align 4
  %3838 = sext i32 %3837 to i64
  store i64 %3838, i64* %RDX.i1708, align 8
  %3839 = shl nsw i64 %3838, 3
  %3840 = add i64 %3839, %3833
  %3841 = add i64 %3820, 20
  store i64 %3841, i64* %3, align 8
  %3842 = inttoptr i64 %3840 to i64*
  %3843 = load i64, i64* %3842, align 8
  store i64 %3843, i64* %RAX.i893, align 8
  %3844 = add i64 %3820, 23
  store i64 %3844, i64* %3, align 8
  %3845 = inttoptr i64 %3843 to i64*
  %3846 = load i64, i64* %3845, align 8
  store i64 %3846, i64* %RAX.i893, align 8
  %3847 = add i64 %3820, 26
  store i64 %3847, i64* %3, align 8
  %3848 = inttoptr i64 %3846 to i64*
  %3849 = load i64, i64* %3848, align 8
  store i64 %3849, i64* %RAX.i893, align 8
  %3850 = add i64 %3818, -56
  %3851 = add i64 %3820, 30
  store i64 %3851, i64* %3, align 8
  %3852 = inttoptr i64 %3850 to i64*
  %3853 = load i64, i64* %3852, align 8
  store i64 %3853, i64* %RDX.i1708, align 8
  %3854 = add i64 %3820, 33
  store i64 %3854, i64* %3, align 8
  %3855 = load i32, i32* %3826, align 4
  %3856 = zext i32 %3855 to i64
  store i64 %3856, i64* %RSI.i4020.pre-phi, align 8
  %3857 = add i64 %3818, -152
  %3858 = add i64 %3820, 40
  store i64 %3858, i64* %3, align 8
  %3859 = inttoptr i64 %3857 to i64*
  store i64 %3849, i64* %3859, align 8
  %3860 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %3861 = zext i32 %3860 to i64
  %3862 = load i64, i64* %3, align 8
  store i64 %3861, i64* %RAX.i893, align 8
  %3863 = load i64, i64* %RBP.i, align 8
  %3864 = add i64 %3863, -160
  %3865 = load i64, i64* %RDX.i1708, align 8
  %3866 = add i64 %3862, 9
  store i64 %3866, i64* %3, align 8
  %3867 = inttoptr i64 %3864 to i64*
  store i64 %3865, i64* %3867, align 8
  %3868 = load i64, i64* %3, align 8
  %3869 = load i32, i32* %EAX.i4054.pre-phi, align 8
  %3870 = sext i32 %3869 to i64
  %3871 = lshr i64 %3870, 32
  store i64 %3871, i64* %2568, align 8
  %3872 = load i32, i32* %ECX.i3327, align 4
  %3873 = add i64 %3868, 3
  store i64 %3873, i64* %3, align 8
  %3874 = zext i32 %3869 to i64
  %3875 = sext i32 %3872 to i64
  %3876 = shl nuw i64 %3871, 32
  %3877 = or i64 %3876, %3874
  %3878 = sdiv i64 %3877, %3875
  %3879 = shl i64 %3878, 32
  %3880 = ashr exact i64 %3879, 32
  %3881 = icmp eq i64 %3878, %3880
  br i1 %3881, label %3884, label %3882

; <label>:3882:                                   ; preds = %block_.L_48e689
  %3883 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %3873, %struct.Memory* %3426)
  %.pre257 = load i64, i64* %3, align 8
  %.pre258 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__ecx.exit2685

; <label>:3884:                                   ; preds = %block_.L_48e689
  %3885 = srem i64 %3877, %3875
  %3886 = and i64 %3878, 4294967295
  store i64 %3886, i64* %RAX.i893, align 8
  %3887 = and i64 %3885, 4294967295
  store i64 %3887, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %3888 = trunc i64 %3878 to i32
  br label %routine_idivl__ecx.exit2685

routine_idivl__ecx.exit2685:                      ; preds = %3884, %3882
  %3889 = phi i32 [ %.pre258, %3882 ], [ %3888, %3884 ]
  %3890 = phi i64 [ %.pre257, %3882 ], [ %3873, %3884 ]
  %3891 = phi %struct.Memory* [ %3883, %3882 ], [ %3426, %3884 ]
  %3892 = load i64, i64* %RBP.i, align 8
  %3893 = add i64 %3892, -16
  %3894 = add i64 %3890, 3
  store i64 %3894, i64* %3, align 8
  %3895 = inttoptr i64 %3893 to i32*
  %3896 = load i32, i32* %3895, align 4
  %3897 = zext i32 %3896 to i64
  store i64 %3897, i64* %RSI.i4020.pre-phi, align 8
  %3898 = add i64 %3892, -164
  %3899 = add i64 %3890, 9
  store i64 %3899, i64* %3, align 8
  %3900 = inttoptr i64 %3898 to i32*
  store i32 %3889, i32* %3900, align 4
  %3901 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %3902 = zext i32 %3901 to i64
  %3903 = load i64, i64* %3, align 8
  store i64 %3902, i64* %RAX.i893, align 8
  %3904 = sext i32 %3901 to i64
  %3905 = lshr i64 %3904, 32
  store i64 %3905, i64* %2568, align 8
  %3906 = load i32, i32* %ECX.i3327, align 4
  %3907 = add i64 %3903, 5
  store i64 %3907, i64* %3, align 8
  %3908 = sext i32 %3906 to i64
  %3909 = shl nuw i64 %3905, 32
  %3910 = or i64 %3909, %3902
  %3911 = sdiv i64 %3910, %3908
  %3912 = shl i64 %3911, 32
  %3913 = ashr exact i64 %3912, 32
  %3914 = icmp eq i64 %3911, %3913
  br i1 %3914, label %3917, label %3915

; <label>:3915:                                   ; preds = %routine_idivl__ecx.exit2685
  %3916 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %3907, %struct.Memory* %3891)
  %.pre259 = load i64, i64* %RAX.i893, align 8
  %.pre260 = load i64, i64* %3, align 8
  br label %routine_idivl__ecx.exit2669

; <label>:3917:                                   ; preds = %routine_idivl__ecx.exit2685
  %3918 = srem i64 %3910, %3908
  %3919 = and i64 %3911, 4294967295
  store i64 %3919, i64* %RAX.i893, align 8
  %3920 = and i64 %3918, 4294967295
  store i64 %3920, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__ecx.exit2669

routine_idivl__ecx.exit2669:                      ; preds = %3917, %3915
  %3921 = phi i64 [ %.pre260, %3915 ], [ %3907, %3917 ]
  %3922 = phi i64 [ %.pre259, %3915 ], [ %3919, %3917 ]
  %3923 = phi %struct.Memory* [ %3916, %3915 ], [ %3891, %3917 ]
  %3924 = trunc i64 %3922 to i32
  %3925 = shl i32 %3924, 1
  %3926 = icmp slt i32 %3924, 0
  %3927 = icmp slt i32 %3925, 0
  %3928 = xor i1 %3926, %3927
  %3929 = zext i32 %3925 to i64
  store i64 %3929, i64* %RAX.i893, align 8
  %.lobit90 = lshr i32 %3924, 31
  %3930 = trunc i32 %.lobit90 to i8
  store i8 %3930, i8* %19, align 1
  %3931 = and i32 %3925, 254
  %3932 = tail call i32 @llvm.ctpop.i32(i32 %3931)
  %3933 = trunc i32 %3932 to i8
  %3934 = and i8 %3933, 1
  %3935 = xor i8 %3934, 1
  store i8 %3935, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %3936 = icmp eq i32 %3925, 0
  %3937 = zext i1 %3936 to i8
  store i8 %3937, i8* %34, align 1
  %3938 = lshr i32 %3924, 30
  %3939 = trunc i32 %3938 to i8
  %3940 = and i8 %3939, 1
  store i8 %3940, i8* %37, align 1
  %3941 = zext i1 %3928 to i8
  store i8 %3941, i8* %43, align 1
  %3942 = load i64, i64* %RBP.i, align 8
  %3943 = add i64 %3942, -164
  %3944 = add i64 %3921, 8
  store i64 %3944, i64* %3, align 8
  %3945 = inttoptr i64 %3943 to i32*
  %3946 = load i32, i32* %3945, align 4
  %3947 = add i32 %3925, %3946
  %3948 = zext i32 %3947 to i64
  store i64 %3948, i64* %RSI.i4020.pre-phi, align 8
  %3949 = icmp ult i32 %3947, %3946
  %3950 = icmp ult i32 %3947, %3925
  %3951 = or i1 %3949, %3950
  %3952 = zext i1 %3951 to i8
  store i8 %3952, i8* %19, align 1
  %3953 = and i32 %3947, 255
  %3954 = tail call i32 @llvm.ctpop.i32(i32 %3953)
  %3955 = trunc i32 %3954 to i8
  %3956 = and i8 %3955, 1
  %3957 = xor i8 %3956, 1
  store i8 %3957, i8* %26, align 1
  %3958 = xor i32 %3925, %3946
  %3959 = xor i32 %3958, %3947
  %3960 = lshr i32 %3959, 4
  %3961 = trunc i32 %3960 to i8
  %3962 = and i8 %3961, 1
  store i8 %3962, i8* %31, align 1
  %3963 = icmp eq i32 %3947, 0
  %3964 = zext i1 %3963 to i8
  store i8 %3964, i8* %34, align 1
  %3965 = lshr i32 %3947, 31
  %3966 = trunc i32 %3965 to i8
  store i8 %3966, i8* %37, align 1
  %3967 = lshr i32 %3946, 31
  %3968 = lshr i32 %3924, 30
  %3969 = and i32 %3968, 1
  %3970 = xor i32 %3965, %3967
  %3971 = xor i32 %3965, %3969
  %3972 = add nuw nsw i32 %3970, %3971
  %3973 = icmp eq i32 %3972, 2
  %3974 = zext i1 %3973 to i8
  store i8 %3974, i8* %43, align 1
  %3975 = sext i32 %3947 to i64
  store i64 %3975, i64* %RDI.i3116, align 8
  %3976 = add i64 %3942, -160
  %3977 = add i64 %3921, 20
  store i64 %3977, i64* %3, align 8
  %3978 = inttoptr i64 %3976 to i64*
  %3979 = load i64, i64* %3978, align 8
  store i64 %3979, i64* %R8.i3094, align 8
  %3980 = shl nsw i64 %3975, 2
  %3981 = add i64 %3979, 472
  %3982 = add i64 %3981, %3980
  %3983 = add i64 %3921, 28
  store i64 %3983, i64* %3, align 8
  %3984 = inttoptr i64 %3982 to i32*
  %3985 = load i32, i32* %3984, align 4
  %3986 = sext i32 %3985 to i64
  store i64 %3986, i64* %RDI.i3116, align 8
  %3987 = add i64 %3942, -152
  %3988 = add i64 %3921, 35
  store i64 %3988, i64* %3, align 8
  %3989 = inttoptr i64 %3987 to i64*
  %3990 = load i64, i64* %3989, align 8
  store i64 %3990, i64* %R9.i2396, align 8
  %3991 = shl nsw i64 %3986, 3
  %3992 = add i64 %3991, %3990
  %3993 = add i64 %3921, 39
  store i64 %3993, i64* %3, align 8
  %3994 = inttoptr i64 %3992 to i64*
  %3995 = load i64, i64* %3994, align 8
  store i64 %3995, i64* %RDI.i3116, align 8
  %3996 = add i64 %3921, 43
  store i64 %3996, i64* %3, align 8
  %3997 = inttoptr i64 %3995 to i16*
  %3998 = load i16, i16* %3997, align 2
  store i16 %3998, i16* %R10W.i2642, align 2
  %3999 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %3999, i64* %RDI.i3116, align 8
  %4000 = add i64 %3999, 6504
  %4001 = add i64 %3921, 58
  store i64 %4001, i64* %3, align 8
  %4002 = inttoptr i64 %4000 to i64*
  %4003 = load i64, i64* %4002, align 8
  store i64 %4003, i64* %RDI.i3116, align 8
  %4004 = add i64 %3921, 61
  store i64 %4004, i64* %3, align 8
  %4005 = inttoptr i64 %4003 to i64*
  %4006 = load i64, i64* %4005, align 8
  store i64 %4006, i64* %RDI.i3116, align 8
  %4007 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %4007, i64* %R11.i2222, align 8
  %4008 = add i64 %4007, 144
  %4009 = add i64 %3921, 76
  store i64 %4009, i64* %3, align 8
  %4010 = inttoptr i64 %4008 to i32*
  %4011 = load i32, i32* %4010, align 4
  %4012 = zext i32 %4011 to i64
  store i64 %4012, i64* %RAX.i893, align 8
  %4013 = load i64, i64* %RBP.i, align 8
  %4014 = add i64 %4013, -12
  %4015 = add i64 %3921, 79
  store i64 %4015, i64* %3, align 8
  %4016 = inttoptr i64 %4014 to i32*
  %4017 = load i32, i32* %4016, align 4
  %4018 = add i32 %4017, %4011
  %4019 = zext i32 %4018 to i64
  store i64 %4019, i64* %RAX.i893, align 8
  %4020 = icmp ult i32 %4018, %4011
  %4021 = icmp ult i32 %4018, %4017
  %4022 = or i1 %4020, %4021
  %4023 = zext i1 %4022 to i8
  store i8 %4023, i8* %19, align 1
  %4024 = and i32 %4018, 255
  %4025 = tail call i32 @llvm.ctpop.i32(i32 %4024)
  %4026 = trunc i32 %4025 to i8
  %4027 = and i8 %4026, 1
  %4028 = xor i8 %4027, 1
  store i8 %4028, i8* %26, align 1
  %4029 = xor i32 %4017, %4011
  %4030 = xor i32 %4029, %4018
  %4031 = lshr i32 %4030, 4
  %4032 = trunc i32 %4031 to i8
  %4033 = and i8 %4032, 1
  store i8 %4033, i8* %31, align 1
  %4034 = icmp eq i32 %4018, 0
  %4035 = zext i1 %4034 to i8
  store i8 %4035, i8* %34, align 1
  %4036 = lshr i32 %4018, 31
  %4037 = trunc i32 %4036 to i8
  store i8 %4037, i8* %37, align 1
  %4038 = lshr i32 %4011, 31
  %4039 = lshr i32 %4017, 31
  %4040 = xor i32 %4036, %4038
  %4041 = xor i32 %4036, %4039
  %4042 = add nuw nsw i32 %4040, %4041
  %4043 = icmp eq i32 %4042, 2
  %4044 = zext i1 %4043 to i8
  store i8 %4044, i8* %43, align 1
  %4045 = sext i32 %4018 to i64
  store i64 %4045, i64* %R11.i2222, align 8
  %4046 = shl nsw i64 %4045, 3
  %4047 = add i64 %4006, %4046
  %4048 = add i64 %3921, 86
  store i64 %4048, i64* %3, align 8
  %4049 = inttoptr i64 %4047 to i64*
  %4050 = load i64, i64* %4049, align 8
  store i64 %4050, i64* %RDI.i3116, align 8
  store i64 %4007, i64* %R11.i2222, align 8
  %4051 = add i64 %4007, 148
  %4052 = add i64 %3921, 101
  store i64 %4052, i64* %3, align 8
  %4053 = inttoptr i64 %4051 to i32*
  %4054 = load i32, i32* %4053, align 4
  %4055 = zext i32 %4054 to i64
  store i64 %4055, i64* %RAX.i893, align 8
  %4056 = add i64 %4013, -16
  %4057 = add i64 %3921, 104
  store i64 %4057, i64* %3, align 8
  %4058 = inttoptr i64 %4056 to i32*
  %4059 = load i32, i32* %4058, align 4
  %4060 = add i32 %4059, %4054
  %4061 = zext i32 %4060 to i64
  store i64 %4061, i64* %RAX.i893, align 8
  %4062 = icmp ult i32 %4060, %4054
  %4063 = icmp ult i32 %4060, %4059
  %4064 = or i1 %4062, %4063
  %4065 = zext i1 %4064 to i8
  store i8 %4065, i8* %19, align 1
  %4066 = and i32 %4060, 255
  %4067 = tail call i32 @llvm.ctpop.i32(i32 %4066)
  %4068 = trunc i32 %4067 to i8
  %4069 = and i8 %4068, 1
  %4070 = xor i8 %4069, 1
  store i8 %4070, i8* %26, align 1
  %4071 = xor i32 %4059, %4054
  %4072 = xor i32 %4071, %4060
  %4073 = lshr i32 %4072, 4
  %4074 = trunc i32 %4073 to i8
  %4075 = and i8 %4074, 1
  store i8 %4075, i8* %31, align 1
  %4076 = icmp eq i32 %4060, 0
  %4077 = zext i1 %4076 to i8
  store i8 %4077, i8* %34, align 1
  %4078 = lshr i32 %4060, 31
  %4079 = trunc i32 %4078 to i8
  store i8 %4079, i8* %37, align 1
  %4080 = lshr i32 %4054, 31
  %4081 = lshr i32 %4059, 31
  %4082 = xor i32 %4078, %4080
  %4083 = xor i32 %4078, %4081
  %4084 = add nuw nsw i32 %4082, %4083
  %4085 = icmp eq i32 %4084, 2
  %4086 = zext i1 %4085 to i8
  store i8 %4086, i8* %43, align 1
  %4087 = sext i32 %4060 to i64
  store i64 %4087, i64* %R11.i2222, align 8
  %4088 = shl nsw i64 %4087, 3
  %4089 = add i64 %4050, %4088
  %4090 = add i64 %3921, 111
  store i64 %4090, i64* %3, align 8
  %4091 = inttoptr i64 %4089 to i64*
  %4092 = load i64, i64* %4091, align 8
  store i64 %4092, i64* %RDI.i3116, align 8
  %4093 = load i16, i16* %R10W.i2642, align 2
  %4094 = add i64 %3921, 115
  store i64 %4094, i64* %3, align 8
  %4095 = inttoptr i64 %4092 to i16*
  store i16 %4093, i16* %4095, align 2
  %4096 = load i64, i64* %RBP.i, align 8
  %4097 = add i64 %4096, -104
  %4098 = load i64, i64* %3, align 8
  %4099 = add i64 %4098, 4
  store i64 %4099, i64* %3, align 8
  %4100 = inttoptr i64 %4097 to i64*
  %4101 = load i64, i64* %4100, align 8
  store i64 %4101, i64* %RDI.i3116, align 8
  %4102 = add i64 %4096, -12
  %4103 = add i64 %4098, 8
  store i64 %4103, i64* %3, align 8
  %4104 = inttoptr i64 %4102 to i32*
  %4105 = load i32, i32* %4104, align 4
  %4106 = sext i32 %4105 to i64
  store i64 %4106, i64* %R11.i2222, align 8
  %4107 = shl nsw i64 %4106, 3
  %4108 = add i64 %4107, %4101
  %4109 = add i64 %4098, 12
  store i64 %4109, i64* %3, align 8
  %4110 = inttoptr i64 %4108 to i64*
  %4111 = load i64, i64* %4110, align 8
  store i64 %4111, i64* %RDI.i3116, align 8
  %4112 = add i64 %4096, -16
  %4113 = add i64 %4098, 16
  store i64 %4113, i64* %3, align 8
  %4114 = inttoptr i64 %4112 to i32*
  %4115 = load i32, i32* %4114, align 4
  %4116 = sext i32 %4115 to i64
  store i64 %4116, i64* %R11.i2222, align 8
  %4117 = shl nsw i64 %4116, 3
  %4118 = add i64 %4117, %4111
  %4119 = add i64 %4098, 20
  store i64 %4119, i64* %3, align 8
  %4120 = inttoptr i64 %4118 to i64*
  %4121 = load i64, i64* %4120, align 8
  store i64 %4121, i64* %RDI.i3116, align 8
  %4122 = add i64 %4098, 23
  store i64 %4122, i64* %3, align 8
  %4123 = inttoptr i64 %4121 to i64*
  %4124 = load i64, i64* %4123, align 8
  store i64 %4124, i64* %RDI.i3116, align 8
  %4125 = add i64 %4098, 26
  store i64 %4125, i64* %3, align 8
  %4126 = inttoptr i64 %4124 to i64*
  %4127 = load i64, i64* %4126, align 8
  store i64 %4127, i64* %RDI.i3116, align 8
  %4128 = add i64 %4096, -56
  %4129 = add i64 %4098, 30
  store i64 %4129, i64* %3, align 8
  %4130 = inttoptr i64 %4128 to i64*
  %4131 = load i64, i64* %4130, align 8
  store i64 %4131, i64* %R11.i2222, align 8
  %4132 = add i64 %4098, 33
  store i64 %4132, i64* %3, align 8
  %4133 = load i32, i32* %4104, align 4
  %4134 = zext i32 %4133 to i64
  store i64 %4134, i64* %RAX.i893, align 8
  %4135 = sext i32 %4133 to i64
  %4136 = lshr i64 %4135, 32
  store i64 %4136, i64* %2568, align 8
  %4137 = load i32, i32* %ECX.i3327, align 4
  %4138 = add i64 %4098, 36
  store i64 %4138, i64* %3, align 8
  %4139 = sext i32 %4137 to i64
  %4140 = shl nuw i64 %4136, 32
  %4141 = or i64 %4140, %4134
  %4142 = sdiv i64 %4141, %4139
  %4143 = shl i64 %4142, 32
  %4144 = ashr exact i64 %4143, 32
  %4145 = icmp eq i64 %4142, %4144
  br i1 %4145, label %4148, label %4146

; <label>:4146:                                   ; preds = %routine_idivl__ecx.exit2669
  %4147 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %4138, %struct.Memory* %3923)
  %.pre261 = load i64, i64* %RBP.i, align 8
  %.pre262 = load i64, i64* %3, align 8
  %.pre263 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__ecx.exit2575

; <label>:4148:                                   ; preds = %routine_idivl__ecx.exit2669
  %4149 = srem i64 %4141, %4139
  %4150 = and i64 %4142, 4294967295
  store i64 %4150, i64* %RAX.i893, align 8
  %4151 = and i64 %4149, 4294967295
  store i64 %4151, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %4152 = trunc i64 %4142 to i32
  br label %routine_idivl__ecx.exit2575

routine_idivl__ecx.exit2575:                      ; preds = %4148, %4146
  %4153 = phi i32 [ %.pre263, %4146 ], [ %4152, %4148 ]
  %4154 = phi i64 [ %.pre262, %4146 ], [ %4138, %4148 ]
  %4155 = phi i64 [ %.pre261, %4146 ], [ %4096, %4148 ]
  %4156 = phi %struct.Memory* [ %4147, %4146 ], [ %3923, %4148 ]
  %4157 = add i64 %4155, -16
  %4158 = add i64 %4154, 3
  store i64 %4158, i64* %3, align 8
  %4159 = inttoptr i64 %4157 to i32*
  %4160 = load i32, i32* %4159, align 4
  %4161 = zext i32 %4160 to i64
  store i64 %4161, i64* %RSI.i4020.pre-phi, align 8
  %4162 = add i64 %4155, -168
  %4163 = add i64 %4154, 9
  store i64 %4163, i64* %3, align 8
  %4164 = inttoptr i64 %4162 to i32*
  store i32 %4153, i32* %4164, align 4
  %4165 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %4166 = zext i32 %4165 to i64
  %4167 = load i64, i64* %3, align 8
  store i64 %4166, i64* %RAX.i893, align 8
  %4168 = sext i32 %4165 to i64
  %4169 = lshr i64 %4168, 32
  store i64 %4169, i64* %2568, align 8
  %4170 = load i32, i32* %ECX.i3327, align 4
  %4171 = add i64 %4167, 5
  store i64 %4171, i64* %3, align 8
  %4172 = sext i32 %4170 to i64
  %4173 = shl nuw i64 %4169, 32
  %4174 = or i64 %4173, %4166
  %4175 = sdiv i64 %4174, %4172
  %4176 = shl i64 %4175, 32
  %4177 = ashr exact i64 %4176, 32
  %4178 = icmp eq i64 %4175, %4177
  br i1 %4178, label %4181, label %4179

; <label>:4179:                                   ; preds = %routine_idivl__ecx.exit2575
  %4180 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %4171, %struct.Memory* %4156)
  %.pre264 = load i64, i64* %RAX.i893, align 8
  %.pre265 = load i64, i64* %3, align 8
  br label %routine_idivl__ecx.exit2560

; <label>:4181:                                   ; preds = %routine_idivl__ecx.exit2575
  %4182 = srem i64 %4174, %4172
  %4183 = and i64 %4175, 4294967295
  store i64 %4183, i64* %RAX.i893, align 8
  %4184 = and i64 %4182, 4294967295
  store i64 %4184, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__ecx.exit2560

routine_idivl__ecx.exit2560:                      ; preds = %4181, %4179
  %4185 = phi i64 [ %.pre265, %4179 ], [ %4171, %4181 ]
  %4186 = phi i64 [ %.pre264, %4179 ], [ %4183, %4181 ]
  %4187 = phi %struct.Memory* [ %4180, %4179 ], [ %4156, %4181 ]
  %4188 = trunc i64 %4186 to i32
  %4189 = shl i32 %4188, 1
  %4190 = icmp slt i32 %4188, 0
  %4191 = icmp slt i32 %4189, 0
  %4192 = xor i1 %4190, %4191
  %4193 = zext i32 %4189 to i64
  store i64 %4193, i64* %RAX.i893, align 8
  %.lobit91 = lshr i32 %4188, 31
  %4194 = trunc i32 %.lobit91 to i8
  store i8 %4194, i8* %19, align 1
  %4195 = and i32 %4189, 254
  %4196 = tail call i32 @llvm.ctpop.i32(i32 %4195)
  %4197 = trunc i32 %4196 to i8
  %4198 = and i8 %4197, 1
  %4199 = xor i8 %4198, 1
  store i8 %4199, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %4200 = icmp eq i32 %4189, 0
  %4201 = zext i1 %4200 to i8
  store i8 %4201, i8* %34, align 1
  %4202 = lshr i32 %4188, 30
  %4203 = trunc i32 %4202 to i8
  %4204 = and i8 %4203, 1
  store i8 %4204, i8* %37, align 1
  %4205 = zext i1 %4192 to i8
  store i8 %4205, i8* %43, align 1
  %4206 = load i64, i64* %RBP.i, align 8
  %4207 = add i64 %4206, -168
  %4208 = add i64 %4185, 8
  store i64 %4208, i64* %3, align 8
  %4209 = inttoptr i64 %4207 to i32*
  %4210 = load i32, i32* %4209, align 4
  %4211 = add i32 %4189, %4210
  %4212 = zext i32 %4211 to i64
  store i64 %4212, i64* %RCX.i1197, align 8
  %4213 = icmp ult i32 %4211, %4210
  %4214 = icmp ult i32 %4211, %4189
  %4215 = or i1 %4213, %4214
  %4216 = zext i1 %4215 to i8
  store i8 %4216, i8* %19, align 1
  %4217 = and i32 %4211, 255
  %4218 = tail call i32 @llvm.ctpop.i32(i32 %4217)
  %4219 = trunc i32 %4218 to i8
  %4220 = and i8 %4219, 1
  %4221 = xor i8 %4220, 1
  store i8 %4221, i8* %26, align 1
  %4222 = xor i32 %4189, %4210
  %4223 = xor i32 %4222, %4211
  %4224 = lshr i32 %4223, 4
  %4225 = trunc i32 %4224 to i8
  %4226 = and i8 %4225, 1
  store i8 %4226, i8* %31, align 1
  %4227 = icmp eq i32 %4211, 0
  %4228 = zext i1 %4227 to i8
  store i8 %4228, i8* %34, align 1
  %4229 = lshr i32 %4211, 31
  %4230 = trunc i32 %4229 to i8
  store i8 %4230, i8* %37, align 1
  %4231 = lshr i32 %4210, 31
  %4232 = lshr i32 %4188, 30
  %4233 = and i32 %4232, 1
  %4234 = xor i32 %4229, %4231
  %4235 = xor i32 %4229, %4233
  %4236 = add nuw nsw i32 %4234, %4235
  %4237 = icmp eq i32 %4236, 2
  %4238 = zext i1 %4237 to i8
  store i8 %4238, i8* %43, align 1
  %4239 = sext i32 %4211 to i64
  store i64 %4239, i64* %RBX.i772, align 8
  %4240 = load i64, i64* %R11.i2222, align 8
  %4241 = shl nsw i64 %4239, 2
  %4242 = add nsw i64 %4241, 472
  %4243 = add i64 %4242, %4240
  %4244 = add i64 %4185, 21
  store i64 %4244, i64* %3, align 8
  %4245 = inttoptr i64 %4243 to i32*
  %4246 = load i32, i32* %4245, align 4
  %4247 = sext i32 %4246 to i64
  store i64 %4247, i64* %R11.i2222, align 8
  %4248 = load i64, i64* %RDI.i3116, align 8
  %4249 = shl nsw i64 %4247, 3
  %4250 = add i64 %4249, %4248
  %4251 = add i64 %4185, 25
  store i64 %4251, i64* %3, align 8
  %4252 = inttoptr i64 %4250 to i64*
  %4253 = load i64, i64* %4252, align 8
  store i64 %4253, i64* %RDI.i3116, align 8
  %4254 = add i64 %4253, 2
  %4255 = add i64 %4185, 30
  store i64 %4255, i64* %3, align 8
  %4256 = inttoptr i64 %4254 to i16*
  %4257 = load i16, i16* %4256, align 2
  store i16 %4257, i16* %R10W.i2642, align 2
  %4258 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %4258, i64* %RDI.i3116, align 8
  %4259 = add i64 %4258, 6504
  %4260 = add i64 %4185, 45
  store i64 %4260, i64* %3, align 8
  %4261 = inttoptr i64 %4259 to i64*
  %4262 = load i64, i64* %4261, align 8
  store i64 %4262, i64* %RDI.i3116, align 8
  %4263 = add i64 %4185, 48
  store i64 %4263, i64* %3, align 8
  %4264 = inttoptr i64 %4262 to i64*
  %4265 = load i64, i64* %4264, align 8
  store i64 %4265, i64* %RDI.i3116, align 8
  %4266 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %4266, i64* %R11.i2222, align 8
  %4267 = add i64 %4266, 144
  %4268 = add i64 %4185, 63
  store i64 %4268, i64* %3, align 8
  %4269 = inttoptr i64 %4267 to i32*
  %4270 = load i32, i32* %4269, align 4
  %4271 = zext i32 %4270 to i64
  store i64 %4271, i64* %RAX.i893, align 8
  %4272 = load i64, i64* %RBP.i, align 8
  %4273 = add i64 %4272, -12
  %4274 = add i64 %4185, 66
  store i64 %4274, i64* %3, align 8
  %4275 = inttoptr i64 %4273 to i32*
  %4276 = load i32, i32* %4275, align 4
  %4277 = add i32 %4276, %4270
  %4278 = zext i32 %4277 to i64
  store i64 %4278, i64* %RAX.i893, align 8
  %4279 = icmp ult i32 %4277, %4270
  %4280 = icmp ult i32 %4277, %4276
  %4281 = or i1 %4279, %4280
  %4282 = zext i1 %4281 to i8
  store i8 %4282, i8* %19, align 1
  %4283 = and i32 %4277, 255
  %4284 = tail call i32 @llvm.ctpop.i32(i32 %4283)
  %4285 = trunc i32 %4284 to i8
  %4286 = and i8 %4285, 1
  %4287 = xor i8 %4286, 1
  store i8 %4287, i8* %26, align 1
  %4288 = xor i32 %4276, %4270
  %4289 = xor i32 %4288, %4277
  %4290 = lshr i32 %4289, 4
  %4291 = trunc i32 %4290 to i8
  %4292 = and i8 %4291, 1
  store i8 %4292, i8* %31, align 1
  %4293 = icmp eq i32 %4277, 0
  %4294 = zext i1 %4293 to i8
  store i8 %4294, i8* %34, align 1
  %4295 = lshr i32 %4277, 31
  %4296 = trunc i32 %4295 to i8
  store i8 %4296, i8* %37, align 1
  %4297 = lshr i32 %4270, 31
  %4298 = lshr i32 %4276, 31
  %4299 = xor i32 %4295, %4297
  %4300 = xor i32 %4295, %4298
  %4301 = add nuw nsw i32 %4299, %4300
  %4302 = icmp eq i32 %4301, 2
  %4303 = zext i1 %4302 to i8
  store i8 %4303, i8* %43, align 1
  %4304 = sext i32 %4277 to i64
  store i64 %4304, i64* %R11.i2222, align 8
  %4305 = shl nsw i64 %4304, 3
  %4306 = add i64 %4265, %4305
  %4307 = add i64 %4185, 73
  store i64 %4307, i64* %3, align 8
  %4308 = inttoptr i64 %4306 to i64*
  %4309 = load i64, i64* %4308, align 8
  store i64 %4309, i64* %RDI.i3116, align 8
  store i64 %4266, i64* %R11.i2222, align 8
  %4310 = add i64 %4266, 148
  %4311 = add i64 %4185, 88
  store i64 %4311, i64* %3, align 8
  %4312 = inttoptr i64 %4310 to i32*
  %4313 = load i32, i32* %4312, align 4
  %4314 = zext i32 %4313 to i64
  store i64 %4314, i64* %RAX.i893, align 8
  %4315 = add i64 %4272, -16
  %4316 = add i64 %4185, 91
  store i64 %4316, i64* %3, align 8
  %4317 = inttoptr i64 %4315 to i32*
  %4318 = load i32, i32* %4317, align 4
  %4319 = add i32 %4318, %4313
  %4320 = zext i32 %4319 to i64
  store i64 %4320, i64* %RAX.i893, align 8
  %4321 = icmp ult i32 %4319, %4313
  %4322 = icmp ult i32 %4319, %4318
  %4323 = or i1 %4321, %4322
  %4324 = zext i1 %4323 to i8
  store i8 %4324, i8* %19, align 1
  %4325 = and i32 %4319, 255
  %4326 = tail call i32 @llvm.ctpop.i32(i32 %4325)
  %4327 = trunc i32 %4326 to i8
  %4328 = and i8 %4327, 1
  %4329 = xor i8 %4328, 1
  store i8 %4329, i8* %26, align 1
  %4330 = xor i32 %4318, %4313
  %4331 = xor i32 %4330, %4319
  %4332 = lshr i32 %4331, 4
  %4333 = trunc i32 %4332 to i8
  %4334 = and i8 %4333, 1
  store i8 %4334, i8* %31, align 1
  %4335 = icmp eq i32 %4319, 0
  %4336 = zext i1 %4335 to i8
  store i8 %4336, i8* %34, align 1
  %4337 = lshr i32 %4319, 31
  %4338 = trunc i32 %4337 to i8
  store i8 %4338, i8* %37, align 1
  %4339 = lshr i32 %4313, 31
  %4340 = lshr i32 %4318, 31
  %4341 = xor i32 %4337, %4339
  %4342 = xor i32 %4337, %4340
  %4343 = add nuw nsw i32 %4341, %4342
  %4344 = icmp eq i32 %4343, 2
  %4345 = zext i1 %4344 to i8
  store i8 %4345, i8* %43, align 1
  %4346 = sext i32 %4319 to i64
  store i64 %4346, i64* %R11.i2222, align 8
  %4347 = shl nsw i64 %4346, 3
  %4348 = add i64 %4309, %4347
  %4349 = add i64 %4185, 98
  store i64 %4349, i64* %3, align 8
  %4350 = inttoptr i64 %4348 to i64*
  %4351 = load i64, i64* %4350, align 8
  %4352 = add i64 %4351, 2
  %4353 = load i16, i16* %R10W.i2642, align 2
  %4354 = add i64 %4185, 103
  store i64 %4354, i64* %3, align 8
  %4355 = inttoptr i64 %4352 to i16*
  store i16 %4353, i16* %4355, align 2
  %4356 = load i64, i64* %3, align 8
  %4357 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %4357, i64* %RDI.i3116, align 8
  %4358 = add i64 %4357, 72400
  %4359 = add i64 %4356, 15
  store i64 %4359, i64* %3, align 8
  %4360 = inttoptr i64 %4358 to i32*
  %4361 = load i32, i32* %4360, align 4
  store i8 0, i8* %19, align 1
  %4362 = and i32 %4361, 255
  %4363 = tail call i32 @llvm.ctpop.i32(i32 %4362)
  %4364 = trunc i32 %4363 to i8
  %4365 = and i8 %4364, 1
  %4366 = xor i8 %4365, 1
  store i8 %4366, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %4367 = icmp eq i32 %4361, 0
  %4368 = zext i1 %4367 to i8
  store i8 %4368, i8* %34, align 1
  %4369 = lshr i32 %4361, 31
  %4370 = trunc i32 %4369 to i8
  store i8 %4370, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v356 = select i1 %4367, i64 56, i64 21
  %4371 = add i64 %4356, %.v356
  store i64 %4371, i64* %3, align 8
  br i1 %4367, label %block_.L_48e8c9, label %block_48e8a6

block_48e8a6:                                     ; preds = %routine_idivl__ecx.exit2560
  %4372 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %4373 = add i64 %4372, 3264
  store i64 %4373, i64* %RAX.i893, align 8
  %4374 = icmp ugt i64 %4372, -3265
  %4375 = zext i1 %4374 to i8
  store i8 %4375, i8* %19, align 1
  %4376 = trunc i64 %4373 to i32
  %4377 = and i32 %4376, 255
  %4378 = tail call i32 @llvm.ctpop.i32(i32 %4377)
  %4379 = trunc i32 %4378 to i8
  %4380 = and i8 %4379, 1
  %4381 = xor i8 %4380, 1
  store i8 %4381, i8* %26, align 1
  %4382 = xor i64 %4373, %4372
  %4383 = lshr i64 %4382, 4
  %4384 = trunc i64 %4383 to i8
  %4385 = and i8 %4384, 1
  store i8 %4385, i8* %31, align 1
  %4386 = icmp eq i64 %4373, 0
  %4387 = zext i1 %4386 to i8
  store i8 %4387, i8* %34, align 1
  %4388 = lshr i64 %4373, 63
  %4389 = trunc i64 %4388 to i8
  store i8 %4389, i8* %37, align 1
  %4390 = lshr i64 %4372, 63
  %4391 = xor i64 %4388, %4390
  %4392 = add nuw nsw i64 %4391, %4388
  %4393 = icmp eq i64 %4392, 2
  %4394 = zext i1 %4393 to i8
  store i8 %4394, i8* %43, align 1
  %4395 = load i64, i64* %RBP.i, align 8
  %4396 = add i64 %4395, -16
  %4397 = add i64 %4371, 18
  store i64 %4397, i64* %3, align 8
  %4398 = inttoptr i64 %4396 to i32*
  %4399 = load i32, i32* %4398, align 4
  %4400 = sext i32 %4399 to i64
  %4401 = shl nsw i64 %4400, 3
  store i64 %4401, i64* %RCX.i1197, align 8
  %4402 = add i64 %4401, %4373
  store i64 %4402, i64* %RAX.i893, align 8
  %4403 = icmp ult i64 %4402, %4373
  %4404 = icmp ult i64 %4402, %4401
  %4405 = or i1 %4403, %4404
  %4406 = zext i1 %4405 to i8
  store i8 %4406, i8* %19, align 1
  %4407 = trunc i64 %4402 to i32
  %4408 = and i32 %4407, 255
  %4409 = tail call i32 @llvm.ctpop.i32(i32 %4408)
  %4410 = trunc i32 %4409 to i8
  %4411 = and i8 %4410, 1
  %4412 = xor i8 %4411, 1
  store i8 %4412, i8* %26, align 1
  %4413 = xor i64 %4401, %4373
  %4414 = xor i64 %4413, %4402
  %4415 = lshr i64 %4414, 4
  %4416 = trunc i64 %4415 to i8
  %4417 = and i8 %4416, 1
  store i8 %4417, i8* %31, align 1
  %4418 = icmp eq i64 %4402, 0
  %4419 = zext i1 %4418 to i8
  store i8 %4419, i8* %34, align 1
  %4420 = lshr i64 %4402, 63
  %4421 = trunc i64 %4420 to i8
  store i8 %4421, i8* %37, align 1
  %4422 = lshr i64 %4400, 60
  %4423 = and i64 %4422, 1
  %4424 = xor i64 %4420, %4388
  %4425 = xor i64 %4420, %4423
  %4426 = add nuw nsw i64 %4424, %4425
  %4427 = icmp eq i64 %4426, 2
  %4428 = zext i1 %4427 to i8
  store i8 %4428, i8* %43, align 1
  %4429 = add i64 %4395, -12
  %4430 = add i64 %4371, 29
  store i64 %4430, i64* %3, align 8
  %4431 = inttoptr i64 %4429 to i32*
  %4432 = load i32, i32* %4431, align 4
  %4433 = sext i32 %4432 to i64
  store i64 %4433, i64* %RCX.i1197, align 8
  %4434 = shl nsw i64 %4433, 1
  %4435 = add i64 %4434, %4402
  %4436 = add i64 %4371, 35
  store i64 %4436, i64* %3, align 8
  %4437 = inttoptr i64 %4435 to i16*
  store i16 0, i16* %4437, align 2
  %.pre266 = load i64, i64* %3, align 8
  br label %block_.L_48e8c9

block_.L_48e8c9:                                  ; preds = %block_48e8a6, %routine_idivl__ecx.exit2560
  %4438 = phi i64 [ %.pre266, %block_48e8a6 ], [ %4371, %routine_idivl__ecx.exit2560 ]
  %4439 = add i64 %4438, 788
  br label %block_.L_48ebdd

block_.L_48e8ce:                                  ; preds = %block_48e639, %routine_idivl__esi.exit2863, %block_.L_48e5e0
  %4440 = phi i64 [ %2726, %block_.L_48e5e0 ], [ %3445, %routine_idivl__esi.exit2863 ], [ %3445, %block_48e639 ]
  %4441 = phi i64 [ %3355, %block_.L_48e5e0 ], [ %3507, %routine_idivl__esi.exit2863 ], [ %3537, %block_48e639 ]
  %MEMORY.30 = phi %struct.Memory* [ %2707, %block_.L_48e5e0 ], [ %3426, %routine_idivl__esi.exit2863 ], [ %3426, %block_48e639 ]
  store i64 2, i64* %RAX.i893, align 8
  store i64 ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64), i64* %RCX.i1197, align 8
  %4442 = add i64 %4440, -16
  %4443 = add i64 %4441, 19
  store i64 %4443, i64* %3, align 8
  %4444 = inttoptr i64 %4442 to i32*
  %4445 = load i32, i32* %4444, align 4
  %4446 = sext i32 %4445 to i64
  %4447 = shl nsw i64 %4446, 3
  store i64 %4447, i64* %RDX.i1708, align 8
  %4448 = add i64 %4447, ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64)
  store i64 %4448, i64* %RSI.i4020.pre-phi, align 8
  %4449 = icmp ult i64 %4448, ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64)
  %4450 = icmp ult i64 %4448, %4447
  %4451 = or i1 %4449, %4450
  %4452 = zext i1 %4451 to i8
  store i8 %4452, i8* %19, align 1
  %4453 = trunc i64 %4448 to i32
  %4454 = and i32 %4453, 248
  %4455 = tail call i32 @llvm.ctpop.i32(i32 %4454)
  %4456 = trunc i32 %4455 to i8
  %4457 = and i8 %4456, 1
  %4458 = xor i8 %4457, 1
  store i8 %4458, i8* %26, align 1
  %4459 = xor i64 %4447, ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64)
  %4460 = xor i64 %4459, %4448
  %4461 = lshr i64 %4460, 4
  %4462 = trunc i64 %4461 to i8
  %4463 = and i8 %4462, 1
  store i8 %4463, i8* %31, align 1
  %4464 = icmp eq i64 %4448, 0
  %4465 = zext i1 %4464 to i8
  store i8 %4465, i8* %34, align 1
  %4466 = lshr i64 %4448, 63
  %4467 = trunc i64 %4466 to i8
  store i8 %4467, i8* %37, align 1
  %4468 = lshr i64 %4446, 60
  %4469 = and i64 %4468, 1
  %4470 = xor i64 %4466, lshr (i64 ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64), i64 63)
  %4471 = xor i64 %4466, %4469
  %4472 = add nuw nsw i64 %4470, %4471
  %4473 = icmp eq i64 %4472, 2
  %4474 = zext i1 %4473 to i8
  store i8 %4474, i8* %43, align 1
  %4475 = add i64 %4440, -12
  %4476 = add i64 %4441, 33
  store i64 %4476, i64* %3, align 8
  %4477 = inttoptr i64 %4475 to i32*
  %4478 = load i32, i32* %4477, align 4
  %4479 = sext i32 %4478 to i64
  store i64 %4479, i64* %RDX.i1708, align 8
  %4480 = shl nsw i64 %4479, 1
  %4481 = add i64 %4480, %4448
  %4482 = add i64 %4441, 37
  store i64 %4482, i64* %3, align 8
  %4483 = inttoptr i64 %4481 to i16*
  %4484 = load i16, i16* %4483, align 2
  store i16 %4484, i16* %DI.i2456, align 2
  %4485 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %4485, i64* %RDX.i1708, align 8
  %4486 = add i64 %4485, 6480
  %4487 = add i64 %4441, 52
  store i64 %4487, i64* %3, align 8
  %4488 = inttoptr i64 %4486 to i64*
  %4489 = load i64, i64* %4488, align 8
  store i64 %4489, i64* %RDX.i1708, align 8
  %4490 = add i64 %4441, 55
  store i64 %4490, i64* %3, align 8
  %4491 = inttoptr i64 %4489 to i64*
  %4492 = load i64, i64* %4491, align 8
  store i64 %4492, i64* %RDX.i1708, align 8
  %4493 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %4493, i64* %RSI.i4020.pre-phi, align 8
  %4494 = add i64 %4493, 144
  %4495 = add i64 %4441, 70
  store i64 %4495, i64* %3, align 8
  %4496 = inttoptr i64 %4494 to i32*
  %4497 = load i32, i32* %4496, align 4
  %4498 = zext i32 %4497 to i64
  store i64 %4498, i64* %R8.i3094, align 8
  %4499 = load i64, i64* %RBP.i, align 8
  %4500 = add i64 %4499, -12
  %4501 = add i64 %4441, 74
  store i64 %4501, i64* %3, align 8
  %4502 = inttoptr i64 %4500 to i32*
  %4503 = load i32, i32* %4502, align 4
  %4504 = add i32 %4503, %4497
  %4505 = zext i32 %4504 to i64
  store i64 %4505, i64* %R8.i3094, align 8
  %4506 = icmp ult i32 %4504, %4497
  %4507 = icmp ult i32 %4504, %4503
  %4508 = or i1 %4506, %4507
  %4509 = zext i1 %4508 to i8
  store i8 %4509, i8* %19, align 1
  %4510 = and i32 %4504, 255
  %4511 = tail call i32 @llvm.ctpop.i32(i32 %4510)
  %4512 = trunc i32 %4511 to i8
  %4513 = and i8 %4512, 1
  %4514 = xor i8 %4513, 1
  store i8 %4514, i8* %26, align 1
  %4515 = xor i32 %4503, %4497
  %4516 = xor i32 %4515, %4504
  %4517 = lshr i32 %4516, 4
  %4518 = trunc i32 %4517 to i8
  %4519 = and i8 %4518, 1
  store i8 %4519, i8* %31, align 1
  %4520 = icmp eq i32 %4504, 0
  %4521 = zext i1 %4520 to i8
  store i8 %4521, i8* %34, align 1
  %4522 = lshr i32 %4504, 31
  %4523 = trunc i32 %4522 to i8
  store i8 %4523, i8* %37, align 1
  %4524 = lshr i32 %4497, 31
  %4525 = lshr i32 %4503, 31
  %4526 = xor i32 %4522, %4524
  %4527 = xor i32 %4522, %4525
  %4528 = add nuw nsw i32 %4526, %4527
  %4529 = icmp eq i32 %4528, 2
  %4530 = zext i1 %4529 to i8
  store i8 %4530, i8* %43, align 1
  %4531 = sext i32 %4504 to i64
  store i64 %4531, i64* %RSI.i4020.pre-phi, align 8
  %4532 = shl nsw i64 %4531, 3
  %4533 = add i64 %4492, %4532
  %4534 = add i64 %4441, 81
  store i64 %4534, i64* %3, align 8
  %4535 = inttoptr i64 %4533 to i64*
  %4536 = load i64, i64* %4535, align 8
  store i64 %4536, i64* %RDX.i1708, align 8
  store i64 %4493, i64* %RSI.i4020.pre-phi, align 8
  %4537 = add i64 %4493, 148
  %4538 = add i64 %4441, 96
  store i64 %4538, i64* %3, align 8
  %4539 = inttoptr i64 %4537 to i32*
  %4540 = load i32, i32* %4539, align 4
  %4541 = zext i32 %4540 to i64
  store i64 %4541, i64* %R8.i3094, align 8
  %4542 = add i64 %4499, -16
  %4543 = add i64 %4441, 100
  store i64 %4543, i64* %3, align 8
  %4544 = inttoptr i64 %4542 to i32*
  %4545 = load i32, i32* %4544, align 4
  %4546 = add i32 %4545, %4540
  %4547 = zext i32 %4546 to i64
  store i64 %4547, i64* %R8.i3094, align 8
  %4548 = sext i32 %4546 to i64
  store i64 %4548, i64* %RSI.i4020.pre-phi, align 8
  %4549 = shl nsw i64 %4548, 1
  %4550 = add i64 %4536, %4549
  %4551 = load i16, i16* %DI.i2456, align 2
  %4552 = add i64 %4441, 107
  store i64 %4552, i64* %3, align 8
  %4553 = inttoptr i64 %4550 to i16*
  store i16 %4551, i16* %4553, align 2
  %4554 = load i64, i64* %3, align 8
  %4555 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  %4556 = add i64 %4555, 24
  store i64 %4556, i64* %RDX.i1708, align 8
  %4557 = icmp ugt i64 %4555, -25
  %4558 = zext i1 %4557 to i8
  store i8 %4558, i8* %19, align 1
  %4559 = trunc i64 %4556 to i32
  %4560 = and i32 %4559, 255
  %4561 = tail call i32 @llvm.ctpop.i32(i32 %4560)
  %4562 = trunc i32 %4561 to i8
  %4563 = and i8 %4562, 1
  %4564 = xor i8 %4563, 1
  store i8 %4564, i8* %26, align 1
  %4565 = xor i64 %4555, 16
  %4566 = xor i64 %4565, %4556
  %4567 = lshr i64 %4566, 4
  %4568 = trunc i64 %4567 to i8
  %4569 = and i8 %4568, 1
  store i8 %4569, i8* %31, align 1
  %4570 = icmp eq i64 %4556, 0
  %4571 = zext i1 %4570 to i8
  store i8 %4571, i8* %34, align 1
  %4572 = lshr i64 %4556, 63
  %4573 = trunc i64 %4572 to i8
  store i8 %4573, i8* %37, align 1
  %4574 = lshr i64 %4555, 63
  %4575 = xor i64 %4572, %4574
  %4576 = add nuw nsw i64 %4575, %4572
  %4577 = icmp eq i64 %4576, 2
  %4578 = zext i1 %4577 to i8
  store i8 %4578, i8* %43, align 1
  %4579 = load i64, i64* %RBP.i, align 8
  %4580 = add i64 %4579, -92
  %4581 = add i64 %4554, 16
  store i64 %4581, i64* %3, align 8
  %4582 = inttoptr i64 %4580 to i32*
  %4583 = load i32, i32* %4582, align 4
  %4584 = zext i32 %4583 to i64
  store i64 %4584, i64* %R8.i3094, align 8
  %4585 = sext i32 %4583 to i64
  %4586 = mul nsw i64 %4585, 264
  %4587 = lshr i64 %4586, 63
  %4588 = add i64 %4586, %4556
  store i64 %4588, i64* %RDX.i1708, align 8
  %4589 = icmp ult i64 %4588, %4556
  %4590 = icmp ult i64 %4588, %4586
  %4591 = or i1 %4589, %4590
  %4592 = zext i1 %4591 to i8
  store i8 %4592, i8* %19, align 1
  %4593 = trunc i64 %4588 to i32
  %4594 = and i32 %4593, 255
  %4595 = tail call i32 @llvm.ctpop.i32(i32 %4594)
  %4596 = trunc i32 %4595 to i8
  %4597 = and i8 %4596, 1
  %4598 = xor i8 %4597, 1
  store i8 %4598, i8* %26, align 1
  %4599 = xor i64 %4586, %4556
  %4600 = xor i64 %4599, %4588
  %4601 = lshr i64 %4600, 4
  %4602 = trunc i64 %4601 to i8
  %4603 = and i8 %4602, 1
  store i8 %4603, i8* %31, align 1
  %4604 = icmp eq i64 %4588, 0
  %4605 = zext i1 %4604 to i8
  store i8 %4605, i8* %34, align 1
  %4606 = lshr i64 %4588, 63
  %4607 = trunc i64 %4606 to i8
  store i8 %4607, i8* %37, align 1
  %4608 = xor i64 %4606, %4572
  %4609 = xor i64 %4606, %4587
  %4610 = add nuw nsw i64 %4608, %4609
  %4611 = icmp eq i64 %4610, 2
  %4612 = zext i1 %4611 to i8
  store i8 %4612, i8* %43, align 1
  %4613 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %4613, i64* %RSI.i4020.pre-phi, align 8
  %4614 = add i64 %4613, 6480
  %4615 = add i64 %4554, 48
  store i64 %4615, i64* %3, align 8
  %4616 = inttoptr i64 %4614 to i64*
  %4617 = load i64, i64* %4616, align 8
  store i64 %4617, i64* %RSI.i4020.pre-phi, align 8
  %4618 = add i64 %4554, 51
  store i64 %4618, i64* %3, align 8
  %4619 = inttoptr i64 %4617 to i64*
  %4620 = load i64, i64* %4619, align 8
  store i64 %4620, i64* %RSI.i4020.pre-phi, align 8
  %4621 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %4621, i64* %R9.i2396, align 8
  %4622 = add i64 %4621, 144
  %4623 = add i64 %4554, 66
  store i64 %4623, i64* %3, align 8
  %4624 = inttoptr i64 %4622 to i32*
  %4625 = load i32, i32* %4624, align 4
  %4626 = zext i32 %4625 to i64
  store i64 %4626, i64* %R8.i3094, align 8
  %4627 = load i64, i64* %RBP.i, align 8
  %4628 = add i64 %4627, -12
  %4629 = add i64 %4554, 70
  store i64 %4629, i64* %3, align 8
  %4630 = inttoptr i64 %4628 to i32*
  %4631 = load i32, i32* %4630, align 4
  %4632 = add i32 %4631, %4625
  %4633 = zext i32 %4632 to i64
  store i64 %4633, i64* %R8.i3094, align 8
  %4634 = icmp ult i32 %4632, %4625
  %4635 = icmp ult i32 %4632, %4631
  %4636 = or i1 %4634, %4635
  %4637 = zext i1 %4636 to i8
  store i8 %4637, i8* %19, align 1
  %4638 = and i32 %4632, 255
  %4639 = tail call i32 @llvm.ctpop.i32(i32 %4638)
  %4640 = trunc i32 %4639 to i8
  %4641 = and i8 %4640, 1
  %4642 = xor i8 %4641, 1
  store i8 %4642, i8* %26, align 1
  %4643 = xor i32 %4631, %4625
  %4644 = xor i32 %4643, %4632
  %4645 = lshr i32 %4644, 4
  %4646 = trunc i32 %4645 to i8
  %4647 = and i8 %4646, 1
  store i8 %4647, i8* %31, align 1
  %4648 = icmp eq i32 %4632, 0
  %4649 = zext i1 %4648 to i8
  store i8 %4649, i8* %34, align 1
  %4650 = lshr i32 %4632, 31
  %4651 = trunc i32 %4650 to i8
  store i8 %4651, i8* %37, align 1
  %4652 = lshr i32 %4625, 31
  %4653 = lshr i32 %4631, 31
  %4654 = xor i32 %4650, %4652
  %4655 = xor i32 %4650, %4653
  %4656 = add nuw nsw i32 %4654, %4655
  %4657 = icmp eq i32 %4656, 2
  %4658 = zext i1 %4657 to i8
  store i8 %4658, i8* %43, align 1
  %4659 = sext i32 %4632 to i64
  store i64 %4659, i64* %R9.i2396, align 8
  %4660 = shl nsw i64 %4659, 3
  %4661 = add i64 %4620, %4660
  %4662 = add i64 %4554, 77
  store i64 %4662, i64* %3, align 8
  %4663 = inttoptr i64 %4661 to i64*
  %4664 = load i64, i64* %4663, align 8
  store i64 %4664, i64* %RSI.i4020.pre-phi, align 8
  store i64 %4621, i64* %R9.i2396, align 8
  %4665 = add i64 %4621, 148
  %4666 = add i64 %4554, 92
  store i64 %4666, i64* %3, align 8
  %4667 = inttoptr i64 %4665 to i32*
  %4668 = load i32, i32* %4667, align 4
  %4669 = zext i32 %4668 to i64
  store i64 %4669, i64* %R8.i3094, align 8
  %4670 = add i64 %4627, -16
  %4671 = add i64 %4554, 96
  store i64 %4671, i64* %3, align 8
  %4672 = inttoptr i64 %4670 to i32*
  %4673 = load i32, i32* %4672, align 4
  %4674 = add i32 %4673, %4668
  %4675 = zext i32 %4674 to i64
  store i64 %4675, i64* %R8.i3094, align 8
  %4676 = icmp ult i32 %4674, %4668
  %4677 = icmp ult i32 %4674, %4673
  %4678 = or i1 %4676, %4677
  %4679 = zext i1 %4678 to i8
  store i8 %4679, i8* %19, align 1
  %4680 = and i32 %4674, 255
  %4681 = tail call i32 @llvm.ctpop.i32(i32 %4680)
  %4682 = trunc i32 %4681 to i8
  %4683 = and i8 %4682, 1
  %4684 = xor i8 %4683, 1
  store i8 %4684, i8* %26, align 1
  %4685 = xor i32 %4673, %4668
  %4686 = xor i32 %4685, %4674
  %4687 = lshr i32 %4686, 4
  %4688 = trunc i32 %4687 to i8
  %4689 = and i8 %4688, 1
  store i8 %4689, i8* %31, align 1
  %4690 = icmp eq i32 %4674, 0
  %4691 = zext i1 %4690 to i8
  store i8 %4691, i8* %34, align 1
  %4692 = lshr i32 %4674, 31
  %4693 = trunc i32 %4692 to i8
  store i8 %4693, i8* %37, align 1
  %4694 = lshr i32 %4668, 31
  %4695 = lshr i32 %4673, 31
  %4696 = xor i32 %4692, %4694
  %4697 = xor i32 %4692, %4695
  %4698 = add nuw nsw i32 %4696, %4697
  %4699 = icmp eq i32 %4698, 2
  %4700 = zext i1 %4699 to i8
  store i8 %4700, i8* %43, align 1
  %4701 = sext i32 %4674 to i64
  store i64 %4701, i64* %R9.i2396, align 8
  %4702 = shl nsw i64 %4701, 1
  %4703 = add i64 %4664, %4702
  %4704 = add i64 %4554, 104
  store i64 %4704, i64* %3, align 8
  %4705 = inttoptr i64 %4703 to i16*
  %4706 = load i16, i16* %4705, align 2
  %4707 = sext i16 %4706 to i64
  store i64 %4707, i64* %RSI.i4020.pre-phi, align 8
  %4708 = load i64, i64* %RDX.i1708, align 8
  %4709 = shl nsw i64 %4707, 3
  %4710 = add i64 %4709, %4708
  %4711 = add i64 %4554, 108
  store i64 %4711, i64* %3, align 8
  %4712 = inttoptr i64 %4710 to i64*
  %4713 = load i64, i64* %4712, align 8
  store i64 %4713, i64* %RDX.i1708, align 8
  %4714 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %4714, i64* %RSI.i4020.pre-phi, align 8
  %4715 = add i64 %4714, 6488
  %4716 = add i64 %4554, 123
  store i64 %4716, i64* %3, align 8
  %4717 = inttoptr i64 %4715 to i64*
  %4718 = load i64, i64* %4717, align 8
  store i64 %4718, i64* %RSI.i4020.pre-phi, align 8
  %4719 = add i64 %4554, 126
  store i64 %4719, i64* %3, align 8
  %4720 = inttoptr i64 %4718 to i64*
  %4721 = load i64, i64* %4720, align 8
  store i64 %4721, i64* %RSI.i4020.pre-phi, align 8
  %4722 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %4722, i64* %R9.i2396, align 8
  %4723 = add i64 %4722, 144
  %4724 = add i64 %4554, 141
  store i64 %4724, i64* %3, align 8
  %4725 = inttoptr i64 %4723 to i32*
  %4726 = load i32, i32* %4725, align 4
  %4727 = zext i32 %4726 to i64
  store i64 %4727, i64* %R8.i3094, align 8
  %4728 = load i64, i64* %RBP.i, align 8
  %4729 = add i64 %4728, -12
  %4730 = add i64 %4554, 145
  store i64 %4730, i64* %3, align 8
  %4731 = inttoptr i64 %4729 to i32*
  %4732 = load i32, i32* %4731, align 4
  %4733 = add i32 %4732, %4726
  %4734 = zext i32 %4733 to i64
  store i64 %4734, i64* %R8.i3094, align 8
  %4735 = icmp ult i32 %4733, %4726
  %4736 = icmp ult i32 %4733, %4732
  %4737 = or i1 %4735, %4736
  %4738 = zext i1 %4737 to i8
  store i8 %4738, i8* %19, align 1
  %4739 = and i32 %4733, 255
  %4740 = tail call i32 @llvm.ctpop.i32(i32 %4739)
  %4741 = trunc i32 %4740 to i8
  %4742 = and i8 %4741, 1
  %4743 = xor i8 %4742, 1
  store i8 %4743, i8* %26, align 1
  %4744 = xor i32 %4732, %4726
  %4745 = xor i32 %4744, %4733
  %4746 = lshr i32 %4745, 4
  %4747 = trunc i32 %4746 to i8
  %4748 = and i8 %4747, 1
  store i8 %4748, i8* %31, align 1
  %4749 = icmp eq i32 %4733, 0
  %4750 = zext i1 %4749 to i8
  store i8 %4750, i8* %34, align 1
  %4751 = lshr i32 %4733, 31
  %4752 = trunc i32 %4751 to i8
  store i8 %4752, i8* %37, align 1
  %4753 = lshr i32 %4726, 31
  %4754 = lshr i32 %4732, 31
  %4755 = xor i32 %4751, %4753
  %4756 = xor i32 %4751, %4754
  %4757 = add nuw nsw i32 %4755, %4756
  %4758 = icmp eq i32 %4757, 2
  %4759 = zext i1 %4758 to i8
  store i8 %4759, i8* %43, align 1
  %4760 = sext i32 %4733 to i64
  store i64 %4760, i64* %R9.i2396, align 8
  %4761 = shl nsw i64 %4760, 3
  %4762 = add i64 %4721, %4761
  %4763 = add i64 %4554, 152
  store i64 %4763, i64* %3, align 8
  %4764 = inttoptr i64 %4762 to i64*
  %4765 = load i64, i64* %4764, align 8
  store i64 %4765, i64* %RSI.i4020.pre-phi, align 8
  store i64 %4722, i64* %R9.i2396, align 8
  %4766 = add i64 %4722, 148
  %4767 = add i64 %4554, 167
  store i64 %4767, i64* %3, align 8
  %4768 = inttoptr i64 %4766 to i32*
  %4769 = load i32, i32* %4768, align 4
  %4770 = zext i32 %4769 to i64
  store i64 %4770, i64* %R8.i3094, align 8
  %4771 = add i64 %4728, -16
  %4772 = add i64 %4554, 171
  store i64 %4772, i64* %3, align 8
  %4773 = inttoptr i64 %4771 to i32*
  %4774 = load i32, i32* %4773, align 4
  %4775 = add i32 %4774, %4769
  %4776 = zext i32 %4775 to i64
  store i64 %4776, i64* %R8.i3094, align 8
  %4777 = icmp ult i32 %4775, %4769
  %4778 = icmp ult i32 %4775, %4774
  %4779 = or i1 %4777, %4778
  %4780 = zext i1 %4779 to i8
  store i8 %4780, i8* %19, align 1
  %4781 = and i32 %4775, 255
  %4782 = tail call i32 @llvm.ctpop.i32(i32 %4781)
  %4783 = trunc i32 %4782 to i8
  %4784 = and i8 %4783, 1
  %4785 = xor i8 %4784, 1
  store i8 %4785, i8* %26, align 1
  %4786 = xor i32 %4774, %4769
  %4787 = xor i32 %4786, %4775
  %4788 = lshr i32 %4787, 4
  %4789 = trunc i32 %4788 to i8
  %4790 = and i8 %4789, 1
  store i8 %4790, i8* %31, align 1
  %4791 = icmp eq i32 %4775, 0
  %4792 = zext i1 %4791 to i8
  store i8 %4792, i8* %34, align 1
  %4793 = lshr i32 %4775, 31
  %4794 = trunc i32 %4793 to i8
  store i8 %4794, i8* %37, align 1
  %4795 = lshr i32 %4769, 31
  %4796 = lshr i32 %4774, 31
  %4797 = xor i32 %4793, %4795
  %4798 = xor i32 %4793, %4796
  %4799 = add nuw nsw i32 %4797, %4798
  %4800 = icmp eq i32 %4799, 2
  %4801 = zext i1 %4800 to i8
  store i8 %4801, i8* %43, align 1
  %4802 = sext i32 %4775 to i64
  store i64 %4802, i64* %R9.i2396, align 8
  %4803 = shl nsw i64 %4802, 3
  %4804 = add i64 %4765, %4803
  %4805 = load i64, i64* %RDX.i1708, align 8
  %4806 = add i64 %4554, 178
  store i64 %4806, i64* %3, align 8
  %4807 = inttoptr i64 %4804 to i64*
  store i64 %4805, i64* %4807, align 8
  %4808 = load i64, i64* %3, align 8
  %4809 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %4809, i64* %RDX.i1708, align 8
  %4810 = add i64 %4809, 71928
  %4811 = add i64 %4808, 15
  store i64 %4811, i64* %3, align 8
  %4812 = inttoptr i64 %4810 to i64*
  %4813 = load i64, i64* %4812, align 8
  store i64 %4813, i64* %RDX.i1708, align 8
  %4814 = load i64, i64* %RBP.i, align 8
  %4815 = add i64 %4814, -12
  %4816 = add i64 %4808, 19
  store i64 %4816, i64* %3, align 8
  %4817 = inttoptr i64 %4815 to i32*
  %4818 = load i32, i32* %4817, align 4
  %4819 = sext i32 %4818 to i64
  store i64 %4819, i64* %RSI.i4020.pre-phi, align 8
  %4820 = shl nsw i64 %4819, 3
  %4821 = add i64 %4820, %4813
  %4822 = add i64 %4808, 23
  store i64 %4822, i64* %3, align 8
  %4823 = inttoptr i64 %4821 to i64*
  %4824 = load i64, i64* %4823, align 8
  store i64 %4824, i64* %RDX.i1708, align 8
  %4825 = add i64 %4814, -16
  %4826 = add i64 %4808, 27
  store i64 %4826, i64* %3, align 8
  %4827 = inttoptr i64 %4825 to i32*
  %4828 = load i32, i32* %4827, align 4
  %4829 = sext i32 %4828 to i64
  store i64 %4829, i64* %RSI.i4020.pre-phi, align 8
  %4830 = shl nsw i64 %4829, 3
  %4831 = add i64 %4830, %4824
  %4832 = add i64 %4808, 31
  store i64 %4832, i64* %3, align 8
  %4833 = inttoptr i64 %4831 to i64*
  %4834 = load i64, i64* %4833, align 8
  store i64 %4834, i64* %RDX.i1708, align 8
  %4835 = add i64 %4808, 34
  store i64 %4835, i64* %3, align 8
  %4836 = inttoptr i64 %4834 to i64*
  %4837 = load i64, i64* %4836, align 8
  store i64 %4837, i64* %RDX.i1708, align 8
  %4838 = add i64 %4808, 38
  store i64 %4838, i64* %3, align 8
  %4839 = load i32, i32* %4827, align 4
  %4840 = sext i32 %4839 to i64
  %4841 = shl nsw i64 %4840, 3
  store i64 %4841, i64* %RSI.i4020.pre-phi, align 8
  %4842 = load i64, i64* %RCX.i1197, align 8
  %4843 = add i64 %4841, %4842
  store i64 %4843, i64* %R9.i2396, align 8
  %4844 = icmp ult i64 %4843, %4842
  %4845 = icmp ult i64 %4843, %4841
  %4846 = or i1 %4844, %4845
  %4847 = zext i1 %4846 to i8
  store i8 %4847, i8* %19, align 1
  %4848 = trunc i64 %4843 to i32
  %4849 = and i32 %4848, 255
  %4850 = tail call i32 @llvm.ctpop.i32(i32 %4849)
  %4851 = trunc i32 %4850 to i8
  %4852 = and i8 %4851, 1
  %4853 = xor i8 %4852, 1
  store i8 %4853, i8* %26, align 1
  %4854 = xor i64 %4841, %4842
  %4855 = xor i64 %4854, %4843
  %4856 = lshr i64 %4855, 4
  %4857 = trunc i64 %4856 to i8
  %4858 = and i8 %4857, 1
  store i8 %4858, i8* %31, align 1
  %4859 = icmp eq i64 %4843, 0
  %4860 = zext i1 %4859 to i8
  store i8 %4860, i8* %34, align 1
  %4861 = lshr i64 %4843, 63
  %4862 = trunc i64 %4861 to i8
  store i8 %4862, i8* %37, align 1
  %4863 = lshr i64 %4842, 63
  %4864 = lshr i64 %4840, 60
  %4865 = and i64 %4864, 1
  %4866 = xor i64 %4861, %4863
  %4867 = xor i64 %4861, %4865
  %4868 = add nuw nsw i64 %4866, %4867
  %4869 = icmp eq i64 %4868, 2
  %4870 = zext i1 %4869 to i8
  store i8 %4870, i8* %43, align 1
  %4871 = load i64, i64* %RBP.i, align 8
  %4872 = add i64 %4871, -12
  %4873 = add i64 %4808, 52
  store i64 %4873, i64* %3, align 8
  %4874 = inttoptr i64 %4872 to i32*
  %4875 = load i32, i32* %4874, align 4
  %4876 = sext i32 %4875 to i64
  store i64 %4876, i64* %RSI.i4020.pre-phi, align 8
  %4877 = shl nsw i64 %4876, 1
  %4878 = add i64 %4877, %4843
  %4879 = add i64 %4808, 57
  store i64 %4879, i64* %3, align 8
  %4880 = inttoptr i64 %4878 to i16*
  %4881 = load i16, i16* %4880, align 2
  %4882 = sext i16 %4881 to i64
  store i64 %4882, i64* %RSI.i4020.pre-phi, align 8
  %4883 = shl nsw i64 %4882, 3
  %4884 = add i64 %4883, %4837
  %4885 = add i64 %4808, 61
  store i64 %4885, i64* %3, align 8
  %4886 = inttoptr i64 %4884 to i64*
  %4887 = load i64, i64* %4886, align 8
  store i64 %4887, i64* %RDX.i1708, align 8
  %4888 = add i64 %4871, -56
  %4889 = add i64 %4808, 65
  store i64 %4889, i64* %3, align 8
  %4890 = inttoptr i64 %4888 to i64*
  %4891 = load i64, i64* %4890, align 8
  store i64 %4891, i64* %RSI.i4020.pre-phi, align 8
  %4892 = add i64 %4808, 69
  store i64 %4892, i64* %3, align 8
  %4893 = load i32, i32* %4874, align 4
  %4894 = zext i32 %4893 to i64
  store i64 %4894, i64* %R8.i3094, align 8
  %4895 = add i64 %4871, -172
  %4896 = load i32, i32* %EAX.i4054.pre-phi, align 4
  %4897 = add i64 %4808, 75
  store i64 %4897, i64* %3, align 8
  %4898 = inttoptr i64 %4895 to i32*
  store i32 %4896, i32* %4898, align 4
  %4899 = load i32, i32* %R8D.i2445, align 4
  %4900 = zext i32 %4899 to i64
  %4901 = load i64, i64* %3, align 8
  store i64 %4900, i64* %RAX.i893, align 8
  %4902 = load i64, i64* %RBP.i, align 8
  %4903 = add i64 %4902, -184
  %4904 = load i64, i64* %RDX.i1708, align 8
  %4905 = add i64 %4901, 10
  store i64 %4905, i64* %3, align 8
  %4906 = inttoptr i64 %4903 to i64*
  store i64 %4904, i64* %4906, align 8
  %4907 = load i64, i64* %3, align 8
  %4908 = load i32, i32* %EAX.i4054.pre-phi, align 8
  %4909 = sext i32 %4908 to i64
  %4910 = lshr i64 %4909, 32
  store i64 %4910, i64* %2568, align 8
  %4911 = load i64, i64* %RBP.i, align 8
  %4912 = add i64 %4911, -172
  %4913 = add i64 %4907, 8
  store i64 %4913, i64* %3, align 8
  %4914 = inttoptr i64 %4912 to i32*
  %4915 = load i32, i32* %4914, align 4
  %4916 = zext i32 %4915 to i64
  store i64 %4916, i64* %R8.i3094, align 8
  %4917 = add i64 %4907, 11
  store i64 %4917, i64* %3, align 8
  %4918 = zext i32 %4908 to i64
  %4919 = sext i32 %4915 to i64
  %4920 = shl nuw i64 %4910, 32
  %4921 = or i64 %4920, %4918
  %4922 = sdiv i64 %4921, %4919
  %4923 = shl i64 %4922, 32
  %4924 = ashr exact i64 %4923, 32
  %4925 = icmp eq i64 %4922, %4924
  br i1 %4925, label %4928, label %4926

; <label>:4926:                                   ; preds = %block_.L_48e8ce
  %4927 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %4917, %struct.Memory* %MEMORY.30)
  %.pre267 = load i64, i64* %RBP.i, align 8
  %.pre268 = load i64, i64* %3, align 8
  %.pre269 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__r8d.exit2270

; <label>:4928:                                   ; preds = %block_.L_48e8ce
  %4929 = srem i64 %4921, %4919
  %4930 = and i64 %4922, 4294967295
  store i64 %4930, i64* %RAX.i893, align 8
  %4931 = and i64 %4929, 4294967295
  store i64 %4931, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %4932 = trunc i64 %4922 to i32
  br label %routine_idivl__r8d.exit2270

routine_idivl__r8d.exit2270:                      ; preds = %4928, %4926
  %4933 = phi i32 [ %.pre269, %4926 ], [ %4932, %4928 ]
  %4934 = phi i64 [ %.pre268, %4926 ], [ %4917, %4928 ]
  %4935 = phi i64 [ %.pre267, %4926 ], [ %4911, %4928 ]
  %4936 = phi %struct.Memory* [ %4927, %4926 ], [ %MEMORY.30, %4928 ]
  %4937 = add i64 %4935, -16
  %4938 = add i64 %4934, 4
  store i64 %4938, i64* %3, align 8
  %4939 = inttoptr i64 %4937 to i32*
  %4940 = load i32, i32* %4939, align 4
  %4941 = zext i32 %4940 to i64
  store i64 %4941, i64* %2572, align 8
  %4942 = add i64 %4935, -188
  %4943 = add i64 %4934, 10
  store i64 %4943, i64* %3, align 8
  %4944 = inttoptr i64 %4942 to i32*
  store i32 %4933, i32* %4944, align 4
  %4945 = load i32, i32* %R10D.i2266, align 4
  %4946 = zext i32 %4945 to i64
  %4947 = load i64, i64* %3, align 8
  store i64 %4946, i64* %RAX.i893, align 8
  %4948 = sext i32 %4945 to i64
  %4949 = lshr i64 %4948, 32
  store i64 %4949, i64* %2568, align 8
  %4950 = load i32, i32* %R8D.i2445, align 4
  %4951 = add i64 %4947, 7
  store i64 %4951, i64* %3, align 8
  %4952 = sext i32 %4950 to i64
  %4953 = shl nuw i64 %4949, 32
  %4954 = or i64 %4953, %4946
  %4955 = sdiv i64 %4954, %4952
  %4956 = shl i64 %4955, 32
  %4957 = ashr exact i64 %4956, 32
  %4958 = icmp eq i64 %4955, %4957
  br i1 %4958, label %4961, label %4959

; <label>:4959:                                   ; preds = %routine_idivl__r8d.exit2270
  %4960 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %4951, %struct.Memory* %4936)
  %.pre270 = load i64, i64* %RAX.i893, align 8
  %.pre271 = load i64, i64* %3, align 8
  br label %routine_idivl__r8d.exit2254

; <label>:4961:                                   ; preds = %routine_idivl__r8d.exit2270
  %4962 = srem i64 %4954, %4952
  %4963 = and i64 %4955, 4294967295
  store i64 %4963, i64* %RAX.i893, align 8
  %4964 = and i64 %4962, 4294967295
  store i64 %4964, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__r8d.exit2254

routine_idivl__r8d.exit2254:                      ; preds = %4961, %4959
  %4965 = phi i64 [ %.pre271, %4959 ], [ %4951, %4961 ]
  %4966 = phi i64 [ %.pre270, %4959 ], [ %4963, %4961 ]
  %4967 = phi %struct.Memory* [ %4960, %4959 ], [ %4936, %4961 ]
  %4968 = trunc i64 %4966 to i32
  %4969 = shl i32 %4968, 1
  %4970 = icmp slt i32 %4968, 0
  %4971 = icmp slt i32 %4969, 0
  %4972 = xor i1 %4970, %4971
  %4973 = zext i32 %4969 to i64
  store i64 %4973, i64* %RAX.i893, align 8
  %.lobit96 = lshr i32 %4968, 31
  %4974 = trunc i32 %.lobit96 to i8
  store i8 %4974, i8* %19, align 1
  %4975 = and i32 %4969, 254
  %4976 = tail call i32 @llvm.ctpop.i32(i32 %4975)
  %4977 = trunc i32 %4976 to i8
  %4978 = and i8 %4977, 1
  %4979 = xor i8 %4978, 1
  store i8 %4979, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %4980 = icmp eq i32 %4969, 0
  %4981 = zext i1 %4980 to i8
  store i8 %4981, i8* %34, align 1
  %4982 = lshr i32 %4968, 30
  %4983 = trunc i32 %4982 to i8
  %4984 = and i8 %4983, 1
  store i8 %4984, i8* %37, align 1
  %4985 = zext i1 %4972 to i8
  store i8 %4985, i8* %43, align 1
  %4986 = load i64, i64* %RBP.i, align 8
  %4987 = add i64 %4986, -188
  %4988 = add i64 %4965, 9
  store i64 %4988, i64* %3, align 8
  %4989 = inttoptr i64 %4987 to i32*
  %4990 = load i32, i32* %4989, align 4
  %4991 = add i32 %4969, %4990
  %4992 = zext i32 %4991 to i64
  store i64 %4992, i64* %2572, align 8
  %4993 = icmp ult i32 %4991, %4990
  %4994 = icmp ult i32 %4991, %4969
  %4995 = or i1 %4993, %4994
  %4996 = zext i1 %4995 to i8
  store i8 %4996, i8* %19, align 1
  %4997 = and i32 %4991, 255
  %4998 = tail call i32 @llvm.ctpop.i32(i32 %4997)
  %4999 = trunc i32 %4998 to i8
  %5000 = and i8 %4999, 1
  %5001 = xor i8 %5000, 1
  store i8 %5001, i8* %26, align 1
  %5002 = xor i32 %4969, %4990
  %5003 = xor i32 %5002, %4991
  %5004 = lshr i32 %5003, 4
  %5005 = trunc i32 %5004 to i8
  %5006 = and i8 %5005, 1
  store i8 %5006, i8* %31, align 1
  %5007 = icmp eq i32 %4991, 0
  %5008 = zext i1 %5007 to i8
  store i8 %5008, i8* %34, align 1
  %5009 = lshr i32 %4991, 31
  %5010 = trunc i32 %5009 to i8
  store i8 %5010, i8* %37, align 1
  %5011 = lshr i32 %4990, 31
  %5012 = lshr i32 %4968, 30
  %5013 = and i32 %5012, 1
  %5014 = xor i32 %5009, %5011
  %5015 = xor i32 %5009, %5013
  %5016 = add nuw nsw i32 %5014, %5015
  %5017 = icmp eq i32 %5016, 2
  %5018 = zext i1 %5017 to i8
  store i8 %5018, i8* %43, align 1
  %5019 = sext i32 %4991 to i64
  store i64 %5019, i64* %R9.i2396, align 8
  %5020 = load i64, i64* %RSI.i4020.pre-phi, align 8
  %5021 = shl nsw i64 %5019, 2
  %5022 = add nsw i64 %5021, 472
  %5023 = add i64 %5022, %5020
  %5024 = add i64 %4965, 23
  store i64 %5024, i64* %3, align 8
  %5025 = inttoptr i64 %5023 to i32*
  %5026 = load i32, i32* %5025, align 4
  %5027 = sext i32 %5026 to i64
  store i64 %5027, i64* %RSI.i4020.pre-phi, align 8
  %5028 = add i64 %4986, -184
  %5029 = add i64 %4965, 30
  store i64 %5029, i64* %3, align 8
  %5030 = inttoptr i64 %5028 to i64*
  %5031 = load i64, i64* %5030, align 8
  store i64 %5031, i64* %R9.i2396, align 8
  %5032 = shl nsw i64 %5027, 3
  %5033 = add i64 %5032, %5031
  %5034 = add i64 %4965, 34
  store i64 %5034, i64* %3, align 8
  %5035 = inttoptr i64 %5033 to i64*
  %5036 = load i64, i64* %5035, align 8
  store i64 %5036, i64* %RSI.i4020.pre-phi, align 8
  %5037 = add i64 %4965, 37
  store i64 %5037, i64* %3, align 8
  %5038 = inttoptr i64 %5036 to i16*
  %5039 = load i16, i16* %5038, align 2
  store i16 %5039, i16* %DI.i2456, align 2
  %5040 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5040, i64* %RSI.i4020.pre-phi, align 8
  %5041 = add i64 %5040, 6504
  %5042 = add i64 %4965, 52
  store i64 %5042, i64* %3, align 8
  %5043 = inttoptr i64 %5041 to i64*
  %5044 = load i64, i64* %5043, align 8
  store i64 %5044, i64* %RSI.i4020.pre-phi, align 8
  %5045 = add i64 %4965, 55
  store i64 %5045, i64* %3, align 8
  %5046 = inttoptr i64 %5044 to i64*
  %5047 = load i64, i64* %5046, align 8
  store i64 %5047, i64* %RSI.i4020.pre-phi, align 8
  %5048 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5048, i64* %R11.i2222, align 8
  %5049 = add i64 %5048, 144
  %5050 = add i64 %4965, 70
  store i64 %5050, i64* %3, align 8
  %5051 = inttoptr i64 %5049 to i32*
  %5052 = load i32, i32* %5051, align 4
  %5053 = zext i32 %5052 to i64
  store i64 %5053, i64* %RAX.i893, align 8
  %5054 = load i64, i64* %RBP.i, align 8
  %5055 = add i64 %5054, -12
  %5056 = add i64 %4965, 73
  store i64 %5056, i64* %3, align 8
  %5057 = inttoptr i64 %5055 to i32*
  %5058 = load i32, i32* %5057, align 4
  %5059 = add i32 %5058, %5052
  %5060 = zext i32 %5059 to i64
  store i64 %5060, i64* %RAX.i893, align 8
  %5061 = icmp ult i32 %5059, %5052
  %5062 = icmp ult i32 %5059, %5058
  %5063 = or i1 %5061, %5062
  %5064 = zext i1 %5063 to i8
  store i8 %5064, i8* %19, align 1
  %5065 = and i32 %5059, 255
  %5066 = tail call i32 @llvm.ctpop.i32(i32 %5065)
  %5067 = trunc i32 %5066 to i8
  %5068 = and i8 %5067, 1
  %5069 = xor i8 %5068, 1
  store i8 %5069, i8* %26, align 1
  %5070 = xor i32 %5058, %5052
  %5071 = xor i32 %5070, %5059
  %5072 = lshr i32 %5071, 4
  %5073 = trunc i32 %5072 to i8
  %5074 = and i8 %5073, 1
  store i8 %5074, i8* %31, align 1
  %5075 = icmp eq i32 %5059, 0
  %5076 = zext i1 %5075 to i8
  store i8 %5076, i8* %34, align 1
  %5077 = lshr i32 %5059, 31
  %5078 = trunc i32 %5077 to i8
  store i8 %5078, i8* %37, align 1
  %5079 = lshr i32 %5052, 31
  %5080 = lshr i32 %5058, 31
  %5081 = xor i32 %5077, %5079
  %5082 = xor i32 %5077, %5080
  %5083 = add nuw nsw i32 %5081, %5082
  %5084 = icmp eq i32 %5083, 2
  %5085 = zext i1 %5084 to i8
  store i8 %5085, i8* %43, align 1
  %5086 = sext i32 %5059 to i64
  store i64 %5086, i64* %R11.i2222, align 8
  %5087 = shl nsw i64 %5086, 3
  %5088 = add i64 %5047, %5087
  %5089 = add i64 %4965, 80
  store i64 %5089, i64* %3, align 8
  %5090 = inttoptr i64 %5088 to i64*
  %5091 = load i64, i64* %5090, align 8
  store i64 %5091, i64* %RSI.i4020.pre-phi, align 8
  store i64 %5048, i64* %R11.i2222, align 8
  %5092 = add i64 %5048, 148
  %5093 = add i64 %4965, 95
  store i64 %5093, i64* %3, align 8
  %5094 = inttoptr i64 %5092 to i32*
  %5095 = load i32, i32* %5094, align 4
  %5096 = zext i32 %5095 to i64
  store i64 %5096, i64* %RAX.i893, align 8
  %5097 = add i64 %5054, -16
  %5098 = add i64 %4965, 98
  store i64 %5098, i64* %3, align 8
  %5099 = inttoptr i64 %5097 to i32*
  %5100 = load i32, i32* %5099, align 4
  %5101 = add i32 %5100, %5095
  %5102 = zext i32 %5101 to i64
  store i64 %5102, i64* %RAX.i893, align 8
  %5103 = icmp ult i32 %5101, %5095
  %5104 = icmp ult i32 %5101, %5100
  %5105 = or i1 %5103, %5104
  %5106 = zext i1 %5105 to i8
  store i8 %5106, i8* %19, align 1
  %5107 = and i32 %5101, 255
  %5108 = tail call i32 @llvm.ctpop.i32(i32 %5107)
  %5109 = trunc i32 %5108 to i8
  %5110 = and i8 %5109, 1
  %5111 = xor i8 %5110, 1
  store i8 %5111, i8* %26, align 1
  %5112 = xor i32 %5100, %5095
  %5113 = xor i32 %5112, %5101
  %5114 = lshr i32 %5113, 4
  %5115 = trunc i32 %5114 to i8
  %5116 = and i8 %5115, 1
  store i8 %5116, i8* %31, align 1
  %5117 = icmp eq i32 %5101, 0
  %5118 = zext i1 %5117 to i8
  store i8 %5118, i8* %34, align 1
  %5119 = lshr i32 %5101, 31
  %5120 = trunc i32 %5119 to i8
  store i8 %5120, i8* %37, align 1
  %5121 = lshr i32 %5095, 31
  %5122 = lshr i32 %5100, 31
  %5123 = xor i32 %5119, %5121
  %5124 = xor i32 %5119, %5122
  %5125 = add nuw nsw i32 %5123, %5124
  %5126 = icmp eq i32 %5125, 2
  %5127 = zext i1 %5126 to i8
  store i8 %5127, i8* %43, align 1
  %5128 = sext i32 %5101 to i64
  store i64 %5128, i64* %R11.i2222, align 8
  %5129 = shl nsw i64 %5128, 3
  %5130 = add i64 %5091, %5129
  %5131 = add i64 %4965, 105
  store i64 %5131, i64* %3, align 8
  %5132 = inttoptr i64 %5130 to i16**
  %5133 = load i16*, i16** %5132, align 8
  %5134 = load i16, i16* %DI.i2456, align 2
  %5135 = add i64 %4965, 108
  store i64 %5135, i64* %3, align 8
  store i16 %5134, i16* %5133, align 2
  %5136 = load i64, i64* %3, align 8
  %5137 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5137, i64* %RSI.i4020.pre-phi, align 8
  %5138 = add i64 %5137, 71928
  %5139 = add i64 %5136, 15
  store i64 %5139, i64* %3, align 8
  %5140 = inttoptr i64 %5138 to i64*
  %5141 = load i64, i64* %5140, align 8
  store i64 %5141, i64* %RSI.i4020.pre-phi, align 8
  %5142 = load i64, i64* %RBP.i, align 8
  %5143 = add i64 %5142, -12
  %5144 = add i64 %5136, 19
  store i64 %5144, i64* %3, align 8
  %5145 = inttoptr i64 %5143 to i32*
  %5146 = load i32, i32* %5145, align 4
  %5147 = sext i32 %5146 to i64
  store i64 %5147, i64* %R11.i2222, align 8
  %5148 = shl nsw i64 %5147, 3
  %5149 = add i64 %5148, %5141
  %5150 = add i64 %5136, 23
  store i64 %5150, i64* %3, align 8
  %5151 = inttoptr i64 %5149 to i64*
  %5152 = load i64, i64* %5151, align 8
  store i64 %5152, i64* %RSI.i4020.pre-phi, align 8
  %5153 = add i64 %5142, -16
  %5154 = add i64 %5136, 27
  store i64 %5154, i64* %3, align 8
  %5155 = inttoptr i64 %5153 to i32*
  %5156 = load i32, i32* %5155, align 4
  %5157 = sext i32 %5156 to i64
  store i64 %5157, i64* %R11.i2222, align 8
  %5158 = shl nsw i64 %5157, 3
  %5159 = add i64 %5158, %5152
  %5160 = add i64 %5136, 31
  store i64 %5160, i64* %3, align 8
  %5161 = inttoptr i64 %5159 to i64*
  %5162 = load i64, i64* %5161, align 8
  store i64 %5162, i64* %RSI.i4020.pre-phi, align 8
  %5163 = add i64 %5136, 34
  store i64 %5163, i64* %3, align 8
  %5164 = inttoptr i64 %5162 to i64*
  %5165 = load i64, i64* %5164, align 8
  store i64 %5165, i64* %RSI.i4020.pre-phi, align 8
  %5166 = add i64 %5136, 38
  store i64 %5166, i64* %3, align 8
  %5167 = load i32, i32* %5155, align 4
  %5168 = sext i32 %5167 to i64
  %5169 = shl nsw i64 %5168, 3
  store i64 %5169, i64* %R11.i2222, align 8
  %5170 = load i64, i64* %RCX.i1197, align 8
  %5171 = add i64 %5169, %5170
  store i64 %5171, i64* %RCX.i1197, align 8
  %5172 = icmp ult i64 %5171, %5170
  %5173 = icmp ult i64 %5171, %5169
  %5174 = or i1 %5172, %5173
  %5175 = zext i1 %5174 to i8
  store i8 %5175, i8* %19, align 1
  %5176 = trunc i64 %5171 to i32
  %5177 = and i32 %5176, 255
  %5178 = tail call i32 @llvm.ctpop.i32(i32 %5177)
  %5179 = trunc i32 %5178 to i8
  %5180 = and i8 %5179, 1
  %5181 = xor i8 %5180, 1
  store i8 %5181, i8* %26, align 1
  %5182 = xor i64 %5169, %5170
  %5183 = xor i64 %5182, %5171
  %5184 = lshr i64 %5183, 4
  %5185 = trunc i64 %5184 to i8
  %5186 = and i8 %5185, 1
  store i8 %5186, i8* %31, align 1
  %5187 = icmp eq i64 %5171, 0
  %5188 = zext i1 %5187 to i8
  store i8 %5188, i8* %34, align 1
  %5189 = lshr i64 %5171, 63
  %5190 = trunc i64 %5189 to i8
  store i8 %5190, i8* %37, align 1
  %5191 = lshr i64 %5170, 63
  %5192 = lshr i64 %5168, 60
  %5193 = and i64 %5192, 1
  %5194 = xor i64 %5189, %5191
  %5195 = xor i64 %5189, %5193
  %5196 = add nuw nsw i64 %5194, %5195
  %5197 = icmp eq i64 %5196, 2
  %5198 = zext i1 %5197 to i8
  store i8 %5198, i8* %43, align 1
  %5199 = add i64 %5136, 49
  store i64 %5199, i64* %3, align 8
  %5200 = load i32, i32* %5145, align 4
  %5201 = sext i32 %5200 to i64
  store i64 %5201, i64* %R11.i2222, align 8
  %5202 = shl nsw i64 %5201, 1
  %5203 = add i64 %5202, %5171
  %5204 = add i64 %5136, 54
  store i64 %5204, i64* %3, align 8
  %5205 = inttoptr i64 %5203 to i16*
  %5206 = load i16, i16* %5205, align 2
  %5207 = sext i16 %5206 to i64
  store i64 %5207, i64* %RCX.i1197, align 8
  %5208 = shl nsw i64 %5207, 3
  %5209 = add i64 %5208, %5165
  %5210 = add i64 %5136, 58
  store i64 %5210, i64* %3, align 8
  %5211 = inttoptr i64 %5209 to i64*
  %5212 = load i64, i64* %5211, align 8
  store i64 %5212, i64* %RCX.i1197, align 8
  %5213 = load i64, i64* %RBP.i, align 8
  %5214 = add i64 %5213, -56
  %5215 = add i64 %5136, 62
  store i64 %5215, i64* %3, align 8
  %5216 = inttoptr i64 %5214 to i64*
  %5217 = load i64, i64* %5216, align 8
  store i64 %5217, i64* %RSI.i4020.pre-phi, align 8
  %5218 = add i64 %5213, -12
  %5219 = add i64 %5136, 65
  store i64 %5219, i64* %3, align 8
  %5220 = inttoptr i64 %5218 to i32*
  %5221 = load i32, i32* %5220, align 4
  %5222 = zext i32 %5221 to i64
  store i64 %5222, i64* %RAX.i893, align 8
  %5223 = sext i32 %5221 to i64
  %5224 = lshr i64 %5223, 32
  store i64 %5224, i64* %2568, align 8
  %5225 = load i32, i32* %R8D.i2445, align 4
  %5226 = add i64 %5136, 69
  store i64 %5226, i64* %3, align 8
  %5227 = sext i32 %5225 to i64
  %5228 = shl nuw i64 %5224, 32
  %5229 = or i64 %5228, %5222
  %5230 = sdiv i64 %5229, %5227
  %5231 = shl i64 %5230, 32
  %5232 = ashr exact i64 %5231, 32
  %5233 = icmp eq i64 %5230, %5232
  br i1 %5233, label %5236, label %5234

; <label>:5234:                                   ; preds = %routine_idivl__r8d.exit2254
  %5235 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %5226, %struct.Memory* %4967)
  %.pre272 = load i64, i64* %RBP.i, align 8
  %.pre273 = load i64, i64* %3, align 8
  %.pre274 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__r8d.exit2147

; <label>:5236:                                   ; preds = %routine_idivl__r8d.exit2254
  %5237 = srem i64 %5229, %5227
  %5238 = and i64 %5230, 4294967295
  store i64 %5238, i64* %RAX.i893, align 8
  %5239 = and i64 %5237, 4294967295
  store i64 %5239, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %5240 = trunc i64 %5230 to i32
  br label %routine_idivl__r8d.exit2147

routine_idivl__r8d.exit2147:                      ; preds = %5236, %5234
  %5241 = phi i32 [ %.pre274, %5234 ], [ %5240, %5236 ]
  %5242 = phi i64 [ %.pre273, %5234 ], [ %5226, %5236 ]
  %5243 = phi i64 [ %.pre272, %5234 ], [ %5213, %5236 ]
  %5244 = phi %struct.Memory* [ %5235, %5234 ], [ %4967, %5236 ]
  %5245 = add i64 %5243, -16
  %5246 = add i64 %5242, 4
  store i64 %5246, i64* %3, align 8
  %5247 = inttoptr i64 %5245 to i32*
  %5248 = load i32, i32* %5247, align 4
  %5249 = zext i32 %5248 to i64
  store i64 %5249, i64* %2572, align 8
  %5250 = add i64 %5243, -192
  %5251 = add i64 %5242, 10
  store i64 %5251, i64* %3, align 8
  %5252 = inttoptr i64 %5250 to i32*
  store i32 %5241, i32* %5252, align 4
  %5253 = load i32, i32* %R10D.i2266, align 4
  %5254 = zext i32 %5253 to i64
  %5255 = load i64, i64* %3, align 8
  store i64 %5254, i64* %RAX.i893, align 8
  %5256 = sext i32 %5253 to i64
  %5257 = lshr i64 %5256, 32
  store i64 %5257, i64* %2568, align 8
  %5258 = load i32, i32* %R8D.i2445, align 4
  %5259 = add i64 %5255, 7
  store i64 %5259, i64* %3, align 8
  %5260 = sext i32 %5258 to i64
  %5261 = shl nuw i64 %5257, 32
  %5262 = or i64 %5261, %5254
  %5263 = sdiv i64 %5262, %5260
  %5264 = shl i64 %5263, 32
  %5265 = ashr exact i64 %5264, 32
  %5266 = icmp eq i64 %5263, %5265
  br i1 %5266, label %5269, label %5267

; <label>:5267:                                   ; preds = %routine_idivl__r8d.exit2147
  %5268 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %5259, %struct.Memory* %5244)
  %.pre275 = load i64, i64* %RAX.i893, align 8
  %.pre276 = load i64, i64* %3, align 8
  br label %routine_idivl__r8d.exit2133

; <label>:5269:                                   ; preds = %routine_idivl__r8d.exit2147
  %5270 = srem i64 %5262, %5260
  %5271 = and i64 %5263, 4294967295
  store i64 %5271, i64* %RAX.i893, align 8
  %5272 = and i64 %5270, 4294967295
  store i64 %5272, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__r8d.exit2133

routine_idivl__r8d.exit2133:                      ; preds = %5269, %5267
  %5273 = phi i64 [ %.pre276, %5267 ], [ %5259, %5269 ]
  %5274 = phi i64 [ %.pre275, %5267 ], [ %5271, %5269 ]
  %5275 = phi %struct.Memory* [ %5268, %5267 ], [ %5244, %5269 ]
  %5276 = trunc i64 %5274 to i32
  %5277 = shl i32 %5276, 1
  %5278 = icmp slt i32 %5276, 0
  %5279 = icmp slt i32 %5277, 0
  %5280 = xor i1 %5278, %5279
  %5281 = zext i32 %5277 to i64
  store i64 %5281, i64* %RAX.i893, align 8
  %.lobit98 = lshr i32 %5276, 31
  %5282 = trunc i32 %.lobit98 to i8
  store i8 %5282, i8* %19, align 1
  %5283 = and i32 %5277, 254
  %5284 = tail call i32 @llvm.ctpop.i32(i32 %5283)
  %5285 = trunc i32 %5284 to i8
  %5286 = and i8 %5285, 1
  %5287 = xor i8 %5286, 1
  store i8 %5287, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %5288 = icmp eq i32 %5277, 0
  %5289 = zext i1 %5288 to i8
  store i8 %5289, i8* %34, align 1
  %5290 = lshr i32 %5276, 30
  %5291 = trunc i32 %5290 to i8
  %5292 = and i8 %5291, 1
  store i8 %5292, i8* %37, align 1
  %5293 = zext i1 %5280 to i8
  store i8 %5293, i8* %43, align 1
  %5294 = load i64, i64* %RBP.i, align 8
  %5295 = add i64 %5294, -192
  %5296 = add i64 %5273, 9
  store i64 %5296, i64* %3, align 8
  %5297 = inttoptr i64 %5295 to i32*
  %5298 = load i32, i32* %5297, align 4
  %5299 = add i32 %5277, %5298
  %5300 = zext i32 %5299 to i64
  store i64 %5300, i64* %2572, align 8
  %5301 = icmp ult i32 %5299, %5298
  %5302 = icmp ult i32 %5299, %5277
  %5303 = or i1 %5301, %5302
  %5304 = zext i1 %5303 to i8
  store i8 %5304, i8* %19, align 1
  %5305 = and i32 %5299, 255
  %5306 = tail call i32 @llvm.ctpop.i32(i32 %5305)
  %5307 = trunc i32 %5306 to i8
  %5308 = and i8 %5307, 1
  %5309 = xor i8 %5308, 1
  store i8 %5309, i8* %26, align 1
  %5310 = xor i32 %5277, %5298
  %5311 = xor i32 %5310, %5299
  %5312 = lshr i32 %5311, 4
  %5313 = trunc i32 %5312 to i8
  %5314 = and i8 %5313, 1
  store i8 %5314, i8* %31, align 1
  %5315 = icmp eq i32 %5299, 0
  %5316 = zext i1 %5315 to i8
  store i8 %5316, i8* %34, align 1
  %5317 = lshr i32 %5299, 31
  %5318 = trunc i32 %5317 to i8
  store i8 %5318, i8* %37, align 1
  %5319 = lshr i32 %5298, 31
  %5320 = lshr i32 %5276, 30
  %5321 = and i32 %5320, 1
  %5322 = xor i32 %5317, %5319
  %5323 = xor i32 %5317, %5321
  %5324 = add nuw nsw i32 %5322, %5323
  %5325 = icmp eq i32 %5324, 2
  %5326 = zext i1 %5325 to i8
  store i8 %5326, i8* %43, align 1
  %5327 = sext i32 %5299 to i64
  store i64 %5327, i64* %R11.i2222, align 8
  %5328 = load i64, i64* %RSI.i4020.pre-phi, align 8
  %5329 = shl nsw i64 %5327, 2
  %5330 = add nsw i64 %5329, 472
  %5331 = add i64 %5330, %5328
  %5332 = add i64 %5273, 23
  store i64 %5332, i64* %3, align 8
  %5333 = inttoptr i64 %5331 to i32*
  %5334 = load i32, i32* %5333, align 4
  %5335 = sext i32 %5334 to i64
  store i64 %5335, i64* %RSI.i4020.pre-phi, align 8
  %5336 = load i64, i64* %RCX.i1197, align 8
  %5337 = shl nsw i64 %5335, 3
  %5338 = add i64 %5337, %5336
  %5339 = add i64 %5273, 27
  store i64 %5339, i64* %3, align 8
  %5340 = inttoptr i64 %5338 to i64*
  %5341 = load i64, i64* %5340, align 8
  store i64 %5341, i64* %RCX.i1197, align 8
  %5342 = add i64 %5341, 2
  %5343 = add i64 %5273, 31
  store i64 %5343, i64* %3, align 8
  %5344 = inttoptr i64 %5342 to i16*
  %5345 = load i16, i16* %5344, align 2
  store i16 %5345, i16* %DI.i2456, align 2
  %5346 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5346, i64* %RCX.i1197, align 8
  %5347 = add i64 %5346, 6504
  %5348 = add i64 %5273, 46
  store i64 %5348, i64* %3, align 8
  %5349 = inttoptr i64 %5347 to i64*
  %5350 = load i64, i64* %5349, align 8
  store i64 %5350, i64* %RCX.i1197, align 8
  %5351 = add i64 %5273, 49
  store i64 %5351, i64* %3, align 8
  %5352 = inttoptr i64 %5350 to i64*
  %5353 = load i64, i64* %5352, align 8
  store i64 %5353, i64* %RCX.i1197, align 8
  %5354 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5354, i64* %RSI.i4020.pre-phi, align 8
  %5355 = add i64 %5354, 144
  %5356 = add i64 %5273, 63
  store i64 %5356, i64* %3, align 8
  %5357 = inttoptr i64 %5355 to i32*
  %5358 = load i32, i32* %5357, align 4
  %5359 = zext i32 %5358 to i64
  store i64 %5359, i64* %RAX.i893, align 8
  %5360 = load i64, i64* %RBP.i, align 8
  %5361 = add i64 %5360, -12
  %5362 = add i64 %5273, 66
  store i64 %5362, i64* %3, align 8
  %5363 = inttoptr i64 %5361 to i32*
  %5364 = load i32, i32* %5363, align 4
  %5365 = add i32 %5364, %5358
  %5366 = zext i32 %5365 to i64
  store i64 %5366, i64* %RAX.i893, align 8
  %5367 = icmp ult i32 %5365, %5358
  %5368 = icmp ult i32 %5365, %5364
  %5369 = or i1 %5367, %5368
  %5370 = zext i1 %5369 to i8
  store i8 %5370, i8* %19, align 1
  %5371 = and i32 %5365, 255
  %5372 = tail call i32 @llvm.ctpop.i32(i32 %5371)
  %5373 = trunc i32 %5372 to i8
  %5374 = and i8 %5373, 1
  %5375 = xor i8 %5374, 1
  store i8 %5375, i8* %26, align 1
  %5376 = xor i32 %5364, %5358
  %5377 = xor i32 %5376, %5365
  %5378 = lshr i32 %5377, 4
  %5379 = trunc i32 %5378 to i8
  %5380 = and i8 %5379, 1
  store i8 %5380, i8* %31, align 1
  %5381 = icmp eq i32 %5365, 0
  %5382 = zext i1 %5381 to i8
  store i8 %5382, i8* %34, align 1
  %5383 = lshr i32 %5365, 31
  %5384 = trunc i32 %5383 to i8
  store i8 %5384, i8* %37, align 1
  %5385 = lshr i32 %5358, 31
  %5386 = lshr i32 %5364, 31
  %5387 = xor i32 %5383, %5385
  %5388 = xor i32 %5383, %5386
  %5389 = add nuw nsw i32 %5387, %5388
  %5390 = icmp eq i32 %5389, 2
  %5391 = zext i1 %5390 to i8
  store i8 %5391, i8* %43, align 1
  %5392 = sext i32 %5365 to i64
  store i64 %5392, i64* %RSI.i4020.pre-phi, align 8
  %5393 = shl nsw i64 %5392, 3
  %5394 = add i64 %5353, %5393
  %5395 = add i64 %5273, 73
  store i64 %5395, i64* %3, align 8
  %5396 = inttoptr i64 %5394 to i64*
  %5397 = load i64, i64* %5396, align 8
  store i64 %5397, i64* %RCX.i1197, align 8
  store i64 %5354, i64* %RSI.i4020.pre-phi, align 8
  %5398 = add i64 %5354, 148
  %5399 = add i64 %5273, 87
  store i64 %5399, i64* %3, align 8
  %5400 = inttoptr i64 %5398 to i32*
  %5401 = load i32, i32* %5400, align 4
  %5402 = zext i32 %5401 to i64
  store i64 %5402, i64* %RAX.i893, align 8
  %5403 = add i64 %5360, -16
  %5404 = add i64 %5273, 90
  store i64 %5404, i64* %3, align 8
  %5405 = inttoptr i64 %5403 to i32*
  %5406 = load i32, i32* %5405, align 4
  %5407 = add i32 %5406, %5401
  %5408 = zext i32 %5407 to i64
  store i64 %5408, i64* %RAX.i893, align 8
  %5409 = icmp ult i32 %5407, %5401
  %5410 = icmp ult i32 %5407, %5406
  %5411 = or i1 %5409, %5410
  %5412 = zext i1 %5411 to i8
  store i8 %5412, i8* %19, align 1
  %5413 = and i32 %5407, 255
  %5414 = tail call i32 @llvm.ctpop.i32(i32 %5413)
  %5415 = trunc i32 %5414 to i8
  %5416 = and i8 %5415, 1
  %5417 = xor i8 %5416, 1
  store i8 %5417, i8* %26, align 1
  %5418 = xor i32 %5406, %5401
  %5419 = xor i32 %5418, %5407
  %5420 = lshr i32 %5419, 4
  %5421 = trunc i32 %5420 to i8
  %5422 = and i8 %5421, 1
  store i8 %5422, i8* %31, align 1
  %5423 = icmp eq i32 %5407, 0
  %5424 = zext i1 %5423 to i8
  store i8 %5424, i8* %34, align 1
  %5425 = lshr i32 %5407, 31
  %5426 = trunc i32 %5425 to i8
  store i8 %5426, i8* %37, align 1
  %5427 = lshr i32 %5401, 31
  %5428 = lshr i32 %5406, 31
  %5429 = xor i32 %5425, %5427
  %5430 = xor i32 %5425, %5428
  %5431 = add nuw nsw i32 %5429, %5430
  %5432 = icmp eq i32 %5431, 2
  %5433 = zext i1 %5432 to i8
  store i8 %5433, i8* %43, align 1
  %5434 = sext i32 %5407 to i64
  store i64 %5434, i64* %RSI.i4020.pre-phi, align 8
  %5435 = shl nsw i64 %5434, 3
  %5436 = add i64 %5397, %5435
  %5437 = add i64 %5273, 97
  store i64 %5437, i64* %3, align 8
  %5438 = inttoptr i64 %5436 to i64*
  %5439 = load i64, i64* %5438, align 8
  %5440 = add i64 %5439, 2
  %5441 = load i16, i16* %DI.i2456, align 2
  %5442 = add i64 %5273, 101
  store i64 %5442, i64* %3, align 8
  %5443 = inttoptr i64 %5440 to i16*
  store i16 %5441, i16* %5443, align 2
  %5444 = load i64, i64* %3, align 8
  %5445 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5445, i64* %RCX.i1197, align 8
  %5446 = add i64 %5445, 72400
  %5447 = add i64 %5444, 15
  store i64 %5447, i64* %3, align 8
  %5448 = inttoptr i64 %5446 to i32*
  %5449 = load i32, i32* %5448, align 4
  store i8 0, i8* %19, align 1
  %5450 = and i32 %5449, 255
  %5451 = tail call i32 @llvm.ctpop.i32(i32 %5450)
  %5452 = trunc i32 %5451 to i8
  %5453 = and i8 %5452, 1
  %5454 = xor i8 %5453, 1
  store i8 %5454, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %5455 = icmp eq i32 %5449, 0
  %5456 = zext i1 %5455 to i8
  store i8 %5456, i8* %34, align 1
  %5457 = lshr i32 %5449, 31
  %5458 = trunc i32 %5457 to i8
  store i8 %5458, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v348 = select i1 %5455, i64 83, i64 21
  %5459 = add i64 %5444, %.v348
  store i64 %5459, i64* %3, align 8
  br i1 %5455, label %block_.L_48ebd8, label %block_48eb9a

block_48eb9a:                                     ; preds = %routine_idivl__r8d.exit2133
  store i64 ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64), i64* %RAX.i893, align 8
  %5460 = load i64, i64* %RBP.i, align 8
  %5461 = add i64 %5460, -16
  %5462 = add i64 %5459, 14
  store i64 %5462, i64* %3, align 8
  %5463 = inttoptr i64 %5461 to i32*
  %5464 = load i32, i32* %5463, align 4
  %5465 = sext i32 %5464 to i64
  %5466 = shl nsw i64 %5465, 3
  store i64 %5466, i64* %RCX.i1197, align 8
  %5467 = add i64 %5466, ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64)
  store i64 %5467, i64* %RAX.i893, align 8
  %5468 = icmp ult i64 %5467, ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64)
  %5469 = icmp ult i64 %5467, %5466
  %5470 = or i1 %5468, %5469
  %5471 = zext i1 %5470 to i8
  store i8 %5471, i8* %19, align 1
  %5472 = trunc i64 %5467 to i32
  %5473 = and i32 %5472, 248
  %5474 = tail call i32 @llvm.ctpop.i32(i32 %5473)
  %5475 = trunc i32 %5474 to i8
  %5476 = and i8 %5475, 1
  %5477 = xor i8 %5476, 1
  store i8 %5477, i8* %26, align 1
  %5478 = xor i64 %5466, ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64)
  %5479 = xor i64 %5478, %5467
  %5480 = lshr i64 %5479, 4
  %5481 = trunc i64 %5480 to i8
  %5482 = and i8 %5481, 1
  store i8 %5482, i8* %31, align 1
  %5483 = icmp eq i64 %5467, 0
  %5484 = zext i1 %5483 to i8
  store i8 %5484, i8* %34, align 1
  %5485 = lshr i64 %5467, 63
  %5486 = trunc i64 %5485 to i8
  store i8 %5486, i8* %37, align 1
  %5487 = lshr i64 %5465, 60
  %5488 = and i64 %5487, 1
  %5489 = xor i64 %5485, lshr (i64 ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64), i64 63)
  %5490 = xor i64 %5485, %5488
  %5491 = add nuw nsw i64 %5489, %5490
  %5492 = icmp eq i64 %5491, 2
  %5493 = zext i1 %5492 to i8
  store i8 %5493, i8* %43, align 1
  %5494 = add i64 %5460, -12
  %5495 = add i64 %5459, 25
  store i64 %5495, i64* %3, align 8
  %5496 = inttoptr i64 %5494 to i32*
  %5497 = load i32, i32* %5496, align 4
  %5498 = sext i32 %5497 to i64
  store i64 %5498, i64* %RCX.i1197, align 8
  %5499 = shl nsw i64 %5498, 1
  %5500 = add i64 %5499, %5467
  %5501 = add i64 %5459, 29
  store i64 %5501, i64* %3, align 8
  %5502 = inttoptr i64 %5500 to i16*
  %5503 = load i16, i16* %5502, align 2
  store i16 %5503, i16* %DX.i4027, align 2
  %5504 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %5505 = add i64 %5504, 3264
  store i64 %5505, i64* %RAX.i893, align 8
  %5506 = icmp ugt i64 %5504, -3265
  %5507 = zext i1 %5506 to i8
  store i8 %5507, i8* %19, align 1
  %5508 = trunc i64 %5505 to i32
  %5509 = and i32 %5508, 255
  %5510 = tail call i32 @llvm.ctpop.i32(i32 %5509)
  %5511 = trunc i32 %5510 to i8
  %5512 = and i8 %5511, 1
  %5513 = xor i8 %5512, 1
  store i8 %5513, i8* %26, align 1
  %5514 = xor i64 %5505, %5504
  %5515 = lshr i64 %5514, 4
  %5516 = trunc i64 %5515 to i8
  %5517 = and i8 %5516, 1
  store i8 %5517, i8* %31, align 1
  %5518 = icmp eq i64 %5505, 0
  %5519 = zext i1 %5518 to i8
  store i8 %5519, i8* %34, align 1
  %5520 = lshr i64 %5505, 63
  %5521 = trunc i64 %5520 to i8
  store i8 %5521, i8* %37, align 1
  %5522 = lshr i64 %5504, 63
  %5523 = xor i64 %5520, %5522
  %5524 = add nuw nsw i64 %5523, %5520
  %5525 = icmp eq i64 %5524, 2
  %5526 = zext i1 %5525 to i8
  store i8 %5526, i8* %43, align 1
  %5527 = load i64, i64* %RBP.i, align 8
  %5528 = add i64 %5527, -16
  %5529 = add i64 %5459, 47
  store i64 %5529, i64* %3, align 8
  %5530 = inttoptr i64 %5528 to i32*
  %5531 = load i32, i32* %5530, align 4
  %5532 = sext i32 %5531 to i64
  %5533 = shl nsw i64 %5532, 3
  store i64 %5533, i64* %RCX.i1197, align 8
  %5534 = add i64 %5533, %5505
  store i64 %5534, i64* %RAX.i893, align 8
  %5535 = icmp ult i64 %5534, %5505
  %5536 = icmp ult i64 %5534, %5533
  %5537 = or i1 %5535, %5536
  %5538 = zext i1 %5537 to i8
  store i8 %5538, i8* %19, align 1
  %5539 = trunc i64 %5534 to i32
  %5540 = and i32 %5539, 255
  %5541 = tail call i32 @llvm.ctpop.i32(i32 %5540)
  %5542 = trunc i32 %5541 to i8
  %5543 = and i8 %5542, 1
  %5544 = xor i8 %5543, 1
  store i8 %5544, i8* %26, align 1
  %5545 = xor i64 %5533, %5505
  %5546 = xor i64 %5545, %5534
  %5547 = lshr i64 %5546, 4
  %5548 = trunc i64 %5547 to i8
  %5549 = and i8 %5548, 1
  store i8 %5549, i8* %31, align 1
  %5550 = icmp eq i64 %5534, 0
  %5551 = zext i1 %5550 to i8
  store i8 %5551, i8* %34, align 1
  %5552 = lshr i64 %5534, 63
  %5553 = trunc i64 %5552 to i8
  store i8 %5553, i8* %37, align 1
  %5554 = lshr i64 %5532, 60
  %5555 = and i64 %5554, 1
  %5556 = xor i64 %5552, %5520
  %5557 = xor i64 %5552, %5555
  %5558 = add nuw nsw i64 %5556, %5557
  %5559 = icmp eq i64 %5558, 2
  %5560 = zext i1 %5559 to i8
  store i8 %5560, i8* %43, align 1
  %5561 = add i64 %5527, -12
  %5562 = add i64 %5459, 58
  store i64 %5562, i64* %3, align 8
  %5563 = inttoptr i64 %5561 to i32*
  %5564 = load i32, i32* %5563, align 4
  %5565 = sext i32 %5564 to i64
  store i64 %5565, i64* %RCX.i1197, align 8
  %5566 = shl nsw i64 %5565, 1
  %5567 = add i64 %5566, %5534
  %5568 = load i16, i16* %DX.i4027, align 2
  %5569 = add i64 %5459, 62
  store i64 %5569, i64* %3, align 8
  %5570 = inttoptr i64 %5567 to i16*
  store i16 %5568, i16* %5570, align 2
  %.pre277 = load i64, i64* %3, align 8
  br label %block_.L_48ebd8

block_.L_48ebd8:                                  ; preds = %block_48eb9a, %routine_idivl__r8d.exit2133
  %5571 = phi i64 [ %.pre277, %block_48eb9a ], [ %5459, %routine_idivl__r8d.exit2133 ]
  %5572 = add i64 %5571, 5
  store i64 %5572, i64* %3, align 8
  br label %block_.L_48ebdd

block_.L_48ebdd:                                  ; preds = %block_.L_48ebd8, %block_.L_48e8c9
  %storemerge93 = phi i64 [ %4439, %block_.L_48e8c9 ], [ %5572, %block_.L_48ebd8 ]
  %MEMORY.32 = phi %struct.Memory* [ %4187, %block_.L_48e8c9 ], [ %5275, %block_.L_48ebd8 ]
  %5573 = add i64 %storemerge93, 5
  store i64 %5573, i64* %3, align 8
  br label %block_.L_48ebe2

block_.L_48ebe2:                                  ; preds = %block_.L_48ebdd, %block_.L_48e5db
  %storemerge86 = phi i64 [ %3339, %block_.L_48e5db ], [ %5573, %block_.L_48ebdd ]
  %MEMORY.33 = phi %struct.Memory* [ %2707, %block_.L_48e5db ], [ %MEMORY.32, %block_.L_48ebdd ]
  store i64 2, i64* %RAX.i893, align 8
  %5574 = load i64, i64* %RBP.i, align 8
  %5575 = add i64 %5574, -56
  %5576 = add i64 %storemerge86, 9
  store i64 %5576, i64* %3, align 8
  %5577 = inttoptr i64 %5575 to i64*
  %5578 = load i64, i64* %5577, align 8
  store i64 %5578, i64* %RCX.i1197, align 8
  %5579 = add i64 %5574, -12
  %5580 = add i64 %storemerge86, 12
  store i64 %5580, i64* %3, align 8
  %5581 = inttoptr i64 %5579 to i32*
  %5582 = load i32, i32* %5581, align 4
  %5583 = zext i32 %5582 to i64
  store i64 %5583, i64* %RDX.i1708, align 8
  %5584 = add i64 %5574, -196
  %5585 = add i64 %storemerge86, 18
  store i64 %5585, i64* %3, align 8
  %5586 = inttoptr i64 %5584 to i32*
  store i32 2, i32* %5586, align 4
  %5587 = load i32, i32* %EDX.i1723, align 4
  %5588 = zext i32 %5587 to i64
  %5589 = load i64, i64* %3, align 8
  store i64 %5588, i64* %RAX.i893, align 8
  %5590 = sext i32 %5587 to i64
  %5591 = lshr i64 %5590, 32
  store i64 %5591, i64* %2568, align 8
  %5592 = load i64, i64* %RBP.i, align 8
  %5593 = add i64 %5592, -196
  %5594 = add i64 %5589, 9
  store i64 %5594, i64* %3, align 8
  %5595 = inttoptr i64 %5593 to i32*
  %5596 = load i32, i32* %5595, align 4
  %5597 = zext i32 %5596 to i64
  store i64 %5597, i64* %RSI.i4020.pre-phi, align 8
  %5598 = add i64 %5589, 11
  store i64 %5598, i64* %3, align 8
  %5599 = sext i32 %5596 to i64
  %5600 = shl nuw i64 %5591, 32
  %5601 = or i64 %5600, %5588
  %5602 = sdiv i64 %5601, %5599
  %5603 = shl i64 %5602, 32
  %5604 = ashr exact i64 %5603, 32
  %5605 = icmp eq i64 %5602, %5604
  br i1 %5605, label %5608, label %5606

; <label>:5606:                                   ; preds = %block_.L_48ebe2
  %5607 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %5598, %struct.Memory* %MEMORY.33)
  %.pre279 = load i64, i64* %RBP.i, align 8
  %.pre280 = load i64, i64* %3, align 8
  %.pre281 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__esi.exit2010

; <label>:5608:                                   ; preds = %block_.L_48ebe2
  %5609 = srem i64 %5601, %5599
  %5610 = and i64 %5602, 4294967295
  store i64 %5610, i64* %RAX.i893, align 8
  %5611 = and i64 %5609, 4294967295
  store i64 %5611, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %5612 = trunc i64 %5602 to i32
  br label %routine_idivl__esi.exit2010

routine_idivl__esi.exit2010:                      ; preds = %5608, %5606
  %5613 = phi i32 [ %.pre281, %5606 ], [ %5612, %5608 ]
  %5614 = phi i64 [ %.pre280, %5606 ], [ %5598, %5608 ]
  %5615 = phi i64 [ %.pre279, %5606 ], [ %5592, %5608 ]
  %5616 = phi %struct.Memory* [ %5607, %5606 ], [ %MEMORY.33, %5608 ]
  %5617 = add i64 %5615, -16
  %5618 = add i64 %5614, 3
  store i64 %5618, i64* %3, align 8
  %5619 = inttoptr i64 %5617 to i32*
  %5620 = load i32, i32* %5619, align 4
  %5621 = zext i32 %5620 to i64
  store i64 %5621, i64* %RDI.i3116, align 8
  %5622 = add i64 %5615, -200
  %5623 = add i64 %5614, 9
  store i64 %5623, i64* %3, align 8
  %5624 = inttoptr i64 %5622 to i32*
  store i32 %5613, i32* %5624, align 4
  %5625 = load i32, i32* %EDI.i3110, align 4
  %5626 = zext i32 %5625 to i64
  %5627 = load i64, i64* %3, align 8
  store i64 %5626, i64* %RAX.i893, align 8
  %5628 = sext i32 %5625 to i64
  %5629 = lshr i64 %5628, 32
  store i64 %5629, i64* %2568, align 8
  %5630 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %5631 = add i64 %5627, 5
  store i64 %5631, i64* %3, align 8
  %5632 = sext i32 %5630 to i64
  %5633 = shl nuw i64 %5629, 32
  %5634 = or i64 %5633, %5626
  %5635 = sdiv i64 %5634, %5632
  %5636 = shl i64 %5635, 32
  %5637 = ashr exact i64 %5636, 32
  %5638 = icmp eq i64 %5635, %5637
  br i1 %5638, label %5641, label %5639

; <label>:5639:                                   ; preds = %routine_idivl__esi.exit2010
  %5640 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %5631, %struct.Memory* %5616)
  %.pre282 = load i64, i64* %RAX.i893, align 8
  %.pre283 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit1995

; <label>:5641:                                   ; preds = %routine_idivl__esi.exit2010
  %5642 = srem i64 %5634, %5632
  %5643 = and i64 %5635, 4294967295
  store i64 %5643, i64* %RAX.i893, align 8
  %5644 = and i64 %5642, 4294967295
  store i64 %5644, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__esi.exit1995

routine_idivl__esi.exit1995:                      ; preds = %5641, %5639
  %5645 = phi i64 [ %.pre283, %5639 ], [ %5631, %5641 ]
  %5646 = phi i64 [ %.pre282, %5639 ], [ %5643, %5641 ]
  %5647 = phi %struct.Memory* [ %5640, %5639 ], [ %5616, %5641 ]
  %5648 = trunc i64 %5646 to i32
  %5649 = shl i32 %5648, 1
  %5650 = icmp slt i32 %5648, 0
  %5651 = icmp slt i32 %5649, 0
  %5652 = xor i1 %5650, %5651
  %5653 = zext i32 %5649 to i64
  store i64 %5653, i64* %RAX.i893, align 8
  %.lobit87 = lshr i32 %5648, 31
  %5654 = trunc i32 %.lobit87 to i8
  store i8 %5654, i8* %19, align 1
  %5655 = and i32 %5649, 254
  %5656 = tail call i32 @llvm.ctpop.i32(i32 %5655)
  %5657 = trunc i32 %5656 to i8
  %5658 = and i8 %5657, 1
  %5659 = xor i8 %5658, 1
  store i8 %5659, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %5660 = icmp eq i32 %5649, 0
  %5661 = zext i1 %5660 to i8
  store i8 %5661, i8* %34, align 1
  %5662 = lshr i32 %5648, 30
  %5663 = trunc i32 %5662 to i8
  %5664 = and i8 %5663, 1
  store i8 %5664, i8* %37, align 1
  %5665 = zext i1 %5652 to i8
  store i8 %5665, i8* %43, align 1
  %5666 = load i64, i64* %RBP.i, align 8
  %5667 = add i64 %5666, -200
  %5668 = add i64 %5645, 8
  store i64 %5668, i64* %3, align 8
  %5669 = inttoptr i64 %5667 to i32*
  %5670 = load i32, i32* %5669, align 4
  %5671 = add i32 %5649, %5670
  %5672 = zext i32 %5671 to i64
  store i64 %5672, i64* %RDI.i3116, align 8
  %5673 = icmp ult i32 %5671, %5670
  %5674 = icmp ult i32 %5671, %5649
  %5675 = or i1 %5673, %5674
  %5676 = zext i1 %5675 to i8
  store i8 %5676, i8* %19, align 1
  %5677 = and i32 %5671, 255
  %5678 = tail call i32 @llvm.ctpop.i32(i32 %5677)
  %5679 = trunc i32 %5678 to i8
  %5680 = and i8 %5679, 1
  %5681 = xor i8 %5680, 1
  store i8 %5681, i8* %26, align 1
  %5682 = xor i32 %5649, %5670
  %5683 = xor i32 %5682, %5671
  %5684 = lshr i32 %5683, 4
  %5685 = trunc i32 %5684 to i8
  %5686 = and i8 %5685, 1
  store i8 %5686, i8* %31, align 1
  %5687 = icmp eq i32 %5671, 0
  %5688 = zext i1 %5687 to i8
  store i8 %5688, i8* %34, align 1
  %5689 = lshr i32 %5671, 31
  %5690 = trunc i32 %5689 to i8
  store i8 %5690, i8* %37, align 1
  %5691 = lshr i32 %5670, 31
  %5692 = lshr i32 %5648, 30
  %5693 = and i32 %5692, 1
  %5694 = xor i32 %5689, %5691
  %5695 = xor i32 %5689, %5693
  %5696 = add nuw nsw i32 %5694, %5695
  %5697 = icmp eq i32 %5696, 2
  %5698 = zext i1 %5697 to i8
  store i8 %5698, i8* %43, align 1
  %5699 = sext i32 %5671 to i64
  store i64 %5699, i64* %R8.i3094, align 8
  %5700 = load i64, i64* %RCX.i1197, align 8
  %5701 = shl nsw i64 %5699, 2
  %5702 = add nsw i64 %5701, 488
  %5703 = add i64 %5702, %5700
  %5704 = add i64 %5645, 22
  store i64 %5704, i64* %3, align 8
  %5705 = inttoptr i64 %5703 to i32*
  %5706 = load i32, i32* %5705, align 4
  store i8 0, i8* %19, align 1
  %5707 = and i32 %5706, 255
  %5708 = tail call i32 @llvm.ctpop.i32(i32 %5707)
  %5709 = trunc i32 %5708 to i8
  %5710 = and i8 %5709, 1
  %5711 = xor i8 %5710, 1
  store i8 %5711, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %5712 = icmp eq i32 %5706, 0
  %5713 = zext i1 %5712 to i8
  store i8 %5713, i8* %34, align 1
  %5714 = lshr i32 %5706, 31
  %5715 = trunc i32 %5714 to i8
  store i8 %5715, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v349 = select i1 %5712, i64 70, i64 28
  %5716 = add i64 %5645, %.v349
  store i64 %5716, i64* %3, align 8
  br i1 %5712, label %block_.L_48ec54, label %block_48ec2a

block_48ec2a:                                     ; preds = %routine_idivl__esi.exit1995
  %5717 = add i64 %5666, -56
  %5718 = add i64 %5716, 4
  store i64 %5718, i64* %3, align 8
  %5719 = inttoptr i64 %5717 to i64*
  %5720 = load i64, i64* %5719, align 8
  store i64 %5720, i64* %RAX.i893, align 8
  %5721 = add i64 %5720, 72
  %5722 = add i64 %5716, 8
  store i64 %5722, i64* %3, align 8
  %5723 = inttoptr i64 %5721 to i32*
  %5724 = load i32, i32* %5723, align 4
  %5725 = add i32 %5724, -9
  %5726 = icmp ult i32 %5724, 9
  %5727 = zext i1 %5726 to i8
  store i8 %5727, i8* %19, align 1
  %5728 = and i32 %5725, 255
  %5729 = tail call i32 @llvm.ctpop.i32(i32 %5728)
  %5730 = trunc i32 %5729 to i8
  %5731 = and i8 %5730, 1
  %5732 = xor i8 %5731, 1
  store i8 %5732, i8* %26, align 1
  %5733 = xor i32 %5725, %5724
  %5734 = lshr i32 %5733, 4
  %5735 = trunc i32 %5734 to i8
  %5736 = and i8 %5735, 1
  store i8 %5736, i8* %31, align 1
  %5737 = icmp eq i32 %5725, 0
  %5738 = zext i1 %5737 to i8
  store i8 %5738, i8* %34, align 1
  %5739 = lshr i32 %5725, 31
  %5740 = trunc i32 %5739 to i8
  store i8 %5740, i8* %37, align 1
  %5741 = lshr i32 %5724, 31
  %5742 = xor i32 %5739, %5741
  %5743 = add nuw nsw i32 %5742, %5741
  %5744 = icmp eq i32 %5743, 2
  %5745 = zext i1 %5744 to i8
  store i8 %5745, i8* %43, align 1
  %.v350 = select i1 %5737, i64 42, i64 14
  %5746 = add i64 %5716, %.v350
  store i64 %5746, i64* %3, align 8
  br i1 %5737, label %block_.L_48ec54, label %block_48ec38

block_48ec38:                                     ; preds = %block_48ec2a
  %5747 = add i64 %5746, 4
  store i64 %5747, i64* %3, align 8
  %5748 = load i64, i64* %5719, align 8
  store i64 %5748, i64* %RAX.i893, align 8
  %5749 = add i64 %5748, 72
  %5750 = add i64 %5746, 8
  store i64 %5750, i64* %3, align 8
  %5751 = inttoptr i64 %5749 to i32*
  %5752 = load i32, i32* %5751, align 4
  %5753 = add i32 %5752, -10
  %5754 = icmp ult i32 %5752, 10
  %5755 = zext i1 %5754 to i8
  store i8 %5755, i8* %19, align 1
  %5756 = and i32 %5753, 255
  %5757 = tail call i32 @llvm.ctpop.i32(i32 %5756)
  %5758 = trunc i32 %5757 to i8
  %5759 = and i8 %5758, 1
  %5760 = xor i8 %5759, 1
  store i8 %5760, i8* %26, align 1
  %5761 = xor i32 %5753, %5752
  %5762 = lshr i32 %5761, 4
  %5763 = trunc i32 %5762 to i8
  %5764 = and i8 %5763, 1
  store i8 %5764, i8* %31, align 1
  %5765 = icmp eq i32 %5753, 0
  %5766 = zext i1 %5765 to i8
  store i8 %5766, i8* %34, align 1
  %5767 = lshr i32 %5753, 31
  %5768 = trunc i32 %5767 to i8
  store i8 %5768, i8* %37, align 1
  %5769 = lshr i32 %5752, 31
  %5770 = xor i32 %5767, %5769
  %5771 = add nuw nsw i32 %5770, %5769
  %5772 = icmp eq i32 %5771, 2
  %5773 = zext i1 %5772 to i8
  store i8 %5773, i8* %43, align 1
  %.v351 = select i1 %5765, i64 28, i64 14
  %5774 = add i64 %5746, %.v351
  store i64 %5774, i64* %3, align 8
  br i1 %5765, label %block_.L_48ec54, label %block_48ec46

block_48ec46:                                     ; preds = %block_48ec38
  %5775 = add i64 %5774, 4
  store i64 %5775, i64* %3, align 8
  %5776 = load i64, i64* %5719, align 8
  store i64 %5776, i64* %RAX.i893, align 8
  %5777 = add i64 %5776, 72
  %5778 = add i64 %5774, 8
  store i64 %5778, i64* %3, align 8
  %5779 = inttoptr i64 %5777 to i32*
  %5780 = load i32, i32* %5779, align 4
  %5781 = add i32 %5780, -13
  %5782 = icmp ult i32 %5780, 13
  %5783 = zext i1 %5782 to i8
  store i8 %5783, i8* %19, align 1
  %5784 = and i32 %5781, 255
  %5785 = tail call i32 @llvm.ctpop.i32(i32 %5784)
  %5786 = trunc i32 %5785 to i8
  %5787 = and i8 %5786, 1
  %5788 = xor i8 %5787, 1
  store i8 %5788, i8* %26, align 1
  %5789 = xor i32 %5781, %5780
  %5790 = lshr i32 %5789, 4
  %5791 = trunc i32 %5790 to i8
  %5792 = and i8 %5791, 1
  store i8 %5792, i8* %31, align 1
  %5793 = icmp eq i32 %5781, 0
  %5794 = zext i1 %5793 to i8
  store i8 %5794, i8* %34, align 1
  %5795 = lshr i32 %5781, 31
  %5796 = trunc i32 %5795 to i8
  store i8 %5796, i8* %37, align 1
  %5797 = lshr i32 %5780, 31
  %5798 = xor i32 %5795, %5797
  %5799 = add nuw nsw i32 %5798, %5797
  %5800 = icmp eq i32 %5799, 2
  %5801 = zext i1 %5800 to i8
  store i8 %5801, i8* %43, align 1
  %.v352 = select i1 %5793, i64 14, i64 364
  %5802 = add i64 %5774, %.v352
  store i64 %5802, i64* %3, align 8
  br i1 %5793, label %block_.L_48ec54, label %block_.L_48edb2

block_.L_48ec54:                                  ; preds = %block_48ec46, %block_48ec38, %block_48ec2a, %routine_idivl__esi.exit1995
  %5803 = phi i64 [ %5802, %block_48ec46 ], [ %5774, %block_48ec38 ], [ %5746, %block_48ec2a ], [ %5716, %routine_idivl__esi.exit1995 ]
  %5804 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5804, i64* %RAX.i893, align 8
  %5805 = add i64 %5804, 6480
  %5806 = add i64 %5803, 15
  store i64 %5806, i64* %3, align 8
  %5807 = inttoptr i64 %5805 to i64*
  %5808 = load i64, i64* %5807, align 8
  store i64 %5808, i64* %RAX.i893, align 8
  %5809 = add i64 %5808, 8
  %5810 = add i64 %5803, 19
  store i64 %5810, i64* %3, align 8
  %5811 = inttoptr i64 %5809 to i64*
  %5812 = load i64, i64* %5811, align 8
  store i64 %5812, i64* %RAX.i893, align 8
  %5813 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5813, i64* %RCX.i1197, align 8
  %5814 = add i64 %5813, 144
  %5815 = add i64 %5803, 33
  store i64 %5815, i64* %3, align 8
  %5816 = inttoptr i64 %5814 to i32*
  %5817 = load i32, i32* %5816, align 4
  %5818 = zext i32 %5817 to i64
  store i64 %5818, i64* %RDX.i1708, align 8
  %5819 = add i64 %5666, -12
  %5820 = add i64 %5803, 36
  store i64 %5820, i64* %3, align 8
  %5821 = inttoptr i64 %5819 to i32*
  %5822 = load i32, i32* %5821, align 4
  %5823 = add i32 %5822, %5817
  %5824 = zext i32 %5823 to i64
  store i64 %5824, i64* %RDX.i1708, align 8
  %5825 = icmp ult i32 %5823, %5817
  %5826 = icmp ult i32 %5823, %5822
  %5827 = or i1 %5825, %5826
  %5828 = zext i1 %5827 to i8
  store i8 %5828, i8* %19, align 1
  %5829 = and i32 %5823, 255
  %5830 = tail call i32 @llvm.ctpop.i32(i32 %5829)
  %5831 = trunc i32 %5830 to i8
  %5832 = and i8 %5831, 1
  %5833 = xor i8 %5832, 1
  store i8 %5833, i8* %26, align 1
  %5834 = xor i32 %5822, %5817
  %5835 = xor i32 %5834, %5823
  %5836 = lshr i32 %5835, 4
  %5837 = trunc i32 %5836 to i8
  %5838 = and i8 %5837, 1
  store i8 %5838, i8* %31, align 1
  %5839 = icmp eq i32 %5823, 0
  %5840 = zext i1 %5839 to i8
  store i8 %5840, i8* %34, align 1
  %5841 = lshr i32 %5823, 31
  %5842 = trunc i32 %5841 to i8
  store i8 %5842, i8* %37, align 1
  %5843 = lshr i32 %5817, 31
  %5844 = lshr i32 %5822, 31
  %5845 = xor i32 %5841, %5843
  %5846 = xor i32 %5841, %5844
  %5847 = add nuw nsw i32 %5845, %5846
  %5848 = icmp eq i32 %5847, 2
  %5849 = zext i1 %5848 to i8
  store i8 %5849, i8* %43, align 1
  %5850 = sext i32 %5823 to i64
  store i64 %5850, i64* %RCX.i1197, align 8
  %5851 = shl nsw i64 %5850, 3
  %5852 = add i64 %5812, %5851
  %5853 = add i64 %5803, 43
  store i64 %5853, i64* %3, align 8
  %5854 = inttoptr i64 %5852 to i64*
  %5855 = load i64, i64* %5854, align 8
  store i64 %5855, i64* %RAX.i893, align 8
  store i64 %5813, i64* %RCX.i1197, align 8
  %5856 = add i64 %5813, 148
  %5857 = add i64 %5803, 57
  store i64 %5857, i64* %3, align 8
  %5858 = inttoptr i64 %5856 to i32*
  %5859 = load i32, i32* %5858, align 4
  %5860 = zext i32 %5859 to i64
  store i64 %5860, i64* %RDX.i1708, align 8
  %5861 = add i64 %5666, -16
  %5862 = add i64 %5803, 60
  store i64 %5862, i64* %3, align 8
  %5863 = inttoptr i64 %5861 to i32*
  %5864 = load i32, i32* %5863, align 4
  %5865 = add i32 %5864, %5859
  %5866 = zext i32 %5865 to i64
  store i64 %5866, i64* %RDX.i1708, align 8
  %5867 = icmp ult i32 %5865, %5859
  %5868 = icmp ult i32 %5865, %5864
  %5869 = or i1 %5867, %5868
  %5870 = zext i1 %5869 to i8
  store i8 %5870, i8* %19, align 1
  %5871 = and i32 %5865, 255
  %5872 = tail call i32 @llvm.ctpop.i32(i32 %5871)
  %5873 = trunc i32 %5872 to i8
  %5874 = and i8 %5873, 1
  %5875 = xor i8 %5874, 1
  store i8 %5875, i8* %26, align 1
  %5876 = xor i32 %5864, %5859
  %5877 = xor i32 %5876, %5865
  %5878 = lshr i32 %5877, 4
  %5879 = trunc i32 %5878 to i8
  %5880 = and i8 %5879, 1
  store i8 %5880, i8* %31, align 1
  %5881 = icmp eq i32 %5865, 0
  %5882 = zext i1 %5881 to i8
  store i8 %5882, i8* %34, align 1
  %5883 = lshr i32 %5865, 31
  %5884 = trunc i32 %5883 to i8
  store i8 %5884, i8* %37, align 1
  %5885 = lshr i32 %5859, 31
  %5886 = lshr i32 %5864, 31
  %5887 = xor i32 %5883, %5885
  %5888 = xor i32 %5883, %5886
  %5889 = add nuw nsw i32 %5887, %5888
  %5890 = icmp eq i32 %5889, 2
  %5891 = zext i1 %5890 to i8
  store i8 %5891, i8* %43, align 1
  %5892 = sext i32 %5865 to i64
  store i64 %5892, i64* %RCX.i1197, align 8
  %5893 = shl nsw i64 %5892, 1
  %5894 = add i64 %5855, %5893
  %5895 = add i64 %5803, 69
  store i64 %5895, i64* %3, align 8
  %5896 = inttoptr i64 %5894 to i16*
  store i16 -1, i16* %5896, align 2
  %5897 = load i64, i64* %3, align 8
  %5898 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5898, i64* %RAX.i893, align 8
  %5899 = add i64 %5898, 6488
  %5900 = add i64 %5897, 15
  store i64 %5900, i64* %3, align 8
  %5901 = inttoptr i64 %5899 to i64*
  %5902 = load i64, i64* %5901, align 8
  store i64 %5902, i64* %RAX.i893, align 8
  %5903 = add i64 %5902, 8
  %5904 = add i64 %5897, 19
  store i64 %5904, i64* %3, align 8
  %5905 = inttoptr i64 %5903 to i64*
  %5906 = load i64, i64* %5905, align 8
  store i64 %5906, i64* %RAX.i893, align 8
  %5907 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5907, i64* %RCX.i1197, align 8
  %5908 = add i64 %5907, 144
  %5909 = add i64 %5897, 33
  store i64 %5909, i64* %3, align 8
  %5910 = inttoptr i64 %5908 to i32*
  %5911 = load i32, i32* %5910, align 4
  %5912 = zext i32 %5911 to i64
  store i64 %5912, i64* %RDX.i1708, align 8
  %5913 = load i64, i64* %RBP.i, align 8
  %5914 = add i64 %5913, -12
  %5915 = add i64 %5897, 36
  store i64 %5915, i64* %3, align 8
  %5916 = inttoptr i64 %5914 to i32*
  %5917 = load i32, i32* %5916, align 4
  %5918 = add i32 %5917, %5911
  %5919 = zext i32 %5918 to i64
  store i64 %5919, i64* %RDX.i1708, align 8
  %5920 = icmp ult i32 %5918, %5911
  %5921 = icmp ult i32 %5918, %5917
  %5922 = or i1 %5920, %5921
  %5923 = zext i1 %5922 to i8
  store i8 %5923, i8* %19, align 1
  %5924 = and i32 %5918, 255
  %5925 = tail call i32 @llvm.ctpop.i32(i32 %5924)
  %5926 = trunc i32 %5925 to i8
  %5927 = and i8 %5926, 1
  %5928 = xor i8 %5927, 1
  store i8 %5928, i8* %26, align 1
  %5929 = xor i32 %5917, %5911
  %5930 = xor i32 %5929, %5918
  %5931 = lshr i32 %5930, 4
  %5932 = trunc i32 %5931 to i8
  %5933 = and i8 %5932, 1
  store i8 %5933, i8* %31, align 1
  %5934 = icmp eq i32 %5918, 0
  %5935 = zext i1 %5934 to i8
  store i8 %5935, i8* %34, align 1
  %5936 = lshr i32 %5918, 31
  %5937 = trunc i32 %5936 to i8
  store i8 %5937, i8* %37, align 1
  %5938 = lshr i32 %5911, 31
  %5939 = lshr i32 %5917, 31
  %5940 = xor i32 %5936, %5938
  %5941 = xor i32 %5936, %5939
  %5942 = add nuw nsw i32 %5940, %5941
  %5943 = icmp eq i32 %5942, 2
  %5944 = zext i1 %5943 to i8
  store i8 %5944, i8* %43, align 1
  %5945 = sext i32 %5918 to i64
  store i64 %5945, i64* %RCX.i1197, align 8
  %5946 = shl nsw i64 %5945, 3
  %5947 = add i64 %5906, %5946
  %5948 = add i64 %5897, 43
  store i64 %5948, i64* %3, align 8
  %5949 = inttoptr i64 %5947 to i64*
  %5950 = load i64, i64* %5949, align 8
  store i64 %5950, i64* %RAX.i893, align 8
  store i64 %5907, i64* %RCX.i1197, align 8
  %5951 = add i64 %5907, 148
  %5952 = add i64 %5897, 57
  store i64 %5952, i64* %3, align 8
  %5953 = inttoptr i64 %5951 to i32*
  %5954 = load i32, i32* %5953, align 4
  %5955 = zext i32 %5954 to i64
  store i64 %5955, i64* %RDX.i1708, align 8
  %5956 = add i64 %5913, -16
  %5957 = add i64 %5897, 60
  store i64 %5957, i64* %3, align 8
  %5958 = inttoptr i64 %5956 to i32*
  %5959 = load i32, i32* %5958, align 4
  %5960 = add i32 %5959, %5954
  %5961 = zext i32 %5960 to i64
  store i64 %5961, i64* %RDX.i1708, align 8
  %5962 = icmp ult i32 %5960, %5954
  %5963 = icmp ult i32 %5960, %5959
  %5964 = or i1 %5962, %5963
  %5965 = zext i1 %5964 to i8
  store i8 %5965, i8* %19, align 1
  %5966 = and i32 %5960, 255
  %5967 = tail call i32 @llvm.ctpop.i32(i32 %5966)
  %5968 = trunc i32 %5967 to i8
  %5969 = and i8 %5968, 1
  %5970 = xor i8 %5969, 1
  store i8 %5970, i8* %26, align 1
  %5971 = xor i32 %5959, %5954
  %5972 = xor i32 %5971, %5960
  %5973 = lshr i32 %5972, 4
  %5974 = trunc i32 %5973 to i8
  %5975 = and i8 %5974, 1
  store i8 %5975, i8* %31, align 1
  %5976 = icmp eq i32 %5960, 0
  %5977 = zext i1 %5976 to i8
  store i8 %5977, i8* %34, align 1
  %5978 = lshr i32 %5960, 31
  %5979 = trunc i32 %5978 to i8
  store i8 %5979, i8* %37, align 1
  %5980 = lshr i32 %5954, 31
  %5981 = lshr i32 %5959, 31
  %5982 = xor i32 %5978, %5980
  %5983 = xor i32 %5978, %5981
  %5984 = add nuw nsw i32 %5982, %5983
  %5985 = icmp eq i32 %5984, 2
  %5986 = zext i1 %5985 to i8
  store i8 %5986, i8* %43, align 1
  %5987 = sext i32 %5960 to i64
  store i64 %5987, i64* %RCX.i1197, align 8
  %5988 = shl nsw i64 %5987, 3
  %5989 = add i64 %5950, %5988
  %5990 = add i64 %5897, 71
  store i64 %5990, i64* %3, align 8
  %5991 = inttoptr i64 %5989 to i64*
  store i64 -1, i64* %5991, align 8
  %5992 = load i64, i64* %3, align 8
  %5993 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5993, i64* %RAX.i893, align 8
  %5994 = add i64 %5993, 6504
  %5995 = add i64 %5992, 15
  store i64 %5995, i64* %3, align 8
  %5996 = inttoptr i64 %5994 to i64*
  %5997 = load i64, i64* %5996, align 8
  store i64 %5997, i64* %RAX.i893, align 8
  %5998 = add i64 %5997, 8
  %5999 = add i64 %5992, 19
  store i64 %5999, i64* %3, align 8
  %6000 = inttoptr i64 %5998 to i64*
  %6001 = load i64, i64* %6000, align 8
  store i64 %6001, i64* %RAX.i893, align 8
  %6002 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6002, i64* %RCX.i1197, align 8
  %6003 = add i64 %6002, 144
  %6004 = add i64 %5992, 33
  store i64 %6004, i64* %3, align 8
  %6005 = inttoptr i64 %6003 to i32*
  %6006 = load i32, i32* %6005, align 4
  %6007 = zext i32 %6006 to i64
  store i64 %6007, i64* %RDX.i1708, align 8
  %6008 = load i64, i64* %RBP.i, align 8
  %6009 = add i64 %6008, -12
  %6010 = add i64 %5992, 36
  store i64 %6010, i64* %3, align 8
  %6011 = inttoptr i64 %6009 to i32*
  %6012 = load i32, i32* %6011, align 4
  %6013 = add i32 %6012, %6006
  %6014 = zext i32 %6013 to i64
  store i64 %6014, i64* %RDX.i1708, align 8
  %6015 = icmp ult i32 %6013, %6006
  %6016 = icmp ult i32 %6013, %6012
  %6017 = or i1 %6015, %6016
  %6018 = zext i1 %6017 to i8
  store i8 %6018, i8* %19, align 1
  %6019 = and i32 %6013, 255
  %6020 = tail call i32 @llvm.ctpop.i32(i32 %6019)
  %6021 = trunc i32 %6020 to i8
  %6022 = and i8 %6021, 1
  %6023 = xor i8 %6022, 1
  store i8 %6023, i8* %26, align 1
  %6024 = xor i32 %6012, %6006
  %6025 = xor i32 %6024, %6013
  %6026 = lshr i32 %6025, 4
  %6027 = trunc i32 %6026 to i8
  %6028 = and i8 %6027, 1
  store i8 %6028, i8* %31, align 1
  %6029 = icmp eq i32 %6013, 0
  %6030 = zext i1 %6029 to i8
  store i8 %6030, i8* %34, align 1
  %6031 = lshr i32 %6013, 31
  %6032 = trunc i32 %6031 to i8
  store i8 %6032, i8* %37, align 1
  %6033 = lshr i32 %6006, 31
  %6034 = lshr i32 %6012, 31
  %6035 = xor i32 %6031, %6033
  %6036 = xor i32 %6031, %6034
  %6037 = add nuw nsw i32 %6035, %6036
  %6038 = icmp eq i32 %6037, 2
  %6039 = zext i1 %6038 to i8
  store i8 %6039, i8* %43, align 1
  %6040 = sext i32 %6013 to i64
  store i64 %6040, i64* %RCX.i1197, align 8
  %6041 = shl nsw i64 %6040, 3
  %6042 = add i64 %6001, %6041
  %6043 = add i64 %5992, 43
  store i64 %6043, i64* %3, align 8
  %6044 = inttoptr i64 %6042 to i64*
  %6045 = load i64, i64* %6044, align 8
  store i64 %6045, i64* %RAX.i893, align 8
  store i64 %6002, i64* %RCX.i1197, align 8
  %6046 = add i64 %6002, 148
  %6047 = add i64 %5992, 57
  store i64 %6047, i64* %3, align 8
  %6048 = inttoptr i64 %6046 to i32*
  %6049 = load i32, i32* %6048, align 4
  %6050 = zext i32 %6049 to i64
  store i64 %6050, i64* %RDX.i1708, align 8
  %6051 = add i64 %6008, -16
  %6052 = add i64 %5992, 60
  store i64 %6052, i64* %3, align 8
  %6053 = inttoptr i64 %6051 to i32*
  %6054 = load i32, i32* %6053, align 4
  %6055 = add i32 %6054, %6049
  %6056 = zext i32 %6055 to i64
  store i64 %6056, i64* %RDX.i1708, align 8
  %6057 = icmp ult i32 %6055, %6049
  %6058 = icmp ult i32 %6055, %6054
  %6059 = or i1 %6057, %6058
  %6060 = zext i1 %6059 to i8
  store i8 %6060, i8* %19, align 1
  %6061 = and i32 %6055, 255
  %6062 = tail call i32 @llvm.ctpop.i32(i32 %6061)
  %6063 = trunc i32 %6062 to i8
  %6064 = and i8 %6063, 1
  %6065 = xor i8 %6064, 1
  store i8 %6065, i8* %26, align 1
  %6066 = xor i32 %6054, %6049
  %6067 = xor i32 %6066, %6055
  %6068 = lshr i32 %6067, 4
  %6069 = trunc i32 %6068 to i8
  %6070 = and i8 %6069, 1
  store i8 %6070, i8* %31, align 1
  %6071 = icmp eq i32 %6055, 0
  %6072 = zext i1 %6071 to i8
  store i8 %6072, i8* %34, align 1
  %6073 = lshr i32 %6055, 31
  %6074 = trunc i32 %6073 to i8
  store i8 %6074, i8* %37, align 1
  %6075 = lshr i32 %6049, 31
  %6076 = lshr i32 %6054, 31
  %6077 = xor i32 %6073, %6075
  %6078 = xor i32 %6073, %6076
  %6079 = add nuw nsw i32 %6077, %6078
  %6080 = icmp eq i32 %6079, 2
  %6081 = zext i1 %6080 to i8
  store i8 %6081, i8* %43, align 1
  %6082 = sext i32 %6055 to i64
  store i64 %6082, i64* %RCX.i1197, align 8
  %6083 = shl nsw i64 %6082, 3
  %6084 = add i64 %6045, %6083
  %6085 = add i64 %5992, 67
  store i64 %6085, i64* %3, align 8
  %6086 = inttoptr i64 %6084 to i16**
  %6087 = load i16*, i16** %6086, align 8
  %6088 = add i64 %5992, 72
  store i64 %6088, i64* %3, align 8
  store i16 0, i16* %6087, align 2
  %6089 = load i64, i64* %3, align 8
  %6090 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %6090, i64* %RAX.i893, align 8
  %6091 = add i64 %6090, 6504
  %6092 = add i64 %6089, 15
  store i64 %6092, i64* %3, align 8
  %6093 = inttoptr i64 %6091 to i64*
  %6094 = load i64, i64* %6093, align 8
  store i64 %6094, i64* %RAX.i893, align 8
  %6095 = add i64 %6094, 8
  %6096 = add i64 %6089, 19
  store i64 %6096, i64* %3, align 8
  %6097 = inttoptr i64 %6095 to i64*
  %6098 = load i64, i64* %6097, align 8
  store i64 %6098, i64* %RAX.i893, align 8
  %6099 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6099, i64* %RCX.i1197, align 8
  %6100 = add i64 %6099, 144
  %6101 = add i64 %6089, 33
  store i64 %6101, i64* %3, align 8
  %6102 = inttoptr i64 %6100 to i32*
  %6103 = load i32, i32* %6102, align 4
  %6104 = zext i32 %6103 to i64
  store i64 %6104, i64* %RDX.i1708, align 8
  %6105 = load i64, i64* %RBP.i, align 8
  %6106 = add i64 %6105, -12
  %6107 = add i64 %6089, 36
  store i64 %6107, i64* %3, align 8
  %6108 = inttoptr i64 %6106 to i32*
  %6109 = load i32, i32* %6108, align 4
  %6110 = add i32 %6109, %6103
  %6111 = zext i32 %6110 to i64
  store i64 %6111, i64* %RDX.i1708, align 8
  %6112 = icmp ult i32 %6110, %6103
  %6113 = icmp ult i32 %6110, %6109
  %6114 = or i1 %6112, %6113
  %6115 = zext i1 %6114 to i8
  store i8 %6115, i8* %19, align 1
  %6116 = and i32 %6110, 255
  %6117 = tail call i32 @llvm.ctpop.i32(i32 %6116)
  %6118 = trunc i32 %6117 to i8
  %6119 = and i8 %6118, 1
  %6120 = xor i8 %6119, 1
  store i8 %6120, i8* %26, align 1
  %6121 = xor i32 %6109, %6103
  %6122 = xor i32 %6121, %6110
  %6123 = lshr i32 %6122, 4
  %6124 = trunc i32 %6123 to i8
  %6125 = and i8 %6124, 1
  store i8 %6125, i8* %31, align 1
  %6126 = icmp eq i32 %6110, 0
  %6127 = zext i1 %6126 to i8
  store i8 %6127, i8* %34, align 1
  %6128 = lshr i32 %6110, 31
  %6129 = trunc i32 %6128 to i8
  store i8 %6129, i8* %37, align 1
  %6130 = lshr i32 %6103, 31
  %6131 = lshr i32 %6109, 31
  %6132 = xor i32 %6128, %6130
  %6133 = xor i32 %6128, %6131
  %6134 = add nuw nsw i32 %6132, %6133
  %6135 = icmp eq i32 %6134, 2
  %6136 = zext i1 %6135 to i8
  store i8 %6136, i8* %43, align 1
  %6137 = sext i32 %6110 to i64
  store i64 %6137, i64* %RCX.i1197, align 8
  %6138 = shl nsw i64 %6137, 3
  %6139 = add i64 %6098, %6138
  %6140 = add i64 %6089, 43
  store i64 %6140, i64* %3, align 8
  %6141 = inttoptr i64 %6139 to i64*
  %6142 = load i64, i64* %6141, align 8
  store i64 %6142, i64* %RAX.i893, align 8
  store i64 %6099, i64* %RCX.i1197, align 8
  %6143 = add i64 %6099, 148
  %6144 = add i64 %6089, 57
  store i64 %6144, i64* %3, align 8
  %6145 = inttoptr i64 %6143 to i32*
  %6146 = load i32, i32* %6145, align 4
  %6147 = zext i32 %6146 to i64
  store i64 %6147, i64* %RDX.i1708, align 8
  %6148 = add i64 %6105, -16
  %6149 = add i64 %6089, 60
  store i64 %6149, i64* %3, align 8
  %6150 = inttoptr i64 %6148 to i32*
  %6151 = load i32, i32* %6150, align 4
  %6152 = add i32 %6151, %6146
  %6153 = zext i32 %6152 to i64
  store i64 %6153, i64* %RDX.i1708, align 8
  %6154 = icmp ult i32 %6152, %6146
  %6155 = icmp ult i32 %6152, %6151
  %6156 = or i1 %6154, %6155
  %6157 = zext i1 %6156 to i8
  store i8 %6157, i8* %19, align 1
  %6158 = and i32 %6152, 255
  %6159 = tail call i32 @llvm.ctpop.i32(i32 %6158)
  %6160 = trunc i32 %6159 to i8
  %6161 = and i8 %6160, 1
  %6162 = xor i8 %6161, 1
  store i8 %6162, i8* %26, align 1
  %6163 = xor i32 %6151, %6146
  %6164 = xor i32 %6163, %6152
  %6165 = lshr i32 %6164, 4
  %6166 = trunc i32 %6165 to i8
  %6167 = and i8 %6166, 1
  store i8 %6167, i8* %31, align 1
  %6168 = icmp eq i32 %6152, 0
  %6169 = zext i1 %6168 to i8
  store i8 %6169, i8* %34, align 1
  %6170 = lshr i32 %6152, 31
  %6171 = trunc i32 %6170 to i8
  store i8 %6171, i8* %37, align 1
  %6172 = lshr i32 %6146, 31
  %6173 = lshr i32 %6151, 31
  %6174 = xor i32 %6170, %6172
  %6175 = xor i32 %6170, %6173
  %6176 = add nuw nsw i32 %6174, %6175
  %6177 = icmp eq i32 %6176, 2
  %6178 = zext i1 %6177 to i8
  store i8 %6178, i8* %43, align 1
  %6179 = sext i32 %6152 to i64
  store i64 %6179, i64* %RCX.i1197, align 8
  %6180 = shl nsw i64 %6179, 3
  %6181 = add i64 %6142, %6180
  %6182 = add i64 %6089, 67
  store i64 %6182, i64* %3, align 8
  %6183 = inttoptr i64 %6181 to i64*
  %6184 = load i64, i64* %6183, align 8
  %6185 = add i64 %6184, 2
  %6186 = add i64 %6089, 73
  store i64 %6186, i64* %3, align 8
  %6187 = inttoptr i64 %6185 to i16*
  store i16 0, i16* %6187, align 2
  %6188 = load i64, i64* %3, align 8
  %6189 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6189, i64* %RAX.i893, align 8
  %6190 = add i64 %6189, 72400
  %6191 = add i64 %6188, 15
  store i64 %6191, i64* %3, align 8
  %6192 = inttoptr i64 %6190 to i32*
  %6193 = load i32, i32* %6192, align 4
  store i8 0, i8* %19, align 1
  %6194 = and i32 %6193, 255
  %6195 = tail call i32 @llvm.ctpop.i32(i32 %6194)
  %6196 = trunc i32 %6195 to i8
  %6197 = and i8 %6196, 1
  %6198 = xor i8 %6197, 1
  store i8 %6198, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %6199 = icmp eq i32 %6193, 0
  %6200 = zext i1 %6199 to i8
  store i8 %6200, i8* %34, align 1
  %6201 = lshr i32 %6193, 31
  %6202 = trunc i32 %6201 to i8
  store i8 %6202, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v353 = select i1 %6199, i64 60, i64 21
  %6203 = add i64 %6188, %.v353
  store i64 %6203, i64* %3, align 8
  br i1 %6199, label %block_.L_48edad, label %block_48ed86

block_48ed86:                                     ; preds = %block_.L_48ec54
  %6204 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %6205 = add i64 %6204, 3264
  %6206 = lshr i64 %6205, 63
  %6207 = add i64 %6204, 3296
  store i64 %6207, i64* %RAX.i893, align 8
  %6208 = icmp ugt i64 %6205, -33
  %6209 = zext i1 %6208 to i8
  store i8 %6209, i8* %19, align 1
  %6210 = trunc i64 %6207 to i32
  %6211 = and i32 %6210, 255
  %6212 = tail call i32 @llvm.ctpop.i32(i32 %6211)
  %6213 = trunc i32 %6212 to i8
  %6214 = and i8 %6213, 1
  %6215 = xor i8 %6214, 1
  store i8 %6215, i8* %26, align 1
  %6216 = xor i64 %6207, %6205
  %6217 = lshr i64 %6216, 4
  %6218 = trunc i64 %6217 to i8
  %6219 = and i8 %6218, 1
  store i8 %6219, i8* %31, align 1
  %6220 = icmp eq i64 %6207, 0
  %6221 = zext i1 %6220 to i8
  store i8 %6221, i8* %34, align 1
  %6222 = lshr i64 %6207, 63
  %6223 = trunc i64 %6222 to i8
  store i8 %6223, i8* %37, align 1
  %6224 = xor i64 %6222, %6206
  %6225 = add nuw nsw i64 %6224, %6222
  %6226 = icmp eq i64 %6225, 2
  %6227 = zext i1 %6226 to i8
  store i8 %6227, i8* %43, align 1
  %6228 = load i64, i64* %RBP.i, align 8
  %6229 = add i64 %6228, -16
  %6230 = add i64 %6203, 22
  store i64 %6230, i64* %3, align 8
  %6231 = inttoptr i64 %6229 to i32*
  %6232 = load i32, i32* %6231, align 4
  %6233 = sext i32 %6232 to i64
  %6234 = shl nsw i64 %6233, 3
  store i64 %6234, i64* %RCX.i1197, align 8
  %6235 = add i64 %6234, %6207
  store i64 %6235, i64* %RAX.i893, align 8
  %6236 = icmp ult i64 %6235, %6207
  %6237 = icmp ult i64 %6235, %6234
  %6238 = or i1 %6236, %6237
  %6239 = zext i1 %6238 to i8
  store i8 %6239, i8* %19, align 1
  %6240 = trunc i64 %6235 to i32
  %6241 = and i32 %6240, 255
  %6242 = tail call i32 @llvm.ctpop.i32(i32 %6241)
  %6243 = trunc i32 %6242 to i8
  %6244 = and i8 %6243, 1
  %6245 = xor i8 %6244, 1
  store i8 %6245, i8* %26, align 1
  %6246 = xor i64 %6234, %6207
  %6247 = xor i64 %6246, %6235
  %6248 = lshr i64 %6247, 4
  %6249 = trunc i64 %6248 to i8
  %6250 = and i8 %6249, 1
  store i8 %6250, i8* %31, align 1
  %6251 = icmp eq i64 %6235, 0
  %6252 = zext i1 %6251 to i8
  store i8 %6252, i8* %34, align 1
  %6253 = lshr i64 %6235, 63
  %6254 = trunc i64 %6253 to i8
  store i8 %6254, i8* %37, align 1
  %6255 = lshr i64 %6233, 60
  %6256 = and i64 %6255, 1
  %6257 = xor i64 %6253, %6222
  %6258 = xor i64 %6253, %6256
  %6259 = add nuw nsw i64 %6257, %6258
  %6260 = icmp eq i64 %6259, 2
  %6261 = zext i1 %6260 to i8
  store i8 %6261, i8* %43, align 1
  %6262 = add i64 %6228, -12
  %6263 = add i64 %6203, 33
  store i64 %6263, i64* %3, align 8
  %6264 = inttoptr i64 %6262 to i32*
  %6265 = load i32, i32* %6264, align 4
  %6266 = sext i32 %6265 to i64
  store i64 %6266, i64* %RCX.i1197, align 8
  %6267 = shl nsw i64 %6266, 1
  %6268 = add i64 %6267, %6235
  %6269 = add i64 %6203, 39
  store i64 %6269, i64* %3, align 8
  %6270 = inttoptr i64 %6268 to i16*
  store i16 -1, i16* %6270, align 2
  %.pre284 = load i64, i64* %3, align 8
  br label %block_.L_48edad

block_.L_48edad:                                  ; preds = %block_48ed86, %block_.L_48ec54
  %6271 = phi i64 [ %.pre284, %block_48ed86 ], [ %6203, %block_.L_48ec54 ]
  %6272 = add i64 %6271, 5
  store i64 %6272, i64* %3, align 8
  %.pre285 = load i64, i64* %RBP.i, align 8
  br label %block_.L_48edb2

block_.L_48edb2:                                  ; preds = %block_48ec46, %block_.L_48edad
  %6273 = phi i64 [ %.pre285, %block_.L_48edad ], [ %5666, %block_48ec46 ]
  %6274 = phi i64 [ %6272, %block_.L_48edad ], [ %5802, %block_48ec46 ]
  %6275 = add i64 %6273, -12
  %6276 = add i64 %6274, 8
  store i64 %6276, i64* %3, align 8
  %6277 = inttoptr i64 %6275 to i32*
  %6278 = load i32, i32* %6277, align 4
  %6279 = add i32 %6278, 1
  %6280 = zext i32 %6279 to i64
  store i64 %6280, i64* %RAX.i893, align 8
  %6281 = icmp eq i32 %6278, -1
  %6282 = icmp eq i32 %6279, 0
  %6283 = or i1 %6281, %6282
  %6284 = zext i1 %6283 to i8
  store i8 %6284, i8* %19, align 1
  %6285 = and i32 %6279, 255
  %6286 = tail call i32 @llvm.ctpop.i32(i32 %6285)
  %6287 = trunc i32 %6286 to i8
  %6288 = and i8 %6287, 1
  %6289 = xor i8 %6288, 1
  store i8 %6289, i8* %26, align 1
  %6290 = xor i32 %6279, %6278
  %6291 = lshr i32 %6290, 4
  %6292 = trunc i32 %6291 to i8
  %6293 = and i8 %6292, 1
  store i8 %6293, i8* %31, align 1
  %6294 = zext i1 %6282 to i8
  store i8 %6294, i8* %34, align 1
  %6295 = lshr i32 %6279, 31
  %6296 = trunc i32 %6295 to i8
  store i8 %6296, i8* %37, align 1
  %6297 = lshr i32 %6278, 31
  %6298 = xor i32 %6295, %6297
  %6299 = add nuw nsw i32 %6298, %6295
  %6300 = icmp eq i32 %6299, 2
  %6301 = zext i1 %6300 to i8
  store i8 %6301, i8* %43, align 1
  %6302 = add i64 %6274, 14
  store i64 %6302, i64* %3, align 8
  store i32 %6279, i32* %6277, align 4
  %6303 = load i64, i64* %3, align 8
  %6304 = add i64 %6303, -2470
  store i64 %6304, i64* %3, align 8
  br label %block_.L_48e41a

block_.L_48edc5:                                  ; preds = %block_.L_48e41a
  %6305 = add i64 %2607, -16
  %6306 = add i64 %2635, 8
  store i64 %6306, i64* %3, align 8
  %6307 = inttoptr i64 %6305 to i32*
  %6308 = load i32, i32* %6307, align 4
  %6309 = add i32 %6308, 1
  %6310 = zext i32 %6309 to i64
  store i64 %6310, i64* %RAX.i893, align 8
  %6311 = icmp eq i32 %6308, -1
  %6312 = icmp eq i32 %6309, 0
  %6313 = or i1 %6311, %6312
  %6314 = zext i1 %6313 to i8
  store i8 %6314, i8* %19, align 1
  %6315 = and i32 %6309, 255
  %6316 = tail call i32 @llvm.ctpop.i32(i32 %6315)
  %6317 = trunc i32 %6316 to i8
  %6318 = and i8 %6317, 1
  %6319 = xor i8 %6318, 1
  store i8 %6319, i8* %26, align 1
  %6320 = xor i32 %6309, %6308
  %6321 = lshr i32 %6320, 4
  %6322 = trunc i32 %6321 to i8
  %6323 = and i8 %6322, 1
  store i8 %6323, i8* %31, align 1
  %6324 = zext i1 %6312 to i8
  store i8 %6324, i8* %34, align 1
  %6325 = lshr i32 %6309, 31
  %6326 = trunc i32 %6325 to i8
  store i8 %6326, i8* %37, align 1
  %6327 = lshr i32 %6308, 31
  %6328 = xor i32 %6325, %6327
  %6329 = add nuw nsw i32 %6328, %6325
  %6330 = icmp eq i32 %6329, 2
  %6331 = zext i1 %6330 to i8
  store i8 %6331, i8* %43, align 1
  %6332 = add i64 %2635, 14
  store i64 %6332, i64* %3, align 8
  store i32 %6309, i32* %6307, align 4
  %6333 = load i64, i64* %3, align 8
  %6334 = add i64 %6333, -2506
  store i64 %6334, i64* %3, align 8
  br label %block_.L_48e409

block_.L_48edd8:                                  ; preds = %block_.L_48e409
  %6335 = add i64 %2574, -64
  %6336 = add i64 %2602, 4
  store i64 %6336, i64* %3, align 8
  %6337 = inttoptr i64 %6335 to i32*
  %6338 = load i32, i32* %6337, align 4
  store i8 0, i8* %19, align 1
  %6339 = and i32 %6338, 255
  %6340 = tail call i32 @llvm.ctpop.i32(i32 %6339)
  %6341 = trunc i32 %6340 to i8
  %6342 = and i8 %6341, 1
  %6343 = xor i8 %6342, 1
  store i8 %6343, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %6344 = icmp eq i32 %6338, 0
  %6345 = zext i1 %6344 to i8
  store i8 %6345, i8* %34, align 1
  %6346 = lshr i32 %6338, 31
  %6347 = trunc i32 %6346 to i8
  store i8 %6347, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v317 = select i1 %6344, i64 2110, i64 10
  %6348 = add i64 %2602, %.v317
  store i64 %6348, i64* %3, align 8
  br i1 %6344, label %block_.L_48f616, label %block_48ede2

block_48ede2:                                     ; preds = %block_.L_48edd8
  %6349 = add i64 %6348, 7
  store i64 %6349, i64* %3, align 8
  store i32 0, i32* %2577, align 4
  %.pre198 = load i64, i64* %3, align 8
  br label %block_.L_48ede9

block_.L_48ede9:                                  ; preds = %block_.L_48f5fe, %block_48ede2
  %6350 = phi i64 [ %.pre198, %block_48ede2 ], [ %9425, %block_.L_48f5fe ]
  %MEMORY.37 = phi %struct.Memory* [ %MEMORY.24, %block_48ede2 ], [ %MEMORY.38, %block_.L_48f5fe ]
  %6351 = load i64, i64* %RBP.i, align 8
  %6352 = add i64 %6351, -16
  %6353 = add i64 %6350, 4
  store i64 %6353, i64* %3, align 8
  %6354 = inttoptr i64 %6352 to i32*
  %6355 = load i32, i32* %6354, align 4
  %6356 = add i32 %6355, -4
  %6357 = icmp ult i32 %6355, 4
  %6358 = zext i1 %6357 to i8
  store i8 %6358, i8* %19, align 1
  %6359 = and i32 %6356, 255
  %6360 = tail call i32 @llvm.ctpop.i32(i32 %6359)
  %6361 = trunc i32 %6360 to i8
  %6362 = and i8 %6361, 1
  %6363 = xor i8 %6362, 1
  store i8 %6363, i8* %26, align 1
  %6364 = xor i32 %6356, %6355
  %6365 = lshr i32 %6364, 4
  %6366 = trunc i32 %6365 to i8
  %6367 = and i8 %6366, 1
  store i8 %6367, i8* %31, align 1
  %6368 = icmp eq i32 %6356, 0
  %6369 = zext i1 %6368 to i8
  store i8 %6369, i8* %34, align 1
  %6370 = lshr i32 %6356, 31
  %6371 = trunc i32 %6370 to i8
  store i8 %6371, i8* %37, align 1
  %6372 = lshr i32 %6355, 31
  %6373 = xor i32 %6370, %6372
  %6374 = add nuw nsw i32 %6373, %6372
  %6375 = icmp eq i32 %6374, 2
  %6376 = zext i1 %6375 to i8
  store i8 %6376, i8* %43, align 1
  %6377 = icmp ne i8 %6371, 0
  %6378 = xor i1 %6377, %6375
  %.v318 = select i1 %6378, i64 10, i64 2088
  %6379 = add i64 %6350, %.v318
  store i64 %6379, i64* %3, align 8
  br i1 %6378, label %block_48edf3, label %block_.L_48f611

block_48edf3:                                     ; preds = %block_.L_48ede9
  %6380 = add i64 %6351, -12
  %6381 = add i64 %6379, 7
  store i64 %6381, i64* %3, align 8
  %6382 = inttoptr i64 %6380 to i32*
  store i32 0, i32* %6382, align 4
  %.pre199 = load i64, i64* %3, align 8
  br label %block_.L_48edfa

block_.L_48edfa:                                  ; preds = %block_.L_48f5eb, %block_48edf3
  %6383 = phi i64 [ %.pre199, %block_48edf3 ], [ %9395, %block_.L_48f5eb ]
  %MEMORY.38 = phi %struct.Memory* [ %MEMORY.37, %block_48edf3 ], [ %MEMORY.46, %block_.L_48f5eb ]
  %6384 = load i64, i64* %RBP.i, align 8
  %6385 = add i64 %6384, -12
  %6386 = add i64 %6383, 4
  store i64 %6386, i64* %3, align 8
  %6387 = inttoptr i64 %6385 to i32*
  %6388 = load i32, i32* %6387, align 4
  %6389 = add i32 %6388, -4
  %6390 = icmp ult i32 %6388, 4
  %6391 = zext i1 %6390 to i8
  store i8 %6391, i8* %19, align 1
  %6392 = and i32 %6389, 255
  %6393 = tail call i32 @llvm.ctpop.i32(i32 %6392)
  %6394 = trunc i32 %6393 to i8
  %6395 = and i8 %6394, 1
  %6396 = xor i8 %6395, 1
  store i8 %6396, i8* %26, align 1
  %6397 = xor i32 %6389, %6388
  %6398 = lshr i32 %6397, 4
  %6399 = trunc i32 %6398 to i8
  %6400 = and i8 %6399, 1
  store i8 %6400, i8* %31, align 1
  %6401 = icmp eq i32 %6389, 0
  %6402 = zext i1 %6401 to i8
  store i8 %6402, i8* %34, align 1
  %6403 = lshr i32 %6389, 31
  %6404 = trunc i32 %6403 to i8
  store i8 %6404, i8* %37, align 1
  %6405 = lshr i32 %6388, 31
  %6406 = xor i32 %6403, %6405
  %6407 = add nuw nsw i32 %6406, %6405
  %6408 = icmp eq i32 %6407, 2
  %6409 = zext i1 %6408 to i8
  store i8 %6409, i8* %43, align 1
  %6410 = icmp ne i8 %6404, 0
  %6411 = xor i1 %6410, %6408
  %.v295 = select i1 %6411, i64 10, i64 2052
  %6412 = add i64 %6383, %.v295
  store i64 %6412, i64* %3, align 8
  br i1 %6411, label %block_48ee04, label %block_.L_48f5fe

block_48ee04:                                     ; preds = %block_.L_48edfa
  %6413 = add i64 %6384, -56
  %6414 = add i64 %6412, 4
  store i64 %6414, i64* %3, align 8
  %6415 = inttoptr i64 %6413 to i64*
  %6416 = load i64, i64* %6415, align 8
  store i64 %6416, i64* %RAX.i893, align 8
  %6417 = add i64 %6416, 72
  %6418 = add i64 %6412, 8
  store i64 %6418, i64* %3, align 8
  %6419 = inttoptr i64 %6417 to i32*
  %6420 = load i32, i32* %6419, align 4
  %6421 = add i32 %6420, -9
  %6422 = icmp ult i32 %6420, 9
  %6423 = zext i1 %6422 to i8
  store i8 %6423, i8* %19, align 1
  %6424 = and i32 %6421, 255
  %6425 = tail call i32 @llvm.ctpop.i32(i32 %6424)
  %6426 = trunc i32 %6425 to i8
  %6427 = and i8 %6426, 1
  %6428 = xor i8 %6427, 1
  store i8 %6428, i8* %26, align 1
  %6429 = xor i32 %6421, %6420
  %6430 = lshr i32 %6429, 4
  %6431 = trunc i32 %6430 to i8
  %6432 = and i8 %6431, 1
  store i8 %6432, i8* %31, align 1
  %6433 = icmp eq i32 %6421, 0
  %6434 = zext i1 %6433 to i8
  store i8 %6434, i8* %34, align 1
  %6435 = lshr i32 %6421, 31
  %6436 = trunc i32 %6435 to i8
  store i8 %6436, i8* %37, align 1
  %6437 = lshr i32 %6420, 31
  %6438 = xor i32 %6435, %6437
  %6439 = add nuw nsw i32 %6438, %6437
  %6440 = icmp eq i32 %6439, 2
  %6441 = zext i1 %6440 to i8
  store i8 %6441, i8* %43, align 1
  %.v330 = select i1 %6433, i64 114, i64 14
  %6442 = add i64 %6412, %.v330
  store i64 %6442, i64* %3, align 8
  br i1 %6433, label %block_.L_48ee76, label %block_48ee12

block_48ee12:                                     ; preds = %block_48ee04
  %6443 = add i64 %6442, 4
  store i64 %6443, i64* %3, align 8
  %6444 = load i64, i64* %6415, align 8
  store i64 %6444, i64* %RAX.i893, align 8
  %6445 = add i64 %6444, 72
  %6446 = add i64 %6442, 8
  store i64 %6446, i64* %3, align 8
  %6447 = inttoptr i64 %6445 to i32*
  %6448 = load i32, i32* %6447, align 4
  %6449 = add i32 %6448, -10
  %6450 = icmp ult i32 %6448, 10
  %6451 = zext i1 %6450 to i8
  store i8 %6451, i8* %19, align 1
  %6452 = and i32 %6449, 255
  %6453 = tail call i32 @llvm.ctpop.i32(i32 %6452)
  %6454 = trunc i32 %6453 to i8
  %6455 = and i8 %6454, 1
  %6456 = xor i8 %6455, 1
  store i8 %6456, i8* %26, align 1
  %6457 = xor i32 %6449, %6448
  %6458 = lshr i32 %6457, 4
  %6459 = trunc i32 %6458 to i8
  %6460 = and i8 %6459, 1
  store i8 %6460, i8* %31, align 1
  %6461 = icmp eq i32 %6449, 0
  %6462 = zext i1 %6461 to i8
  store i8 %6462, i8* %34, align 1
  %6463 = lshr i32 %6449, 31
  %6464 = trunc i32 %6463 to i8
  store i8 %6464, i8* %37, align 1
  %6465 = lshr i32 %6448, 31
  %6466 = xor i32 %6463, %6465
  %6467 = add nuw nsw i32 %6466, %6465
  %6468 = icmp eq i32 %6467, 2
  %6469 = zext i1 %6468 to i8
  store i8 %6469, i8* %43, align 1
  %.v331 = select i1 %6461, i64 100, i64 14
  %6470 = add i64 %6442, %.v331
  store i64 %6470, i64* %3, align 8
  br i1 %6461, label %block_.L_48ee76, label %block_48ee20

block_48ee20:                                     ; preds = %block_48ee12
  %6471 = add i64 %6470, 4
  store i64 %6471, i64* %3, align 8
  %6472 = load i64, i64* %6415, align 8
  store i64 %6472, i64* %RAX.i893, align 8
  %6473 = add i64 %6472, 72
  %6474 = add i64 %6470, 8
  store i64 %6474, i64* %3, align 8
  %6475 = inttoptr i64 %6473 to i32*
  %6476 = load i32, i32* %6475, align 4
  %6477 = add i32 %6476, -13
  %6478 = icmp ult i32 %6476, 13
  %6479 = zext i1 %6478 to i8
  store i8 %6479, i8* %19, align 1
  %6480 = and i32 %6477, 255
  %6481 = tail call i32 @llvm.ctpop.i32(i32 %6480)
  %6482 = trunc i32 %6481 to i8
  %6483 = and i8 %6482, 1
  %6484 = xor i8 %6483, 1
  store i8 %6484, i8* %26, align 1
  %6485 = xor i32 %6477, %6476
  %6486 = lshr i32 %6485, 4
  %6487 = trunc i32 %6486 to i8
  %6488 = and i8 %6487, 1
  store i8 %6488, i8* %31, align 1
  %6489 = icmp eq i32 %6477, 0
  %6490 = zext i1 %6489 to i8
  store i8 %6490, i8* %34, align 1
  %6491 = lshr i32 %6477, 31
  %6492 = trunc i32 %6491 to i8
  store i8 %6492, i8* %37, align 1
  %6493 = lshr i32 %6476, 31
  %6494 = xor i32 %6491, %6493
  %6495 = add nuw nsw i32 %6494, %6493
  %6496 = icmp eq i32 %6495, 2
  %6497 = zext i1 %6496 to i8
  store i8 %6497, i8* %43, align 1
  %.v332 = select i1 %6489, i64 86, i64 14
  %6498 = add i64 %6470, %.v332
  store i64 %6498, i64* %3, align 8
  br i1 %6489, label %block_.L_48ee76, label %block_48ee2e

block_48ee2e:                                     ; preds = %block_48ee20
  store i64 2, i64* %RAX.i893, align 8
  %6499 = add i64 %6498, 9
  store i64 %6499, i64* %3, align 8
  %6500 = load i64, i64* %6415, align 8
  store i64 %6500, i64* %RCX.i1197, align 8
  %6501 = add i64 %6498, 12
  store i64 %6501, i64* %3, align 8
  %6502 = load i32, i32* %6387, align 4
  %6503 = zext i32 %6502 to i64
  store i64 %6503, i64* %RDX.i1708, align 8
  %6504 = add i64 %6384, -204
  %6505 = add i64 %6498, 18
  store i64 %6505, i64* %3, align 8
  %6506 = inttoptr i64 %6504 to i32*
  store i32 2, i32* %6506, align 4
  %6507 = load i32, i32* %EDX.i1723, align 4
  %6508 = zext i32 %6507 to i64
  %6509 = load i64, i64* %3, align 8
  store i64 %6508, i64* %RAX.i893, align 8
  %6510 = sext i32 %6507 to i64
  %6511 = lshr i64 %6510, 32
  store i64 %6511, i64* %2568, align 8
  %6512 = load i64, i64* %RBP.i, align 8
  %6513 = add i64 %6512, -204
  %6514 = add i64 %6509, 9
  store i64 %6514, i64* %3, align 8
  %6515 = inttoptr i64 %6513 to i32*
  %6516 = load i32, i32* %6515, align 4
  %6517 = zext i32 %6516 to i64
  store i64 %6517, i64* %RSI.i4020.pre-phi, align 8
  %6518 = add i64 %6509, 11
  store i64 %6518, i64* %3, align 8
  %6519 = sext i32 %6516 to i64
  %6520 = shl nuw i64 %6511, 32
  %6521 = or i64 %6520, %6508
  %6522 = sdiv i64 %6521, %6519
  %6523 = shl i64 %6522, 32
  %6524 = ashr exact i64 %6523, 32
  %6525 = icmp eq i64 %6522, %6524
  br i1 %6525, label %6528, label %6526

; <label>:6526:                                   ; preds = %block_48ee2e
  %6527 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6518, %struct.Memory* %MEMORY.38)
  %.pre200 = load i64, i64* %RBP.i, align 8
  %.pre201 = load i64, i64* %3, align 8
  %.pre202 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__esi.exit1721

; <label>:6528:                                   ; preds = %block_48ee2e
  %6529 = srem i64 %6521, %6519
  %6530 = and i64 %6522, 4294967295
  store i64 %6530, i64* %RAX.i893, align 8
  %6531 = and i64 %6529, 4294967295
  store i64 %6531, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %6532 = trunc i64 %6522 to i32
  br label %routine_idivl__esi.exit1721

routine_idivl__esi.exit1721:                      ; preds = %6528, %6526
  %6533 = phi i32 [ %.pre202, %6526 ], [ %6532, %6528 ]
  %6534 = phi i64 [ %.pre201, %6526 ], [ %6518, %6528 ]
  %6535 = phi i64 [ %.pre200, %6526 ], [ %6512, %6528 ]
  %6536 = phi %struct.Memory* [ %6527, %6526 ], [ %MEMORY.38, %6528 ]
  %6537 = add i64 %6535, -16
  %6538 = add i64 %6534, 3
  store i64 %6538, i64* %3, align 8
  %6539 = inttoptr i64 %6537 to i32*
  %6540 = load i32, i32* %6539, align 4
  %6541 = zext i32 %6540 to i64
  store i64 %6541, i64* %RDI.i3116, align 8
  %6542 = add i64 %6535, -208
  %6543 = add i64 %6534, 9
  store i64 %6543, i64* %3, align 8
  %6544 = inttoptr i64 %6542 to i32*
  store i32 %6533, i32* %6544, align 4
  %6545 = load i32, i32* %EDI.i3110, align 4
  %6546 = zext i32 %6545 to i64
  %6547 = load i64, i64* %3, align 8
  store i64 %6546, i64* %RAX.i893, align 8
  %6548 = sext i32 %6545 to i64
  %6549 = lshr i64 %6548, 32
  store i64 %6549, i64* %2568, align 8
  %6550 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %6551 = add i64 %6547, 5
  store i64 %6551, i64* %3, align 8
  %6552 = sext i32 %6550 to i64
  %6553 = shl nuw i64 %6549, 32
  %6554 = or i64 %6553, %6546
  %6555 = sdiv i64 %6554, %6552
  %6556 = shl i64 %6555, 32
  %6557 = ashr exact i64 %6556, 32
  %6558 = icmp eq i64 %6555, %6557
  br i1 %6558, label %6561, label %6559

; <label>:6559:                                   ; preds = %routine_idivl__esi.exit1721
  %6560 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6551, %struct.Memory* %6536)
  %.pre203 = load i64, i64* %RAX.i893, align 8
  %.pre204 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit1706

; <label>:6561:                                   ; preds = %routine_idivl__esi.exit1721
  %6562 = srem i64 %6554, %6552
  %6563 = and i64 %6555, 4294967295
  store i64 %6563, i64* %RAX.i893, align 8
  %6564 = and i64 %6562, 4294967295
  store i64 %6564, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__esi.exit1706

routine_idivl__esi.exit1706:                      ; preds = %6561, %6559
  %6565 = phi i64 [ %.pre204, %6559 ], [ %6551, %6561 ]
  %6566 = phi i64 [ %.pre203, %6559 ], [ %6563, %6561 ]
  %6567 = phi %struct.Memory* [ %6560, %6559 ], [ %6536, %6561 ]
  %6568 = trunc i64 %6566 to i32
  %6569 = shl i32 %6568, 1
  %6570 = icmp slt i32 %6568, 0
  %6571 = icmp slt i32 %6569, 0
  %6572 = xor i1 %6570, %6571
  %6573 = zext i32 %6569 to i64
  store i64 %6573, i64* %RAX.i893, align 8
  %.lobit101 = lshr i32 %6568, 31
  %6574 = trunc i32 %.lobit101 to i8
  store i8 %6574, i8* %19, align 1
  %6575 = and i32 %6569, 254
  %6576 = tail call i32 @llvm.ctpop.i32(i32 %6575)
  %6577 = trunc i32 %6576 to i8
  %6578 = and i8 %6577, 1
  %6579 = xor i8 %6578, 1
  store i8 %6579, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %6580 = icmp eq i32 %6569, 0
  %6581 = zext i1 %6580 to i8
  store i8 %6581, i8* %34, align 1
  %6582 = lshr i32 %6568, 30
  %6583 = trunc i32 %6582 to i8
  %6584 = and i8 %6583, 1
  store i8 %6584, i8* %37, align 1
  %6585 = zext i1 %6572 to i8
  store i8 %6585, i8* %43, align 1
  %6586 = load i64, i64* %RBP.i, align 8
  %6587 = add i64 %6586, -208
  %6588 = add i64 %6565, 8
  store i64 %6588, i64* %3, align 8
  %6589 = inttoptr i64 %6587 to i32*
  %6590 = load i32, i32* %6589, align 4
  %6591 = add i32 %6569, %6590
  %6592 = zext i32 %6591 to i64
  store i64 %6592, i64* %RDI.i3116, align 8
  %6593 = icmp ult i32 %6591, %6590
  %6594 = icmp ult i32 %6591, %6569
  %6595 = or i1 %6593, %6594
  %6596 = zext i1 %6595 to i8
  store i8 %6596, i8* %19, align 1
  %6597 = and i32 %6591, 255
  %6598 = tail call i32 @llvm.ctpop.i32(i32 %6597)
  %6599 = trunc i32 %6598 to i8
  %6600 = and i8 %6599, 1
  %6601 = xor i8 %6600, 1
  store i8 %6601, i8* %26, align 1
  %6602 = xor i32 %6569, %6590
  %6603 = xor i32 %6602, %6591
  %6604 = lshr i32 %6603, 4
  %6605 = trunc i32 %6604 to i8
  %6606 = and i8 %6605, 1
  store i8 %6606, i8* %31, align 1
  %6607 = icmp eq i32 %6591, 0
  %6608 = zext i1 %6607 to i8
  store i8 %6608, i8* %34, align 1
  %6609 = lshr i32 %6591, 31
  %6610 = trunc i32 %6609 to i8
  store i8 %6610, i8* %37, align 1
  %6611 = lshr i32 %6590, 31
  %6612 = lshr i32 %6568, 30
  %6613 = and i32 %6612, 1
  %6614 = xor i32 %6609, %6611
  %6615 = xor i32 %6609, %6613
  %6616 = add nuw nsw i32 %6614, %6615
  %6617 = icmp eq i32 %6616, 2
  %6618 = zext i1 %6617 to i8
  store i8 %6618, i8* %43, align 1
  %6619 = sext i32 %6591 to i64
  store i64 %6619, i64* %R8.i3094, align 8
  %6620 = load i64, i64* %RCX.i1197, align 8
  %6621 = shl nsw i64 %6619, 2
  %6622 = add nsw i64 %6621, 488
  %6623 = add i64 %6622, %6620
  %6624 = add i64 %6565, 22
  store i64 %6624, i64* %3, align 8
  %6625 = inttoptr i64 %6623 to i32*
  %6626 = load i32, i32* %6625, align 4
  store i8 0, i8* %19, align 1
  %6627 = and i32 %6626, 255
  %6628 = tail call i32 @llvm.ctpop.i32(i32 %6627)
  %6629 = trunc i32 %6628 to i8
  %6630 = and i8 %6629, 1
  %6631 = xor i8 %6630, 1
  store i8 %6631, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %6632 = icmp eq i32 %6626, 0
  %6633 = zext i1 %6632 to i8
  store i8 %6633, i8* %34, align 1
  %6634 = lshr i32 %6626, 31
  %6635 = trunc i32 %6634 to i8
  store i8 %6635, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v333 = select i1 %6632, i64 28, i64 378
  %6636 = add i64 %6565, %.v333
  store i64 %6636, i64* %3, align 8
  br i1 %6632, label %block_.L_48ee76, label %block_.L_48efd4

block_.L_48ee76:                                  ; preds = %routine_idivl__esi.exit1706, %block_48ee20, %block_48ee12, %block_48ee04
  %6637 = phi i64 [ %6384, %block_48ee04 ], [ %6384, %block_48ee12 ], [ %6384, %block_48ee20 ], [ %6586, %routine_idivl__esi.exit1706 ]
  %6638 = phi i64 [ %6442, %block_48ee04 ], [ %6470, %block_48ee12 ], [ %6498, %block_48ee20 ], [ %6636, %routine_idivl__esi.exit1706 ]
  %MEMORY.39 = phi %struct.Memory* [ %MEMORY.38, %block_48ee04 ], [ %MEMORY.38, %block_48ee12 ], [ %MEMORY.38, %block_48ee20 ], [ %6567, %routine_idivl__esi.exit1706 ]
  %6639 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %6639, i64* %RAX.i893, align 8
  %6640 = add i64 %6639, 6480
  %6641 = add i64 %6638, 15
  store i64 %6641, i64* %3, align 8
  %6642 = inttoptr i64 %6640 to i64*
  %6643 = load i64, i64* %6642, align 8
  store i64 %6643, i64* %RAX.i893, align 8
  %6644 = add i64 %6643, 8
  %6645 = add i64 %6638, 19
  store i64 %6645, i64* %3, align 8
  %6646 = inttoptr i64 %6644 to i64*
  %6647 = load i64, i64* %6646, align 8
  store i64 %6647, i64* %RAX.i893, align 8
  %6648 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6648, i64* %RCX.i1197, align 8
  %6649 = add i64 %6648, 144
  %6650 = add i64 %6638, 33
  store i64 %6650, i64* %3, align 8
  %6651 = inttoptr i64 %6649 to i32*
  %6652 = load i32, i32* %6651, align 4
  %6653 = zext i32 %6652 to i64
  store i64 %6653, i64* %RDX.i1708, align 8
  %6654 = add i64 %6637, -12
  %6655 = add i64 %6638, 36
  store i64 %6655, i64* %3, align 8
  %6656 = inttoptr i64 %6654 to i32*
  %6657 = load i32, i32* %6656, align 4
  %6658 = add i32 %6657, %6652
  %6659 = zext i32 %6658 to i64
  store i64 %6659, i64* %RDX.i1708, align 8
  %6660 = icmp ult i32 %6658, %6652
  %6661 = icmp ult i32 %6658, %6657
  %6662 = or i1 %6660, %6661
  %6663 = zext i1 %6662 to i8
  store i8 %6663, i8* %19, align 1
  %6664 = and i32 %6658, 255
  %6665 = tail call i32 @llvm.ctpop.i32(i32 %6664)
  %6666 = trunc i32 %6665 to i8
  %6667 = and i8 %6666, 1
  %6668 = xor i8 %6667, 1
  store i8 %6668, i8* %26, align 1
  %6669 = xor i32 %6657, %6652
  %6670 = xor i32 %6669, %6658
  %6671 = lshr i32 %6670, 4
  %6672 = trunc i32 %6671 to i8
  %6673 = and i8 %6672, 1
  store i8 %6673, i8* %31, align 1
  %6674 = icmp eq i32 %6658, 0
  %6675 = zext i1 %6674 to i8
  store i8 %6675, i8* %34, align 1
  %6676 = lshr i32 %6658, 31
  %6677 = trunc i32 %6676 to i8
  store i8 %6677, i8* %37, align 1
  %6678 = lshr i32 %6652, 31
  %6679 = lshr i32 %6657, 31
  %6680 = xor i32 %6676, %6678
  %6681 = xor i32 %6676, %6679
  %6682 = add nuw nsw i32 %6680, %6681
  %6683 = icmp eq i32 %6682, 2
  %6684 = zext i1 %6683 to i8
  store i8 %6684, i8* %43, align 1
  %6685 = sext i32 %6658 to i64
  store i64 %6685, i64* %RCX.i1197, align 8
  %6686 = shl nsw i64 %6685, 3
  %6687 = add i64 %6647, %6686
  %6688 = add i64 %6638, 43
  store i64 %6688, i64* %3, align 8
  %6689 = inttoptr i64 %6687 to i64*
  %6690 = load i64, i64* %6689, align 8
  store i64 %6690, i64* %RAX.i893, align 8
  store i64 %6648, i64* %RCX.i1197, align 8
  %6691 = add i64 %6648, 148
  %6692 = add i64 %6638, 57
  store i64 %6692, i64* %3, align 8
  %6693 = inttoptr i64 %6691 to i32*
  %6694 = load i32, i32* %6693, align 4
  %6695 = zext i32 %6694 to i64
  store i64 %6695, i64* %RDX.i1708, align 8
  %6696 = add i64 %6637, -16
  %6697 = add i64 %6638, 60
  store i64 %6697, i64* %3, align 8
  %6698 = inttoptr i64 %6696 to i32*
  %6699 = load i32, i32* %6698, align 4
  %6700 = add i32 %6699, %6694
  %6701 = zext i32 %6700 to i64
  store i64 %6701, i64* %RDX.i1708, align 8
  %6702 = icmp ult i32 %6700, %6694
  %6703 = icmp ult i32 %6700, %6699
  %6704 = or i1 %6702, %6703
  %6705 = zext i1 %6704 to i8
  store i8 %6705, i8* %19, align 1
  %6706 = and i32 %6700, 255
  %6707 = tail call i32 @llvm.ctpop.i32(i32 %6706)
  %6708 = trunc i32 %6707 to i8
  %6709 = and i8 %6708, 1
  %6710 = xor i8 %6709, 1
  store i8 %6710, i8* %26, align 1
  %6711 = xor i32 %6699, %6694
  %6712 = xor i32 %6711, %6700
  %6713 = lshr i32 %6712, 4
  %6714 = trunc i32 %6713 to i8
  %6715 = and i8 %6714, 1
  store i8 %6715, i8* %31, align 1
  %6716 = icmp eq i32 %6700, 0
  %6717 = zext i1 %6716 to i8
  store i8 %6717, i8* %34, align 1
  %6718 = lshr i32 %6700, 31
  %6719 = trunc i32 %6718 to i8
  store i8 %6719, i8* %37, align 1
  %6720 = lshr i32 %6694, 31
  %6721 = lshr i32 %6699, 31
  %6722 = xor i32 %6718, %6720
  %6723 = xor i32 %6718, %6721
  %6724 = add nuw nsw i32 %6722, %6723
  %6725 = icmp eq i32 %6724, 2
  %6726 = zext i1 %6725 to i8
  store i8 %6726, i8* %43, align 1
  %6727 = sext i32 %6700 to i64
  store i64 %6727, i64* %RCX.i1197, align 8
  %6728 = shl nsw i64 %6727, 1
  %6729 = add i64 %6690, %6728
  %6730 = add i64 %6638, 69
  store i64 %6730, i64* %3, align 8
  %6731 = inttoptr i64 %6729 to i16*
  store i16 -1, i16* %6731, align 2
  %6732 = load i64, i64* %3, align 8
  %6733 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %6733, i64* %RAX.i893, align 8
  %6734 = add i64 %6733, 6488
  %6735 = add i64 %6732, 15
  store i64 %6735, i64* %3, align 8
  %6736 = inttoptr i64 %6734 to i64*
  %6737 = load i64, i64* %6736, align 8
  store i64 %6737, i64* %RAX.i893, align 8
  %6738 = add i64 %6737, 8
  %6739 = add i64 %6732, 19
  store i64 %6739, i64* %3, align 8
  %6740 = inttoptr i64 %6738 to i64*
  %6741 = load i64, i64* %6740, align 8
  store i64 %6741, i64* %RAX.i893, align 8
  %6742 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6742, i64* %RCX.i1197, align 8
  %6743 = add i64 %6742, 144
  %6744 = add i64 %6732, 33
  store i64 %6744, i64* %3, align 8
  %6745 = inttoptr i64 %6743 to i32*
  %6746 = load i32, i32* %6745, align 4
  %6747 = zext i32 %6746 to i64
  store i64 %6747, i64* %RDX.i1708, align 8
  %6748 = load i64, i64* %RBP.i, align 8
  %6749 = add i64 %6748, -12
  %6750 = add i64 %6732, 36
  store i64 %6750, i64* %3, align 8
  %6751 = inttoptr i64 %6749 to i32*
  %6752 = load i32, i32* %6751, align 4
  %6753 = add i32 %6752, %6746
  %6754 = zext i32 %6753 to i64
  store i64 %6754, i64* %RDX.i1708, align 8
  %6755 = icmp ult i32 %6753, %6746
  %6756 = icmp ult i32 %6753, %6752
  %6757 = or i1 %6755, %6756
  %6758 = zext i1 %6757 to i8
  store i8 %6758, i8* %19, align 1
  %6759 = and i32 %6753, 255
  %6760 = tail call i32 @llvm.ctpop.i32(i32 %6759)
  %6761 = trunc i32 %6760 to i8
  %6762 = and i8 %6761, 1
  %6763 = xor i8 %6762, 1
  store i8 %6763, i8* %26, align 1
  %6764 = xor i32 %6752, %6746
  %6765 = xor i32 %6764, %6753
  %6766 = lshr i32 %6765, 4
  %6767 = trunc i32 %6766 to i8
  %6768 = and i8 %6767, 1
  store i8 %6768, i8* %31, align 1
  %6769 = icmp eq i32 %6753, 0
  %6770 = zext i1 %6769 to i8
  store i8 %6770, i8* %34, align 1
  %6771 = lshr i32 %6753, 31
  %6772 = trunc i32 %6771 to i8
  store i8 %6772, i8* %37, align 1
  %6773 = lshr i32 %6746, 31
  %6774 = lshr i32 %6752, 31
  %6775 = xor i32 %6771, %6773
  %6776 = xor i32 %6771, %6774
  %6777 = add nuw nsw i32 %6775, %6776
  %6778 = icmp eq i32 %6777, 2
  %6779 = zext i1 %6778 to i8
  store i8 %6779, i8* %43, align 1
  %6780 = sext i32 %6753 to i64
  store i64 %6780, i64* %RCX.i1197, align 8
  %6781 = shl nsw i64 %6780, 3
  %6782 = add i64 %6741, %6781
  %6783 = add i64 %6732, 43
  store i64 %6783, i64* %3, align 8
  %6784 = inttoptr i64 %6782 to i64*
  %6785 = load i64, i64* %6784, align 8
  store i64 %6785, i64* %RAX.i893, align 8
  store i64 %6742, i64* %RCX.i1197, align 8
  %6786 = add i64 %6742, 148
  %6787 = add i64 %6732, 57
  store i64 %6787, i64* %3, align 8
  %6788 = inttoptr i64 %6786 to i32*
  %6789 = load i32, i32* %6788, align 4
  %6790 = zext i32 %6789 to i64
  store i64 %6790, i64* %RDX.i1708, align 8
  %6791 = add i64 %6748, -16
  %6792 = add i64 %6732, 60
  store i64 %6792, i64* %3, align 8
  %6793 = inttoptr i64 %6791 to i32*
  %6794 = load i32, i32* %6793, align 4
  %6795 = add i32 %6794, %6789
  %6796 = zext i32 %6795 to i64
  store i64 %6796, i64* %RDX.i1708, align 8
  %6797 = icmp ult i32 %6795, %6789
  %6798 = icmp ult i32 %6795, %6794
  %6799 = or i1 %6797, %6798
  %6800 = zext i1 %6799 to i8
  store i8 %6800, i8* %19, align 1
  %6801 = and i32 %6795, 255
  %6802 = tail call i32 @llvm.ctpop.i32(i32 %6801)
  %6803 = trunc i32 %6802 to i8
  %6804 = and i8 %6803, 1
  %6805 = xor i8 %6804, 1
  store i8 %6805, i8* %26, align 1
  %6806 = xor i32 %6794, %6789
  %6807 = xor i32 %6806, %6795
  %6808 = lshr i32 %6807, 4
  %6809 = trunc i32 %6808 to i8
  %6810 = and i8 %6809, 1
  store i8 %6810, i8* %31, align 1
  %6811 = icmp eq i32 %6795, 0
  %6812 = zext i1 %6811 to i8
  store i8 %6812, i8* %34, align 1
  %6813 = lshr i32 %6795, 31
  %6814 = trunc i32 %6813 to i8
  store i8 %6814, i8* %37, align 1
  %6815 = lshr i32 %6789, 31
  %6816 = lshr i32 %6794, 31
  %6817 = xor i32 %6813, %6815
  %6818 = xor i32 %6813, %6816
  %6819 = add nuw nsw i32 %6817, %6818
  %6820 = icmp eq i32 %6819, 2
  %6821 = zext i1 %6820 to i8
  store i8 %6821, i8* %43, align 1
  %6822 = sext i32 %6795 to i64
  store i64 %6822, i64* %RCX.i1197, align 8
  %6823 = shl nsw i64 %6822, 3
  %6824 = add i64 %6785, %6823
  %6825 = add i64 %6732, 71
  store i64 %6825, i64* %3, align 8
  %6826 = inttoptr i64 %6824 to i64*
  store i64 -1, i64* %6826, align 8
  %6827 = load i64, i64* %3, align 8
  %6828 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %6828, i64* %RAX.i893, align 8
  %6829 = add i64 %6828, 6504
  %6830 = add i64 %6827, 15
  store i64 %6830, i64* %3, align 8
  %6831 = inttoptr i64 %6829 to i64*
  %6832 = load i64, i64* %6831, align 8
  store i64 %6832, i64* %RAX.i893, align 8
  %6833 = add i64 %6832, 8
  %6834 = add i64 %6827, 19
  store i64 %6834, i64* %3, align 8
  %6835 = inttoptr i64 %6833 to i64*
  %6836 = load i64, i64* %6835, align 8
  store i64 %6836, i64* %RAX.i893, align 8
  %6837 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6837, i64* %RCX.i1197, align 8
  %6838 = add i64 %6837, 144
  %6839 = add i64 %6827, 33
  store i64 %6839, i64* %3, align 8
  %6840 = inttoptr i64 %6838 to i32*
  %6841 = load i32, i32* %6840, align 4
  %6842 = zext i32 %6841 to i64
  store i64 %6842, i64* %RDX.i1708, align 8
  %6843 = load i64, i64* %RBP.i, align 8
  %6844 = add i64 %6843, -12
  %6845 = add i64 %6827, 36
  store i64 %6845, i64* %3, align 8
  %6846 = inttoptr i64 %6844 to i32*
  %6847 = load i32, i32* %6846, align 4
  %6848 = add i32 %6847, %6841
  %6849 = zext i32 %6848 to i64
  store i64 %6849, i64* %RDX.i1708, align 8
  %6850 = icmp ult i32 %6848, %6841
  %6851 = icmp ult i32 %6848, %6847
  %6852 = or i1 %6850, %6851
  %6853 = zext i1 %6852 to i8
  store i8 %6853, i8* %19, align 1
  %6854 = and i32 %6848, 255
  %6855 = tail call i32 @llvm.ctpop.i32(i32 %6854)
  %6856 = trunc i32 %6855 to i8
  %6857 = and i8 %6856, 1
  %6858 = xor i8 %6857, 1
  store i8 %6858, i8* %26, align 1
  %6859 = xor i32 %6847, %6841
  %6860 = xor i32 %6859, %6848
  %6861 = lshr i32 %6860, 4
  %6862 = trunc i32 %6861 to i8
  %6863 = and i8 %6862, 1
  store i8 %6863, i8* %31, align 1
  %6864 = icmp eq i32 %6848, 0
  %6865 = zext i1 %6864 to i8
  store i8 %6865, i8* %34, align 1
  %6866 = lshr i32 %6848, 31
  %6867 = trunc i32 %6866 to i8
  store i8 %6867, i8* %37, align 1
  %6868 = lshr i32 %6841, 31
  %6869 = lshr i32 %6847, 31
  %6870 = xor i32 %6866, %6868
  %6871 = xor i32 %6866, %6869
  %6872 = add nuw nsw i32 %6870, %6871
  %6873 = icmp eq i32 %6872, 2
  %6874 = zext i1 %6873 to i8
  store i8 %6874, i8* %43, align 1
  %6875 = sext i32 %6848 to i64
  store i64 %6875, i64* %RCX.i1197, align 8
  %6876 = shl nsw i64 %6875, 3
  %6877 = add i64 %6836, %6876
  %6878 = add i64 %6827, 43
  store i64 %6878, i64* %3, align 8
  %6879 = inttoptr i64 %6877 to i64*
  %6880 = load i64, i64* %6879, align 8
  store i64 %6880, i64* %RAX.i893, align 8
  store i64 %6837, i64* %RCX.i1197, align 8
  %6881 = add i64 %6837, 148
  %6882 = add i64 %6827, 57
  store i64 %6882, i64* %3, align 8
  %6883 = inttoptr i64 %6881 to i32*
  %6884 = load i32, i32* %6883, align 4
  %6885 = zext i32 %6884 to i64
  store i64 %6885, i64* %RDX.i1708, align 8
  %6886 = add i64 %6843, -16
  %6887 = add i64 %6827, 60
  store i64 %6887, i64* %3, align 8
  %6888 = inttoptr i64 %6886 to i32*
  %6889 = load i32, i32* %6888, align 4
  %6890 = add i32 %6889, %6884
  %6891 = zext i32 %6890 to i64
  store i64 %6891, i64* %RDX.i1708, align 8
  %6892 = icmp ult i32 %6890, %6884
  %6893 = icmp ult i32 %6890, %6889
  %6894 = or i1 %6892, %6893
  %6895 = zext i1 %6894 to i8
  store i8 %6895, i8* %19, align 1
  %6896 = and i32 %6890, 255
  %6897 = tail call i32 @llvm.ctpop.i32(i32 %6896)
  %6898 = trunc i32 %6897 to i8
  %6899 = and i8 %6898, 1
  %6900 = xor i8 %6899, 1
  store i8 %6900, i8* %26, align 1
  %6901 = xor i32 %6889, %6884
  %6902 = xor i32 %6901, %6890
  %6903 = lshr i32 %6902, 4
  %6904 = trunc i32 %6903 to i8
  %6905 = and i8 %6904, 1
  store i8 %6905, i8* %31, align 1
  %6906 = icmp eq i32 %6890, 0
  %6907 = zext i1 %6906 to i8
  store i8 %6907, i8* %34, align 1
  %6908 = lshr i32 %6890, 31
  %6909 = trunc i32 %6908 to i8
  store i8 %6909, i8* %37, align 1
  %6910 = lshr i32 %6884, 31
  %6911 = lshr i32 %6889, 31
  %6912 = xor i32 %6908, %6910
  %6913 = xor i32 %6908, %6911
  %6914 = add nuw nsw i32 %6912, %6913
  %6915 = icmp eq i32 %6914, 2
  %6916 = zext i1 %6915 to i8
  store i8 %6916, i8* %43, align 1
  %6917 = sext i32 %6890 to i64
  store i64 %6917, i64* %RCX.i1197, align 8
  %6918 = shl nsw i64 %6917, 3
  %6919 = add i64 %6880, %6918
  %6920 = add i64 %6827, 67
  store i64 %6920, i64* %3, align 8
  %6921 = inttoptr i64 %6919 to i16**
  %6922 = load i16*, i16** %6921, align 8
  %6923 = add i64 %6827, 72
  store i64 %6923, i64* %3, align 8
  store i16 0, i16* %6922, align 2
  %6924 = load i64, i64* %3, align 8
  %6925 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %6925, i64* %RAX.i893, align 8
  %6926 = add i64 %6925, 6504
  %6927 = add i64 %6924, 15
  store i64 %6927, i64* %3, align 8
  %6928 = inttoptr i64 %6926 to i64*
  %6929 = load i64, i64* %6928, align 8
  store i64 %6929, i64* %RAX.i893, align 8
  %6930 = add i64 %6929, 8
  %6931 = add i64 %6924, 19
  store i64 %6931, i64* %3, align 8
  %6932 = inttoptr i64 %6930 to i64*
  %6933 = load i64, i64* %6932, align 8
  store i64 %6933, i64* %RAX.i893, align 8
  %6934 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %6934, i64* %RCX.i1197, align 8
  %6935 = add i64 %6934, 144
  %6936 = add i64 %6924, 33
  store i64 %6936, i64* %3, align 8
  %6937 = inttoptr i64 %6935 to i32*
  %6938 = load i32, i32* %6937, align 4
  %6939 = zext i32 %6938 to i64
  store i64 %6939, i64* %RDX.i1708, align 8
  %6940 = load i64, i64* %RBP.i, align 8
  %6941 = add i64 %6940, -12
  %6942 = add i64 %6924, 36
  store i64 %6942, i64* %3, align 8
  %6943 = inttoptr i64 %6941 to i32*
  %6944 = load i32, i32* %6943, align 4
  %6945 = add i32 %6944, %6938
  %6946 = zext i32 %6945 to i64
  store i64 %6946, i64* %RDX.i1708, align 8
  %6947 = icmp ult i32 %6945, %6938
  %6948 = icmp ult i32 %6945, %6944
  %6949 = or i1 %6947, %6948
  %6950 = zext i1 %6949 to i8
  store i8 %6950, i8* %19, align 1
  %6951 = and i32 %6945, 255
  %6952 = tail call i32 @llvm.ctpop.i32(i32 %6951)
  %6953 = trunc i32 %6952 to i8
  %6954 = and i8 %6953, 1
  %6955 = xor i8 %6954, 1
  store i8 %6955, i8* %26, align 1
  %6956 = xor i32 %6944, %6938
  %6957 = xor i32 %6956, %6945
  %6958 = lshr i32 %6957, 4
  %6959 = trunc i32 %6958 to i8
  %6960 = and i8 %6959, 1
  store i8 %6960, i8* %31, align 1
  %6961 = icmp eq i32 %6945, 0
  %6962 = zext i1 %6961 to i8
  store i8 %6962, i8* %34, align 1
  %6963 = lshr i32 %6945, 31
  %6964 = trunc i32 %6963 to i8
  store i8 %6964, i8* %37, align 1
  %6965 = lshr i32 %6938, 31
  %6966 = lshr i32 %6944, 31
  %6967 = xor i32 %6963, %6965
  %6968 = xor i32 %6963, %6966
  %6969 = add nuw nsw i32 %6967, %6968
  %6970 = icmp eq i32 %6969, 2
  %6971 = zext i1 %6970 to i8
  store i8 %6971, i8* %43, align 1
  %6972 = sext i32 %6945 to i64
  store i64 %6972, i64* %RCX.i1197, align 8
  %6973 = shl nsw i64 %6972, 3
  %6974 = add i64 %6933, %6973
  %6975 = add i64 %6924, 43
  store i64 %6975, i64* %3, align 8
  %6976 = inttoptr i64 %6974 to i64*
  %6977 = load i64, i64* %6976, align 8
  store i64 %6977, i64* %RAX.i893, align 8
  store i64 %6934, i64* %RCX.i1197, align 8
  %6978 = add i64 %6934, 148
  %6979 = add i64 %6924, 57
  store i64 %6979, i64* %3, align 8
  %6980 = inttoptr i64 %6978 to i32*
  %6981 = load i32, i32* %6980, align 4
  %6982 = zext i32 %6981 to i64
  store i64 %6982, i64* %RDX.i1708, align 8
  %6983 = add i64 %6940, -16
  %6984 = add i64 %6924, 60
  store i64 %6984, i64* %3, align 8
  %6985 = inttoptr i64 %6983 to i32*
  %6986 = load i32, i32* %6985, align 4
  %6987 = add i32 %6986, %6981
  %6988 = zext i32 %6987 to i64
  store i64 %6988, i64* %RDX.i1708, align 8
  %6989 = icmp ult i32 %6987, %6981
  %6990 = icmp ult i32 %6987, %6986
  %6991 = or i1 %6989, %6990
  %6992 = zext i1 %6991 to i8
  store i8 %6992, i8* %19, align 1
  %6993 = and i32 %6987, 255
  %6994 = tail call i32 @llvm.ctpop.i32(i32 %6993)
  %6995 = trunc i32 %6994 to i8
  %6996 = and i8 %6995, 1
  %6997 = xor i8 %6996, 1
  store i8 %6997, i8* %26, align 1
  %6998 = xor i32 %6986, %6981
  %6999 = xor i32 %6998, %6987
  %7000 = lshr i32 %6999, 4
  %7001 = trunc i32 %7000 to i8
  %7002 = and i8 %7001, 1
  store i8 %7002, i8* %31, align 1
  %7003 = icmp eq i32 %6987, 0
  %7004 = zext i1 %7003 to i8
  store i8 %7004, i8* %34, align 1
  %7005 = lshr i32 %6987, 31
  %7006 = trunc i32 %7005 to i8
  store i8 %7006, i8* %37, align 1
  %7007 = lshr i32 %6981, 31
  %7008 = lshr i32 %6986, 31
  %7009 = xor i32 %7005, %7007
  %7010 = xor i32 %7005, %7008
  %7011 = add nuw nsw i32 %7009, %7010
  %7012 = icmp eq i32 %7011, 2
  %7013 = zext i1 %7012 to i8
  store i8 %7013, i8* %43, align 1
  %7014 = sext i32 %6987 to i64
  store i64 %7014, i64* %RCX.i1197, align 8
  %7015 = shl nsw i64 %7014, 3
  %7016 = add i64 %6977, %7015
  %7017 = add i64 %6924, 67
  store i64 %7017, i64* %3, align 8
  %7018 = inttoptr i64 %7016 to i64*
  %7019 = load i64, i64* %7018, align 8
  %7020 = add i64 %7019, 2
  %7021 = add i64 %6924, 73
  store i64 %7021, i64* %3, align 8
  %7022 = inttoptr i64 %7020 to i16*
  store i16 0, i16* %7022, align 2
  %7023 = load i64, i64* %3, align 8
  %7024 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7024, i64* %RAX.i893, align 8
  %7025 = add i64 %7024, 72400
  %7026 = add i64 %7023, 15
  store i64 %7026, i64* %3, align 8
  %7027 = inttoptr i64 %7025 to i32*
  %7028 = load i32, i32* %7027, align 4
  store i8 0, i8* %19, align 1
  %7029 = and i32 %7028, 255
  %7030 = tail call i32 @llvm.ctpop.i32(i32 %7029)
  %7031 = trunc i32 %7030 to i8
  %7032 = and i8 %7031, 1
  %7033 = xor i8 %7032, 1
  store i8 %7033, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %7034 = icmp eq i32 %7028, 0
  %7035 = zext i1 %7034 to i8
  store i8 %7035, i8* %34, align 1
  %7036 = lshr i32 %7028, 31
  %7037 = trunc i32 %7036 to i8
  store i8 %7037, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v340 = select i1 %7034, i64 60, i64 21
  %7038 = add i64 %7023, %.v340
  store i64 %7038, i64* %3, align 8
  br i1 %7034, label %block_.L_48efcf, label %block_48efa8

block_48efa8:                                     ; preds = %block_.L_48ee76
  %7039 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %7040 = add i64 %7039, 3264
  %7041 = lshr i64 %7040, 63
  %7042 = add i64 %7039, 3296
  store i64 %7042, i64* %RAX.i893, align 8
  %7043 = icmp ugt i64 %7040, -33
  %7044 = zext i1 %7043 to i8
  store i8 %7044, i8* %19, align 1
  %7045 = trunc i64 %7042 to i32
  %7046 = and i32 %7045, 255
  %7047 = tail call i32 @llvm.ctpop.i32(i32 %7046)
  %7048 = trunc i32 %7047 to i8
  %7049 = and i8 %7048, 1
  %7050 = xor i8 %7049, 1
  store i8 %7050, i8* %26, align 1
  %7051 = xor i64 %7042, %7040
  %7052 = lshr i64 %7051, 4
  %7053 = trunc i64 %7052 to i8
  %7054 = and i8 %7053, 1
  store i8 %7054, i8* %31, align 1
  %7055 = icmp eq i64 %7042, 0
  %7056 = zext i1 %7055 to i8
  store i8 %7056, i8* %34, align 1
  %7057 = lshr i64 %7042, 63
  %7058 = trunc i64 %7057 to i8
  store i8 %7058, i8* %37, align 1
  %7059 = xor i64 %7057, %7041
  %7060 = add nuw nsw i64 %7059, %7057
  %7061 = icmp eq i64 %7060, 2
  %7062 = zext i1 %7061 to i8
  store i8 %7062, i8* %43, align 1
  %7063 = load i64, i64* %RBP.i, align 8
  %7064 = add i64 %7063, -16
  %7065 = add i64 %7038, 22
  store i64 %7065, i64* %3, align 8
  %7066 = inttoptr i64 %7064 to i32*
  %7067 = load i32, i32* %7066, align 4
  %7068 = sext i32 %7067 to i64
  %7069 = shl nsw i64 %7068, 3
  store i64 %7069, i64* %RCX.i1197, align 8
  %7070 = add i64 %7069, %7042
  store i64 %7070, i64* %RAX.i893, align 8
  %7071 = icmp ult i64 %7070, %7042
  %7072 = icmp ult i64 %7070, %7069
  %7073 = or i1 %7071, %7072
  %7074 = zext i1 %7073 to i8
  store i8 %7074, i8* %19, align 1
  %7075 = trunc i64 %7070 to i32
  %7076 = and i32 %7075, 255
  %7077 = tail call i32 @llvm.ctpop.i32(i32 %7076)
  %7078 = trunc i32 %7077 to i8
  %7079 = and i8 %7078, 1
  %7080 = xor i8 %7079, 1
  store i8 %7080, i8* %26, align 1
  %7081 = xor i64 %7069, %7042
  %7082 = xor i64 %7081, %7070
  %7083 = lshr i64 %7082, 4
  %7084 = trunc i64 %7083 to i8
  %7085 = and i8 %7084, 1
  store i8 %7085, i8* %31, align 1
  %7086 = icmp eq i64 %7070, 0
  %7087 = zext i1 %7086 to i8
  store i8 %7087, i8* %34, align 1
  %7088 = lshr i64 %7070, 63
  %7089 = trunc i64 %7088 to i8
  store i8 %7089, i8* %37, align 1
  %7090 = lshr i64 %7068, 60
  %7091 = and i64 %7090, 1
  %7092 = xor i64 %7088, %7057
  %7093 = xor i64 %7088, %7091
  %7094 = add nuw nsw i64 %7092, %7093
  %7095 = icmp eq i64 %7094, 2
  %7096 = zext i1 %7095 to i8
  store i8 %7096, i8* %43, align 1
  %7097 = add i64 %7063, -12
  %7098 = add i64 %7038, 33
  store i64 %7098, i64* %3, align 8
  %7099 = inttoptr i64 %7097 to i32*
  %7100 = load i32, i32* %7099, align 4
  %7101 = sext i32 %7100 to i64
  store i64 %7101, i64* %RCX.i1197, align 8
  %7102 = shl nsw i64 %7101, 1
  %7103 = add i64 %7102, %7070
  %7104 = add i64 %7038, 39
  store i64 %7104, i64* %3, align 8
  %7105 = inttoptr i64 %7103 to i16*
  store i16 -1, i16* %7105, align 2
  %.pre232 = load i64, i64* %3, align 8
  br label %block_.L_48efcf

block_.L_48efcf:                                  ; preds = %block_48efa8, %block_.L_48ee76
  %7106 = phi i64 [ %.pre232, %block_48efa8 ], [ %7038, %block_.L_48ee76 ]
  %7107 = add i64 %7106, 1564
  br label %block_.L_48f5eb

block_.L_48efd4:                                  ; preds = %routine_idivl__esi.exit1706
  %7108 = add i64 %6586, -56
  %7109 = add i64 %6636, 4
  store i64 %7109, i64* %3, align 8
  %7110 = inttoptr i64 %7108 to i64*
  %7111 = load i64, i64* %7110, align 8
  store i64 %7111, i64* %RAX.i893, align 8
  %7112 = add i64 %7111, 580
  %7113 = add i64 %6636, 11
  store i64 %7113, i64* %3, align 8
  %7114 = inttoptr i64 %7112 to i32*
  %7115 = load i32, i32* %7114, align 4
  store i8 0, i8* %19, align 1
  %7116 = and i32 %7115, 255
  %7117 = tail call i32 @llvm.ctpop.i32(i32 %7116)
  %7118 = trunc i32 %7117 to i8
  %7119 = and i8 %7118, 1
  %7120 = xor i8 %7119, 1
  store i8 %7120, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %7121 = icmp eq i32 %7115, 0
  %7122 = zext i1 %7121 to i8
  store i8 %7122, i8* %34, align 1
  %7123 = lshr i32 %7115, 31
  %7124 = trunc i32 %7123 to i8
  store i8 %7124, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v334 = select i1 %7121, i64 760, i64 17
  %7125 = add i64 %6636, %.v334
  store i64 %7125, i64* %3, align 8
  br i1 %7121, label %block_.L_48f2cc, label %block_48efe5

block_48efe5:                                     ; preds = %block_.L_48efd4
  store i64 2, i64* %RAX.i893, align 8
  %7126 = add i64 %7125, 9
  store i64 %7126, i64* %3, align 8
  %7127 = load i64, i64* %7110, align 8
  store i64 %7127, i64* %RCX.i1197, align 8
  %7128 = add i64 %6586, -12
  %7129 = add i64 %7125, 12
  store i64 %7129, i64* %3, align 8
  %7130 = inttoptr i64 %7128 to i32*
  %7131 = load i32, i32* %7130, align 4
  %7132 = zext i32 %7131 to i64
  store i64 %7132, i64* %RDX.i1708, align 8
  %7133 = add i64 %6586, -212
  %7134 = add i64 %7125, 18
  store i64 %7134, i64* %3, align 8
  %7135 = inttoptr i64 %7133 to i32*
  store i32 2, i32* %7135, align 4
  %7136 = load i32, i32* %EDX.i1723, align 4
  %7137 = zext i32 %7136 to i64
  %7138 = load i64, i64* %3, align 8
  store i64 %7137, i64* %RAX.i893, align 8
  %7139 = sext i32 %7136 to i64
  %7140 = lshr i64 %7139, 32
  store i64 %7140, i64* %2568, align 8
  %7141 = load i64, i64* %RBP.i, align 8
  %7142 = add i64 %7141, -212
  %7143 = add i64 %7138, 9
  store i64 %7143, i64* %3, align 8
  %7144 = inttoptr i64 %7142 to i32*
  %7145 = load i32, i32* %7144, align 4
  %7146 = zext i32 %7145 to i64
  store i64 %7146, i64* %RSI.i4020.pre-phi, align 8
  %7147 = add i64 %7138, 11
  store i64 %7147, i64* %3, align 8
  %7148 = sext i32 %7145 to i64
  %7149 = shl nuw i64 %7140, 32
  %7150 = or i64 %7149, %7137
  %7151 = sdiv i64 %7150, %7148
  %7152 = shl i64 %7151, 32
  %7153 = ashr exact i64 %7152, 32
  %7154 = icmp eq i64 %7151, %7153
  br i1 %7154, label %7157, label %7155

; <label>:7155:                                   ; preds = %block_48efe5
  %7156 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %7147, %struct.Memory* %6567)
  %.pre205 = load i64, i64* %RBP.i, align 8
  %.pre206 = load i64, i64* %3, align 8
  %.pre207 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__esi.exit1495

; <label>:7157:                                   ; preds = %block_48efe5
  %7158 = srem i64 %7150, %7148
  %7159 = and i64 %7151, 4294967295
  store i64 %7159, i64* %RAX.i893, align 8
  %7160 = and i64 %7158, 4294967295
  store i64 %7160, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %7161 = trunc i64 %7151 to i32
  br label %routine_idivl__esi.exit1495

routine_idivl__esi.exit1495:                      ; preds = %7157, %7155
  %7162 = phi i32 [ %.pre207, %7155 ], [ %7161, %7157 ]
  %7163 = phi i64 [ %.pre206, %7155 ], [ %7147, %7157 ]
  %7164 = phi i64 [ %.pre205, %7155 ], [ %7141, %7157 ]
  %7165 = phi %struct.Memory* [ %7156, %7155 ], [ %6567, %7157 ]
  %7166 = add i64 %7164, -16
  %7167 = add i64 %7163, 3
  store i64 %7167, i64* %3, align 8
  %7168 = inttoptr i64 %7166 to i32*
  %7169 = load i32, i32* %7168, align 4
  %7170 = zext i32 %7169 to i64
  store i64 %7170, i64* %RDI.i3116, align 8
  %7171 = add i64 %7164, -216
  %7172 = add i64 %7163, 9
  store i64 %7172, i64* %3, align 8
  %7173 = inttoptr i64 %7171 to i32*
  store i32 %7162, i32* %7173, align 4
  %7174 = load i32, i32* %EDI.i3110, align 4
  %7175 = zext i32 %7174 to i64
  %7176 = load i64, i64* %3, align 8
  store i64 %7175, i64* %RAX.i893, align 8
  %7177 = sext i32 %7174 to i64
  %7178 = lshr i64 %7177, 32
  store i64 %7178, i64* %2568, align 8
  %7179 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %7180 = add i64 %7176, 5
  store i64 %7180, i64* %3, align 8
  %7181 = sext i32 %7179 to i64
  %7182 = shl nuw i64 %7178, 32
  %7183 = or i64 %7182, %7175
  %7184 = sdiv i64 %7183, %7181
  %7185 = shl i64 %7184, 32
  %7186 = ashr exact i64 %7185, 32
  %7187 = icmp eq i64 %7184, %7186
  br i1 %7187, label %7190, label %7188

; <label>:7188:                                   ; preds = %routine_idivl__esi.exit1495
  %7189 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %7180, %struct.Memory* %7165)
  %.pre208 = load i64, i64* %RAX.i893, align 8
  %.pre209 = load i64, i64* %3, align 8
  br label %routine_idivl__esi.exit

; <label>:7190:                                   ; preds = %routine_idivl__esi.exit1495
  %7191 = srem i64 %7183, %7181
  %7192 = and i64 %7184, 4294967295
  store i64 %7192, i64* %RAX.i893, align 8
  %7193 = and i64 %7191, 4294967295
  store i64 %7193, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__esi.exit

routine_idivl__esi.exit:                          ; preds = %7190, %7188
  %7194 = phi i64 [ %.pre209, %7188 ], [ %7180, %7190 ]
  %7195 = phi i64 [ %.pre208, %7188 ], [ %7192, %7190 ]
  %7196 = phi %struct.Memory* [ %7189, %7188 ], [ %7165, %7190 ]
  %7197 = trunc i64 %7195 to i32
  %7198 = shl i32 %7197, 1
  %7199 = icmp slt i32 %7197, 0
  %7200 = icmp slt i32 %7198, 0
  %7201 = xor i1 %7199, %7200
  %7202 = zext i32 %7198 to i64
  store i64 %7202, i64* %RAX.i893, align 8
  %.lobit104 = lshr i32 %7197, 31
  %7203 = trunc i32 %.lobit104 to i8
  store i8 %7203, i8* %19, align 1
  %7204 = and i32 %7198, 254
  %7205 = tail call i32 @llvm.ctpop.i32(i32 %7204)
  %7206 = trunc i32 %7205 to i8
  %7207 = and i8 %7206, 1
  %7208 = xor i8 %7207, 1
  store i8 %7208, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %7209 = icmp eq i32 %7198, 0
  %7210 = zext i1 %7209 to i8
  store i8 %7210, i8* %34, align 1
  %7211 = lshr i32 %7197, 30
  %7212 = trunc i32 %7211 to i8
  %7213 = and i8 %7212, 1
  store i8 %7213, i8* %37, align 1
  %7214 = zext i1 %7201 to i8
  store i8 %7214, i8* %43, align 1
  %7215 = load i64, i64* %RBP.i, align 8
  %7216 = add i64 %7215, -216
  %7217 = add i64 %7194, 8
  store i64 %7217, i64* %3, align 8
  %7218 = inttoptr i64 %7216 to i32*
  %7219 = load i32, i32* %7218, align 4
  %7220 = add i32 %7198, %7219
  %7221 = zext i32 %7220 to i64
  store i64 %7221, i64* %RDI.i3116, align 8
  %7222 = icmp ult i32 %7220, %7219
  %7223 = icmp ult i32 %7220, %7198
  %7224 = or i1 %7222, %7223
  %7225 = zext i1 %7224 to i8
  store i8 %7225, i8* %19, align 1
  %7226 = and i32 %7220, 255
  %7227 = tail call i32 @llvm.ctpop.i32(i32 %7226)
  %7228 = trunc i32 %7227 to i8
  %7229 = and i8 %7228, 1
  %7230 = xor i8 %7229, 1
  store i8 %7230, i8* %26, align 1
  %7231 = xor i32 %7198, %7219
  %7232 = xor i32 %7231, %7220
  %7233 = lshr i32 %7232, 4
  %7234 = trunc i32 %7233 to i8
  %7235 = and i8 %7234, 1
  store i8 %7235, i8* %31, align 1
  %7236 = icmp eq i32 %7220, 0
  %7237 = zext i1 %7236 to i8
  store i8 %7237, i8* %34, align 1
  %7238 = lshr i32 %7220, 31
  %7239 = trunc i32 %7238 to i8
  store i8 %7239, i8* %37, align 1
  %7240 = lshr i32 %7219, 31
  %7241 = lshr i32 %7197, 30
  %7242 = and i32 %7241, 1
  %7243 = xor i32 %7238, %7240
  %7244 = xor i32 %7238, %7242
  %7245 = add nuw nsw i32 %7243, %7244
  %7246 = icmp eq i32 %7245, 2
  %7247 = zext i1 %7246 to i8
  store i8 %7247, i8* %43, align 1
  %7248 = sext i32 %7220 to i64
  store i64 %7248, i64* %R8.i3094, align 8
  %7249 = load i64, i64* %RCX.i1197, align 8
  %7250 = shl nsw i64 %7248, 2
  %7251 = add nsw i64 %7250, 488
  %7252 = add i64 %7251, %7249
  %7253 = add i64 %7194, 22
  store i64 %7253, i64* %3, align 8
  %7254 = inttoptr i64 %7252 to i32*
  %7255 = load i32, i32* %7254, align 4
  %7256 = add i32 %7255, -2
  %7257 = icmp ult i32 %7255, 2
  %7258 = zext i1 %7257 to i8
  store i8 %7258, i8* %19, align 1
  %7259 = and i32 %7256, 255
  %7260 = tail call i32 @llvm.ctpop.i32(i32 %7259)
  %7261 = trunc i32 %7260 to i8
  %7262 = and i8 %7261, 1
  %7263 = xor i8 %7262, 1
  store i8 %7263, i8* %26, align 1
  %7264 = xor i32 %7256, %7255
  %7265 = lshr i32 %7264, 4
  %7266 = trunc i32 %7265 to i8
  %7267 = and i8 %7266, 1
  store i8 %7267, i8* %31, align 1
  %7268 = icmp eq i32 %7256, 0
  %7269 = zext i1 %7268 to i8
  store i8 %7269, i8* %34, align 1
  %7270 = lshr i32 %7256, 31
  %7271 = trunc i32 %7270 to i8
  store i8 %7271, i8* %37, align 1
  %7272 = lshr i32 %7255, 31
  %7273 = xor i32 %7270, %7272
  %7274 = add nuw nsw i32 %7273, %7272
  %7275 = icmp eq i32 %7274, 2
  %7276 = zext i1 %7275 to i8
  store i8 %7276, i8* %43, align 1
  %.v335 = select i1 %7268, i64 28, i64 699
  %7277 = add i64 %7194, %.v335
  store i64 %7277, i64* %3, align 8
  br i1 %7268, label %block_48f02d, label %block_.L_48f2cc

block_48f02d:                                     ; preds = %routine_idivl__esi.exit
  %7278 = add i64 %7215, -56
  %7279 = add i64 %7277, 4
  store i64 %7279, i64* %3, align 8
  %7280 = inttoptr i64 %7278 to i64*
  %7281 = load i64, i64* %7280, align 8
  store i64 %7281, i64* %RAX.i893, align 8
  %7282 = add i64 %7281, 72
  %7283 = add i64 %7277, 8
  store i64 %7283, i64* %3, align 8
  %7284 = inttoptr i64 %7282 to i32*
  %7285 = load i32, i32* %7284, align 4
  %7286 = add i32 %7285, -1
  %7287 = icmp eq i32 %7285, 0
  %7288 = zext i1 %7287 to i8
  store i8 %7288, i8* %19, align 1
  %7289 = and i32 %7286, 255
  %7290 = tail call i32 @llvm.ctpop.i32(i32 %7289)
  %7291 = trunc i32 %7290 to i8
  %7292 = and i8 %7291, 1
  %7293 = xor i8 %7292, 1
  store i8 %7293, i8* %26, align 1
  %7294 = xor i32 %7286, %7285
  %7295 = lshr i32 %7294, 4
  %7296 = trunc i32 %7295 to i8
  %7297 = and i8 %7296, 1
  store i8 %7297, i8* %31, align 1
  %7298 = icmp eq i32 %7286, 0
  %7299 = zext i1 %7298 to i8
  store i8 %7299, i8* %34, align 1
  %7300 = lshr i32 %7286, 31
  %7301 = trunc i32 %7300 to i8
  store i8 %7301, i8* %37, align 1
  %7302 = lshr i32 %7285, 31
  %7303 = xor i32 %7300, %7302
  %7304 = add nuw nsw i32 %7303, %7302
  %7305 = icmp eq i32 %7304, 2
  %7306 = zext i1 %7305 to i8
  store i8 %7306, i8* %43, align 1
  %.v337 = select i1 %7298, i64 14, i64 671
  %7307 = add i64 %7277, %.v337
  store i64 %7307, i64* %3, align 8
  br i1 %7298, label %block_48f03b, label %block_.L_48f2cc

block_48f03b:                                     ; preds = %block_48f02d
  %7308 = add i64 %7307, 4
  store i64 %7308, i64* %3, align 8
  %7309 = load i64, i64* %7280, align 8
  store i64 %7309, i64* %RAX.i893, align 8
  %7310 = add i64 %7309, 580
  %7311 = add i64 %7307, 11
  store i64 %7311, i64* %3, align 8
  %7312 = inttoptr i64 %7310 to i32*
  %7313 = load i32, i32* %7312, align 4
  %7314 = add i32 %7313, -1
  %7315 = icmp eq i32 %7313, 0
  %7316 = zext i1 %7315 to i8
  store i8 %7316, i8* %19, align 1
  %7317 = and i32 %7314, 255
  %7318 = tail call i32 @llvm.ctpop.i32(i32 %7317)
  %7319 = trunc i32 %7318 to i8
  %7320 = and i8 %7319, 1
  %7321 = xor i8 %7320, 1
  store i8 %7321, i8* %26, align 1
  %7322 = xor i32 %7314, %7313
  %7323 = lshr i32 %7322, 4
  %7324 = trunc i32 %7323 to i8
  %7325 = and i8 %7324, 1
  store i8 %7325, i8* %31, align 1
  %7326 = icmp eq i32 %7314, 0
  %7327 = zext i1 %7326 to i8
  store i8 %7327, i8* %34, align 1
  %7328 = lshr i32 %7314, 31
  %7329 = trunc i32 %7328 to i8
  store i8 %7329, i8* %37, align 1
  %7330 = lshr i32 %7313, 31
  %7331 = xor i32 %7328, %7330
  %7332 = add nuw nsw i32 %7331, %7330
  %7333 = icmp eq i32 %7332, 2
  %7334 = zext i1 %7333 to i8
  store i8 %7334, i8* %43, align 1
  %.v338 = select i1 %7326, i64 17, i64 44
  %7335 = add i64 %7307, %.v338
  %7336 = add i64 %7335, 8
  store i64 %7336, i64* %3, align 8
  %7337 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7337, i64* %RAX.i893, align 8
  br i1 %7326, label %block_48f04c, label %block_.L_48f067

block_48f04c:                                     ; preds = %block_48f03b
  %7338 = add i64 %7337, 71936
  %7339 = add i64 %7335, 15
  store i64 %7339, i64* %3, align 8
  %7340 = inttoptr i64 %7338 to i64*
  %7341 = load i64, i64* %7340, align 8
  store i64 %7341, i64* %RAX.i893, align 8
  %7342 = add i64 %7215, -224
  %7343 = add i64 %7335, 22
  store i64 %7343, i64* %3, align 8
  %7344 = inttoptr i64 %7342 to i64*
  store i64 %7341, i64* %7344, align 8
  %7345 = load i64, i64* %3, align 8
  %7346 = add i64 %7345, 27
  store i64 %7346, i64* %3, align 8
  br label %block_.L_48f07d

block_.L_48f067:                                  ; preds = %block_48f03b
  %7347 = add i64 %7337, 71944
  %7348 = add i64 %7335, 15
  store i64 %7348, i64* %3, align 8
  %7349 = inttoptr i64 %7347 to i64*
  %7350 = load i64, i64* %7349, align 8
  store i64 %7350, i64* %RAX.i893, align 8
  %7351 = add i64 %7215, -224
  %7352 = add i64 %7335, 22
  store i64 %7352, i64* %3, align 8
  %7353 = inttoptr i64 %7351 to i64*
  store i64 %7350, i64* %7353, align 8
  %.pre210 = load i64, i64* %3, align 8
  br label %block_.L_48f07d

block_.L_48f07d:                                  ; preds = %block_.L_48f067, %block_48f04c
  %7354 = phi i64 [ %.pre210, %block_.L_48f067 ], [ %7346, %block_48f04c ]
  %7355 = load i64, i64* %RBP.i, align 8
  %7356 = add i64 %7355, -224
  %7357 = add i64 %7354, 7
  store i64 %7357, i64* %3, align 8
  %7358 = inttoptr i64 %7356 to i64*
  %7359 = load i64, i64* %7358, align 8
  store i64 2, i64* %RCX.i1197, align 8
  %7360 = add i64 %7355, -112
  %7361 = add i64 %7354, 16
  store i64 %7361, i64* %3, align 8
  %7362 = inttoptr i64 %7360 to i64*
  store i64 %7359, i64* %7362, align 8
  %7363 = load i64, i64* %3, align 8
  %7364 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %7364, i64* %RAX.i893, align 8
  %7365 = add i64 %7364, 6480
  %7366 = add i64 %7363, 15
  store i64 %7366, i64* %3, align 8
  %7367 = inttoptr i64 %7365 to i64*
  %7368 = load i64, i64* %7367, align 8
  store i64 %7368, i64* %RAX.i893, align 8
  %7369 = add i64 %7368, 8
  %7370 = add i64 %7363, 19
  store i64 %7370, i64* %3, align 8
  %7371 = inttoptr i64 %7369 to i64*
  %7372 = load i64, i64* %7371, align 8
  store i64 %7372, i64* %RAX.i893, align 8
  %7373 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7373, i64* %RDX.i1708, align 8
  %7374 = add i64 %7373, 144
  %7375 = add i64 %7363, 33
  store i64 %7375, i64* %3, align 8
  %7376 = inttoptr i64 %7374 to i32*
  %7377 = load i32, i32* %7376, align 4
  %7378 = zext i32 %7377 to i64
  store i64 %7378, i64* %RSI.i4020.pre-phi, align 8
  %7379 = load i64, i64* %RBP.i, align 8
  %7380 = add i64 %7379, -12
  %7381 = add i64 %7363, 36
  store i64 %7381, i64* %3, align 8
  %7382 = inttoptr i64 %7380 to i32*
  %7383 = load i32, i32* %7382, align 4
  %7384 = add i32 %7383, %7377
  %7385 = zext i32 %7384 to i64
  store i64 %7385, i64* %RSI.i4020.pre-phi, align 8
  %7386 = icmp ult i32 %7384, %7377
  %7387 = icmp ult i32 %7384, %7383
  %7388 = or i1 %7386, %7387
  %7389 = zext i1 %7388 to i8
  store i8 %7389, i8* %19, align 1
  %7390 = and i32 %7384, 255
  %7391 = tail call i32 @llvm.ctpop.i32(i32 %7390)
  %7392 = trunc i32 %7391 to i8
  %7393 = and i8 %7392, 1
  %7394 = xor i8 %7393, 1
  store i8 %7394, i8* %26, align 1
  %7395 = xor i32 %7383, %7377
  %7396 = xor i32 %7395, %7384
  %7397 = lshr i32 %7396, 4
  %7398 = trunc i32 %7397 to i8
  %7399 = and i8 %7398, 1
  store i8 %7399, i8* %31, align 1
  %7400 = icmp eq i32 %7384, 0
  %7401 = zext i1 %7400 to i8
  store i8 %7401, i8* %34, align 1
  %7402 = lshr i32 %7384, 31
  %7403 = trunc i32 %7402 to i8
  store i8 %7403, i8* %37, align 1
  %7404 = lshr i32 %7377, 31
  %7405 = lshr i32 %7383, 31
  %7406 = xor i32 %7402, %7404
  %7407 = xor i32 %7402, %7405
  %7408 = add nuw nsw i32 %7406, %7407
  %7409 = icmp eq i32 %7408, 2
  %7410 = zext i1 %7409 to i8
  store i8 %7410, i8* %43, align 1
  %7411 = sext i32 %7384 to i64
  store i64 %7411, i64* %RDX.i1708, align 8
  %7412 = shl nsw i64 %7411, 3
  %7413 = add i64 %7372, %7412
  %7414 = add i64 %7363, 43
  store i64 %7414, i64* %3, align 8
  %7415 = inttoptr i64 %7413 to i64*
  %7416 = load i64, i64* %7415, align 8
  store i64 %7416, i64* %RAX.i893, align 8
  store i64 %7373, i64* %RDX.i1708, align 8
  %7417 = add i64 %7373, 148
  %7418 = add i64 %7363, 57
  store i64 %7418, i64* %3, align 8
  %7419 = inttoptr i64 %7417 to i32*
  %7420 = load i32, i32* %7419, align 4
  %7421 = zext i32 %7420 to i64
  store i64 %7421, i64* %RSI.i4020.pre-phi, align 8
  %7422 = add i64 %7379, -16
  %7423 = add i64 %7363, 60
  store i64 %7423, i64* %3, align 8
  %7424 = inttoptr i64 %7422 to i32*
  %7425 = load i32, i32* %7424, align 4
  %7426 = add i32 %7425, %7420
  %7427 = zext i32 %7426 to i64
  store i64 %7427, i64* %RSI.i4020.pre-phi, align 8
  %7428 = sext i32 %7426 to i64
  store i64 %7428, i64* %RDX.i1708, align 8
  %7429 = shl nsw i64 %7428, 1
  %7430 = add i64 %7416, %7429
  %7431 = add i64 %7363, 69
  store i64 %7431, i64* %3, align 8
  %7432 = inttoptr i64 %7430 to i16*
  store i16 0, i16* %7432, align 2
  %7433 = load i64, i64* %3, align 8
  %7434 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  %7435 = add i64 %7434, 24
  store i64 %7435, i64* %RAX.i893, align 8
  %7436 = icmp ugt i64 %7434, -25
  %7437 = zext i1 %7436 to i8
  store i8 %7437, i8* %19, align 1
  %7438 = trunc i64 %7435 to i32
  %7439 = and i32 %7438, 255
  %7440 = tail call i32 @llvm.ctpop.i32(i32 %7439)
  %7441 = trunc i32 %7440 to i8
  %7442 = and i8 %7441, 1
  %7443 = xor i8 %7442, 1
  store i8 %7443, i8* %26, align 1
  %7444 = xor i64 %7434, 16
  %7445 = xor i64 %7444, %7435
  %7446 = lshr i64 %7445, 4
  %7447 = trunc i64 %7446 to i8
  %7448 = and i8 %7447, 1
  store i8 %7448, i8* %31, align 1
  %7449 = icmp eq i64 %7435, 0
  %7450 = zext i1 %7449 to i8
  store i8 %7450, i8* %34, align 1
  %7451 = lshr i64 %7435, 63
  %7452 = trunc i64 %7451 to i8
  store i8 %7452, i8* %37, align 1
  %7453 = lshr i64 %7434, 63
  %7454 = xor i64 %7451, %7453
  %7455 = add nuw nsw i64 %7454, %7451
  %7456 = icmp eq i64 %7455, 2
  %7457 = zext i1 %7456 to i8
  store i8 %7457, i8* %43, align 1
  %7458 = load i64, i64* %RBP.i, align 8
  %7459 = add i64 %7458, -92
  %7460 = add i64 %7433, 15
  store i64 %7460, i64* %3, align 8
  %7461 = inttoptr i64 %7459 to i32*
  %7462 = load i32, i32* %7461, align 4
  %7463 = add i32 %7462, 1
  %7464 = zext i32 %7463 to i64
  store i64 %7464, i64* %RSI.i4020.pre-phi, align 8
  %7465 = sext i32 %7463 to i64
  %7466 = mul nsw i64 %7465, 264
  store i64 %7466, i64* %RDX.i1708, align 8
  %7467 = lshr i64 %7466, 63
  %7468 = load i64, i64* %RAX.i893, align 8
  %7469 = add i64 %7466, %7468
  store i64 %7469, i64* %RAX.i893, align 8
  %7470 = icmp ult i64 %7469, %7468
  %7471 = icmp ult i64 %7469, %7466
  %7472 = or i1 %7470, %7471
  %7473 = zext i1 %7472 to i8
  store i8 %7473, i8* %19, align 1
  %7474 = trunc i64 %7469 to i32
  %7475 = and i32 %7474, 255
  %7476 = tail call i32 @llvm.ctpop.i32(i32 %7475)
  %7477 = trunc i32 %7476 to i8
  %7478 = and i8 %7477, 1
  %7479 = xor i8 %7478, 1
  store i8 %7479, i8* %26, align 1
  %7480 = xor i64 %7466, %7468
  %7481 = xor i64 %7480, %7469
  %7482 = lshr i64 %7481, 4
  %7483 = trunc i64 %7482 to i8
  %7484 = and i8 %7483, 1
  store i8 %7484, i8* %31, align 1
  %7485 = icmp eq i64 %7469, 0
  %7486 = zext i1 %7485 to i8
  store i8 %7486, i8* %34, align 1
  %7487 = lshr i64 %7469, 63
  %7488 = trunc i64 %7487 to i8
  store i8 %7488, i8* %37, align 1
  %7489 = lshr i64 %7468, 63
  %7490 = xor i64 %7487, %7489
  %7491 = xor i64 %7487, %7467
  %7492 = add nuw nsw i64 %7490, %7491
  %7493 = icmp eq i64 %7492, 2
  %7494 = zext i1 %7493 to i8
  store i8 %7494, i8* %43, align 1
  %7495 = inttoptr i64 %7469 to i64*
  %7496 = add i64 %7433, 34
  store i64 %7496, i64* %3, align 8
  %7497 = load i64, i64* %7495, align 8
  store i64 %7497, i64* %RAX.i893, align 8
  %7498 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %7498, i64* %RDX.i1708, align 8
  %7499 = add i64 %7498, 6488
  %7500 = add i64 %7433, 49
  store i64 %7500, i64* %3, align 8
  %7501 = inttoptr i64 %7499 to i64*
  %7502 = load i64, i64* %7501, align 8
  store i64 %7502, i64* %RDX.i1708, align 8
  %7503 = add i64 %7502, 8
  %7504 = add i64 %7433, 53
  store i64 %7504, i64* %3, align 8
  %7505 = inttoptr i64 %7503 to i64*
  %7506 = load i64, i64* %7505, align 8
  store i64 %7506, i64* %RDX.i1708, align 8
  %7507 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7507, i64* %RDI.i3116, align 8
  %7508 = add i64 %7507, 144
  %7509 = add i64 %7433, 67
  store i64 %7509, i64* %3, align 8
  %7510 = inttoptr i64 %7508 to i32*
  %7511 = load i32, i32* %7510, align 4
  %7512 = zext i32 %7511 to i64
  store i64 %7512, i64* %RSI.i4020.pre-phi, align 8
  %7513 = load i64, i64* %RBP.i, align 8
  %7514 = add i64 %7513, -12
  %7515 = add i64 %7433, 70
  store i64 %7515, i64* %3, align 8
  %7516 = inttoptr i64 %7514 to i32*
  %7517 = load i32, i32* %7516, align 4
  %7518 = add i32 %7517, %7511
  %7519 = zext i32 %7518 to i64
  store i64 %7519, i64* %RSI.i4020.pre-phi, align 8
  %7520 = icmp ult i32 %7518, %7511
  %7521 = icmp ult i32 %7518, %7517
  %7522 = or i1 %7520, %7521
  %7523 = zext i1 %7522 to i8
  store i8 %7523, i8* %19, align 1
  %7524 = and i32 %7518, 255
  %7525 = tail call i32 @llvm.ctpop.i32(i32 %7524)
  %7526 = trunc i32 %7525 to i8
  %7527 = and i8 %7526, 1
  %7528 = xor i8 %7527, 1
  store i8 %7528, i8* %26, align 1
  %7529 = xor i32 %7517, %7511
  %7530 = xor i32 %7529, %7518
  %7531 = lshr i32 %7530, 4
  %7532 = trunc i32 %7531 to i8
  %7533 = and i8 %7532, 1
  store i8 %7533, i8* %31, align 1
  %7534 = icmp eq i32 %7518, 0
  %7535 = zext i1 %7534 to i8
  store i8 %7535, i8* %34, align 1
  %7536 = lshr i32 %7518, 31
  %7537 = trunc i32 %7536 to i8
  store i8 %7537, i8* %37, align 1
  %7538 = lshr i32 %7511, 31
  %7539 = lshr i32 %7517, 31
  %7540 = xor i32 %7536, %7538
  %7541 = xor i32 %7536, %7539
  %7542 = add nuw nsw i32 %7540, %7541
  %7543 = icmp eq i32 %7542, 2
  %7544 = zext i1 %7543 to i8
  store i8 %7544, i8* %43, align 1
  %7545 = sext i32 %7518 to i64
  store i64 %7545, i64* %RDI.i3116, align 8
  %7546 = shl nsw i64 %7545, 3
  %7547 = add i64 %7506, %7546
  %7548 = add i64 %7433, 77
  store i64 %7548, i64* %3, align 8
  %7549 = inttoptr i64 %7547 to i64*
  %7550 = load i64, i64* %7549, align 8
  store i64 %7550, i64* %RDX.i1708, align 8
  store i64 %7507, i64* %RDI.i3116, align 8
  %7551 = add i64 %7507, 148
  %7552 = add i64 %7433, 91
  store i64 %7552, i64* %3, align 8
  %7553 = inttoptr i64 %7551 to i32*
  %7554 = load i32, i32* %7553, align 4
  %7555 = zext i32 %7554 to i64
  store i64 %7555, i64* %RSI.i4020.pre-phi, align 8
  %7556 = add i64 %7513, -16
  %7557 = add i64 %7433, 94
  store i64 %7557, i64* %3, align 8
  %7558 = inttoptr i64 %7556 to i32*
  %7559 = load i32, i32* %7558, align 4
  %7560 = add i32 %7559, %7554
  %7561 = zext i32 %7560 to i64
  store i64 %7561, i64* %RSI.i4020.pre-phi, align 8
  %7562 = icmp ult i32 %7560, %7554
  %7563 = icmp ult i32 %7560, %7559
  %7564 = or i1 %7562, %7563
  %7565 = zext i1 %7564 to i8
  store i8 %7565, i8* %19, align 1
  %7566 = and i32 %7560, 255
  %7567 = tail call i32 @llvm.ctpop.i32(i32 %7566)
  %7568 = trunc i32 %7567 to i8
  %7569 = and i8 %7568, 1
  %7570 = xor i8 %7569, 1
  store i8 %7570, i8* %26, align 1
  %7571 = xor i32 %7559, %7554
  %7572 = xor i32 %7571, %7560
  %7573 = lshr i32 %7572, 4
  %7574 = trunc i32 %7573 to i8
  %7575 = and i8 %7574, 1
  store i8 %7575, i8* %31, align 1
  %7576 = icmp eq i32 %7560, 0
  %7577 = zext i1 %7576 to i8
  store i8 %7577, i8* %34, align 1
  %7578 = lshr i32 %7560, 31
  %7579 = trunc i32 %7578 to i8
  store i8 %7579, i8* %37, align 1
  %7580 = lshr i32 %7554, 31
  %7581 = lshr i32 %7559, 31
  %7582 = xor i32 %7578, %7580
  %7583 = xor i32 %7578, %7581
  %7584 = add nuw nsw i32 %7582, %7583
  %7585 = icmp eq i32 %7584, 2
  %7586 = zext i1 %7585 to i8
  store i8 %7586, i8* %43, align 1
  %7587 = sext i32 %7560 to i64
  store i64 %7587, i64* %RDI.i3116, align 8
  %7588 = shl nsw i64 %7587, 3
  %7589 = add i64 %7550, %7588
  %7590 = load i64, i64* %RAX.i893, align 8
  %7591 = add i64 %7433, 101
  store i64 %7591, i64* %3, align 8
  %7592 = inttoptr i64 %7589 to i64*
  store i64 %7590, i64* %7592, align 8
  %7593 = load i64, i64* %RBP.i, align 8
  %7594 = add i64 %7593, -112
  %7595 = load i64, i64* %3, align 8
  %7596 = add i64 %7595, 4
  store i64 %7596, i64* %3, align 8
  %7597 = inttoptr i64 %7594 to i64*
  %7598 = load i64, i64* %7597, align 8
  store i64 %7598, i64* %RAX.i893, align 8
  %7599 = add i64 %7593, -12
  %7600 = add i64 %7595, 8
  store i64 %7600, i64* %3, align 8
  %7601 = inttoptr i64 %7599 to i32*
  %7602 = load i32, i32* %7601, align 4
  %7603 = sext i32 %7602 to i64
  store i64 %7603, i64* %RDX.i1708, align 8
  %7604 = shl nsw i64 %7603, 3
  %7605 = add i64 %7604, %7598
  %7606 = add i64 %7595, 12
  store i64 %7606, i64* %3, align 8
  %7607 = inttoptr i64 %7605 to i64*
  %7608 = load i64, i64* %7607, align 8
  store i64 %7608, i64* %RAX.i893, align 8
  %7609 = add i64 %7593, -16
  %7610 = add i64 %7595, 16
  store i64 %7610, i64* %3, align 8
  %7611 = inttoptr i64 %7609 to i32*
  %7612 = load i32, i32* %7611, align 4
  %7613 = sext i32 %7612 to i64
  store i64 %7613, i64* %RDX.i1708, align 8
  %7614 = shl nsw i64 %7613, 3
  %7615 = add i64 %7614, %7608
  %7616 = add i64 %7595, 20
  store i64 %7616, i64* %3, align 8
  %7617 = inttoptr i64 %7615 to i64*
  %7618 = load i64, i64* %7617, align 8
  store i64 %7618, i64* %RAX.i893, align 8
  %7619 = add i64 %7618, 8
  %7620 = add i64 %7595, 24
  store i64 %7620, i64* %3, align 8
  %7621 = inttoptr i64 %7619 to i64*
  %7622 = load i64, i64* %7621, align 8
  store i64 %7622, i64* %RAX.i893, align 8
  %7623 = add i64 %7595, 27
  store i64 %7623, i64* %3, align 8
  %7624 = inttoptr i64 %7622 to i64*
  %7625 = load i64, i64* %7624, align 8
  store i64 %7625, i64* %RAX.i893, align 8
  %7626 = add i64 %7593, -56
  %7627 = add i64 %7595, 31
  store i64 %7627, i64* %3, align 8
  %7628 = inttoptr i64 %7626 to i64*
  %7629 = load i64, i64* %7628, align 8
  store i64 %7629, i64* %RDX.i1708, align 8
  %7630 = add i64 %7595, 34
  store i64 %7630, i64* %3, align 8
  %7631 = load i32, i32* %7601, align 4
  %7632 = zext i32 %7631 to i64
  store i64 %7632, i64* %RSI.i4020.pre-phi, align 8
  %7633 = add i64 %7593, -232
  %7634 = add i64 %7595, 41
  store i64 %7634, i64* %3, align 8
  %7635 = inttoptr i64 %7633 to i64*
  store i64 %7625, i64* %7635, align 8
  %7636 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %7637 = zext i32 %7636 to i64
  %7638 = load i64, i64* %3, align 8
  store i64 %7637, i64* %RAX.i893, align 8
  %7639 = load i64, i64* %RBP.i, align 8
  %7640 = add i64 %7639, -240
  %7641 = load i64, i64* %RDX.i1708, align 8
  %7642 = add i64 %7638, 9
  store i64 %7642, i64* %3, align 8
  %7643 = inttoptr i64 %7640 to i64*
  store i64 %7641, i64* %7643, align 8
  %7644 = load i64, i64* %3, align 8
  %7645 = load i32, i32* %EAX.i4054.pre-phi, align 8
  %7646 = sext i32 %7645 to i64
  %7647 = lshr i64 %7646, 32
  store i64 %7647, i64* %2568, align 8
  %7648 = load i32, i32* %ECX.i3327, align 4
  %7649 = add i64 %7644, 3
  store i64 %7649, i64* %3, align 8
  %7650 = zext i32 %7645 to i64
  %7651 = sext i32 %7648 to i64
  %7652 = shl nuw i64 %7647, 32
  %7653 = or i64 %7652, %7650
  %7654 = sdiv i64 %7653, %7651
  %7655 = shl i64 %7654, 32
  %7656 = ashr exact i64 %7655, 32
  %7657 = icmp eq i64 %7654, %7656
  br i1 %7657, label %7660, label %7658

; <label>:7658:                                   ; preds = %block_.L_48f07d
  %7659 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %7649, %struct.Memory* %7196)
  %.pre211 = load i64, i64* %3, align 8
  %.pre212 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__ecx.exit1303

; <label>:7660:                                   ; preds = %block_.L_48f07d
  %7661 = srem i64 %7653, %7651
  %7662 = and i64 %7654, 4294967295
  store i64 %7662, i64* %RAX.i893, align 8
  %7663 = and i64 %7661, 4294967295
  store i64 %7663, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %7664 = trunc i64 %7654 to i32
  br label %routine_idivl__ecx.exit1303

routine_idivl__ecx.exit1303:                      ; preds = %7660, %7658
  %7665 = phi i32 [ %.pre212, %7658 ], [ %7664, %7660 ]
  %7666 = phi i64 [ %.pre211, %7658 ], [ %7649, %7660 ]
  %7667 = phi %struct.Memory* [ %7659, %7658 ], [ %7196, %7660 ]
  %7668 = load i64, i64* %RBP.i, align 8
  %7669 = add i64 %7668, -16
  %7670 = add i64 %7666, 3
  store i64 %7670, i64* %3, align 8
  %7671 = inttoptr i64 %7669 to i32*
  %7672 = load i32, i32* %7671, align 4
  %7673 = zext i32 %7672 to i64
  store i64 %7673, i64* %RSI.i4020.pre-phi, align 8
  %7674 = add i64 %7668, -244
  %7675 = add i64 %7666, 9
  store i64 %7675, i64* %3, align 8
  %7676 = inttoptr i64 %7674 to i32*
  store i32 %7665, i32* %7676, align 4
  %7677 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %7678 = zext i32 %7677 to i64
  %7679 = load i64, i64* %3, align 8
  store i64 %7678, i64* %RAX.i893, align 8
  %7680 = sext i32 %7677 to i64
  %7681 = lshr i64 %7680, 32
  store i64 %7681, i64* %2568, align 8
  %7682 = load i32, i32* %ECX.i3327, align 4
  %7683 = add i64 %7679, 5
  store i64 %7683, i64* %3, align 8
  %7684 = sext i32 %7682 to i64
  %7685 = shl nuw i64 %7681, 32
  %7686 = or i64 %7685, %7678
  %7687 = sdiv i64 %7686, %7684
  %7688 = shl i64 %7687, 32
  %7689 = ashr exact i64 %7688, 32
  %7690 = icmp eq i64 %7687, %7689
  br i1 %7690, label %7693, label %7691

; <label>:7691:                                   ; preds = %routine_idivl__ecx.exit1303
  %7692 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %7683, %struct.Memory* %7667)
  %.pre213 = load i64, i64* %RAX.i893, align 8
  %.pre214 = load i64, i64* %3, align 8
  br label %routine_idivl__ecx.exit1288

; <label>:7693:                                   ; preds = %routine_idivl__ecx.exit1303
  %7694 = srem i64 %7686, %7684
  %7695 = and i64 %7687, 4294967295
  store i64 %7695, i64* %RAX.i893, align 8
  %7696 = and i64 %7694, 4294967295
  store i64 %7696, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__ecx.exit1288

routine_idivl__ecx.exit1288:                      ; preds = %7693, %7691
  %7697 = phi i64 [ %.pre214, %7691 ], [ %7683, %7693 ]
  %7698 = phi i64 [ %.pre213, %7691 ], [ %7695, %7693 ]
  %7699 = phi %struct.Memory* [ %7692, %7691 ], [ %7667, %7693 ]
  %7700 = trunc i64 %7698 to i32
  %7701 = shl i32 %7700, 1
  %7702 = icmp slt i32 %7700, 0
  %7703 = icmp slt i32 %7701, 0
  %7704 = xor i1 %7702, %7703
  %7705 = zext i32 %7701 to i64
  store i64 %7705, i64* %RAX.i893, align 8
  %.lobit105 = lshr i32 %7700, 31
  %7706 = trunc i32 %.lobit105 to i8
  store i8 %7706, i8* %19, align 1
  %7707 = and i32 %7701, 254
  %7708 = tail call i32 @llvm.ctpop.i32(i32 %7707)
  %7709 = trunc i32 %7708 to i8
  %7710 = and i8 %7709, 1
  %7711 = xor i8 %7710, 1
  store i8 %7711, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %7712 = icmp eq i32 %7701, 0
  %7713 = zext i1 %7712 to i8
  store i8 %7713, i8* %34, align 1
  %7714 = lshr i32 %7700, 30
  %7715 = trunc i32 %7714 to i8
  %7716 = and i8 %7715, 1
  store i8 %7716, i8* %37, align 1
  %7717 = zext i1 %7704 to i8
  store i8 %7717, i8* %43, align 1
  %7718 = load i64, i64* %RBP.i, align 8
  %7719 = add i64 %7718, -244
  %7720 = add i64 %7697, 8
  store i64 %7720, i64* %3, align 8
  %7721 = inttoptr i64 %7719 to i32*
  %7722 = load i32, i32* %7721, align 4
  %7723 = add i32 %7701, %7722
  %7724 = zext i32 %7723 to i64
  store i64 %7724, i64* %RSI.i4020.pre-phi, align 8
  %7725 = icmp ult i32 %7723, %7722
  %7726 = icmp ult i32 %7723, %7701
  %7727 = or i1 %7725, %7726
  %7728 = zext i1 %7727 to i8
  store i8 %7728, i8* %19, align 1
  %7729 = and i32 %7723, 255
  %7730 = tail call i32 @llvm.ctpop.i32(i32 %7729)
  %7731 = trunc i32 %7730 to i8
  %7732 = and i8 %7731, 1
  %7733 = xor i8 %7732, 1
  store i8 %7733, i8* %26, align 1
  %7734 = xor i32 %7701, %7722
  %7735 = xor i32 %7734, %7723
  %7736 = lshr i32 %7735, 4
  %7737 = trunc i32 %7736 to i8
  %7738 = and i8 %7737, 1
  store i8 %7738, i8* %31, align 1
  %7739 = icmp eq i32 %7723, 0
  %7740 = zext i1 %7739 to i8
  store i8 %7740, i8* %34, align 1
  %7741 = lshr i32 %7723, 31
  %7742 = trunc i32 %7741 to i8
  store i8 %7742, i8* %37, align 1
  %7743 = lshr i32 %7722, 31
  %7744 = lshr i32 %7700, 30
  %7745 = and i32 %7744, 1
  %7746 = xor i32 %7741, %7743
  %7747 = xor i32 %7741, %7745
  %7748 = add nuw nsw i32 %7746, %7747
  %7749 = icmp eq i32 %7748, 2
  %7750 = zext i1 %7749 to i8
  store i8 %7750, i8* %43, align 1
  %7751 = sext i32 %7723 to i64
  store i64 %7751, i64* %RDI.i3116, align 8
  %7752 = add i64 %7718, -240
  %7753 = add i64 %7697, 20
  store i64 %7753, i64* %3, align 8
  %7754 = inttoptr i64 %7752 to i64*
  %7755 = load i64, i64* %7754, align 8
  store i64 %7755, i64* %R8.i3094, align 8
  %7756 = shl nsw i64 %7751, 2
  %7757 = add i64 %7755, 472
  %7758 = add i64 %7757, %7756
  %7759 = add i64 %7697, 28
  store i64 %7759, i64* %3, align 8
  %7760 = inttoptr i64 %7758 to i32*
  %7761 = load i32, i32* %7760, align 4
  %7762 = sext i32 %7761 to i64
  store i64 %7762, i64* %RDI.i3116, align 8
  %7763 = add i64 %7718, -232
  %7764 = add i64 %7697, 35
  store i64 %7764, i64* %3, align 8
  %7765 = inttoptr i64 %7763 to i64*
  %7766 = load i64, i64* %7765, align 8
  store i64 %7766, i64* %R9.i2396, align 8
  %7767 = shl nsw i64 %7762, 3
  %7768 = add i64 %7767, %7766
  %7769 = add i64 %7697, 39
  store i64 %7769, i64* %3, align 8
  %7770 = inttoptr i64 %7768 to i64*
  %7771 = load i64, i64* %7770, align 8
  store i64 %7771, i64* %RDI.i3116, align 8
  %7772 = add i64 %7697, 43
  store i64 %7772, i64* %3, align 8
  %7773 = inttoptr i64 %7771 to i16*
  %7774 = load i16, i16* %7773, align 2
  store i16 %7774, i16* %R10W.i2642, align 2
  %7775 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %7775, i64* %RDI.i3116, align 8
  %7776 = add i64 %7775, 6504
  %7777 = add i64 %7697, 58
  store i64 %7777, i64* %3, align 8
  %7778 = inttoptr i64 %7776 to i64*
  %7779 = load i64, i64* %7778, align 8
  store i64 %7779, i64* %RDI.i3116, align 8
  %7780 = add i64 %7779, 8
  %7781 = add i64 %7697, 62
  store i64 %7781, i64* %3, align 8
  %7782 = inttoptr i64 %7780 to i64*
  %7783 = load i64, i64* %7782, align 8
  store i64 %7783, i64* %RDI.i3116, align 8
  %7784 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %7784, i64* %R11.i2222, align 8
  %7785 = add i64 %7784, 144
  %7786 = add i64 %7697, 77
  store i64 %7786, i64* %3, align 8
  %7787 = inttoptr i64 %7785 to i32*
  %7788 = load i32, i32* %7787, align 4
  %7789 = zext i32 %7788 to i64
  store i64 %7789, i64* %RAX.i893, align 8
  %7790 = load i64, i64* %RBP.i, align 8
  %7791 = add i64 %7790, -12
  %7792 = add i64 %7697, 80
  store i64 %7792, i64* %3, align 8
  %7793 = inttoptr i64 %7791 to i32*
  %7794 = load i32, i32* %7793, align 4
  %7795 = add i32 %7794, %7788
  %7796 = zext i32 %7795 to i64
  store i64 %7796, i64* %RAX.i893, align 8
  %7797 = icmp ult i32 %7795, %7788
  %7798 = icmp ult i32 %7795, %7794
  %7799 = or i1 %7797, %7798
  %7800 = zext i1 %7799 to i8
  store i8 %7800, i8* %19, align 1
  %7801 = and i32 %7795, 255
  %7802 = tail call i32 @llvm.ctpop.i32(i32 %7801)
  %7803 = trunc i32 %7802 to i8
  %7804 = and i8 %7803, 1
  %7805 = xor i8 %7804, 1
  store i8 %7805, i8* %26, align 1
  %7806 = xor i32 %7794, %7788
  %7807 = xor i32 %7806, %7795
  %7808 = lshr i32 %7807, 4
  %7809 = trunc i32 %7808 to i8
  %7810 = and i8 %7809, 1
  store i8 %7810, i8* %31, align 1
  %7811 = icmp eq i32 %7795, 0
  %7812 = zext i1 %7811 to i8
  store i8 %7812, i8* %34, align 1
  %7813 = lshr i32 %7795, 31
  %7814 = trunc i32 %7813 to i8
  store i8 %7814, i8* %37, align 1
  %7815 = lshr i32 %7788, 31
  %7816 = lshr i32 %7794, 31
  %7817 = xor i32 %7813, %7815
  %7818 = xor i32 %7813, %7816
  %7819 = add nuw nsw i32 %7817, %7818
  %7820 = icmp eq i32 %7819, 2
  %7821 = zext i1 %7820 to i8
  store i8 %7821, i8* %43, align 1
  %7822 = sext i32 %7795 to i64
  store i64 %7822, i64* %R11.i2222, align 8
  %7823 = shl nsw i64 %7822, 3
  %7824 = add i64 %7783, %7823
  %7825 = add i64 %7697, 87
  store i64 %7825, i64* %3, align 8
  %7826 = inttoptr i64 %7824 to i64*
  %7827 = load i64, i64* %7826, align 8
  store i64 %7827, i64* %RDI.i3116, align 8
  store i64 %7784, i64* %R11.i2222, align 8
  %7828 = add i64 %7784, 148
  %7829 = add i64 %7697, 102
  store i64 %7829, i64* %3, align 8
  %7830 = inttoptr i64 %7828 to i32*
  %7831 = load i32, i32* %7830, align 4
  %7832 = zext i32 %7831 to i64
  store i64 %7832, i64* %RAX.i893, align 8
  %7833 = add i64 %7790, -16
  %7834 = add i64 %7697, 105
  store i64 %7834, i64* %3, align 8
  %7835 = inttoptr i64 %7833 to i32*
  %7836 = load i32, i32* %7835, align 4
  %7837 = add i32 %7836, %7831
  %7838 = zext i32 %7837 to i64
  store i64 %7838, i64* %RAX.i893, align 8
  %7839 = icmp ult i32 %7837, %7831
  %7840 = icmp ult i32 %7837, %7836
  %7841 = or i1 %7839, %7840
  %7842 = zext i1 %7841 to i8
  store i8 %7842, i8* %19, align 1
  %7843 = and i32 %7837, 255
  %7844 = tail call i32 @llvm.ctpop.i32(i32 %7843)
  %7845 = trunc i32 %7844 to i8
  %7846 = and i8 %7845, 1
  %7847 = xor i8 %7846, 1
  store i8 %7847, i8* %26, align 1
  %7848 = xor i32 %7836, %7831
  %7849 = xor i32 %7848, %7837
  %7850 = lshr i32 %7849, 4
  %7851 = trunc i32 %7850 to i8
  %7852 = and i8 %7851, 1
  store i8 %7852, i8* %31, align 1
  %7853 = icmp eq i32 %7837, 0
  %7854 = zext i1 %7853 to i8
  store i8 %7854, i8* %34, align 1
  %7855 = lshr i32 %7837, 31
  %7856 = trunc i32 %7855 to i8
  store i8 %7856, i8* %37, align 1
  %7857 = lshr i32 %7831, 31
  %7858 = lshr i32 %7836, 31
  %7859 = xor i32 %7855, %7857
  %7860 = xor i32 %7855, %7858
  %7861 = add nuw nsw i32 %7859, %7860
  %7862 = icmp eq i32 %7861, 2
  %7863 = zext i1 %7862 to i8
  store i8 %7863, i8* %43, align 1
  %7864 = sext i32 %7837 to i64
  store i64 %7864, i64* %R11.i2222, align 8
  %7865 = shl nsw i64 %7864, 3
  %7866 = add i64 %7827, %7865
  %7867 = add i64 %7697, 112
  store i64 %7867, i64* %3, align 8
  %7868 = inttoptr i64 %7866 to i64*
  %7869 = load i64, i64* %7868, align 8
  store i64 %7869, i64* %RDI.i3116, align 8
  %7870 = load i16, i16* %R10W.i2642, align 2
  %7871 = add i64 %7697, 116
  store i64 %7871, i64* %3, align 8
  %7872 = inttoptr i64 %7869 to i16*
  store i16 %7870, i16* %7872, align 2
  %7873 = load i64, i64* %RBP.i, align 8
  %7874 = add i64 %7873, -112
  %7875 = load i64, i64* %3, align 8
  %7876 = add i64 %7875, 4
  store i64 %7876, i64* %3, align 8
  %7877 = inttoptr i64 %7874 to i64*
  %7878 = load i64, i64* %7877, align 8
  store i64 %7878, i64* %RDI.i3116, align 8
  %7879 = add i64 %7873, -12
  %7880 = add i64 %7875, 8
  store i64 %7880, i64* %3, align 8
  %7881 = inttoptr i64 %7879 to i32*
  %7882 = load i32, i32* %7881, align 4
  %7883 = sext i32 %7882 to i64
  store i64 %7883, i64* %R11.i2222, align 8
  %7884 = shl nsw i64 %7883, 3
  %7885 = add i64 %7884, %7878
  %7886 = add i64 %7875, 12
  store i64 %7886, i64* %3, align 8
  %7887 = inttoptr i64 %7885 to i64*
  %7888 = load i64, i64* %7887, align 8
  store i64 %7888, i64* %RDI.i3116, align 8
  %7889 = add i64 %7873, -16
  %7890 = add i64 %7875, 16
  store i64 %7890, i64* %3, align 8
  %7891 = inttoptr i64 %7889 to i32*
  %7892 = load i32, i32* %7891, align 4
  %7893 = sext i32 %7892 to i64
  store i64 %7893, i64* %R11.i2222, align 8
  %7894 = shl nsw i64 %7893, 3
  %7895 = add i64 %7894, %7888
  %7896 = add i64 %7875, 20
  store i64 %7896, i64* %3, align 8
  %7897 = inttoptr i64 %7895 to i64*
  %7898 = load i64, i64* %7897, align 8
  store i64 %7898, i64* %RDI.i3116, align 8
  %7899 = add i64 %7898, 8
  %7900 = add i64 %7875, 24
  store i64 %7900, i64* %3, align 8
  %7901 = inttoptr i64 %7899 to i64*
  %7902 = load i64, i64* %7901, align 8
  store i64 %7902, i64* %RDI.i3116, align 8
  %7903 = add i64 %7875, 27
  store i64 %7903, i64* %3, align 8
  %7904 = inttoptr i64 %7902 to i64*
  %7905 = load i64, i64* %7904, align 8
  store i64 %7905, i64* %RDI.i3116, align 8
  %7906 = add i64 %7873, -56
  %7907 = add i64 %7875, 31
  store i64 %7907, i64* %3, align 8
  %7908 = inttoptr i64 %7906 to i64*
  %7909 = load i64, i64* %7908, align 8
  store i64 %7909, i64* %R11.i2222, align 8
  %7910 = add i64 %7875, 34
  store i64 %7910, i64* %3, align 8
  %7911 = load i32, i32* %7881, align 4
  %7912 = zext i32 %7911 to i64
  store i64 %7912, i64* %RAX.i893, align 8
  %7913 = sext i32 %7911 to i64
  %7914 = lshr i64 %7913, 32
  store i64 %7914, i64* %2568, align 8
  %7915 = load i32, i32* %ECX.i3327, align 4
  %7916 = add i64 %7875, 37
  store i64 %7916, i64* %3, align 8
  %7917 = sext i32 %7915 to i64
  %7918 = shl nuw i64 %7914, 32
  %7919 = or i64 %7918, %7912
  %7920 = sdiv i64 %7919, %7917
  %7921 = shl i64 %7920, 32
  %7922 = ashr exact i64 %7921, 32
  %7923 = icmp eq i64 %7920, %7922
  br i1 %7923, label %7926, label %7924

; <label>:7924:                                   ; preds = %routine_idivl__ecx.exit1288
  %7925 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %7916, %struct.Memory* %7699)
  %.pre215 = load i64, i64* %RBP.i, align 8
  %.pre216 = load i64, i64* %3, align 8
  %.pre217 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__ecx.exit1195

; <label>:7926:                                   ; preds = %routine_idivl__ecx.exit1288
  %7927 = srem i64 %7919, %7917
  %7928 = and i64 %7920, 4294967295
  store i64 %7928, i64* %RAX.i893, align 8
  %7929 = and i64 %7927, 4294967295
  store i64 %7929, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %7930 = trunc i64 %7920 to i32
  br label %routine_idivl__ecx.exit1195

routine_idivl__ecx.exit1195:                      ; preds = %7926, %7924
  %7931 = phi i32 [ %.pre217, %7924 ], [ %7930, %7926 ]
  %7932 = phi i64 [ %.pre216, %7924 ], [ %7916, %7926 ]
  %7933 = phi i64 [ %.pre215, %7924 ], [ %7873, %7926 ]
  %7934 = phi %struct.Memory* [ %7925, %7924 ], [ %7699, %7926 ]
  %7935 = add i64 %7933, -16
  %7936 = add i64 %7932, 3
  store i64 %7936, i64* %3, align 8
  %7937 = inttoptr i64 %7935 to i32*
  %7938 = load i32, i32* %7937, align 4
  %7939 = zext i32 %7938 to i64
  store i64 %7939, i64* %RSI.i4020.pre-phi, align 8
  %7940 = add i64 %7933, -248
  %7941 = add i64 %7932, 9
  store i64 %7941, i64* %3, align 8
  %7942 = inttoptr i64 %7940 to i32*
  store i32 %7931, i32* %7942, align 4
  %7943 = load i32, i32* %ESI.i4013.pre-phi, align 4
  %7944 = zext i32 %7943 to i64
  %7945 = load i64, i64* %3, align 8
  store i64 %7944, i64* %RAX.i893, align 8
  %7946 = sext i32 %7943 to i64
  %7947 = lshr i64 %7946, 32
  store i64 %7947, i64* %2568, align 8
  %7948 = load i32, i32* %ECX.i3327, align 4
  %7949 = add i64 %7945, 5
  store i64 %7949, i64* %3, align 8
  %7950 = sext i32 %7948 to i64
  %7951 = shl nuw i64 %7947, 32
  %7952 = or i64 %7951, %7944
  %7953 = sdiv i64 %7952, %7950
  %7954 = shl i64 %7953, 32
  %7955 = ashr exact i64 %7954, 32
  %7956 = icmp eq i64 %7953, %7955
  br i1 %7956, label %7959, label %7957

; <label>:7957:                                   ; preds = %routine_idivl__ecx.exit1195
  %7958 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %7949, %struct.Memory* %7934)
  %.pre218 = load i64, i64* %RAX.i893, align 8
  %.pre219 = load i64, i64* %3, align 8
  br label %routine_idivl__ecx.exit

; <label>:7959:                                   ; preds = %routine_idivl__ecx.exit1195
  %7960 = srem i64 %7952, %7950
  %7961 = and i64 %7953, 4294967295
  store i64 %7961, i64* %RAX.i893, align 8
  %7962 = and i64 %7960, 4294967295
  store i64 %7962, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__ecx.exit

routine_idivl__ecx.exit:                          ; preds = %7959, %7957
  %7963 = phi i64 [ %.pre219, %7957 ], [ %7949, %7959 ]
  %7964 = phi i64 [ %.pre218, %7957 ], [ %7961, %7959 ]
  %7965 = phi %struct.Memory* [ %7958, %7957 ], [ %7934, %7959 ]
  %7966 = trunc i64 %7964 to i32
  %7967 = shl i32 %7966, 1
  %7968 = icmp slt i32 %7966, 0
  %7969 = icmp slt i32 %7967, 0
  %7970 = xor i1 %7968, %7969
  %7971 = zext i32 %7967 to i64
  store i64 %7971, i64* %RAX.i893, align 8
  %.lobit106 = lshr i32 %7966, 31
  %7972 = trunc i32 %.lobit106 to i8
  store i8 %7972, i8* %19, align 1
  %7973 = and i32 %7967, 254
  %7974 = tail call i32 @llvm.ctpop.i32(i32 %7973)
  %7975 = trunc i32 %7974 to i8
  %7976 = and i8 %7975, 1
  %7977 = xor i8 %7976, 1
  store i8 %7977, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %7978 = icmp eq i32 %7967, 0
  %7979 = zext i1 %7978 to i8
  store i8 %7979, i8* %34, align 1
  %7980 = lshr i32 %7966, 30
  %7981 = trunc i32 %7980 to i8
  %7982 = and i8 %7981, 1
  store i8 %7982, i8* %37, align 1
  %7983 = zext i1 %7970 to i8
  store i8 %7983, i8* %43, align 1
  %7984 = load i64, i64* %RBP.i, align 8
  %7985 = add i64 %7984, -248
  %7986 = add i64 %7963, 8
  store i64 %7986, i64* %3, align 8
  %7987 = inttoptr i64 %7985 to i32*
  %7988 = load i32, i32* %7987, align 4
  %7989 = add i32 %7967, %7988
  %7990 = zext i32 %7989 to i64
  store i64 %7990, i64* %RCX.i1197, align 8
  %7991 = icmp ult i32 %7989, %7988
  %7992 = icmp ult i32 %7989, %7967
  %7993 = or i1 %7991, %7992
  %7994 = zext i1 %7993 to i8
  store i8 %7994, i8* %19, align 1
  %7995 = and i32 %7989, 255
  %7996 = tail call i32 @llvm.ctpop.i32(i32 %7995)
  %7997 = trunc i32 %7996 to i8
  %7998 = and i8 %7997, 1
  %7999 = xor i8 %7998, 1
  store i8 %7999, i8* %26, align 1
  %8000 = xor i32 %7967, %7988
  %8001 = xor i32 %8000, %7989
  %8002 = lshr i32 %8001, 4
  %8003 = trunc i32 %8002 to i8
  %8004 = and i8 %8003, 1
  store i8 %8004, i8* %31, align 1
  %8005 = icmp eq i32 %7989, 0
  %8006 = zext i1 %8005 to i8
  store i8 %8006, i8* %34, align 1
  %8007 = lshr i32 %7989, 31
  %8008 = trunc i32 %8007 to i8
  store i8 %8008, i8* %37, align 1
  %8009 = lshr i32 %7988, 31
  %8010 = lshr i32 %7966, 30
  %8011 = and i32 %8010, 1
  %8012 = xor i32 %8007, %8009
  %8013 = xor i32 %8007, %8011
  %8014 = add nuw nsw i32 %8012, %8013
  %8015 = icmp eq i32 %8014, 2
  %8016 = zext i1 %8015 to i8
  store i8 %8016, i8* %43, align 1
  %8017 = sext i32 %7989 to i64
  store i64 %8017, i64* %RBX.i772, align 8
  %8018 = load i64, i64* %R11.i2222, align 8
  %8019 = shl nsw i64 %8017, 2
  %8020 = add nsw i64 %8019, 472
  %8021 = add i64 %8020, %8018
  %8022 = add i64 %7963, 21
  store i64 %8022, i64* %3, align 8
  %8023 = inttoptr i64 %8021 to i32*
  %8024 = load i32, i32* %8023, align 4
  %8025 = sext i32 %8024 to i64
  store i64 %8025, i64* %R11.i2222, align 8
  %8026 = load i64, i64* %RDI.i3116, align 8
  %8027 = shl nsw i64 %8025, 3
  %8028 = add i64 %8027, %8026
  %8029 = add i64 %7963, 25
  store i64 %8029, i64* %3, align 8
  %8030 = inttoptr i64 %8028 to i64*
  %8031 = load i64, i64* %8030, align 8
  store i64 %8031, i64* %RDI.i3116, align 8
  %8032 = add i64 %8031, 2
  %8033 = add i64 %7963, 30
  store i64 %8033, i64* %3, align 8
  %8034 = inttoptr i64 %8032 to i16*
  %8035 = load i16, i16* %8034, align 2
  store i16 %8035, i16* %R10W.i2642, align 2
  %8036 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %8036, i64* %RDI.i3116, align 8
  %8037 = add i64 %8036, 6504
  %8038 = add i64 %7963, 45
  store i64 %8038, i64* %3, align 8
  %8039 = inttoptr i64 %8037 to i64*
  %8040 = load i64, i64* %8039, align 8
  store i64 %8040, i64* %RDI.i3116, align 8
  %8041 = add i64 %8040, 8
  %8042 = add i64 %7963, 49
  store i64 %8042, i64* %3, align 8
  %8043 = inttoptr i64 %8041 to i64*
  %8044 = load i64, i64* %8043, align 8
  store i64 %8044, i64* %RDI.i3116, align 8
  %8045 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8045, i64* %R11.i2222, align 8
  %8046 = add i64 %8045, 144
  %8047 = add i64 %7963, 64
  store i64 %8047, i64* %3, align 8
  %8048 = inttoptr i64 %8046 to i32*
  %8049 = load i32, i32* %8048, align 4
  %8050 = zext i32 %8049 to i64
  store i64 %8050, i64* %RAX.i893, align 8
  %8051 = load i64, i64* %RBP.i, align 8
  %8052 = add i64 %8051, -12
  %8053 = add i64 %7963, 67
  store i64 %8053, i64* %3, align 8
  %8054 = inttoptr i64 %8052 to i32*
  %8055 = load i32, i32* %8054, align 4
  %8056 = add i32 %8055, %8049
  %8057 = zext i32 %8056 to i64
  store i64 %8057, i64* %RAX.i893, align 8
  %8058 = icmp ult i32 %8056, %8049
  %8059 = icmp ult i32 %8056, %8055
  %8060 = or i1 %8058, %8059
  %8061 = zext i1 %8060 to i8
  store i8 %8061, i8* %19, align 1
  %8062 = and i32 %8056, 255
  %8063 = tail call i32 @llvm.ctpop.i32(i32 %8062)
  %8064 = trunc i32 %8063 to i8
  %8065 = and i8 %8064, 1
  %8066 = xor i8 %8065, 1
  store i8 %8066, i8* %26, align 1
  %8067 = xor i32 %8055, %8049
  %8068 = xor i32 %8067, %8056
  %8069 = lshr i32 %8068, 4
  %8070 = trunc i32 %8069 to i8
  %8071 = and i8 %8070, 1
  store i8 %8071, i8* %31, align 1
  %8072 = icmp eq i32 %8056, 0
  %8073 = zext i1 %8072 to i8
  store i8 %8073, i8* %34, align 1
  %8074 = lshr i32 %8056, 31
  %8075 = trunc i32 %8074 to i8
  store i8 %8075, i8* %37, align 1
  %8076 = lshr i32 %8049, 31
  %8077 = lshr i32 %8055, 31
  %8078 = xor i32 %8074, %8076
  %8079 = xor i32 %8074, %8077
  %8080 = add nuw nsw i32 %8078, %8079
  %8081 = icmp eq i32 %8080, 2
  %8082 = zext i1 %8081 to i8
  store i8 %8082, i8* %43, align 1
  %8083 = sext i32 %8056 to i64
  store i64 %8083, i64* %R11.i2222, align 8
  %8084 = shl nsw i64 %8083, 3
  %8085 = add i64 %8044, %8084
  %8086 = add i64 %7963, 74
  store i64 %8086, i64* %3, align 8
  %8087 = inttoptr i64 %8085 to i64*
  %8088 = load i64, i64* %8087, align 8
  store i64 %8088, i64* %RDI.i3116, align 8
  store i64 %8045, i64* %R11.i2222, align 8
  %8089 = add i64 %8045, 148
  %8090 = add i64 %7963, 89
  store i64 %8090, i64* %3, align 8
  %8091 = inttoptr i64 %8089 to i32*
  %8092 = load i32, i32* %8091, align 4
  %8093 = zext i32 %8092 to i64
  store i64 %8093, i64* %RAX.i893, align 8
  %8094 = add i64 %8051, -16
  %8095 = add i64 %7963, 92
  store i64 %8095, i64* %3, align 8
  %8096 = inttoptr i64 %8094 to i32*
  %8097 = load i32, i32* %8096, align 4
  %8098 = add i32 %8097, %8092
  %8099 = zext i32 %8098 to i64
  store i64 %8099, i64* %RAX.i893, align 8
  %8100 = icmp ult i32 %8098, %8092
  %8101 = icmp ult i32 %8098, %8097
  %8102 = or i1 %8100, %8101
  %8103 = zext i1 %8102 to i8
  store i8 %8103, i8* %19, align 1
  %8104 = and i32 %8098, 255
  %8105 = tail call i32 @llvm.ctpop.i32(i32 %8104)
  %8106 = trunc i32 %8105 to i8
  %8107 = and i8 %8106, 1
  %8108 = xor i8 %8107, 1
  store i8 %8108, i8* %26, align 1
  %8109 = xor i32 %8097, %8092
  %8110 = xor i32 %8109, %8098
  %8111 = lshr i32 %8110, 4
  %8112 = trunc i32 %8111 to i8
  %8113 = and i8 %8112, 1
  store i8 %8113, i8* %31, align 1
  %8114 = icmp eq i32 %8098, 0
  %8115 = zext i1 %8114 to i8
  store i8 %8115, i8* %34, align 1
  %8116 = lshr i32 %8098, 31
  %8117 = trunc i32 %8116 to i8
  store i8 %8117, i8* %37, align 1
  %8118 = lshr i32 %8092, 31
  %8119 = lshr i32 %8097, 31
  %8120 = xor i32 %8116, %8118
  %8121 = xor i32 %8116, %8119
  %8122 = add nuw nsw i32 %8120, %8121
  %8123 = icmp eq i32 %8122, 2
  %8124 = zext i1 %8123 to i8
  store i8 %8124, i8* %43, align 1
  %8125 = sext i32 %8098 to i64
  store i64 %8125, i64* %R11.i2222, align 8
  %8126 = shl nsw i64 %8125, 3
  %8127 = add i64 %8088, %8126
  %8128 = add i64 %7963, 99
  store i64 %8128, i64* %3, align 8
  %8129 = inttoptr i64 %8127 to i64*
  %8130 = load i64, i64* %8129, align 8
  %8131 = add i64 %8130, 2
  %8132 = load i16, i16* %R10W.i2642, align 2
  %8133 = add i64 %7963, 104
  store i64 %8133, i64* %3, align 8
  %8134 = inttoptr i64 %8131 to i16*
  store i16 %8132, i16* %8134, align 2
  %8135 = load i64, i64* %3, align 8
  %8136 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8136, i64* %RDI.i3116, align 8
  %8137 = add i64 %8136, 72400
  %8138 = add i64 %8135, 15
  store i64 %8138, i64* %3, align 8
  %8139 = inttoptr i64 %8137 to i32*
  %8140 = load i32, i32* %8139, align 4
  store i8 0, i8* %19, align 1
  %8141 = and i32 %8140, 255
  %8142 = tail call i32 @llvm.ctpop.i32(i32 %8141)
  %8143 = trunc i32 %8142 to i8
  %8144 = and i8 %8143, 1
  %8145 = xor i8 %8144, 1
  store i8 %8145, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %8146 = icmp eq i32 %8140, 0
  %8147 = zext i1 %8146 to i8
  store i8 %8147, i8* %34, align 1
  %8148 = lshr i32 %8140, 31
  %8149 = trunc i32 %8148 to i8
  store i8 %8149, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v339 = select i1 %8146, i64 60, i64 21
  %8150 = add i64 %8135, %.v339
  store i64 %8150, i64* %3, align 8
  br i1 %8146, label %block_.L_48f2c7, label %block_48f2a0

block_48f2a0:                                     ; preds = %routine_idivl__ecx.exit
  %8151 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %8152 = add i64 %8151, 3264
  %8153 = lshr i64 %8152, 63
  %8154 = add i64 %8151, 3296
  store i64 %8154, i64* %RAX.i893, align 8
  %8155 = icmp ugt i64 %8152, -33
  %8156 = zext i1 %8155 to i8
  store i8 %8156, i8* %19, align 1
  %8157 = trunc i64 %8154 to i32
  %8158 = and i32 %8157, 255
  %8159 = tail call i32 @llvm.ctpop.i32(i32 %8158)
  %8160 = trunc i32 %8159 to i8
  %8161 = and i8 %8160, 1
  %8162 = xor i8 %8161, 1
  store i8 %8162, i8* %26, align 1
  %8163 = xor i64 %8154, %8152
  %8164 = lshr i64 %8163, 4
  %8165 = trunc i64 %8164 to i8
  %8166 = and i8 %8165, 1
  store i8 %8166, i8* %31, align 1
  %8167 = icmp eq i64 %8154, 0
  %8168 = zext i1 %8167 to i8
  store i8 %8168, i8* %34, align 1
  %8169 = lshr i64 %8154, 63
  %8170 = trunc i64 %8169 to i8
  store i8 %8170, i8* %37, align 1
  %8171 = xor i64 %8169, %8153
  %8172 = add nuw nsw i64 %8171, %8169
  %8173 = icmp eq i64 %8172, 2
  %8174 = zext i1 %8173 to i8
  store i8 %8174, i8* %43, align 1
  %8175 = load i64, i64* %RBP.i, align 8
  %8176 = add i64 %8175, -16
  %8177 = add i64 %8150, 22
  store i64 %8177, i64* %3, align 8
  %8178 = inttoptr i64 %8176 to i32*
  %8179 = load i32, i32* %8178, align 4
  %8180 = sext i32 %8179 to i64
  %8181 = shl nsw i64 %8180, 3
  store i64 %8181, i64* %RCX.i1197, align 8
  %8182 = add i64 %8181, %8154
  store i64 %8182, i64* %RAX.i893, align 8
  %8183 = icmp ult i64 %8182, %8154
  %8184 = icmp ult i64 %8182, %8181
  %8185 = or i1 %8183, %8184
  %8186 = zext i1 %8185 to i8
  store i8 %8186, i8* %19, align 1
  %8187 = trunc i64 %8182 to i32
  %8188 = and i32 %8187, 255
  %8189 = tail call i32 @llvm.ctpop.i32(i32 %8188)
  %8190 = trunc i32 %8189 to i8
  %8191 = and i8 %8190, 1
  %8192 = xor i8 %8191, 1
  store i8 %8192, i8* %26, align 1
  %8193 = xor i64 %8181, %8154
  %8194 = xor i64 %8193, %8182
  %8195 = lshr i64 %8194, 4
  %8196 = trunc i64 %8195 to i8
  %8197 = and i8 %8196, 1
  store i8 %8197, i8* %31, align 1
  %8198 = icmp eq i64 %8182, 0
  %8199 = zext i1 %8198 to i8
  store i8 %8199, i8* %34, align 1
  %8200 = lshr i64 %8182, 63
  %8201 = trunc i64 %8200 to i8
  store i8 %8201, i8* %37, align 1
  %8202 = lshr i64 %8180, 60
  %8203 = and i64 %8202, 1
  %8204 = xor i64 %8200, %8169
  %8205 = xor i64 %8200, %8203
  %8206 = add nuw nsw i64 %8204, %8205
  %8207 = icmp eq i64 %8206, 2
  %8208 = zext i1 %8207 to i8
  store i8 %8208, i8* %43, align 1
  %8209 = add i64 %8175, -12
  %8210 = add i64 %8150, 33
  store i64 %8210, i64* %3, align 8
  %8211 = inttoptr i64 %8209 to i32*
  %8212 = load i32, i32* %8211, align 4
  %8213 = sext i32 %8212 to i64
  store i64 %8213, i64* %RCX.i1197, align 8
  %8214 = shl nsw i64 %8213, 1
  %8215 = add i64 %8214, %8182
  %8216 = add i64 %8150, 39
  store i64 %8216, i64* %3, align 8
  %8217 = inttoptr i64 %8215 to i16*
  store i16 0, i16* %8217, align 2
  %.pre220 = load i64, i64* %3, align 8
  br label %block_.L_48f2c7

block_.L_48f2c7:                                  ; preds = %block_48f2a0, %routine_idivl__ecx.exit
  %8218 = phi i64 [ %.pre220, %block_48f2a0 ], [ %8150, %routine_idivl__ecx.exit ]
  %8219 = add i64 %8218, 799
  br label %block_.L_48f5e6

block_.L_48f2cc:                                  ; preds = %block_48f02d, %routine_idivl__esi.exit, %block_.L_48efd4
  %8220 = phi i64 [ %6586, %block_.L_48efd4 ], [ %7215, %routine_idivl__esi.exit ], [ %7215, %block_48f02d ]
  %8221 = phi i64 [ %7125, %block_.L_48efd4 ], [ %7277, %routine_idivl__esi.exit ], [ %7307, %block_48f02d ]
  %MEMORY.43 = phi %struct.Memory* [ %6567, %block_.L_48efd4 ], [ %7196, %routine_idivl__esi.exit ], [ %7196, %block_48f02d ]
  store i64 2, i64* %RAX.i893, align 8
  store i64 ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64), i64* %RCX.i1197, align 8
  %8222 = add i64 %8220, -16
  %8223 = add i64 %8221, 19
  store i64 %8223, i64* %3, align 8
  %8224 = inttoptr i64 %8222 to i32*
  %8225 = load i32, i32* %8224, align 4
  %8226 = sext i32 %8225 to i64
  %8227 = shl nsw i64 %8226, 3
  store i64 %8227, i64* %RDX.i1708, align 8
  %8228 = add i64 %8227, ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64)
  store i64 %8228, i64* %RSI.i4020.pre-phi, align 8
  %8229 = icmp ult i64 %8228, ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64)
  %8230 = icmp ult i64 %8228, %8227
  %8231 = or i1 %8229, %8230
  %8232 = zext i1 %8231 to i8
  store i8 %8232, i8* %19, align 1
  %8233 = trunc i64 %8228 to i32
  %8234 = and i32 %8233, 248
  %8235 = tail call i32 @llvm.ctpop.i32(i32 %8234)
  %8236 = trunc i32 %8235 to i8
  %8237 = and i8 %8236, 1
  %8238 = xor i8 %8237, 1
  store i8 %8238, i8* %26, align 1
  %8239 = xor i64 %8227, ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64)
  %8240 = xor i64 %8239, %8228
  %8241 = lshr i64 %8240, 4
  %8242 = trunc i64 %8241 to i8
  %8243 = and i8 %8242, 1
  store i8 %8243, i8* %31, align 1
  %8244 = icmp eq i64 %8228, 0
  %8245 = zext i1 %8244 to i8
  store i8 %8245, i8* %34, align 1
  %8246 = lshr i64 %8228, 63
  %8247 = trunc i64 %8246 to i8
  store i8 %8247, i8* %37, align 1
  %8248 = lshr i64 %8226, 60
  %8249 = and i64 %8248, 1
  %8250 = xor i64 %8246, lshr (i64 ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64), i64 63)
  %8251 = xor i64 %8246, %8249
  %8252 = add nuw nsw i64 %8250, %8251
  %8253 = icmp eq i64 %8252, 2
  %8254 = zext i1 %8253 to i8
  store i8 %8254, i8* %43, align 1
  %8255 = add i64 %8220, -12
  %8256 = add i64 %8221, 33
  store i64 %8256, i64* %3, align 8
  %8257 = inttoptr i64 %8255 to i32*
  %8258 = load i32, i32* %8257, align 4
  %8259 = sext i32 %8258 to i64
  store i64 %8259, i64* %RDX.i1708, align 8
  %8260 = shl nsw i64 %8259, 1
  %8261 = add i64 %8260, %8228
  %8262 = add i64 %8221, 37
  store i64 %8262, i64* %3, align 8
  %8263 = inttoptr i64 %8261 to i16*
  %8264 = load i16, i16* %8263, align 2
  store i16 %8264, i16* %DI.i2456, align 2
  %8265 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %8265, i64* %RDX.i1708, align 8
  %8266 = add i64 %8265, 6480
  %8267 = add i64 %8221, 52
  store i64 %8267, i64* %3, align 8
  %8268 = inttoptr i64 %8266 to i64*
  %8269 = load i64, i64* %8268, align 8
  store i64 %8269, i64* %RDX.i1708, align 8
  %8270 = add i64 %8269, 8
  %8271 = add i64 %8221, 56
  store i64 %8271, i64* %3, align 8
  %8272 = inttoptr i64 %8270 to i64*
  %8273 = load i64, i64* %8272, align 8
  store i64 %8273, i64* %RDX.i1708, align 8
  %8274 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8274, i64* %RSI.i4020.pre-phi, align 8
  %8275 = add i64 %8274, 144
  %8276 = add i64 %8221, 71
  store i64 %8276, i64* %3, align 8
  %8277 = inttoptr i64 %8275 to i32*
  %8278 = load i32, i32* %8277, align 4
  %8279 = zext i32 %8278 to i64
  store i64 %8279, i64* %R8.i3094, align 8
  %8280 = load i64, i64* %RBP.i, align 8
  %8281 = add i64 %8280, -12
  %8282 = add i64 %8221, 75
  store i64 %8282, i64* %3, align 8
  %8283 = inttoptr i64 %8281 to i32*
  %8284 = load i32, i32* %8283, align 4
  %8285 = add i32 %8284, %8278
  %8286 = zext i32 %8285 to i64
  store i64 %8286, i64* %R8.i3094, align 8
  %8287 = icmp ult i32 %8285, %8278
  %8288 = icmp ult i32 %8285, %8284
  %8289 = or i1 %8287, %8288
  %8290 = zext i1 %8289 to i8
  store i8 %8290, i8* %19, align 1
  %8291 = and i32 %8285, 255
  %8292 = tail call i32 @llvm.ctpop.i32(i32 %8291)
  %8293 = trunc i32 %8292 to i8
  %8294 = and i8 %8293, 1
  %8295 = xor i8 %8294, 1
  store i8 %8295, i8* %26, align 1
  %8296 = xor i32 %8284, %8278
  %8297 = xor i32 %8296, %8285
  %8298 = lshr i32 %8297, 4
  %8299 = trunc i32 %8298 to i8
  %8300 = and i8 %8299, 1
  store i8 %8300, i8* %31, align 1
  %8301 = icmp eq i32 %8285, 0
  %8302 = zext i1 %8301 to i8
  store i8 %8302, i8* %34, align 1
  %8303 = lshr i32 %8285, 31
  %8304 = trunc i32 %8303 to i8
  store i8 %8304, i8* %37, align 1
  %8305 = lshr i32 %8278, 31
  %8306 = lshr i32 %8284, 31
  %8307 = xor i32 %8303, %8305
  %8308 = xor i32 %8303, %8306
  %8309 = add nuw nsw i32 %8307, %8308
  %8310 = icmp eq i32 %8309, 2
  %8311 = zext i1 %8310 to i8
  store i8 %8311, i8* %43, align 1
  %8312 = sext i32 %8285 to i64
  store i64 %8312, i64* %RSI.i4020.pre-phi, align 8
  %8313 = shl nsw i64 %8312, 3
  %8314 = add i64 %8273, %8313
  %8315 = add i64 %8221, 82
  store i64 %8315, i64* %3, align 8
  %8316 = inttoptr i64 %8314 to i64*
  %8317 = load i64, i64* %8316, align 8
  store i64 %8317, i64* %RDX.i1708, align 8
  store i64 %8274, i64* %RSI.i4020.pre-phi, align 8
  %8318 = add i64 %8274, 148
  %8319 = add i64 %8221, 97
  store i64 %8319, i64* %3, align 8
  %8320 = inttoptr i64 %8318 to i32*
  %8321 = load i32, i32* %8320, align 4
  %8322 = zext i32 %8321 to i64
  store i64 %8322, i64* %R8.i3094, align 8
  %8323 = add i64 %8280, -16
  %8324 = add i64 %8221, 101
  store i64 %8324, i64* %3, align 8
  %8325 = inttoptr i64 %8323 to i32*
  %8326 = load i32, i32* %8325, align 4
  %8327 = add i32 %8326, %8321
  %8328 = zext i32 %8327 to i64
  store i64 %8328, i64* %R8.i3094, align 8
  %8329 = sext i32 %8327 to i64
  store i64 %8329, i64* %RSI.i4020.pre-phi, align 8
  %8330 = shl nsw i64 %8329, 1
  %8331 = add i64 %8317, %8330
  %8332 = load i16, i16* %DI.i2456, align 2
  %8333 = add i64 %8221, 108
  store i64 %8333, i64* %3, align 8
  %8334 = inttoptr i64 %8331 to i16*
  store i16 %8332, i16* %8334, align 2
  %8335 = load i64, i64* %3, align 8
  %8336 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  %8337 = add i64 %8336, 24
  store i64 %8337, i64* %RDX.i1708, align 8
  %8338 = icmp ugt i64 %8336, -25
  %8339 = zext i1 %8338 to i8
  store i8 %8339, i8* %19, align 1
  %8340 = trunc i64 %8337 to i32
  %8341 = and i32 %8340, 255
  %8342 = tail call i32 @llvm.ctpop.i32(i32 %8341)
  %8343 = trunc i32 %8342 to i8
  %8344 = and i8 %8343, 1
  %8345 = xor i8 %8344, 1
  store i8 %8345, i8* %26, align 1
  %8346 = xor i64 %8336, 16
  %8347 = xor i64 %8346, %8337
  %8348 = lshr i64 %8347, 4
  %8349 = trunc i64 %8348 to i8
  %8350 = and i8 %8349, 1
  store i8 %8350, i8* %31, align 1
  %8351 = icmp eq i64 %8337, 0
  %8352 = zext i1 %8351 to i8
  store i8 %8352, i8* %34, align 1
  %8353 = lshr i64 %8337, 63
  %8354 = trunc i64 %8353 to i8
  store i8 %8354, i8* %37, align 1
  %8355 = lshr i64 %8336, 63
  %8356 = xor i64 %8353, %8355
  %8357 = add nuw nsw i64 %8356, %8353
  %8358 = icmp eq i64 %8357, 2
  %8359 = zext i1 %8358 to i8
  store i8 %8359, i8* %43, align 1
  %8360 = load i64, i64* %RBP.i, align 8
  %8361 = add i64 %8360, -92
  %8362 = add i64 %8335, 16
  store i64 %8362, i64* %3, align 8
  %8363 = inttoptr i64 %8361 to i32*
  %8364 = load i32, i32* %8363, align 4
  %8365 = add i32 %8364, 1
  %8366 = zext i32 %8365 to i64
  store i64 %8366, i64* %R8.i3094, align 8
  %8367 = sext i32 %8365 to i64
  %8368 = mul nsw i64 %8367, 264
  %8369 = lshr i64 %8368, 63
  %8370 = load i64, i64* %RDX.i1708, align 8
  %8371 = add i64 %8368, %8370
  store i64 %8371, i64* %RDX.i1708, align 8
  %8372 = icmp ult i64 %8371, %8370
  %8373 = icmp ult i64 %8371, %8368
  %8374 = or i1 %8372, %8373
  %8375 = zext i1 %8374 to i8
  store i8 %8375, i8* %19, align 1
  %8376 = trunc i64 %8371 to i32
  %8377 = and i32 %8376, 255
  %8378 = tail call i32 @llvm.ctpop.i32(i32 %8377)
  %8379 = trunc i32 %8378 to i8
  %8380 = and i8 %8379, 1
  %8381 = xor i8 %8380, 1
  store i8 %8381, i8* %26, align 1
  %8382 = xor i64 %8368, %8370
  %8383 = xor i64 %8382, %8371
  %8384 = lshr i64 %8383, 4
  %8385 = trunc i64 %8384 to i8
  %8386 = and i8 %8385, 1
  store i8 %8386, i8* %31, align 1
  %8387 = icmp eq i64 %8371, 0
  %8388 = zext i1 %8387 to i8
  store i8 %8388, i8* %34, align 1
  %8389 = lshr i64 %8371, 63
  %8390 = trunc i64 %8389 to i8
  store i8 %8390, i8* %37, align 1
  %8391 = lshr i64 %8370, 63
  %8392 = xor i64 %8389, %8391
  %8393 = xor i64 %8389, %8369
  %8394 = add nuw nsw i64 %8392, %8393
  %8395 = icmp eq i64 %8394, 2
  %8396 = zext i1 %8395 to i8
  store i8 %8396, i8* %43, align 1
  %8397 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %8397, i64* %RSI.i4020.pre-phi, align 8
  %8398 = add i64 %8397, 6480
  %8399 = add i64 %8335, 48
  store i64 %8399, i64* %3, align 8
  %8400 = inttoptr i64 %8398 to i64*
  %8401 = load i64, i64* %8400, align 8
  store i64 %8401, i64* %RSI.i4020.pre-phi, align 8
  %8402 = add i64 %8401, 8
  %8403 = add i64 %8335, 52
  store i64 %8403, i64* %3, align 8
  %8404 = inttoptr i64 %8402 to i64*
  %8405 = load i64, i64* %8404, align 8
  store i64 %8405, i64* %RSI.i4020.pre-phi, align 8
  %8406 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8406, i64* %R9.i2396, align 8
  %8407 = add i64 %8406, 144
  %8408 = add i64 %8335, 67
  store i64 %8408, i64* %3, align 8
  %8409 = inttoptr i64 %8407 to i32*
  %8410 = load i32, i32* %8409, align 4
  %8411 = zext i32 %8410 to i64
  store i64 %8411, i64* %R8.i3094, align 8
  %8412 = load i64, i64* %RBP.i, align 8
  %8413 = add i64 %8412, -12
  %8414 = add i64 %8335, 71
  store i64 %8414, i64* %3, align 8
  %8415 = inttoptr i64 %8413 to i32*
  %8416 = load i32, i32* %8415, align 4
  %8417 = add i32 %8416, %8410
  %8418 = zext i32 %8417 to i64
  store i64 %8418, i64* %R8.i3094, align 8
  %8419 = icmp ult i32 %8417, %8410
  %8420 = icmp ult i32 %8417, %8416
  %8421 = or i1 %8419, %8420
  %8422 = zext i1 %8421 to i8
  store i8 %8422, i8* %19, align 1
  %8423 = and i32 %8417, 255
  %8424 = tail call i32 @llvm.ctpop.i32(i32 %8423)
  %8425 = trunc i32 %8424 to i8
  %8426 = and i8 %8425, 1
  %8427 = xor i8 %8426, 1
  store i8 %8427, i8* %26, align 1
  %8428 = xor i32 %8416, %8410
  %8429 = xor i32 %8428, %8417
  %8430 = lshr i32 %8429, 4
  %8431 = trunc i32 %8430 to i8
  %8432 = and i8 %8431, 1
  store i8 %8432, i8* %31, align 1
  %8433 = icmp eq i32 %8417, 0
  %8434 = zext i1 %8433 to i8
  store i8 %8434, i8* %34, align 1
  %8435 = lshr i32 %8417, 31
  %8436 = trunc i32 %8435 to i8
  store i8 %8436, i8* %37, align 1
  %8437 = lshr i32 %8410, 31
  %8438 = lshr i32 %8416, 31
  %8439 = xor i32 %8435, %8437
  %8440 = xor i32 %8435, %8438
  %8441 = add nuw nsw i32 %8439, %8440
  %8442 = icmp eq i32 %8441, 2
  %8443 = zext i1 %8442 to i8
  store i8 %8443, i8* %43, align 1
  %8444 = sext i32 %8417 to i64
  store i64 %8444, i64* %R9.i2396, align 8
  %8445 = shl nsw i64 %8444, 3
  %8446 = add i64 %8405, %8445
  %8447 = add i64 %8335, 78
  store i64 %8447, i64* %3, align 8
  %8448 = inttoptr i64 %8446 to i64*
  %8449 = load i64, i64* %8448, align 8
  store i64 %8449, i64* %RSI.i4020.pre-phi, align 8
  store i64 %8406, i64* %R9.i2396, align 8
  %8450 = add i64 %8406, 148
  %8451 = add i64 %8335, 93
  store i64 %8451, i64* %3, align 8
  %8452 = inttoptr i64 %8450 to i32*
  %8453 = load i32, i32* %8452, align 4
  %8454 = zext i32 %8453 to i64
  store i64 %8454, i64* %R8.i3094, align 8
  %8455 = add i64 %8412, -16
  %8456 = add i64 %8335, 97
  store i64 %8456, i64* %3, align 8
  %8457 = inttoptr i64 %8455 to i32*
  %8458 = load i32, i32* %8457, align 4
  %8459 = add i32 %8458, %8453
  %8460 = zext i32 %8459 to i64
  store i64 %8460, i64* %R8.i3094, align 8
  %8461 = icmp ult i32 %8459, %8453
  %8462 = icmp ult i32 %8459, %8458
  %8463 = or i1 %8461, %8462
  %8464 = zext i1 %8463 to i8
  store i8 %8464, i8* %19, align 1
  %8465 = and i32 %8459, 255
  %8466 = tail call i32 @llvm.ctpop.i32(i32 %8465)
  %8467 = trunc i32 %8466 to i8
  %8468 = and i8 %8467, 1
  %8469 = xor i8 %8468, 1
  store i8 %8469, i8* %26, align 1
  %8470 = xor i32 %8458, %8453
  %8471 = xor i32 %8470, %8459
  %8472 = lshr i32 %8471, 4
  %8473 = trunc i32 %8472 to i8
  %8474 = and i8 %8473, 1
  store i8 %8474, i8* %31, align 1
  %8475 = icmp eq i32 %8459, 0
  %8476 = zext i1 %8475 to i8
  store i8 %8476, i8* %34, align 1
  %8477 = lshr i32 %8459, 31
  %8478 = trunc i32 %8477 to i8
  store i8 %8478, i8* %37, align 1
  %8479 = lshr i32 %8453, 31
  %8480 = lshr i32 %8458, 31
  %8481 = xor i32 %8477, %8479
  %8482 = xor i32 %8477, %8480
  %8483 = add nuw nsw i32 %8481, %8482
  %8484 = icmp eq i32 %8483, 2
  %8485 = zext i1 %8484 to i8
  store i8 %8485, i8* %43, align 1
  %8486 = sext i32 %8459 to i64
  store i64 %8486, i64* %R9.i2396, align 8
  %8487 = shl nsw i64 %8486, 1
  %8488 = add i64 %8449, %8487
  %8489 = add i64 %8335, 105
  store i64 %8489, i64* %3, align 8
  %8490 = inttoptr i64 %8488 to i16*
  %8491 = load i16, i16* %8490, align 2
  %8492 = sext i16 %8491 to i64
  store i64 %8492, i64* %RSI.i4020.pre-phi, align 8
  %8493 = load i64, i64* %RDX.i1708, align 8
  %8494 = shl nsw i64 %8492, 3
  %8495 = add i64 %8494, %8493
  %8496 = add i64 %8335, 109
  store i64 %8496, i64* %3, align 8
  %8497 = inttoptr i64 %8495 to i64*
  %8498 = load i64, i64* %8497, align 8
  store i64 %8498, i64* %RDX.i1708, align 8
  %8499 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %8499, i64* %RSI.i4020.pre-phi, align 8
  %8500 = add i64 %8499, 6488
  %8501 = add i64 %8335, 124
  store i64 %8501, i64* %3, align 8
  %8502 = inttoptr i64 %8500 to i64*
  %8503 = load i64, i64* %8502, align 8
  store i64 %8503, i64* %RSI.i4020.pre-phi, align 8
  %8504 = add i64 %8503, 8
  %8505 = add i64 %8335, 128
  store i64 %8505, i64* %3, align 8
  %8506 = inttoptr i64 %8504 to i64*
  %8507 = load i64, i64* %8506, align 8
  store i64 %8507, i64* %RSI.i4020.pre-phi, align 8
  %8508 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8508, i64* %R9.i2396, align 8
  %8509 = add i64 %8508, 144
  %8510 = add i64 %8335, 143
  store i64 %8510, i64* %3, align 8
  %8511 = inttoptr i64 %8509 to i32*
  %8512 = load i32, i32* %8511, align 4
  %8513 = zext i32 %8512 to i64
  store i64 %8513, i64* %R8.i3094, align 8
  %8514 = load i64, i64* %RBP.i, align 8
  %8515 = add i64 %8514, -12
  %8516 = add i64 %8335, 147
  store i64 %8516, i64* %3, align 8
  %8517 = inttoptr i64 %8515 to i32*
  %8518 = load i32, i32* %8517, align 4
  %8519 = add i32 %8518, %8512
  %8520 = zext i32 %8519 to i64
  store i64 %8520, i64* %R8.i3094, align 8
  %8521 = icmp ult i32 %8519, %8512
  %8522 = icmp ult i32 %8519, %8518
  %8523 = or i1 %8521, %8522
  %8524 = zext i1 %8523 to i8
  store i8 %8524, i8* %19, align 1
  %8525 = and i32 %8519, 255
  %8526 = tail call i32 @llvm.ctpop.i32(i32 %8525)
  %8527 = trunc i32 %8526 to i8
  %8528 = and i8 %8527, 1
  %8529 = xor i8 %8528, 1
  store i8 %8529, i8* %26, align 1
  %8530 = xor i32 %8518, %8512
  %8531 = xor i32 %8530, %8519
  %8532 = lshr i32 %8531, 4
  %8533 = trunc i32 %8532 to i8
  %8534 = and i8 %8533, 1
  store i8 %8534, i8* %31, align 1
  %8535 = icmp eq i32 %8519, 0
  %8536 = zext i1 %8535 to i8
  store i8 %8536, i8* %34, align 1
  %8537 = lshr i32 %8519, 31
  %8538 = trunc i32 %8537 to i8
  store i8 %8538, i8* %37, align 1
  %8539 = lshr i32 %8512, 31
  %8540 = lshr i32 %8518, 31
  %8541 = xor i32 %8537, %8539
  %8542 = xor i32 %8537, %8540
  %8543 = add nuw nsw i32 %8541, %8542
  %8544 = icmp eq i32 %8543, 2
  %8545 = zext i1 %8544 to i8
  store i8 %8545, i8* %43, align 1
  %8546 = sext i32 %8519 to i64
  store i64 %8546, i64* %R9.i2396, align 8
  %8547 = shl nsw i64 %8546, 3
  %8548 = add i64 %8507, %8547
  %8549 = add i64 %8335, 154
  store i64 %8549, i64* %3, align 8
  %8550 = inttoptr i64 %8548 to i64*
  %8551 = load i64, i64* %8550, align 8
  store i64 %8551, i64* %RSI.i4020.pre-phi, align 8
  store i64 %8508, i64* %R9.i2396, align 8
  %8552 = add i64 %8508, 148
  %8553 = add i64 %8335, 169
  store i64 %8553, i64* %3, align 8
  %8554 = inttoptr i64 %8552 to i32*
  %8555 = load i32, i32* %8554, align 4
  %8556 = zext i32 %8555 to i64
  store i64 %8556, i64* %R8.i3094, align 8
  %8557 = add i64 %8514, -16
  %8558 = add i64 %8335, 173
  store i64 %8558, i64* %3, align 8
  %8559 = inttoptr i64 %8557 to i32*
  %8560 = load i32, i32* %8559, align 4
  %8561 = add i32 %8560, %8555
  %8562 = zext i32 %8561 to i64
  store i64 %8562, i64* %R8.i3094, align 8
  %8563 = icmp ult i32 %8561, %8555
  %8564 = icmp ult i32 %8561, %8560
  %8565 = or i1 %8563, %8564
  %8566 = zext i1 %8565 to i8
  store i8 %8566, i8* %19, align 1
  %8567 = and i32 %8561, 255
  %8568 = tail call i32 @llvm.ctpop.i32(i32 %8567)
  %8569 = trunc i32 %8568 to i8
  %8570 = and i8 %8569, 1
  %8571 = xor i8 %8570, 1
  store i8 %8571, i8* %26, align 1
  %8572 = xor i32 %8560, %8555
  %8573 = xor i32 %8572, %8561
  %8574 = lshr i32 %8573, 4
  %8575 = trunc i32 %8574 to i8
  %8576 = and i8 %8575, 1
  store i8 %8576, i8* %31, align 1
  %8577 = icmp eq i32 %8561, 0
  %8578 = zext i1 %8577 to i8
  store i8 %8578, i8* %34, align 1
  %8579 = lshr i32 %8561, 31
  %8580 = trunc i32 %8579 to i8
  store i8 %8580, i8* %37, align 1
  %8581 = lshr i32 %8555, 31
  %8582 = lshr i32 %8560, 31
  %8583 = xor i32 %8579, %8581
  %8584 = xor i32 %8579, %8582
  %8585 = add nuw nsw i32 %8583, %8584
  %8586 = icmp eq i32 %8585, 2
  %8587 = zext i1 %8586 to i8
  store i8 %8587, i8* %43, align 1
  %8588 = sext i32 %8561 to i64
  store i64 %8588, i64* %R9.i2396, align 8
  %8589 = shl nsw i64 %8588, 3
  %8590 = add i64 %8551, %8589
  %8591 = load i64, i64* %RDX.i1708, align 8
  %8592 = add i64 %8335, 180
  store i64 %8592, i64* %3, align 8
  %8593 = inttoptr i64 %8590 to i64*
  store i64 %8591, i64* %8593, align 8
  %8594 = load i64, i64* %3, align 8
  %8595 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8595, i64* %RDX.i1708, align 8
  %8596 = add i64 %8595, 71928
  %8597 = add i64 %8594, 15
  store i64 %8597, i64* %3, align 8
  %8598 = inttoptr i64 %8596 to i64*
  %8599 = load i64, i64* %8598, align 8
  store i64 %8599, i64* %RDX.i1708, align 8
  %8600 = load i64, i64* %RBP.i, align 8
  %8601 = add i64 %8600, -12
  %8602 = add i64 %8594, 19
  store i64 %8602, i64* %3, align 8
  %8603 = inttoptr i64 %8601 to i32*
  %8604 = load i32, i32* %8603, align 4
  %8605 = sext i32 %8604 to i64
  store i64 %8605, i64* %RSI.i4020.pre-phi, align 8
  %8606 = shl nsw i64 %8605, 3
  %8607 = add i64 %8606, %8599
  %8608 = add i64 %8594, 23
  store i64 %8608, i64* %3, align 8
  %8609 = inttoptr i64 %8607 to i64*
  %8610 = load i64, i64* %8609, align 8
  store i64 %8610, i64* %RDX.i1708, align 8
  %8611 = add i64 %8600, -16
  %8612 = add i64 %8594, 27
  store i64 %8612, i64* %3, align 8
  %8613 = inttoptr i64 %8611 to i32*
  %8614 = load i32, i32* %8613, align 4
  %8615 = sext i32 %8614 to i64
  store i64 %8615, i64* %RSI.i4020.pre-phi, align 8
  %8616 = shl nsw i64 %8615, 3
  %8617 = add i64 %8616, %8610
  %8618 = add i64 %8594, 31
  store i64 %8618, i64* %3, align 8
  %8619 = inttoptr i64 %8617 to i64*
  %8620 = load i64, i64* %8619, align 8
  store i64 %8620, i64* %RDX.i1708, align 8
  %8621 = add i64 %8620, 8
  %8622 = add i64 %8594, 35
  store i64 %8622, i64* %3, align 8
  %8623 = inttoptr i64 %8621 to i64*
  %8624 = load i64, i64* %8623, align 8
  store i64 %8624, i64* %RDX.i1708, align 8
  %8625 = add i64 %8594, 39
  store i64 %8625, i64* %3, align 8
  %8626 = load i32, i32* %8613, align 4
  %8627 = sext i32 %8626 to i64
  %8628 = shl nsw i64 %8627, 3
  store i64 %8628, i64* %RSI.i4020.pre-phi, align 8
  %8629 = load i64, i64* %RCX.i1197, align 8
  %8630 = add i64 %8628, %8629
  store i64 %8630, i64* %R9.i2396, align 8
  %8631 = icmp ult i64 %8630, %8629
  %8632 = icmp ult i64 %8630, %8628
  %8633 = or i1 %8631, %8632
  %8634 = zext i1 %8633 to i8
  store i8 %8634, i8* %19, align 1
  %8635 = trunc i64 %8630 to i32
  %8636 = and i32 %8635, 255
  %8637 = tail call i32 @llvm.ctpop.i32(i32 %8636)
  %8638 = trunc i32 %8637 to i8
  %8639 = and i8 %8638, 1
  %8640 = xor i8 %8639, 1
  store i8 %8640, i8* %26, align 1
  %8641 = xor i64 %8628, %8629
  %8642 = xor i64 %8641, %8630
  %8643 = lshr i64 %8642, 4
  %8644 = trunc i64 %8643 to i8
  %8645 = and i8 %8644, 1
  store i8 %8645, i8* %31, align 1
  %8646 = icmp eq i64 %8630, 0
  %8647 = zext i1 %8646 to i8
  store i8 %8647, i8* %34, align 1
  %8648 = lshr i64 %8630, 63
  %8649 = trunc i64 %8648 to i8
  store i8 %8649, i8* %37, align 1
  %8650 = lshr i64 %8629, 63
  %8651 = lshr i64 %8627, 60
  %8652 = and i64 %8651, 1
  %8653 = xor i64 %8648, %8650
  %8654 = xor i64 %8648, %8652
  %8655 = add nuw nsw i64 %8653, %8654
  %8656 = icmp eq i64 %8655, 2
  %8657 = zext i1 %8656 to i8
  store i8 %8657, i8* %43, align 1
  %8658 = load i64, i64* %RBP.i, align 8
  %8659 = add i64 %8658, -12
  %8660 = add i64 %8594, 53
  store i64 %8660, i64* %3, align 8
  %8661 = inttoptr i64 %8659 to i32*
  %8662 = load i32, i32* %8661, align 4
  %8663 = sext i32 %8662 to i64
  store i64 %8663, i64* %RSI.i4020.pre-phi, align 8
  %8664 = shl nsw i64 %8663, 1
  %8665 = add i64 %8664, %8630
  %8666 = add i64 %8594, 58
  store i64 %8666, i64* %3, align 8
  %8667 = inttoptr i64 %8665 to i16*
  %8668 = load i16, i16* %8667, align 2
  %8669 = sext i16 %8668 to i64
  store i64 %8669, i64* %RSI.i4020.pre-phi, align 8
  %8670 = shl nsw i64 %8669, 3
  %8671 = add i64 %8670, %8624
  %8672 = add i64 %8594, 62
  store i64 %8672, i64* %3, align 8
  %8673 = inttoptr i64 %8671 to i64*
  %8674 = load i64, i64* %8673, align 8
  store i64 %8674, i64* %RDX.i1708, align 8
  %8675 = add i64 %8658, -56
  %8676 = add i64 %8594, 66
  store i64 %8676, i64* %3, align 8
  %8677 = inttoptr i64 %8675 to i64*
  %8678 = load i64, i64* %8677, align 8
  store i64 %8678, i64* %RSI.i4020.pre-phi, align 8
  %8679 = add i64 %8594, 70
  store i64 %8679, i64* %3, align 8
  %8680 = load i32, i32* %8661, align 4
  %8681 = zext i32 %8680 to i64
  store i64 %8681, i64* %R8.i3094, align 8
  %8682 = add i64 %8658, -252
  %8683 = load i32, i32* %EAX.i4054.pre-phi, align 4
  %8684 = add i64 %8594, 76
  store i64 %8684, i64* %3, align 8
  %8685 = inttoptr i64 %8682 to i32*
  store i32 %8683, i32* %8685, align 4
  %8686 = load i32, i32* %R8D.i2445, align 4
  %8687 = zext i32 %8686 to i64
  %8688 = load i64, i64* %3, align 8
  store i64 %8687, i64* %RAX.i893, align 8
  %8689 = load i64, i64* %RBP.i, align 8
  %8690 = add i64 %8689, -264
  %8691 = load i64, i64* %RDX.i1708, align 8
  %8692 = add i64 %8688, 10
  store i64 %8692, i64* %3, align 8
  %8693 = inttoptr i64 %8690 to i64*
  store i64 %8691, i64* %8693, align 8
  %8694 = load i64, i64* %3, align 8
  %8695 = load i32, i32* %EAX.i4054.pre-phi, align 8
  %8696 = sext i32 %8695 to i64
  %8697 = lshr i64 %8696, 32
  store i64 %8697, i64* %2568, align 8
  %8698 = load i64, i64* %RBP.i, align 8
  %8699 = add i64 %8698, -252
  %8700 = add i64 %8694, 8
  store i64 %8700, i64* %3, align 8
  %8701 = inttoptr i64 %8699 to i32*
  %8702 = load i32, i32* %8701, align 4
  %8703 = zext i32 %8702 to i64
  store i64 %8703, i64* %R8.i3094, align 8
  %8704 = add i64 %8694, 11
  store i64 %8704, i64* %3, align 8
  %8705 = zext i32 %8695 to i64
  %8706 = sext i32 %8702 to i64
  %8707 = shl nuw i64 %8697, 32
  %8708 = or i64 %8707, %8705
  %8709 = sdiv i64 %8708, %8706
  %8710 = shl i64 %8709, 32
  %8711 = ashr exact i64 %8710, 32
  %8712 = icmp eq i64 %8709, %8711
  br i1 %8712, label %8715, label %8713

; <label>:8713:                                   ; preds = %block_.L_48f2cc
  %8714 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %8704, %struct.Memory* %MEMORY.43)
  %.pre221 = load i64, i64* %RBP.i, align 8
  %.pre222 = load i64, i64* %3, align 8
  %.pre223 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__r8d.exit891

; <label>:8715:                                   ; preds = %block_.L_48f2cc
  %8716 = srem i64 %8708, %8706
  %8717 = and i64 %8709, 4294967295
  store i64 %8717, i64* %RAX.i893, align 8
  %8718 = and i64 %8716, 4294967295
  store i64 %8718, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %8719 = trunc i64 %8709 to i32
  br label %routine_idivl__r8d.exit891

routine_idivl__r8d.exit891:                       ; preds = %8715, %8713
  %8720 = phi i32 [ %.pre223, %8713 ], [ %8719, %8715 ]
  %8721 = phi i64 [ %.pre222, %8713 ], [ %8704, %8715 ]
  %8722 = phi i64 [ %.pre221, %8713 ], [ %8698, %8715 ]
  %8723 = phi %struct.Memory* [ %8714, %8713 ], [ %MEMORY.43, %8715 ]
  %8724 = add i64 %8722, -16
  %8725 = add i64 %8721, 4
  store i64 %8725, i64* %3, align 8
  %8726 = inttoptr i64 %8724 to i32*
  %8727 = load i32, i32* %8726, align 4
  %8728 = zext i32 %8727 to i64
  store i64 %8728, i64* %2572, align 8
  %8729 = add i64 %8722, -268
  %8730 = add i64 %8721, 10
  store i64 %8730, i64* %3, align 8
  %8731 = inttoptr i64 %8729 to i32*
  store i32 %8720, i32* %8731, align 4
  %8732 = load i32, i32* %R10D.i2266, align 4
  %8733 = zext i32 %8732 to i64
  %8734 = load i64, i64* %3, align 8
  store i64 %8733, i64* %RAX.i893, align 8
  %8735 = sext i32 %8732 to i64
  %8736 = lshr i64 %8735, 32
  store i64 %8736, i64* %2568, align 8
  %8737 = load i32, i32* %R8D.i2445, align 4
  %8738 = add i64 %8734, 7
  store i64 %8738, i64* %3, align 8
  %8739 = sext i32 %8737 to i64
  %8740 = shl nuw i64 %8736, 32
  %8741 = or i64 %8740, %8733
  %8742 = sdiv i64 %8741, %8739
  %8743 = shl i64 %8742, 32
  %8744 = ashr exact i64 %8743, 32
  %8745 = icmp eq i64 %8742, %8744
  br i1 %8745, label %8748, label %8746

; <label>:8746:                                   ; preds = %routine_idivl__r8d.exit891
  %8747 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %8738, %struct.Memory* %8723)
  %.pre224 = load i64, i64* %RAX.i893, align 8
  %.pre225 = load i64, i64* %3, align 8
  br label %routine_idivl__r8d.exit876

; <label>:8748:                                   ; preds = %routine_idivl__r8d.exit891
  %8749 = srem i64 %8741, %8739
  %8750 = and i64 %8742, 4294967295
  store i64 %8750, i64* %RAX.i893, align 8
  %8751 = and i64 %8749, 4294967295
  store i64 %8751, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__r8d.exit876

routine_idivl__r8d.exit876:                       ; preds = %8748, %8746
  %8752 = phi i64 [ %.pre225, %8746 ], [ %8738, %8748 ]
  %8753 = phi i64 [ %.pre224, %8746 ], [ %8750, %8748 ]
  %8754 = phi %struct.Memory* [ %8747, %8746 ], [ %8723, %8748 ]
  %8755 = trunc i64 %8753 to i32
  %8756 = shl i32 %8755, 1
  %8757 = icmp slt i32 %8755, 0
  %8758 = icmp slt i32 %8756, 0
  %8759 = xor i1 %8757, %8758
  %8760 = zext i32 %8756 to i64
  store i64 %8760, i64* %RAX.i893, align 8
  %.lobit111 = lshr i32 %8755, 31
  %8761 = trunc i32 %.lobit111 to i8
  store i8 %8761, i8* %19, align 1
  %8762 = and i32 %8756, 254
  %8763 = tail call i32 @llvm.ctpop.i32(i32 %8762)
  %8764 = trunc i32 %8763 to i8
  %8765 = and i8 %8764, 1
  %8766 = xor i8 %8765, 1
  store i8 %8766, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %8767 = icmp eq i32 %8756, 0
  %8768 = zext i1 %8767 to i8
  store i8 %8768, i8* %34, align 1
  %8769 = lshr i32 %8755, 30
  %8770 = trunc i32 %8769 to i8
  %8771 = and i8 %8770, 1
  store i8 %8771, i8* %37, align 1
  %8772 = zext i1 %8759 to i8
  store i8 %8772, i8* %43, align 1
  %8773 = load i64, i64* %RBP.i, align 8
  %8774 = add i64 %8773, -268
  %8775 = add i64 %8752, 9
  store i64 %8775, i64* %3, align 8
  %8776 = inttoptr i64 %8774 to i32*
  %8777 = load i32, i32* %8776, align 4
  %8778 = add i32 %8756, %8777
  %8779 = zext i32 %8778 to i64
  store i64 %8779, i64* %2572, align 8
  %8780 = icmp ult i32 %8778, %8777
  %8781 = icmp ult i32 %8778, %8756
  %8782 = or i1 %8780, %8781
  %8783 = zext i1 %8782 to i8
  store i8 %8783, i8* %19, align 1
  %8784 = and i32 %8778, 255
  %8785 = tail call i32 @llvm.ctpop.i32(i32 %8784)
  %8786 = trunc i32 %8785 to i8
  %8787 = and i8 %8786, 1
  %8788 = xor i8 %8787, 1
  store i8 %8788, i8* %26, align 1
  %8789 = xor i32 %8756, %8777
  %8790 = xor i32 %8789, %8778
  %8791 = lshr i32 %8790, 4
  %8792 = trunc i32 %8791 to i8
  %8793 = and i8 %8792, 1
  store i8 %8793, i8* %31, align 1
  %8794 = icmp eq i32 %8778, 0
  %8795 = zext i1 %8794 to i8
  store i8 %8795, i8* %34, align 1
  %8796 = lshr i32 %8778, 31
  %8797 = trunc i32 %8796 to i8
  store i8 %8797, i8* %37, align 1
  %8798 = lshr i32 %8777, 31
  %8799 = lshr i32 %8755, 30
  %8800 = and i32 %8799, 1
  %8801 = xor i32 %8796, %8798
  %8802 = xor i32 %8796, %8800
  %8803 = add nuw nsw i32 %8801, %8802
  %8804 = icmp eq i32 %8803, 2
  %8805 = zext i1 %8804 to i8
  store i8 %8805, i8* %43, align 1
  %8806 = sext i32 %8778 to i64
  store i64 %8806, i64* %R9.i2396, align 8
  %8807 = load i64, i64* %RSI.i4020.pre-phi, align 8
  %8808 = shl nsw i64 %8806, 2
  %8809 = add nsw i64 %8808, 472
  %8810 = add i64 %8809, %8807
  %8811 = add i64 %8752, 23
  store i64 %8811, i64* %3, align 8
  %8812 = inttoptr i64 %8810 to i32*
  %8813 = load i32, i32* %8812, align 4
  %8814 = sext i32 %8813 to i64
  store i64 %8814, i64* %RSI.i4020.pre-phi, align 8
  %8815 = add i64 %8773, -264
  %8816 = add i64 %8752, 30
  store i64 %8816, i64* %3, align 8
  %8817 = inttoptr i64 %8815 to i64*
  %8818 = load i64, i64* %8817, align 8
  store i64 %8818, i64* %R9.i2396, align 8
  %8819 = shl nsw i64 %8814, 3
  %8820 = add i64 %8819, %8818
  %8821 = add i64 %8752, 34
  store i64 %8821, i64* %3, align 8
  %8822 = inttoptr i64 %8820 to i64*
  %8823 = load i64, i64* %8822, align 8
  store i64 %8823, i64* %RSI.i4020.pre-phi, align 8
  %8824 = add i64 %8752, 37
  store i64 %8824, i64* %3, align 8
  %8825 = inttoptr i64 %8823 to i16*
  %8826 = load i16, i16* %8825, align 2
  store i16 %8826, i16* %DI.i2456, align 2
  %8827 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %8827, i64* %RSI.i4020.pre-phi, align 8
  %8828 = add i64 %8827, 6504
  %8829 = add i64 %8752, 52
  store i64 %8829, i64* %3, align 8
  %8830 = inttoptr i64 %8828 to i64*
  %8831 = load i64, i64* %8830, align 8
  store i64 %8831, i64* %RSI.i4020.pre-phi, align 8
  %8832 = add i64 %8831, 8
  %8833 = add i64 %8752, 56
  store i64 %8833, i64* %3, align 8
  %8834 = inttoptr i64 %8832 to i64*
  %8835 = load i64, i64* %8834, align 8
  store i64 %8835, i64* %RSI.i4020.pre-phi, align 8
  %8836 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8836, i64* %R11.i2222, align 8
  %8837 = add i64 %8836, 144
  %8838 = add i64 %8752, 71
  store i64 %8838, i64* %3, align 8
  %8839 = inttoptr i64 %8837 to i32*
  %8840 = load i32, i32* %8839, align 4
  %8841 = zext i32 %8840 to i64
  store i64 %8841, i64* %RAX.i893, align 8
  %8842 = load i64, i64* %RBP.i, align 8
  %8843 = add i64 %8842, -12
  %8844 = add i64 %8752, 74
  store i64 %8844, i64* %3, align 8
  %8845 = inttoptr i64 %8843 to i32*
  %8846 = load i32, i32* %8845, align 4
  %8847 = add i32 %8846, %8840
  %8848 = zext i32 %8847 to i64
  store i64 %8848, i64* %RAX.i893, align 8
  %8849 = icmp ult i32 %8847, %8840
  %8850 = icmp ult i32 %8847, %8846
  %8851 = or i1 %8849, %8850
  %8852 = zext i1 %8851 to i8
  store i8 %8852, i8* %19, align 1
  %8853 = and i32 %8847, 255
  %8854 = tail call i32 @llvm.ctpop.i32(i32 %8853)
  %8855 = trunc i32 %8854 to i8
  %8856 = and i8 %8855, 1
  %8857 = xor i8 %8856, 1
  store i8 %8857, i8* %26, align 1
  %8858 = xor i32 %8846, %8840
  %8859 = xor i32 %8858, %8847
  %8860 = lshr i32 %8859, 4
  %8861 = trunc i32 %8860 to i8
  %8862 = and i8 %8861, 1
  store i8 %8862, i8* %31, align 1
  %8863 = icmp eq i32 %8847, 0
  %8864 = zext i1 %8863 to i8
  store i8 %8864, i8* %34, align 1
  %8865 = lshr i32 %8847, 31
  %8866 = trunc i32 %8865 to i8
  store i8 %8866, i8* %37, align 1
  %8867 = lshr i32 %8840, 31
  %8868 = lshr i32 %8846, 31
  %8869 = xor i32 %8865, %8867
  %8870 = xor i32 %8865, %8868
  %8871 = add nuw nsw i32 %8869, %8870
  %8872 = icmp eq i32 %8871, 2
  %8873 = zext i1 %8872 to i8
  store i8 %8873, i8* %43, align 1
  %8874 = sext i32 %8847 to i64
  store i64 %8874, i64* %R11.i2222, align 8
  %8875 = shl nsw i64 %8874, 3
  %8876 = add i64 %8835, %8875
  %8877 = add i64 %8752, 81
  store i64 %8877, i64* %3, align 8
  %8878 = inttoptr i64 %8876 to i64*
  %8879 = load i64, i64* %8878, align 8
  store i64 %8879, i64* %RSI.i4020.pre-phi, align 8
  store i64 %8836, i64* %R11.i2222, align 8
  %8880 = add i64 %8836, 148
  %8881 = add i64 %8752, 96
  store i64 %8881, i64* %3, align 8
  %8882 = inttoptr i64 %8880 to i32*
  %8883 = load i32, i32* %8882, align 4
  %8884 = zext i32 %8883 to i64
  store i64 %8884, i64* %RAX.i893, align 8
  %8885 = add i64 %8842, -16
  %8886 = add i64 %8752, 99
  store i64 %8886, i64* %3, align 8
  %8887 = inttoptr i64 %8885 to i32*
  %8888 = load i32, i32* %8887, align 4
  %8889 = add i32 %8888, %8883
  %8890 = zext i32 %8889 to i64
  store i64 %8890, i64* %RAX.i893, align 8
  %8891 = icmp ult i32 %8889, %8883
  %8892 = icmp ult i32 %8889, %8888
  %8893 = or i1 %8891, %8892
  %8894 = zext i1 %8893 to i8
  store i8 %8894, i8* %19, align 1
  %8895 = and i32 %8889, 255
  %8896 = tail call i32 @llvm.ctpop.i32(i32 %8895)
  %8897 = trunc i32 %8896 to i8
  %8898 = and i8 %8897, 1
  %8899 = xor i8 %8898, 1
  store i8 %8899, i8* %26, align 1
  %8900 = xor i32 %8888, %8883
  %8901 = xor i32 %8900, %8889
  %8902 = lshr i32 %8901, 4
  %8903 = trunc i32 %8902 to i8
  %8904 = and i8 %8903, 1
  store i8 %8904, i8* %31, align 1
  %8905 = icmp eq i32 %8889, 0
  %8906 = zext i1 %8905 to i8
  store i8 %8906, i8* %34, align 1
  %8907 = lshr i32 %8889, 31
  %8908 = trunc i32 %8907 to i8
  store i8 %8908, i8* %37, align 1
  %8909 = lshr i32 %8883, 31
  %8910 = lshr i32 %8888, 31
  %8911 = xor i32 %8907, %8909
  %8912 = xor i32 %8907, %8910
  %8913 = add nuw nsw i32 %8911, %8912
  %8914 = icmp eq i32 %8913, 2
  %8915 = zext i1 %8914 to i8
  store i8 %8915, i8* %43, align 1
  %8916 = sext i32 %8889 to i64
  store i64 %8916, i64* %R11.i2222, align 8
  %8917 = shl nsw i64 %8916, 3
  %8918 = add i64 %8879, %8917
  %8919 = add i64 %8752, 106
  store i64 %8919, i64* %3, align 8
  %8920 = inttoptr i64 %8918 to i16**
  %8921 = load i16*, i16** %8920, align 8
  %8922 = load i16, i16* %DI.i2456, align 2
  %8923 = add i64 %8752, 109
  store i64 %8923, i64* %3, align 8
  store i16 %8922, i16* %8921, align 2
  %8924 = load i64, i64* %3, align 8
  %8925 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %8925, i64* %RSI.i4020.pre-phi, align 8
  %8926 = add i64 %8925, 71928
  %8927 = add i64 %8924, 15
  store i64 %8927, i64* %3, align 8
  %8928 = inttoptr i64 %8926 to i64*
  %8929 = load i64, i64* %8928, align 8
  store i64 %8929, i64* %RSI.i4020.pre-phi, align 8
  %8930 = load i64, i64* %RBP.i, align 8
  %8931 = add i64 %8930, -12
  %8932 = add i64 %8924, 19
  store i64 %8932, i64* %3, align 8
  %8933 = inttoptr i64 %8931 to i32*
  %8934 = load i32, i32* %8933, align 4
  %8935 = sext i32 %8934 to i64
  store i64 %8935, i64* %R11.i2222, align 8
  %8936 = shl nsw i64 %8935, 3
  %8937 = add i64 %8936, %8929
  %8938 = add i64 %8924, 23
  store i64 %8938, i64* %3, align 8
  %8939 = inttoptr i64 %8937 to i64*
  %8940 = load i64, i64* %8939, align 8
  store i64 %8940, i64* %RSI.i4020.pre-phi, align 8
  %8941 = add i64 %8930, -16
  %8942 = add i64 %8924, 27
  store i64 %8942, i64* %3, align 8
  %8943 = inttoptr i64 %8941 to i32*
  %8944 = load i32, i32* %8943, align 4
  %8945 = sext i32 %8944 to i64
  store i64 %8945, i64* %R11.i2222, align 8
  %8946 = shl nsw i64 %8945, 3
  %8947 = add i64 %8946, %8940
  %8948 = add i64 %8924, 31
  store i64 %8948, i64* %3, align 8
  %8949 = inttoptr i64 %8947 to i64*
  %8950 = load i64, i64* %8949, align 8
  store i64 %8950, i64* %RSI.i4020.pre-phi, align 8
  %8951 = add i64 %8950, 8
  %8952 = add i64 %8924, 35
  store i64 %8952, i64* %3, align 8
  %8953 = inttoptr i64 %8951 to i64*
  %8954 = load i64, i64* %8953, align 8
  store i64 %8954, i64* %RSI.i4020.pre-phi, align 8
  %8955 = add i64 %8924, 39
  store i64 %8955, i64* %3, align 8
  %8956 = load i32, i32* %8943, align 4
  %8957 = sext i32 %8956 to i64
  %8958 = shl nsw i64 %8957, 3
  store i64 %8958, i64* %R11.i2222, align 8
  %8959 = load i64, i64* %RCX.i1197, align 8
  %8960 = add i64 %8958, %8959
  store i64 %8960, i64* %RCX.i1197, align 8
  %8961 = icmp ult i64 %8960, %8959
  %8962 = icmp ult i64 %8960, %8958
  %8963 = or i1 %8961, %8962
  %8964 = zext i1 %8963 to i8
  store i8 %8964, i8* %19, align 1
  %8965 = trunc i64 %8960 to i32
  %8966 = and i32 %8965, 255
  %8967 = tail call i32 @llvm.ctpop.i32(i32 %8966)
  %8968 = trunc i32 %8967 to i8
  %8969 = and i8 %8968, 1
  %8970 = xor i8 %8969, 1
  store i8 %8970, i8* %26, align 1
  %8971 = xor i64 %8958, %8959
  %8972 = xor i64 %8971, %8960
  %8973 = lshr i64 %8972, 4
  %8974 = trunc i64 %8973 to i8
  %8975 = and i8 %8974, 1
  store i8 %8975, i8* %31, align 1
  %8976 = icmp eq i64 %8960, 0
  %8977 = zext i1 %8976 to i8
  store i8 %8977, i8* %34, align 1
  %8978 = lshr i64 %8960, 63
  %8979 = trunc i64 %8978 to i8
  store i8 %8979, i8* %37, align 1
  %8980 = lshr i64 %8959, 63
  %8981 = lshr i64 %8957, 60
  %8982 = and i64 %8981, 1
  %8983 = xor i64 %8978, %8980
  %8984 = xor i64 %8978, %8982
  %8985 = add nuw nsw i64 %8983, %8984
  %8986 = icmp eq i64 %8985, 2
  %8987 = zext i1 %8986 to i8
  store i8 %8987, i8* %43, align 1
  %8988 = load i64, i64* %RBP.i, align 8
  %8989 = add i64 %8988, -12
  %8990 = add i64 %8924, 50
  store i64 %8990, i64* %3, align 8
  %8991 = inttoptr i64 %8989 to i32*
  %8992 = load i32, i32* %8991, align 4
  %8993 = sext i32 %8992 to i64
  store i64 %8993, i64* %R11.i2222, align 8
  %8994 = shl nsw i64 %8993, 1
  %8995 = add i64 %8994, %8960
  %8996 = add i64 %8924, 55
  store i64 %8996, i64* %3, align 8
  %8997 = inttoptr i64 %8995 to i16*
  %8998 = load i16, i16* %8997, align 2
  %8999 = sext i16 %8998 to i64
  store i64 %8999, i64* %RCX.i1197, align 8
  %9000 = shl nsw i64 %8999, 3
  %9001 = add i64 %9000, %8954
  %9002 = add i64 %8924, 59
  store i64 %9002, i64* %3, align 8
  %9003 = inttoptr i64 %9001 to i64*
  %9004 = load i64, i64* %9003, align 8
  store i64 %9004, i64* %RCX.i1197, align 8
  %9005 = add i64 %8988, -56
  %9006 = add i64 %8924, 63
  store i64 %9006, i64* %3, align 8
  %9007 = inttoptr i64 %9005 to i64*
  %9008 = load i64, i64* %9007, align 8
  store i64 %9008, i64* %RSI.i4020.pre-phi, align 8
  %9009 = add i64 %8924, 66
  store i64 %9009, i64* %3, align 8
  %9010 = load i32, i32* %8991, align 4
  %9011 = zext i32 %9010 to i64
  store i64 %9011, i64* %RAX.i893, align 8
  %9012 = sext i32 %9010 to i64
  %9013 = lshr i64 %9012, 32
  store i64 %9013, i64* %2568, align 8
  %9014 = load i32, i32* %R8D.i2445, align 4
  %9015 = add i64 %8924, 70
  store i64 %9015, i64* %3, align 8
  %9016 = sext i32 %9014 to i64
  %9017 = shl nuw i64 %9013, 32
  %9018 = or i64 %9017, %9011
  %9019 = sdiv i64 %9018, %9016
  %9020 = shl i64 %9019, 32
  %9021 = ashr exact i64 %9020, 32
  %9022 = icmp eq i64 %9019, %9021
  br i1 %9022, label %9025, label %9023

; <label>:9023:                                   ; preds = %routine_idivl__r8d.exit876
  %9024 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %9015, %struct.Memory* %8754)
  %.pre226 = load i64, i64* %RBP.i, align 8
  %.pre227 = load i64, i64* %3, align 8
  %.pre228 = load i32, i32* %EAX.i4054.pre-phi, align 4
  br label %routine_idivl__r8d.exit770

; <label>:9025:                                   ; preds = %routine_idivl__r8d.exit876
  %9026 = srem i64 %9018, %9016
  %9027 = and i64 %9019, 4294967295
  store i64 %9027, i64* %RAX.i893, align 8
  %9028 = and i64 %9026, 4294967295
  store i64 %9028, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %9029 = trunc i64 %9019 to i32
  br label %routine_idivl__r8d.exit770

routine_idivl__r8d.exit770:                       ; preds = %9025, %9023
  %9030 = phi i32 [ %.pre228, %9023 ], [ %9029, %9025 ]
  %9031 = phi i64 [ %.pre227, %9023 ], [ %9015, %9025 ]
  %9032 = phi i64 [ %.pre226, %9023 ], [ %8988, %9025 ]
  %9033 = phi %struct.Memory* [ %9024, %9023 ], [ %8754, %9025 ]
  %9034 = add i64 %9032, -16
  %9035 = add i64 %9031, 4
  store i64 %9035, i64* %3, align 8
  %9036 = inttoptr i64 %9034 to i32*
  %9037 = load i32, i32* %9036, align 4
  %9038 = zext i32 %9037 to i64
  store i64 %9038, i64* %2572, align 8
  %9039 = add i64 %9032, -272
  %9040 = add i64 %9031, 10
  store i64 %9040, i64* %3, align 8
  %9041 = inttoptr i64 %9039 to i32*
  store i32 %9030, i32* %9041, align 4
  %9042 = load i32, i32* %R10D.i2266, align 4
  %9043 = zext i32 %9042 to i64
  %9044 = load i64, i64* %3, align 8
  store i64 %9043, i64* %RAX.i893, align 8
  %9045 = sext i32 %9042 to i64
  %9046 = lshr i64 %9045, 32
  store i64 %9046, i64* %2568, align 8
  %9047 = load i32, i32* %R8D.i2445, align 4
  %9048 = add i64 %9044, 7
  store i64 %9048, i64* %3, align 8
  %9049 = sext i32 %9047 to i64
  %9050 = shl nuw i64 %9046, 32
  %9051 = or i64 %9050, %9043
  %9052 = sdiv i64 %9051, %9049
  %9053 = shl i64 %9052, 32
  %9054 = ashr exact i64 %9053, 32
  %9055 = icmp eq i64 %9052, %9054
  br i1 %9055, label %9058, label %9056

; <label>:9056:                                   ; preds = %routine_idivl__r8d.exit770
  %9057 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %9048, %struct.Memory* %9033)
  %.pre229 = load i64, i64* %RAX.i893, align 8
  %.pre230 = load i64, i64* %3, align 8
  br label %routine_idivl__r8d.exit

; <label>:9058:                                   ; preds = %routine_idivl__r8d.exit770
  %9059 = srem i64 %9051, %9049
  %9060 = and i64 %9052, 4294967295
  store i64 %9060, i64* %RAX.i893, align 8
  %9061 = and i64 %9059, 4294967295
  store i64 %9061, i64* %RDX.i1708, align 8
  store i8 0, i8* %19, align 1
  store i8 0, i8* %26, align 1
  store i8 0, i8* %31, align 1
  store i8 0, i8* %34, align 1
  store i8 0, i8* %37, align 1
  store i8 0, i8* %43, align 1
  br label %routine_idivl__r8d.exit

routine_idivl__r8d.exit:                          ; preds = %9058, %9056
  %9062 = phi i64 [ %.pre230, %9056 ], [ %9048, %9058 ]
  %9063 = phi i64 [ %.pre229, %9056 ], [ %9060, %9058 ]
  %9064 = phi %struct.Memory* [ %9057, %9056 ], [ %9033, %9058 ]
  %9065 = trunc i64 %9063 to i32
  %9066 = shl i32 %9065, 1
  %9067 = icmp slt i32 %9065, 0
  %9068 = icmp slt i32 %9066, 0
  %9069 = xor i1 %9067, %9068
  %9070 = zext i32 %9066 to i64
  store i64 %9070, i64* %RAX.i893, align 8
  %.lobit113 = lshr i32 %9065, 31
  %9071 = trunc i32 %.lobit113 to i8
  store i8 %9071, i8* %19, align 1
  %9072 = and i32 %9066, 254
  %9073 = tail call i32 @llvm.ctpop.i32(i32 %9072)
  %9074 = trunc i32 %9073 to i8
  %9075 = and i8 %9074, 1
  %9076 = xor i8 %9075, 1
  store i8 %9076, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %9077 = icmp eq i32 %9066, 0
  %9078 = zext i1 %9077 to i8
  store i8 %9078, i8* %34, align 1
  %9079 = lshr i32 %9065, 30
  %9080 = trunc i32 %9079 to i8
  %9081 = and i8 %9080, 1
  store i8 %9081, i8* %37, align 1
  %9082 = zext i1 %9069 to i8
  store i8 %9082, i8* %43, align 1
  %9083 = load i64, i64* %RBP.i, align 8
  %9084 = add i64 %9083, -272
  %9085 = add i64 %9062, 9
  store i64 %9085, i64* %3, align 8
  %9086 = inttoptr i64 %9084 to i32*
  %9087 = load i32, i32* %9086, align 4
  %9088 = add i32 %9066, %9087
  %9089 = zext i32 %9088 to i64
  store i64 %9089, i64* %2572, align 8
  %9090 = icmp ult i32 %9088, %9087
  %9091 = icmp ult i32 %9088, %9066
  %9092 = or i1 %9090, %9091
  %9093 = zext i1 %9092 to i8
  store i8 %9093, i8* %19, align 1
  %9094 = and i32 %9088, 255
  %9095 = tail call i32 @llvm.ctpop.i32(i32 %9094)
  %9096 = trunc i32 %9095 to i8
  %9097 = and i8 %9096, 1
  %9098 = xor i8 %9097, 1
  store i8 %9098, i8* %26, align 1
  %9099 = xor i32 %9066, %9087
  %9100 = xor i32 %9099, %9088
  %9101 = lshr i32 %9100, 4
  %9102 = trunc i32 %9101 to i8
  %9103 = and i8 %9102, 1
  store i8 %9103, i8* %31, align 1
  %9104 = icmp eq i32 %9088, 0
  %9105 = zext i1 %9104 to i8
  store i8 %9105, i8* %34, align 1
  %9106 = lshr i32 %9088, 31
  %9107 = trunc i32 %9106 to i8
  store i8 %9107, i8* %37, align 1
  %9108 = lshr i32 %9087, 31
  %9109 = lshr i32 %9065, 30
  %9110 = and i32 %9109, 1
  %9111 = xor i32 %9106, %9108
  %9112 = xor i32 %9106, %9110
  %9113 = add nuw nsw i32 %9111, %9112
  %9114 = icmp eq i32 %9113, 2
  %9115 = zext i1 %9114 to i8
  store i8 %9115, i8* %43, align 1
  %9116 = sext i32 %9088 to i64
  store i64 %9116, i64* %R11.i2222, align 8
  %9117 = load i64, i64* %RSI.i4020.pre-phi, align 8
  %9118 = shl nsw i64 %9116, 2
  %9119 = add nsw i64 %9118, 472
  %9120 = add i64 %9119, %9117
  %9121 = add i64 %9062, 23
  store i64 %9121, i64* %3, align 8
  %9122 = inttoptr i64 %9120 to i32*
  %9123 = load i32, i32* %9122, align 4
  %9124 = sext i32 %9123 to i64
  store i64 %9124, i64* %RSI.i4020.pre-phi, align 8
  %9125 = load i64, i64* %RCX.i1197, align 8
  %9126 = shl nsw i64 %9124, 3
  %9127 = add i64 %9126, %9125
  %9128 = add i64 %9062, 27
  store i64 %9128, i64* %3, align 8
  %9129 = inttoptr i64 %9127 to i64*
  %9130 = load i64, i64* %9129, align 8
  store i64 %9130, i64* %RCX.i1197, align 8
  %9131 = add i64 %9130, 2
  %9132 = add i64 %9062, 31
  store i64 %9132, i64* %3, align 8
  %9133 = inttoptr i64 %9131 to i16*
  %9134 = load i16, i16* %9133, align 2
  store i16 %9134, i16* %DI.i2456, align 2
  %9135 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %9135, i64* %RCX.i1197, align 8
  %9136 = add i64 %9135, 6504
  %9137 = add i64 %9062, 46
  store i64 %9137, i64* %3, align 8
  %9138 = inttoptr i64 %9136 to i64*
  %9139 = load i64, i64* %9138, align 8
  store i64 %9139, i64* %RCX.i1197, align 8
  %9140 = add i64 %9139, 8
  %9141 = add i64 %9062, 50
  store i64 %9141, i64* %3, align 8
  %9142 = inttoptr i64 %9140 to i64*
  %9143 = load i64, i64* %9142, align 8
  store i64 %9143, i64* %RCX.i1197, align 8
  %9144 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %9144, i64* %RSI.i4020.pre-phi, align 8
  %9145 = add i64 %9144, 144
  %9146 = add i64 %9062, 64
  store i64 %9146, i64* %3, align 8
  %9147 = inttoptr i64 %9145 to i32*
  %9148 = load i32, i32* %9147, align 4
  %9149 = zext i32 %9148 to i64
  store i64 %9149, i64* %RAX.i893, align 8
  %9150 = load i64, i64* %RBP.i, align 8
  %9151 = add i64 %9150, -12
  %9152 = add i64 %9062, 67
  store i64 %9152, i64* %3, align 8
  %9153 = inttoptr i64 %9151 to i32*
  %9154 = load i32, i32* %9153, align 4
  %9155 = add i32 %9154, %9148
  %9156 = zext i32 %9155 to i64
  store i64 %9156, i64* %RAX.i893, align 8
  %9157 = icmp ult i32 %9155, %9148
  %9158 = icmp ult i32 %9155, %9154
  %9159 = or i1 %9157, %9158
  %9160 = zext i1 %9159 to i8
  store i8 %9160, i8* %19, align 1
  %9161 = and i32 %9155, 255
  %9162 = tail call i32 @llvm.ctpop.i32(i32 %9161)
  %9163 = trunc i32 %9162 to i8
  %9164 = and i8 %9163, 1
  %9165 = xor i8 %9164, 1
  store i8 %9165, i8* %26, align 1
  %9166 = xor i32 %9154, %9148
  %9167 = xor i32 %9166, %9155
  %9168 = lshr i32 %9167, 4
  %9169 = trunc i32 %9168 to i8
  %9170 = and i8 %9169, 1
  store i8 %9170, i8* %31, align 1
  %9171 = icmp eq i32 %9155, 0
  %9172 = zext i1 %9171 to i8
  store i8 %9172, i8* %34, align 1
  %9173 = lshr i32 %9155, 31
  %9174 = trunc i32 %9173 to i8
  store i8 %9174, i8* %37, align 1
  %9175 = lshr i32 %9148, 31
  %9176 = lshr i32 %9154, 31
  %9177 = xor i32 %9173, %9175
  %9178 = xor i32 %9173, %9176
  %9179 = add nuw nsw i32 %9177, %9178
  %9180 = icmp eq i32 %9179, 2
  %9181 = zext i1 %9180 to i8
  store i8 %9181, i8* %43, align 1
  %9182 = sext i32 %9155 to i64
  store i64 %9182, i64* %RSI.i4020.pre-phi, align 8
  %9183 = shl nsw i64 %9182, 3
  %9184 = add i64 %9143, %9183
  %9185 = add i64 %9062, 74
  store i64 %9185, i64* %3, align 8
  %9186 = inttoptr i64 %9184 to i64*
  %9187 = load i64, i64* %9186, align 8
  store i64 %9187, i64* %RCX.i1197, align 8
  store i64 %9144, i64* %RSI.i4020.pre-phi, align 8
  %9188 = add i64 %9144, 148
  %9189 = add i64 %9062, 88
  store i64 %9189, i64* %3, align 8
  %9190 = inttoptr i64 %9188 to i32*
  %9191 = load i32, i32* %9190, align 4
  %9192 = zext i32 %9191 to i64
  store i64 %9192, i64* %RAX.i893, align 8
  %9193 = add i64 %9150, -16
  %9194 = add i64 %9062, 91
  store i64 %9194, i64* %3, align 8
  %9195 = inttoptr i64 %9193 to i32*
  %9196 = load i32, i32* %9195, align 4
  %9197 = add i32 %9196, %9191
  %9198 = zext i32 %9197 to i64
  store i64 %9198, i64* %RAX.i893, align 8
  %9199 = icmp ult i32 %9197, %9191
  %9200 = icmp ult i32 %9197, %9196
  %9201 = or i1 %9199, %9200
  %9202 = zext i1 %9201 to i8
  store i8 %9202, i8* %19, align 1
  %9203 = and i32 %9197, 255
  %9204 = tail call i32 @llvm.ctpop.i32(i32 %9203)
  %9205 = trunc i32 %9204 to i8
  %9206 = and i8 %9205, 1
  %9207 = xor i8 %9206, 1
  store i8 %9207, i8* %26, align 1
  %9208 = xor i32 %9196, %9191
  %9209 = xor i32 %9208, %9197
  %9210 = lshr i32 %9209, 4
  %9211 = trunc i32 %9210 to i8
  %9212 = and i8 %9211, 1
  store i8 %9212, i8* %31, align 1
  %9213 = icmp eq i32 %9197, 0
  %9214 = zext i1 %9213 to i8
  store i8 %9214, i8* %34, align 1
  %9215 = lshr i32 %9197, 31
  %9216 = trunc i32 %9215 to i8
  store i8 %9216, i8* %37, align 1
  %9217 = lshr i32 %9191, 31
  %9218 = lshr i32 %9196, 31
  %9219 = xor i32 %9215, %9217
  %9220 = xor i32 %9215, %9218
  %9221 = add nuw nsw i32 %9219, %9220
  %9222 = icmp eq i32 %9221, 2
  %9223 = zext i1 %9222 to i8
  store i8 %9223, i8* %43, align 1
  %9224 = sext i32 %9197 to i64
  store i64 %9224, i64* %RSI.i4020.pre-phi, align 8
  %9225 = shl nsw i64 %9224, 3
  %9226 = add i64 %9187, %9225
  %9227 = add i64 %9062, 98
  store i64 %9227, i64* %3, align 8
  %9228 = inttoptr i64 %9226 to i64*
  %9229 = load i64, i64* %9228, align 8
  %9230 = add i64 %9229, 2
  %9231 = load i16, i16* %DI.i2456, align 2
  %9232 = add i64 %9062, 102
  store i64 %9232, i64* %3, align 8
  %9233 = inttoptr i64 %9230 to i16*
  store i16 %9231, i16* %9233, align 2
  %9234 = load i64, i64* %3, align 8
  %9235 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %9235, i64* %RCX.i1197, align 8
  %9236 = add i64 %9235, 72400
  %9237 = add i64 %9234, 15
  store i64 %9237, i64* %3, align 8
  %9238 = inttoptr i64 %9236 to i32*
  %9239 = load i32, i32* %9238, align 4
  store i8 0, i8* %19, align 1
  %9240 = and i32 %9239, 255
  %9241 = tail call i32 @llvm.ctpop.i32(i32 %9240)
  %9242 = trunc i32 %9241 to i8
  %9243 = and i8 %9242, 1
  %9244 = xor i8 %9243, 1
  store i8 %9244, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %9245 = icmp eq i32 %9239, 0
  %9246 = zext i1 %9245 to i8
  store i8 %9246, i8* %34, align 1
  %9247 = lshr i32 %9239, 31
  %9248 = trunc i32 %9247 to i8
  store i8 %9248, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v336 = select i1 %9245, i64 87, i64 21
  %9249 = add i64 %9234, %.v336
  store i64 %9249, i64* %3, align 8
  br i1 %9245, label %block_.L_48f5e1, label %block_48f59f

block_48f59f:                                     ; preds = %routine_idivl__r8d.exit
  store i64 ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64), i64* %RAX.i893, align 8
  %9250 = load i64, i64* %RBP.i, align 8
  %9251 = add i64 %9250, -16
  %9252 = add i64 %9249, 14
  store i64 %9252, i64* %3, align 8
  %9253 = inttoptr i64 %9251 to i32*
  %9254 = load i32, i32* %9253, align 4
  %9255 = sext i32 %9254 to i64
  %9256 = shl nsw i64 %9255, 3
  store i64 %9256, i64* %RCX.i1197, align 8
  %9257 = add i64 %9256, ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64)
  store i64 %9257, i64* %RAX.i893, align 8
  %9258 = icmp ult i64 %9257, ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64)
  %9259 = icmp ult i64 %9257, %9256
  %9260 = or i1 %9258, %9259
  %9261 = zext i1 %9260 to i8
  store i8 %9261, i8* %19, align 1
  %9262 = trunc i64 %9257 to i32
  %9263 = and i32 %9262, 248
  %9264 = tail call i32 @llvm.ctpop.i32(i32 %9263)
  %9265 = trunc i32 %9264 to i8
  %9266 = and i8 %9265, 1
  %9267 = xor i8 %9266, 1
  store i8 %9267, i8* %26, align 1
  %9268 = xor i64 %9256, ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64)
  %9269 = xor i64 %9268, %9257
  %9270 = lshr i64 %9269, 4
  %9271 = trunc i64 %9270 to i8
  %9272 = and i8 %9271, 1
  store i8 %9272, i8* %31, align 1
  %9273 = icmp eq i64 %9257, 0
  %9274 = zext i1 %9273 to i8
  store i8 %9274, i8* %34, align 1
  %9275 = lshr i64 %9257, 63
  %9276 = trunc i64 %9275 to i8
  store i8 %9276, i8* %37, align 1
  %9277 = lshr i64 %9255, 60
  %9278 = and i64 %9277, 1
  %9279 = xor i64 %9275, lshr (i64 ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64), i64 63)
  %9280 = xor i64 %9275, %9278
  %9281 = add nuw nsw i64 %9279, %9280
  %9282 = icmp eq i64 %9281, 2
  %9283 = zext i1 %9282 to i8
  store i8 %9283, i8* %43, align 1
  %9284 = add i64 %9250, -12
  %9285 = add i64 %9249, 25
  store i64 %9285, i64* %3, align 8
  %9286 = inttoptr i64 %9284 to i32*
  %9287 = load i32, i32* %9286, align 4
  %9288 = sext i32 %9287 to i64
  store i64 %9288, i64* %RCX.i1197, align 8
  %9289 = shl nsw i64 %9288, 1
  %9290 = add i64 %9289, %9257
  %9291 = add i64 %9249, 29
  store i64 %9291, i64* %3, align 8
  %9292 = inttoptr i64 %9290 to i16*
  %9293 = load i16, i16* %9292, align 2
  store i16 %9293, i16* %DX.i4027, align 2
  %9294 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %9295 = add i64 %9294, 3264
  %9296 = lshr i64 %9295, 63
  %9297 = add i64 %9294, 3296
  store i64 %9297, i64* %RAX.i893, align 8
  %9298 = icmp ugt i64 %9295, -33
  %9299 = zext i1 %9298 to i8
  store i8 %9299, i8* %19, align 1
  %9300 = trunc i64 %9297 to i32
  %9301 = and i32 %9300, 255
  %9302 = tail call i32 @llvm.ctpop.i32(i32 %9301)
  %9303 = trunc i32 %9302 to i8
  %9304 = and i8 %9303, 1
  %9305 = xor i8 %9304, 1
  store i8 %9305, i8* %26, align 1
  %9306 = xor i64 %9297, %9295
  %9307 = lshr i64 %9306, 4
  %9308 = trunc i64 %9307 to i8
  %9309 = and i8 %9308, 1
  store i8 %9309, i8* %31, align 1
  %9310 = icmp eq i64 %9297, 0
  %9311 = zext i1 %9310 to i8
  store i8 %9311, i8* %34, align 1
  %9312 = lshr i64 %9297, 63
  %9313 = trunc i64 %9312 to i8
  store i8 %9313, i8* %37, align 1
  %9314 = xor i64 %9312, %9296
  %9315 = add nuw nsw i64 %9314, %9312
  %9316 = icmp eq i64 %9315, 2
  %9317 = zext i1 %9316 to i8
  store i8 %9317, i8* %43, align 1
  %9318 = load i64, i64* %RBP.i, align 8
  %9319 = add i64 %9318, -16
  %9320 = add i64 %9249, 51
  store i64 %9320, i64* %3, align 8
  %9321 = inttoptr i64 %9319 to i32*
  %9322 = load i32, i32* %9321, align 4
  %9323 = sext i32 %9322 to i64
  %9324 = shl nsw i64 %9323, 3
  store i64 %9324, i64* %RCX.i1197, align 8
  %9325 = add i64 %9324, %9297
  store i64 %9325, i64* %RAX.i893, align 8
  %9326 = icmp ult i64 %9325, %9297
  %9327 = icmp ult i64 %9325, %9324
  %9328 = or i1 %9326, %9327
  %9329 = zext i1 %9328 to i8
  store i8 %9329, i8* %19, align 1
  %9330 = trunc i64 %9325 to i32
  %9331 = and i32 %9330, 255
  %9332 = tail call i32 @llvm.ctpop.i32(i32 %9331)
  %9333 = trunc i32 %9332 to i8
  %9334 = and i8 %9333, 1
  %9335 = xor i8 %9334, 1
  store i8 %9335, i8* %26, align 1
  %9336 = xor i64 %9324, %9297
  %9337 = xor i64 %9336, %9325
  %9338 = lshr i64 %9337, 4
  %9339 = trunc i64 %9338 to i8
  %9340 = and i8 %9339, 1
  store i8 %9340, i8* %31, align 1
  %9341 = icmp eq i64 %9325, 0
  %9342 = zext i1 %9341 to i8
  store i8 %9342, i8* %34, align 1
  %9343 = lshr i64 %9325, 63
  %9344 = trunc i64 %9343 to i8
  store i8 %9344, i8* %37, align 1
  %9345 = lshr i64 %9323, 60
  %9346 = and i64 %9345, 1
  %9347 = xor i64 %9343, %9312
  %9348 = xor i64 %9343, %9346
  %9349 = add nuw nsw i64 %9347, %9348
  %9350 = icmp eq i64 %9349, 2
  %9351 = zext i1 %9350 to i8
  store i8 %9351, i8* %43, align 1
  %9352 = add i64 %9318, -12
  %9353 = add i64 %9249, 62
  store i64 %9353, i64* %3, align 8
  %9354 = inttoptr i64 %9352 to i32*
  %9355 = load i32, i32* %9354, align 4
  %9356 = sext i32 %9355 to i64
  store i64 %9356, i64* %RCX.i1197, align 8
  %9357 = shl nsw i64 %9356, 1
  %9358 = add i64 %9357, %9325
  %9359 = load i16, i16* %DX.i4027, align 2
  %9360 = add i64 %9249, 66
  store i64 %9360, i64* %3, align 8
  %9361 = inttoptr i64 %9358 to i16*
  store i16 %9359, i16* %9361, align 2
  %.pre231 = load i64, i64* %3, align 8
  br label %block_.L_48f5e1

block_.L_48f5e1:                                  ; preds = %block_48f59f, %routine_idivl__r8d.exit
  %9362 = phi i64 [ %.pre231, %block_48f59f ], [ %9249, %routine_idivl__r8d.exit ]
  %9363 = add i64 %9362, 5
  store i64 %9363, i64* %3, align 8
  br label %block_.L_48f5e6

block_.L_48f5e6:                                  ; preds = %block_.L_48f5e1, %block_.L_48f2c7
  %storemerge108 = phi i64 [ %8219, %block_.L_48f2c7 ], [ %9363, %block_.L_48f5e1 ]
  %MEMORY.45 = phi %struct.Memory* [ %7965, %block_.L_48f2c7 ], [ %9064, %block_.L_48f5e1 ]
  %9364 = add i64 %storemerge108, 5
  store i64 %9364, i64* %3, align 8
  br label %block_.L_48f5eb

block_.L_48f5eb:                                  ; preds = %block_.L_48f5e6, %block_.L_48efcf
  %storemerge103 = phi i64 [ %7107, %block_.L_48efcf ], [ %9364, %block_.L_48f5e6 ]
  %MEMORY.46 = phi %struct.Memory* [ %MEMORY.39, %block_.L_48efcf ], [ %MEMORY.45, %block_.L_48f5e6 ]
  %9365 = load i64, i64* %RBP.i, align 8
  %9366 = add i64 %9365, -12
  %9367 = add i64 %storemerge103, 8
  store i64 %9367, i64* %3, align 8
  %9368 = inttoptr i64 %9366 to i32*
  %9369 = load i32, i32* %9368, align 4
  %9370 = add i32 %9369, 1
  %9371 = zext i32 %9370 to i64
  store i64 %9371, i64* %RAX.i893, align 8
  %9372 = icmp eq i32 %9369, -1
  %9373 = icmp eq i32 %9370, 0
  %9374 = or i1 %9372, %9373
  %9375 = zext i1 %9374 to i8
  store i8 %9375, i8* %19, align 1
  %9376 = and i32 %9370, 255
  %9377 = tail call i32 @llvm.ctpop.i32(i32 %9376)
  %9378 = trunc i32 %9377 to i8
  %9379 = and i8 %9378, 1
  %9380 = xor i8 %9379, 1
  store i8 %9380, i8* %26, align 1
  %9381 = xor i32 %9370, %9369
  %9382 = lshr i32 %9381, 4
  %9383 = trunc i32 %9382 to i8
  %9384 = and i8 %9383, 1
  store i8 %9384, i8* %31, align 1
  %9385 = zext i1 %9373 to i8
  store i8 %9385, i8* %34, align 1
  %9386 = lshr i32 %9370, 31
  %9387 = trunc i32 %9386 to i8
  store i8 %9387, i8* %37, align 1
  %9388 = lshr i32 %9369, 31
  %9389 = xor i32 %9386, %9388
  %9390 = add nuw nsw i32 %9389, %9386
  %9391 = icmp eq i32 %9390, 2
  %9392 = zext i1 %9391 to i8
  store i8 %9392, i8* %43, align 1
  %9393 = add i64 %storemerge103, 14
  store i64 %9393, i64* %3, align 8
  store i32 %9370, i32* %9368, align 4
  %9394 = load i64, i64* %3, align 8
  %9395 = add i64 %9394, -2047
  store i64 %9395, i64* %3, align 8
  br label %block_.L_48edfa

block_.L_48f5fe:                                  ; preds = %block_.L_48edfa
  %9396 = add i64 %6384, -16
  %9397 = add i64 %6412, 8
  store i64 %9397, i64* %3, align 8
  %9398 = inttoptr i64 %9396 to i32*
  %9399 = load i32, i32* %9398, align 4
  %9400 = add i32 %9399, 1
  %9401 = zext i32 %9400 to i64
  store i64 %9401, i64* %RAX.i893, align 8
  %9402 = icmp eq i32 %9399, -1
  %9403 = icmp eq i32 %9400, 0
  %9404 = or i1 %9402, %9403
  %9405 = zext i1 %9404 to i8
  store i8 %9405, i8* %19, align 1
  %9406 = and i32 %9400, 255
  %9407 = tail call i32 @llvm.ctpop.i32(i32 %9406)
  %9408 = trunc i32 %9407 to i8
  %9409 = and i8 %9408, 1
  %9410 = xor i8 %9409, 1
  store i8 %9410, i8* %26, align 1
  %9411 = xor i32 %9400, %9399
  %9412 = lshr i32 %9411, 4
  %9413 = trunc i32 %9412 to i8
  %9414 = and i8 %9413, 1
  store i8 %9414, i8* %31, align 1
  %9415 = zext i1 %9403 to i8
  store i8 %9415, i8* %34, align 1
  %9416 = lshr i32 %9400, 31
  %9417 = trunc i32 %9416 to i8
  store i8 %9417, i8* %37, align 1
  %9418 = lshr i32 %9399, 31
  %9419 = xor i32 %9416, %9418
  %9420 = add nuw nsw i32 %9419, %9416
  %9421 = icmp eq i32 %9420, 2
  %9422 = zext i1 %9421 to i8
  store i8 %9422, i8* %43, align 1
  %9423 = add i64 %6412, 14
  store i64 %9423, i64* %3, align 8
  store i32 %9400, i32* %9398, align 4
  %9424 = load i64, i64* %3, align 8
  %9425 = add i64 %9424, -2083
  store i64 %9425, i64* %3, align 8
  br label %block_.L_48ede9

block_.L_48f611:                                  ; preds = %block_.L_48ede9
  %9426 = add i64 %6379, 5
  store i64 %9426, i64* %3, align 8
  br label %block_.L_48f616

block_.L_48f616:                                  ; preds = %block_.L_48f611, %block_.L_48edd8
  %9427 = phi i64 [ %2574, %block_.L_48edd8 ], [ %6351, %block_.L_48f611 ]
  %9428 = phi i64 [ %6348, %block_.L_48edd8 ], [ %9426, %block_.L_48f611 ]
  %MEMORY.47 = phi %struct.Memory* [ %MEMORY.24, %block_.L_48edd8 ], [ %MEMORY.37, %block_.L_48f611 ]
  %9429 = load i32, i32* bitcast (%G_0x710a58_type* @G_0x710a58 to i32*), align 8
  %9430 = zext i32 %9429 to i64
  store i64 %9430, i64* %RAX.i893, align 8
  %9431 = add i64 %9427, -56
  %9432 = add i64 %9428, 11
  store i64 %9432, i64* %3, align 8
  %9433 = inttoptr i64 %9431 to i64*
  %9434 = load i64, i64* %9433, align 8
  %9435 = add i64 %9434, 524
  %9436 = add i64 %9428, 17
  store i64 %9436, i64* %3, align 8
  %9437 = inttoptr i64 %9435 to i32*
  store i32 %9429, i32* %9437, align 4
  %9438 = load i64, i64* %3, align 8
  %9439 = load i32, i32* bitcast (%G_0x70fd50_type* @G_0x70fd50 to i32*), align 8
  %9440 = zext i32 %9439 to i64
  store i64 %9440, i64* %RAX.i893, align 8
  %9441 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %9441, i64* %RCX.i1197, align 8
  %9442 = add i64 %9441, 72380
  %9443 = add i64 %9438, 21
  store i64 %9443, i64* %3, align 8
  %9444 = inttoptr i64 %9442 to i32*
  store i32 %9439, i32* %9444, align 4
  %9445 = load i64, i64* %RBP.i, align 8
  %9446 = add i64 %9445, -56
  %9447 = load i64, i64* %3, align 8
  %9448 = add i64 %9447, 4
  store i64 %9448, i64* %3, align 8
  %9449 = inttoptr i64 %9446 to i64*
  %9450 = load i64, i64* %9449, align 8
  store i64 %9450, i64* %RCX.i1197, align 8
  %9451 = add i64 %9450, 72
  %9452 = add i64 %9447, 8
  store i64 %9452, i64* %3, align 8
  %9453 = inttoptr i64 %9451 to i32*
  %9454 = load i32, i32* %9453, align 4
  %9455 = add i32 %9454, -13
  %9456 = icmp ult i32 %9454, 13
  %9457 = zext i1 %9456 to i8
  store i8 %9457, i8* %19, align 1
  %9458 = and i32 %9455, 255
  %9459 = tail call i32 @llvm.ctpop.i32(i32 %9458)
  %9460 = trunc i32 %9459 to i8
  %9461 = and i8 %9460, 1
  %9462 = xor i8 %9461, 1
  store i8 %9462, i8* %26, align 1
  %9463 = xor i32 %9455, %9454
  %9464 = lshr i32 %9463, 4
  %9465 = trunc i32 %9464 to i8
  %9466 = and i8 %9465, 1
  store i8 %9466, i8* %31, align 1
  %9467 = icmp eq i32 %9455, 0
  %9468 = zext i1 %9467 to i8
  store i8 %9468, i8* %34, align 1
  %9469 = lshr i32 %9455, 31
  %9470 = trunc i32 %9469 to i8
  store i8 %9470, i8* %37, align 1
  %9471 = lshr i32 %9454, 31
  %9472 = xor i32 %9469, %9471
  %9473 = add nuw nsw i32 %9472, %9471
  %9474 = icmp eq i32 %9473, 2
  %9475 = zext i1 %9474 to i8
  store i8 %9475, i8* %43, align 1
  %.v319 = select i1 %9467, i64 14, i64 250
  %9476 = add i64 %9447, %.v319
  store i64 %9476, i64* %3, align 8
  br i1 %9467, label %block_48f64a, label %block_.L_48f736

block_48f64a:                                     ; preds = %block_.L_48f616
  %9477 = add i64 %9445, -20
  %9478 = add i64 %9476, 7
  store i64 %9478, i64* %3, align 8
  %9479 = inttoptr i64 %9477 to i32*
  store i32 0, i32* %9479, align 4
  %9480 = load i64, i64* %RBP.i, align 8
  %9481 = add i64 %9480, -12
  %9482 = load i64, i64* %3, align 8
  %9483 = add i64 %9482, 7
  store i64 %9483, i64* %3, align 8
  %9484 = inttoptr i64 %9481 to i32*
  store i32 0, i32* %9484, align 4
  %.pre233 = load i64, i64* %3, align 8
  br label %block_.L_48f658

block_.L_48f658:                                  ; preds = %block_.L_48f71e, %block_48f64a
  %9485 = phi i64 [ %9845, %block_.L_48f71e ], [ %.pre233, %block_48f64a ]
  %9486 = load i64, i64* %RBP.i, align 8
  %9487 = add i64 %9486, -12
  %9488 = add i64 %9485, 4
  store i64 %9488, i64* %3, align 8
  %9489 = inttoptr i64 %9487 to i32*
  %9490 = load i32, i32* %9489, align 4
  %9491 = add i32 %9490, -4
  %9492 = icmp ult i32 %9490, 4
  %9493 = zext i1 %9492 to i8
  store i8 %9493, i8* %19, align 1
  %9494 = and i32 %9491, 255
  %9495 = tail call i32 @llvm.ctpop.i32(i32 %9494)
  %9496 = trunc i32 %9495 to i8
  %9497 = and i8 %9496, 1
  %9498 = xor i8 %9497, 1
  store i8 %9498, i8* %26, align 1
  %9499 = xor i32 %9491, %9490
  %9500 = lshr i32 %9499, 4
  %9501 = trunc i32 %9500 to i8
  %9502 = and i8 %9501, 1
  store i8 %9502, i8* %31, align 1
  %9503 = icmp eq i32 %9491, 0
  %9504 = zext i1 %9503 to i8
  store i8 %9504, i8* %34, align 1
  %9505 = lshr i32 %9491, 31
  %9506 = trunc i32 %9505 to i8
  store i8 %9506, i8* %37, align 1
  %9507 = lshr i32 %9490, 31
  %9508 = xor i32 %9505, %9507
  %9509 = add nuw nsw i32 %9508, %9507
  %9510 = icmp eq i32 %9509, 2
  %9511 = zext i1 %9510 to i8
  store i8 %9511, i8* %43, align 1
  %9512 = icmp ne i8 %9506, 0
  %9513 = xor i1 %9512, %9510
  %.v329 = select i1 %9513, i64 10, i64 217
  %9514 = add i64 %9485, %.v329
  store i64 %9514, i64* %3, align 8
  br i1 %9513, label %block_48f662, label %block_.L_48f731

block_48f662:                                     ; preds = %block_.L_48f658
  %9515 = add i64 %9486, -16
  %9516 = add i64 %9514, 7
  store i64 %9516, i64* %3, align 8
  %9517 = inttoptr i64 %9515 to i32*
  store i32 0, i32* %9517, align 4
  %.pre234 = load i64, i64* %3, align 8
  br label %block_.L_48f669

block_.L_48f669:                                  ; preds = %block_48f673, %block_48f662
  %9518 = phi i64 [ %9815, %block_48f673 ], [ %.pre234, %block_48f662 ]
  %9519 = load i64, i64* %RBP.i, align 8
  %9520 = add i64 %9519, -16
  %9521 = add i64 %9518, 4
  store i64 %9521, i64* %3, align 8
  %9522 = inttoptr i64 %9520 to i32*
  %9523 = load i32, i32* %9522, align 4
  %9524 = add i32 %9523, -4
  %9525 = icmp ult i32 %9523, 4
  %9526 = zext i1 %9525 to i8
  store i8 %9526, i8* %19, align 1
  %9527 = and i32 %9524, 255
  %9528 = tail call i32 @llvm.ctpop.i32(i32 %9527)
  %9529 = trunc i32 %9528 to i8
  %9530 = and i8 %9529, 1
  %9531 = xor i8 %9530, 1
  store i8 %9531, i8* %26, align 1
  %9532 = xor i32 %9524, %9523
  %9533 = lshr i32 %9532, 4
  %9534 = trunc i32 %9533 to i8
  %9535 = and i8 %9534, 1
  store i8 %9535, i8* %31, align 1
  %9536 = icmp eq i32 %9524, 0
  %9537 = zext i1 %9536 to i8
  store i8 %9537, i8* %34, align 1
  %9538 = lshr i32 %9524, 31
  %9539 = trunc i32 %9538 to i8
  store i8 %9539, i8* %37, align 1
  %9540 = lshr i32 %9523, 31
  %9541 = xor i32 %9538, %9540
  %9542 = add nuw nsw i32 %9541, %9540
  %9543 = icmp eq i32 %9542, 2
  %9544 = zext i1 %9543 to i8
  store i8 %9544, i8* %43, align 1
  %9545 = icmp ne i8 %9539, 0
  %9546 = xor i1 %9545, %9543
  %.v292 = select i1 %9546, i64 10, i64 181
  %9547 = add i64 %9518, %.v292
  store i64 %9547, i64* %3, align 8
  br i1 %9546, label %block_48f673, label %block_.L_48f71e

block_48f673:                                     ; preds = %block_.L_48f669
  %9548 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %9548, i64* %RAX.i893, align 8
  %9549 = add i64 %9548, 112
  %9550 = add i64 %9547, 12
  store i64 %9550, i64* %3, align 8
  %9551 = inttoptr i64 %9549 to i64*
  %9552 = load i64, i64* %9551, align 8
  store i64 %9552, i64* %RAX.i893, align 8
  store i64 %9548, i64* %RCX.i1197, align 8
  %9553 = add i64 %9548, 144
  %9554 = add i64 %9547, 26
  store i64 %9554, i64* %3, align 8
  %9555 = inttoptr i64 %9553 to i32*
  %9556 = load i32, i32* %9555, align 4
  %9557 = zext i32 %9556 to i64
  store i64 %9557, i64* %RDX.i1708, align 8
  %9558 = add i64 %9519, -12
  %9559 = add i64 %9547, 29
  store i64 %9559, i64* %3, align 8
  %9560 = inttoptr i64 %9558 to i32*
  %9561 = load i32, i32* %9560, align 4
  %9562 = add i32 %9561, %9556
  %9563 = zext i32 %9562 to i64
  store i64 %9563, i64* %RDX.i1708, align 8
  %9564 = icmp ult i32 %9562, %9556
  %9565 = icmp ult i32 %9562, %9561
  %9566 = or i1 %9564, %9565
  %9567 = zext i1 %9566 to i8
  store i8 %9567, i8* %19, align 1
  %9568 = and i32 %9562, 255
  %9569 = tail call i32 @llvm.ctpop.i32(i32 %9568)
  %9570 = trunc i32 %9569 to i8
  %9571 = and i8 %9570, 1
  %9572 = xor i8 %9571, 1
  store i8 %9572, i8* %26, align 1
  %9573 = xor i32 %9561, %9556
  %9574 = xor i32 %9573, %9562
  %9575 = lshr i32 %9574, 4
  %9576 = trunc i32 %9575 to i8
  %9577 = and i8 %9576, 1
  store i8 %9577, i8* %31, align 1
  %9578 = icmp eq i32 %9562, 0
  %9579 = zext i1 %9578 to i8
  store i8 %9579, i8* %34, align 1
  %9580 = lshr i32 %9562, 31
  %9581 = trunc i32 %9580 to i8
  store i8 %9581, i8* %37, align 1
  %9582 = lshr i32 %9556, 31
  %9583 = lshr i32 %9561, 31
  %9584 = xor i32 %9580, %9582
  %9585 = xor i32 %9580, %9583
  %9586 = add nuw nsw i32 %9584, %9585
  %9587 = icmp eq i32 %9586, 2
  %9588 = zext i1 %9587 to i8
  store i8 %9588, i8* %43, align 1
  %9589 = sext i32 %9562 to i64
  store i64 %9589, i64* %RCX.i1197, align 8
  %9590 = shl nsw i64 %9589, 3
  %9591 = add i64 %9552, %9590
  %9592 = add i64 %9547, 36
  store i64 %9592, i64* %3, align 8
  %9593 = inttoptr i64 %9591 to i64*
  %9594 = load i64, i64* %9593, align 8
  store i64 %9594, i64* %RAX.i893, align 8
  store i64 %9548, i64* %RCX.i1197, align 8
  %9595 = add i64 %9548, 148
  %9596 = add i64 %9547, 50
  store i64 %9596, i64* %3, align 8
  %9597 = inttoptr i64 %9595 to i32*
  %9598 = load i32, i32* %9597, align 4
  %9599 = zext i32 %9598 to i64
  store i64 %9599, i64* %RDX.i1708, align 8
  %9600 = add i64 %9547, 53
  store i64 %9600, i64* %3, align 8
  %9601 = load i32, i32* %9522, align 4
  %9602 = add i32 %9601, %9598
  %9603 = zext i32 %9602 to i64
  store i64 %9603, i64* %RDX.i1708, align 8
  %9604 = icmp ult i32 %9602, %9598
  %9605 = icmp ult i32 %9602, %9601
  %9606 = or i1 %9604, %9605
  %9607 = zext i1 %9606 to i8
  store i8 %9607, i8* %19, align 1
  %9608 = and i32 %9602, 255
  %9609 = tail call i32 @llvm.ctpop.i32(i32 %9608)
  %9610 = trunc i32 %9609 to i8
  %9611 = and i8 %9610, 1
  %9612 = xor i8 %9611, 1
  store i8 %9612, i8* %26, align 1
  %9613 = xor i32 %9601, %9598
  %9614 = xor i32 %9613, %9602
  %9615 = lshr i32 %9614, 4
  %9616 = trunc i32 %9615 to i8
  %9617 = and i8 %9616, 1
  store i8 %9617, i8* %31, align 1
  %9618 = icmp eq i32 %9602, 0
  %9619 = zext i1 %9618 to i8
  store i8 %9619, i8* %34, align 1
  %9620 = lshr i32 %9602, 31
  %9621 = trunc i32 %9620 to i8
  store i8 %9621, i8* %37, align 1
  %9622 = lshr i32 %9598, 31
  %9623 = lshr i32 %9601, 31
  %9624 = xor i32 %9620, %9622
  %9625 = xor i32 %9620, %9623
  %9626 = add nuw nsw i32 %9624, %9625
  %9627 = icmp eq i32 %9626, 2
  %9628 = zext i1 %9627 to i8
  store i8 %9628, i8* %43, align 1
  %9629 = sext i32 %9602 to i64
  store i64 %9629, i64* %RCX.i1197, align 8
  %9630 = shl nsw i64 %9629, 2
  %9631 = add i64 %9594, %9630
  %9632 = add i64 %9547, 59
  store i64 %9632, i64* %3, align 8
  %9633 = inttoptr i64 %9631 to i32*
  %9634 = load i32, i32* %9633, align 4
  %9635 = zext i32 %9634 to i64
  store i64 %9635, i64* %RDX.i1708, align 8
  %9636 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %9636, i64* %RAX.i893, align 8
  %9637 = add i64 %9636, 104
  %9638 = add i64 %9547, 71
  store i64 %9638, i64* %3, align 8
  %9639 = inttoptr i64 %9637 to i64*
  %9640 = load i64, i64* %9639, align 8
  store i64 %9640, i64* %RAX.i893, align 8
  store i64 %9636, i64* %RCX.i1197, align 8
  %9641 = add i64 %9636, 144
  %9642 = add i64 %9547, 85
  store i64 %9642, i64* %3, align 8
  %9643 = inttoptr i64 %9641 to i32*
  %9644 = load i32, i32* %9643, align 4
  %9645 = zext i32 %9644 to i64
  store i64 %9645, i64* %RSI.i4020.pre-phi, align 8
  %9646 = load i64, i64* %RBP.i, align 8
  %9647 = add i64 %9646, -12
  %9648 = add i64 %9547, 88
  store i64 %9648, i64* %3, align 8
  %9649 = inttoptr i64 %9647 to i32*
  %9650 = load i32, i32* %9649, align 4
  %9651 = add i32 %9650, %9644
  %9652 = zext i32 %9651 to i64
  store i64 %9652, i64* %RSI.i4020.pre-phi, align 8
  %9653 = icmp ult i32 %9651, %9644
  %9654 = icmp ult i32 %9651, %9650
  %9655 = or i1 %9653, %9654
  %9656 = zext i1 %9655 to i8
  store i8 %9656, i8* %19, align 1
  %9657 = and i32 %9651, 255
  %9658 = tail call i32 @llvm.ctpop.i32(i32 %9657)
  %9659 = trunc i32 %9658 to i8
  %9660 = and i8 %9659, 1
  %9661 = xor i8 %9660, 1
  store i8 %9661, i8* %26, align 1
  %9662 = xor i32 %9650, %9644
  %9663 = xor i32 %9662, %9651
  %9664 = lshr i32 %9663, 4
  %9665 = trunc i32 %9664 to i8
  %9666 = and i8 %9665, 1
  store i8 %9666, i8* %31, align 1
  %9667 = icmp eq i32 %9651, 0
  %9668 = zext i1 %9667 to i8
  store i8 %9668, i8* %34, align 1
  %9669 = lshr i32 %9651, 31
  %9670 = trunc i32 %9669 to i8
  store i8 %9670, i8* %37, align 1
  %9671 = lshr i32 %9644, 31
  %9672 = lshr i32 %9650, 31
  %9673 = xor i32 %9669, %9671
  %9674 = xor i32 %9669, %9672
  %9675 = add nuw nsw i32 %9673, %9674
  %9676 = icmp eq i32 %9675, 2
  %9677 = zext i1 %9676 to i8
  store i8 %9677, i8* %43, align 1
  %9678 = sext i32 %9651 to i64
  store i64 %9678, i64* %RCX.i1197, align 8
  %9679 = shl nsw i64 %9678, 3
  %9680 = add i64 %9640, %9679
  %9681 = add i64 %9547, 95
  store i64 %9681, i64* %3, align 8
  %9682 = inttoptr i64 %9680 to i64*
  %9683 = load i64, i64* %9682, align 8
  store i64 %9683, i64* %RAX.i893, align 8
  store i64 %9636, i64* %RCX.i1197, align 8
  %9684 = add i64 %9636, 148
  %9685 = add i64 %9547, 109
  store i64 %9685, i64* %3, align 8
  %9686 = inttoptr i64 %9684 to i32*
  %9687 = load i32, i32* %9686, align 4
  %9688 = zext i32 %9687 to i64
  store i64 %9688, i64* %RSI.i4020.pre-phi, align 8
  %9689 = add i64 %9646, -16
  %9690 = add i64 %9547, 112
  store i64 %9690, i64* %3, align 8
  %9691 = inttoptr i64 %9689 to i32*
  %9692 = load i32, i32* %9691, align 4
  %9693 = add i32 %9692, %9687
  %9694 = zext i32 %9693 to i64
  store i64 %9694, i64* %RSI.i4020.pre-phi, align 8
  %9695 = icmp ult i32 %9693, %9687
  %9696 = icmp ult i32 %9693, %9692
  %9697 = or i1 %9695, %9696
  %9698 = zext i1 %9697 to i8
  store i8 %9698, i8* %19, align 1
  %9699 = and i32 %9693, 255
  %9700 = tail call i32 @llvm.ctpop.i32(i32 %9699)
  %9701 = trunc i32 %9700 to i8
  %9702 = and i8 %9701, 1
  %9703 = xor i8 %9702, 1
  store i8 %9703, i8* %26, align 1
  %9704 = xor i32 %9692, %9687
  %9705 = xor i32 %9704, %9693
  %9706 = lshr i32 %9705, 4
  %9707 = trunc i32 %9706 to i8
  %9708 = and i8 %9707, 1
  store i8 %9708, i8* %31, align 1
  %9709 = icmp eq i32 %9693, 0
  %9710 = zext i1 %9709 to i8
  store i8 %9710, i8* %34, align 1
  %9711 = lshr i32 %9693, 31
  %9712 = trunc i32 %9711 to i8
  store i8 %9712, i8* %37, align 1
  %9713 = lshr i32 %9687, 31
  %9714 = lshr i32 %9692, 31
  %9715 = xor i32 %9711, %9713
  %9716 = xor i32 %9711, %9714
  %9717 = add nuw nsw i32 %9715, %9716
  %9718 = icmp eq i32 %9717, 2
  %9719 = zext i1 %9718 to i8
  store i8 %9719, i8* %43, align 1
  %9720 = sext i32 %9693 to i64
  store i64 %9720, i64* %RCX.i1197, align 8
  %9721 = shl nsw i64 %9720, 2
  %9722 = add i64 %9683, %9721
  %9723 = load i32, i32* %EDX.i1723, align 4
  %9724 = add i64 %9547, 118
  store i64 %9724, i64* %3, align 8
  %9725 = inttoptr i64 %9722 to i32*
  store i32 %9723, i32* %9725, align 4
  %9726 = load i64, i64* %RBP.i, align 8
  %9727 = add i64 %9726, -56
  %9728 = load i64, i64* %3, align 8
  %9729 = add i64 %9728, 4
  store i64 %9729, i64* %3, align 8
  %9730 = inttoptr i64 %9727 to i64*
  %9731 = load i64, i64* %9730, align 8
  store i64 %9731, i64* %RAX.i893, align 8
  %9732 = add i64 %9726, -20
  %9733 = add i64 %9728, 8
  store i64 %9733, i64* %3, align 8
  %9734 = inttoptr i64 %9732 to i32*
  %9735 = load i32, i32* %9734, align 4
  %9736 = sext i32 %9735 to i64
  store i64 %9736, i64* %RCX.i1197, align 8
  %9737 = shl nsw i64 %9736, 2
  %9738 = add i64 %9731, 396
  %9739 = add i64 %9738, %9737
  %9740 = add i64 %9728, 15
  store i64 %9740, i64* %3, align 8
  %9741 = inttoptr i64 %9739 to i32*
  %9742 = load i32, i32* %9741, align 4
  %9743 = zext i32 %9742 to i64
  store i64 %9743, i64* %RDX.i1708, align 8
  %9744 = add i64 %9728, 19
  store i64 %9744, i64* %3, align 8
  %9745 = load i64, i64* %9730, align 8
  store i64 %9745, i64* %RAX.i893, align 8
  %9746 = add i64 %9728, 23
  store i64 %9746, i64* %3, align 8
  %9747 = load i32, i32* %9734, align 4
  %9748 = sext i32 %9747 to i64
  store i64 %9748, i64* %RCX.i1197, align 8
  %9749 = shl nsw i64 %9748, 2
  %9750 = add i64 %9745, 332
  %9751 = add i64 %9750, %9749
  %9752 = add i64 %9728, 30
  store i64 %9752, i64* %3, align 8
  %9753 = inttoptr i64 %9751 to i32*
  store i32 %9742, i32* %9753, align 4
  %9754 = load i64, i64* %RBP.i, align 8
  %9755 = add i64 %9754, -16
  %9756 = load i64, i64* %3, align 8
  %9757 = add i64 %9756, 3
  store i64 %9757, i64* %3, align 8
  %9758 = inttoptr i64 %9755 to i32*
  %9759 = load i32, i32* %9758, align 4
  %9760 = add i32 %9759, 1
  %9761 = zext i32 %9760 to i64
  store i64 %9761, i64* %RAX.i893, align 8
  %9762 = icmp eq i32 %9759, -1
  %9763 = icmp eq i32 %9760, 0
  %9764 = or i1 %9762, %9763
  %9765 = zext i1 %9764 to i8
  store i8 %9765, i8* %19, align 1
  %9766 = and i32 %9760, 255
  %9767 = tail call i32 @llvm.ctpop.i32(i32 %9766)
  %9768 = trunc i32 %9767 to i8
  %9769 = and i8 %9768, 1
  %9770 = xor i8 %9769, 1
  store i8 %9770, i8* %26, align 1
  %9771 = xor i32 %9760, %9759
  %9772 = lshr i32 %9771, 4
  %9773 = trunc i32 %9772 to i8
  %9774 = and i8 %9773, 1
  store i8 %9774, i8* %31, align 1
  %9775 = zext i1 %9763 to i8
  store i8 %9775, i8* %34, align 1
  %9776 = lshr i32 %9760, 31
  %9777 = trunc i32 %9776 to i8
  store i8 %9777, i8* %37, align 1
  %9778 = lshr i32 %9759, 31
  %9779 = xor i32 %9776, %9778
  %9780 = add nuw nsw i32 %9779, %9776
  %9781 = icmp eq i32 %9780, 2
  %9782 = zext i1 %9781 to i8
  store i8 %9782, i8* %43, align 1
  %9783 = add i64 %9756, 9
  store i64 %9783, i64* %3, align 8
  store i32 %9760, i32* %9758, align 4
  %9784 = load i64, i64* %RBP.i, align 8
  %9785 = add i64 %9784, -20
  %9786 = load i64, i64* %3, align 8
  %9787 = add i64 %9786, 3
  store i64 %9787, i64* %3, align 8
  %9788 = inttoptr i64 %9785 to i32*
  %9789 = load i32, i32* %9788, align 4
  %9790 = add i32 %9789, 1
  %9791 = zext i32 %9790 to i64
  store i64 %9791, i64* %RAX.i893, align 8
  %9792 = icmp eq i32 %9789, -1
  %9793 = icmp eq i32 %9790, 0
  %9794 = or i1 %9792, %9793
  %9795 = zext i1 %9794 to i8
  store i8 %9795, i8* %19, align 1
  %9796 = and i32 %9790, 255
  %9797 = tail call i32 @llvm.ctpop.i32(i32 %9796)
  %9798 = trunc i32 %9797 to i8
  %9799 = and i8 %9798, 1
  %9800 = xor i8 %9799, 1
  store i8 %9800, i8* %26, align 1
  %9801 = xor i32 %9790, %9789
  %9802 = lshr i32 %9801, 4
  %9803 = trunc i32 %9802 to i8
  %9804 = and i8 %9803, 1
  store i8 %9804, i8* %31, align 1
  %9805 = zext i1 %9793 to i8
  store i8 %9805, i8* %34, align 1
  %9806 = lshr i32 %9790, 31
  %9807 = trunc i32 %9806 to i8
  store i8 %9807, i8* %37, align 1
  %9808 = lshr i32 %9789, 31
  %9809 = xor i32 %9806, %9808
  %9810 = add nuw nsw i32 %9809, %9806
  %9811 = icmp eq i32 %9810, 2
  %9812 = zext i1 %9811 to i8
  store i8 %9812, i8* %43, align 1
  %9813 = add i64 %9786, 9
  store i64 %9813, i64* %3, align 8
  store i32 %9790, i32* %9788, align 4
  %9814 = load i64, i64* %3, align 8
  %9815 = add i64 %9814, -176
  store i64 %9815, i64* %3, align 8
  br label %block_.L_48f669

block_.L_48f71e:                                  ; preds = %block_.L_48f669
  %9816 = add i64 %9519, -12
  %9817 = add i64 %9547, 8
  store i64 %9817, i64* %3, align 8
  %9818 = inttoptr i64 %9816 to i32*
  %9819 = load i32, i32* %9818, align 4
  %9820 = add i32 %9819, 1
  %9821 = zext i32 %9820 to i64
  store i64 %9821, i64* %RAX.i893, align 8
  %9822 = icmp eq i32 %9819, -1
  %9823 = icmp eq i32 %9820, 0
  %9824 = or i1 %9822, %9823
  %9825 = zext i1 %9824 to i8
  store i8 %9825, i8* %19, align 1
  %9826 = and i32 %9820, 255
  %9827 = tail call i32 @llvm.ctpop.i32(i32 %9826)
  %9828 = trunc i32 %9827 to i8
  %9829 = and i8 %9828, 1
  %9830 = xor i8 %9829, 1
  store i8 %9830, i8* %26, align 1
  %9831 = xor i32 %9820, %9819
  %9832 = lshr i32 %9831, 4
  %9833 = trunc i32 %9832 to i8
  %9834 = and i8 %9833, 1
  store i8 %9834, i8* %31, align 1
  %9835 = zext i1 %9823 to i8
  store i8 %9835, i8* %34, align 1
  %9836 = lshr i32 %9820, 31
  %9837 = trunc i32 %9836 to i8
  store i8 %9837, i8* %37, align 1
  %9838 = lshr i32 %9819, 31
  %9839 = xor i32 %9836, %9838
  %9840 = add nuw nsw i32 %9839, %9836
  %9841 = icmp eq i32 %9840, 2
  %9842 = zext i1 %9841 to i8
  store i8 %9842, i8* %43, align 1
  %9843 = add i64 %9547, 14
  store i64 %9843, i64* %3, align 8
  store i32 %9820, i32* %9818, align 4
  %9844 = load i64, i64* %3, align 8
  %9845 = add i64 %9844, -212
  store i64 %9845, i64* %3, align 8
  br label %block_.L_48f658

block_.L_48f731:                                  ; preds = %block_.L_48f658
  %9846 = add i64 %9514, 431
  br label %block_.L_48f8e0

block_.L_48f736:                                  ; preds = %block_.L_48f616
  %9847 = add i64 %9445, -60
  %9848 = add i64 %9476, 4
  store i64 %9848, i64* %3, align 8
  %9849 = inttoptr i64 %9847 to i32*
  %9850 = load i32, i32* %9849, align 4
  %9851 = add i32 %9850, -9
  %9852 = icmp ult i32 %9850, 9
  %9853 = zext i1 %9852 to i8
  store i8 %9853, i8* %19, align 1
  %9854 = and i32 %9851, 255
  %9855 = tail call i32 @llvm.ctpop.i32(i32 %9854)
  %9856 = trunc i32 %9855 to i8
  %9857 = and i8 %9856, 1
  %9858 = xor i8 %9857, 1
  store i8 %9858, i8* %26, align 1
  %9859 = xor i32 %9851, %9850
  %9860 = lshr i32 %9859, 4
  %9861 = trunc i32 %9860 to i8
  %9862 = and i8 %9861, 1
  store i8 %9862, i8* %31, align 1
  %9863 = icmp eq i32 %9851, 0
  %9864 = zext i1 %9863 to i8
  store i8 %9864, i8* %34, align 1
  %9865 = lshr i32 %9851, 31
  %9866 = trunc i32 %9865 to i8
  store i8 %9866, i8* %37, align 1
  %9867 = lshr i32 %9850, 31
  %9868 = xor i32 %9865, %9867
  %9869 = add nuw nsw i32 %9868, %9867
  %9870 = icmp eq i32 %9869, 2
  %9871 = zext i1 %9870 to i8
  store i8 %9871, i8* %43, align 1
  %.v320 = select i1 %9863, i64 206, i64 10
  %9872 = add i64 %9476, %.v320
  store i64 %9872, i64* %3, align 8
  br i1 %9863, label %block_.L_48f804, label %block_48f740

block_48f740:                                     ; preds = %block_.L_48f736
  %9873 = add i64 %9872, 4
  store i64 %9873, i64* %3, align 8
  %9874 = load i32, i32* %9849, align 4
  %9875 = add i32 %9874, -13
  %9876 = icmp ult i32 %9874, 13
  %9877 = zext i1 %9876 to i8
  store i8 %9877, i8* %19, align 1
  %9878 = and i32 %9875, 255
  %9879 = tail call i32 @llvm.ctpop.i32(i32 %9878)
  %9880 = trunc i32 %9879 to i8
  %9881 = and i8 %9880, 1
  %9882 = xor i8 %9881, 1
  store i8 %9882, i8* %26, align 1
  %9883 = xor i32 %9875, %9874
  %9884 = lshr i32 %9883, 4
  %9885 = trunc i32 %9884 to i8
  %9886 = and i8 %9885, 1
  store i8 %9886, i8* %31, align 1
  %9887 = icmp eq i32 %9875, 0
  %9888 = zext i1 %9887 to i8
  store i8 %9888, i8* %34, align 1
  %9889 = lshr i32 %9875, 31
  %9890 = trunc i32 %9889 to i8
  store i8 %9890, i8* %37, align 1
  %9891 = lshr i32 %9874, 31
  %9892 = xor i32 %9889, %9891
  %9893 = add nuw nsw i32 %9892, %9891
  %9894 = icmp eq i32 %9893, 2
  %9895 = zext i1 %9894 to i8
  store i8 %9895, i8* %43, align 1
  %.v321 = select i1 %9887, i64 196, i64 10
  %9896 = add i64 %9872, %.v321
  store i64 %9896, i64* %3, align 8
  br i1 %9887, label %block_.L_48f804, label %block_48f74a

block_48f74a:                                     ; preds = %block_48f740
  %9897 = add i64 %9445, -20
  %9898 = add i64 %9896, 7
  store i64 %9898, i64* %3, align 8
  %9899 = inttoptr i64 %9897 to i32*
  store i32 0, i32* %9899, align 4
  %9900 = load i64, i64* %3, align 8
  %9901 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %9901, i64* %RAX.i893, align 8
  %9902 = add i64 %9901, 148
  %9903 = add i64 %9900, 14
  store i64 %9903, i64* %3, align 8
  %9904 = inttoptr i64 %9902 to i32*
  %9905 = load i32, i32* %9904, align 4
  %9906 = zext i32 %9905 to i64
  store i64 %9906, i64* %RCX.i1197, align 8
  %9907 = load i64, i64* %RBP.i, align 8
  %9908 = add i64 %9907, -16
  %9909 = add i64 %9900, 17
  store i64 %9909, i64* %3, align 8
  %9910 = inttoptr i64 %9908 to i32*
  store i32 %9905, i32* %9910, align 4
  %.pre235 = load i64, i64* %3, align 8
  br label %block_.L_48f762

block_.L_48f762:                                  ; preds = %block_.L_48f7ec, %block_48f74a
  %9911 = phi i64 [ %10129, %block_.L_48f7ec ], [ %.pre235, %block_48f74a ]
  %9912 = load i64, i64* %RBP.i, align 8
  %9913 = add i64 %9912, -16
  %9914 = add i64 %9911, 3
  store i64 %9914, i64* %3, align 8
  %9915 = inttoptr i64 %9913 to i32*
  %9916 = load i32, i32* %9915, align 4
  %9917 = zext i32 %9916 to i64
  store i64 %9917, i64* %RAX.i893, align 8
  %9918 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %9918, i64* %RCX.i1197, align 8
  %9919 = add i64 %9918, 148
  %9920 = add i64 %9911, 17
  store i64 %9920, i64* %3, align 8
  %9921 = inttoptr i64 %9919 to i32*
  %9922 = load i32, i32* %9921, align 4
  %9923 = add i32 %9922, 4
  %9924 = zext i32 %9923 to i64
  store i64 %9924, i64* %RDX.i1708, align 8
  %9925 = lshr i32 %9923, 31
  %9926 = sub i32 %9916, %9923
  %9927 = icmp ult i32 %9916, %9923
  %9928 = zext i1 %9927 to i8
  store i8 %9928, i8* %19, align 1
  %9929 = and i32 %9926, 255
  %9930 = tail call i32 @llvm.ctpop.i32(i32 %9929)
  %9931 = trunc i32 %9930 to i8
  %9932 = and i8 %9931, 1
  %9933 = xor i8 %9932, 1
  store i8 %9933, i8* %26, align 1
  %9934 = xor i32 %9923, %9916
  %9935 = xor i32 %9934, %9926
  %9936 = lshr i32 %9935, 4
  %9937 = trunc i32 %9936 to i8
  %9938 = and i8 %9937, 1
  store i8 %9938, i8* %31, align 1
  %9939 = icmp eq i32 %9926, 0
  %9940 = zext i1 %9939 to i8
  store i8 %9940, i8* %34, align 1
  %9941 = lshr i32 %9926, 31
  %9942 = trunc i32 %9941 to i8
  store i8 %9942, i8* %37, align 1
  %9943 = lshr i32 %9916, 31
  %9944 = xor i32 %9925, %9943
  %9945 = xor i32 %9941, %9943
  %9946 = add nuw nsw i32 %9945, %9944
  %9947 = icmp eq i32 %9946, 2
  %9948 = zext i1 %9947 to i8
  store i8 %9948, i8* %43, align 1
  %9949 = icmp ne i8 %9942, 0
  %9950 = xor i1 %9949, %9947
  %.v322 = select i1 %9950, i64 28, i64 157
  %9951 = add i64 %9911, %.v322
  store i64 %9951, i64* %3, align 8
  br i1 %9950, label %block_48f77e, label %block_.L_48f7ff

block_48f77e:                                     ; preds = %block_.L_48f762
  store i64 %9918, i64* %RAX.i893, align 8
  %9952 = add i64 %9918, 144
  %9953 = add i64 %9951, 14
  store i64 %9953, i64* %3, align 8
  %9954 = inttoptr i64 %9952 to i32*
  %9955 = load i32, i32* %9954, align 4
  %9956 = zext i32 %9955 to i64
  store i64 %9956, i64* %RCX.i1197, align 8
  %9957 = add i64 %9912, -12
  %9958 = add i64 %9951, 17
  store i64 %9958, i64* %3, align 8
  %9959 = inttoptr i64 %9957 to i32*
  store i32 %9955, i32* %9959, align 4
  %.pre236 = load i64, i64* %3, align 8
  br label %block_.L_48f78f

block_.L_48f78f:                                  ; preds = %block_48f7ab, %block_48f77e
  %9960 = phi i64 [ %10099, %block_48f7ab ], [ %.pre236, %block_48f77e ]
  %9961 = load i64, i64* %RBP.i, align 8
  %9962 = add i64 %9961, -12
  %9963 = add i64 %9960, 3
  store i64 %9963, i64* %3, align 8
  %9964 = inttoptr i64 %9962 to i32*
  %9965 = load i32, i32* %9964, align 4
  %9966 = zext i32 %9965 to i64
  store i64 %9966, i64* %RAX.i893, align 8
  %9967 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %9967, i64* %RCX.i1197, align 8
  %9968 = add i64 %9967, 144
  %9969 = add i64 %9960, 17
  store i64 %9969, i64* %3, align 8
  %9970 = inttoptr i64 %9968 to i32*
  %9971 = load i32, i32* %9970, align 4
  %9972 = add i32 %9971, 4
  %9973 = zext i32 %9972 to i64
  store i64 %9973, i64* %RDX.i1708, align 8
  %9974 = lshr i32 %9972, 31
  %9975 = sub i32 %9965, %9972
  %9976 = icmp ult i32 %9965, %9972
  %9977 = zext i1 %9976 to i8
  store i8 %9977, i8* %19, align 1
  %9978 = and i32 %9975, 255
  %9979 = tail call i32 @llvm.ctpop.i32(i32 %9978)
  %9980 = trunc i32 %9979 to i8
  %9981 = and i8 %9980, 1
  %9982 = xor i8 %9981, 1
  store i8 %9982, i8* %26, align 1
  %9983 = xor i32 %9972, %9965
  %9984 = xor i32 %9983, %9975
  %9985 = lshr i32 %9984, 4
  %9986 = trunc i32 %9985 to i8
  %9987 = and i8 %9986, 1
  store i8 %9987, i8* %31, align 1
  %9988 = icmp eq i32 %9975, 0
  %9989 = zext i1 %9988 to i8
  store i8 %9989, i8* %34, align 1
  %9990 = lshr i32 %9975, 31
  %9991 = trunc i32 %9990 to i8
  store i8 %9991, i8* %37, align 1
  %9992 = lshr i32 %9965, 31
  %9993 = xor i32 %9974, %9992
  %9994 = xor i32 %9990, %9992
  %9995 = add nuw nsw i32 %9994, %9993
  %9996 = icmp eq i32 %9995, 2
  %9997 = zext i1 %9996 to i8
  store i8 %9997, i8* %43, align 1
  %9998 = icmp ne i8 %9991, 0
  %9999 = xor i1 %9998, %9996
  %.v293 = select i1 %9999, i64 28, i64 93
  %10000 = add i64 %9960, %.v293
  store i64 %10000, i64* %3, align 8
  br i1 %9999, label %block_48f7ab, label %block_.L_48f7ec

block_48f7ab:                                     ; preds = %block_.L_48f78f
  %10001 = add i64 %9961, -72
  %10002 = add i64 %10000, 4
  store i64 %10002, i64* %3, align 8
  %10003 = inttoptr i64 %10001 to i64*
  %10004 = load i64, i64* %10003, align 8
  store i64 %10004, i64* %RAX.i893, align 8
  %10005 = add i64 %10000, 8
  store i64 %10005, i64* %3, align 8
  %10006 = load i32, i32* %9964, align 4
  %10007 = sext i32 %10006 to i64
  store i64 %10007, i64* %RCX.i1197, align 8
  %10008 = shl nsw i64 %10007, 3
  %10009 = add i64 %10008, %10004
  %10010 = add i64 %10000, 12
  store i64 %10010, i64* %3, align 8
  %10011 = inttoptr i64 %10009 to i64*
  %10012 = load i64, i64* %10011, align 8
  store i64 %10012, i64* %RAX.i893, align 8
  %10013 = add i64 %9961, -16
  %10014 = add i64 %10000, 16
  store i64 %10014, i64* %3, align 8
  %10015 = inttoptr i64 %10013 to i32*
  %10016 = load i32, i32* %10015, align 4
  %10017 = sext i32 %10016 to i64
  store i64 %10017, i64* %RCX.i1197, align 8
  %10018 = shl nsw i64 %10017, 2
  %10019 = add i64 %10018, %10012
  %10020 = add i64 %10000, 23
  store i64 %10020, i64* %3, align 8
  %10021 = inttoptr i64 %10019 to i32*
  store i32 2, i32* %10021, align 4
  %10022 = load i64, i64* %RBP.i, align 8
  %10023 = add i64 %10022, -56
  %10024 = load i64, i64* %3, align 8
  %10025 = add i64 %10024, 4
  store i64 %10025, i64* %3, align 8
  %10026 = inttoptr i64 %10023 to i64*
  %10027 = load i64, i64* %10026, align 8
  store i64 %10027, i64* %RAX.i893, align 8
  %10028 = add i64 %10022, -20
  %10029 = add i64 %10024, 8
  store i64 %10029, i64* %3, align 8
  %10030 = inttoptr i64 %10028 to i32*
  %10031 = load i32, i32* %10030, align 4
  %10032 = sext i32 %10031 to i64
  store i64 %10032, i64* %RCX.i1197, align 8
  %10033 = shl nsw i64 %10032, 2
  %10034 = add i64 %10027, 332
  %10035 = add i64 %10034, %10033
  %10036 = add i64 %10024, 19
  store i64 %10036, i64* %3, align 8
  %10037 = inttoptr i64 %10035 to i32*
  store i32 2, i32* %10037, align 4
  %10038 = load i64, i64* %RBP.i, align 8
  %10039 = add i64 %10038, -12
  %10040 = load i64, i64* %3, align 8
  %10041 = add i64 %10040, 3
  store i64 %10041, i64* %3, align 8
  %10042 = inttoptr i64 %10039 to i32*
  %10043 = load i32, i32* %10042, align 4
  %10044 = add i32 %10043, 1
  %10045 = zext i32 %10044 to i64
  store i64 %10045, i64* %RAX.i893, align 8
  %10046 = icmp eq i32 %10043, -1
  %10047 = icmp eq i32 %10044, 0
  %10048 = or i1 %10046, %10047
  %10049 = zext i1 %10048 to i8
  store i8 %10049, i8* %19, align 1
  %10050 = and i32 %10044, 255
  %10051 = tail call i32 @llvm.ctpop.i32(i32 %10050)
  %10052 = trunc i32 %10051 to i8
  %10053 = and i8 %10052, 1
  %10054 = xor i8 %10053, 1
  store i8 %10054, i8* %26, align 1
  %10055 = xor i32 %10044, %10043
  %10056 = lshr i32 %10055, 4
  %10057 = trunc i32 %10056 to i8
  %10058 = and i8 %10057, 1
  store i8 %10058, i8* %31, align 1
  %10059 = zext i1 %10047 to i8
  store i8 %10059, i8* %34, align 1
  %10060 = lshr i32 %10044, 31
  %10061 = trunc i32 %10060 to i8
  store i8 %10061, i8* %37, align 1
  %10062 = lshr i32 %10043, 31
  %10063 = xor i32 %10060, %10062
  %10064 = add nuw nsw i32 %10063, %10060
  %10065 = icmp eq i32 %10064, 2
  %10066 = zext i1 %10065 to i8
  store i8 %10066, i8* %43, align 1
  %10067 = add i64 %10040, 9
  store i64 %10067, i64* %3, align 8
  store i32 %10044, i32* %10042, align 4
  %10068 = load i64, i64* %RBP.i, align 8
  %10069 = add i64 %10068, -20
  %10070 = load i64, i64* %3, align 8
  %10071 = add i64 %10070, 3
  store i64 %10071, i64* %3, align 8
  %10072 = inttoptr i64 %10069 to i32*
  %10073 = load i32, i32* %10072, align 4
  %10074 = add i32 %10073, 1
  %10075 = zext i32 %10074 to i64
  store i64 %10075, i64* %RAX.i893, align 8
  %10076 = icmp eq i32 %10073, -1
  %10077 = icmp eq i32 %10074, 0
  %10078 = or i1 %10076, %10077
  %10079 = zext i1 %10078 to i8
  store i8 %10079, i8* %19, align 1
  %10080 = and i32 %10074, 255
  %10081 = tail call i32 @llvm.ctpop.i32(i32 %10080)
  %10082 = trunc i32 %10081 to i8
  %10083 = and i8 %10082, 1
  %10084 = xor i8 %10083, 1
  store i8 %10084, i8* %26, align 1
  %10085 = xor i32 %10074, %10073
  %10086 = lshr i32 %10085, 4
  %10087 = trunc i32 %10086 to i8
  %10088 = and i8 %10087, 1
  store i8 %10088, i8* %31, align 1
  %10089 = zext i1 %10077 to i8
  store i8 %10089, i8* %34, align 1
  %10090 = lshr i32 %10074, 31
  %10091 = trunc i32 %10090 to i8
  store i8 %10091, i8* %37, align 1
  %10092 = lshr i32 %10073, 31
  %10093 = xor i32 %10090, %10092
  %10094 = add nuw nsw i32 %10093, %10090
  %10095 = icmp eq i32 %10094, 2
  %10096 = zext i1 %10095 to i8
  store i8 %10096, i8* %43, align 1
  %10097 = add i64 %10070, 9
  store i64 %10097, i64* %3, align 8
  store i32 %10074, i32* %10072, align 4
  %10098 = load i64, i64* %3, align 8
  %10099 = add i64 %10098, -88
  store i64 %10099, i64* %3, align 8
  br label %block_.L_48f78f

block_.L_48f7ec:                                  ; preds = %block_.L_48f78f
  %10100 = add i64 %9961, -16
  %10101 = add i64 %10000, 8
  store i64 %10101, i64* %3, align 8
  %10102 = inttoptr i64 %10100 to i32*
  %10103 = load i32, i32* %10102, align 4
  %10104 = add i32 %10103, 1
  %10105 = zext i32 %10104 to i64
  store i64 %10105, i64* %RAX.i893, align 8
  %10106 = icmp eq i32 %10103, -1
  %10107 = icmp eq i32 %10104, 0
  %10108 = or i1 %10106, %10107
  %10109 = zext i1 %10108 to i8
  store i8 %10109, i8* %19, align 1
  %10110 = and i32 %10104, 255
  %10111 = tail call i32 @llvm.ctpop.i32(i32 %10110)
  %10112 = trunc i32 %10111 to i8
  %10113 = and i8 %10112, 1
  %10114 = xor i8 %10113, 1
  store i8 %10114, i8* %26, align 1
  %10115 = xor i32 %10104, %10103
  %10116 = lshr i32 %10115, 4
  %10117 = trunc i32 %10116 to i8
  %10118 = and i8 %10117, 1
  store i8 %10118, i8* %31, align 1
  %10119 = zext i1 %10107 to i8
  store i8 %10119, i8* %34, align 1
  %10120 = lshr i32 %10104, 31
  %10121 = trunc i32 %10120 to i8
  store i8 %10121, i8* %37, align 1
  %10122 = lshr i32 %10103, 31
  %10123 = xor i32 %10120, %10122
  %10124 = add nuw nsw i32 %10123, %10120
  %10125 = icmp eq i32 %10124, 2
  %10126 = zext i1 %10125 to i8
  store i8 %10126, i8* %43, align 1
  %10127 = add i64 %10000, 14
  store i64 %10127, i64* %3, align 8
  store i32 %10104, i32* %10102, align 4
  %10128 = load i64, i64* %3, align 8
  %10129 = add i64 %10128, -152
  store i64 %10129, i64* %3, align 8
  br label %block_.L_48f762

block_.L_48f7ff:                                  ; preds = %block_.L_48f762
  %10130 = add i64 %9951, 220
  br label %block_.L_48f8db

block_.L_48f804:                                  ; preds = %block_48f740, %block_.L_48f736
  %10131 = phi i64 [ %9896, %block_48f740 ], [ %9872, %block_.L_48f736 ]
  %10132 = add i64 %10131, 4
  store i64 %10132, i64* %3, align 8
  %10133 = load i32, i32* %9849, align 4
  %10134 = add i32 %10133, -9
  %10135 = icmp ult i32 %10133, 9
  %10136 = zext i1 %10135 to i8
  store i8 %10136, i8* %19, align 1
  %10137 = and i32 %10134, 255
  %10138 = tail call i32 @llvm.ctpop.i32(i32 %10137)
  %10139 = trunc i32 %10138 to i8
  %10140 = and i8 %10139, 1
  %10141 = xor i8 %10140, 1
  store i8 %10141, i8* %26, align 1
  %10142 = xor i32 %10134, %10133
  %10143 = lshr i32 %10142, 4
  %10144 = trunc i32 %10143 to i8
  %10145 = and i8 %10144, 1
  store i8 %10145, i8* %31, align 1
  %10146 = icmp eq i32 %10134, 0
  %10147 = zext i1 %10146 to i8
  store i8 %10147, i8* %34, align 1
  %10148 = lshr i32 %10134, 31
  %10149 = trunc i32 %10148 to i8
  store i8 %10149, i8* %37, align 1
  %10150 = lshr i32 %10133, 31
  %10151 = xor i32 %10148, %10150
  %10152 = add nuw nsw i32 %10151, %10150
  %10153 = icmp eq i32 %10152, 2
  %10154 = zext i1 %10153 to i8
  store i8 %10154, i8* %43, align 1
  %.v327 = select i1 %10146, i64 10, i64 210
  %10155 = add i64 %10131, %.v327
  store i64 %10155, i64* %3, align 8
  br i1 %10146, label %block_48f80e, label %block_.L_48f8d6

block_48f80e:                                     ; preds = %block_.L_48f804
  %10156 = add i64 %9445, -20
  %10157 = add i64 %10155, 7
  store i64 %10157, i64* %3, align 8
  %10158 = inttoptr i64 %10156 to i32*
  store i32 0, i32* %10158, align 4
  %10159 = load i64, i64* %3, align 8
  %10160 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10160, i64* %RAX.i893, align 8
  %10161 = add i64 %10160, 148
  %10162 = add i64 %10159, 14
  store i64 %10162, i64* %3, align 8
  %10163 = inttoptr i64 %10161 to i32*
  %10164 = load i32, i32* %10163, align 4
  %10165 = zext i32 %10164 to i64
  store i64 %10165, i64* %RCX.i1197, align 8
  %10166 = load i64, i64* %RBP.i, align 8
  %10167 = add i64 %10166, -16
  %10168 = add i64 %10159, 17
  store i64 %10168, i64* %3, align 8
  %10169 = inttoptr i64 %10167 to i32*
  store i32 %10164, i32* %10169, align 4
  %.pre237 = load i64, i64* %3, align 8
  br label %block_.L_48f826

block_.L_48f826:                                  ; preds = %block_.L_48f8be, %block_48f80e
  %10170 = phi i64 [ %10408, %block_.L_48f8be ], [ %.pre237, %block_48f80e ]
  %10171 = load i64, i64* %RBP.i, align 8
  %10172 = add i64 %10171, -16
  %10173 = add i64 %10170, 3
  store i64 %10173, i64* %3, align 8
  %10174 = inttoptr i64 %10172 to i32*
  %10175 = load i32, i32* %10174, align 4
  %10176 = zext i32 %10175 to i64
  store i64 %10176, i64* %RAX.i893, align 8
  %10177 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10177, i64* %RCX.i1197, align 8
  %10178 = add i64 %10177, 148
  %10179 = add i64 %10170, 17
  store i64 %10179, i64* %3, align 8
  %10180 = inttoptr i64 %10178 to i32*
  %10181 = load i32, i32* %10180, align 4
  %10182 = add i32 %10181, 4
  %10183 = zext i32 %10182 to i64
  store i64 %10183, i64* %RDX.i1708, align 8
  %10184 = lshr i32 %10182, 31
  %10185 = sub i32 %10175, %10182
  %10186 = icmp ult i32 %10175, %10182
  %10187 = zext i1 %10186 to i8
  store i8 %10187, i8* %19, align 1
  %10188 = and i32 %10185, 255
  %10189 = tail call i32 @llvm.ctpop.i32(i32 %10188)
  %10190 = trunc i32 %10189 to i8
  %10191 = and i8 %10190, 1
  %10192 = xor i8 %10191, 1
  store i8 %10192, i8* %26, align 1
  %10193 = xor i32 %10182, %10175
  %10194 = xor i32 %10193, %10185
  %10195 = lshr i32 %10194, 4
  %10196 = trunc i32 %10195 to i8
  %10197 = and i8 %10196, 1
  store i8 %10197, i8* %31, align 1
  %10198 = icmp eq i32 %10185, 0
  %10199 = zext i1 %10198 to i8
  store i8 %10199, i8* %34, align 1
  %10200 = lshr i32 %10185, 31
  %10201 = trunc i32 %10200 to i8
  store i8 %10201, i8* %37, align 1
  %10202 = lshr i32 %10175, 31
  %10203 = xor i32 %10184, %10202
  %10204 = xor i32 %10200, %10202
  %10205 = add nuw nsw i32 %10204, %10203
  %10206 = icmp eq i32 %10205, 2
  %10207 = zext i1 %10206 to i8
  store i8 %10207, i8* %43, align 1
  %10208 = icmp ne i8 %10201, 0
  %10209 = xor i1 %10208, %10206
  %.v328 = select i1 %10209, i64 28, i64 171
  %10210 = add i64 %10170, %.v328
  store i64 %10210, i64* %3, align 8
  br i1 %10209, label %block_48f842, label %block_.L_48f8d1

block_48f842:                                     ; preds = %block_.L_48f826
  store i64 %10177, i64* %RAX.i893, align 8
  %10211 = add i64 %10177, 144
  %10212 = add i64 %10210, 14
  store i64 %10212, i64* %3, align 8
  %10213 = inttoptr i64 %10211 to i32*
  %10214 = load i32, i32* %10213, align 4
  %10215 = zext i32 %10214 to i64
  store i64 %10215, i64* %RCX.i1197, align 8
  %10216 = add i64 %10171, -12
  %10217 = add i64 %10210, 17
  store i64 %10217, i64* %3, align 8
  %10218 = inttoptr i64 %10216 to i32*
  store i32 %10214, i32* %10218, align 4
  %.pre238 = load i64, i64* %3, align 8
  br label %block_.L_48f853

block_.L_48f853:                                  ; preds = %block_48f86f, %block_48f842
  %10219 = phi i64 [ %10378, %block_48f86f ], [ %.pre238, %block_48f842 ]
  %10220 = load i64, i64* %RBP.i, align 8
  %10221 = add i64 %10220, -12
  %10222 = add i64 %10219, 3
  store i64 %10222, i64* %3, align 8
  %10223 = inttoptr i64 %10221 to i32*
  %10224 = load i32, i32* %10223, align 4
  %10225 = zext i32 %10224 to i64
  store i64 %10225, i64* %RAX.i893, align 8
  %10226 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10226, i64* %RCX.i1197, align 8
  %10227 = add i64 %10226, 144
  %10228 = add i64 %10219, 17
  store i64 %10228, i64* %3, align 8
  %10229 = inttoptr i64 %10227 to i32*
  %10230 = load i32, i32* %10229, align 4
  %10231 = add i32 %10230, 4
  %10232 = zext i32 %10231 to i64
  store i64 %10232, i64* %RDX.i1708, align 8
  %10233 = lshr i32 %10231, 31
  %10234 = sub i32 %10224, %10231
  %10235 = icmp ult i32 %10224, %10231
  %10236 = zext i1 %10235 to i8
  store i8 %10236, i8* %19, align 1
  %10237 = and i32 %10234, 255
  %10238 = tail call i32 @llvm.ctpop.i32(i32 %10237)
  %10239 = trunc i32 %10238 to i8
  %10240 = and i8 %10239, 1
  %10241 = xor i8 %10240, 1
  store i8 %10241, i8* %26, align 1
  %10242 = xor i32 %10231, %10224
  %10243 = xor i32 %10242, %10234
  %10244 = lshr i32 %10243, 4
  %10245 = trunc i32 %10244 to i8
  %10246 = and i8 %10245, 1
  store i8 %10246, i8* %31, align 1
  %10247 = icmp eq i32 %10234, 0
  %10248 = zext i1 %10247 to i8
  store i8 %10248, i8* %34, align 1
  %10249 = lshr i32 %10234, 31
  %10250 = trunc i32 %10249 to i8
  store i8 %10250, i8* %37, align 1
  %10251 = lshr i32 %10224, 31
  %10252 = xor i32 %10233, %10251
  %10253 = xor i32 %10249, %10251
  %10254 = add nuw nsw i32 %10253, %10252
  %10255 = icmp eq i32 %10254, 2
  %10256 = zext i1 %10255 to i8
  store i8 %10256, i8* %43, align 1
  %10257 = icmp ne i8 %10250, 0
  %10258 = xor i1 %10257, %10255
  %.v294 = select i1 %10258, i64 28, i64 107
  %10259 = add i64 %10219, %.v294
  store i64 %10259, i64* %3, align 8
  br i1 %10258, label %block_48f86f, label %block_.L_48f8be

block_48f86f:                                     ; preds = %block_.L_48f853
  %10260 = add i64 %10220, -20
  %10261 = add i64 %10259, 4
  store i64 %10261, i64* %3, align 8
  %10262 = inttoptr i64 %10260 to i32*
  %10263 = load i32, i32* %10262, align 4
  %10264 = sext i32 %10263 to i64
  store i64 %10264, i64* %RAX.i893, align 8
  %10265 = shl nsw i64 %10264, 2
  %10266 = add nsw i64 %10265, 7485136
  %10267 = add i64 %10259, 11
  store i64 %10267, i64* %3, align 8
  %10268 = inttoptr i64 %10266 to i32*
  %10269 = load i32, i32* %10268, align 4
  %10270 = zext i32 %10269 to i64
  store i64 %10270, i64* %RCX.i1197, align 8
  %10271 = add i64 %10220, -72
  %10272 = add i64 %10259, 15
  store i64 %10272, i64* %3, align 8
  %10273 = inttoptr i64 %10271 to i64*
  %10274 = load i64, i64* %10273, align 8
  store i64 %10274, i64* %RAX.i893, align 8
  %10275 = add i64 %10259, 19
  store i64 %10275, i64* %3, align 8
  %10276 = load i32, i32* %10223, align 4
  %10277 = sext i32 %10276 to i64
  store i64 %10277, i64* %RDX.i1708, align 8
  %10278 = shl nsw i64 %10277, 3
  %10279 = add i64 %10278, %10274
  %10280 = add i64 %10259, 23
  store i64 %10280, i64* %3, align 8
  %10281 = inttoptr i64 %10279 to i64*
  %10282 = load i64, i64* %10281, align 8
  store i64 %10282, i64* %RAX.i893, align 8
  %10283 = add i64 %10220, -16
  %10284 = add i64 %10259, 27
  store i64 %10284, i64* %3, align 8
  %10285 = inttoptr i64 %10283 to i32*
  %10286 = load i32, i32* %10285, align 4
  %10287 = sext i32 %10286 to i64
  store i64 %10287, i64* %RDX.i1708, align 8
  %10288 = shl nsw i64 %10287, 2
  %10289 = add i64 %10288, %10282
  %10290 = add i64 %10259, 30
  store i64 %10290, i64* %3, align 8
  %10291 = inttoptr i64 %10289 to i32*
  store i32 %10269, i32* %10291, align 4
  %10292 = load i64, i64* %RBP.i, align 8
  %10293 = add i64 %10292, -20
  %10294 = load i64, i64* %3, align 8
  %10295 = add i64 %10294, 4
  store i64 %10295, i64* %3, align 8
  %10296 = inttoptr i64 %10293 to i32*
  %10297 = load i32, i32* %10296, align 4
  %10298 = sext i32 %10297 to i64
  store i64 %10298, i64* %RAX.i893, align 8
  %10299 = shl nsw i64 %10298, 2
  %10300 = add nsw i64 %10299, 7393232
  %10301 = add i64 %10294, 11
  store i64 %10301, i64* %3, align 8
  %10302 = inttoptr i64 %10300 to i32*
  %10303 = load i32, i32* %10302, align 4
  %10304 = zext i32 %10303 to i64
  store i64 %10304, i64* %RCX.i1197, align 8
  %10305 = add i64 %10292, -56
  %10306 = add i64 %10294, 15
  store i64 %10306, i64* %3, align 8
  %10307 = inttoptr i64 %10305 to i64*
  %10308 = load i64, i64* %10307, align 8
  store i64 %10308, i64* %RAX.i893, align 8
  %10309 = add i64 %10294, 19
  store i64 %10309, i64* %3, align 8
  %10310 = load i32, i32* %10296, align 4
  %10311 = sext i32 %10310 to i64
  store i64 %10311, i64* %RDX.i1708, align 8
  %10312 = shl nsw i64 %10311, 2
  %10313 = add i64 %10308, 332
  %10314 = add i64 %10313, %10312
  %10315 = add i64 %10294, 26
  store i64 %10315, i64* %3, align 8
  %10316 = inttoptr i64 %10314 to i32*
  store i32 %10303, i32* %10316, align 4
  %10317 = load i64, i64* %RBP.i, align 8
  %10318 = add i64 %10317, -12
  %10319 = load i64, i64* %3, align 8
  %10320 = add i64 %10319, 3
  store i64 %10320, i64* %3, align 8
  %10321 = inttoptr i64 %10318 to i32*
  %10322 = load i32, i32* %10321, align 4
  %10323 = add i32 %10322, 1
  %10324 = zext i32 %10323 to i64
  store i64 %10324, i64* %RAX.i893, align 8
  %10325 = icmp eq i32 %10322, -1
  %10326 = icmp eq i32 %10323, 0
  %10327 = or i1 %10325, %10326
  %10328 = zext i1 %10327 to i8
  store i8 %10328, i8* %19, align 1
  %10329 = and i32 %10323, 255
  %10330 = tail call i32 @llvm.ctpop.i32(i32 %10329)
  %10331 = trunc i32 %10330 to i8
  %10332 = and i8 %10331, 1
  %10333 = xor i8 %10332, 1
  store i8 %10333, i8* %26, align 1
  %10334 = xor i32 %10323, %10322
  %10335 = lshr i32 %10334, 4
  %10336 = trunc i32 %10335 to i8
  %10337 = and i8 %10336, 1
  store i8 %10337, i8* %31, align 1
  %10338 = zext i1 %10326 to i8
  store i8 %10338, i8* %34, align 1
  %10339 = lshr i32 %10323, 31
  %10340 = trunc i32 %10339 to i8
  store i8 %10340, i8* %37, align 1
  %10341 = lshr i32 %10322, 31
  %10342 = xor i32 %10339, %10341
  %10343 = add nuw nsw i32 %10342, %10339
  %10344 = icmp eq i32 %10343, 2
  %10345 = zext i1 %10344 to i8
  store i8 %10345, i8* %43, align 1
  %10346 = add i64 %10319, 9
  store i64 %10346, i64* %3, align 8
  store i32 %10323, i32* %10321, align 4
  %10347 = load i64, i64* %RBP.i, align 8
  %10348 = add i64 %10347, -20
  %10349 = load i64, i64* %3, align 8
  %10350 = add i64 %10349, 3
  store i64 %10350, i64* %3, align 8
  %10351 = inttoptr i64 %10348 to i32*
  %10352 = load i32, i32* %10351, align 4
  %10353 = add i32 %10352, 1
  %10354 = zext i32 %10353 to i64
  store i64 %10354, i64* %RAX.i893, align 8
  %10355 = icmp eq i32 %10352, -1
  %10356 = icmp eq i32 %10353, 0
  %10357 = or i1 %10355, %10356
  %10358 = zext i1 %10357 to i8
  store i8 %10358, i8* %19, align 1
  %10359 = and i32 %10353, 255
  %10360 = tail call i32 @llvm.ctpop.i32(i32 %10359)
  %10361 = trunc i32 %10360 to i8
  %10362 = and i8 %10361, 1
  %10363 = xor i8 %10362, 1
  store i8 %10363, i8* %26, align 1
  %10364 = xor i32 %10353, %10352
  %10365 = lshr i32 %10364, 4
  %10366 = trunc i32 %10365 to i8
  %10367 = and i8 %10366, 1
  store i8 %10367, i8* %31, align 1
  %10368 = zext i1 %10356 to i8
  store i8 %10368, i8* %34, align 1
  %10369 = lshr i32 %10353, 31
  %10370 = trunc i32 %10369 to i8
  store i8 %10370, i8* %37, align 1
  %10371 = lshr i32 %10352, 31
  %10372 = xor i32 %10369, %10371
  %10373 = add nuw nsw i32 %10372, %10369
  %10374 = icmp eq i32 %10373, 2
  %10375 = zext i1 %10374 to i8
  store i8 %10375, i8* %43, align 1
  %10376 = add i64 %10349, 9
  store i64 %10376, i64* %3, align 8
  store i32 %10353, i32* %10351, align 4
  %10377 = load i64, i64* %3, align 8
  %10378 = add i64 %10377, -102
  store i64 %10378, i64* %3, align 8
  br label %block_.L_48f853

block_.L_48f8be:                                  ; preds = %block_.L_48f853
  %10379 = add i64 %10220, -16
  %10380 = add i64 %10259, 8
  store i64 %10380, i64* %3, align 8
  %10381 = inttoptr i64 %10379 to i32*
  %10382 = load i32, i32* %10381, align 4
  %10383 = add i32 %10382, 1
  %10384 = zext i32 %10383 to i64
  store i64 %10384, i64* %RAX.i893, align 8
  %10385 = icmp eq i32 %10382, -1
  %10386 = icmp eq i32 %10383, 0
  %10387 = or i1 %10385, %10386
  %10388 = zext i1 %10387 to i8
  store i8 %10388, i8* %19, align 1
  %10389 = and i32 %10383, 255
  %10390 = tail call i32 @llvm.ctpop.i32(i32 %10389)
  %10391 = trunc i32 %10390 to i8
  %10392 = and i8 %10391, 1
  %10393 = xor i8 %10392, 1
  store i8 %10393, i8* %26, align 1
  %10394 = xor i32 %10383, %10382
  %10395 = lshr i32 %10394, 4
  %10396 = trunc i32 %10395 to i8
  %10397 = and i8 %10396, 1
  store i8 %10397, i8* %31, align 1
  %10398 = zext i1 %10386 to i8
  store i8 %10398, i8* %34, align 1
  %10399 = lshr i32 %10383, 31
  %10400 = trunc i32 %10399 to i8
  store i8 %10400, i8* %37, align 1
  %10401 = lshr i32 %10382, 31
  %10402 = xor i32 %10399, %10401
  %10403 = add nuw nsw i32 %10402, %10399
  %10404 = icmp eq i32 %10403, 2
  %10405 = zext i1 %10404 to i8
  store i8 %10405, i8* %43, align 1
  %10406 = add i64 %10259, 14
  store i64 %10406, i64* %3, align 8
  store i32 %10383, i32* %10381, align 4
  %10407 = load i64, i64* %3, align 8
  %10408 = add i64 %10407, -166
  store i64 %10408, i64* %3, align 8
  br label %block_.L_48f826

block_.L_48f8d1:                                  ; preds = %block_.L_48f826
  %10409 = add i64 %10210, 5
  store i64 %10409, i64* %3, align 8
  br label %block_.L_48f8d6

block_.L_48f8d6:                                  ; preds = %block_.L_48f804, %block_.L_48f8d1
  %10410 = phi i64 [ %10171, %block_.L_48f8d1 ], [ %9445, %block_.L_48f804 ]
  %10411 = phi i64 [ %10409, %block_.L_48f8d1 ], [ %10155, %block_.L_48f804 ]
  %10412 = add i64 %10411, 5
  store i64 %10412, i64* %3, align 8
  br label %block_.L_48f8db

block_.L_48f8db:                                  ; preds = %block_.L_48f8d6, %block_.L_48f7ff
  %10413 = phi i64 [ %9912, %block_.L_48f7ff ], [ %10410, %block_.L_48f8d6 ]
  %storemerge118 = phi i64 [ %10130, %block_.L_48f7ff ], [ %10412, %block_.L_48f8d6 ]
  %10414 = add i64 %storemerge118, 5
  store i64 %10414, i64* %3, align 8
  br label %block_.L_48f8e0

block_.L_48f8e0:                                  ; preds = %block_.L_48f8db, %block_.L_48f731
  %10415 = phi i64 [ %9486, %block_.L_48f731 ], [ %10413, %block_.L_48f8db ]
  %storemerge116 = phi i64 [ %9846, %block_.L_48f731 ], [ %10414, %block_.L_48f8db ]
  %10416 = add i64 %10415, -56
  %10417 = add i64 %storemerge116, 4
  store i64 %10417, i64* %3, align 8
  %10418 = inttoptr i64 %10416 to i64*
  %10419 = load i64, i64* %10418, align 8
  store i64 %10419, i64* %RAX.i893, align 8
  %10420 = add i64 %10419, 72
  %10421 = add i64 %storemerge116, 8
  store i64 %10421, i64* %3, align 8
  %10422 = inttoptr i64 %10420 to i32*
  %10423 = load i32, i32* %10422, align 4
  %10424 = add i32 %10423, -13
  %10425 = icmp ult i32 %10423, 13
  %10426 = zext i1 %10425 to i8
  store i8 %10426, i8* %19, align 1
  %10427 = and i32 %10424, 255
  %10428 = tail call i32 @llvm.ctpop.i32(i32 %10427)
  %10429 = trunc i32 %10428 to i8
  %10430 = and i8 %10429, 1
  %10431 = xor i8 %10430, 1
  store i8 %10431, i8* %26, align 1
  %10432 = xor i32 %10424, %10423
  %10433 = lshr i32 %10432, 4
  %10434 = trunc i32 %10433 to i8
  %10435 = and i8 %10434, 1
  store i8 %10435, i8* %31, align 1
  %10436 = icmp eq i32 %10424, 0
  %10437 = zext i1 %10436 to i8
  store i8 %10437, i8* %34, align 1
  %10438 = lshr i32 %10424, 31
  %10439 = trunc i32 %10438 to i8
  store i8 %10439, i8* %37, align 1
  %10440 = lshr i32 %10423, 31
  %10441 = xor i32 %10438, %10440
  %10442 = add nuw nsw i32 %10441, %10440
  %10443 = icmp eq i32 %10442, 2
  %10444 = zext i1 %10443 to i8
  store i8 %10444, i8* %43, align 1
  %.v323 = select i1 %10436, i64 14, i64 215
  %10445 = add i64 %storemerge116, %.v323
  store i64 %10445, i64* %3, align 8
  br i1 %10436, label %block_48f8ee, label %block_.L_48f9b7

block_48f8ee:                                     ; preds = %block_.L_48f8e0
  %10446 = add i64 %10415, -20
  %10447 = add i64 %10445, 7
  store i64 %10447, i64* %3, align 8
  %10448 = inttoptr i64 %10446 to i32*
  store i32 0, i32* %10448, align 4
  %10449 = load i64, i64* %RBP.i, align 8
  %10450 = add i64 %10449, -12
  %10451 = load i64, i64* %3, align 8
  %10452 = add i64 %10451, 7
  store i64 %10452, i64* %3, align 8
  %10453 = inttoptr i64 %10450 to i32*
  store i32 0, i32* %10453, align 4
  %.pre239 = load i64, i64* %3, align 8
  br label %block_.L_48f8fc

block_.L_48f8fc:                                  ; preds = %block_.L_48f99f, %block_48f8ee
  %10454 = phi i64 [ %10765, %block_.L_48f99f ], [ %.pre239, %block_48f8ee ]
  %10455 = load i64, i64* %RBP.i, align 8
  %10456 = add i64 %10455, -12
  %10457 = add i64 %10454, 4
  store i64 %10457, i64* %3, align 8
  %10458 = inttoptr i64 %10456 to i32*
  %10459 = load i32, i32* %10458, align 4
  %10460 = add i32 %10459, -4
  %10461 = icmp ult i32 %10459, 4
  %10462 = zext i1 %10461 to i8
  store i8 %10462, i8* %19, align 1
  %10463 = and i32 %10460, 255
  %10464 = tail call i32 @llvm.ctpop.i32(i32 %10463)
  %10465 = trunc i32 %10464 to i8
  %10466 = and i8 %10465, 1
  %10467 = xor i8 %10466, 1
  store i8 %10467, i8* %26, align 1
  %10468 = xor i32 %10460, %10459
  %10469 = lshr i32 %10468, 4
  %10470 = trunc i32 %10469 to i8
  %10471 = and i8 %10470, 1
  store i8 %10471, i8* %31, align 1
  %10472 = icmp eq i32 %10460, 0
  %10473 = zext i1 %10472 to i8
  store i8 %10473, i8* %34, align 1
  %10474 = lshr i32 %10460, 31
  %10475 = trunc i32 %10474 to i8
  store i8 %10475, i8* %37, align 1
  %10476 = lshr i32 %10459, 31
  %10477 = xor i32 %10474, %10476
  %10478 = add nuw nsw i32 %10477, %10476
  %10479 = icmp eq i32 %10478, 2
  %10480 = zext i1 %10479 to i8
  store i8 %10480, i8* %43, align 1
  %10481 = icmp ne i8 %10475, 0
  %10482 = xor i1 %10481, %10479
  %.v326 = select i1 %10482, i64 10, i64 182
  %10483 = add i64 %10454, %.v326
  store i64 %10483, i64* %3, align 8
  br i1 %10482, label %block_48f906, label %block_.L_48f9b2

block_48f906:                                     ; preds = %block_.L_48f8fc
  %10484 = add i64 %10455, -16
  %10485 = add i64 %10483, 7
  store i64 %10485, i64* %3, align 8
  %10486 = inttoptr i64 %10484 to i32*
  store i32 0, i32* %10486, align 4
  %.pre240 = load i64, i64* %3, align 8
  br label %block_.L_48f90d

block_.L_48f90d:                                  ; preds = %block_48f917, %block_48f906
  %10487 = phi i64 [ %10735, %block_48f917 ], [ %.pre240, %block_48f906 ]
  %10488 = load i64, i64* %RBP.i, align 8
  %10489 = add i64 %10488, -16
  %10490 = add i64 %10487, 4
  store i64 %10490, i64* %3, align 8
  %10491 = inttoptr i64 %10489 to i32*
  %10492 = load i32, i32* %10491, align 4
  %10493 = add i32 %10492, -4
  %10494 = icmp ult i32 %10492, 4
  %10495 = zext i1 %10494 to i8
  store i8 %10495, i8* %19, align 1
  %10496 = and i32 %10493, 255
  %10497 = tail call i32 @llvm.ctpop.i32(i32 %10496)
  %10498 = trunc i32 %10497 to i8
  %10499 = and i8 %10498, 1
  %10500 = xor i8 %10499, 1
  store i8 %10500, i8* %26, align 1
  %10501 = xor i32 %10493, %10492
  %10502 = lshr i32 %10501, 4
  %10503 = trunc i32 %10502 to i8
  %10504 = and i8 %10503, 1
  store i8 %10504, i8* %31, align 1
  %10505 = icmp eq i32 %10493, 0
  %10506 = zext i1 %10505 to i8
  store i8 %10506, i8* %34, align 1
  %10507 = lshr i32 %10493, 31
  %10508 = trunc i32 %10507 to i8
  store i8 %10508, i8* %37, align 1
  %10509 = lshr i32 %10492, 31
  %10510 = xor i32 %10507, %10509
  %10511 = add nuw nsw i32 %10510, %10509
  %10512 = icmp eq i32 %10511, 2
  %10513 = zext i1 %10512 to i8
  store i8 %10513, i8* %43, align 1
  %10514 = icmp ne i8 %10508, 0
  %10515 = xor i1 %10514, %10512
  %.v291 = select i1 %10515, i64 10, i64 146
  %10516 = add i64 %10487, %.v291
  store i64 %10516, i64* %3, align 8
  br i1 %10515, label %block_48f917, label %block_.L_48f99f

block_48f917:                                     ; preds = %block_.L_48f90d
  store i64 ptrtoint (%G__0x7242b0_type* @G__0x7242b0 to i64), i64* %RAX.i893, align 8
  %10517 = add i64 %10488, -12
  %10518 = add i64 %10516, 14
  store i64 %10518, i64* %3, align 8
  %10519 = inttoptr i64 %10517 to i32*
  %10520 = load i32, i32* %10519, align 4
  %10521 = sext i32 %10520 to i64
  %10522 = shl nsw i64 %10521, 4
  store i64 %10522, i64* %RCX.i1197, align 8
  %10523 = add i64 %10522, ptrtoint (%G__0x7242b0_type* @G__0x7242b0 to i64)
  store i64 %10523, i64* %RAX.i893, align 8
  %10524 = icmp ult i64 %10523, ptrtoint (%G__0x7242b0_type* @G__0x7242b0 to i64)
  %10525 = icmp ult i64 %10523, %10522
  %10526 = or i1 %10524, %10525
  %10527 = zext i1 %10526 to i8
  store i8 %10527, i8* %19, align 1
  %10528 = trunc i64 %10523 to i32
  %10529 = and i32 %10528, 248
  %10530 = tail call i32 @llvm.ctpop.i32(i32 %10529)
  %10531 = trunc i32 %10530 to i8
  %10532 = and i8 %10531, 1
  %10533 = xor i8 %10532, 1
  store i8 %10533, i8* %26, align 1
  %10534 = xor i64 %10522, ptrtoint (%G__0x7242b0_type* @G__0x7242b0 to i64)
  %10535 = xor i64 %10534, %10523
  %10536 = lshr i64 %10535, 4
  %10537 = trunc i64 %10536 to i8
  %10538 = and i8 %10537, 1
  store i8 %10538, i8* %31, align 1
  %10539 = icmp eq i64 %10523, 0
  %10540 = zext i1 %10539 to i8
  store i8 %10540, i8* %34, align 1
  %10541 = lshr i64 %10523, 63
  %10542 = trunc i64 %10541 to i8
  store i8 %10542, i8* %37, align 1
  %10543 = lshr i64 %10521, 59
  %10544 = and i64 %10543, 1
  %10545 = xor i64 %10541, lshr (i64 ptrtoint (%G__0x7242b0_type* @G__0x7242b0 to i64), i64 63)
  %10546 = xor i64 %10541, %10544
  %10547 = add nuw nsw i64 %10545, %10546
  %10548 = icmp eq i64 %10547, 2
  %10549 = zext i1 %10548 to i8
  store i8 %10549, i8* %43, align 1
  %10550 = add i64 %10516, 25
  store i64 %10550, i64* %3, align 8
  %10551 = load i32, i32* %10491, align 4
  %10552 = sext i32 %10551 to i64
  store i64 %10552, i64* %RCX.i1197, align 8
  %10553 = shl nsw i64 %10552, 2
  %10554 = add i64 %10553, %10523
  %10555 = add i64 %10516, 28
  store i64 %10555, i64* %3, align 8
  %10556 = inttoptr i64 %10554 to i32*
  %10557 = load i32, i32* %10556, align 4
  %10558 = zext i32 %10557 to i64
  store i64 %10558, i64* %RDX.i1708, align 8
  %10559 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10559, i64* %RAX.i893, align 8
  %10560 = add i64 %10559, 104
  %10561 = add i64 %10516, 40
  store i64 %10561, i64* %3, align 8
  %10562 = inttoptr i64 %10560 to i64*
  %10563 = load i64, i64* %10562, align 8
  store i64 %10563, i64* %RAX.i893, align 8
  store i64 %10559, i64* %RCX.i1197, align 8
  %10564 = add i64 %10559, 144
  %10565 = add i64 %10516, 54
  store i64 %10565, i64* %3, align 8
  %10566 = inttoptr i64 %10564 to i32*
  %10567 = load i32, i32* %10566, align 4
  %10568 = zext i32 %10567 to i64
  store i64 %10568, i64* %RSI.i4020.pre-phi, align 8
  %10569 = load i64, i64* %RBP.i, align 8
  %10570 = add i64 %10569, -12
  %10571 = add i64 %10516, 57
  store i64 %10571, i64* %3, align 8
  %10572 = inttoptr i64 %10570 to i32*
  %10573 = load i32, i32* %10572, align 4
  %10574 = add i32 %10573, %10567
  %10575 = zext i32 %10574 to i64
  store i64 %10575, i64* %RSI.i4020.pre-phi, align 8
  %10576 = icmp ult i32 %10574, %10567
  %10577 = icmp ult i32 %10574, %10573
  %10578 = or i1 %10576, %10577
  %10579 = zext i1 %10578 to i8
  store i8 %10579, i8* %19, align 1
  %10580 = and i32 %10574, 255
  %10581 = tail call i32 @llvm.ctpop.i32(i32 %10580)
  %10582 = trunc i32 %10581 to i8
  %10583 = and i8 %10582, 1
  %10584 = xor i8 %10583, 1
  store i8 %10584, i8* %26, align 1
  %10585 = xor i32 %10573, %10567
  %10586 = xor i32 %10585, %10574
  %10587 = lshr i32 %10586, 4
  %10588 = trunc i32 %10587 to i8
  %10589 = and i8 %10588, 1
  store i8 %10589, i8* %31, align 1
  %10590 = icmp eq i32 %10574, 0
  %10591 = zext i1 %10590 to i8
  store i8 %10591, i8* %34, align 1
  %10592 = lshr i32 %10574, 31
  %10593 = trunc i32 %10592 to i8
  store i8 %10593, i8* %37, align 1
  %10594 = lshr i32 %10567, 31
  %10595 = lshr i32 %10573, 31
  %10596 = xor i32 %10592, %10594
  %10597 = xor i32 %10592, %10595
  %10598 = add nuw nsw i32 %10596, %10597
  %10599 = icmp eq i32 %10598, 2
  %10600 = zext i1 %10599 to i8
  store i8 %10600, i8* %43, align 1
  %10601 = sext i32 %10574 to i64
  store i64 %10601, i64* %RCX.i1197, align 8
  %10602 = shl nsw i64 %10601, 3
  %10603 = add i64 %10563, %10602
  %10604 = add i64 %10516, 64
  store i64 %10604, i64* %3, align 8
  %10605 = inttoptr i64 %10603 to i64*
  %10606 = load i64, i64* %10605, align 8
  store i64 %10606, i64* %RAX.i893, align 8
  store i64 %10559, i64* %RCX.i1197, align 8
  %10607 = add i64 %10559, 148
  %10608 = add i64 %10516, 78
  store i64 %10608, i64* %3, align 8
  %10609 = inttoptr i64 %10607 to i32*
  %10610 = load i32, i32* %10609, align 4
  %10611 = zext i32 %10610 to i64
  store i64 %10611, i64* %RSI.i4020.pre-phi, align 8
  %10612 = add i64 %10569, -16
  %10613 = add i64 %10516, 81
  store i64 %10613, i64* %3, align 8
  %10614 = inttoptr i64 %10612 to i32*
  %10615 = load i32, i32* %10614, align 4
  %10616 = add i32 %10615, %10610
  %10617 = zext i32 %10616 to i64
  store i64 %10617, i64* %RSI.i4020.pre-phi, align 8
  %10618 = icmp ult i32 %10616, %10610
  %10619 = icmp ult i32 %10616, %10615
  %10620 = or i1 %10618, %10619
  %10621 = zext i1 %10620 to i8
  store i8 %10621, i8* %19, align 1
  %10622 = and i32 %10616, 255
  %10623 = tail call i32 @llvm.ctpop.i32(i32 %10622)
  %10624 = trunc i32 %10623 to i8
  %10625 = and i8 %10624, 1
  %10626 = xor i8 %10625, 1
  store i8 %10626, i8* %26, align 1
  %10627 = xor i32 %10615, %10610
  %10628 = xor i32 %10627, %10616
  %10629 = lshr i32 %10628, 4
  %10630 = trunc i32 %10629 to i8
  %10631 = and i8 %10630, 1
  store i8 %10631, i8* %31, align 1
  %10632 = icmp eq i32 %10616, 0
  %10633 = zext i1 %10632 to i8
  store i8 %10633, i8* %34, align 1
  %10634 = lshr i32 %10616, 31
  %10635 = trunc i32 %10634 to i8
  store i8 %10635, i8* %37, align 1
  %10636 = lshr i32 %10610, 31
  %10637 = lshr i32 %10615, 31
  %10638 = xor i32 %10634, %10636
  %10639 = xor i32 %10634, %10637
  %10640 = add nuw nsw i32 %10638, %10639
  %10641 = icmp eq i32 %10640, 2
  %10642 = zext i1 %10641 to i8
  store i8 %10642, i8* %43, align 1
  %10643 = sext i32 %10616 to i64
  store i64 %10643, i64* %RCX.i1197, align 8
  %10644 = shl nsw i64 %10643, 2
  %10645 = add i64 %10606, %10644
  %10646 = load i32, i32* %EDX.i1723, align 4
  %10647 = add i64 %10516, 87
  store i64 %10647, i64* %3, align 8
  %10648 = inttoptr i64 %10645 to i32*
  store i32 %10646, i32* %10648, align 4
  %10649 = load i64, i64* %RBP.i, align 8
  %10650 = add i64 %10649, -20
  %10651 = load i64, i64* %3, align 8
  %10652 = add i64 %10651, 4
  store i64 %10652, i64* %3, align 8
  %10653 = inttoptr i64 %10650 to i32*
  %10654 = load i32, i32* %10653, align 4
  %10655 = sext i32 %10654 to i64
  store i64 %10655, i64* %RAX.i893, align 8
  %10656 = shl nsw i64 %10655, 2
  %10657 = add nsw i64 %10656, 7149760
  %10658 = add i64 %10651, 11
  store i64 %10658, i64* %3, align 8
  %10659 = inttoptr i64 %10657 to i32*
  %10660 = load i32, i32* %10659, align 4
  %10661 = zext i32 %10660 to i64
  store i64 %10661, i64* %RDX.i1708, align 8
  %10662 = add i64 %10649, -56
  %10663 = add i64 %10651, 15
  store i64 %10663, i64* %3, align 8
  %10664 = inttoptr i64 %10662 to i64*
  %10665 = load i64, i64* %10664, align 8
  store i64 %10665, i64* %RAX.i893, align 8
  %10666 = add i64 %10651, 19
  store i64 %10666, i64* %3, align 8
  %10667 = load i32, i32* %10653, align 4
  %10668 = sext i32 %10667 to i64
  store i64 %10668, i64* %RCX.i1197, align 8
  %10669 = shl nsw i64 %10668, 2
  %10670 = add i64 %10665, 332
  %10671 = add i64 %10670, %10669
  %10672 = add i64 %10651, 26
  store i64 %10672, i64* %3, align 8
  %10673 = inttoptr i64 %10671 to i32*
  store i32 %10660, i32* %10673, align 4
  %10674 = load i64, i64* %RBP.i, align 8
  %10675 = add i64 %10674, -16
  %10676 = load i64, i64* %3, align 8
  %10677 = add i64 %10676, 3
  store i64 %10677, i64* %3, align 8
  %10678 = inttoptr i64 %10675 to i32*
  %10679 = load i32, i32* %10678, align 4
  %10680 = add i32 %10679, 1
  %10681 = zext i32 %10680 to i64
  store i64 %10681, i64* %RAX.i893, align 8
  %10682 = icmp eq i32 %10679, -1
  %10683 = icmp eq i32 %10680, 0
  %10684 = or i1 %10682, %10683
  %10685 = zext i1 %10684 to i8
  store i8 %10685, i8* %19, align 1
  %10686 = and i32 %10680, 255
  %10687 = tail call i32 @llvm.ctpop.i32(i32 %10686)
  %10688 = trunc i32 %10687 to i8
  %10689 = and i8 %10688, 1
  %10690 = xor i8 %10689, 1
  store i8 %10690, i8* %26, align 1
  %10691 = xor i32 %10680, %10679
  %10692 = lshr i32 %10691, 4
  %10693 = trunc i32 %10692 to i8
  %10694 = and i8 %10693, 1
  store i8 %10694, i8* %31, align 1
  %10695 = zext i1 %10683 to i8
  store i8 %10695, i8* %34, align 1
  %10696 = lshr i32 %10680, 31
  %10697 = trunc i32 %10696 to i8
  store i8 %10697, i8* %37, align 1
  %10698 = lshr i32 %10679, 31
  %10699 = xor i32 %10696, %10698
  %10700 = add nuw nsw i32 %10699, %10696
  %10701 = icmp eq i32 %10700, 2
  %10702 = zext i1 %10701 to i8
  store i8 %10702, i8* %43, align 1
  %10703 = add i64 %10676, 9
  store i64 %10703, i64* %3, align 8
  store i32 %10680, i32* %10678, align 4
  %10704 = load i64, i64* %RBP.i, align 8
  %10705 = add i64 %10704, -20
  %10706 = load i64, i64* %3, align 8
  %10707 = add i64 %10706, 3
  store i64 %10707, i64* %3, align 8
  %10708 = inttoptr i64 %10705 to i32*
  %10709 = load i32, i32* %10708, align 4
  %10710 = add i32 %10709, 1
  %10711 = zext i32 %10710 to i64
  store i64 %10711, i64* %RAX.i893, align 8
  %10712 = icmp eq i32 %10709, -1
  %10713 = icmp eq i32 %10710, 0
  %10714 = or i1 %10712, %10713
  %10715 = zext i1 %10714 to i8
  store i8 %10715, i8* %19, align 1
  %10716 = and i32 %10710, 255
  %10717 = tail call i32 @llvm.ctpop.i32(i32 %10716)
  %10718 = trunc i32 %10717 to i8
  %10719 = and i8 %10718, 1
  %10720 = xor i8 %10719, 1
  store i8 %10720, i8* %26, align 1
  %10721 = xor i32 %10710, %10709
  %10722 = lshr i32 %10721, 4
  %10723 = trunc i32 %10722 to i8
  %10724 = and i8 %10723, 1
  store i8 %10724, i8* %31, align 1
  %10725 = zext i1 %10713 to i8
  store i8 %10725, i8* %34, align 1
  %10726 = lshr i32 %10710, 31
  %10727 = trunc i32 %10726 to i8
  store i8 %10727, i8* %37, align 1
  %10728 = lshr i32 %10709, 31
  %10729 = xor i32 %10726, %10728
  %10730 = add nuw nsw i32 %10729, %10726
  %10731 = icmp eq i32 %10730, 2
  %10732 = zext i1 %10731 to i8
  store i8 %10732, i8* %43, align 1
  %10733 = add i64 %10706, 9
  store i64 %10733, i64* %3, align 8
  store i32 %10710, i32* %10708, align 4
  %10734 = load i64, i64* %3, align 8
  %10735 = add i64 %10734, -141
  store i64 %10735, i64* %3, align 8
  br label %block_.L_48f90d

block_.L_48f99f:                                  ; preds = %block_.L_48f90d
  %10736 = add i64 %10488, -12
  %10737 = add i64 %10516, 8
  store i64 %10737, i64* %3, align 8
  %10738 = inttoptr i64 %10736 to i32*
  %10739 = load i32, i32* %10738, align 4
  %10740 = add i32 %10739, 1
  %10741 = zext i32 %10740 to i64
  store i64 %10741, i64* %RAX.i893, align 8
  %10742 = icmp eq i32 %10739, -1
  %10743 = icmp eq i32 %10740, 0
  %10744 = or i1 %10742, %10743
  %10745 = zext i1 %10744 to i8
  store i8 %10745, i8* %19, align 1
  %10746 = and i32 %10740, 255
  %10747 = tail call i32 @llvm.ctpop.i32(i32 %10746)
  %10748 = trunc i32 %10747 to i8
  %10749 = and i8 %10748, 1
  %10750 = xor i8 %10749, 1
  store i8 %10750, i8* %26, align 1
  %10751 = xor i32 %10740, %10739
  %10752 = lshr i32 %10751, 4
  %10753 = trunc i32 %10752 to i8
  %10754 = and i8 %10753, 1
  store i8 %10754, i8* %31, align 1
  %10755 = zext i1 %10743 to i8
  store i8 %10755, i8* %34, align 1
  %10756 = lshr i32 %10740, 31
  %10757 = trunc i32 %10756 to i8
  store i8 %10757, i8* %37, align 1
  %10758 = lshr i32 %10739, 31
  %10759 = xor i32 %10756, %10758
  %10760 = add nuw nsw i32 %10759, %10756
  %10761 = icmp eq i32 %10760, 2
  %10762 = zext i1 %10761 to i8
  store i8 %10762, i8* %43, align 1
  %10763 = add i64 %10516, 14
  store i64 %10763, i64* %3, align 8
  store i32 %10740, i32* %10738, align 4
  %10764 = load i64, i64* %3, align 8
  %10765 = add i64 %10764, -177
  store i64 %10765, i64* %3, align 8
  br label %block_.L_48f8fc

block_.L_48f9b2:                                  ; preds = %block_.L_48f8fc
  %10766 = add i64 %10483, 5
  store i64 %10766, i64* %3, align 8
  br label %block_.L_48f9b7

block_.L_48f9b7:                                  ; preds = %block_.L_48f8e0, %block_.L_48f9b2
  %10767 = phi i64 [ %10455, %block_.L_48f9b2 ], [ %10415, %block_.L_48f8e0 ]
  %10768 = phi i64 [ %10766, %block_.L_48f9b2 ], [ %10445, %block_.L_48f8e0 ]
  %10769 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10769, i64* %RAX.i893, align 8
  %10770 = add i64 %10769, 72400
  %10771 = add i64 %10768, 15
  store i64 %10771, i64* %3, align 8
  %10772 = inttoptr i64 %10770 to i32*
  %10773 = load i32, i32* %10772, align 4
  store i8 0, i8* %19, align 1
  %10774 = and i32 %10773, 255
  %10775 = tail call i32 @llvm.ctpop.i32(i32 %10774)
  %10776 = trunc i32 %10775 to i8
  %10777 = and i8 %10776, 1
  %10778 = xor i8 %10777, 1
  store i8 %10778, i8* %26, align 1
  store i8 0, i8* %31, align 1
  %10779 = icmp eq i32 %10773, 0
  %10780 = zext i1 %10779 to i8
  store i8 %10780, i8* %34, align 1
  %10781 = lshr i32 %10773, 31
  %10782 = trunc i32 %10781 to i8
  store i8 %10782, i8* %37, align 1
  store i8 0, i8* %43, align 1
  %.v324 = select i1 %10779, i64 295, i64 21
  %10783 = add i64 %10768, %.v324
  store i64 %10783, i64* %3, align 8
  br i1 %10779, label %block_.L_48fade, label %block_48f9cc

block_48f9cc:                                     ; preds = %block_.L_48f9b7
  %10784 = add i64 %10767, -20
  %10785 = add i64 %10783, 7
  store i64 %10785, i64* %3, align 8
  %10786 = inttoptr i64 %10784 to i32*
  store i32 0, i32* %10786, align 4
  %10787 = load i64, i64* %3, align 8
  %10788 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10788, i64* %RAX.i893, align 8
  %10789 = add i64 %10788, 148
  %10790 = add i64 %10787, 14
  store i64 %10790, i64* %3, align 8
  %10791 = inttoptr i64 %10789 to i32*
  %10792 = load i32, i32* %10791, align 4
  %10793 = zext i32 %10792 to i64
  store i64 %10793, i64* %RCX.i1197, align 8
  %10794 = load i64, i64* %RBP.i, align 8
  %10795 = add i64 %10794, -16
  %10796 = add i64 %10787, 17
  store i64 %10796, i64* %3, align 8
  %10797 = inttoptr i64 %10795 to i32*
  store i32 %10792, i32* %10797, align 4
  %.pre241 = load i64, i64* %3, align 8
  br label %block_.L_48f9e4

block_.L_48f9e4:                                  ; preds = %block_.L_48fa97, %block_48f9cc
  %10798 = phi i64 [ %11049, %block_.L_48fa97 ], [ %.pre241, %block_48f9cc ]
  %10799 = load i64, i64* %RBP.i, align 8
  %10800 = add i64 %10799, -16
  %10801 = add i64 %10798, 3
  store i64 %10801, i64* %3, align 8
  %10802 = inttoptr i64 %10800 to i32*
  %10803 = load i32, i32* %10802, align 4
  %10804 = zext i32 %10803 to i64
  store i64 %10804, i64* %RAX.i893, align 8
  %10805 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10805, i64* %RCX.i1197, align 8
  %10806 = add i64 %10805, 148
  %10807 = add i64 %10798, 17
  store i64 %10807, i64* %3, align 8
  %10808 = inttoptr i64 %10806 to i32*
  %10809 = load i32, i32* %10808, align 4
  %10810 = add i32 %10809, 4
  %10811 = zext i32 %10810 to i64
  store i64 %10811, i64* %RDX.i1708, align 8
  %10812 = lshr i32 %10810, 31
  %10813 = sub i32 %10803, %10810
  %10814 = icmp ult i32 %10803, %10810
  %10815 = zext i1 %10814 to i8
  store i8 %10815, i8* %19, align 1
  %10816 = and i32 %10813, 255
  %10817 = tail call i32 @llvm.ctpop.i32(i32 %10816)
  %10818 = trunc i32 %10817 to i8
  %10819 = and i8 %10818, 1
  %10820 = xor i8 %10819, 1
  store i8 %10820, i8* %26, align 1
  %10821 = xor i32 %10810, %10803
  %10822 = xor i32 %10821, %10813
  %10823 = lshr i32 %10822, 4
  %10824 = trunc i32 %10823 to i8
  %10825 = and i8 %10824, 1
  store i8 %10825, i8* %31, align 1
  %10826 = icmp eq i32 %10813, 0
  %10827 = zext i1 %10826 to i8
  store i8 %10827, i8* %34, align 1
  %10828 = lshr i32 %10813, 31
  %10829 = trunc i32 %10828 to i8
  store i8 %10829, i8* %37, align 1
  %10830 = lshr i32 %10803, 31
  %10831 = xor i32 %10812, %10830
  %10832 = xor i32 %10828, %10830
  %10833 = add nuw nsw i32 %10832, %10831
  %10834 = icmp eq i32 %10833, 2
  %10835 = zext i1 %10834 to i8
  store i8 %10835, i8* %43, align 1
  %10836 = icmp ne i8 %10829, 0
  %10837 = xor i1 %10836, %10834
  %.v325 = select i1 %10837, i64 28, i64 198
  %10838 = add i64 %10798, %.v325
  store i64 %10838, i64* %3, align 8
  br i1 %10837, label %block_48fa00, label %block_.L_48faaa

block_48fa00:                                     ; preds = %block_.L_48f9e4
  store i64 %10805, i64* %RAX.i893, align 8
  %10839 = add i64 %10805, 144
  %10840 = add i64 %10838, 14
  store i64 %10840, i64* %3, align 8
  %10841 = inttoptr i64 %10839 to i32*
  %10842 = load i32, i32* %10841, align 4
  %10843 = zext i32 %10842 to i64
  store i64 %10843, i64* %RCX.i1197, align 8
  %10844 = add i64 %10799, -12
  %10845 = add i64 %10838, 17
  store i64 %10845, i64* %3, align 8
  %10846 = inttoptr i64 %10844 to i32*
  store i32 %10842, i32* %10846, align 4
  %.pre242 = load i64, i64* %3, align 8
  br label %block_.L_48fa11

block_.L_48fa11:                                  ; preds = %block_48fa2d, %block_48fa00
  %10847 = phi i64 [ %11019, %block_48fa2d ], [ %.pre242, %block_48fa00 ]
  %10848 = load i64, i64* %RBP.i, align 8
  %10849 = add i64 %10848, -12
  %10850 = add i64 %10847, 3
  store i64 %10850, i64* %3, align 8
  %10851 = inttoptr i64 %10849 to i32*
  %10852 = load i32, i32* %10851, align 4
  %10853 = zext i32 %10852 to i64
  store i64 %10853, i64* %RAX.i893, align 8
  %10854 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %10854, i64* %RCX.i1197, align 8
  %10855 = add i64 %10854, 144
  %10856 = add i64 %10847, 17
  store i64 %10856, i64* %3, align 8
  %10857 = inttoptr i64 %10855 to i32*
  %10858 = load i32, i32* %10857, align 4
  %10859 = add i32 %10858, 4
  %10860 = zext i32 %10859 to i64
  store i64 %10860, i64* %RDX.i1708, align 8
  %10861 = lshr i32 %10859, 31
  %10862 = sub i32 %10852, %10859
  %10863 = icmp ult i32 %10852, %10859
  %10864 = zext i1 %10863 to i8
  store i8 %10864, i8* %19, align 1
  %10865 = and i32 %10862, 255
  %10866 = tail call i32 @llvm.ctpop.i32(i32 %10865)
  %10867 = trunc i32 %10866 to i8
  %10868 = and i8 %10867, 1
  %10869 = xor i8 %10868, 1
  store i8 %10869, i8* %26, align 1
  %10870 = xor i32 %10859, %10852
  %10871 = xor i32 %10870, %10862
  %10872 = lshr i32 %10871, 4
  %10873 = trunc i32 %10872 to i8
  %10874 = and i8 %10873, 1
  store i8 %10874, i8* %31, align 1
  %10875 = icmp eq i32 %10862, 0
  %10876 = zext i1 %10875 to i8
  store i8 %10876, i8* %34, align 1
  %10877 = lshr i32 %10862, 31
  %10878 = trunc i32 %10877 to i8
  store i8 %10878, i8* %37, align 1
  %10879 = lshr i32 %10852, 31
  %10880 = xor i32 %10861, %10879
  %10881 = xor i32 %10877, %10879
  %10882 = add nuw nsw i32 %10881, %10880
  %10883 = icmp eq i32 %10882, 2
  %10884 = zext i1 %10883 to i8
  store i8 %10884, i8* %43, align 1
  %10885 = icmp ne i8 %10878, 0
  %10886 = xor i1 %10885, %10883
  %.v = select i1 %10886, i64 28, i64 134
  %10887 = add i64 %10847, %.v
  store i64 %10887, i64* %3, align 8
  br i1 %10886, label %block_48fa2d, label %block_.L_48fa97

block_48fa2d:                                     ; preds = %block_.L_48fa11
  %10888 = add i64 %10848, -72
  %10889 = add i64 %10887, 4
  store i64 %10889, i64* %3, align 8
  %10890 = inttoptr i64 %10888 to i64*
  %10891 = load i64, i64* %10890, align 8
  store i64 %10891, i64* %RAX.i893, align 8
  %10892 = add i64 %10887, 8
  store i64 %10892, i64* %3, align 8
  %10893 = load i32, i32* %10851, align 4
  %10894 = sext i32 %10893 to i64
  store i64 %10894, i64* %RCX.i1197, align 8
  %10895 = shl nsw i64 %10894, 3
  %10896 = add i64 %10895, %10891
  %10897 = add i64 %10887, 12
  store i64 %10897, i64* %3, align 8
  %10898 = inttoptr i64 %10896 to i64*
  %10899 = load i64, i64* %10898, align 8
  store i64 %10899, i64* %RAX.i893, align 8
  %10900 = add i64 %10848, -16
  %10901 = add i64 %10887, 16
  store i64 %10901, i64* %3, align 8
  %10902 = inttoptr i64 %10900 to i32*
  %10903 = load i32, i32* %10902, align 4
  %10904 = sext i32 %10903 to i64
  store i64 %10904, i64* %RCX.i1197, align 8
  %10905 = shl nsw i64 %10904, 2
  %10906 = add i64 %10905, %10899
  %10907 = add i64 %10887, 19
  store i64 %10907, i64* %3, align 8
  %10908 = inttoptr i64 %10906 to i32*
  %10909 = load i32, i32* %10908, align 4
  %10910 = zext i32 %10909 to i64
  store i64 %10910, i64* %RDX.i1708, align 8
  %10911 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %10911, i64* %RAX.i893, align 8
  %10912 = add i64 %10911, 3136
  %10913 = add i64 %10887, 34
  store i64 %10913, i64* %3, align 8
  %10914 = inttoptr i64 %10912 to i64*
  %10915 = load i64, i64* %10914, align 8
  store i64 %10915, i64* %RAX.i893, align 8
  %10916 = add i64 %10887, 38
  store i64 %10916, i64* %3, align 8
  %10917 = load i32, i32* %10851, align 4
  %10918 = sext i32 %10917 to i64
  store i64 %10918, i64* %RCX.i1197, align 8
  %10919 = shl nsw i64 %10918, 3
  %10920 = add i64 %10919, %10915
  %10921 = add i64 %10887, 42
  store i64 %10921, i64* %3, align 8
  %10922 = inttoptr i64 %10920 to i64*
  %10923 = load i64, i64* %10922, align 8
  store i64 %10923, i64* %RAX.i893, align 8
  %10924 = add i64 %10887, 46
  store i64 %10924, i64* %3, align 8
  %10925 = load i32, i32* %10902, align 4
  %10926 = sext i32 %10925 to i64
  store i64 %10926, i64* %RCX.i1197, align 8
  %10927 = shl nsw i64 %10926, 2
  %10928 = add i64 %10927, %10923
  %10929 = add i64 %10887, 49
  store i64 %10929, i64* %3, align 8
  %10930 = inttoptr i64 %10928 to i32*
  store i32 %10909, i32* %10930, align 4
  %10931 = load i64, i64* %RBP.i, align 8
  %10932 = add i64 %10931, -56
  %10933 = load i64, i64* %3, align 8
  %10934 = add i64 %10933, 4
  store i64 %10934, i64* %3, align 8
  %10935 = inttoptr i64 %10932 to i64*
  %10936 = load i64, i64* %10935, align 8
  store i64 %10936, i64* %RAX.i893, align 8
  %10937 = add i64 %10931, -20
  %10938 = add i64 %10933, 8
  store i64 %10938, i64* %3, align 8
  %10939 = inttoptr i64 %10937 to i32*
  %10940 = load i32, i32* %10939, align 4
  %10941 = sext i32 %10940 to i64
  store i64 %10941, i64* %RCX.i1197, align 8
  %10942 = shl nsw i64 %10941, 2
  %10943 = add i64 %10936, 332
  %10944 = add i64 %10943, %10942
  %10945 = add i64 %10933, 15
  store i64 %10945, i64* %3, align 8
  %10946 = inttoptr i64 %10944 to i32*
  %10947 = load i32, i32* %10946, align 4
  %10948 = zext i32 %10947 to i64
  store i64 %10948, i64* %RDX.i1708, align 8
  %10949 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %10949, i64* %RAX.i893, align 8
  %10950 = add i64 %10933, 27
  store i64 %10950, i64* %3, align 8
  %10951 = load i32, i32* %10939, align 4
  %10952 = sext i32 %10951 to i64
  store i64 %10952, i64* %RCX.i1197, align 8
  %10953 = shl nsw i64 %10952, 2
  %10954 = add i64 %10949, 3144
  %10955 = add i64 %10954, %10953
  %10956 = add i64 %10933, 34
  store i64 %10956, i64* %3, align 8
  %10957 = inttoptr i64 %10955 to i32*
  store i32 %10947, i32* %10957, align 4
  %10958 = load i64, i64* %RBP.i, align 8
  %10959 = add i64 %10958, -12
  %10960 = load i64, i64* %3, align 8
  %10961 = add i64 %10960, 3
  store i64 %10961, i64* %3, align 8
  %10962 = inttoptr i64 %10959 to i32*
  %10963 = load i32, i32* %10962, align 4
  %10964 = add i32 %10963, 1
  %10965 = zext i32 %10964 to i64
  store i64 %10965, i64* %RAX.i893, align 8
  %10966 = icmp eq i32 %10963, -1
  %10967 = icmp eq i32 %10964, 0
  %10968 = or i1 %10966, %10967
  %10969 = zext i1 %10968 to i8
  store i8 %10969, i8* %19, align 1
  %10970 = and i32 %10964, 255
  %10971 = tail call i32 @llvm.ctpop.i32(i32 %10970)
  %10972 = trunc i32 %10971 to i8
  %10973 = and i8 %10972, 1
  %10974 = xor i8 %10973, 1
  store i8 %10974, i8* %26, align 1
  %10975 = xor i32 %10964, %10963
  %10976 = lshr i32 %10975, 4
  %10977 = trunc i32 %10976 to i8
  %10978 = and i8 %10977, 1
  store i8 %10978, i8* %31, align 1
  %10979 = zext i1 %10967 to i8
  store i8 %10979, i8* %34, align 1
  %10980 = lshr i32 %10964, 31
  %10981 = trunc i32 %10980 to i8
  store i8 %10981, i8* %37, align 1
  %10982 = lshr i32 %10963, 31
  %10983 = xor i32 %10980, %10982
  %10984 = add nuw nsw i32 %10983, %10980
  %10985 = icmp eq i32 %10984, 2
  %10986 = zext i1 %10985 to i8
  store i8 %10986, i8* %43, align 1
  %10987 = add i64 %10960, 9
  store i64 %10987, i64* %3, align 8
  store i32 %10964, i32* %10962, align 4
  %10988 = load i64, i64* %RBP.i, align 8
  %10989 = add i64 %10988, -20
  %10990 = load i64, i64* %3, align 8
  %10991 = add i64 %10990, 3
  store i64 %10991, i64* %3, align 8
  %10992 = inttoptr i64 %10989 to i32*
  %10993 = load i32, i32* %10992, align 4
  %10994 = add i32 %10993, 1
  %10995 = zext i32 %10994 to i64
  store i64 %10995, i64* %RAX.i893, align 8
  %10996 = icmp eq i32 %10993, -1
  %10997 = icmp eq i32 %10994, 0
  %10998 = or i1 %10996, %10997
  %10999 = zext i1 %10998 to i8
  store i8 %10999, i8* %19, align 1
  %11000 = and i32 %10994, 255
  %11001 = tail call i32 @llvm.ctpop.i32(i32 %11000)
  %11002 = trunc i32 %11001 to i8
  %11003 = and i8 %11002, 1
  %11004 = xor i8 %11003, 1
  store i8 %11004, i8* %26, align 1
  %11005 = xor i32 %10994, %10993
  %11006 = lshr i32 %11005, 4
  %11007 = trunc i32 %11006 to i8
  %11008 = and i8 %11007, 1
  store i8 %11008, i8* %31, align 1
  %11009 = zext i1 %10997 to i8
  store i8 %11009, i8* %34, align 1
  %11010 = lshr i32 %10994, 31
  %11011 = trunc i32 %11010 to i8
  store i8 %11011, i8* %37, align 1
  %11012 = lshr i32 %10993, 31
  %11013 = xor i32 %11010, %11012
  %11014 = add nuw nsw i32 %11013, %11010
  %11015 = icmp eq i32 %11014, 2
  %11016 = zext i1 %11015 to i8
  store i8 %11016, i8* %43, align 1
  %11017 = add i64 %10990, 9
  store i64 %11017, i64* %3, align 8
  store i32 %10994, i32* %10992, align 4
  %11018 = load i64, i64* %3, align 8
  %11019 = add i64 %11018, -129
  store i64 %11019, i64* %3, align 8
  br label %block_.L_48fa11

block_.L_48fa97:                                  ; preds = %block_.L_48fa11
  %11020 = add i64 %10848, -16
  %11021 = add i64 %10887, 8
  store i64 %11021, i64* %3, align 8
  %11022 = inttoptr i64 %11020 to i32*
  %11023 = load i32, i32* %11022, align 4
  %11024 = add i32 %11023, 1
  %11025 = zext i32 %11024 to i64
  store i64 %11025, i64* %RAX.i893, align 8
  %11026 = icmp eq i32 %11023, -1
  %11027 = icmp eq i32 %11024, 0
  %11028 = or i1 %11026, %11027
  %11029 = zext i1 %11028 to i8
  store i8 %11029, i8* %19, align 1
  %11030 = and i32 %11024, 255
  %11031 = tail call i32 @llvm.ctpop.i32(i32 %11030)
  %11032 = trunc i32 %11031 to i8
  %11033 = and i8 %11032, 1
  %11034 = xor i8 %11033, 1
  store i8 %11034, i8* %26, align 1
  %11035 = xor i32 %11024, %11023
  %11036 = lshr i32 %11035, 4
  %11037 = trunc i32 %11036 to i8
  %11038 = and i8 %11037, 1
  store i8 %11038, i8* %31, align 1
  %11039 = zext i1 %11027 to i8
  store i8 %11039, i8* %34, align 1
  %11040 = lshr i32 %11024, 31
  %11041 = trunc i32 %11040 to i8
  store i8 %11041, i8* %37, align 1
  %11042 = lshr i32 %11023, 31
  %11043 = xor i32 %11040, %11042
  %11044 = add nuw nsw i32 %11043, %11040
  %11045 = icmp eq i32 %11044, 2
  %11046 = zext i1 %11045 to i8
  store i8 %11046, i8* %43, align 1
  %11047 = add i64 %10887, 14
  store i64 %11047, i64* %3, align 8
  store i32 %11024, i32* %11022, align 4
  %11048 = load i64, i64* %3, align 8
  %11049 = add i64 %11048, -193
  store i64 %11049, i64* %3, align 8
  br label %block_.L_48f9e4

block_.L_48faaa:                                  ; preds = %block_.L_48f9e4
  %11050 = add i64 %10799, -56
  %11051 = add i64 %10838, 4
  store i64 %11051, i64* %3, align 8
  %11052 = inttoptr i64 %11050 to i64*
  %11053 = load i64, i64* %11052, align 8
  store i64 %11053, i64* %RAX.i893, align 8
  %11054 = add i64 %11053, 524
  %11055 = add i64 %10838, 10
  store i64 %11055, i64* %3, align 8
  %11056 = inttoptr i64 %11054 to i32*
  %11057 = load i32, i32* %11056, align 4
  %11058 = zext i32 %11057 to i64
  store i64 %11058, i64* %RCX.i1197, align 8
  %11059 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  %11060 = add i64 %11059, 3332
  %11061 = add i64 %10838, 24
  store i64 %11061, i64* %3, align 8
  %11062 = inttoptr i64 %11060 to i32*
  store i32 %11057, i32* %11062, align 4
  %11063 = load i64, i64* %3, align 8
  %11064 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %11064, i64* %RAX.i893, align 8
  %11065 = add i64 %11064, 72380
  %11066 = add i64 %11063, 14
  store i64 %11066, i64* %3, align 8
  %11067 = inttoptr i64 %11065 to i32*
  %11068 = load i32, i32* %11067, align 4
  %11069 = zext i32 %11068 to i64
  store i64 %11069, i64* %RCX.i1197, align 8
  %11070 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %11070, i64* %RAX.i893, align 8
  %11071 = add i64 %11070, 3328
  %11072 = add i64 %11063, 28
  store i64 %11072, i64* %3, align 8
  %11073 = inttoptr i64 %11071 to i32*
  store i32 %11068, i32* %11073, align 4
  %.pre243 = load i64, i64* %RBP.i, align 8
  %.pre244 = load i64, i64* %3, align 8
  br label %block_.L_48fade

block_.L_48fade:                                  ; preds = %block_.L_48faaa, %block_.L_48f9b7
  %11074 = phi i64 [ %.pre244, %block_.L_48faaa ], [ %10783, %block_.L_48f9b7 ]
  %11075 = phi i64 [ %.pre243, %block_.L_48faaa ], [ %10767, %block_.L_48f9b7 ]
  %RDI.i = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %11076 = add i64 %11075, -56
  %11077 = add i64 %11074, 4
  store i64 %11077, i64* %3, align 8
  %11078 = inttoptr i64 %11076 to i64*
  %11079 = load i64, i64* %11078, align 8
  store i64 %11079, i64* %RDI.i, align 8
  %11080 = add i64 %11075, -64
  %11081 = add i64 %11074, 7
  store i64 %11081, i64* %3, align 8
  %11082 = inttoptr i64 %11080 to i32*
  %11083 = load i32, i32* %11082, align 4
  %11084 = zext i32 %11083 to i64
  store i64 %11084, i64* %RSI.i4020.pre-phi, align 8
  %11085 = add i64 %11074, -16142
  %11086 = add i64 %11074, 12
  %11087 = load i64, i64* %6, align 8
  %11088 = add i64 %11087, -8
  %11089 = inttoptr i64 %11088 to i64*
  store i64 %11086, i64* %11089, align 8
  store i64 %11088, i64* %6, align 8
  store i64 %11085, i64* %3, align 8
  %call2_48fae5 = tail call %struct.Memory* @sub_48bbd0.SetMotionVectorsMB(%struct.State* nonnull %0, i64 %11085, %struct.Memory* %MEMORY.47)
  %11090 = load i64, i64* %6, align 8
  %11091 = load i64, i64* %3, align 8
  %11092 = add i64 %11090, 264
  store i64 %11092, i64* %6, align 8
  %11093 = icmp ugt i64 %11090, -265
  %11094 = zext i1 %11093 to i8
  store i8 %11094, i8* %19, align 1
  %11095 = trunc i64 %11092 to i32
  %11096 = and i32 %11095, 255
  %11097 = tail call i32 @llvm.ctpop.i32(i32 %11096)
  %11098 = trunc i32 %11097 to i8
  %11099 = and i8 %11098, 1
  %11100 = xor i8 %11099, 1
  store i8 %11100, i8* %26, align 1
  %11101 = xor i64 %11092, %11090
  %11102 = lshr i64 %11101, 4
  %11103 = trunc i64 %11102 to i8
  %11104 = and i8 %11103, 1
  store i8 %11104, i8* %31, align 1
  %11105 = icmp eq i64 %11092, 0
  %11106 = zext i1 %11105 to i8
  store i8 %11106, i8* %34, align 1
  %11107 = lshr i64 %11092, 63
  %11108 = trunc i64 %11107 to i8
  store i8 %11108, i8* %37, align 1
  %11109 = lshr i64 %11090, 63
  %11110 = xor i64 %11107, %11109
  %11111 = add nuw nsw i64 %11110, %11107
  %11112 = icmp eq i64 %11111, 2
  %11113 = zext i1 %11112 to i8
  store i8 %11113, i8* %43, align 1
  %11114 = add i64 %11091, 8
  store i64 %11114, i64* %3, align 8
  %11115 = add i64 %11090, 272
  %11116 = inttoptr i64 %11092 to i64*
  %11117 = load i64, i64* %11116, align 8
  store i64 %11117, i64* %RBX.i772, align 8
  store i64 %11115, i64* %6, align 8
  %11118 = add i64 %11091, 9
  store i64 %11118, i64* %3, align 8
  %11119 = add i64 %11090, 280
  %11120 = inttoptr i64 %11115 to i64*
  %11121 = load i64, i64* %11120, align 8
  store i64 %11121, i64* %RBP.i, align 8
  store i64 %11119, i64* %6, align 8
  %11122 = add i64 %11091, 10
  store i64 %11122, i64* %3, align 8
  %11123 = inttoptr i64 %11119 to i64*
  %11124 = load i64, i64* %11123, align 8
  store i64 %11124, i64* %3, align 8
  %11125 = add i64 %11090, 288
  store i64 %11125, i64* %6, align 8
  ret %struct.Memory* %call2_48fae5
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_pushq__rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %3, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rsp___rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RBP, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_pushq__rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %RBX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %3, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_subq__0x108___rsp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, -264
  store i64 %6, i64* %RSP, align 8
  %7 = icmp ult i64 %3, 264
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %28
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3758__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 14168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0xc__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x278___rcx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 632
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rcx___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RAX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x38__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x7247a0___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 7
  store i64 %4, i64* %PC, align 8
  %5 = load i32, i32* bitcast (%G_0x7247a0_type* @G_0x7247a0 to i32*), align 8
  %6 = zext i32 %5 to i64
  store i64 %6, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -60
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__0x18__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 24
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -1
  %10 = icmp eq i32 %8, 0
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_sete__sil(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SIL = bitcast %union.anon* %3 to i8*
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %7 = load i8, i8* %6, align 1
  store i8 %7, i8* %SIL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_andb__0x1___sil(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SIL = bitcast %union.anon* %3 to i8*
  %4 = load i8, i8* %SIL, align 1
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = and i8 %4, 1
  store i8 %7, i8* %SIL, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = zext i8 %7 to i32
  %10 = tail call i32 @llvm.ctpop.i32(i32 %9)
  %11 = trunc i32 %10 to i8
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = xor i8 %7, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %16, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzbl__sil___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SIL = bitcast %union.anon* %3 to i8*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i8, i8* %SIL, align 1
  %5 = zext i8 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__MINUS0x40__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -64
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x68__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 104
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x48__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -72
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1918__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6424
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x50__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -80
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1940__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x58__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -88
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11ad0__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72400
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48dc64(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x38__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x214__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 532
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 2, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x4___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 4, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xc__rdx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x74__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -116
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cltd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %7 = bitcast %union.anon* %6 to i32*
  %8 = load i32, i32* %7, align 8
  %9 = sext i32 %8 to i64
  %10 = lshr i64 %9, 32
  store i64 %10, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x74__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -116
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__esi(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %7, align 1
  %8 = and i32 %4, 255
  %9 = tail call i32 @llvm.ctpop.i32(i32 %8)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %14, align 1
  %15 = icmp eq i32 %4, 0
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %16, i8* %17, align 1
  %18 = lshr i32 %4, 31
  %19 = trunc i32 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %19, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %21, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_cmovnel__ecx___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %ECX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %9 = load i8, i8* %8, align 1
  %10 = icmp eq i8 %9, 0
  %11 = load i64, i64* %RSI, align 8
  %12 = select i1 %10, i64 %5, i64 %11
  %13 = and i64 %12, 4294967295
  store i64 %13, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi__MINUS0x78__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -120
  %6 = load i32, i32* %ESI, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48dc6e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_xorl__eax___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 2
  store i64 %4, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %5, align 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %6, align 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %7, align 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %8, align 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %9, align 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x78__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -120
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x78__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -120
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x5c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -92
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x10__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x10__MINUS0x10__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -16
  %10 = icmp ult i32 %8, 16
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %8, 16
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %8, 31
  %32 = xor i32 %28, %31
  %33 = add nuw nsw i32 %32, %31
  %34 = icmp eq i32 %33, 2
  %35 = zext i1 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %35, i8* %36, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48dd5d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0xc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x10__MINUS0xc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -16
  %10 = icmp ult i32 %8, 16
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %8, 16
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %8, 31
  %32 = xor i32 %28, %31
  %33 = add nuw nsw i32 %32, %31
  %34 = icmp eq i32 %33, 2
  %35 = zext i1 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %35, i8* %36, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48dd4a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x725320___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x725320_type* @G__0x725320 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x10__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xc__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rax__rcx_2____dx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %DX, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x50__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -80
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x9c__rcx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 156
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x10__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax__rcx_8____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x98__rcx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 152
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0xc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__dx____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %DX = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %DX, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48dd37(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rcx_2____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6d4518___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x8___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 8
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -9
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %EDX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48dd3c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 1
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RAX, align 8
  %9 = icmp eq i32 %6, -1
  %10 = icmp eq i32 %7, 0
  %11 = or i1 %9, %10
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1
  %14 = and i32 %7, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i32 %7, %6
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = zext i1 %10 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %7, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %6, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %27
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48dc8c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48dd4f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x10__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48dc7b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11bfc__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72700
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48df12(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl_0x11c08__rcx____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %RCX, align 8
  %6 = add i64 %5, 72712
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %4, %10
  %12 = icmp ult i32 %4, %10
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %10, %4
  %22 = xor i32 %21, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %11, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %4, 31
  %34 = lshr i32 %10, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48df0d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl_0x11c04__rcx____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %RCX, align 8
  %6 = add i64 %5, 72708
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = sub i32 %4, %10
  %12 = icmp ult i32 %4, %10
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %11, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %10, %4
  %22 = xor i32 %21, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %11, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %4, 31
  %34 = lshr i32 %10, 31
  %35 = xor i32 %34, %33
  %36 = xor i32 %30, %33
  %37 = add nuw nsw i32 %36, %35
  %38 = icmp eq i32 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48defa(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6f9360___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6f9360_type* @G__0x6f9360 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x726210___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x726210_type* @G__0x726210 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x10__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x5___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 5
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 59
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 224
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 58
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xc__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rcx__rdx_2____si(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %3 to i16*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %SI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x58__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -88
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = bitcast i64* %RCX to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xa4__rdx____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 164
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x10__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx__rdx_8____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xa0__rdx____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 160
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0xc__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__si____rcx__rdx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %3 to i16*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %SI, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rax__rcx_2____si(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %SI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x58__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -88
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xa4__rcx____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 164
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xa0__rcx____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 160
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__si____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %SI = bitcast %union.anon* %3 to i16*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %SI, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48dee7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rcx__rdx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6d4518___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x408___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 1032
  store i64 %6, i64* %RCX, align 8
  %7 = icmp ugt i64 %3, -1033
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x6___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 6
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 58
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 192
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 57
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi____rcx__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %ESI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movzwl___rax__rcx_2____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x808___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 2056
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -2057
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__esi____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %ESI, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48deec(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48dd97(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48deff(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48dd79(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48df12(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cc5f0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cc5f0_type* @G_0x6cc5f0 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x20__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3738__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__0x6cc5f0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 8
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* bitcast (%G_0x6cc5f0_type* @G_0x6cc5f0 to i64*), align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x20__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -32
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__0x3738__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 14136
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cc600___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cc600_type* @G_0x6cc600 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x28__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x3740__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 14144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__0x6cc600(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 8
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* bitcast (%G_0x6cc600_type* @G_0x6cc600 to i64*), align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x28__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -40
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__0x3740__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 14144
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x6d4688___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 7
  store i64 %4, i64* %PC, align 8
  %5 = load i32, i32* bitcast (%G_0x6d4688_type* @G_0x6d4688 to i32*), align 8
  %6 = zext i32 %5 to i64
  store i64 %6, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__0x1cc__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = add i64 %4, 460
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6f8f10___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6f8f10_type* @G_0x6f8f10 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x38__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__0x1d0__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 464
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x3c__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__0x48__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = add i64 %4, 72
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e221(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x3c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0xc98__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 3224
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11abc__rcx____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 72380
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0xd00__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 3328
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x6d4688___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 7
  store i64 %4, i64* %PC, align 8
  %5 = load i32, i32* bitcast (%G_0x6d4688_type* @G_0x6d4688 to i32*), align 8
  %6 = zext i32 %5 to i64
  store i64 %6, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0xc88__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 3208
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6f8f10___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6f8f10_type* @G_0x6f8f10 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6d4518___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6d4518_type* @G_0x6d4518 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rcx__0xc90__rdx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 3216
  %5 = load i64, i64* %RCX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0xc18__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 3096
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x250__rcx____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 592
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0xd14__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 3348
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x254__rcx____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 596
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0xd18__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 3352
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0xc__rcx____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0xd10__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 3344
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11bf4__rcx____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 72692
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x4___edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 4
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RDX, align 8
  %9 = icmp ugt i32 %6, -5
  %10 = zext i1 %9 to i8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %10, i8* %11, align 1
  %12 = and i32 %7, 255
  %13 = tail call i32 @llvm.ctpop.i32(i32 %12)
  %14 = trunc i32 %13 to i8
  %15 = and i8 %14, 1
  %16 = xor i8 %15, 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %16, i8* %17, align 1
  %18 = xor i32 %7, %6
  %19 = lshr i32 %18, 4
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i32 %7, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i32 %7, 31
  %27 = trunc i32 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i32 %6, 31
  %30 = xor i32 %26, %29
  %31 = add nuw nsw i32 %30, %26
  %32 = icmp eq i32 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__edx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = load i32, i32* %EAX, align 4
  %6 = load i32, i32* %EDX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = sub i32 %5, %6
  %10 = icmp ult i32 %5, %6
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %6, %5
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = lshr i32 %6, 31
  %33 = xor i32 %32, %31
  %34 = xor i32 %28, %31
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48e169(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0x10__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48e156(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x14__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -20
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__MINUS0x14__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -20
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48e143(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x41__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -65
  %10 = icmp ult i32 %8, 65
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48e130(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x14__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -20
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x2c__rbp____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl___rax__rcx_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0xc08__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 3080
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x2c__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -44
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e0bc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e135(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x14__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -20
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x14__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -20
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e0ab(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e148(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e09a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e15b(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e077(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x3__MINUS0xc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -3
  %10 = icmp ult i32 %8, 3
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48e21c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48e209(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x12__MINUS0x2c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -44
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -18
  %10 = icmp ult i32 %8, 18
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %8, 16
  %20 = xor i32 %19, %9
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = icmp eq i32 %9, 0
  %26 = zext i1 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %9, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %8, 31
  %32 = xor i32 %28, %31
  %33 = add nuw nsw i32 %32, %31
  %34 = icmp eq i32 %33, 2
  %35 = zext i1 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %35, i8* %36, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48e1f6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0xc10__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 3088
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e192(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e1fb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e181(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e20e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e170(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e221(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x4__MINUS0xc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -4
  %10 = icmp ult i32 %8, 4
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48e2ce(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xc__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movswl_0x6cea20___rax_2____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 1
  %5 = add i64 %4, 7137824
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = sext i16 %9 to i64
  %11 = and i64 %10, 4294967295
  store i64 %11, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__0x1d8__rax__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 472
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ECX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movswl_0x6d452c___rax_2____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 1
  %5 = add i64 %4, 7161132
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 8
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = sext i16 %9 to i64
  %11 = and i64 %10, 4294967295
  store i64 %11, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__0x1e8__rax__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 488
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ECX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e2bb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__0xc20__rax__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 3104
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ECX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__0xc30__rax__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 3120
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ECX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e2c0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e228(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__0x48__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -1
  %10 = icmp eq i32 %8, 0
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48e2f2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x6d2080___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 7
  store i64 %4, i64* %PC, align 8
  %5 = load i32, i32* bitcast (%G_0x6d2080_type* @G_0x6d2080 to i32*), align 8
  %6 = zext i32 %5 to i64
  store i64 %6, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x244__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 580
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e300(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__0x244__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 580
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x8__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -8
  %10 = icmp ult i32 %8, 8
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48e337(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x723710(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i32, i32* bitcast (%G_0x723710_type* @G_0x723710 to i32*), align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %6, align 1
  %7 = and i32 %5, 255
  %8 = tail call i32 @llvm.ctpop.i32(i32 %7)
  %9 = trunc i32 %8 to i8
  %10 = and i8 %9, 1
  %11 = xor i8 %10, 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %11, i8* %12, align 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %13, align 1
  %14 = icmp eq i32 %5, 0
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %15, i8* %16, align 1
  %17 = lshr i32 %5, 31
  %18 = trunc i32 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %18, i8* %19, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %20, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb8f8___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb8f8_type* @G_0x6cb8f8 to i64*), align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0xc94__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 3220
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e337(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x1___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 1, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.RestoreMV8x8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x1cc__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 460
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_andl__0xf___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = and i64 %3, 15
  %7 = trunc i64 %6 to i32
  store i64 %6, i64* %RCX, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = tail call i32 @llvm.ctpop.i32(i32 %7)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = icmp eq i32 %7, 0
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %15, i8* %16, align 1
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %19, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %ECX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %7, align 1
  %8 = and i32 %4, 255
  %9 = tail call i32 @llvm.ctpop.i32(i32 %8)
  %10 = trunc i32 %9 to i8
  %11 = and i8 %10, 1
  %12 = xor i8 %11, 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %12, i8* %13, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %14, align 1
  %15 = icmp eq i32 %4, 0
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %16, i8* %17, align 1
  %18 = lshr i32 %4, 31
  %19 = trunc i32 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %19, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %21, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48e37c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x9__0x48__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -9
  %10 = icmp ult i32 %8, 9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e37c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0xd__0x48__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -13
  %10 = icmp ult i32 %8, 13
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x0__0x23c__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 572
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 10
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  store i32 0, i32* %7, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e38d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x723710___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 7
  store i64 %4, i64* %PC, align 8
  %5 = load i32, i32* bitcast (%G_0x723710_type* @G_0x723710 to i32*), align 8
  %6 = zext i32 %5 to i64
  store i64 %6, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x23c__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 572
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x23c__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 572
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__0xd08__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = add i64 %4, 3336
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__0x9a0__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 2464
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -2
  %10 = icmp ult i32 %8, 2
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48e402(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e402(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__al___cl(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %4 to i8*
  %5 = load i8, i8* %AL, align 1
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i8 %5, i8* %CL, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb918___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb918_type* @G_0x6cb918 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x30__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 48
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x88__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rdx__rsi_8____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x8c__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 140
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movb__cl____rdx__rsi_1_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %CL = bitcast %union.anon* %3 to i8*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = add i64 %5, %4
  %7 = load i8, i8* %CL, align 1
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %6 to i8*
  store i8 %7, i8* %10, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48edd8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48edc5(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x7c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -124
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x7c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -124
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x80__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -128
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edi___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 2
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shll__0x1___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 2
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = shl i32 %6, 1
  %8 = icmp slt i32 %6, 0
  %9 = icmp slt i32 %7, 0
  %10 = xor i1 %8, %9
  %11 = zext i32 %7 to i64
  store i64 %11, i64* %RAX, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %.lobit = lshr i32 %6, 31
  %13 = trunc i32 %.lobit to i8
  store i8 %13, i8* %12, align 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = and i32 %7, 254
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  store i8 %19, i8* %14, align 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %20, align 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %22 = icmp eq i32 %7, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %21, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %25 = lshr i32 %6, 30
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  store i8 %27, i8* %24, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %29 = zext i1 %10 to i8
  store i8 %29, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x80__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -128
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = load i32, i32* %EAX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RDI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edi___r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i32, i32* %EDI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__0x1e8__rcx__r8_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 488
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 9
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, -1
  %13 = icmp eq i32 %11, 0
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %12, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %12, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %12, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %12, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = xor i32 %30, %33
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e48a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0xa__0x48__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -10
  %10 = icmp ult i32 %8, 10
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48e5e0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1950__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6480
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = bitcast i64* %RAX to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__rcx____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0xc__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__edx___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i32, i32* %EDX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__rcx____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 148
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x10__rbp____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__0xffff____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  store i16 -1, i16* %9, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1958__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6488
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0xffffffffffffffff____rax__rcx_8_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 8
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  store i64 -1, i64* %9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1968__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 6504
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__0x0____rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = bitcast i64* %RAX to i16**
  %4 = load i16*, i16** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 5
  store i64 %6, i64* %PC, align 8
  store i16 0, i16* %4, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__0x0__0x2__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 2
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i16*
  store i16 0, i16* %7, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e5db(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0xcc0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 6
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 3264
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -3265
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x3___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 3
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 61
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 60
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48ebe2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x244__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 580
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e8ce(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x84__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -132
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x84__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -132
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x88__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -136
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x88__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x2__0x1e8__rcx__r8_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 488
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 9
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, -2
  %13 = icmp ult i32 %11, 2
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = and i32 %12, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16)
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1
  %22 = xor i32 %12, %11
  %23 = lshr i32 %22, 4
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1
  %27 = icmp eq i32 %12, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %12, 31
  %31 = trunc i32 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = xor i32 %30, %33
  %35 = add nuw nsw i32 %34, %33
  %36 = icmp eq i32 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48e8ce(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x1__0x244__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 580
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -1
  %10 = icmp eq i32 %8, 0
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48e673(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x11900__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 71936
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x90__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -144
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e689(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x11908__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 71944
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x90__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 5
  store i64 %4, i64* %PC, align 8
  store i64 2, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x68__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -104
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__rdx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rax__rdx_8____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__rdx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 148
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__0x0____rax__rdx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  store i16 0, i16* %9, align 2
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x18___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 24
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -25
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5c__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -92
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x0___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = and i64 %3, 4294967295
  store i64 %7, i64* %RSI, align 8
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %8, align 1
  %9 = and i32 %6, 255
  %10 = tail call i32 @llvm.ctpop.i32(i32 %9)
  %11 = trunc i32 %10 to i8
  %12 = and i8 %11, 1
  %13 = xor i8 %12, 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %13, i8* %14, align 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %15, align 1
  %16 = icmp eq i32 %6, 0
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %17, i8* %18, align 1
  %19 = lshr i32 %6, 31
  %20 = trunc i32 %19 to i8
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %20, i8* %21, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %22, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x108___rdx___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 264
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RDX, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RAX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1958__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 6488
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = bitcast i64* %RDX to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__rdi____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = add i64 %3, 144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__esi___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i32, i32* %ESI, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rdx__rdi_8____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__rdi____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = add i64 %3, 148
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax____rdx__rdi_8_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %RAX, align 8
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %6 to i64*
  store i64 %7, i64* %10, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x68__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -104
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x38__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x98__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -152
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0xa0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -160
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__ecx(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %ECX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xa4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -164
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xa4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -164
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i32, i32* %EAX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0xa0__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -160
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x1d8__r8__rdi_4____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %R8, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 472
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 8
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sext i32 %11 to i64
  store i64 %12, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x98__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -152
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___r9__rdi_8____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %RDI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rdi____r10w(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10W = bitcast %union.anon* %3 to i16*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = bitcast i64* %RDI to i16**
  %5 = load i16*, i16** %4, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = load i16, i16* %5, align 2
  store i16 %8, i16* %R10W, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1968__rdi____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = add i64 %3, 6504
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rdi____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = bitcast i64* %RDI to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__r11____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0xc__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rdi__r11_8____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = load i64, i64* %R11, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__r11____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = add i64 %3, 148
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x10__rbp____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = trunc i64 %3 to i32
  %9 = inttoptr i64 %5 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = add i32 %10, %8
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RAX, align 8
  %13 = icmp ult i32 %11, %8
  %14 = icmp ult i32 %11, %10
  %15 = or i1 %13, %14
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1
  %18 = and i32 %11, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18)
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1
  %24 = xor i32 %10, %8
  %25 = xor i32 %24, %11
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %11, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %11, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %8, 31
  %37 = lshr i32 %10, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__r10w____rdi_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10W = bitcast %union.anon* %3 to i16*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = bitcast i64* %RDI to i16**
  %5 = load i16*, i16** %4, align 8
  %6 = load i16, i16* %R10W, align 2
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  store i16 %6, i16* %5, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x68__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -104
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xc__rbp____r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x10__rbp____r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x38__rbp____r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xa8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -168
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xa8__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -168
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = load i32, i32* %EAX, align 4
  %6 = zext i32 %5 to i64
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 2
  store i64 %8, i64* %PC, align 8
  %9 = trunc i64 %4 to i32
  %10 = add i32 %5, %9
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %RCX, align 8
  %12 = icmp ult i32 %10, %9
  %13 = icmp ult i32 %10, %5
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i64 %6, %4
  %24 = trunc i64 %23 to i32
  %25 = xor i32 %24, %10
  %26 = lshr i32 %25, 4
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1
  %30 = icmp eq i32 %10, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1
  %33 = lshr i32 %10, 31
  %34 = trunc i32 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1
  %36 = lshr i32 %9, 31
  %37 = lshr i32 %5, 31
  %38 = xor i32 %33, %36
  %39 = xor i32 %33, %37
  %40 = add nuw nsw i32 %38, %39
  %41 = icmp eq i32 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__ecx___rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %4 = load i32, i32* %ECX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RBX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x1d8__r11__rbx_4____r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = load i64, i64* %RBX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 472
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 8
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sext i32 %11 to i64
  store i64 %12, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw_0x2__rdi____r10w(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10W = bitcast %union.anon* %3 to i16*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = add i64 %4, 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 5
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i16*
  %9 = load i16, i16* %8, align 2
  store i16 %9, i16* %R10W, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__r10w__0x2__rdi_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10W = bitcast %union.anon* %3 to i16*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %4 = load i64, i64* %RDI, align 8
  %5 = add i64 %4, 2
  %6 = load i16, i16* %R10W, align 2
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 5
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i16*
  store i16 %6, i16* %9, align 2
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11ad0__rdi_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = add i64 %3, 72400
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48e8c9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__0x0____rax__rcx_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  store i16 0, i16* %9, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48ebdd(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d1290___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x3___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 3
  store i64 %6, i64* %RDX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 61
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 60
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rcx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rdx___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RSI, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rsi__rdx_2____di(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %DI = bitcast %union.anon* %3 to i16*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i16*
  %11 = load i16, i16* %10, align 2
  store i16 %11, i16* %DI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1950__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 6480
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__rsi____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 144
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0xc__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -12
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r8d___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %R8D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__rsi____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RSI, align 8
  %5 = add i64 %4, 148
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl_MINUS0x10__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %6, -16
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i32 %11, %5
  %13 = zext i32 %12 to i64
  store i64 %13, i64* %4, align 8
  %14 = icmp ult i32 %12, %5
  %15 = icmp ult i32 %12, %11
  %16 = or i1 %14, %15
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1
  %19 = and i32 %12, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19)
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1
  %25 = xor i32 %11, %5
  %26 = xor i32 %25, %12
  %27 = lshr i32 %26, 4
  %28 = trunc i32 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1
  %31 = icmp eq i32 %12, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1
  %34 = lshr i32 %12, 31
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1
  %37 = lshr i32 %5, 31
  %38 = lshr i32 %11, 31
  %39 = xor i32 %34, %37
  %40 = xor i32 %34, %38
  %41 = add nuw nsw i32 %39, %40
  %42 = icmp eq i32 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__di____rdx__rsi_2_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %DI = bitcast %union.anon* %3 to i16*
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i64, i64* %RDX, align 8
  %5 = load i64, i64* %RSI, align 8
  %6 = shl i64 %5, 1
  %7 = add i64 %6, %4
  %8 = load i16, i16* %DI, align 2
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i16*
  store i16 %8, i16* %11, align 2
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x18___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 24
  store i64 %6, i64* %RDX, align 8
  %7 = icmp ugt i64 %3, -25
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %3, 16
  %18 = xor i64 %17, %6
  %19 = lshr i64 %18, 4
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %21, i8* %22, align 1
  %23 = icmp eq i64 %6, 0
  %24 = zext i1 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %24, i8* %25, align 1
  %26 = lshr i64 %6, 63
  %27 = trunc i64 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %3, 63
  %30 = xor i64 %26, %29
  %31 = add nuw nsw i64 %30, %26
  %32 = icmp eq i64 %31, 2
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %33, i8* %34, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x5c__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -92
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x0___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = zext i32 %5 to i64
  store i64 %8, i64* %4, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %5, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %5, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %5, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_imulq__0x108___rsi___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = sext i64 %3 to i128
  %7 = and i128 %6, -18446744073709551616
  %8 = zext i64 %3 to i128
  %9 = or i128 %7, %8
  %10 = mul nsw i128 %9, 264
  %11 = trunc i128 %10 to i64
  store i64 %11, i64* %RSI, align 8
  %12 = sext i64 %11 to i128
  %13 = icmp ne i128 %12, %10
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1
  %16 = trunc i128 %10 to i32
  %17 = and i32 %16, 248
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %23, align 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %24, align 1
  %25 = lshr i64 %11, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %14, i8* %28, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RDX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1950__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 6480
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = bitcast i64* %RSI to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %4, align 8
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x6cb900___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x6cb900_type* @G_0x6cb900 to i64*), align 8
  store i64 %5, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__r9____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %R9, align 8
  %5 = add i64 %4, 144
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r8d___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i32, i32* %R8D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi__r9_8____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R9, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__r9____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %R9, align 8
  %5 = add i64 %4, 148
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movswq___rsi__r9_2____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R9, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 5
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = sext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1958__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 6488
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx____rsi__r9_8_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R9, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %RDX, align 8
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 4
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %6 to i64*
  store i64 %7, i64* %10, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x118f8__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 71928
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0xc__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -12
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x10__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -16
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x3___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 3
  store i64 %6, i64* %RSI, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 61
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 60
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rcx___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  store i64 %3, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__rsi___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %R9, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movswq___r9__rsi_2____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 5
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = sext i16 %10 to i64
  store i64 %11, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x38__rbp____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xac__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -172
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r8d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %R8D, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0xb8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -184
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xac__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -172
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

define %struct.Memory* @routine_idivl__r8d(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = load i32, i32* %R8D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %8 = bitcast %union.anon* %7 to i32*
  %9 = load i32, i32* %8, align 8
  %10 = zext i32 %9 to i64
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %12 = bitcast %union.anon* %11 to i32*
  %13 = load i32, i32* %12, align 8
  %14 = zext i32 %13 to i64
  %15 = sext i32 %4 to i64
  %16 = shl nuw i64 %14, 32
  %17 = or i64 %16, %10
  %18 = sdiv i64 %17, %15
  %19 = shl i64 %18, 32
  %20 = ashr exact i64 %19, 32
  %21 = icmp eq i64 %18, %20
  br i1 %21, label %24, label %22

; <label>:22:                                     ; preds = %block_400488
  %23 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %6, %struct.Memory* %2)
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:24:                                     ; preds = %block_400488
  %25 = srem i64 %17, %15
  %26 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %27 = and i64 %18, 4294967295
  store i64 %27, i64* %26, align 8
  %28 = getelementptr inbounds %union.anon, %union.anon* %11, i64 0, i32 0
  %29 = and i64 %25, 4294967295
  store i64 %29, i64* %28, align 8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %30, align 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 0, i8* %31, align 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %32, align 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %34, align 1
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %35, align 1
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %24, %22
  %36 = phi %struct.Memory* [ %23, %22 ], [ %2, %24 ]
  ret %struct.Memory* %36
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xbc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -188
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__r10d___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = zext i32 %4 to i64
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  store i64 %5, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xbc__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -188
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__eax___r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %6 = load i32, i32* %R10D, align 4
  %7 = load i32, i32* %EAX, align 4
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 3
  store i64 %9, i64* %PC, align 8
  %10 = add i32 %7, %6
  %11 = zext i32 %10 to i64
  store i64 %11, i64* %5, align 8
  %12 = icmp ult i32 %10, %6
  %13 = icmp ult i32 %10, %7
  %14 = or i1 %12, %13
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1
  %17 = and i32 %10, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17)
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1
  %23 = xor i32 %7, %6
  %24 = xor i32 %23, %10
  %25 = lshr i32 %24, 4
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1
  %29 = icmp eq i32 %10, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1
  %32 = lshr i32 %10, 31
  %33 = trunc i32 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1
  %35 = lshr i32 %6, 31
  %36 = lshr i32 %7, 31
  %37 = xor i32 %32, %35
  %38 = xor i32 %32, %36
  %39 = add nuw nsw i32 %37, %38
  %40 = icmp eq i32 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x1d8__rsi__r9_4____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R9, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 472
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 8
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0xb8__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -184
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___r9__rsi_8____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %R9, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw___rsi____di(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %DI = bitcast %union.anon* %3 to i16*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = bitcast i64* %RSI to i16**
  %5 = load i16*, i16** %4, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 3
  store i64 %7, i64* %PC, align 8
  %8 = load i16, i16* %5, align 2
  store i16 %8, i16* %DI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1968__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 6504
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi__r11_8____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R11, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__di____rsi_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %DI = bitcast %union.anon* %3 to i16*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = bitcast i64* %RSI to i16**
  %5 = load i16*, i16** %4, align 8
  %6 = load i16, i16* %DI, align 2
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  store i16 %6, i16* %5, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x118f8__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 71928
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x3___r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %R11, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 3
  store i64 %6, i64* %R11, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 61
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 248
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 60
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__r11___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %R11, align 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = add i64 %4, %3
  store i64 %7, i64* %RCX, align 8
  %8 = icmp ult i64 %7, %3
  %9 = icmp ult i64 %7, %4
  %10 = or i1 %8, %9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = trunc i64 %7 to i32
  %14 = and i32 %13, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i64 %4, %3
  %21 = xor i64 %20, %7
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = icmp eq i64 %7, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1
  %29 = lshr i64 %7, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1
  %32 = lshr i64 %3, 63
  %33 = lshr i64 %4, 63
  %34 = xor i64 %29, %32
  %35 = xor i64 %29, %33
  %36 = add nuw nsw i64 %34, %35
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movswq___rcx__r11_2____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %R11, align 8
  %5 = shl i64 %4, 1
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 5
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i16*
  %10 = load i16, i16* %9, align 2
  %11 = sext i16 %10 to i64
  store i64 %11, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rsi__rcx_8____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xc0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -192
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc0__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -192
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__r10d___r11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %3 to i32*
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %4 = load i32, i32* %R10D, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %R11, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_0x1d8__rsi__r11_4____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %R11, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 472
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 8
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = sext i32 %11 to i64
  store i64 %12, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq___rcx__rsi_8____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %RSI, align 8
  %5 = shl i64 %4, 3
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i64*
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw_0x2__rcx____di(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %DI = bitcast %union.anon* %3 to i16*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 2
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i16*
  %9 = load i16, i16* %8, align 2
  store i16 %9, i16* %DI, align 2
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70fcf0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 8
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* bitcast (%G_0x70fcf0_type* @G_0x70fcf0 to i64*), align 8
  store i64 %5, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x1968__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 6504
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq__eax___rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %4 = load i32, i32* %EAX, align 4
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = sext i32 %4 to i64
  store i64 %7, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__rsi____eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 148
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movw__di__0x2__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %DI = bitcast %union.anon* %3 to i16*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 2
  %6 = load i16, i16* %DI, align 2
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 4
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i16*
  store i16 %6, i16* %9, align 2
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x11ad0__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 72400
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48ebd8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x6d1290___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x6d1290_type* @G__0x6d1290 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xc4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -196
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -196
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xc8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -200
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xc8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -200
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__0x1e8__rcx__r8_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %R8, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 488
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 9
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %12, align 1
  %13 = and i32 %11, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %19, align 1
  %20 = icmp eq i32 %11, 0
  %21 = zext i1 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %21, i8* %22, align 1
  %23 = lshr i32 %11, 31
  %24 = trunc i32 %23 to i8
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %24, i8* %25, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48ec54(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48edb2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48edad(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x20___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 32
  store i64 %6, i64* %RAX, align 8
  %7 = icmp ugt i64 %3, -33
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48edb2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48edb7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e41a(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48edca(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48e409(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x0__MINUS0x40__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -64
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %9, align 1
  %10 = and i32 %8, 255
  %11 = tail call i32 @llvm.ctpop.i32(i32 %10)
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %16, align 1
  %17 = icmp eq i32 %8, 0
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %18, i8* %19, align 1
  %20 = lshr i32 %8, 31
  %21 = trunc i32 %20 to i8
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %23, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48f616(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f611(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f5fe(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48ee76(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xcc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -204
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xcc__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -204
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xd0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -208
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xd0__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -208
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48efd4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48efcf(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f5eb(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48f2cc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xd4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -212
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xd4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -212
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xd8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -216
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xd8__rbp____edi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -216
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48f2cc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48f067(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0xe0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -224
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f07d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0xe0__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -224
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0x70__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -112
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x1___esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 3
  store i64 %5, i64* %PC, align 8
  %6 = trunc i64 %3 to i32
  %7 = add i32 %6, 1
  %8 = zext i32 %7 to i64
  store i64 %8, i64* %RSI, align 8
  %9 = icmp eq i32 %6, -1
  %10 = icmp eq i32 %7, 0
  %11 = or i1 %9, %10
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1
  %14 = and i32 %7, 255
  %15 = tail call i32 @llvm.ctpop.i32(i32 %14)
  %16 = trunc i32 %15 to i8
  %17 = and i8 %16, 1
  %18 = xor i8 %17, 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %18, i8* %19, align 1
  %20 = xor i32 %7, %6
  %21 = lshr i32 %20, 4
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %23, i8* %24, align 1
  %25 = zext i1 %10 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %7, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %6, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %27
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rdx____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RDX, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x70__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -112
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rax__MINUS0xe8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -232
  %5 = load i64, i64* %RAX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0xf0__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -240
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xf4__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -244
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xf4__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -244
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0xf0__rbp____r8(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -240
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0xe8__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -232
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rdi____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %3 = load i64, i64* %RDI, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x70__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -112
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xf8__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -248
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xf8__rbp____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -248
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48f2c7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f5e6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x7236a0___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64), i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addl__0x1___r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %5 = load i32, i32* %R8D, align 4
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 4
  store i64 %7, i64* %PC, align 8
  %8 = add i32 %5, 1
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %4, align 8
  %10 = icmp eq i32 %5, -1
  %11 = icmp eq i32 %8, 0
  %12 = or i1 %10, %11
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1
  %15 = and i32 %8, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15)
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1
  %21 = xor i32 %8, %5
  %22 = lshr i32 %21, 4
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1
  %26 = zext i1 %11 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %26, i8* %27, align 1
  %28 = lshr i32 %8, 31
  %29 = trunc i32 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %29, i8* %30, align 1
  %31 = lshr i32 %5, 31
  %32 = xor i32 %28, %31
  %33 = add nuw nsw i32 %32, %28
  %34 = icmp eq i32 %33, 2
  %35 = zext i1 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %35, i8* %36, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rsi____rsi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RSI, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0xfc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -252
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__rdx__MINUS0x108__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -264
  %5 = load i64, i64* %RDX, align 8
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %4 to i64*
  store i64 %5, i64* %8, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0xfc__rbp____r8d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -252
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x10c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -268
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x10c__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -268
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x108__rbp____r9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -264
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %R9, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__MINUS0x110__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -272
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x110__rbp____r10d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -272
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %3, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x8__rcx____rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 8
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48f5e1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x7236a0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x7236a0_type* @G__0x7236a0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f5f0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48edfa(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f603(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48ede9(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f616(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x710a58___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 7
  store i64 %4, i64* %PC, align 8
  %5 = load i32, i32* bitcast (%G_0x710a58_type* @G_0x710a58 to i32*), align 8
  %6 = zext i32 %5 to i64
  store i64 %6, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x20c__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 524
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x70fd50___eax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 7
  store i64 %4, i64* %PC, align 8
  %5 = load i32, i32* bitcast (%G_0x70fd50_type* @G_0x70fd50 to i32*), align 8
  %6 = zext i32 %5 to i64
  store i64 %6, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__eax__0x11abc__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RCX, align 8
  %5 = add i64 %4, 72380
  %6 = load i32, i32* %EAX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0xd__0x48__rcx_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -13
  %10 = icmp ult i32 %8, 13
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48f736(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f731(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f71e(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0x70__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 112
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__rcx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__rcx____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = add i64 %3, 148
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x18c__rax__rcx_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 396
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__0x14c__rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 332
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EDX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f669(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f723(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f658(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f8e0(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0x9__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -9
  %10 = icmp ult i32 %8, 9
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48f804(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_cmpl__0xd__MINUS0x3c__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -60
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = add i32 %8, -13
  %10 = icmp ult i32 %8, 13
  %11 = zext i1 %10 to i8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %11, i8* %12, align 1
  %13 = and i32 %9, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %17, i8* %18, align 1
  %19 = xor i32 %9, %8
  %20 = lshr i32 %19, 4
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %22, i8* %23, align 1
  %24 = icmp eq i32 %9, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %25, i8* %26, align 1
  %27 = lshr i32 %9, 31
  %28 = trunc i32 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %28, i8* %29, align 1
  %30 = lshr i32 %8, 31
  %31 = xor i32 %27, %30
  %32 = add nuw nsw i32 %31, %30
  %33 = icmp eq i32 %32, 2
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %34, i8* %35, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x94__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 148
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0x10__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -16
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f7ff(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x90__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 144
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__MINUS0xc__rbp_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %4, -12
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 3
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f7ec(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x48__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -72
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2____rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %5, %3
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 7
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %6 to i32*
  store i32 2, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__0x2__0x14c__rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 332
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 11
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  store i32 2, i32* %10, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f78f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f7f1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f762(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f8db(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48f8d6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f8d1(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f8be(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x14__rbp____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -20
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x7236d0___rax_4____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 2
  %5 = add i64 %4, 7485136
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx____rax__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %6, %4
  %8 = load i32, i32* %ECX, align 4
  %9 = load i64, i64* %PC, align 8
  %10 = add i64 %9, 3
  store i64 %10, i64* %PC, align 8
  %11 = inttoptr i64 %7 to i32*
  store i32 %8, i32* %11, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x70cfd0___rax_4____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 2
  %5 = add i64 %4, 7393232
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movslq_MINUS0x14__rbp____rdx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -20
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  store i64 %9, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__0x14c__rax__rdx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RDX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 332
  %8 = add i64 %7, %6
  %9 = load i32, i32* %ECX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f853(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f8c3(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f826(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f8d6(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jne_.L_48f9b7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  %6 = icmp eq i8 %5, 0
  %7 = zext i1 %6 to i8
  store i8 %7, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %8 = add i64 %.v, %3
  store i64 %8, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f9b2(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48f99f(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq__0x7242b0___rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 10
  store i64 %4, i64* %PC, align 8
  store i64 ptrtoint (%G__0x7242b0_type* @G__0x7242b0 to i64), i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_shlq__0x4___rcx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RCX, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 4
  store i64 %5, i64* %PC, align 8
  %6 = shl i64 %3, 4
  store i64 %6, i64* %RCX, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %8 = lshr i64 %3, 60
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  store i8 %10, i8* %7, align 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %12 = trunc i64 %6 to i32
  %13 = and i32 %12, 240
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13)
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %11, align 1
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %18, align 1
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %20 = icmp eq i64 %6, 0
  %21 = zext i1 %20 to i8
  store i8 %21, i8* %19, align 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %23 = lshr i64 %3, 59
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  store i8 %25, i8* %22, align 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %26, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x6d18c0___rax_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = shl i64 %3, 2
  %5 = add i64 %4, 7149760
  %6 = load i64, i64* %PC, align 8
  %7 = add i64 %6, 7
  store i64 %7, i64* %PC, align 8
  %8 = inttoptr i64 %5 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = zext i32 %9 to i64
  store i64 %10, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f90d(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f9a4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f8fc(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f9b7(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_je_.L_48fade(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %5 = load i8, i8* %4, align 1
  store i8 %5, i8* %BRANCH_TAKEN, align 1
  %6 = icmp ne i8 %5, 0
  %.v = select i1 %6, i64 %rel_off1, i64 %rel_off2
  %7 = add i64 %.v, %3
  store i64 %7, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48faaa(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jge_.L_48fa97(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i8* nocapture %BRANCH_TAKEN, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %5 = load i8, i8* %4, align 1
  %6 = icmp ne i8 %5, 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %8 = load i8, i8* %7, align 1
  %9 = icmp ne i8 %8, 0
  %10 = xor i1 %6, %9
  %11 = xor i1 %10, true
  %12 = zext i1 %11 to i8
  store i8 %12, i8* %BRANCH_TAKEN, align 1
  %.v = select i1 %10, i64 %rel_off2, i64 %rel_off1
  %13 = add i64 %.v, %3
  store i64 %13, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_0xc40__rax____rax(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 3136
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 7
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RAX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x14c__rax__rcx_4____edx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = load i64, i64* %RCX, align 8
  %5 = shl i64 %4, 2
  %6 = add i64 %3, 332
  %7 = add i64 %6, %5
  %8 = load i64, i64* %PC, align 8
  %9 = add i64 %8, 7
  store i64 %9, i64* %PC, align 8
  %10 = inttoptr i64 %7 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = zext i32 %11 to i64
  store i64 %12, i64* %RDX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__edx__0xc48__rax__rcx_4_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = load i64, i64* %RCX, align 8
  %6 = shl i64 %5, 2
  %7 = add i64 %4, 3144
  %8 = add i64 %7, %6
  %9 = load i32, i32* %EDX, align 4
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %10, 7
  store i64 %11, i64* %PC, align 8
  %12 = inttoptr i64 %8 to i32*
  store i32 %9, i32* %12, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48fa11(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48fa9c(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_jmpq_.L_48f9e4(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x20c__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 524
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__0xd04__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = add i64 %4, 3332
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_0x11abc__rax____ecx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %3 = load i64, i64* %RAX, align 8
  %4 = add i64 %3, 72380
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 6
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RCX, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl__ecx__0xd00__rax_(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %4 = load i64, i64* %RAX, align 8
  %5 = add i64 %4, 3328
  %6 = load i32, i32* %ECX, align 4
  %7 = load i64, i64* %PC, align 8
  %8 = add i64 %7, 6
  store i64 %8, i64* %PC, align 8
  %9 = inttoptr i64 %5 to i32*
  store i32 %6, i32* %9, align 4
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movq_MINUS0x38__rbp____rdi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -56
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 4
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %RDI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_movl_MINUS0x40__rbp____esi(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %3, -64
  %5 = load i64, i64* %PC, align 8
  %6 = add i64 %5, 3
  store i64 %6, i64* %PC, align 8
  %7 = inttoptr i64 %4 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = zext i32 %8 to i64
  store i64 %9, i64* %RSI, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_callq_.SetMotionVectorsMB(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned, i64 %rel_off1, i64 %rel_off2, i64 %rel_off3) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, %rel_off1
  %5 = add i64 %3, %rel_off2
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  store i64 %8, i64* %6, align 8
  store i64 %4, i64* %PC, align 8
  ret %struct.Memory* %2
}

; Function Attrs: nounwind
define %struct.Memory* @routine_addq__0x108___rsp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #3 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = load i64, i64* %PC, align 8
  %5 = add i64 %4, 7
  store i64 %5, i64* %PC, align 8
  %6 = add i64 %3, 264
  store i64 %6, i64* %RSP, align 8
  %7 = icmp ugt i64 %3, -265
  %8 = zext i1 %7 to i8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %8, i8* %9, align 1
  %10 = trunc i64 %6 to i32
  %11 = and i32 %10, 255
  %12 = tail call i32 @llvm.ctpop.i32(i32 %11)
  %13 = trunc i32 %12 to i8
  %14 = and i8 %13, 1
  %15 = xor i8 %14, 1
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %15, i8* %16, align 1
  %17 = xor i64 %6, %3
  %18 = lshr i64 %17, 4
  %19 = trunc i64 %18 to i8
  %20 = and i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %20, i8* %21, align 1
  %22 = icmp eq i64 %6, 0
  %23 = zext i1 %22 to i8
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %23, i8* %24, align 1
  %25 = lshr i64 %6, 63
  %26 = trunc i64 %25 to i8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %26, i8* %27, align 1
  %28 = lshr i64 %3, 63
  %29 = xor i64 %25, %28
  %30 = add nuw nsw i64 %29, %25
  %31 = icmp eq i64 %30, 2
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %32, i8* %33, align 1
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_popq__rbx(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 8
  %8 = inttoptr i64 %6 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %RBX, align 8
  store i64 %7, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_popq__rbp(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 8
  %8 = inttoptr i64 %6 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %RBP, align 8
  store i64 %7, i64* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: norecurse nounwind
define %struct.Memory* @routine_retq(%struct.State* nocapture dereferenceable(3376), i64, %struct.Memory* readnone returned) local_unnamed_addr #2 {
block_400488:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = load i64, i64* %PC, align 8
  %4 = add i64 %3, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = inttoptr i64 %6 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %PC, align 8
  %9 = add i64 %6, 8
  store i64 %9, i64* %5, align 8
  ret %struct.Memory* %2
}

attributes #0 = { nounwind readnone }
attributes #1 = { alwaysinline }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
