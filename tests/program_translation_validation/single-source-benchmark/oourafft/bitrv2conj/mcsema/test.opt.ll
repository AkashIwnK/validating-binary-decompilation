; ModuleID = 'mcsema/test.inline.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%union.anon = type { i64 }
%seg_404090__rodata_type = type <{ [24 x i8], [88 x i8], [45 x i8], [7 x i8] }>
%seg_604df0__init_array_type = type <{ i64, i64 }>
%seg_604ff0__got_type = type <{ i64, i64 }>
%__bss_start_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque
%struct.anon.2 = type { i8, i8 }
%"class.std::bitset" = type { %struct.uint64v4_t }
%struct.uint64v4_t = type { [4 x i64] }

@DR0 = external global i64, align 8
@DR1 = external global i64, align 8
@DR2 = external global i64, align 8
@DR3 = external global i64, align 8
@DR4 = external global i64, align 8
@DR5 = external global i64, align 8
@DR6 = external global i64, align 8
@DR7 = external global i64, align 8
@gCR0 = external global %union.anon, align 1
@gCR1 = external global %union.anon, align 1
@gCR2 = external global %union.anon, align 1
@gCR3 = external global %union.anon, align 1
@gCR4 = external global %union.anon, align 1
@gCR8 = external global %union.anon, align 1
@seg_404090__rodata = internal constant %seg_404090__rodata_type <{ [24 x i8] c"\01\00\02\00\00\00\00\00\BB\BD\D7\D9\DF|\DB=\00\00\00\00\00\00P?", [88 x i8] c"\00\00\00\00\00\00\90@\00\00\00\00\00\00\10@\00\00\00\00\00\00\E0C\95\D6&\E8\0B.\11>\8D\ED\B5\A0\F7\C6\B0>\00\00\00\00\00\00\F0?q\8B\89\C0\85.\D0>\00\00\00\00\00\00\00@\00\00\00\00\00\00\00\00\FF\FF\FF\FF\FF\FF\FF\7F\FF\FF\FF\FF\FF\FF\FF\7F", [45 x i8] c"FFT sanity check failed! Difference is: %le\0A\00", [7 x i8] c"%e %e\0A\00" }>
@seg_604df0__init_array = internal global %seg_604df0__init_array_type <{ i64 ptrtoint (void ()* @callback_sub_400830_frame_dummy to i64), i64 ptrtoint (void ()* @callback_sub_400800___do_global_dtors_aux to i64) }>
@seg_604ff0__got = internal global %seg_604ff0__got_type <{ i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), i64 ptrtoint (i64 ()* @__gmon_start__ to i64) }>
@__bss_start = global %__bss_start_type zeroinitializer
@0 = internal global i1 false
@1 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_400830_frame_dummy_wrapper
@2 = internal constant void ()* @__mcsema_attach_call
@3 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_400800___do_global_dtors_aux_wrapper
@4 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_404080___libc_csu_fini_wrapper
@5 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_404010___libc_csu_init_wrapper
@6 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @main_wrapper
@7 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @cdft_wrapper
@8 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @errorcheck_wrapper
@9 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.term_proc_wrapper
@10 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @get_time_wrapper
@11 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @putdata_wrapper
@12 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.init_proc_wrapper
@13 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @makewt_wrapper
@llvm.global_ctors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_constructor, i8* null }]
@llvm.global_dtors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_destructor, i8* null }]

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare double @llvm.fabs.f64(double) #0

; Function Attrs: nounwind readnone
declare double @llvm.trunc.f64(double) #0

; Function Attrs: nounwind readnone
declare double @sqrt(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @cos(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @sin(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @atan(double) local_unnamed_addr #2

; Function Attrs: noinline nounwind optnone
define %struct.Memory* @__remill_basic_block(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #3 !dbg !1261 {
  %state = alloca %struct.State*, align 8
  %curr_pc = alloca i64, align 8
  %memory = alloca %struct.Memory*, align 8
  %BRANCH_TAKEN = alloca i8, align 1
  %SS_BASE = alloca i64, align 8
  %ES_BASE = alloca i64, align 8
  %DS_BASE = alloca i64, align 8
  %CS_BASE = alloca i64, align 8
  %STATE = alloca %struct.State*, align 8
  %MEMORY = alloca %struct.Memory*, align 8
  %_DR0 = alloca i64*, align 8
  %_DR1 = alloca i64*, align 8
  %_DR2 = alloca i64*, align 8
  %_DR3 = alloca i64*, align 8
  %_DR4 = alloca i64*, align 8
  %_DR5 = alloca i64*, align 8
  %_DR6 = alloca i64*, align 8
  %_DR7 = alloca i64*, align 8
  %CR0 = alloca i64*, align 8
  %CR1 = alloca i64*, align 8
  %CR2 = alloca i64*, align 8
  %CR3 = alloca i64*, align 8
  %CR4 = alloca i64*, align 8
  %CR8 = alloca i64*, align 8
  store %struct.State* %0, %struct.State** %state, align 8
  store i64 %1, i64* %curr_pc, align 8
  store %struct.Memory* %2, %struct.Memory** %memory, align 8
  store i8 0, i8* %BRANCH_TAKEN, align 1, !dbg !1952
  store i64 0, i64* %SS_BASE, align 8, !dbg !1953
  store i64 0, i64* %ES_BASE, align 8, !dbg !1954
  store i64 0, i64* %DS_BASE, align 8, !dbg !1955
  store i64 0, i64* %CS_BASE, align 8, !dbg !1956
  store %struct.State* %0, %struct.State** %STATE, align 8, !dbg !1957
  store %struct.Memory* %2, %struct.Memory** %MEMORY, align 8, !dbg !1958
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1959
  %5 = getelementptr inbounds %struct.GPR, %struct.GPR* %4, i32 0, i32 33, !dbg !1960
  %6 = getelementptr inbounds %struct.Reg, %struct.Reg* %5, i32 0, i32 0, !dbg !1961
  %PC = bitcast %union.anon* %6 to i64*, !dbg !1961
  store i64 %1, i64* %PC, align 8, !dbg !1962
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1963
  %8 = getelementptr inbounds %struct.GPR, %struct.GPR* %7, i32 0, i32 1, !dbg !1964
  %9 = getelementptr inbounds %struct.Reg, %struct.Reg* %8, i32 0, i32 0, !dbg !1965
  %10 = bitcast %union.anon* %9 to %struct.anon.2*, !dbg !1965
  %AH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %10, i32 0, i32 1, !dbg !1966
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1967
  %12 = getelementptr inbounds %struct.GPR, %struct.GPR* %11, i32 0, i32 3, !dbg !1968
  %13 = getelementptr inbounds %struct.Reg, %struct.Reg* %12, i32 0, i32 0, !dbg !1969
  %14 = bitcast %union.anon* %13 to %struct.anon.2*, !dbg !1969
  %BH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %14, i32 0, i32 1, !dbg !1970
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1971
  %16 = getelementptr inbounds %struct.GPR, %struct.GPR* %15, i32 0, i32 5, !dbg !1972
  %17 = getelementptr inbounds %struct.Reg, %struct.Reg* %16, i32 0, i32 0, !dbg !1973
  %18 = bitcast %union.anon* %17 to %struct.anon.2*, !dbg !1973
  %CH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %18, i32 0, i32 1, !dbg !1974
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1975
  %20 = getelementptr inbounds %struct.GPR, %struct.GPR* %19, i32 0, i32 7, !dbg !1976
  %21 = getelementptr inbounds %struct.Reg, %struct.Reg* %20, i32 0, i32 0, !dbg !1977
  %22 = bitcast %union.anon* %21 to %struct.anon.2*, !dbg !1977
  %DH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %22, i32 0, i32 1, !dbg !1978
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1979
  %24 = getelementptr inbounds %struct.GPR, %struct.GPR* %23, i32 0, i32 1, !dbg !1980
  %25 = getelementptr inbounds %struct.Reg, %struct.Reg* %24, i32 0, i32 0, !dbg !1981
  %26 = bitcast %union.anon* %25 to %struct.anon.2*, !dbg !1981
  %AL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %26, i32 0, i32 0, !dbg !1982
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1983
  %28 = getelementptr inbounds %struct.GPR, %struct.GPR* %27, i32 0, i32 3, !dbg !1984
  %29 = getelementptr inbounds %struct.Reg, %struct.Reg* %28, i32 0, i32 0, !dbg !1985
  %30 = bitcast %union.anon* %29 to %struct.anon.2*, !dbg !1985
  %BL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %30, i32 0, i32 0, !dbg !1986
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1987
  %32 = getelementptr inbounds %struct.GPR, %struct.GPR* %31, i32 0, i32 5, !dbg !1988
  %33 = getelementptr inbounds %struct.Reg, %struct.Reg* %32, i32 0, i32 0, !dbg !1989
  %34 = bitcast %union.anon* %33 to %struct.anon.2*, !dbg !1989
  %CL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %34, i32 0, i32 0, !dbg !1990
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1991
  %36 = getelementptr inbounds %struct.GPR, %struct.GPR* %35, i32 0, i32 7, !dbg !1992
  %37 = getelementptr inbounds %struct.Reg, %struct.Reg* %36, i32 0, i32 0, !dbg !1993
  %38 = bitcast %union.anon* %37 to %struct.anon.2*, !dbg !1993
  %DL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %38, i32 0, i32 0, !dbg !1994
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1995
  %40 = getelementptr inbounds %struct.GPR, %struct.GPR* %39, i32 0, i32 9, !dbg !1996
  %41 = getelementptr inbounds %struct.Reg, %struct.Reg* %40, i32 0, i32 0, !dbg !1997
  %42 = bitcast %union.anon* %41 to %struct.anon.2*, !dbg !1997
  %SIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %42, i32 0, i32 0, !dbg !1998
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1999
  %44 = getelementptr inbounds %struct.GPR, %struct.GPR* %43, i32 0, i32 11, !dbg !2000
  %45 = getelementptr inbounds %struct.Reg, %struct.Reg* %44, i32 0, i32 0, !dbg !2001
  %46 = bitcast %union.anon* %45 to %struct.anon.2*, !dbg !2001
  %DIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %46, i32 0, i32 0, !dbg !2002
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2003
  %48 = getelementptr inbounds %struct.GPR, %struct.GPR* %47, i32 0, i32 13, !dbg !2004
  %49 = getelementptr inbounds %struct.Reg, %struct.Reg* %48, i32 0, i32 0, !dbg !2005
  %50 = bitcast %union.anon* %49 to %struct.anon.2*, !dbg !2005
  %SPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %50, i32 0, i32 0, !dbg !2006
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2007
  %52 = getelementptr inbounds %struct.GPR, %struct.GPR* %51, i32 0, i32 15, !dbg !2008
  %53 = getelementptr inbounds %struct.Reg, %struct.Reg* %52, i32 0, i32 0, !dbg !2009
  %54 = bitcast %union.anon* %53 to %struct.anon.2*, !dbg !2009
  %BPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %54, i32 0, i32 0, !dbg !2010
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2011
  %56 = getelementptr inbounds %struct.GPR, %struct.GPR* %55, i32 0, i32 17, !dbg !2012
  %57 = getelementptr inbounds %struct.Reg, %struct.Reg* %56, i32 0, i32 0, !dbg !2013
  %58 = bitcast %union.anon* %57 to %struct.anon.2*, !dbg !2013
  %R8B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %58, i32 0, i32 0, !dbg !2014
  %59 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2015
  %60 = getelementptr inbounds %struct.GPR, %struct.GPR* %59, i32 0, i32 19, !dbg !2016
  %61 = getelementptr inbounds %struct.Reg, %struct.Reg* %60, i32 0, i32 0, !dbg !2017
  %62 = bitcast %union.anon* %61 to %struct.anon.2*, !dbg !2017
  %R9B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %62, i32 0, i32 0, !dbg !2018
  %63 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2019
  %64 = getelementptr inbounds %struct.GPR, %struct.GPR* %63, i32 0, i32 21, !dbg !2020
  %65 = getelementptr inbounds %struct.Reg, %struct.Reg* %64, i32 0, i32 0, !dbg !2021
  %66 = bitcast %union.anon* %65 to %struct.anon.2*, !dbg !2021
  %R10B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %66, i32 0, i32 0, !dbg !2022
  %67 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2023
  %68 = getelementptr inbounds %struct.GPR, %struct.GPR* %67, i32 0, i32 23, !dbg !2024
  %69 = getelementptr inbounds %struct.Reg, %struct.Reg* %68, i32 0, i32 0, !dbg !2025
  %70 = bitcast %union.anon* %69 to %struct.anon.2*, !dbg !2025
  %R11B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %70, i32 0, i32 0, !dbg !2026
  %71 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2027
  %72 = getelementptr inbounds %struct.GPR, %struct.GPR* %71, i32 0, i32 25, !dbg !2028
  %73 = getelementptr inbounds %struct.Reg, %struct.Reg* %72, i32 0, i32 0, !dbg !2029
  %74 = bitcast %union.anon* %73 to %struct.anon.2*, !dbg !2029
  %R12B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %74, i32 0, i32 0, !dbg !2030
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2031
  %76 = getelementptr inbounds %struct.GPR, %struct.GPR* %75, i32 0, i32 27, !dbg !2032
  %77 = getelementptr inbounds %struct.Reg, %struct.Reg* %76, i32 0, i32 0, !dbg !2033
  %78 = bitcast %union.anon* %77 to %struct.anon.2*, !dbg !2033
  %R13B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %78, i32 0, i32 0, !dbg !2034
  %79 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2035
  %80 = getelementptr inbounds %struct.GPR, %struct.GPR* %79, i32 0, i32 29, !dbg !2036
  %81 = getelementptr inbounds %struct.Reg, %struct.Reg* %80, i32 0, i32 0, !dbg !2037
  %82 = bitcast %union.anon* %81 to %struct.anon.2*, !dbg !2037
  %R14B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %82, i32 0, i32 0, !dbg !2038
  %83 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2039
  %84 = getelementptr inbounds %struct.GPR, %struct.GPR* %83, i32 0, i32 31, !dbg !2040
  %85 = getelementptr inbounds %struct.Reg, %struct.Reg* %84, i32 0, i32 0, !dbg !2041
  %86 = bitcast %union.anon* %85 to %struct.anon.2*, !dbg !2041
  %R15B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %86, i32 0, i32 0, !dbg !2042
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2043
  %88 = getelementptr inbounds %struct.GPR, %struct.GPR* %87, i32 0, i32 1, !dbg !2044
  %89 = getelementptr inbounds %struct.Reg, %struct.Reg* %88, i32 0, i32 0, !dbg !2045
  %AX = bitcast %union.anon* %89 to i16*, !dbg !2045
  %90 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2046
  %91 = getelementptr inbounds %struct.GPR, %struct.GPR* %90, i32 0, i32 3, !dbg !2047
  %92 = getelementptr inbounds %struct.Reg, %struct.Reg* %91, i32 0, i32 0, !dbg !2048
  %BX = bitcast %union.anon* %92 to i16*, !dbg !2048
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2049
  %94 = getelementptr inbounds %struct.GPR, %struct.GPR* %93, i32 0, i32 5, !dbg !2050
  %95 = getelementptr inbounds %struct.Reg, %struct.Reg* %94, i32 0, i32 0, !dbg !2051
  %CX = bitcast %union.anon* %95 to i16*, !dbg !2051
  %96 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2052
  %97 = getelementptr inbounds %struct.GPR, %struct.GPR* %96, i32 0, i32 7, !dbg !2053
  %98 = getelementptr inbounds %struct.Reg, %struct.Reg* %97, i32 0, i32 0, !dbg !2054
  %DX = bitcast %union.anon* %98 to i16*, !dbg !2054
  %99 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2055
  %100 = getelementptr inbounds %struct.GPR, %struct.GPR* %99, i32 0, i32 9, !dbg !2056
  %101 = getelementptr inbounds %struct.Reg, %struct.Reg* %100, i32 0, i32 0, !dbg !2057
  %SI = bitcast %union.anon* %101 to i16*, !dbg !2057
  %102 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2058
  %103 = getelementptr inbounds %struct.GPR, %struct.GPR* %102, i32 0, i32 11, !dbg !2059
  %104 = getelementptr inbounds %struct.Reg, %struct.Reg* %103, i32 0, i32 0, !dbg !2060
  %DI = bitcast %union.anon* %104 to i16*, !dbg !2060
  %105 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2061
  %106 = getelementptr inbounds %struct.GPR, %struct.GPR* %105, i32 0, i32 13, !dbg !2062
  %107 = getelementptr inbounds %struct.Reg, %struct.Reg* %106, i32 0, i32 0, !dbg !2063
  %SP = bitcast %union.anon* %107 to i16*, !dbg !2063
  %108 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2064
  %109 = getelementptr inbounds %struct.GPR, %struct.GPR* %108, i32 0, i32 15, !dbg !2065
  %110 = getelementptr inbounds %struct.Reg, %struct.Reg* %109, i32 0, i32 0, !dbg !2066
  %BP = bitcast %union.anon* %110 to i16*, !dbg !2066
  %111 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2067
  %112 = getelementptr inbounds %struct.GPR, %struct.GPR* %111, i32 0, i32 17, !dbg !2068
  %113 = getelementptr inbounds %struct.Reg, %struct.Reg* %112, i32 0, i32 0, !dbg !2069
  %R8W = bitcast %union.anon* %113 to i16*, !dbg !2069
  %114 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2070
  %115 = getelementptr inbounds %struct.GPR, %struct.GPR* %114, i32 0, i32 19, !dbg !2071
  %116 = getelementptr inbounds %struct.Reg, %struct.Reg* %115, i32 0, i32 0, !dbg !2072
  %R9W = bitcast %union.anon* %116 to i16*, !dbg !2072
  %117 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2073
  %118 = getelementptr inbounds %struct.GPR, %struct.GPR* %117, i32 0, i32 21, !dbg !2074
  %119 = getelementptr inbounds %struct.Reg, %struct.Reg* %118, i32 0, i32 0, !dbg !2075
  %R10W = bitcast %union.anon* %119 to i16*, !dbg !2075
  %120 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2076
  %121 = getelementptr inbounds %struct.GPR, %struct.GPR* %120, i32 0, i32 23, !dbg !2077
  %122 = getelementptr inbounds %struct.Reg, %struct.Reg* %121, i32 0, i32 0, !dbg !2078
  %R11W = bitcast %union.anon* %122 to i16*, !dbg !2078
  %123 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2079
  %124 = getelementptr inbounds %struct.GPR, %struct.GPR* %123, i32 0, i32 25, !dbg !2080
  %125 = getelementptr inbounds %struct.Reg, %struct.Reg* %124, i32 0, i32 0, !dbg !2081
  %R12W = bitcast %union.anon* %125 to i16*, !dbg !2081
  %126 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2082
  %127 = getelementptr inbounds %struct.GPR, %struct.GPR* %126, i32 0, i32 27, !dbg !2083
  %128 = getelementptr inbounds %struct.Reg, %struct.Reg* %127, i32 0, i32 0, !dbg !2084
  %R13W = bitcast %union.anon* %128 to i16*, !dbg !2084
  %129 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2085
  %130 = getelementptr inbounds %struct.GPR, %struct.GPR* %129, i32 0, i32 29, !dbg !2086
  %131 = getelementptr inbounds %struct.Reg, %struct.Reg* %130, i32 0, i32 0, !dbg !2087
  %R14W = bitcast %union.anon* %131 to i16*, !dbg !2087
  %132 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2088
  %133 = getelementptr inbounds %struct.GPR, %struct.GPR* %132, i32 0, i32 31, !dbg !2089
  %134 = getelementptr inbounds %struct.Reg, %struct.Reg* %133, i32 0, i32 0, !dbg !2090
  %R15W = bitcast %union.anon* %134 to i16*, !dbg !2090
  %135 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2091
  %136 = getelementptr inbounds %struct.GPR, %struct.GPR* %135, i32 0, i32 33, !dbg !2092
  %137 = getelementptr inbounds %struct.Reg, %struct.Reg* %136, i32 0, i32 0, !dbg !2093
  %IP = bitcast %union.anon* %137 to i16*, !dbg !2093
  %138 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2094
  %139 = getelementptr inbounds %struct.GPR, %struct.GPR* %138, i32 0, i32 1, !dbg !2095
  %140 = getelementptr inbounds %struct.Reg, %struct.Reg* %139, i32 0, i32 0, !dbg !2096
  %EAX = bitcast %union.anon* %140 to i32*, !dbg !2096
  %141 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2097
  %142 = getelementptr inbounds %struct.GPR, %struct.GPR* %141, i32 0, i32 3, !dbg !2098
  %143 = getelementptr inbounds %struct.Reg, %struct.Reg* %142, i32 0, i32 0, !dbg !2099
  %EBX = bitcast %union.anon* %143 to i32*, !dbg !2099
  %144 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2100
  %145 = getelementptr inbounds %struct.GPR, %struct.GPR* %144, i32 0, i32 5, !dbg !2101
  %146 = getelementptr inbounds %struct.Reg, %struct.Reg* %145, i32 0, i32 0, !dbg !2102
  %ECX = bitcast %union.anon* %146 to i32*, !dbg !2102
  %147 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2103
  %148 = getelementptr inbounds %struct.GPR, %struct.GPR* %147, i32 0, i32 7, !dbg !2104
  %149 = getelementptr inbounds %struct.Reg, %struct.Reg* %148, i32 0, i32 0, !dbg !2105
  %EDX = bitcast %union.anon* %149 to i32*, !dbg !2105
  %150 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2106
  %151 = getelementptr inbounds %struct.GPR, %struct.GPR* %150, i32 0, i32 9, !dbg !2107
  %152 = getelementptr inbounds %struct.Reg, %struct.Reg* %151, i32 0, i32 0, !dbg !2108
  %ESI = bitcast %union.anon* %152 to i32*, !dbg !2108
  %153 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2109
  %154 = getelementptr inbounds %struct.GPR, %struct.GPR* %153, i32 0, i32 11, !dbg !2110
  %155 = getelementptr inbounds %struct.Reg, %struct.Reg* %154, i32 0, i32 0, !dbg !2111
  %EDI = bitcast %union.anon* %155 to i32*, !dbg !2111
  %156 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2112
  %157 = getelementptr inbounds %struct.GPR, %struct.GPR* %156, i32 0, i32 13, !dbg !2113
  %158 = getelementptr inbounds %struct.Reg, %struct.Reg* %157, i32 0, i32 0, !dbg !2114
  %ESP = bitcast %union.anon* %158 to i32*, !dbg !2114
  %159 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2115
  %160 = getelementptr inbounds %struct.GPR, %struct.GPR* %159, i32 0, i32 15, !dbg !2116
  %161 = getelementptr inbounds %struct.Reg, %struct.Reg* %160, i32 0, i32 0, !dbg !2117
  %EBP = bitcast %union.anon* %161 to i32*, !dbg !2117
  %162 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2118
  %163 = getelementptr inbounds %struct.GPR, %struct.GPR* %162, i32 0, i32 33, !dbg !2119
  %164 = getelementptr inbounds %struct.Reg, %struct.Reg* %163, i32 0, i32 0, !dbg !2120
  %EIP = bitcast %union.anon* %164 to i32*, !dbg !2120
  %165 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2121
  %166 = getelementptr inbounds %struct.GPR, %struct.GPR* %165, i32 0, i32 17, !dbg !2122
  %167 = getelementptr inbounds %struct.Reg, %struct.Reg* %166, i32 0, i32 0, !dbg !2123
  %R8D = bitcast %union.anon* %167 to i32*, !dbg !2123
  %168 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2124
  %169 = getelementptr inbounds %struct.GPR, %struct.GPR* %168, i32 0, i32 19, !dbg !2125
  %170 = getelementptr inbounds %struct.Reg, %struct.Reg* %169, i32 0, i32 0, !dbg !2126
  %R9D = bitcast %union.anon* %170 to i32*, !dbg !2126
  %171 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2127
  %172 = getelementptr inbounds %struct.GPR, %struct.GPR* %171, i32 0, i32 21, !dbg !2128
  %173 = getelementptr inbounds %struct.Reg, %struct.Reg* %172, i32 0, i32 0, !dbg !2129
  %R10D = bitcast %union.anon* %173 to i32*, !dbg !2129
  %174 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2130
  %175 = getelementptr inbounds %struct.GPR, %struct.GPR* %174, i32 0, i32 23, !dbg !2131
  %176 = getelementptr inbounds %struct.Reg, %struct.Reg* %175, i32 0, i32 0, !dbg !2132
  %R11D = bitcast %union.anon* %176 to i32*, !dbg !2132
  %177 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2133
  %178 = getelementptr inbounds %struct.GPR, %struct.GPR* %177, i32 0, i32 25, !dbg !2134
  %179 = getelementptr inbounds %struct.Reg, %struct.Reg* %178, i32 0, i32 0, !dbg !2135
  %R12D = bitcast %union.anon* %179 to i32*, !dbg !2135
  %180 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2136
  %181 = getelementptr inbounds %struct.GPR, %struct.GPR* %180, i32 0, i32 27, !dbg !2137
  %182 = getelementptr inbounds %struct.Reg, %struct.Reg* %181, i32 0, i32 0, !dbg !2138
  %R13D = bitcast %union.anon* %182 to i32*, !dbg !2138
  %183 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2139
  %184 = getelementptr inbounds %struct.GPR, %struct.GPR* %183, i32 0, i32 29, !dbg !2140
  %185 = getelementptr inbounds %struct.Reg, %struct.Reg* %184, i32 0, i32 0, !dbg !2141
  %R14D = bitcast %union.anon* %185 to i32*, !dbg !2141
  %186 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2142
  %187 = getelementptr inbounds %struct.GPR, %struct.GPR* %186, i32 0, i32 31, !dbg !2143
  %188 = getelementptr inbounds %struct.Reg, %struct.Reg* %187, i32 0, i32 0, !dbg !2144
  %R15D = bitcast %union.anon* %188 to i32*, !dbg !2144
  %189 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2145
  %190 = getelementptr inbounds %struct.GPR, %struct.GPR* %189, i32 0, i32 1, !dbg !2146
  %191 = getelementptr inbounds %struct.Reg, %struct.Reg* %190, i32 0, i32 0, !dbg !2147
  %RAX = bitcast %union.anon* %191 to i64*, !dbg !2147
  %192 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2148
  %193 = getelementptr inbounds %struct.GPR, %struct.GPR* %192, i32 0, i32 3, !dbg !2149
  %194 = getelementptr inbounds %struct.Reg, %struct.Reg* %193, i32 0, i32 0, !dbg !2150
  %RBX = bitcast %union.anon* %194 to i64*, !dbg !2150
  %195 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2151
  %196 = getelementptr inbounds %struct.GPR, %struct.GPR* %195, i32 0, i32 5, !dbg !2152
  %197 = getelementptr inbounds %struct.Reg, %struct.Reg* %196, i32 0, i32 0, !dbg !2153
  %RCX = bitcast %union.anon* %197 to i64*, !dbg !2153
  %198 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2154
  %199 = getelementptr inbounds %struct.GPR, %struct.GPR* %198, i32 0, i32 7, !dbg !2155
  %200 = getelementptr inbounds %struct.Reg, %struct.Reg* %199, i32 0, i32 0, !dbg !2156
  %RDX = bitcast %union.anon* %200 to i64*, !dbg !2156
  %201 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2157
  %202 = getelementptr inbounds %struct.GPR, %struct.GPR* %201, i32 0, i32 9, !dbg !2158
  %203 = getelementptr inbounds %struct.Reg, %struct.Reg* %202, i32 0, i32 0, !dbg !2159
  %RSI = bitcast %union.anon* %203 to i64*, !dbg !2159
  %204 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2160
  %205 = getelementptr inbounds %struct.GPR, %struct.GPR* %204, i32 0, i32 11, !dbg !2161
  %206 = getelementptr inbounds %struct.Reg, %struct.Reg* %205, i32 0, i32 0, !dbg !2162
  %RDI = bitcast %union.anon* %206 to i64*, !dbg !2162
  %207 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2163
  %208 = getelementptr inbounds %struct.GPR, %struct.GPR* %207, i32 0, i32 13, !dbg !2164
  %209 = getelementptr inbounds %struct.Reg, %struct.Reg* %208, i32 0, i32 0, !dbg !2165
  %RSP = bitcast %union.anon* %209 to i64*, !dbg !2165
  %210 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2166
  %211 = getelementptr inbounds %struct.GPR, %struct.GPR* %210, i32 0, i32 15, !dbg !2167
  %212 = getelementptr inbounds %struct.Reg, %struct.Reg* %211, i32 0, i32 0, !dbg !2168
  %RBP = bitcast %union.anon* %212 to i64*, !dbg !2168
  %213 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2169
  %214 = getelementptr inbounds %struct.GPR, %struct.GPR* %213, i32 0, i32 17, !dbg !2170
  %215 = getelementptr inbounds %struct.Reg, %struct.Reg* %214, i32 0, i32 0, !dbg !2171
  %R8 = bitcast %union.anon* %215 to i64*, !dbg !2171
  %216 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2172
  %217 = getelementptr inbounds %struct.GPR, %struct.GPR* %216, i32 0, i32 19, !dbg !2173
  %218 = getelementptr inbounds %struct.Reg, %struct.Reg* %217, i32 0, i32 0, !dbg !2174
  %R9 = bitcast %union.anon* %218 to i64*, !dbg !2174
  %219 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2175
  %220 = getelementptr inbounds %struct.GPR, %struct.GPR* %219, i32 0, i32 21, !dbg !2176
  %221 = getelementptr inbounds %struct.Reg, %struct.Reg* %220, i32 0, i32 0, !dbg !2177
  %R10 = bitcast %union.anon* %221 to i64*, !dbg !2177
  %222 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2178
  %223 = getelementptr inbounds %struct.GPR, %struct.GPR* %222, i32 0, i32 23, !dbg !2179
  %224 = getelementptr inbounds %struct.Reg, %struct.Reg* %223, i32 0, i32 0, !dbg !2180
  %R11 = bitcast %union.anon* %224 to i64*, !dbg !2180
  %225 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2181
  %226 = getelementptr inbounds %struct.GPR, %struct.GPR* %225, i32 0, i32 25, !dbg !2182
  %227 = getelementptr inbounds %struct.Reg, %struct.Reg* %226, i32 0, i32 0, !dbg !2183
  %R12 = bitcast %union.anon* %227 to i64*, !dbg !2183
  %228 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2184
  %229 = getelementptr inbounds %struct.GPR, %struct.GPR* %228, i32 0, i32 27, !dbg !2185
  %230 = getelementptr inbounds %struct.Reg, %struct.Reg* %229, i32 0, i32 0, !dbg !2186
  %R13 = bitcast %union.anon* %230 to i64*, !dbg !2186
  %231 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2187
  %232 = getelementptr inbounds %struct.GPR, %struct.GPR* %231, i32 0, i32 29, !dbg !2188
  %233 = getelementptr inbounds %struct.Reg, %struct.Reg* %232, i32 0, i32 0, !dbg !2189
  %R14 = bitcast %union.anon* %233 to i64*, !dbg !2189
  %234 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2190
  %235 = getelementptr inbounds %struct.GPR, %struct.GPR* %234, i32 0, i32 31, !dbg !2191
  %236 = getelementptr inbounds %struct.Reg, %struct.Reg* %235, i32 0, i32 0, !dbg !2192
  %R15 = bitcast %union.anon* %236 to i64*, !dbg !2192
  %237 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2193
  %238 = getelementptr inbounds %struct.GPR, %struct.GPR* %237, i32 0, i32 33, !dbg !2194
  %239 = getelementptr inbounds %struct.Reg, %struct.Reg* %238, i32 0, i32 0, !dbg !2195
  %RIP = bitcast %union.anon* %239 to i64*, !dbg !2195
  %240 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2196
  %241 = getelementptr inbounds %struct.Segments, %struct.Segments* %240, i32 0, i32 1, !dbg !2197
  %SS = bitcast %union.SegmentSelector* %241 to i16*, !dbg !2198
  %242 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2199
  %243 = getelementptr inbounds %struct.Segments, %struct.Segments* %242, i32 0, i32 3, !dbg !2200
  %ES = bitcast %union.SegmentSelector* %243 to i16*, !dbg !2201
  %244 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2202
  %245 = getelementptr inbounds %struct.Segments, %struct.Segments* %244, i32 0, i32 5, !dbg !2203
  %GS = bitcast %union.SegmentSelector* %245 to i16*, !dbg !2204
  %246 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2205
  %247 = getelementptr inbounds %struct.Segments, %struct.Segments* %246, i32 0, i32 7, !dbg !2206
  %FS = bitcast %union.SegmentSelector* %247 to i16*, !dbg !2207
  %248 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2208
  %249 = getelementptr inbounds %struct.Segments, %struct.Segments* %248, i32 0, i32 9, !dbg !2209
  %DS = bitcast %union.SegmentSelector* %249 to i16*, !dbg !2210
  %250 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2211
  %251 = getelementptr inbounds %struct.Segments, %struct.Segments* %250, i32 0, i32 11, !dbg !2212
  %CS = bitcast %union.SegmentSelector* %251 to i16*, !dbg !2213
  %252 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2214
  %253 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %252, i32 0, i32 5, !dbg !2215
  %254 = getelementptr inbounds %struct.Reg, %struct.Reg* %253, i32 0, i32 0, !dbg !2216
  %GS_BASE = bitcast %union.anon* %254 to i64*, !dbg !2216
  %255 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2217
  %256 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %255, i32 0, i32 7, !dbg !2218
  %257 = getelementptr inbounds %struct.Reg, %struct.Reg* %256, i32 0, i32 0, !dbg !2219
  %FS_BASE = bitcast %union.anon* %257 to i64*, !dbg !2219
  %258 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2220
  %259 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %258, i64 0, i64 0, !dbg !2221
  %YMM0 = bitcast %union.VectorReg* %259 to %"class.std::bitset"*, !dbg !2222
  %260 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2223
  %261 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %260, i64 0, i64 1, !dbg !2224
  %YMM1 = bitcast %union.VectorReg* %261 to %"class.std::bitset"*, !dbg !2225
  %262 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2226
  %263 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %262, i64 0, i64 2, !dbg !2227
  %YMM2 = bitcast %union.VectorReg* %263 to %"class.std::bitset"*, !dbg !2228
  %264 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2229
  %265 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %264, i64 0, i64 3, !dbg !2230
  %YMM3 = bitcast %union.VectorReg* %265 to %"class.std::bitset"*, !dbg !2231
  %266 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2232
  %267 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %266, i64 0, i64 4, !dbg !2233
  %YMM4 = bitcast %union.VectorReg* %267 to %"class.std::bitset"*, !dbg !2234
  %268 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2235
  %269 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %268, i64 0, i64 5, !dbg !2236
  %YMM5 = bitcast %union.VectorReg* %269 to %"class.std::bitset"*, !dbg !2237
  %270 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2238
  %271 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %270, i64 0, i64 6, !dbg !2239
  %YMM6 = bitcast %union.VectorReg* %271 to %"class.std::bitset"*, !dbg !2240
  %272 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2241
  %273 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %272, i64 0, i64 7, !dbg !2242
  %YMM7 = bitcast %union.VectorReg* %273 to %"class.std::bitset"*, !dbg !2243
  %274 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2244
  %275 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %274, i64 0, i64 8, !dbg !2245
  %YMM8 = bitcast %union.VectorReg* %275 to %"class.std::bitset"*, !dbg !2246
  %276 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2247
  %277 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %276, i64 0, i64 9, !dbg !2248
  %YMM9 = bitcast %union.VectorReg* %277 to %"class.std::bitset"*, !dbg !2249
  %278 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2250
  %279 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %278, i64 0, i64 10, !dbg !2251
  %YMM10 = bitcast %union.VectorReg* %279 to %"class.std::bitset"*, !dbg !2252
  %280 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2253
  %281 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %280, i64 0, i64 11, !dbg !2254
  %YMM11 = bitcast %union.VectorReg* %281 to %"class.std::bitset"*, !dbg !2255
  %282 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2256
  %283 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %282, i64 0, i64 12, !dbg !2257
  %YMM12 = bitcast %union.VectorReg* %283 to %"class.std::bitset"*, !dbg !2258
  %284 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2259
  %285 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %284, i64 0, i64 13, !dbg !2260
  %YMM13 = bitcast %union.VectorReg* %285 to %"class.std::bitset"*, !dbg !2261
  %286 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2262
  %287 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %286, i64 0, i64 14, !dbg !2263
  %YMM14 = bitcast %union.VectorReg* %287 to %"class.std::bitset"*, !dbg !2264
  %288 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2265
  %289 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %288, i64 0, i64 15, !dbg !2266
  %YMM15 = bitcast %union.VectorReg* %289 to %"class.std::bitset"*, !dbg !2267
  %290 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2268
  %291 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %290, i64 0, i64 0, !dbg !2269
  %XMM0 = bitcast %union.VectorReg* %291 to %union.vec128_t*, !dbg !2270
  %292 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2271
  %293 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %292, i64 0, i64 1, !dbg !2272
  %XMM1 = bitcast %union.VectorReg* %293 to %union.vec128_t*, !dbg !2273
  %294 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2274
  %295 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %294, i64 0, i64 2, !dbg !2275
  %XMM2 = bitcast %union.VectorReg* %295 to %union.vec128_t*, !dbg !2276
  %296 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2277
  %297 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %296, i64 0, i64 3, !dbg !2278
  %XMM3 = bitcast %union.VectorReg* %297 to %union.vec128_t*, !dbg !2279
  %298 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2280
  %299 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %298, i64 0, i64 4, !dbg !2281
  %XMM4 = bitcast %union.VectorReg* %299 to %union.vec128_t*, !dbg !2282
  %300 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2283
  %301 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %300, i64 0, i64 5, !dbg !2284
  %XMM5 = bitcast %union.VectorReg* %301 to %union.vec128_t*, !dbg !2285
  %302 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2286
  %303 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %302, i64 0, i64 6, !dbg !2287
  %XMM6 = bitcast %union.VectorReg* %303 to %union.vec128_t*, !dbg !2288
  %304 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2289
  %305 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %304, i64 0, i64 7, !dbg !2290
  %XMM7 = bitcast %union.VectorReg* %305 to %union.vec128_t*, !dbg !2291
  %306 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2292
  %307 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %306, i64 0, i64 8, !dbg !2293
  %XMM8 = bitcast %union.VectorReg* %307 to %union.vec128_t*, !dbg !2294
  %308 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2295
  %309 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %308, i64 0, i64 9, !dbg !2296
  %XMM9 = bitcast %union.VectorReg* %309 to %union.vec128_t*, !dbg !2297
  %310 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2298
  %311 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %310, i64 0, i64 10, !dbg !2299
  %XMM10 = bitcast %union.VectorReg* %311 to %union.vec128_t*, !dbg !2300
  %312 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2301
  %313 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %312, i64 0, i64 11, !dbg !2302
  %XMM11 = bitcast %union.VectorReg* %313 to %union.vec128_t*, !dbg !2303
  %314 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2304
  %315 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %314, i64 0, i64 12, !dbg !2305
  %XMM12 = bitcast %union.VectorReg* %315 to %union.vec128_t*, !dbg !2306
  %316 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2307
  %317 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %316, i64 0, i64 13, !dbg !2308
  %XMM13 = bitcast %union.VectorReg* %317 to %union.vec128_t*, !dbg !2309
  %318 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2310
  %319 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %318, i64 0, i64 14, !dbg !2311
  %XMM14 = bitcast %union.VectorReg* %319 to %union.vec128_t*, !dbg !2312
  %320 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2313
  %321 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %320, i64 0, i64 15, !dbg !2314
  %XMM15 = bitcast %union.VectorReg* %321 to %union.vec128_t*, !dbg !2315
  %322 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2316
  %323 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %322, i32 0, i32 0, !dbg !2317
  %324 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %323, i64 0, i64 0, !dbg !2318
  %ST0 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %324, i32 0, i32 1, !dbg !2319
  %325 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2320
  %326 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %325, i32 0, i32 0, !dbg !2321
  %327 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %326, i64 0, i64 1, !dbg !2322
  %ST1 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %327, i32 0, i32 1, !dbg !2323
  %328 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2324
  %329 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %328, i32 0, i32 0, !dbg !2325
  %330 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %329, i64 0, i64 2, !dbg !2326
  %ST2 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %330, i32 0, i32 1, !dbg !2327
  %331 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2328
  %332 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %331, i32 0, i32 0, !dbg !2329
  %333 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %332, i64 0, i64 3, !dbg !2330
  %ST3 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %333, i32 0, i32 1, !dbg !2331
  %334 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2332
  %335 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %334, i32 0, i32 0, !dbg !2333
  %336 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %335, i64 0, i64 4, !dbg !2334
  %ST4 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %336, i32 0, i32 1, !dbg !2335
  %337 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2336
  %338 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %337, i32 0, i32 0, !dbg !2337
  %339 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %338, i64 0, i64 5, !dbg !2338
  %ST5 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %339, i32 0, i32 1, !dbg !2339
  %340 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2340
  %341 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %340, i32 0, i32 0, !dbg !2341
  %342 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %341, i64 0, i64 6, !dbg !2342
  %ST6 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %342, i32 0, i32 1, !dbg !2343
  %343 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2344
  %344 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %343, i32 0, i32 0, !dbg !2345
  %345 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %344, i64 0, i64 7, !dbg !2346
  %ST7 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %345, i32 0, i32 1, !dbg !2347
  %346 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2348
  %347 = getelementptr inbounds %struct.MMX, %struct.MMX* %346, i32 0, i32 0, !dbg !2349
  %348 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %347, i64 0, i64 0, !dbg !2350
  %349 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %348, i32 0, i32 1, !dbg !2351
  %350 = bitcast %union.vec64_t* %349 to %struct.uint64v1_t*, !dbg !2352
  %351 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %350, i32 0, i32 0, !dbg !2353
  %MM0 = getelementptr inbounds [1 x i64], [1 x i64]* %351, i64 0, i64 0, !dbg !2350
  %352 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2354
  %353 = getelementptr inbounds %struct.MMX, %struct.MMX* %352, i32 0, i32 0, !dbg !2355
  %354 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %353, i64 0, i64 1, !dbg !2356
  %355 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %354, i32 0, i32 1, !dbg !2357
  %356 = bitcast %union.vec64_t* %355 to %struct.uint64v1_t*, !dbg !2358
  %357 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %356, i32 0, i32 0, !dbg !2359
  %MM1 = getelementptr inbounds [1 x i64], [1 x i64]* %357, i64 0, i64 0, !dbg !2356
  %358 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2360
  %359 = getelementptr inbounds %struct.MMX, %struct.MMX* %358, i32 0, i32 0, !dbg !2361
  %360 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %359, i64 0, i64 2, !dbg !2362
  %361 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %360, i32 0, i32 1, !dbg !2363
  %362 = bitcast %union.vec64_t* %361 to %struct.uint64v1_t*, !dbg !2364
  %363 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %362, i32 0, i32 0, !dbg !2365
  %MM2 = getelementptr inbounds [1 x i64], [1 x i64]* %363, i64 0, i64 0, !dbg !2362
  %364 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2366
  %365 = getelementptr inbounds %struct.MMX, %struct.MMX* %364, i32 0, i32 0, !dbg !2367
  %366 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %365, i64 0, i64 3, !dbg !2368
  %367 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %366, i32 0, i32 1, !dbg !2369
  %368 = bitcast %union.vec64_t* %367 to %struct.uint64v1_t*, !dbg !2370
  %369 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %368, i32 0, i32 0, !dbg !2371
  %MM3 = getelementptr inbounds [1 x i64], [1 x i64]* %369, i64 0, i64 0, !dbg !2368
  %370 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2372
  %371 = getelementptr inbounds %struct.MMX, %struct.MMX* %370, i32 0, i32 0, !dbg !2373
  %372 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %371, i64 0, i64 4, !dbg !2374
  %373 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %372, i32 0, i32 1, !dbg !2375
  %374 = bitcast %union.vec64_t* %373 to %struct.uint64v1_t*, !dbg !2376
  %375 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %374, i32 0, i32 0, !dbg !2377
  %MM4 = getelementptr inbounds [1 x i64], [1 x i64]* %375, i64 0, i64 0, !dbg !2374
  %376 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2378
  %377 = getelementptr inbounds %struct.MMX, %struct.MMX* %376, i32 0, i32 0, !dbg !2379
  %378 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %377, i64 0, i64 5, !dbg !2380
  %379 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %378, i32 0, i32 1, !dbg !2381
  %380 = bitcast %union.vec64_t* %379 to %struct.uint64v1_t*, !dbg !2382
  %381 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %380, i32 0, i32 0, !dbg !2383
  %MM5 = getelementptr inbounds [1 x i64], [1 x i64]* %381, i64 0, i64 0, !dbg !2380
  %382 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2384
  %383 = getelementptr inbounds %struct.MMX, %struct.MMX* %382, i32 0, i32 0, !dbg !2385
  %384 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %383, i64 0, i64 6, !dbg !2386
  %385 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %384, i32 0, i32 1, !dbg !2387
  %386 = bitcast %union.vec64_t* %385 to %struct.uint64v1_t*, !dbg !2388
  %387 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %386, i32 0, i32 0, !dbg !2389
  %MM6 = getelementptr inbounds [1 x i64], [1 x i64]* %387, i64 0, i64 0, !dbg !2386
  %388 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2390
  %389 = getelementptr inbounds %struct.MMX, %struct.MMX* %388, i32 0, i32 0, !dbg !2391
  %390 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %389, i64 0, i64 7, !dbg !2392
  %391 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %390, i32 0, i32 1, !dbg !2393
  %392 = bitcast %union.vec64_t* %391 to %struct.uint64v1_t*, !dbg !2394
  %393 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %392, i32 0, i32 0, !dbg !2395
  %MM7 = getelementptr inbounds [1 x i64], [1 x i64]* %393, i64 0, i64 0, !dbg !2392
  %394 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2396
  %AF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %394, i32 0, i32 5, !dbg !2397
  %395 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2398
  %CF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %395, i32 0, i32 1, !dbg !2399
  %396 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2400
  %DF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %396, i32 0, i32 11, !dbg !2401
  %397 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2402
  %OF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %397, i32 0, i32 13, !dbg !2403
  %398 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2404
  %PF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %398, i32 0, i32 3, !dbg !2405
  %399 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2406
  %SF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %399, i32 0, i32 9, !dbg !2407
  %400 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2408
  %ZF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %400, i32 0, i32 7, !dbg !2409
  store i64* @DR0, i64** %_DR0, align 8, !dbg !2410
  store i64* @DR1, i64** %_DR1, align 8, !dbg !2411
  store i64* @DR2, i64** %_DR2, align 8, !dbg !2412
  store i64* @DR3, i64** %_DR3, align 8, !dbg !2413
  store i64* @DR4, i64** %_DR4, align 8, !dbg !2414
  store i64* @DR5, i64** %_DR5, align 8, !dbg !2415
  store i64* @DR6, i64** %_DR6, align 8, !dbg !2416
  store i64* @DR7, i64** %_DR7, align 8, !dbg !2417
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR0, i32 0, i32 0), i64** %CR0, align 8, !dbg !2418
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR1, i32 0, i32 0), i64** %CR1, align 8, !dbg !2419
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR2, i32 0, i32 0), i64** %CR2, align 8, !dbg !2420
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR3, i32 0, i32 0), i64** %CR3, align 8, !dbg !2421
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR4, i32 0, i32 0), i64** %CR4, align 8, !dbg !2422
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR8, i32 0, i32 0), i64** %CR8, align 8, !dbg !2423
  ret %struct.Memory* %2, !dbg !2424
}

; Function Attrs: noduplicate noinline nounwind optnone
define void @__remill_intrinsics() local_unnamed_addr #4 !dbg !2425 {
  ret void, !dbg !2427
}

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @abort() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memset(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @printf(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @free(i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__libc_start_main(i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @gettimeofday(i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__gmon_start__() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memcpy(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memalign(i64, i64) #6

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_404010___libc_csu_init(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_404010:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0
  %R13D = bitcast %union.anon* %4 to i32*
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %5 = load i64, i64* %R15, align 8
  %6 = add i64 %1, 2
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %R14, align 8
  %11 = load i64, i64* %PC, align 8
  %12 = add i64 %11, 2
  store i64 %12, i64* %PC, align 8
  %13 = add i64 %7, -16
  %14 = inttoptr i64 %13 to i64*
  store i64 %10, i64* %14, align 8
  %15 = load i64, i64* %RDX, align 8
  %16 = load i64, i64* %PC, align 8
  store i64 %15, i64* %R15, align 8, !tbaa !2428
  %17 = load i64, i64* %R13, align 8
  %18 = add i64 %16, 5
  store i64 %18, i64* %PC, align 8
  %19 = add i64 %7, -24
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %R12, align 8
  %22 = load i64, i64* %PC, align 8
  %23 = add i64 %22, 2
  store i64 %23, i64* %PC, align 8
  %24 = add i64 %7, -32
  %25 = inttoptr i64 %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = load i64, i64* %PC, align 8
  store i64 ptrtoint (%seg_604df0__init_array_type* @seg_604df0__init_array to i64), i64* %R12, align 8, !tbaa !2428
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %26, 8
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %7, -40
  %30 = inttoptr i64 %29 to i64*
  store i64 %27, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_604df0__init_array_type* @seg_604df0__init_array to i64), i64 8), i64* %RBP, align 8, !tbaa !2428
  %32 = load i64, i64* %RBX, align 8
  %33 = add i64 %31, 8
  store i64 %33, i64* %PC, align 8
  %34 = add i64 %7, -48
  %35 = inttoptr i64 %34 to i64*
  store i64 %32, i64* %35, align 8
  %36 = load i32, i32* %EDI, align 4
  %37 = zext i32 %36 to i64
  %38 = load i64, i64* %PC, align 8
  store i64 %37, i64* %R13, align 8, !tbaa !2428
  %39 = load i64, i64* %RSI, align 8
  store i64 %39, i64* %R14, align 8, !tbaa !2428
  %40 = load i64, i64* %RBP, align 8
  %41 = load i64, i64* %R12, align 8
  %42 = sub i64 %40, %41
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %49 = lshr i64 %42, 2
  %50 = trunc i64 %49 to i8
  %51 = and i8 %50, 1
  %52 = ashr i64 %42, 3
  store i64 %52, i64* %RBP, align 8, !tbaa !2428
  store i8 %51, i8* %43, align 1, !tbaa !2432
  %53 = trunc i64 %52 to i32
  %54 = and i32 %53, 255
  %55 = tail call i32 @llvm.ctpop.i32(i32 %54) #10
  %56 = trunc i32 %55 to i8
  %57 = and i8 %56, 1
  %58 = xor i8 %57, 1
  store i8 %58, i8* %44, align 1, !tbaa !2432
  store i8 0, i8* %45, align 1, !tbaa !2432
  %59 = icmp eq i64 %52, 0
  %60 = zext i1 %59 to i8
  store i8 %60, i8* %46, align 1, !tbaa !2432
  %61 = lshr i64 %52, 63
  %62 = trunc i64 %61 to i8
  store i8 %62, i8* %47, align 1, !tbaa !2432
  store i8 0, i8* %48, align 1, !tbaa !2432
  %63 = add i64 %38, -14771
  %64 = add i64 %38, 22
  %65 = add i64 %7, -64
  %66 = inttoptr i64 %65 to i64*
  store i64 %64, i64* %66, align 8
  store i64 %65, i64* %RSP, align 8, !tbaa !2428
  store i64 %63, i64* %PC, align 8, !tbaa !2428
  %67 = tail call %struct.Memory* @sub_400678__init_proc(%struct.State* nonnull %0, i64 %63, %struct.Memory* %2)
  %68 = load i64, i64* %RBP, align 8
  %69 = load i64, i64* %PC, align 8
  store i8 0, i8* %43, align 1, !tbaa !2433
  %70 = trunc i64 %68 to i32
  %71 = and i32 %70, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #10
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %44, align 1, !tbaa !2447
  %76 = icmp eq i64 %68, 0
  %77 = zext i1 %76 to i8
  store i8 %77, i8* %46, align 1, !tbaa !2448
  %78 = lshr i64 %68, 63
  %79 = trunc i64 %78 to i8
  store i8 %79, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2451
  %.v = select i1 %76, i64 37, i64 5
  %80 = add i64 %69, %.v
  store i64 %80, i64* %PC, align 8, !tbaa !2428
  br i1 %76, label %block_404066, label %block_404046

block_404066.loopexit:                            ; preds = %block_404050
  br label %block_404066

block_404066:                                     ; preds = %block_404066.loopexit, %block_404010
  %81 = phi i64 [ %80, %block_404010 ], [ %179, %block_404066.loopexit ]
  %MEMORY.0 = phi %struct.Memory* [ %67, %block_404010 ], [ %149, %block_404066.loopexit ]
  %82 = load i64, i64* %RSP, align 8
  %83 = add i64 %82, 8
  store i64 %83, i64* %RSP, align 8, !tbaa !2428
  %84 = icmp ugt i64 %82, -9
  %85 = zext i1 %84 to i8
  store i8 %85, i8* %43, align 1, !tbaa !2433
  %86 = trunc i64 %83 to i32
  %87 = and i32 %86, 255
  %88 = tail call i32 @llvm.ctpop.i32(i32 %87) #10
  %89 = trunc i32 %88 to i8
  %90 = and i8 %89, 1
  %91 = xor i8 %90, 1
  store i8 %91, i8* %44, align 1, !tbaa !2447
  %92 = xor i64 %83, %82
  %93 = lshr i64 %92, 4
  %94 = trunc i64 %93 to i8
  %95 = and i8 %94, 1
  store i8 %95, i8* %45, align 1, !tbaa !2451
  %96 = icmp eq i64 %83, 0
  %97 = zext i1 %96 to i8
  store i8 %97, i8* %46, align 1, !tbaa !2448
  %98 = lshr i64 %83, 63
  %99 = trunc i64 %98 to i8
  store i8 %99, i8* %47, align 1, !tbaa !2449
  %100 = lshr i64 %82, 63
  %101 = xor i64 %98, %100
  %102 = add nuw nsw i64 %101, %98
  %103 = icmp eq i64 %102, 2
  %104 = zext i1 %103 to i8
  store i8 %104, i8* %48, align 1, !tbaa !2450
  %105 = add i64 %81, 5
  store i64 %105, i64* %PC, align 8
  %106 = add i64 %82, 16
  %107 = inttoptr i64 %83 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RBX, align 8, !tbaa !2428
  store i64 %106, i64* %RSP, align 8, !tbaa !2428
  %109 = add i64 %81, 6
  store i64 %109, i64* %PC, align 8
  %110 = add i64 %82, 24
  %111 = inttoptr i64 %106 to i64*
  %112 = load i64, i64* %111, align 8
  store i64 %112, i64* %RBP, align 8, !tbaa !2428
  store i64 %110, i64* %RSP, align 8, !tbaa !2428
  %113 = add i64 %81, 8
  store i64 %113, i64* %PC, align 8
  %114 = add i64 %82, 32
  %115 = inttoptr i64 %110 to i64*
  %116 = load i64, i64* %115, align 8
  store i64 %116, i64* %R12, align 8, !tbaa !2428
  store i64 %114, i64* %RSP, align 8, !tbaa !2428
  %117 = add i64 %81, 10
  store i64 %117, i64* %PC, align 8
  %118 = add i64 %82, 40
  %119 = inttoptr i64 %114 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %R13, align 8, !tbaa !2428
  store i64 %118, i64* %RSP, align 8, !tbaa !2428
  %121 = add i64 %81, 12
  store i64 %121, i64* %PC, align 8
  %122 = add i64 %82, 48
  %123 = inttoptr i64 %118 to i64*
  %124 = load i64, i64* %123, align 8
  store i64 %124, i64* %R14, align 8, !tbaa !2428
  store i64 %122, i64* %RSP, align 8, !tbaa !2428
  %125 = add i64 %81, 14
  store i64 %125, i64* %PC, align 8
  %126 = add i64 %82, 56
  %127 = inttoptr i64 %122 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %R15, align 8, !tbaa !2428
  store i64 %126, i64* %RSP, align 8, !tbaa !2428
  %129 = add i64 %81, 15
  store i64 %129, i64* %PC, align 8
  %130 = inttoptr i64 %126 to i64*
  %131 = load i64, i64* %130, align 8
  store i64 %131, i64* %PC, align 8, !tbaa !2428
  %132 = add i64 %82, 64
  store i64 %132, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_404046:                                     ; preds = %block_404010
  store i64 0, i64* %RBX, align 8, !tbaa !2428
  store i8 0, i8* %43, align 1, !tbaa !2433
  store i8 1, i8* %44, align 1, !tbaa !2447
  store i8 1, i8* %46, align 1, !tbaa !2448
  store i8 0, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2451
  %133 = add i64 %80, 10
  store i64 %133, i64* %PC, align 8
  br label %block_404050

block_404050:                                     ; preds = %block_404050, %block_404046
  %134 = phi i64 [ 0, %block_404046 ], [ %152, %block_404050 ]
  %135 = phi i64 [ %133, %block_404046 ], [ %179, %block_404050 ]
  %MEMORY.1 = phi %struct.Memory* [ %67, %block_404046 ], [ %149, %block_404050 ]
  %136 = load i64, i64* %R15, align 8
  store i64 %136, i64* %RDX, align 8, !tbaa !2428
  %137 = load i64, i64* %R14, align 8
  store i64 %137, i64* %RSI, align 8, !tbaa !2428
  %138 = load i32, i32* %R13D, align 4
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RDI, align 8, !tbaa !2428
  %140 = load i64, i64* %R12, align 8
  %141 = shl i64 %134, 3
  %142 = add i64 %141, %140
  %143 = add i64 %135, 13
  store i64 %143, i64* %PC, align 8
  %144 = load i64, i64* %RSP, align 8, !tbaa !2428
  %145 = add i64 %144, -8
  %146 = inttoptr i64 %145 to i64*
  store i64 %143, i64* %146, align 8
  store i64 %145, i64* %RSP, align 8, !tbaa !2428
  %147 = inttoptr i64 %142 to i64*
  %148 = load i64, i64* %147, align 8
  store i64 %148, i64* %PC, align 8, !tbaa !2428
  %149 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %148, %struct.Memory* %MEMORY.1)
  %150 = load i64, i64* %RBX, align 8
  %151 = load i64, i64* %PC, align 8
  %152 = add i64 %150, 1
  store i64 %152, i64* %RBX, align 8, !tbaa !2428
  %153 = lshr i64 %152, 63
  %154 = load i64, i64* %RBP, align 8
  %155 = sub i64 %154, %152
  %156 = icmp ult i64 %154, %152
  %157 = zext i1 %156 to i8
  store i8 %157, i8* %43, align 1, !tbaa !2433
  %158 = trunc i64 %155 to i32
  %159 = and i32 %158, 255
  %160 = tail call i32 @llvm.ctpop.i32(i32 %159) #10
  %161 = trunc i32 %160 to i8
  %162 = and i8 %161, 1
  %163 = xor i8 %162, 1
  store i8 %163, i8* %44, align 1, !tbaa !2447
  %164 = xor i64 %152, %154
  %165 = xor i64 %164, %155
  %166 = lshr i64 %165, 4
  %167 = trunc i64 %166 to i8
  %168 = and i8 %167, 1
  store i8 %168, i8* %45, align 1, !tbaa !2451
  %169 = icmp eq i64 %155, 0
  %170 = zext i1 %169 to i8
  store i8 %170, i8* %46, align 1, !tbaa !2448
  %171 = lshr i64 %155, 63
  %172 = trunc i64 %171 to i8
  store i8 %172, i8* %47, align 1, !tbaa !2449
  %173 = lshr i64 %154, 63
  %174 = xor i64 %153, %173
  %175 = xor i64 %171, %173
  %176 = add nuw nsw i64 %175, %174
  %177 = icmp eq i64 %176, 2
  %178 = zext i1 %177 to i8
  store i8 %178, i8* %48, align 1, !tbaa !2450
  %.v2 = select i1 %169, i64 9, i64 -13
  %179 = add i64 %151, %.v2
  store i64 %179, i64* %PC, align 8, !tbaa !2428
  br i1 %169, label %block_404066.loopexit, label %block_404050
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400678__init_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400678:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  store i64 %4, i64* %RSP, align 8, !tbaa !2428
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_604ff0__got_type* @seg_604ff0__got to i64), i64 8) to i64*), align 8
  store i64 %11, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %5, align 1, !tbaa !2433
  %12 = trunc i64 %11 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13) #10
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %6, align 1, !tbaa !2447
  %18 = icmp eq i64 %11, 0
  %19 = zext i1 %18 to i8
  store i8 %19, i8* %8, align 1, !tbaa !2448
  %20 = lshr i64 %11, 63
  %21 = trunc i64 %20 to i8
  store i8 %21, i8* %9, align 1, !tbaa !2449
  store i8 0, i8* %10, align 1, !tbaa !2450
  store i8 0, i8* %7, align 1, !tbaa !2451
  %.v = select i1 %18, i64 18, i64 16
  %22 = add i64 %.v, %1
  store i64 %22, i64* %PC, align 8, !tbaa !2428
  br i1 %18, label %block_40068a, label %block_400688

block_400688:                                     ; preds = %block_400678
  %23 = add i64 %22, 2
  %24 = add i64 %3, -16
  %25 = inttoptr i64 %24 to i64*
  store i64 %23, i64* %25, align 8
  store i64 %24, i64* %RSP, align 8, !tbaa !2428
  store i64 %11, i64* %PC, align 8, !tbaa !2428
  %26 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %11, %struct.Memory* %2)
  %.pre = load i64, i64* %RSP, align 8
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_40068a

block_40068a:                                     ; preds = %block_400688, %block_400678
  %27 = phi i64 [ %22, %block_400678 ], [ %.pre1, %block_400688 ]
  %28 = phi i64 [ %4, %block_400678 ], [ %.pre, %block_400688 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400678 ], [ %26, %block_400688 ]
  %29 = add i64 %28, 8
  store i64 %29, i64* %RSP, align 8, !tbaa !2428
  %30 = icmp ugt i64 %28, -9
  %31 = zext i1 %30 to i8
  store i8 %31, i8* %5, align 1, !tbaa !2433
  %32 = trunc i64 %29 to i32
  %33 = and i32 %32, 255
  %34 = tail call i32 @llvm.ctpop.i32(i32 %33) #10
  %35 = trunc i32 %34 to i8
  %36 = and i8 %35, 1
  %37 = xor i8 %36, 1
  store i8 %37, i8* %6, align 1, !tbaa !2447
  %38 = xor i64 %29, %28
  %39 = lshr i64 %38, 4
  %40 = trunc i64 %39 to i8
  %41 = and i8 %40, 1
  store i8 %41, i8* %7, align 1, !tbaa !2451
  %42 = icmp eq i64 %29, 0
  %43 = zext i1 %42 to i8
  store i8 %43, i8* %8, align 1, !tbaa !2448
  %44 = lshr i64 %29, 63
  %45 = trunc i64 %44 to i8
  store i8 %45, i8* %9, align 1, !tbaa !2449
  %46 = lshr i64 %28, 63
  %47 = xor i64 %44, %46
  %48 = add nuw nsw i64 %47, %44
  %49 = icmp eq i64 %48, 2
  %50 = zext i1 %49 to i8
  store i8 %50, i8* %10, align 1, !tbaa !2450
  %51 = add i64 %27, 5
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %29 to i64*
  %53 = load i64, i64* %52, align 8
  store i64 %53, i64* %PC, align 8, !tbaa !2428
  %54 = add i64 %28, 16
  store i64 %54, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400fd0_putdata(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400fd0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = load i64, i64* %RBP, align 8
  %10 = add i64 %1, 1
  store i64 %10, i64* %PC, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %12 = load i64, i64* %11, align 8, !tbaa !2428
  %13 = add i64 %12, -8
  %14 = inttoptr i64 %13 to i64*
  store i64 %9, i64* %14, align 8
  store i64 %13, i64* %11, align 8, !tbaa !2428
  %15 = load i64, i64* %PC, align 8
  store i64 %13, i64* %RBP, align 8, !tbaa !2428
  %16 = add i64 %12, -12
  %17 = load i32, i32* %EDI, align 4
  %18 = add i64 %15, 6
  store i64 %18, i64* %PC, align 8
  %19 = inttoptr i64 %16 to i32*
  store i32 %17, i32* %19, align 4
  %20 = load i64, i64* %RBP, align 8
  %21 = add i64 %20, -8
  %22 = load i32, i32* %ESI, align 4
  %23 = load i64, i64* %PC, align 8
  %24 = add i64 %23, 3
  store i64 %24, i64* %PC, align 8
  %25 = inttoptr i64 %21 to i32*
  store i32 %22, i32* %25, align 4
  %26 = load i64, i64* %RBP, align 8
  %27 = add i64 %26, -16
  %28 = load i64, i64* %RDX, align 8
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %27 to i64*
  store i64 %28, i64* %31, align 8
  %32 = load i64, i64* %RBP, align 8
  %33 = add i64 %32, -24
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 7
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %33 to i32*
  store i32 0, i32* %36, align 4
  %37 = load i64, i64* %RBP, align 8
  %38 = add i64 %37, -4
  %39 = load i64, i64* %PC, align 8
  %40 = add i64 %39, 3
  store i64 %40, i64* %PC, align 8
  %41 = inttoptr i64 %38 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = zext i32 %42 to i64
  store i64 %43, i64* %RSI, align 8, !tbaa !2428
  %44 = add i64 %37, -20
  %45 = add i64 %39, 6
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %44 to i32*
  store i32 %42, i32* %46, align 4
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %53 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %55 = bitcast i64* %54 to double*
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %57 = bitcast %union.VectorReg* %8 to double*
  %58 = bitcast [32 x %union.VectorReg]* %7 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_400feb

block_400feb:                                     ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit, %block_400fd0
  %59 = phi i64 [ %.pre, %block_400fd0 ], [ %212, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400fd0 ], [ %158, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %60 = load i64, i64* %RBP, align 8
  %61 = add i64 %60, -20
  %62 = add i64 %59, 3
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %61 to i32*
  %64 = load i32, i32* %63, align 4
  %65 = zext i32 %64 to i64
  store i64 %65, i64* %RAX, align 8, !tbaa !2428
  %66 = add i64 %60, -8
  %67 = add i64 %59, 6
  store i64 %67, i64* %PC, align 8
  %68 = inttoptr i64 %66 to i32*
  %69 = load i32, i32* %68, align 4
  %70 = sub i32 %64, %69
  %71 = icmp ult i32 %64, %69
  %72 = zext i1 %71 to i8
  store i8 %72, i8* %47, align 1, !tbaa !2433
  %73 = and i32 %70, 255
  %74 = tail call i32 @llvm.ctpop.i32(i32 %73) #10
  %75 = trunc i32 %74 to i8
  %76 = and i8 %75, 1
  %77 = xor i8 %76, 1
  store i8 %77, i8* %48, align 1, !tbaa !2447
  %78 = xor i32 %69, %64
  %79 = xor i32 %78, %70
  %80 = lshr i32 %79, 4
  %81 = trunc i32 %80 to i8
  %82 = and i8 %81, 1
  store i8 %82, i8* %49, align 1, !tbaa !2451
  %83 = icmp eq i32 %70, 0
  %84 = zext i1 %83 to i8
  store i8 %84, i8* %50, align 1, !tbaa !2448
  %85 = lshr i32 %70, 31
  %86 = trunc i32 %85 to i8
  store i8 %86, i8* %51, align 1, !tbaa !2449
  %87 = lshr i32 %64, 31
  %88 = lshr i32 %69, 31
  %89 = xor i32 %88, %87
  %90 = xor i32 %85, %87
  %91 = add nuw nsw i32 %90, %89
  %92 = icmp eq i32 %91, 2
  %93 = zext i1 %92 to i8
  store i8 %93, i8* %52, align 1, !tbaa !2450
  %94 = icmp ne i8 %86, 0
  %95 = xor i1 %94, %92
  %.demorgan = or i1 %83, %95
  %.v = select i1 %.demorgan, i64 12, i64 87
  %96 = add i64 %59, %.v
  store i64 %96, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_400ff7, label %block_401042

block_400ff7:                                     ; preds = %block_400feb
  %97 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 72) to i64*), align 8
  store i64 %97, i64* %53, align 1, !tbaa !2452
  store double 0.000000e+00, double* %55, align 1, !tbaa !2452
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %98 = add i64 %60, -24
  %99 = add i64 %96, 20
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %98 to i32*
  %101 = load i32, i32* %100, align 4
  %102 = mul i32 %101, 7141
  %103 = add i32 %102, 54773
  %104 = zext i32 %103 to i64
  store i64 %104, i64* %RCX, align 8, !tbaa !2428
  %105 = icmp ugt i32 %102, -54774
  %106 = zext i1 %105 to i8
  store i8 %106, i8* %47, align 1, !tbaa !2433
  %107 = and i32 %103, 255
  %108 = tail call i32 @llvm.ctpop.i32(i32 %107) #10
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  %111 = xor i8 %110, 1
  store i8 %111, i8* %48, align 1, !tbaa !2447
  %112 = xor i32 %102, 16
  %113 = xor i32 %112, %103
  %114 = lshr i32 %113, 4
  %115 = trunc i32 %114 to i8
  %116 = and i8 %115, 1
  store i8 %116, i8* %49, align 1, !tbaa !2451
  %117 = icmp eq i32 %103, 0
  %118 = zext i1 %117 to i8
  store i8 %118, i8* %50, align 1, !tbaa !2448
  %119 = lshr i32 %103, 31
  %120 = trunc i32 %119 to i8
  store i8 %120, i8* %51, align 1, !tbaa !2449
  %121 = lshr i32 %102, 31
  %122 = xor i32 %119, %121
  %123 = add nuw nsw i32 %122, %119
  %124 = icmp eq i32 %123, 2
  %125 = zext i1 %124 to i8
  store i8 %125, i8* %52, align 1, !tbaa !2450
  %126 = add i64 %60, -28
  %127 = add i64 %96, 29
  store i64 %127, i64* %PC, align 8
  %128 = inttoptr i64 %126 to i32*
  store i32 259200, i32* %128, align 4
  %129 = load i32, i32* %ECX, align 4
  %130 = zext i32 %129 to i64
  %131 = load i64, i64* %PC, align 8
  store i64 %130, i64* %RAX, align 8, !tbaa !2428
  %132 = sext i32 %129 to i64
  %133 = lshr i64 %132, 32
  store i64 %133, i64* %56, align 8, !tbaa !2428
  %134 = load i64, i64* %RBP, align 8
  %135 = add i64 %134, -28
  %136 = add i64 %131, 6
  store i64 %136, i64* %PC, align 8
  %137 = inttoptr i64 %135 to i32*
  %138 = load i32, i32* %137, align 4
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RCX, align 8, !tbaa !2428
  %140 = add i64 %131, 8
  store i64 %140, i64* %PC, align 8
  %141 = sext i32 %138 to i64
  %142 = shl nuw i64 %133, 32
  %143 = or i64 %142, %130
  %144 = sdiv i64 %143, %141
  %145 = shl i64 %144, 32
  %146 = ashr exact i64 %145, 32
  %147 = icmp eq i64 %144, %146
  br i1 %147, label %150, label %148

; <label>:148:                                    ; preds = %block_400ff7
  %149 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %140, %struct.Memory* %MEMORY.0) #15
  %.pre1 = load i64, i64* %RBP, align 8
  %.pre2 = load i32, i32* %EDX, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:150:                                    ; preds = %block_400ff7
  %151 = srem i64 %143, %141
  %152 = and i64 %144, 4294967295
  store i64 %152, i64* %RAX, align 8, !tbaa !2428
  %153 = and i64 %151, 4294967295
  store i64 %153, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %47, align 1, !tbaa !2433
  store i8 0, i8* %48, align 1, !tbaa !2447
  store i8 0, i8* %49, align 1, !tbaa !2451
  store i8 0, i8* %50, align 1, !tbaa !2448
  store i8 0, i8* %51, align 1, !tbaa !2449
  store i8 0, i8* %52, align 1, !tbaa !2450
  %154 = trunc i64 %151 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %150, %148
  %155 = phi i64 [ %.pre3, %148 ], [ %140, %150 ]
  %156 = phi i32 [ %.pre2, %148 ], [ %154, %150 ]
  %157 = phi i64 [ %.pre1, %148 ], [ %134, %150 ]
  %158 = phi %struct.Memory* [ %149, %148 ], [ %MEMORY.0, %150 ]
  %159 = add i64 %157, -24
  %160 = add i64 %155, 3
  store i64 %160, i64* %PC, align 8
  %161 = inttoptr i64 %159 to i32*
  store i32 %156, i32* %161, align 4
  %162 = load i32, i32* %EDX, align 4
  %163 = load i64, i64* %PC, align 8
  %164 = sitofp i32 %162 to double
  %165 = load double, double* %58, align 1
  %166 = fmul double %164, %165
  store double %166, double* %57, align 1, !tbaa !2452
  %167 = load i64, i64* %RBP, align 8
  %168 = add i64 %167, -16
  %169 = add i64 %163, 12
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %168 to i64*
  %171 = load i64, i64* %170, align 8
  store i64 %171, i64* %RSI, align 8, !tbaa !2428
  %172 = add i64 %167, -20
  %173 = add i64 %163, 16
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i32*
  %175 = load i32, i32* %174, align 4
  %176 = sext i32 %175 to i64
  store i64 %176, i64* %RDI, align 8, !tbaa !2428
  %177 = shl nsw i64 %176, 3
  %178 = add i64 %177, %171
  %179 = add i64 %163, 21
  store i64 %179, i64* %PC, align 8
  %180 = inttoptr i64 %178 to double*
  store double %166, double* %180, align 8
  %181 = load i64, i64* %RBP, align 8
  %182 = add i64 %181, -20
  %183 = load i64, i64* %PC, align 8
  %184 = add i64 %183, 3
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %182 to i32*
  %186 = load i32, i32* %185, align 4
  %187 = add i32 %186, 1
  %188 = zext i32 %187 to i64
  store i64 %188, i64* %RAX, align 8, !tbaa !2428
  %189 = icmp eq i32 %186, -1
  %190 = icmp eq i32 %187, 0
  %191 = or i1 %189, %190
  %192 = zext i1 %191 to i8
  store i8 %192, i8* %47, align 1, !tbaa !2433
  %193 = and i32 %187, 255
  %194 = tail call i32 @llvm.ctpop.i32(i32 %193) #10
  %195 = trunc i32 %194 to i8
  %196 = and i8 %195, 1
  %197 = xor i8 %196, 1
  store i8 %197, i8* %48, align 1, !tbaa !2447
  %198 = xor i32 %187, %186
  %199 = lshr i32 %198, 4
  %200 = trunc i32 %199 to i8
  %201 = and i8 %200, 1
  store i8 %201, i8* %49, align 1, !tbaa !2451
  %202 = zext i1 %190 to i8
  store i8 %202, i8* %50, align 1, !tbaa !2448
  %203 = lshr i32 %187, 31
  %204 = trunc i32 %203 to i8
  store i8 %204, i8* %51, align 1, !tbaa !2449
  %205 = lshr i32 %186, 31
  %206 = xor i32 %203, %205
  %207 = add nuw nsw i32 %206, %203
  %208 = icmp eq i32 %207, 2
  %209 = zext i1 %208 to i8
  store i8 %209, i8* %52, align 1, !tbaa !2450
  %210 = add i64 %183, 9
  store i64 %210, i64* %PC, align 8
  store i32 %187, i32* %185, align 4
  %211 = load i64, i64* %PC, align 8
  %212 = add i64 %211, -82
  store i64 %212, i64* %PC, align 8, !tbaa !2428
  br label %block_400feb

block_401042:                                     ; preds = %block_400feb
  %213 = add i64 %96, 1
  store i64 %213, i64* %PC, align 8
  %214 = load i64, i64* %11, align 8, !tbaa !2428
  %215 = add i64 %214, 8
  %216 = inttoptr i64 %214 to i64*
  %217 = load i64, i64* %216, align 8
  store i64 %217, i64* %RBP, align 8, !tbaa !2428
  store i64 %215, i64* %11, align 8, !tbaa !2428
  %218 = add i64 %96, 2
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %215 to i64*
  %220 = load i64, i64* %219, align 8
  store i64 %220, i64* %PC, align 8, !tbaa !2428
  %221 = add i64 %214, 16
  store i64 %221, i64* %11, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400800___do_global_dtors_aux(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400800:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i8, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %4, align 1, !tbaa !2433
  %5 = zext i8 %3 to i32
  %6 = tail call i32 @llvm.ctpop.i32(i32 %5) #10
  %7 = trunc i32 %6 to i8
  %8 = and i8 %7, 1
  %9 = xor i8 %8, 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %9, i8* %10, align 1, !tbaa !2447
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %11, align 1, !tbaa !2451
  %12 = icmp eq i8 %3, 0
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %13, i8* %14, align 1, !tbaa !2448
  %15 = lshr i8 %3, 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %15, i8* %16, align 1, !tbaa !2449
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1, !tbaa !2450
  %.v = select i1 %12, i64 9, i64 32
  %18 = add i64 %.v, %1
  store i64 %18, i64* %PC, align 8, !tbaa !2428
  br i1 %12, label %block_400809, label %block_400820

block_400820:                                     ; preds = %block_400800
  %19 = add i64 %18, 2
  store i64 %19, i64* %PC, align 8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %21 = load i64, i64* %20, align 8, !tbaa !2428
  %22 = inttoptr i64 %21 to i64*
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %PC, align 8, !tbaa !2428
  %24 = add i64 %21, 8
  store i64 %24, i64* %20, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_400809:                                     ; preds = %block_400800
  %25 = load i64, i64* %RBP, align 8
  %26 = add i64 %18, 1
  store i64 %26, i64* %PC, align 8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %28 = load i64, i64* %27, align 8, !tbaa !2428
  %29 = add i64 %28, -8
  %30 = inttoptr i64 %29 to i64*
  store i64 %25, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 %29, i64* %RBP, align 8, !tbaa !2428
  %32 = add i64 %31, -122
  %33 = add i64 %31, 8
  %34 = add i64 %28, -16
  %35 = inttoptr i64 %34 to i64*
  store i64 %33, i64* %35, align 8
  store i64 %34, i64* %27, align 8, !tbaa !2428
  store i64 %32, i64* %PC, align 8, !tbaa !2428
  %36 = tail call %struct.Memory* @sub_400790_deregister_tm_clones(%struct.State* nonnull %0, i64 %32, %struct.Memory* %2)
  %37 = load i64, i64* %PC, align 8
  store i8 1, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %38 = add i64 %37, 8
  store i64 %38, i64* %PC, align 8
  %39 = load i64, i64* %27, align 8, !tbaa !2428
  %40 = add i64 %39, 8
  %41 = inttoptr i64 %39 to i64*
  %42 = load i64, i64* %41, align 8
  store i64 %42, i64* %RBP, align 8, !tbaa !2428
  store i64 %40, i64* %27, align 8, !tbaa !2428
  %43 = add i64 %37, 9
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %40 to i64*
  %45 = load i64, i64* %44, align 8
  store i64 %45, i64* %PC, align 8, !tbaa !2428
  %46 = add i64 %39, 16
  store i64 %46, i64* %27, align 8, !tbaa !2428
  ret %struct.Memory* %36
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_403320_cftmdl(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_403320:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = add i64 %9, -56
  store i64 %13, i64* %RSP, align 8, !tbaa !2428
  %14 = icmp ult i64 %10, 48
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1, !tbaa !2433
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #10
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1, !tbaa !2447
  %24 = xor i64 %10, 16
  %25 = xor i64 %24, %13
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1, !tbaa !2451
  %30 = icmp eq i64 %13, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1, !tbaa !2448
  %33 = lshr i64 %13, 63
  %34 = trunc i64 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1, !tbaa !2449
  %36 = lshr i64 %10, 63
  %37 = xor i64 %33, %36
  %38 = add nuw nsw i64 %37, %36
  %39 = icmp eq i64 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1, !tbaa !2450
  %42 = add i64 %9, -12
  %43 = load i32, i32* %EDI, align 4
  %44 = add i64 %12, 10
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %42 to i32*
  store i32 %43, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -8
  %48 = load i32, i32* %ESI, align 4
  %49 = load i64, i64* %PC, align 8
  %50 = add i64 %49, 3
  store i64 %50, i64* %PC, align 8
  %51 = inttoptr i64 %47 to i32*
  store i32 %48, i32* %51, align 4
  %52 = load i64, i64* %RBP, align 8
  %53 = add i64 %52, -16
  %54 = load i64, i64* %RDX, align 8
  %55 = load i64, i64* %PC, align 8
  %56 = add i64 %55, 4
  store i64 %56, i64* %PC, align 8
  %57 = inttoptr i64 %53 to i64*
  store i64 %54, i64* %57, align 8
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -24
  %60 = load i64, i64* %RCX, align 8
  %61 = load i64, i64* %PC, align 8
  %62 = add i64 %61, 4
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %59 to i64*
  store i64 %60, i64* %63, align 8
  %64 = load i64, i64* %RBP, align 8
  %65 = add i64 %64, -8
  %66 = load i64, i64* %PC, align 8
  %67 = add i64 %66, 3
  store i64 %67, i64* %PC, align 8
  %68 = inttoptr i64 %65 to i32*
  %69 = load i32, i32* %68, align 4
  %70 = shl i32 %69, 2
  %71 = zext i32 %70 to i64
  store i64 %71, i64* %RSI, align 8, !tbaa !2428
  %72 = lshr i32 %69, 30
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  store i8 %74, i8* %16, align 1, !tbaa !2432
  %75 = and i32 %70, 252
  %76 = tail call i32 @llvm.ctpop.i32(i32 %75) #10
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  %79 = xor i8 %78, 1
  store i8 %79, i8* %23, align 1, !tbaa !2432
  store i8 0, i8* %29, align 1, !tbaa !2432
  %80 = icmp eq i32 %70, 0
  %81 = zext i1 %80 to i8
  store i8 %81, i8* %32, align 1, !tbaa !2432
  %82 = lshr i32 %69, 29
  %83 = trunc i32 %82 to i8
  %84 = and i8 %83, 1
  store i8 %84, i8* %35, align 1, !tbaa !2432
  store i8 0, i8* %41, align 1, !tbaa !2432
  %85 = add i64 %64, -56
  %86 = add i64 %66, 9
  store i64 %86, i64* %PC, align 8
  %87 = inttoptr i64 %85 to i32*
  store i32 %70, i32* %87, align 4
  %88 = load i64, i64* %RBP, align 8
  %89 = add i64 %88, -28
  %90 = load i64, i64* %PC, align 8
  %91 = add i64 %90, 7
  store i64 %91, i64* %PC, align 8
  %92 = inttoptr i64 %89 to i32*
  store i32 0, i32* %92, align 4
  %93 = bitcast [32 x %union.VectorReg]* %5 to double*
  %94 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %95 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %96 = bitcast i64* %95 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_403346

block_40359d:                                     ; preds = %block_403346
  %97 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %98 = add i64 %4819, -24
  %99 = add i64 %4855, 4
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %98 to i64*
  %101 = load i64, i64* %100, align 8
  store i64 %101, i64* %RAX, align 8, !tbaa !2428
  %102 = add i64 %101, 16
  %103 = add i64 %4855, 9
  store i64 %103, i64* %PC, align 8
  %104 = inttoptr i64 %102 to i64*
  %105 = load i64, i64* %104, align 8
  store i64 %105, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %106 = add i64 %4819, -72
  %107 = add i64 %4855, 14
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %106 to i64*
  store i64 %105, i64* %108, align 8
  %109 = load i64, i64* %RBP, align 8
  %110 = add i64 %109, -56
  %111 = load i64, i64* %PC, align 8
  %112 = add i64 %111, 3
  store i64 %112, i64* %PC, align 8
  %113 = inttoptr i64 %110 to i32*
  %114 = load i32, i32* %113, align 4
  %115 = zext i32 %114 to i64
  store i64 %115, i64* %RCX, align 8, !tbaa !2428
  %116 = add i64 %109, -28
  %117 = add i64 %111, 6
  store i64 %117, i64* %PC, align 8
  %118 = inttoptr i64 %116 to i32*
  store i32 %114, i32* %118, align 4
  %119 = bitcast %union.VectorReg* %6 to double*
  %120 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  %121 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %122 = bitcast i64* %121 to double*
  %.pre23 = load i64, i64* %PC, align 8
  br label %block_4035b1

block_40388f:                                     ; preds = %block_403883
  %123 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 80) to i64*), align 16
  store i64 %123, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %124 = add i64 %2662, -48
  %125 = add i64 %2698, 11
  store i64 %125, i64* %PC, align 8
  %126 = inttoptr i64 %124 to i32*
  %127 = load i32, i32* %126, align 4
  %128 = add i32 %127, 2
  %129 = zext i32 %128 to i64
  store i64 %129, i64* %RAX, align 8, !tbaa !2428
  %130 = icmp ugt i32 %127, -3
  %131 = zext i1 %130 to i8
  store i8 %131, i8* %16, align 1, !tbaa !2433
  %132 = and i32 %128, 255
  %133 = tail call i32 @llvm.ctpop.i32(i32 %132) #10
  %134 = trunc i32 %133 to i8
  %135 = and i8 %134, 1
  %136 = xor i8 %135, 1
  store i8 %136, i8* %23, align 1, !tbaa !2447
  %137 = xor i32 %128, %127
  %138 = lshr i32 %137, 4
  %139 = trunc i32 %138 to i8
  %140 = and i8 %139, 1
  store i8 %140, i8* %29, align 1, !tbaa !2451
  %141 = icmp eq i32 %128, 0
  %142 = zext i1 %141 to i8
  store i8 %142, i8* %32, align 1, !tbaa !2448
  %143 = lshr i32 %128, 31
  %144 = trunc i32 %143 to i8
  store i8 %144, i8* %35, align 1, !tbaa !2449
  %145 = lshr i32 %127, 31
  %146 = xor i32 %143, %145
  %147 = add nuw nsw i32 %146, %143
  %148 = icmp eq i32 %147, 2
  %149 = zext i1 %148 to i8
  store i8 %149, i8* %41, align 1, !tbaa !2450
  %150 = add i64 %2698, 17
  store i64 %150, i64* %PC, align 8
  store i32 %128, i32* %126, align 4
  %151 = load i64, i64* %RBP, align 8
  %152 = add i64 %151, -48
  %153 = load i64, i64* %PC, align 8
  %154 = add i64 %153, 3
  store i64 %154, i64* %PC, align 8
  %155 = inttoptr i64 %152 to i32*
  %156 = load i32, i32* %155, align 4
  %157 = shl i32 %156, 1
  %158 = icmp slt i32 %156, 0
  %159 = icmp slt i32 %157, 0
  %160 = xor i1 %158, %159
  %161 = zext i32 %157 to i64
  store i64 %161, i64* %RAX, align 8, !tbaa !2428
  %.lobit5 = lshr i32 %156, 31
  %162 = trunc i32 %.lobit5 to i8
  store i8 %162, i8* %16, align 1, !tbaa !2432
  %163 = and i32 %157, 254
  %164 = tail call i32 @llvm.ctpop.i32(i32 %163) #10
  %165 = trunc i32 %164 to i8
  %166 = and i8 %165, 1
  %167 = xor i8 %166, 1
  store i8 %167, i8* %23, align 1, !tbaa !2432
  store i8 0, i8* %29, align 1, !tbaa !2432
  %168 = icmp eq i32 %157, 0
  %169 = zext i1 %168 to i8
  store i8 %169, i8* %32, align 1, !tbaa !2432
  %170 = lshr i32 %156, 30
  %171 = trunc i32 %170 to i8
  %172 = and i8 %171, 1
  store i8 %172, i8* %35, align 1, !tbaa !2432
  %173 = zext i1 %160 to i8
  store i8 %173, i8* %41, align 1, !tbaa !2432
  %174 = add i64 %151, -52
  %175 = add i64 %153, 9
  store i64 %175, i64* %PC, align 8
  %176 = inttoptr i64 %174 to i32*
  store i32 %157, i32* %176, align 4
  %177 = load i64, i64* %RBP, align 8
  %178 = add i64 %177, -24
  %179 = load i64, i64* %PC, align 8
  %180 = add i64 %179, 4
  store i64 %180, i64* %PC, align 8
  %181 = inttoptr i64 %178 to i64*
  %182 = load i64, i64* %181, align 8
  store i64 %182, i64* %RCX, align 8, !tbaa !2428
  %183 = add i64 %177, -48
  %184 = add i64 %179, 8
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %183 to i32*
  %186 = load i32, i32* %185, align 4
  %187 = sext i32 %186 to i64
  store i64 %187, i64* %RDX, align 8, !tbaa !2428
  %188 = shl nsw i64 %187, 3
  %189 = add i64 %188, %182
  %190 = add i64 %179, 13
  store i64 %190, i64* %PC, align 8
  %191 = inttoptr i64 %189 to i64*
  %192 = load i64, i64* %191, align 8
  store i64 %192, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %193 = add i64 %177, -88
  %194 = add i64 %179, 18
  store i64 %194, i64* %PC, align 8
  %195 = inttoptr i64 %193 to i64*
  store i64 %192, i64* %195, align 8
  %196 = load i64, i64* %RBP, align 8
  %197 = add i64 %196, -24
  %198 = load i64, i64* %PC, align 8
  %199 = add i64 %198, 4
  store i64 %199, i64* %PC, align 8
  %200 = inttoptr i64 %197 to i64*
  %201 = load i64, i64* %200, align 8
  store i64 %201, i64* %RCX, align 8, !tbaa !2428
  %202 = add i64 %196, -48
  %203 = add i64 %198, 7
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %202 to i32*
  %205 = load i32, i32* %204, align 4
  %206 = add i32 %205, 1
  %207 = zext i32 %206 to i64
  store i64 %207, i64* %RAX, align 8, !tbaa !2428
  %208 = icmp eq i32 %205, -1
  %209 = icmp eq i32 %206, 0
  %210 = or i1 %208, %209
  %211 = zext i1 %210 to i8
  store i8 %211, i8* %16, align 1, !tbaa !2433
  %212 = and i32 %206, 255
  %213 = tail call i32 @llvm.ctpop.i32(i32 %212) #10
  %214 = trunc i32 %213 to i8
  %215 = and i8 %214, 1
  %216 = xor i8 %215, 1
  store i8 %216, i8* %23, align 1, !tbaa !2447
  %217 = xor i32 %206, %205
  %218 = lshr i32 %217, 4
  %219 = trunc i32 %218 to i8
  %220 = and i8 %219, 1
  store i8 %220, i8* %29, align 1, !tbaa !2451
  %221 = zext i1 %209 to i8
  store i8 %221, i8* %32, align 1, !tbaa !2448
  %222 = lshr i32 %206, 31
  %223 = trunc i32 %222 to i8
  store i8 %223, i8* %35, align 1, !tbaa !2449
  %224 = lshr i32 %205, 31
  %225 = xor i32 %222, %224
  %226 = add nuw nsw i32 %225, %222
  %227 = icmp eq i32 %226, 2
  %228 = zext i1 %227 to i8
  store i8 %228, i8* %41, align 1, !tbaa !2450
  %229 = sext i32 %206 to i64
  store i64 %229, i64* %RDX, align 8, !tbaa !2428
  %230 = shl nsw i64 %229, 3
  %231 = add i64 %201, %230
  %232 = add i64 %198, 18
  store i64 %232, i64* %PC, align 8
  %233 = inttoptr i64 %231 to i64*
  %234 = load i64, i64* %233, align 8
  store i64 %234, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %235 = add i64 %196, -96
  %236 = add i64 %198, 23
  store i64 %236, i64* %PC, align 8
  %237 = inttoptr i64 %235 to i64*
  store i64 %234, i64* %237, align 8
  %238 = load i64, i64* %RBP, align 8
  %239 = add i64 %238, -24
  %240 = load i64, i64* %PC, align 8
  %241 = add i64 %240, 4
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %239 to i64*
  %243 = load i64, i64* %242, align 8
  store i64 %243, i64* %RCX, align 8, !tbaa !2428
  %244 = add i64 %238, -52
  %245 = add i64 %240, 8
  store i64 %245, i64* %PC, align 8
  %246 = inttoptr i64 %244 to i32*
  %247 = load i32, i32* %246, align 4
  %248 = sext i32 %247 to i64
  store i64 %248, i64* %RDX, align 8, !tbaa !2428
  %249 = shl nsw i64 %248, 3
  %250 = add i64 %249, %243
  %251 = add i64 %240, 13
  store i64 %251, i64* %PC, align 8
  %252 = inttoptr i64 %250 to i64*
  %253 = load i64, i64* %252, align 8
  store i64 %253, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %254 = add i64 %238, -72
  %255 = add i64 %240, 18
  store i64 %255, i64* %PC, align 8
  %256 = inttoptr i64 %254 to i64*
  store i64 %253, i64* %256, align 8
  %257 = load i64, i64* %RBP, align 8
  %258 = add i64 %257, -24
  %259 = load i64, i64* %PC, align 8
  %260 = add i64 %259, 4
  store i64 %260, i64* %PC, align 8
  %261 = inttoptr i64 %258 to i64*
  %262 = load i64, i64* %261, align 8
  store i64 %262, i64* %RCX, align 8, !tbaa !2428
  %263 = add i64 %257, -52
  %264 = add i64 %259, 7
  store i64 %264, i64* %PC, align 8
  %265 = inttoptr i64 %263 to i32*
  %266 = load i32, i32* %265, align 4
  %267 = add i32 %266, 1
  %268 = zext i32 %267 to i64
  store i64 %268, i64* %RAX, align 8, !tbaa !2428
  %269 = icmp eq i32 %266, -1
  %270 = icmp eq i32 %267, 0
  %271 = or i1 %269, %270
  %272 = zext i1 %271 to i8
  store i8 %272, i8* %16, align 1, !tbaa !2433
  %273 = and i32 %267, 255
  %274 = tail call i32 @llvm.ctpop.i32(i32 %273) #10
  %275 = trunc i32 %274 to i8
  %276 = and i8 %275, 1
  %277 = xor i8 %276, 1
  store i8 %277, i8* %23, align 1, !tbaa !2447
  %278 = xor i32 %267, %266
  %279 = lshr i32 %278, 4
  %280 = trunc i32 %279 to i8
  %281 = and i8 %280, 1
  store i8 %281, i8* %29, align 1, !tbaa !2451
  %282 = zext i1 %270 to i8
  store i8 %282, i8* %32, align 1, !tbaa !2448
  %283 = lshr i32 %267, 31
  %284 = trunc i32 %283 to i8
  store i8 %284, i8* %35, align 1, !tbaa !2449
  %285 = lshr i32 %266, 31
  %286 = xor i32 %283, %285
  %287 = add nuw nsw i32 %286, %283
  %288 = icmp eq i32 %287, 2
  %289 = zext i1 %288 to i8
  store i8 %289, i8* %41, align 1, !tbaa !2450
  %290 = sext i32 %267 to i64
  store i64 %290, i64* %RDX, align 8, !tbaa !2428
  %291 = shl nsw i64 %290, 3
  %292 = add i64 %262, %291
  %293 = add i64 %259, 18
  store i64 %293, i64* %PC, align 8
  %294 = inttoptr i64 %292 to i64*
  %295 = load i64, i64* %294, align 8
  store i64 %295, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %296 = add i64 %257, -80
  %297 = add i64 %259, 23
  store i64 %297, i64* %PC, align 8
  %298 = inttoptr i64 %296 to i64*
  store i64 %295, i64* %298, align 8
  %299 = load i64, i64* %RBP, align 8
  %300 = add i64 %299, -72
  %301 = load i64, i64* %PC, align 8
  %302 = add i64 %301, 5
  store i64 %302, i64* %PC, align 8
  %303 = inttoptr i64 %300 to i64*
  %304 = load i64, i64* %303, align 8
  store i64 %304, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %305 = load <2 x i32>, <2 x i32>* %1290, align 1
  %306 = load <2 x i32>, <2 x i32>* %1291, align 1
  %307 = extractelement <2 x i32> %305, i32 0
  store i32 %307, i32* %1292, align 1, !tbaa !2454
  %308 = extractelement <2 x i32> %305, i32 1
  store i32 %308, i32* %1294, align 1, !tbaa !2454
  %309 = extractelement <2 x i32> %306, i32 0
  store i32 %309, i32* %1296, align 1, !tbaa !2454
  %310 = extractelement <2 x i32> %306, i32 1
  store i32 %310, i32* %1298, align 1, !tbaa !2454
  %311 = add i64 %299, -96
  %312 = add i64 %301, 13
  store i64 %312, i64* %PC, align 8
  %313 = load double, double* %1299, align 1
  %314 = inttoptr i64 %311 to double*
  %315 = load double, double* %314, align 8
  %316 = fmul double %313, %315
  store double %316, double* %1299, align 1, !tbaa !2452
  %317 = add i64 %299, -80
  %318 = add i64 %301, 18
  store i64 %318, i64* %PC, align 8
  %319 = inttoptr i64 %317 to double*
  %320 = load double, double* %319, align 8
  %321 = fmul double %316, %320
  store double %321, double* %1299, align 1, !tbaa !2452
  %322 = bitcast i64 %304 to double
  %323 = fsub double %322, %321
  store double %323, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %324 = add i64 %299, -104
  %325 = add i64 %301, 27
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %324 to double*
  store double %323, double* %326, align 8
  %327 = load i64, i64* %RBP, align 8
  %328 = add i64 %327, -96
  %329 = load i64, i64* %PC, align 8
  %330 = add i64 %329, 5
  store i64 %330, i64* %PC, align 8
  %331 = load double, double* %93, align 1
  %332 = inttoptr i64 %328 to double*
  %333 = load double, double* %332, align 8
  %334 = fmul double %331, %333
  store double %334, double* %93, align 1, !tbaa !2452
  %335 = add i64 %327, -72
  %336 = add i64 %329, 10
  store i64 %336, i64* %PC, align 8
  %337 = inttoptr i64 %335 to double*
  %338 = load double, double* %337, align 8
  %339 = fmul double %334, %338
  store double %339, double* %93, align 1, !tbaa !2452
  %340 = add i64 %327, -80
  %341 = add i64 %329, 15
  store i64 %341, i64* %PC, align 8
  %342 = inttoptr i64 %340 to double*
  %343 = load double, double* %342, align 8
  %344 = fsub double %339, %343
  store double %344, double* %93, align 1, !tbaa !2452
  %345 = add i64 %327, -112
  %346 = add i64 %329, 20
  store i64 %346, i64* %PC, align 8
  %347 = inttoptr i64 %345 to double*
  store double %344, double* %347, align 8
  %348 = load i64, i64* %RBP, align 8
  %349 = add i64 %348, -44
  %350 = load i64, i64* %PC, align 8
  %351 = add i64 %350, 3
  store i64 %351, i64* %PC, align 8
  %352 = inttoptr i64 %349 to i32*
  %353 = load i32, i32* %352, align 4
  %354 = zext i32 %353 to i64
  store i64 %354, i64* %RAX, align 8, !tbaa !2428
  %355 = add i64 %348, -28
  %356 = add i64 %350, 6
  store i64 %356, i64* %PC, align 8
  %357 = inttoptr i64 %355 to i32*
  store i32 %353, i32* %357, align 4
  %.pre25 = load i64, i64* %PC, align 8
  br label %block_403930

block_403352:                                     ; preds = %block_403346
  %358 = add i64 %4855, 3
  store i64 %358, i64* %PC, align 8
  %359 = load i32, i32* %4822, align 4
  %360 = zext i32 %359 to i64
  store i64 %360, i64* %RAX, align 8, !tbaa !2428
  %361 = add i64 %4855, 6
  store i64 %361, i64* %PC, align 8
  %362 = load i32, i32* %4827, align 4
  %363 = add i32 %362, %359
  %364 = zext i32 %363 to i64
  store i64 %364, i64* %RAX, align 8, !tbaa !2428
  %365 = icmp ult i32 %363, %359
  %366 = icmp ult i32 %363, %362
  %367 = or i1 %365, %366
  %368 = zext i1 %367 to i8
  store i8 %368, i8* %16, align 1, !tbaa !2433
  %369 = and i32 %363, 255
  %370 = tail call i32 @llvm.ctpop.i32(i32 %369) #10
  %371 = trunc i32 %370 to i8
  %372 = and i8 %371, 1
  %373 = xor i8 %372, 1
  store i8 %373, i8* %23, align 1, !tbaa !2447
  %374 = xor i32 %362, %359
  %375 = xor i32 %374, %363
  %376 = lshr i32 %375, 4
  %377 = trunc i32 %376 to i8
  %378 = and i8 %377, 1
  store i8 %378, i8* %29, align 1, !tbaa !2451
  %379 = icmp eq i32 %363, 0
  %380 = zext i1 %379 to i8
  store i8 %380, i8* %32, align 1, !tbaa !2448
  %381 = lshr i32 %363, 31
  %382 = trunc i32 %381 to i8
  store i8 %382, i8* %35, align 1, !tbaa !2449
  %383 = lshr i32 %359, 31
  %384 = lshr i32 %362, 31
  %385 = xor i32 %381, %383
  %386 = xor i32 %381, %384
  %387 = add nuw nsw i32 %385, %386
  %388 = icmp eq i32 %387, 2
  %389 = zext i1 %388 to i8
  store i8 %389, i8* %41, align 1, !tbaa !2450
  %390 = add i64 %4819, -32
  %391 = add i64 %4855, 9
  store i64 %391, i64* %PC, align 8
  %392 = inttoptr i64 %390 to i32*
  store i32 %363, i32* %392, align 4
  %393 = load i64, i64* %RBP, align 8
  %394 = add i64 %393, -32
  %395 = load i64, i64* %PC, align 8
  %396 = add i64 %395, 3
  store i64 %396, i64* %PC, align 8
  %397 = inttoptr i64 %394 to i32*
  %398 = load i32, i32* %397, align 4
  %399 = zext i32 %398 to i64
  store i64 %399, i64* %RAX, align 8, !tbaa !2428
  %400 = add i64 %393, -8
  %401 = add i64 %395, 6
  store i64 %401, i64* %PC, align 8
  %402 = inttoptr i64 %400 to i32*
  %403 = load i32, i32* %402, align 4
  %404 = add i32 %403, %398
  %405 = zext i32 %404 to i64
  store i64 %405, i64* %RAX, align 8, !tbaa !2428
  %406 = icmp ult i32 %404, %398
  %407 = icmp ult i32 %404, %403
  %408 = or i1 %406, %407
  %409 = zext i1 %408 to i8
  store i8 %409, i8* %16, align 1, !tbaa !2433
  %410 = and i32 %404, 255
  %411 = tail call i32 @llvm.ctpop.i32(i32 %410) #10
  %412 = trunc i32 %411 to i8
  %413 = and i8 %412, 1
  %414 = xor i8 %413, 1
  store i8 %414, i8* %23, align 1, !tbaa !2447
  %415 = xor i32 %403, %398
  %416 = xor i32 %415, %404
  %417 = lshr i32 %416, 4
  %418 = trunc i32 %417 to i8
  %419 = and i8 %418, 1
  store i8 %419, i8* %29, align 1, !tbaa !2451
  %420 = icmp eq i32 %404, 0
  %421 = zext i1 %420 to i8
  store i8 %421, i8* %32, align 1, !tbaa !2448
  %422 = lshr i32 %404, 31
  %423 = trunc i32 %422 to i8
  store i8 %423, i8* %35, align 1, !tbaa !2449
  %424 = lshr i32 %398, 31
  %425 = lshr i32 %403, 31
  %426 = xor i32 %422, %424
  %427 = xor i32 %422, %425
  %428 = add nuw nsw i32 %426, %427
  %429 = icmp eq i32 %428, 2
  %430 = zext i1 %429 to i8
  store i8 %430, i8* %41, align 1, !tbaa !2450
  %431 = add i64 %393, -36
  %432 = add i64 %395, 9
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %431 to i32*
  store i32 %404, i32* %433, align 4
  %434 = load i64, i64* %RBP, align 8
  %435 = add i64 %434, -36
  %436 = load i64, i64* %PC, align 8
  %437 = add i64 %436, 3
  store i64 %437, i64* %PC, align 8
  %438 = inttoptr i64 %435 to i32*
  %439 = load i32, i32* %438, align 4
  %440 = zext i32 %439 to i64
  store i64 %440, i64* %RAX, align 8, !tbaa !2428
  %441 = add i64 %434, -8
  %442 = add i64 %436, 6
  store i64 %442, i64* %PC, align 8
  %443 = inttoptr i64 %441 to i32*
  %444 = load i32, i32* %443, align 4
  %445 = add i32 %444, %439
  %446 = zext i32 %445 to i64
  store i64 %446, i64* %RAX, align 8, !tbaa !2428
  %447 = icmp ult i32 %445, %439
  %448 = icmp ult i32 %445, %444
  %449 = or i1 %447, %448
  %450 = zext i1 %449 to i8
  store i8 %450, i8* %16, align 1, !tbaa !2433
  %451 = and i32 %445, 255
  %452 = tail call i32 @llvm.ctpop.i32(i32 %451) #10
  %453 = trunc i32 %452 to i8
  %454 = and i8 %453, 1
  %455 = xor i8 %454, 1
  store i8 %455, i8* %23, align 1, !tbaa !2447
  %456 = xor i32 %444, %439
  %457 = xor i32 %456, %445
  %458 = lshr i32 %457, 4
  %459 = trunc i32 %458 to i8
  %460 = and i8 %459, 1
  store i8 %460, i8* %29, align 1, !tbaa !2451
  %461 = icmp eq i32 %445, 0
  %462 = zext i1 %461 to i8
  store i8 %462, i8* %32, align 1, !tbaa !2448
  %463 = lshr i32 %445, 31
  %464 = trunc i32 %463 to i8
  store i8 %464, i8* %35, align 1, !tbaa !2449
  %465 = lshr i32 %439, 31
  %466 = lshr i32 %444, 31
  %467 = xor i32 %463, %465
  %468 = xor i32 %463, %466
  %469 = add nuw nsw i32 %467, %468
  %470 = icmp eq i32 %469, 2
  %471 = zext i1 %470 to i8
  store i8 %471, i8* %41, align 1, !tbaa !2450
  %472 = add i64 %434, -40
  %473 = add i64 %436, 9
  store i64 %473, i64* %PC, align 8
  %474 = inttoptr i64 %472 to i32*
  store i32 %445, i32* %474, align 4
  %475 = load i64, i64* %RBP, align 8
  %476 = add i64 %475, -16
  %477 = load i64, i64* %PC, align 8
  %478 = add i64 %477, 4
  store i64 %478, i64* %PC, align 8
  %479 = inttoptr i64 %476 to i64*
  %480 = load i64, i64* %479, align 8
  store i64 %480, i64* %RCX, align 8, !tbaa !2428
  %481 = add i64 %475, -28
  %482 = add i64 %477, 8
  store i64 %482, i64* %PC, align 8
  %483 = inttoptr i64 %481 to i32*
  %484 = load i32, i32* %483, align 4
  %485 = sext i32 %484 to i64
  store i64 %485, i64* %RDX, align 8, !tbaa !2428
  %486 = shl nsw i64 %485, 3
  %487 = add i64 %486, %480
  %488 = add i64 %477, 13
  store i64 %488, i64* %PC, align 8
  %489 = inttoptr i64 %487 to i64*
  %490 = load i64, i64* %489, align 8
  store i64 %490, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %491 = add i64 %477, 17
  store i64 %491, i64* %PC, align 8
  %492 = load i64, i64* %479, align 8
  store i64 %492, i64* %RCX, align 8, !tbaa !2428
  %493 = add i64 %475, -32
  %494 = add i64 %477, 21
  store i64 %494, i64* %PC, align 8
  %495 = inttoptr i64 %493 to i32*
  %496 = load i32, i32* %495, align 4
  %497 = sext i32 %496 to i64
  store i64 %497, i64* %RDX, align 8, !tbaa !2428
  %498 = shl nsw i64 %497, 3
  %499 = add i64 %498, %492
  %500 = add i64 %477, 26
  store i64 %500, i64* %PC, align 8
  %501 = bitcast i64 %490 to double
  %502 = inttoptr i64 %499 to double*
  %503 = load double, double* %502, align 8
  %504 = fadd double %501, %503
  store double %504, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %505 = add i64 %475, -120
  %506 = add i64 %477, 31
  store i64 %506, i64* %PC, align 8
  %507 = inttoptr i64 %505 to double*
  store double %504, double* %507, align 8
  %508 = load i64, i64* %RBP, align 8
  %509 = add i64 %508, -16
  %510 = load i64, i64* %PC, align 8
  %511 = add i64 %510, 4
  store i64 %511, i64* %PC, align 8
  %512 = inttoptr i64 %509 to i64*
  %513 = load i64, i64* %512, align 8
  store i64 %513, i64* %RCX, align 8, !tbaa !2428
  %514 = add i64 %508, -28
  %515 = add i64 %510, 7
  store i64 %515, i64* %PC, align 8
  %516 = inttoptr i64 %514 to i32*
  %517 = load i32, i32* %516, align 4
  %518 = add i32 %517, 1
  %519 = zext i32 %518 to i64
  store i64 %519, i64* %RAX, align 8, !tbaa !2428
  %520 = icmp eq i32 %517, -1
  %521 = icmp eq i32 %518, 0
  %522 = or i1 %520, %521
  %523 = zext i1 %522 to i8
  store i8 %523, i8* %16, align 1, !tbaa !2433
  %524 = and i32 %518, 255
  %525 = tail call i32 @llvm.ctpop.i32(i32 %524) #10
  %526 = trunc i32 %525 to i8
  %527 = and i8 %526, 1
  %528 = xor i8 %527, 1
  store i8 %528, i8* %23, align 1, !tbaa !2447
  %529 = xor i32 %518, %517
  %530 = lshr i32 %529, 4
  %531 = trunc i32 %530 to i8
  %532 = and i8 %531, 1
  store i8 %532, i8* %29, align 1, !tbaa !2451
  %533 = zext i1 %521 to i8
  store i8 %533, i8* %32, align 1, !tbaa !2448
  %534 = lshr i32 %518, 31
  %535 = trunc i32 %534 to i8
  store i8 %535, i8* %35, align 1, !tbaa !2449
  %536 = lshr i32 %517, 31
  %537 = xor i32 %534, %536
  %538 = add nuw nsw i32 %537, %534
  %539 = icmp eq i32 %538, 2
  %540 = zext i1 %539 to i8
  store i8 %540, i8* %41, align 1, !tbaa !2450
  %541 = sext i32 %518 to i64
  store i64 %541, i64* %RDX, align 8, !tbaa !2428
  %542 = shl nsw i64 %541, 3
  %543 = add i64 %513, %542
  %544 = add i64 %510, 18
  store i64 %544, i64* %PC, align 8
  %545 = inttoptr i64 %543 to i64*
  %546 = load i64, i64* %545, align 8
  store i64 %546, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %547 = add i64 %510, 22
  store i64 %547, i64* %PC, align 8
  %548 = load i64, i64* %512, align 8
  store i64 %548, i64* %RCX, align 8, !tbaa !2428
  %549 = add i64 %508, -32
  %550 = add i64 %510, 25
  store i64 %550, i64* %PC, align 8
  %551 = inttoptr i64 %549 to i32*
  %552 = load i32, i32* %551, align 4
  %553 = add i32 %552, 1
  %554 = zext i32 %553 to i64
  store i64 %554, i64* %RAX, align 8, !tbaa !2428
  %555 = icmp eq i32 %552, -1
  %556 = icmp eq i32 %553, 0
  %557 = or i1 %555, %556
  %558 = zext i1 %557 to i8
  store i8 %558, i8* %16, align 1, !tbaa !2433
  %559 = and i32 %553, 255
  %560 = tail call i32 @llvm.ctpop.i32(i32 %559) #10
  %561 = trunc i32 %560 to i8
  %562 = and i8 %561, 1
  %563 = xor i8 %562, 1
  store i8 %563, i8* %23, align 1, !tbaa !2447
  %564 = xor i32 %553, %552
  %565 = lshr i32 %564, 4
  %566 = trunc i32 %565 to i8
  %567 = and i8 %566, 1
  store i8 %567, i8* %29, align 1, !tbaa !2451
  %568 = zext i1 %556 to i8
  store i8 %568, i8* %32, align 1, !tbaa !2448
  %569 = lshr i32 %553, 31
  %570 = trunc i32 %569 to i8
  store i8 %570, i8* %35, align 1, !tbaa !2449
  %571 = lshr i32 %552, 31
  %572 = xor i32 %569, %571
  %573 = add nuw nsw i32 %572, %569
  %574 = icmp eq i32 %573, 2
  %575 = zext i1 %574 to i8
  store i8 %575, i8* %41, align 1, !tbaa !2450
  %576 = sext i32 %553 to i64
  store i64 %576, i64* %RDX, align 8, !tbaa !2428
  %577 = shl nsw i64 %576, 3
  %578 = add i64 %548, %577
  %579 = add i64 %510, 36
  store i64 %579, i64* %PC, align 8
  %580 = bitcast i64 %546 to double
  %581 = inttoptr i64 %578 to double*
  %582 = load double, double* %581, align 8
  %583 = fadd double %580, %582
  store double %583, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %584 = load i64, i64* %RBP, align 8
  %585 = add i64 %584, -128
  %586 = add i64 %510, 41
  store i64 %586, i64* %PC, align 8
  %587 = inttoptr i64 %585 to double*
  store double %583, double* %587, align 8
  %588 = load i64, i64* %RBP, align 8
  %589 = add i64 %588, -16
  %590 = load i64, i64* %PC, align 8
  %591 = add i64 %590, 4
  store i64 %591, i64* %PC, align 8
  %592 = inttoptr i64 %589 to i64*
  %593 = load i64, i64* %592, align 8
  store i64 %593, i64* %RCX, align 8, !tbaa !2428
  %594 = add i64 %588, -28
  %595 = add i64 %590, 8
  store i64 %595, i64* %PC, align 8
  %596 = inttoptr i64 %594 to i32*
  %597 = load i32, i32* %596, align 4
  %598 = sext i32 %597 to i64
  store i64 %598, i64* %RDX, align 8, !tbaa !2428
  %599 = shl nsw i64 %598, 3
  %600 = add i64 %599, %593
  %601 = add i64 %590, 13
  store i64 %601, i64* %PC, align 8
  %602 = inttoptr i64 %600 to i64*
  %603 = load i64, i64* %602, align 8
  store i64 %603, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %604 = add i64 %590, 17
  store i64 %604, i64* %PC, align 8
  %605 = load i64, i64* %592, align 8
  store i64 %605, i64* %RCX, align 8, !tbaa !2428
  %606 = add i64 %588, -32
  %607 = add i64 %590, 21
  store i64 %607, i64* %PC, align 8
  %608 = inttoptr i64 %606 to i32*
  %609 = load i32, i32* %608, align 4
  %610 = sext i32 %609 to i64
  store i64 %610, i64* %RDX, align 8, !tbaa !2428
  %611 = shl nsw i64 %610, 3
  %612 = add i64 %611, %605
  %613 = add i64 %590, 26
  store i64 %613, i64* %PC, align 8
  %614 = bitcast i64 %603 to double
  %615 = inttoptr i64 %612 to double*
  %616 = load double, double* %615, align 8
  %617 = fsub double %614, %616
  store double %617, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %618 = add i64 %588, -136
  %619 = add i64 %590, 34
  store i64 %619, i64* %PC, align 8
  %620 = inttoptr i64 %618 to double*
  store double %617, double* %620, align 8
  %621 = load i64, i64* %RBP, align 8
  %622 = add i64 %621, -16
  %623 = load i64, i64* %PC, align 8
  %624 = add i64 %623, 4
  store i64 %624, i64* %PC, align 8
  %625 = inttoptr i64 %622 to i64*
  %626 = load i64, i64* %625, align 8
  store i64 %626, i64* %RCX, align 8, !tbaa !2428
  %627 = add i64 %621, -28
  %628 = add i64 %623, 7
  store i64 %628, i64* %PC, align 8
  %629 = inttoptr i64 %627 to i32*
  %630 = load i32, i32* %629, align 4
  %631 = add i32 %630, 1
  %632 = zext i32 %631 to i64
  store i64 %632, i64* %RAX, align 8, !tbaa !2428
  %633 = icmp eq i32 %630, -1
  %634 = icmp eq i32 %631, 0
  %635 = or i1 %633, %634
  %636 = zext i1 %635 to i8
  store i8 %636, i8* %16, align 1, !tbaa !2433
  %637 = and i32 %631, 255
  %638 = tail call i32 @llvm.ctpop.i32(i32 %637) #10
  %639 = trunc i32 %638 to i8
  %640 = and i8 %639, 1
  %641 = xor i8 %640, 1
  store i8 %641, i8* %23, align 1, !tbaa !2447
  %642 = xor i32 %631, %630
  %643 = lshr i32 %642, 4
  %644 = trunc i32 %643 to i8
  %645 = and i8 %644, 1
  store i8 %645, i8* %29, align 1, !tbaa !2451
  %646 = zext i1 %634 to i8
  store i8 %646, i8* %32, align 1, !tbaa !2448
  %647 = lshr i32 %631, 31
  %648 = trunc i32 %647 to i8
  store i8 %648, i8* %35, align 1, !tbaa !2449
  %649 = lshr i32 %630, 31
  %650 = xor i32 %647, %649
  %651 = add nuw nsw i32 %650, %647
  %652 = icmp eq i32 %651, 2
  %653 = zext i1 %652 to i8
  store i8 %653, i8* %41, align 1, !tbaa !2450
  %654 = sext i32 %631 to i64
  store i64 %654, i64* %RDX, align 8, !tbaa !2428
  %655 = shl nsw i64 %654, 3
  %656 = add i64 %626, %655
  %657 = add i64 %623, 18
  store i64 %657, i64* %PC, align 8
  %658 = inttoptr i64 %656 to i64*
  %659 = load i64, i64* %658, align 8
  store i64 %659, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %660 = add i64 %623, 22
  store i64 %660, i64* %PC, align 8
  %661 = load i64, i64* %625, align 8
  store i64 %661, i64* %RCX, align 8, !tbaa !2428
  %662 = add i64 %621, -32
  %663 = add i64 %623, 25
  store i64 %663, i64* %PC, align 8
  %664 = inttoptr i64 %662 to i32*
  %665 = load i32, i32* %664, align 4
  %666 = add i32 %665, 1
  %667 = zext i32 %666 to i64
  store i64 %667, i64* %RAX, align 8, !tbaa !2428
  %668 = icmp eq i32 %665, -1
  %669 = icmp eq i32 %666, 0
  %670 = or i1 %668, %669
  %671 = zext i1 %670 to i8
  store i8 %671, i8* %16, align 1, !tbaa !2433
  %672 = and i32 %666, 255
  %673 = tail call i32 @llvm.ctpop.i32(i32 %672) #10
  %674 = trunc i32 %673 to i8
  %675 = and i8 %674, 1
  %676 = xor i8 %675, 1
  store i8 %676, i8* %23, align 1, !tbaa !2447
  %677 = xor i32 %666, %665
  %678 = lshr i32 %677, 4
  %679 = trunc i32 %678 to i8
  %680 = and i8 %679, 1
  store i8 %680, i8* %29, align 1, !tbaa !2451
  %681 = zext i1 %669 to i8
  store i8 %681, i8* %32, align 1, !tbaa !2448
  %682 = lshr i32 %666, 31
  %683 = trunc i32 %682 to i8
  store i8 %683, i8* %35, align 1, !tbaa !2449
  %684 = lshr i32 %665, 31
  %685 = xor i32 %682, %684
  %686 = add nuw nsw i32 %685, %682
  %687 = icmp eq i32 %686, 2
  %688 = zext i1 %687 to i8
  store i8 %688, i8* %41, align 1, !tbaa !2450
  %689 = sext i32 %666 to i64
  store i64 %689, i64* %RDX, align 8, !tbaa !2428
  %690 = shl nsw i64 %689, 3
  %691 = add i64 %661, %690
  %692 = add i64 %623, 36
  store i64 %692, i64* %PC, align 8
  %693 = bitcast i64 %659 to double
  %694 = inttoptr i64 %691 to double*
  %695 = load double, double* %694, align 8
  %696 = fsub double %693, %695
  store double %696, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %697 = load i64, i64* %RBP, align 8
  %698 = add i64 %697, -144
  %699 = add i64 %623, 44
  store i64 %699, i64* %PC, align 8
  %700 = inttoptr i64 %698 to double*
  store double %696, double* %700, align 8
  %701 = load i64, i64* %RBP, align 8
  %702 = add i64 %701, -16
  %703 = load i64, i64* %PC, align 8
  %704 = add i64 %703, 4
  store i64 %704, i64* %PC, align 8
  %705 = inttoptr i64 %702 to i64*
  %706 = load i64, i64* %705, align 8
  store i64 %706, i64* %RCX, align 8, !tbaa !2428
  %707 = add i64 %701, -36
  %708 = add i64 %703, 8
  store i64 %708, i64* %PC, align 8
  %709 = inttoptr i64 %707 to i32*
  %710 = load i32, i32* %709, align 4
  %711 = sext i32 %710 to i64
  store i64 %711, i64* %RDX, align 8, !tbaa !2428
  %712 = shl nsw i64 %711, 3
  %713 = add i64 %712, %706
  %714 = add i64 %703, 13
  store i64 %714, i64* %PC, align 8
  %715 = inttoptr i64 %713 to i64*
  %716 = load i64, i64* %715, align 8
  store i64 %716, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %717 = add i64 %703, 17
  store i64 %717, i64* %PC, align 8
  %718 = load i64, i64* %705, align 8
  store i64 %718, i64* %RCX, align 8, !tbaa !2428
  %719 = add i64 %701, -40
  %720 = add i64 %703, 21
  store i64 %720, i64* %PC, align 8
  %721 = inttoptr i64 %719 to i32*
  %722 = load i32, i32* %721, align 4
  %723 = sext i32 %722 to i64
  store i64 %723, i64* %RDX, align 8, !tbaa !2428
  %724 = shl nsw i64 %723, 3
  %725 = add i64 %724, %718
  %726 = add i64 %703, 26
  store i64 %726, i64* %PC, align 8
  %727 = bitcast i64 %716 to double
  %728 = inttoptr i64 %725 to double*
  %729 = load double, double* %728, align 8
  %730 = fadd double %727, %729
  store double %730, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %731 = add i64 %701, -152
  %732 = add i64 %703, 34
  store i64 %732, i64* %PC, align 8
  %733 = inttoptr i64 %731 to double*
  store double %730, double* %733, align 8
  %734 = load i64, i64* %RBP, align 8
  %735 = add i64 %734, -16
  %736 = load i64, i64* %PC, align 8
  %737 = add i64 %736, 4
  store i64 %737, i64* %PC, align 8
  %738 = inttoptr i64 %735 to i64*
  %739 = load i64, i64* %738, align 8
  store i64 %739, i64* %RCX, align 8, !tbaa !2428
  %740 = add i64 %734, -36
  %741 = add i64 %736, 7
  store i64 %741, i64* %PC, align 8
  %742 = inttoptr i64 %740 to i32*
  %743 = load i32, i32* %742, align 4
  %744 = add i32 %743, 1
  %745 = zext i32 %744 to i64
  store i64 %745, i64* %RAX, align 8, !tbaa !2428
  %746 = icmp eq i32 %743, -1
  %747 = icmp eq i32 %744, 0
  %748 = or i1 %746, %747
  %749 = zext i1 %748 to i8
  store i8 %749, i8* %16, align 1, !tbaa !2433
  %750 = and i32 %744, 255
  %751 = tail call i32 @llvm.ctpop.i32(i32 %750) #10
  %752 = trunc i32 %751 to i8
  %753 = and i8 %752, 1
  %754 = xor i8 %753, 1
  store i8 %754, i8* %23, align 1, !tbaa !2447
  %755 = xor i32 %744, %743
  %756 = lshr i32 %755, 4
  %757 = trunc i32 %756 to i8
  %758 = and i8 %757, 1
  store i8 %758, i8* %29, align 1, !tbaa !2451
  %759 = zext i1 %747 to i8
  store i8 %759, i8* %32, align 1, !tbaa !2448
  %760 = lshr i32 %744, 31
  %761 = trunc i32 %760 to i8
  store i8 %761, i8* %35, align 1, !tbaa !2449
  %762 = lshr i32 %743, 31
  %763 = xor i32 %760, %762
  %764 = add nuw nsw i32 %763, %760
  %765 = icmp eq i32 %764, 2
  %766 = zext i1 %765 to i8
  store i8 %766, i8* %41, align 1, !tbaa !2450
  %767 = sext i32 %744 to i64
  store i64 %767, i64* %RDX, align 8, !tbaa !2428
  %768 = shl nsw i64 %767, 3
  %769 = add i64 %739, %768
  %770 = add i64 %736, 18
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %769 to i64*
  %772 = load i64, i64* %771, align 8
  store i64 %772, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %773 = add i64 %736, 22
  store i64 %773, i64* %PC, align 8
  %774 = load i64, i64* %738, align 8
  store i64 %774, i64* %RCX, align 8, !tbaa !2428
  %775 = add i64 %734, -40
  %776 = add i64 %736, 25
  store i64 %776, i64* %PC, align 8
  %777 = inttoptr i64 %775 to i32*
  %778 = load i32, i32* %777, align 4
  %779 = add i32 %778, 1
  %780 = zext i32 %779 to i64
  store i64 %780, i64* %RAX, align 8, !tbaa !2428
  %781 = icmp eq i32 %778, -1
  %782 = icmp eq i32 %779, 0
  %783 = or i1 %781, %782
  %784 = zext i1 %783 to i8
  store i8 %784, i8* %16, align 1, !tbaa !2433
  %785 = and i32 %779, 255
  %786 = tail call i32 @llvm.ctpop.i32(i32 %785) #10
  %787 = trunc i32 %786 to i8
  %788 = and i8 %787, 1
  %789 = xor i8 %788, 1
  store i8 %789, i8* %23, align 1, !tbaa !2447
  %790 = xor i32 %779, %778
  %791 = lshr i32 %790, 4
  %792 = trunc i32 %791 to i8
  %793 = and i8 %792, 1
  store i8 %793, i8* %29, align 1, !tbaa !2451
  %794 = zext i1 %782 to i8
  store i8 %794, i8* %32, align 1, !tbaa !2448
  %795 = lshr i32 %779, 31
  %796 = trunc i32 %795 to i8
  store i8 %796, i8* %35, align 1, !tbaa !2449
  %797 = lshr i32 %778, 31
  %798 = xor i32 %795, %797
  %799 = add nuw nsw i32 %798, %795
  %800 = icmp eq i32 %799, 2
  %801 = zext i1 %800 to i8
  store i8 %801, i8* %41, align 1, !tbaa !2450
  %802 = sext i32 %779 to i64
  store i64 %802, i64* %RDX, align 8, !tbaa !2428
  %803 = shl nsw i64 %802, 3
  %804 = add i64 %774, %803
  %805 = add i64 %736, 36
  store i64 %805, i64* %PC, align 8
  %806 = bitcast i64 %772 to double
  %807 = inttoptr i64 %804 to double*
  %808 = load double, double* %807, align 8
  %809 = fadd double %806, %808
  store double %809, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %810 = load i64, i64* %RBP, align 8
  %811 = add i64 %810, -160
  %812 = add i64 %736, 44
  store i64 %812, i64* %PC, align 8
  %813 = inttoptr i64 %811 to double*
  store double %809, double* %813, align 8
  %814 = load i64, i64* %RBP, align 8
  %815 = add i64 %814, -16
  %816 = load i64, i64* %PC, align 8
  %817 = add i64 %816, 4
  store i64 %817, i64* %PC, align 8
  %818 = inttoptr i64 %815 to i64*
  %819 = load i64, i64* %818, align 8
  store i64 %819, i64* %RCX, align 8, !tbaa !2428
  %820 = add i64 %814, -36
  %821 = add i64 %816, 8
  store i64 %821, i64* %PC, align 8
  %822 = inttoptr i64 %820 to i32*
  %823 = load i32, i32* %822, align 4
  %824 = sext i32 %823 to i64
  store i64 %824, i64* %RDX, align 8, !tbaa !2428
  %825 = shl nsw i64 %824, 3
  %826 = add i64 %825, %819
  %827 = add i64 %816, 13
  store i64 %827, i64* %PC, align 8
  %828 = inttoptr i64 %826 to i64*
  %829 = load i64, i64* %828, align 8
  store i64 %829, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %830 = add i64 %816, 17
  store i64 %830, i64* %PC, align 8
  %831 = load i64, i64* %818, align 8
  store i64 %831, i64* %RCX, align 8, !tbaa !2428
  %832 = add i64 %814, -40
  %833 = add i64 %816, 21
  store i64 %833, i64* %PC, align 8
  %834 = inttoptr i64 %832 to i32*
  %835 = load i32, i32* %834, align 4
  %836 = sext i32 %835 to i64
  store i64 %836, i64* %RDX, align 8, !tbaa !2428
  %837 = shl nsw i64 %836, 3
  %838 = add i64 %837, %831
  %839 = add i64 %816, 26
  store i64 %839, i64* %PC, align 8
  %840 = bitcast i64 %829 to double
  %841 = inttoptr i64 %838 to double*
  %842 = load double, double* %841, align 8
  %843 = fsub double %840, %842
  store double %843, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %844 = add i64 %814, -168
  %845 = add i64 %816, 34
  store i64 %845, i64* %PC, align 8
  %846 = inttoptr i64 %844 to double*
  store double %843, double* %846, align 8
  %847 = load i64, i64* %RBP, align 8
  %848 = add i64 %847, -16
  %849 = load i64, i64* %PC, align 8
  %850 = add i64 %849, 4
  store i64 %850, i64* %PC, align 8
  %851 = inttoptr i64 %848 to i64*
  %852 = load i64, i64* %851, align 8
  store i64 %852, i64* %RCX, align 8, !tbaa !2428
  %853 = add i64 %847, -36
  %854 = add i64 %849, 7
  store i64 %854, i64* %PC, align 8
  %855 = inttoptr i64 %853 to i32*
  %856 = load i32, i32* %855, align 4
  %857 = add i32 %856, 1
  %858 = zext i32 %857 to i64
  store i64 %858, i64* %RAX, align 8, !tbaa !2428
  %859 = icmp eq i32 %856, -1
  %860 = icmp eq i32 %857, 0
  %861 = or i1 %859, %860
  %862 = zext i1 %861 to i8
  store i8 %862, i8* %16, align 1, !tbaa !2433
  %863 = and i32 %857, 255
  %864 = tail call i32 @llvm.ctpop.i32(i32 %863) #10
  %865 = trunc i32 %864 to i8
  %866 = and i8 %865, 1
  %867 = xor i8 %866, 1
  store i8 %867, i8* %23, align 1, !tbaa !2447
  %868 = xor i32 %857, %856
  %869 = lshr i32 %868, 4
  %870 = trunc i32 %869 to i8
  %871 = and i8 %870, 1
  store i8 %871, i8* %29, align 1, !tbaa !2451
  %872 = zext i1 %860 to i8
  store i8 %872, i8* %32, align 1, !tbaa !2448
  %873 = lshr i32 %857, 31
  %874 = trunc i32 %873 to i8
  store i8 %874, i8* %35, align 1, !tbaa !2449
  %875 = lshr i32 %856, 31
  %876 = xor i32 %873, %875
  %877 = add nuw nsw i32 %876, %873
  %878 = icmp eq i32 %877, 2
  %879 = zext i1 %878 to i8
  store i8 %879, i8* %41, align 1, !tbaa !2450
  %880 = sext i32 %857 to i64
  store i64 %880, i64* %RDX, align 8, !tbaa !2428
  %881 = shl nsw i64 %880, 3
  %882 = add i64 %852, %881
  %883 = add i64 %849, 18
  store i64 %883, i64* %PC, align 8
  %884 = inttoptr i64 %882 to i64*
  %885 = load i64, i64* %884, align 8
  store i64 %885, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %886 = add i64 %849, 22
  store i64 %886, i64* %PC, align 8
  %887 = load i64, i64* %851, align 8
  store i64 %887, i64* %RCX, align 8, !tbaa !2428
  %888 = add i64 %847, -40
  %889 = add i64 %849, 25
  store i64 %889, i64* %PC, align 8
  %890 = inttoptr i64 %888 to i32*
  %891 = load i32, i32* %890, align 4
  %892 = add i32 %891, 1
  %893 = zext i32 %892 to i64
  store i64 %893, i64* %RAX, align 8, !tbaa !2428
  %894 = icmp eq i32 %891, -1
  %895 = icmp eq i32 %892, 0
  %896 = or i1 %894, %895
  %897 = zext i1 %896 to i8
  store i8 %897, i8* %16, align 1, !tbaa !2433
  %898 = and i32 %892, 255
  %899 = tail call i32 @llvm.ctpop.i32(i32 %898) #10
  %900 = trunc i32 %899 to i8
  %901 = and i8 %900, 1
  %902 = xor i8 %901, 1
  store i8 %902, i8* %23, align 1, !tbaa !2447
  %903 = xor i32 %892, %891
  %904 = lshr i32 %903, 4
  %905 = trunc i32 %904 to i8
  %906 = and i8 %905, 1
  store i8 %906, i8* %29, align 1, !tbaa !2451
  %907 = zext i1 %895 to i8
  store i8 %907, i8* %32, align 1, !tbaa !2448
  %908 = lshr i32 %892, 31
  %909 = trunc i32 %908 to i8
  store i8 %909, i8* %35, align 1, !tbaa !2449
  %910 = lshr i32 %891, 31
  %911 = xor i32 %908, %910
  %912 = add nuw nsw i32 %911, %908
  %913 = icmp eq i32 %912, 2
  %914 = zext i1 %913 to i8
  store i8 %914, i8* %41, align 1, !tbaa !2450
  %915 = sext i32 %892 to i64
  store i64 %915, i64* %RDX, align 8, !tbaa !2428
  %916 = shl nsw i64 %915, 3
  %917 = add i64 %887, %916
  %918 = add i64 %849, 36
  store i64 %918, i64* %PC, align 8
  %919 = bitcast i64 %885 to double
  %920 = inttoptr i64 %917 to double*
  %921 = load double, double* %920, align 8
  %922 = fsub double %919, %921
  store double %922, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %923 = load i64, i64* %RBP, align 8
  %924 = add i64 %923, -176
  %925 = add i64 %849, 44
  store i64 %925, i64* %PC, align 8
  %926 = inttoptr i64 %924 to double*
  store double %922, double* %926, align 8
  %927 = load i64, i64* %RBP, align 8
  %928 = add i64 %927, -120
  %929 = load i64, i64* %PC, align 8
  %930 = add i64 %929, 5
  store i64 %930, i64* %PC, align 8
  %931 = inttoptr i64 %928 to i64*
  %932 = load i64, i64* %931, align 8
  store i64 %932, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %933 = add i64 %927, -152
  %934 = add i64 %929, 13
  store i64 %934, i64* %PC, align 8
  %935 = bitcast i64 %932 to double
  %936 = inttoptr i64 %933 to double*
  %937 = load double, double* %936, align 8
  %938 = fadd double %935, %937
  store double %938, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %939 = add i64 %927, -16
  %940 = add i64 %929, 17
  store i64 %940, i64* %PC, align 8
  %941 = inttoptr i64 %939 to i64*
  %942 = load i64, i64* %941, align 8
  store i64 %942, i64* %RCX, align 8, !tbaa !2428
  %943 = add i64 %927, -28
  %944 = add i64 %929, 21
  store i64 %944, i64* %PC, align 8
  %945 = inttoptr i64 %943 to i32*
  %946 = load i32, i32* %945, align 4
  %947 = sext i32 %946 to i64
  store i64 %947, i64* %RDX, align 8, !tbaa !2428
  %948 = shl nsw i64 %947, 3
  %949 = add i64 %948, %942
  %950 = add i64 %929, 26
  store i64 %950, i64* %PC, align 8
  %951 = inttoptr i64 %949 to double*
  store double %938, double* %951, align 8
  %952 = load i64, i64* %RBP, align 8
  %953 = add i64 %952, -128
  %954 = load i64, i64* %PC, align 8
  %955 = add i64 %954, 5
  store i64 %955, i64* %PC, align 8
  %956 = inttoptr i64 %953 to i64*
  %957 = load i64, i64* %956, align 8
  store i64 %957, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %958 = add i64 %952, -160
  %959 = add i64 %954, 13
  store i64 %959, i64* %PC, align 8
  %960 = bitcast i64 %957 to double
  %961 = inttoptr i64 %958 to double*
  %962 = load double, double* %961, align 8
  %963 = fadd double %960, %962
  store double %963, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %964 = add i64 %952, -16
  %965 = add i64 %954, 17
  store i64 %965, i64* %PC, align 8
  %966 = inttoptr i64 %964 to i64*
  %967 = load i64, i64* %966, align 8
  store i64 %967, i64* %RCX, align 8, !tbaa !2428
  %968 = add i64 %952, -28
  %969 = add i64 %954, 20
  store i64 %969, i64* %PC, align 8
  %970 = inttoptr i64 %968 to i32*
  %971 = load i32, i32* %970, align 4
  %972 = add i32 %971, 1
  %973 = zext i32 %972 to i64
  store i64 %973, i64* %RAX, align 8, !tbaa !2428
  %974 = icmp eq i32 %971, -1
  %975 = icmp eq i32 %972, 0
  %976 = or i1 %974, %975
  %977 = zext i1 %976 to i8
  store i8 %977, i8* %16, align 1, !tbaa !2433
  %978 = and i32 %972, 255
  %979 = tail call i32 @llvm.ctpop.i32(i32 %978) #10
  %980 = trunc i32 %979 to i8
  %981 = and i8 %980, 1
  %982 = xor i8 %981, 1
  store i8 %982, i8* %23, align 1, !tbaa !2447
  %983 = xor i32 %972, %971
  %984 = lshr i32 %983, 4
  %985 = trunc i32 %984 to i8
  %986 = and i8 %985, 1
  store i8 %986, i8* %29, align 1, !tbaa !2451
  %987 = zext i1 %975 to i8
  store i8 %987, i8* %32, align 1, !tbaa !2448
  %988 = lshr i32 %972, 31
  %989 = trunc i32 %988 to i8
  store i8 %989, i8* %35, align 1, !tbaa !2449
  %990 = lshr i32 %971, 31
  %991 = xor i32 %988, %990
  %992 = add nuw nsw i32 %991, %988
  %993 = icmp eq i32 %992, 2
  %994 = zext i1 %993 to i8
  store i8 %994, i8* %41, align 1, !tbaa !2450
  %995 = sext i32 %972 to i64
  store i64 %995, i64* %RDX, align 8, !tbaa !2428
  %996 = shl nsw i64 %995, 3
  %997 = add i64 %967, %996
  %998 = add i64 %954, 31
  store i64 %998, i64* %PC, align 8
  %999 = inttoptr i64 %997 to double*
  store double %963, double* %999, align 8
  %1000 = load i64, i64* %RBP, align 8
  %1001 = add i64 %1000, -120
  %1002 = load i64, i64* %PC, align 8
  %1003 = add i64 %1002, 5
  store i64 %1003, i64* %PC, align 8
  %1004 = inttoptr i64 %1001 to i64*
  %1005 = load i64, i64* %1004, align 8
  store i64 %1005, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1006 = add i64 %1000, -152
  %1007 = add i64 %1002, 13
  store i64 %1007, i64* %PC, align 8
  %1008 = bitcast i64 %1005 to double
  %1009 = inttoptr i64 %1006 to double*
  %1010 = load double, double* %1009, align 8
  %1011 = fsub double %1008, %1010
  store double %1011, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1012 = add i64 %1000, -16
  %1013 = add i64 %1002, 17
  store i64 %1013, i64* %PC, align 8
  %1014 = inttoptr i64 %1012 to i64*
  %1015 = load i64, i64* %1014, align 8
  store i64 %1015, i64* %RCX, align 8, !tbaa !2428
  %1016 = add i64 %1000, -36
  %1017 = add i64 %1002, 21
  store i64 %1017, i64* %PC, align 8
  %1018 = inttoptr i64 %1016 to i32*
  %1019 = load i32, i32* %1018, align 4
  %1020 = sext i32 %1019 to i64
  store i64 %1020, i64* %RDX, align 8, !tbaa !2428
  %1021 = shl nsw i64 %1020, 3
  %1022 = add i64 %1021, %1015
  %1023 = add i64 %1002, 26
  store i64 %1023, i64* %PC, align 8
  %1024 = inttoptr i64 %1022 to double*
  store double %1011, double* %1024, align 8
  %1025 = load i64, i64* %RBP, align 8
  %1026 = add i64 %1025, -128
  %1027 = load i64, i64* %PC, align 8
  %1028 = add i64 %1027, 5
  store i64 %1028, i64* %PC, align 8
  %1029 = inttoptr i64 %1026 to i64*
  %1030 = load i64, i64* %1029, align 8
  store i64 %1030, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1031 = add i64 %1025, -160
  %1032 = add i64 %1027, 13
  store i64 %1032, i64* %PC, align 8
  %1033 = bitcast i64 %1030 to double
  %1034 = inttoptr i64 %1031 to double*
  %1035 = load double, double* %1034, align 8
  %1036 = fsub double %1033, %1035
  store double %1036, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1037 = add i64 %1025, -16
  %1038 = add i64 %1027, 17
  store i64 %1038, i64* %PC, align 8
  %1039 = inttoptr i64 %1037 to i64*
  %1040 = load i64, i64* %1039, align 8
  store i64 %1040, i64* %RCX, align 8, !tbaa !2428
  %1041 = add i64 %1025, -36
  %1042 = add i64 %1027, 20
  store i64 %1042, i64* %PC, align 8
  %1043 = inttoptr i64 %1041 to i32*
  %1044 = load i32, i32* %1043, align 4
  %1045 = add i32 %1044, 1
  %1046 = zext i32 %1045 to i64
  store i64 %1046, i64* %RAX, align 8, !tbaa !2428
  %1047 = icmp eq i32 %1044, -1
  %1048 = icmp eq i32 %1045, 0
  %1049 = or i1 %1047, %1048
  %1050 = zext i1 %1049 to i8
  store i8 %1050, i8* %16, align 1, !tbaa !2433
  %1051 = and i32 %1045, 255
  %1052 = tail call i32 @llvm.ctpop.i32(i32 %1051) #10
  %1053 = trunc i32 %1052 to i8
  %1054 = and i8 %1053, 1
  %1055 = xor i8 %1054, 1
  store i8 %1055, i8* %23, align 1, !tbaa !2447
  %1056 = xor i32 %1045, %1044
  %1057 = lshr i32 %1056, 4
  %1058 = trunc i32 %1057 to i8
  %1059 = and i8 %1058, 1
  store i8 %1059, i8* %29, align 1, !tbaa !2451
  %1060 = zext i1 %1048 to i8
  store i8 %1060, i8* %32, align 1, !tbaa !2448
  %1061 = lshr i32 %1045, 31
  %1062 = trunc i32 %1061 to i8
  store i8 %1062, i8* %35, align 1, !tbaa !2449
  %1063 = lshr i32 %1044, 31
  %1064 = xor i32 %1061, %1063
  %1065 = add nuw nsw i32 %1064, %1061
  %1066 = icmp eq i32 %1065, 2
  %1067 = zext i1 %1066 to i8
  store i8 %1067, i8* %41, align 1, !tbaa !2450
  %1068 = sext i32 %1045 to i64
  store i64 %1068, i64* %RDX, align 8, !tbaa !2428
  %1069 = shl nsw i64 %1068, 3
  %1070 = add i64 %1040, %1069
  %1071 = add i64 %1027, 31
  store i64 %1071, i64* %PC, align 8
  %1072 = inttoptr i64 %1070 to double*
  store double %1036, double* %1072, align 8
  %1073 = load i64, i64* %RBP, align 8
  %1074 = add i64 %1073, -136
  %1075 = load i64, i64* %PC, align 8
  %1076 = add i64 %1075, 8
  store i64 %1076, i64* %PC, align 8
  %1077 = inttoptr i64 %1074 to i64*
  %1078 = load i64, i64* %1077, align 8
  store i64 %1078, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1079 = add i64 %1073, -176
  %1080 = add i64 %1075, 16
  store i64 %1080, i64* %PC, align 8
  %1081 = bitcast i64 %1078 to double
  %1082 = inttoptr i64 %1079 to double*
  %1083 = load double, double* %1082, align 8
  %1084 = fsub double %1081, %1083
  store double %1084, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1085 = add i64 %1073, -16
  %1086 = add i64 %1075, 20
  store i64 %1086, i64* %PC, align 8
  %1087 = inttoptr i64 %1085 to i64*
  %1088 = load i64, i64* %1087, align 8
  store i64 %1088, i64* %RCX, align 8, !tbaa !2428
  %1089 = add i64 %1073, -32
  %1090 = add i64 %1075, 24
  store i64 %1090, i64* %PC, align 8
  %1091 = inttoptr i64 %1089 to i32*
  %1092 = load i32, i32* %1091, align 4
  %1093 = sext i32 %1092 to i64
  store i64 %1093, i64* %RDX, align 8, !tbaa !2428
  %1094 = shl nsw i64 %1093, 3
  %1095 = add i64 %1094, %1088
  %1096 = add i64 %1075, 29
  store i64 %1096, i64* %PC, align 8
  %1097 = inttoptr i64 %1095 to double*
  store double %1084, double* %1097, align 8
  %1098 = load i64, i64* %RBP, align 8
  %1099 = add i64 %1098, -144
  %1100 = load i64, i64* %PC, align 8
  %1101 = add i64 %1100, 8
  store i64 %1101, i64* %PC, align 8
  %1102 = inttoptr i64 %1099 to i64*
  %1103 = load i64, i64* %1102, align 8
  store i64 %1103, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1104 = add i64 %1098, -168
  %1105 = add i64 %1100, 16
  store i64 %1105, i64* %PC, align 8
  %1106 = bitcast i64 %1103 to double
  %1107 = inttoptr i64 %1104 to double*
  %1108 = load double, double* %1107, align 8
  %1109 = fadd double %1106, %1108
  store double %1109, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1110 = add i64 %1098, -16
  %1111 = add i64 %1100, 20
  store i64 %1111, i64* %PC, align 8
  %1112 = inttoptr i64 %1110 to i64*
  %1113 = load i64, i64* %1112, align 8
  store i64 %1113, i64* %RCX, align 8, !tbaa !2428
  %1114 = add i64 %1098, -32
  %1115 = add i64 %1100, 23
  store i64 %1115, i64* %PC, align 8
  %1116 = inttoptr i64 %1114 to i32*
  %1117 = load i32, i32* %1116, align 4
  %1118 = add i32 %1117, 1
  %1119 = zext i32 %1118 to i64
  store i64 %1119, i64* %RAX, align 8, !tbaa !2428
  %1120 = icmp eq i32 %1117, -1
  %1121 = icmp eq i32 %1118, 0
  %1122 = or i1 %1120, %1121
  %1123 = zext i1 %1122 to i8
  store i8 %1123, i8* %16, align 1, !tbaa !2433
  %1124 = and i32 %1118, 255
  %1125 = tail call i32 @llvm.ctpop.i32(i32 %1124) #10
  %1126 = trunc i32 %1125 to i8
  %1127 = and i8 %1126, 1
  %1128 = xor i8 %1127, 1
  store i8 %1128, i8* %23, align 1, !tbaa !2447
  %1129 = xor i32 %1118, %1117
  %1130 = lshr i32 %1129, 4
  %1131 = trunc i32 %1130 to i8
  %1132 = and i8 %1131, 1
  store i8 %1132, i8* %29, align 1, !tbaa !2451
  %1133 = zext i1 %1121 to i8
  store i8 %1133, i8* %32, align 1, !tbaa !2448
  %1134 = lshr i32 %1118, 31
  %1135 = trunc i32 %1134 to i8
  store i8 %1135, i8* %35, align 1, !tbaa !2449
  %1136 = lshr i32 %1117, 31
  %1137 = xor i32 %1134, %1136
  %1138 = add nuw nsw i32 %1137, %1134
  %1139 = icmp eq i32 %1138, 2
  %1140 = zext i1 %1139 to i8
  store i8 %1140, i8* %41, align 1, !tbaa !2450
  %1141 = sext i32 %1118 to i64
  store i64 %1141, i64* %RDX, align 8, !tbaa !2428
  %1142 = shl nsw i64 %1141, 3
  %1143 = add i64 %1113, %1142
  %1144 = add i64 %1100, 34
  store i64 %1144, i64* %PC, align 8
  %1145 = inttoptr i64 %1143 to double*
  store double %1109, double* %1145, align 8
  %1146 = load i64, i64* %RBP, align 8
  %1147 = add i64 %1146, -136
  %1148 = load i64, i64* %PC, align 8
  %1149 = add i64 %1148, 8
  store i64 %1149, i64* %PC, align 8
  %1150 = inttoptr i64 %1147 to i64*
  %1151 = load i64, i64* %1150, align 8
  store i64 %1151, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1152 = add i64 %1146, -176
  %1153 = add i64 %1148, 16
  store i64 %1153, i64* %PC, align 8
  %1154 = bitcast i64 %1151 to double
  %1155 = inttoptr i64 %1152 to double*
  %1156 = load double, double* %1155, align 8
  %1157 = fadd double %1154, %1156
  store double %1157, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1158 = add i64 %1146, -16
  %1159 = add i64 %1148, 20
  store i64 %1159, i64* %PC, align 8
  %1160 = inttoptr i64 %1158 to i64*
  %1161 = load i64, i64* %1160, align 8
  store i64 %1161, i64* %RCX, align 8, !tbaa !2428
  %1162 = add i64 %1146, -40
  %1163 = add i64 %1148, 24
  store i64 %1163, i64* %PC, align 8
  %1164 = inttoptr i64 %1162 to i32*
  %1165 = load i32, i32* %1164, align 4
  %1166 = sext i32 %1165 to i64
  store i64 %1166, i64* %RDX, align 8, !tbaa !2428
  %1167 = shl nsw i64 %1166, 3
  %1168 = add i64 %1167, %1161
  %1169 = add i64 %1148, 29
  store i64 %1169, i64* %PC, align 8
  %1170 = inttoptr i64 %1168 to double*
  store double %1157, double* %1170, align 8
  %1171 = load i64, i64* %RBP, align 8
  %1172 = add i64 %1171, -144
  %1173 = load i64, i64* %PC, align 8
  %1174 = add i64 %1173, 8
  store i64 %1174, i64* %PC, align 8
  %1175 = inttoptr i64 %1172 to i64*
  %1176 = load i64, i64* %1175, align 8
  store i64 %1176, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1177 = add i64 %1171, -168
  %1178 = add i64 %1173, 16
  store i64 %1178, i64* %PC, align 8
  %1179 = bitcast i64 %1176 to double
  %1180 = inttoptr i64 %1177 to double*
  %1181 = load double, double* %1180, align 8
  %1182 = fsub double %1179, %1181
  store double %1182, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1183 = add i64 %1171, -16
  %1184 = add i64 %1173, 20
  store i64 %1184, i64* %PC, align 8
  %1185 = inttoptr i64 %1183 to i64*
  %1186 = load i64, i64* %1185, align 8
  store i64 %1186, i64* %RCX, align 8, !tbaa !2428
  %1187 = add i64 %1171, -40
  %1188 = add i64 %1173, 23
  store i64 %1188, i64* %PC, align 8
  %1189 = inttoptr i64 %1187 to i32*
  %1190 = load i32, i32* %1189, align 4
  %1191 = add i32 %1190, 1
  %1192 = zext i32 %1191 to i64
  store i64 %1192, i64* %RAX, align 8, !tbaa !2428
  %1193 = icmp eq i32 %1190, -1
  %1194 = icmp eq i32 %1191, 0
  %1195 = or i1 %1193, %1194
  %1196 = zext i1 %1195 to i8
  store i8 %1196, i8* %16, align 1, !tbaa !2433
  %1197 = and i32 %1191, 255
  %1198 = tail call i32 @llvm.ctpop.i32(i32 %1197) #10
  %1199 = trunc i32 %1198 to i8
  %1200 = and i8 %1199, 1
  %1201 = xor i8 %1200, 1
  store i8 %1201, i8* %23, align 1, !tbaa !2447
  %1202 = xor i32 %1191, %1190
  %1203 = lshr i32 %1202, 4
  %1204 = trunc i32 %1203 to i8
  %1205 = and i8 %1204, 1
  store i8 %1205, i8* %29, align 1, !tbaa !2451
  %1206 = zext i1 %1194 to i8
  store i8 %1206, i8* %32, align 1, !tbaa !2448
  %1207 = lshr i32 %1191, 31
  %1208 = trunc i32 %1207 to i8
  store i8 %1208, i8* %35, align 1, !tbaa !2449
  %1209 = lshr i32 %1190, 31
  %1210 = xor i32 %1207, %1209
  %1211 = add nuw nsw i32 %1210, %1207
  %1212 = icmp eq i32 %1211, 2
  %1213 = zext i1 %1212 to i8
  store i8 %1213, i8* %41, align 1, !tbaa !2450
  %1214 = sext i32 %1191 to i64
  store i64 %1214, i64* %RDX, align 8, !tbaa !2428
  %1215 = shl nsw i64 %1214, 3
  %1216 = add i64 %1186, %1215
  %1217 = add i64 %1173, 34
  store i64 %1217, i64* %PC, align 8
  %1218 = inttoptr i64 %1216 to double*
  store double %1182, double* %1218, align 8
  %1219 = load i64, i64* %RBP, align 8
  %1220 = add i64 %1219, -28
  %1221 = load i64, i64* %PC, align 8
  %1222 = add i64 %1221, 3
  store i64 %1222, i64* %PC, align 8
  %1223 = inttoptr i64 %1220 to i32*
  %1224 = load i32, i32* %1223, align 4
  %1225 = add i32 %1224, 2
  %1226 = zext i32 %1225 to i64
  store i64 %1226, i64* %RAX, align 8, !tbaa !2428
  %1227 = icmp ugt i32 %1224, -3
  %1228 = zext i1 %1227 to i8
  store i8 %1228, i8* %16, align 1, !tbaa !2433
  %1229 = and i32 %1225, 255
  %1230 = tail call i32 @llvm.ctpop.i32(i32 %1229) #10
  %1231 = trunc i32 %1230 to i8
  %1232 = and i8 %1231, 1
  %1233 = xor i8 %1232, 1
  store i8 %1233, i8* %23, align 1, !tbaa !2447
  %1234 = xor i32 %1225, %1224
  %1235 = lshr i32 %1234, 4
  %1236 = trunc i32 %1235 to i8
  %1237 = and i8 %1236, 1
  store i8 %1237, i8* %29, align 1, !tbaa !2451
  %1238 = icmp eq i32 %1225, 0
  %1239 = zext i1 %1238 to i8
  store i8 %1239, i8* %32, align 1, !tbaa !2448
  %1240 = lshr i32 %1225, 31
  %1241 = trunc i32 %1240 to i8
  store i8 %1241, i8* %35, align 1, !tbaa !2449
  %1242 = lshr i32 %1224, 31
  %1243 = xor i32 %1240, %1242
  %1244 = add nuw nsw i32 %1243, %1240
  %1245 = icmp eq i32 %1244, 2
  %1246 = zext i1 %1245 to i8
  store i8 %1246, i8* %41, align 1, !tbaa !2450
  %1247 = add i64 %1221, 9
  store i64 %1247, i64* %PC, align 8
  store i32 %1225, i32* %1223, align 4
  %1248 = load i64, i64* %PC, align 8
  %1249 = add i64 %1248, -594
  store i64 %1249, i64* %PC, align 8, !tbaa !2428
  br label %block_403346

block_40386d:                                     ; preds = %block_4035b1
  %1250 = add i64 %2617, -48
  %1251 = add i64 %2660, 7
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i32*
  store i32 0, i32* %1252, align 4
  %1253 = load i64, i64* %RBP, align 8
  %1254 = add i64 %1253, -56
  %1255 = load i64, i64* %PC, align 8
  %1256 = add i64 %1255, 3
  store i64 %1256, i64* %PC, align 8
  %1257 = inttoptr i64 %1254 to i32*
  %1258 = load i32, i32* %1257, align 4
  %1259 = shl i32 %1258, 1
  %1260 = icmp slt i32 %1258, 0
  %1261 = icmp slt i32 %1259, 0
  %1262 = xor i1 %1260, %1261
  %1263 = zext i32 %1259 to i64
  store i64 %1263, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %1258, 31
  %1264 = trunc i32 %.lobit to i8
  store i8 %1264, i8* %16, align 1, !tbaa !2432
  %1265 = and i32 %1259, 254
  %1266 = tail call i32 @llvm.ctpop.i32(i32 %1265) #10
  %1267 = trunc i32 %1266 to i8
  %1268 = and i8 %1267, 1
  %1269 = xor i8 %1268, 1
  store i8 %1269, i8* %23, align 1, !tbaa !2432
  store i8 0, i8* %29, align 1, !tbaa !2432
  %1270 = icmp eq i32 %1259, 0
  %1271 = zext i1 %1270 to i8
  store i8 %1271, i8* %32, align 1, !tbaa !2432
  %1272 = lshr i32 %1258, 30
  %1273 = trunc i32 %1272 to i8
  %1274 = and i8 %1273, 1
  store i8 %1274, i8* %35, align 1, !tbaa !2432
  %1275 = zext i1 %1262 to i8
  store i8 %1275, i8* %41, align 1, !tbaa !2432
  %1276 = add i64 %1253, -60
  %1277 = add i64 %1255, 9
  store i64 %1277, i64* %PC, align 8
  %1278 = inttoptr i64 %1276 to i32*
  store i32 %1259, i32* %1278, align 4
  %1279 = load i64, i64* %RBP, align 8
  %1280 = add i64 %1279, -60
  %1281 = load i64, i64* %PC, align 8
  %1282 = add i64 %1281, 3
  store i64 %1282, i64* %PC, align 8
  %1283 = inttoptr i64 %1280 to i32*
  %1284 = load i32, i32* %1283, align 4
  %1285 = zext i32 %1284 to i64
  store i64 %1285, i64* %RAX, align 8, !tbaa !2428
  %1286 = add i64 %1279, -44
  %1287 = add i64 %1281, 6
  store i64 %1287, i64* %PC, align 8
  %1288 = inttoptr i64 %1286 to i32*
  store i32 %1284, i32* %1288, align 4
  %1289 = bitcast %union.VectorReg* %97 to i8*
  %1290 = bitcast [32 x %union.VectorReg]* %5 to <2 x i32>*
  %1291 = bitcast i64* %95 to <2 x i32>*
  %1292 = bitcast %union.VectorReg* %97 to i32*
  %1293 = getelementptr inbounds i8, i8* %1289, i64 4
  %1294 = bitcast i8* %1293 to i32*
  %1295 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %1296 = bitcast i64* %1295 to i32*
  %1297 = getelementptr inbounds i8, i8* %1289, i64 12
  %1298 = bitcast i8* %1297 to i32*
  %1299 = bitcast %union.VectorReg* %97 to double*
  %.pre24 = load i64, i64* %PC, align 8
  br label %block_403883

block_403c42:                                     ; preds = %block_403930
  %1300 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 80) to i64*), align 16
  store i64 %1300, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1301 = add i64 %1596, -24
  %1302 = add i64 %1639, 12
  store i64 %1302, i64* %PC, align 8
  %1303 = inttoptr i64 %1301 to i64*
  %1304 = load i64, i64* %1303, align 8
  store i64 %1304, i64* %RAX, align 8, !tbaa !2428
  %1305 = add i64 %1596, -52
  %1306 = add i64 %1639, 15
  store i64 %1306, i64* %PC, align 8
  %1307 = inttoptr i64 %1305 to i32*
  %1308 = load i32, i32* %1307, align 4
  %1309 = add i32 %1308, 2
  %1310 = zext i32 %1309 to i64
  store i64 %1310, i64* %RCX, align 8, !tbaa !2428
  %1311 = icmp ugt i32 %1308, -3
  %1312 = zext i1 %1311 to i8
  store i8 %1312, i8* %16, align 1, !tbaa !2433
  %1313 = and i32 %1309, 255
  %1314 = tail call i32 @llvm.ctpop.i32(i32 %1313) #10
  %1315 = trunc i32 %1314 to i8
  %1316 = and i8 %1315, 1
  %1317 = xor i8 %1316, 1
  store i8 %1317, i8* %23, align 1, !tbaa !2447
  %1318 = xor i32 %1309, %1308
  %1319 = lshr i32 %1318, 4
  %1320 = trunc i32 %1319 to i8
  %1321 = and i8 %1320, 1
  store i8 %1321, i8* %29, align 1, !tbaa !2451
  %1322 = icmp eq i32 %1309, 0
  %1323 = zext i1 %1322 to i8
  store i8 %1323, i8* %32, align 1, !tbaa !2448
  %1324 = lshr i32 %1309, 31
  %1325 = trunc i32 %1324 to i8
  store i8 %1325, i8* %35, align 1, !tbaa !2449
  %1326 = lshr i32 %1308, 31
  %1327 = xor i32 %1324, %1326
  %1328 = add nuw nsw i32 %1327, %1324
  %1329 = icmp eq i32 %1328, 2
  %1330 = zext i1 %1329 to i8
  store i8 %1330, i8* %41, align 1, !tbaa !2450
  %1331 = sext i32 %1309 to i64
  store i64 %1331, i64* %RDX, align 8, !tbaa !2428
  %1332 = shl nsw i64 %1331, 3
  %1333 = add i64 %1304, %1332
  %1334 = add i64 %1639, 26
  store i64 %1334, i64* %PC, align 8
  %1335 = inttoptr i64 %1333 to i64*
  %1336 = load i64, i64* %1335, align 8
  store i64 %1336, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %1337 = add i64 %1596, -72
  %1338 = add i64 %1639, 31
  store i64 %1338, i64* %PC, align 8
  %1339 = inttoptr i64 %1337 to i64*
  store i64 %1336, i64* %1339, align 8
  %1340 = load i64, i64* %RBP, align 8
  %1341 = add i64 %1340, -24
  %1342 = load i64, i64* %PC, align 8
  %1343 = add i64 %1342, 4
  store i64 %1343, i64* %PC, align 8
  %1344 = inttoptr i64 %1341 to i64*
  %1345 = load i64, i64* %1344, align 8
  store i64 %1345, i64* %RAX, align 8, !tbaa !2428
  %1346 = add i64 %1340, -52
  %1347 = add i64 %1342, 7
  store i64 %1347, i64* %PC, align 8
  %1348 = inttoptr i64 %1346 to i32*
  %1349 = load i32, i32* %1348, align 4
  %1350 = add i32 %1349, 3
  %1351 = zext i32 %1350 to i64
  store i64 %1351, i64* %RCX, align 8, !tbaa !2428
  %1352 = icmp ugt i32 %1349, -4
  %1353 = zext i1 %1352 to i8
  store i8 %1353, i8* %16, align 1, !tbaa !2433
  %1354 = and i32 %1350, 255
  %1355 = tail call i32 @llvm.ctpop.i32(i32 %1354) #10
  %1356 = trunc i32 %1355 to i8
  %1357 = and i8 %1356, 1
  %1358 = xor i8 %1357, 1
  store i8 %1358, i8* %23, align 1, !tbaa !2447
  %1359 = xor i32 %1350, %1349
  %1360 = lshr i32 %1359, 4
  %1361 = trunc i32 %1360 to i8
  %1362 = and i8 %1361, 1
  store i8 %1362, i8* %29, align 1, !tbaa !2451
  %1363 = icmp eq i32 %1350, 0
  %1364 = zext i1 %1363 to i8
  store i8 %1364, i8* %32, align 1, !tbaa !2448
  %1365 = lshr i32 %1350, 31
  %1366 = trunc i32 %1365 to i8
  store i8 %1366, i8* %35, align 1, !tbaa !2449
  %1367 = lshr i32 %1349, 31
  %1368 = xor i32 %1365, %1367
  %1369 = add nuw nsw i32 %1368, %1365
  %1370 = icmp eq i32 %1369, 2
  %1371 = zext i1 %1370 to i8
  store i8 %1371, i8* %41, align 1, !tbaa !2450
  %1372 = sext i32 %1350 to i64
  store i64 %1372, i64* %RDX, align 8, !tbaa !2428
  %1373 = shl nsw i64 %1372, 3
  %1374 = add i64 %1345, %1373
  %1375 = add i64 %1342, 18
  store i64 %1375, i64* %PC, align 8
  %1376 = inttoptr i64 %1374 to i64*
  %1377 = load i64, i64* %1376, align 8
  store i64 %1377, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %1378 = add i64 %1340, -80
  %1379 = add i64 %1342, 23
  store i64 %1379, i64* %PC, align 8
  %1380 = inttoptr i64 %1378 to i64*
  store i64 %1377, i64* %1380, align 8
  %1381 = load i64, i64* %RBP, align 8
  %1382 = add i64 %1381, -72
  %1383 = load i64, i64* %PC, align 8
  %1384 = add i64 %1383, 5
  store i64 %1384, i64* %PC, align 8
  %1385 = inttoptr i64 %1382 to i64*
  %1386 = load i64, i64* %1385, align 8
  store i64 %1386, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %1387 = load <2 x i32>, <2 x i32>* %1290, align 1
  %1388 = load <2 x i32>, <2 x i32>* %1291, align 1
  %1389 = extractelement <2 x i32> %1387, i32 0
  store i32 %1389, i32* %1292, align 1, !tbaa !2454
  %1390 = extractelement <2 x i32> %1387, i32 1
  store i32 %1390, i32* %1294, align 1, !tbaa !2454
  %1391 = extractelement <2 x i32> %1388, i32 0
  store i32 %1391, i32* %1296, align 1, !tbaa !2454
  %1392 = extractelement <2 x i32> %1388, i32 1
  store i32 %1392, i32* %1298, align 1, !tbaa !2454
  %1393 = add i64 %1381, -88
  %1394 = add i64 %1383, 13
  store i64 %1394, i64* %PC, align 8
  %1395 = load double, double* %1299, align 1
  %1396 = inttoptr i64 %1393 to double*
  %1397 = load double, double* %1396, align 8
  %1398 = fmul double %1395, %1397
  store double %1398, double* %1299, align 1, !tbaa !2452
  %1399 = add i64 %1381, -80
  %1400 = add i64 %1383, 18
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1399 to double*
  %1402 = load double, double* %1401, align 8
  %1403 = fmul double %1398, %1402
  store double %1403, double* %1299, align 1, !tbaa !2452
  %1404 = bitcast i64 %1386 to double
  %1405 = fsub double %1404, %1403
  store double %1405, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %1406 = add i64 %1381, -104
  %1407 = add i64 %1383, 27
  store i64 %1407, i64* %PC, align 8
  %1408 = inttoptr i64 %1406 to double*
  store double %1405, double* %1408, align 8
  %1409 = load i64, i64* %RBP, align 8
  %1410 = add i64 %1409, -88
  %1411 = load i64, i64* %PC, align 8
  %1412 = add i64 %1411, 5
  store i64 %1412, i64* %PC, align 8
  %1413 = load double, double* %93, align 1
  %1414 = inttoptr i64 %1410 to double*
  %1415 = load double, double* %1414, align 8
  %1416 = fmul double %1413, %1415
  store double %1416, double* %93, align 1, !tbaa !2452
  %1417 = add i64 %1409, -72
  %1418 = add i64 %1411, 10
  store i64 %1418, i64* %PC, align 8
  %1419 = inttoptr i64 %1417 to double*
  %1420 = load double, double* %1419, align 8
  %1421 = fmul double %1416, %1420
  store double %1421, double* %93, align 1, !tbaa !2452
  %1422 = add i64 %1409, -80
  %1423 = add i64 %1411, 15
  store i64 %1423, i64* %PC, align 8
  %1424 = inttoptr i64 %1422 to double*
  %1425 = load double, double* %1424, align 8
  %1426 = fsub double %1421, %1425
  store double %1426, double* %93, align 1, !tbaa !2452
  %1427 = add i64 %1409, -112
  %1428 = add i64 %1411, 20
  store i64 %1428, i64* %PC, align 8
  %1429 = inttoptr i64 %1427 to double*
  store double %1426, double* %1429, align 8
  %1430 = load i64, i64* %RBP, align 8
  %1431 = add i64 %1430, -44
  %1432 = load i64, i64* %PC, align 8
  %1433 = add i64 %1432, 3
  store i64 %1433, i64* %PC, align 8
  %1434 = inttoptr i64 %1431 to i32*
  %1435 = load i32, i32* %1434, align 4
  %1436 = zext i32 %1435 to i64
  store i64 %1436, i64* %RCX, align 8, !tbaa !2428
  %1437 = add i64 %1430, -56
  %1438 = add i64 %1432, 6
  store i64 %1438, i64* %PC, align 8
  %1439 = inttoptr i64 %1437 to i32*
  %1440 = load i32, i32* %1439, align 4
  %1441 = add i32 %1440, %1435
  %1442 = zext i32 %1441 to i64
  store i64 %1442, i64* %RCX, align 8, !tbaa !2428
  %1443 = icmp ult i32 %1441, %1435
  %1444 = icmp ult i32 %1441, %1440
  %1445 = or i1 %1443, %1444
  %1446 = zext i1 %1445 to i8
  store i8 %1446, i8* %16, align 1, !tbaa !2433
  %1447 = and i32 %1441, 255
  %1448 = tail call i32 @llvm.ctpop.i32(i32 %1447) #10
  %1449 = trunc i32 %1448 to i8
  %1450 = and i8 %1449, 1
  %1451 = xor i8 %1450, 1
  store i8 %1451, i8* %23, align 1, !tbaa !2447
  %1452 = xor i32 %1440, %1435
  %1453 = xor i32 %1452, %1441
  %1454 = lshr i32 %1453, 4
  %1455 = trunc i32 %1454 to i8
  %1456 = and i8 %1455, 1
  store i8 %1456, i8* %29, align 1, !tbaa !2451
  %1457 = icmp eq i32 %1441, 0
  %1458 = zext i1 %1457 to i8
  store i8 %1458, i8* %32, align 1, !tbaa !2448
  %1459 = lshr i32 %1441, 31
  %1460 = trunc i32 %1459 to i8
  store i8 %1460, i8* %35, align 1, !tbaa !2449
  %1461 = lshr i32 %1435, 31
  %1462 = lshr i32 %1440, 31
  %1463 = xor i32 %1459, %1461
  %1464 = xor i32 %1459, %1462
  %1465 = add nuw nsw i32 %1463, %1464
  %1466 = icmp eq i32 %1465, 2
  %1467 = zext i1 %1466 to i8
  store i8 %1467, i8* %41, align 1, !tbaa !2450
  %1468 = add i64 %1430, -28
  %1469 = add i64 %1432, 9
  store i64 %1469, i64* %PC, align 8
  %1470 = inttoptr i64 %1468 to i32*
  store i32 %1441, i32* %1470, align 4
  %.pre26 = load i64, i64* %PC, align 8
  br label %block_403cb0

block_403cb0:                                     ; preds = %block_403cc6, %block_403c42
  %1471 = phi i64 [ %4817, %block_403cc6 ], [ %.pre26, %block_403c42 ]
  %1472 = load i64, i64* %RBP, align 8
  %1473 = add i64 %1472, -28
  %1474 = add i64 %1471, 3
  store i64 %1474, i64* %PC, align 8
  %1475 = inttoptr i64 %1473 to i32*
  %1476 = load i32, i32* %1475, align 4
  %1477 = zext i32 %1476 to i64
  store i64 %1477, i64* %RAX, align 8, !tbaa !2428
  %1478 = add i64 %1472, -8
  %1479 = add i64 %1471, 6
  store i64 %1479, i64* %PC, align 8
  %1480 = inttoptr i64 %1478 to i32*
  %1481 = load i32, i32* %1480, align 4
  %1482 = zext i32 %1481 to i64
  store i64 %1482, i64* %RCX, align 8, !tbaa !2428
  %1483 = add i64 %1472, -44
  %1484 = add i64 %1471, 9
  store i64 %1484, i64* %PC, align 8
  %1485 = inttoptr i64 %1483 to i32*
  %1486 = load i32, i32* %1485, align 4
  %1487 = zext i32 %1486 to i64
  store i64 %1487, i64* %RDX, align 8, !tbaa !2428
  %1488 = add i64 %1472, -56
  %1489 = add i64 %1471, 12
  store i64 %1489, i64* %PC, align 8
  %1490 = inttoptr i64 %1488 to i32*
  %1491 = load i32, i32* %1490, align 4
  %1492 = add i32 %1491, %1486
  %1493 = zext i32 %1492 to i64
  store i64 %1493, i64* %RDX, align 8, !tbaa !2428
  %1494 = add i32 %1492, %1481
  %1495 = zext i32 %1494 to i64
  store i64 %1495, i64* %RCX, align 8, !tbaa !2428
  %1496 = lshr i32 %1494, 31
  %1497 = sub i32 %1476, %1494
  %1498 = icmp ult i32 %1476, %1494
  %1499 = zext i1 %1498 to i8
  store i8 %1499, i8* %16, align 1, !tbaa !2433
  %1500 = and i32 %1497, 255
  %1501 = tail call i32 @llvm.ctpop.i32(i32 %1500) #10
  %1502 = trunc i32 %1501 to i8
  %1503 = and i8 %1502, 1
  %1504 = xor i8 %1503, 1
  store i8 %1504, i8* %23, align 1, !tbaa !2447
  %1505 = xor i32 %1494, %1476
  %1506 = xor i32 %1505, %1497
  %1507 = lshr i32 %1506, 4
  %1508 = trunc i32 %1507 to i8
  %1509 = and i8 %1508, 1
  store i8 %1509, i8* %29, align 1, !tbaa !2451
  %1510 = icmp eq i32 %1497, 0
  %1511 = zext i1 %1510 to i8
  store i8 %1511, i8* %32, align 1, !tbaa !2448
  %1512 = lshr i32 %1497, 31
  %1513 = trunc i32 %1512 to i8
  store i8 %1513, i8* %35, align 1, !tbaa !2449
  %1514 = lshr i32 %1476, 31
  %1515 = xor i32 %1496, %1514
  %1516 = xor i32 %1512, %1514
  %1517 = add nuw nsw i32 %1516, %1515
  %1518 = icmp eq i32 %1517, 2
  %1519 = zext i1 %1518 to i8
  store i8 %1519, i8* %41, align 1, !tbaa !2450
  %1520 = icmp ne i8 %1513, 0
  %1521 = xor i1 %1520, %1518
  %.v30 = select i1 %1521, i64 22, i64 827
  %1522 = add i64 %1471, %.v30
  store i64 %1522, i64* %PC, align 8, !tbaa !2428
  br i1 %1521, label %block_403cc6, label %block_403feb

block_403ffe:                                     ; preds = %block_403883
  %1523 = load i64, i64* %RSP, align 8
  %1524 = add i64 %1523, 48
  store i64 %1524, i64* %RSP, align 8, !tbaa !2428
  %1525 = icmp ugt i64 %1523, -49
  %1526 = zext i1 %1525 to i8
  store i8 %1526, i8* %16, align 1, !tbaa !2433
  %1527 = trunc i64 %1524 to i32
  %1528 = and i32 %1527, 255
  %1529 = tail call i32 @llvm.ctpop.i32(i32 %1528) #10
  %1530 = trunc i32 %1529 to i8
  %1531 = and i8 %1530, 1
  %1532 = xor i8 %1531, 1
  store i8 %1532, i8* %23, align 1, !tbaa !2447
  %1533 = xor i64 %1523, 16
  %1534 = xor i64 %1533, %1524
  %1535 = lshr i64 %1534, 4
  %1536 = trunc i64 %1535 to i8
  %1537 = and i8 %1536, 1
  store i8 %1537, i8* %29, align 1, !tbaa !2451
  %1538 = icmp eq i64 %1524, 0
  %1539 = zext i1 %1538 to i8
  store i8 %1539, i8* %32, align 1, !tbaa !2448
  %1540 = lshr i64 %1524, 63
  %1541 = trunc i64 %1540 to i8
  store i8 %1541, i8* %35, align 1, !tbaa !2449
  %1542 = lshr i64 %1523, 63
  %1543 = xor i64 %1540, %1542
  %1544 = add nuw nsw i64 %1543, %1540
  %1545 = icmp eq i64 %1544, 2
  %1546 = zext i1 %1545 to i8
  store i8 %1546, i8* %41, align 1, !tbaa !2450
  %1547 = add i64 %2698, 5
  store i64 %1547, i64* %PC, align 8
  %1548 = add i64 %1523, 56
  %1549 = inttoptr i64 %1524 to i64*
  %1550 = load i64, i64* %1549, align 8
  store i64 %1550, i64* %RBP, align 8, !tbaa !2428
  store i64 %1548, i64* %RSP, align 8, !tbaa !2428
  %1551 = add i64 %2698, 6
  store i64 %1551, i64* %PC, align 8
  %1552 = inttoptr i64 %1548 to i64*
  %1553 = load i64, i64* %1552, align 8
  store i64 %1553, i64* %PC, align 8, !tbaa !2428
  %1554 = add i64 %1523, 64
  store i64 %1554, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_403feb:                                     ; preds = %block_403cb0
  %1555 = load i64, i64* %RBP, align 8
  %1556 = add i64 %1555, -60
  %1557 = add i64 %1522, 8
  store i64 %1557, i64* %PC, align 8
  %1558 = inttoptr i64 %1556 to i32*
  %1559 = load i32, i32* %1558, align 4
  %1560 = zext i32 %1559 to i64
  store i64 %1560, i64* %RAX, align 8, !tbaa !2428
  %1561 = add i64 %1555, -44
  %1562 = add i64 %1522, 11
  store i64 %1562, i64* %PC, align 8
  %1563 = inttoptr i64 %1561 to i32*
  %1564 = load i32, i32* %1563, align 4
  %1565 = add i32 %1564, %1559
  %1566 = zext i32 %1565 to i64
  store i64 %1566, i64* %RAX, align 8, !tbaa !2428
  %1567 = icmp ult i32 %1565, %1559
  %1568 = icmp ult i32 %1565, %1564
  %1569 = or i1 %1567, %1568
  %1570 = zext i1 %1569 to i8
  store i8 %1570, i8* %16, align 1, !tbaa !2433
  %1571 = and i32 %1565, 255
  %1572 = tail call i32 @llvm.ctpop.i32(i32 %1571) #10
  %1573 = trunc i32 %1572 to i8
  %1574 = and i8 %1573, 1
  %1575 = xor i8 %1574, 1
  store i8 %1575, i8* %23, align 1, !tbaa !2447
  %1576 = xor i32 %1564, %1559
  %1577 = xor i32 %1576, %1565
  %1578 = lshr i32 %1577, 4
  %1579 = trunc i32 %1578 to i8
  %1580 = and i8 %1579, 1
  store i8 %1580, i8* %29, align 1, !tbaa !2451
  %1581 = icmp eq i32 %1565, 0
  %1582 = zext i1 %1581 to i8
  store i8 %1582, i8* %32, align 1, !tbaa !2448
  %1583 = lshr i32 %1565, 31
  %1584 = trunc i32 %1583 to i8
  store i8 %1584, i8* %35, align 1, !tbaa !2449
  %1585 = lshr i32 %1559, 31
  %1586 = lshr i32 %1564, 31
  %1587 = xor i32 %1583, %1585
  %1588 = xor i32 %1583, %1586
  %1589 = add nuw nsw i32 %1587, %1588
  %1590 = icmp eq i32 %1589, 2
  %1591 = zext i1 %1590 to i8
  store i8 %1591, i8* %41, align 1, !tbaa !2450
  %1592 = add i64 %1522, 14
  store i64 %1592, i64* %PC, align 8
  store i32 %1565, i32* %1563, align 4
  %1593 = load i64, i64* %PC, align 8
  %1594 = add i64 %1593, -1910
  store i64 %1594, i64* %PC, align 8, !tbaa !2428
  br label %block_403883

block_403930:                                     ; preds = %block_403941, %block_40388f
  %1595 = phi i64 [ %3744, %block_403941 ], [ %.pre25, %block_40388f ]
  %1596 = load i64, i64* %RBP, align 8
  %1597 = add i64 %1596, -28
  %1598 = add i64 %1595, 3
  store i64 %1598, i64* %PC, align 8
  %1599 = inttoptr i64 %1597 to i32*
  %1600 = load i32, i32* %1599, align 4
  %1601 = zext i32 %1600 to i64
  store i64 %1601, i64* %RAX, align 8, !tbaa !2428
  %1602 = add i64 %1596, -8
  %1603 = add i64 %1595, 6
  store i64 %1603, i64* %PC, align 8
  %1604 = inttoptr i64 %1602 to i32*
  %1605 = load i32, i32* %1604, align 4
  %1606 = zext i32 %1605 to i64
  store i64 %1606, i64* %RCX, align 8, !tbaa !2428
  %1607 = add i64 %1596, -44
  %1608 = add i64 %1595, 9
  store i64 %1608, i64* %PC, align 8
  %1609 = inttoptr i64 %1607 to i32*
  %1610 = load i32, i32* %1609, align 4
  %1611 = add i32 %1610, %1605
  %1612 = zext i32 %1611 to i64
  store i64 %1612, i64* %RCX, align 8, !tbaa !2428
  %1613 = lshr i32 %1611, 31
  %1614 = sub i32 %1600, %1611
  %1615 = icmp ult i32 %1600, %1611
  %1616 = zext i1 %1615 to i8
  store i8 %1616, i8* %16, align 1, !tbaa !2433
  %1617 = and i32 %1614, 255
  %1618 = tail call i32 @llvm.ctpop.i32(i32 %1617) #10
  %1619 = trunc i32 %1618 to i8
  %1620 = and i8 %1619, 1
  %1621 = xor i8 %1620, 1
  store i8 %1621, i8* %23, align 1, !tbaa !2447
  %1622 = xor i32 %1611, %1600
  %1623 = xor i32 %1622, %1614
  %1624 = lshr i32 %1623, 4
  %1625 = trunc i32 %1624 to i8
  %1626 = and i8 %1625, 1
  store i8 %1626, i8* %29, align 1, !tbaa !2451
  %1627 = icmp eq i32 %1614, 0
  %1628 = zext i1 %1627 to i8
  store i8 %1628, i8* %32, align 1, !tbaa !2448
  %1629 = lshr i32 %1614, 31
  %1630 = trunc i32 %1629 to i8
  store i8 %1630, i8* %35, align 1, !tbaa !2449
  %1631 = lshr i32 %1600, 31
  %1632 = xor i32 %1613, %1631
  %1633 = xor i32 %1629, %1631
  %1634 = add nuw nsw i32 %1633, %1632
  %1635 = icmp eq i32 %1634, 2
  %1636 = zext i1 %1635 to i8
  store i8 %1636, i8* %41, align 1, !tbaa !2450
  %1637 = icmp ne i8 %1630, 0
  %1638 = xor i1 %1637, %1635
  %.v29 = select i1 %1638, i64 17, i64 786
  %1639 = add i64 %1595, %.v29
  store i64 %1639, i64* %PC, align 8, !tbaa !2428
  br i1 %1638, label %block_403941, label %block_403c42

block_4035c2:                                     ; preds = %block_4035b1
  %1640 = add i64 %2660, 3
  store i64 %1640, i64* %PC, align 8
  %1641 = load i32, i32* %2620, align 4
  %1642 = zext i32 %1641 to i64
  store i64 %1642, i64* %RAX, align 8, !tbaa !2428
  %1643 = add i64 %2660, 6
  store i64 %1643, i64* %PC, align 8
  %1644 = load i32, i32* %2625, align 4
  %1645 = add i32 %1644, %1641
  %1646 = zext i32 %1645 to i64
  store i64 %1646, i64* %RAX, align 8, !tbaa !2428
  %1647 = icmp ult i32 %1645, %1641
  %1648 = icmp ult i32 %1645, %1644
  %1649 = or i1 %1647, %1648
  %1650 = zext i1 %1649 to i8
  store i8 %1650, i8* %16, align 1, !tbaa !2433
  %1651 = and i32 %1645, 255
  %1652 = tail call i32 @llvm.ctpop.i32(i32 %1651) #10
  %1653 = trunc i32 %1652 to i8
  %1654 = and i8 %1653, 1
  %1655 = xor i8 %1654, 1
  store i8 %1655, i8* %23, align 1, !tbaa !2447
  %1656 = xor i32 %1644, %1641
  %1657 = xor i32 %1656, %1645
  %1658 = lshr i32 %1657, 4
  %1659 = trunc i32 %1658 to i8
  %1660 = and i8 %1659, 1
  store i8 %1660, i8* %29, align 1, !tbaa !2451
  %1661 = icmp eq i32 %1645, 0
  %1662 = zext i1 %1661 to i8
  store i8 %1662, i8* %32, align 1, !tbaa !2448
  %1663 = lshr i32 %1645, 31
  %1664 = trunc i32 %1663 to i8
  store i8 %1664, i8* %35, align 1, !tbaa !2449
  %1665 = lshr i32 %1641, 31
  %1666 = lshr i32 %1644, 31
  %1667 = xor i32 %1663, %1665
  %1668 = xor i32 %1663, %1666
  %1669 = add nuw nsw i32 %1667, %1668
  %1670 = icmp eq i32 %1669, 2
  %1671 = zext i1 %1670 to i8
  store i8 %1671, i8* %41, align 1, !tbaa !2450
  %1672 = add i64 %2617, -32
  %1673 = add i64 %2660, 9
  store i64 %1673, i64* %PC, align 8
  %1674 = inttoptr i64 %1672 to i32*
  store i32 %1645, i32* %1674, align 4
  %1675 = load i64, i64* %RBP, align 8
  %1676 = add i64 %1675, -32
  %1677 = load i64, i64* %PC, align 8
  %1678 = add i64 %1677, 3
  store i64 %1678, i64* %PC, align 8
  %1679 = inttoptr i64 %1676 to i32*
  %1680 = load i32, i32* %1679, align 4
  %1681 = zext i32 %1680 to i64
  store i64 %1681, i64* %RAX, align 8, !tbaa !2428
  %1682 = add i64 %1675, -8
  %1683 = add i64 %1677, 6
  store i64 %1683, i64* %PC, align 8
  %1684 = inttoptr i64 %1682 to i32*
  %1685 = load i32, i32* %1684, align 4
  %1686 = add i32 %1685, %1680
  %1687 = zext i32 %1686 to i64
  store i64 %1687, i64* %RAX, align 8, !tbaa !2428
  %1688 = icmp ult i32 %1686, %1680
  %1689 = icmp ult i32 %1686, %1685
  %1690 = or i1 %1688, %1689
  %1691 = zext i1 %1690 to i8
  store i8 %1691, i8* %16, align 1, !tbaa !2433
  %1692 = and i32 %1686, 255
  %1693 = tail call i32 @llvm.ctpop.i32(i32 %1692) #10
  %1694 = trunc i32 %1693 to i8
  %1695 = and i8 %1694, 1
  %1696 = xor i8 %1695, 1
  store i8 %1696, i8* %23, align 1, !tbaa !2447
  %1697 = xor i32 %1685, %1680
  %1698 = xor i32 %1697, %1686
  %1699 = lshr i32 %1698, 4
  %1700 = trunc i32 %1699 to i8
  %1701 = and i8 %1700, 1
  store i8 %1701, i8* %29, align 1, !tbaa !2451
  %1702 = icmp eq i32 %1686, 0
  %1703 = zext i1 %1702 to i8
  store i8 %1703, i8* %32, align 1, !tbaa !2448
  %1704 = lshr i32 %1686, 31
  %1705 = trunc i32 %1704 to i8
  store i8 %1705, i8* %35, align 1, !tbaa !2449
  %1706 = lshr i32 %1680, 31
  %1707 = lshr i32 %1685, 31
  %1708 = xor i32 %1704, %1706
  %1709 = xor i32 %1704, %1707
  %1710 = add nuw nsw i32 %1708, %1709
  %1711 = icmp eq i32 %1710, 2
  %1712 = zext i1 %1711 to i8
  store i8 %1712, i8* %41, align 1, !tbaa !2450
  %1713 = add i64 %1675, -36
  %1714 = add i64 %1677, 9
  store i64 %1714, i64* %PC, align 8
  %1715 = inttoptr i64 %1713 to i32*
  store i32 %1686, i32* %1715, align 4
  %1716 = load i64, i64* %RBP, align 8
  %1717 = add i64 %1716, -36
  %1718 = load i64, i64* %PC, align 8
  %1719 = add i64 %1718, 3
  store i64 %1719, i64* %PC, align 8
  %1720 = inttoptr i64 %1717 to i32*
  %1721 = load i32, i32* %1720, align 4
  %1722 = zext i32 %1721 to i64
  store i64 %1722, i64* %RAX, align 8, !tbaa !2428
  %1723 = add i64 %1716, -8
  %1724 = add i64 %1718, 6
  store i64 %1724, i64* %PC, align 8
  %1725 = inttoptr i64 %1723 to i32*
  %1726 = load i32, i32* %1725, align 4
  %1727 = add i32 %1726, %1721
  %1728 = zext i32 %1727 to i64
  store i64 %1728, i64* %RAX, align 8, !tbaa !2428
  %1729 = icmp ult i32 %1727, %1721
  %1730 = icmp ult i32 %1727, %1726
  %1731 = or i1 %1729, %1730
  %1732 = zext i1 %1731 to i8
  store i8 %1732, i8* %16, align 1, !tbaa !2433
  %1733 = and i32 %1727, 255
  %1734 = tail call i32 @llvm.ctpop.i32(i32 %1733) #10
  %1735 = trunc i32 %1734 to i8
  %1736 = and i8 %1735, 1
  %1737 = xor i8 %1736, 1
  store i8 %1737, i8* %23, align 1, !tbaa !2447
  %1738 = xor i32 %1726, %1721
  %1739 = xor i32 %1738, %1727
  %1740 = lshr i32 %1739, 4
  %1741 = trunc i32 %1740 to i8
  %1742 = and i8 %1741, 1
  store i8 %1742, i8* %29, align 1, !tbaa !2451
  %1743 = icmp eq i32 %1727, 0
  %1744 = zext i1 %1743 to i8
  store i8 %1744, i8* %32, align 1, !tbaa !2448
  %1745 = lshr i32 %1727, 31
  %1746 = trunc i32 %1745 to i8
  store i8 %1746, i8* %35, align 1, !tbaa !2449
  %1747 = lshr i32 %1721, 31
  %1748 = lshr i32 %1726, 31
  %1749 = xor i32 %1745, %1747
  %1750 = xor i32 %1745, %1748
  %1751 = add nuw nsw i32 %1749, %1750
  %1752 = icmp eq i32 %1751, 2
  %1753 = zext i1 %1752 to i8
  store i8 %1753, i8* %41, align 1, !tbaa !2450
  %1754 = add i64 %1716, -40
  %1755 = add i64 %1718, 9
  store i64 %1755, i64* %PC, align 8
  %1756 = inttoptr i64 %1754 to i32*
  store i32 %1727, i32* %1756, align 4
  %1757 = load i64, i64* %RBP, align 8
  %1758 = add i64 %1757, -16
  %1759 = load i64, i64* %PC, align 8
  %1760 = add i64 %1759, 4
  store i64 %1760, i64* %PC, align 8
  %1761 = inttoptr i64 %1758 to i64*
  %1762 = load i64, i64* %1761, align 8
  store i64 %1762, i64* %RCX, align 8, !tbaa !2428
  %1763 = add i64 %1757, -28
  %1764 = add i64 %1759, 8
  store i64 %1764, i64* %PC, align 8
  %1765 = inttoptr i64 %1763 to i32*
  %1766 = load i32, i32* %1765, align 4
  %1767 = sext i32 %1766 to i64
  store i64 %1767, i64* %RDX, align 8, !tbaa !2428
  %1768 = shl nsw i64 %1767, 3
  %1769 = add i64 %1768, %1762
  %1770 = add i64 %1759, 13
  store i64 %1770, i64* %PC, align 8
  %1771 = inttoptr i64 %1769 to i64*
  %1772 = load i64, i64* %1771, align 8
  store i64 %1772, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1773 = add i64 %1759, 17
  store i64 %1773, i64* %PC, align 8
  %1774 = load i64, i64* %1761, align 8
  store i64 %1774, i64* %RCX, align 8, !tbaa !2428
  %1775 = add i64 %1757, -32
  %1776 = add i64 %1759, 21
  store i64 %1776, i64* %PC, align 8
  %1777 = inttoptr i64 %1775 to i32*
  %1778 = load i32, i32* %1777, align 4
  %1779 = sext i32 %1778 to i64
  store i64 %1779, i64* %RDX, align 8, !tbaa !2428
  %1780 = shl nsw i64 %1779, 3
  %1781 = add i64 %1780, %1774
  %1782 = add i64 %1759, 26
  store i64 %1782, i64* %PC, align 8
  %1783 = bitcast i64 %1772 to double
  %1784 = inttoptr i64 %1781 to double*
  %1785 = load double, double* %1784, align 8
  %1786 = fadd double %1783, %1785
  store double %1786, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1787 = add i64 %1757, -120
  %1788 = add i64 %1759, 31
  store i64 %1788, i64* %PC, align 8
  %1789 = inttoptr i64 %1787 to double*
  store double %1786, double* %1789, align 8
  %1790 = load i64, i64* %RBP, align 8
  %1791 = add i64 %1790, -16
  %1792 = load i64, i64* %PC, align 8
  %1793 = add i64 %1792, 4
  store i64 %1793, i64* %PC, align 8
  %1794 = inttoptr i64 %1791 to i64*
  %1795 = load i64, i64* %1794, align 8
  store i64 %1795, i64* %RCX, align 8, !tbaa !2428
  %1796 = add i64 %1790, -28
  %1797 = add i64 %1792, 7
  store i64 %1797, i64* %PC, align 8
  %1798 = inttoptr i64 %1796 to i32*
  %1799 = load i32, i32* %1798, align 4
  %1800 = add i32 %1799, 1
  %1801 = zext i32 %1800 to i64
  store i64 %1801, i64* %RAX, align 8, !tbaa !2428
  %1802 = icmp eq i32 %1799, -1
  %1803 = icmp eq i32 %1800, 0
  %1804 = or i1 %1802, %1803
  %1805 = zext i1 %1804 to i8
  store i8 %1805, i8* %16, align 1, !tbaa !2433
  %1806 = and i32 %1800, 255
  %1807 = tail call i32 @llvm.ctpop.i32(i32 %1806) #10
  %1808 = trunc i32 %1807 to i8
  %1809 = and i8 %1808, 1
  %1810 = xor i8 %1809, 1
  store i8 %1810, i8* %23, align 1, !tbaa !2447
  %1811 = xor i32 %1800, %1799
  %1812 = lshr i32 %1811, 4
  %1813 = trunc i32 %1812 to i8
  %1814 = and i8 %1813, 1
  store i8 %1814, i8* %29, align 1, !tbaa !2451
  %1815 = zext i1 %1803 to i8
  store i8 %1815, i8* %32, align 1, !tbaa !2448
  %1816 = lshr i32 %1800, 31
  %1817 = trunc i32 %1816 to i8
  store i8 %1817, i8* %35, align 1, !tbaa !2449
  %1818 = lshr i32 %1799, 31
  %1819 = xor i32 %1816, %1818
  %1820 = add nuw nsw i32 %1819, %1816
  %1821 = icmp eq i32 %1820, 2
  %1822 = zext i1 %1821 to i8
  store i8 %1822, i8* %41, align 1, !tbaa !2450
  %1823 = sext i32 %1800 to i64
  store i64 %1823, i64* %RDX, align 8, !tbaa !2428
  %1824 = shl nsw i64 %1823, 3
  %1825 = add i64 %1795, %1824
  %1826 = add i64 %1792, 18
  store i64 %1826, i64* %PC, align 8
  %1827 = inttoptr i64 %1825 to i64*
  %1828 = load i64, i64* %1827, align 8
  store i64 %1828, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1829 = add i64 %1792, 22
  store i64 %1829, i64* %PC, align 8
  %1830 = load i64, i64* %1794, align 8
  store i64 %1830, i64* %RCX, align 8, !tbaa !2428
  %1831 = add i64 %1790, -32
  %1832 = add i64 %1792, 25
  store i64 %1832, i64* %PC, align 8
  %1833 = inttoptr i64 %1831 to i32*
  %1834 = load i32, i32* %1833, align 4
  %1835 = add i32 %1834, 1
  %1836 = zext i32 %1835 to i64
  store i64 %1836, i64* %RAX, align 8, !tbaa !2428
  %1837 = icmp eq i32 %1834, -1
  %1838 = icmp eq i32 %1835, 0
  %1839 = or i1 %1837, %1838
  %1840 = zext i1 %1839 to i8
  store i8 %1840, i8* %16, align 1, !tbaa !2433
  %1841 = and i32 %1835, 255
  %1842 = tail call i32 @llvm.ctpop.i32(i32 %1841) #10
  %1843 = trunc i32 %1842 to i8
  %1844 = and i8 %1843, 1
  %1845 = xor i8 %1844, 1
  store i8 %1845, i8* %23, align 1, !tbaa !2447
  %1846 = xor i32 %1835, %1834
  %1847 = lshr i32 %1846, 4
  %1848 = trunc i32 %1847 to i8
  %1849 = and i8 %1848, 1
  store i8 %1849, i8* %29, align 1, !tbaa !2451
  %1850 = zext i1 %1838 to i8
  store i8 %1850, i8* %32, align 1, !tbaa !2448
  %1851 = lshr i32 %1835, 31
  %1852 = trunc i32 %1851 to i8
  store i8 %1852, i8* %35, align 1, !tbaa !2449
  %1853 = lshr i32 %1834, 31
  %1854 = xor i32 %1851, %1853
  %1855 = add nuw nsw i32 %1854, %1851
  %1856 = icmp eq i32 %1855, 2
  %1857 = zext i1 %1856 to i8
  store i8 %1857, i8* %41, align 1, !tbaa !2450
  %1858 = sext i32 %1835 to i64
  store i64 %1858, i64* %RDX, align 8, !tbaa !2428
  %1859 = shl nsw i64 %1858, 3
  %1860 = add i64 %1830, %1859
  %1861 = add i64 %1792, 36
  store i64 %1861, i64* %PC, align 8
  %1862 = bitcast i64 %1828 to double
  %1863 = inttoptr i64 %1860 to double*
  %1864 = load double, double* %1863, align 8
  %1865 = fadd double %1862, %1864
  store double %1865, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1866 = load i64, i64* %RBP, align 8
  %1867 = add i64 %1866, -128
  %1868 = add i64 %1792, 41
  store i64 %1868, i64* %PC, align 8
  %1869 = inttoptr i64 %1867 to double*
  store double %1865, double* %1869, align 8
  %1870 = load i64, i64* %RBP, align 8
  %1871 = add i64 %1870, -16
  %1872 = load i64, i64* %PC, align 8
  %1873 = add i64 %1872, 4
  store i64 %1873, i64* %PC, align 8
  %1874 = inttoptr i64 %1871 to i64*
  %1875 = load i64, i64* %1874, align 8
  store i64 %1875, i64* %RCX, align 8, !tbaa !2428
  %1876 = add i64 %1870, -28
  %1877 = add i64 %1872, 8
  store i64 %1877, i64* %PC, align 8
  %1878 = inttoptr i64 %1876 to i32*
  %1879 = load i32, i32* %1878, align 4
  %1880 = sext i32 %1879 to i64
  store i64 %1880, i64* %RDX, align 8, !tbaa !2428
  %1881 = shl nsw i64 %1880, 3
  %1882 = add i64 %1881, %1875
  %1883 = add i64 %1872, 13
  store i64 %1883, i64* %PC, align 8
  %1884 = inttoptr i64 %1882 to i64*
  %1885 = load i64, i64* %1884, align 8
  store i64 %1885, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1886 = add i64 %1872, 17
  store i64 %1886, i64* %PC, align 8
  %1887 = load i64, i64* %1874, align 8
  store i64 %1887, i64* %RCX, align 8, !tbaa !2428
  %1888 = add i64 %1870, -32
  %1889 = add i64 %1872, 21
  store i64 %1889, i64* %PC, align 8
  %1890 = inttoptr i64 %1888 to i32*
  %1891 = load i32, i32* %1890, align 4
  %1892 = sext i32 %1891 to i64
  store i64 %1892, i64* %RDX, align 8, !tbaa !2428
  %1893 = shl nsw i64 %1892, 3
  %1894 = add i64 %1893, %1887
  %1895 = add i64 %1872, 26
  store i64 %1895, i64* %PC, align 8
  %1896 = bitcast i64 %1885 to double
  %1897 = inttoptr i64 %1894 to double*
  %1898 = load double, double* %1897, align 8
  %1899 = fsub double %1896, %1898
  store double %1899, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1900 = add i64 %1870, -136
  %1901 = add i64 %1872, 34
  store i64 %1901, i64* %PC, align 8
  %1902 = inttoptr i64 %1900 to double*
  store double %1899, double* %1902, align 8
  %1903 = load i64, i64* %RBP, align 8
  %1904 = add i64 %1903, -16
  %1905 = load i64, i64* %PC, align 8
  %1906 = add i64 %1905, 4
  store i64 %1906, i64* %PC, align 8
  %1907 = inttoptr i64 %1904 to i64*
  %1908 = load i64, i64* %1907, align 8
  store i64 %1908, i64* %RCX, align 8, !tbaa !2428
  %1909 = add i64 %1903, -28
  %1910 = add i64 %1905, 7
  store i64 %1910, i64* %PC, align 8
  %1911 = inttoptr i64 %1909 to i32*
  %1912 = load i32, i32* %1911, align 4
  %1913 = add i32 %1912, 1
  %1914 = zext i32 %1913 to i64
  store i64 %1914, i64* %RAX, align 8, !tbaa !2428
  %1915 = icmp eq i32 %1912, -1
  %1916 = icmp eq i32 %1913, 0
  %1917 = or i1 %1915, %1916
  %1918 = zext i1 %1917 to i8
  store i8 %1918, i8* %16, align 1, !tbaa !2433
  %1919 = and i32 %1913, 255
  %1920 = tail call i32 @llvm.ctpop.i32(i32 %1919) #10
  %1921 = trunc i32 %1920 to i8
  %1922 = and i8 %1921, 1
  %1923 = xor i8 %1922, 1
  store i8 %1923, i8* %23, align 1, !tbaa !2447
  %1924 = xor i32 %1913, %1912
  %1925 = lshr i32 %1924, 4
  %1926 = trunc i32 %1925 to i8
  %1927 = and i8 %1926, 1
  store i8 %1927, i8* %29, align 1, !tbaa !2451
  %1928 = zext i1 %1916 to i8
  store i8 %1928, i8* %32, align 1, !tbaa !2448
  %1929 = lshr i32 %1913, 31
  %1930 = trunc i32 %1929 to i8
  store i8 %1930, i8* %35, align 1, !tbaa !2449
  %1931 = lshr i32 %1912, 31
  %1932 = xor i32 %1929, %1931
  %1933 = add nuw nsw i32 %1932, %1929
  %1934 = icmp eq i32 %1933, 2
  %1935 = zext i1 %1934 to i8
  store i8 %1935, i8* %41, align 1, !tbaa !2450
  %1936 = sext i32 %1913 to i64
  store i64 %1936, i64* %RDX, align 8, !tbaa !2428
  %1937 = shl nsw i64 %1936, 3
  %1938 = add i64 %1908, %1937
  %1939 = add i64 %1905, 18
  store i64 %1939, i64* %PC, align 8
  %1940 = inttoptr i64 %1938 to i64*
  %1941 = load i64, i64* %1940, align 8
  store i64 %1941, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1942 = add i64 %1905, 22
  store i64 %1942, i64* %PC, align 8
  %1943 = load i64, i64* %1907, align 8
  store i64 %1943, i64* %RCX, align 8, !tbaa !2428
  %1944 = add i64 %1903, -32
  %1945 = add i64 %1905, 25
  store i64 %1945, i64* %PC, align 8
  %1946 = inttoptr i64 %1944 to i32*
  %1947 = load i32, i32* %1946, align 4
  %1948 = add i32 %1947, 1
  %1949 = zext i32 %1948 to i64
  store i64 %1949, i64* %RAX, align 8, !tbaa !2428
  %1950 = icmp eq i32 %1947, -1
  %1951 = icmp eq i32 %1948, 0
  %1952 = or i1 %1950, %1951
  %1953 = zext i1 %1952 to i8
  store i8 %1953, i8* %16, align 1, !tbaa !2433
  %1954 = and i32 %1948, 255
  %1955 = tail call i32 @llvm.ctpop.i32(i32 %1954) #10
  %1956 = trunc i32 %1955 to i8
  %1957 = and i8 %1956, 1
  %1958 = xor i8 %1957, 1
  store i8 %1958, i8* %23, align 1, !tbaa !2447
  %1959 = xor i32 %1948, %1947
  %1960 = lshr i32 %1959, 4
  %1961 = trunc i32 %1960 to i8
  %1962 = and i8 %1961, 1
  store i8 %1962, i8* %29, align 1, !tbaa !2451
  %1963 = zext i1 %1951 to i8
  store i8 %1963, i8* %32, align 1, !tbaa !2448
  %1964 = lshr i32 %1948, 31
  %1965 = trunc i32 %1964 to i8
  store i8 %1965, i8* %35, align 1, !tbaa !2449
  %1966 = lshr i32 %1947, 31
  %1967 = xor i32 %1964, %1966
  %1968 = add nuw nsw i32 %1967, %1964
  %1969 = icmp eq i32 %1968, 2
  %1970 = zext i1 %1969 to i8
  store i8 %1970, i8* %41, align 1, !tbaa !2450
  %1971 = sext i32 %1948 to i64
  store i64 %1971, i64* %RDX, align 8, !tbaa !2428
  %1972 = shl nsw i64 %1971, 3
  %1973 = add i64 %1943, %1972
  %1974 = add i64 %1905, 36
  store i64 %1974, i64* %PC, align 8
  %1975 = bitcast i64 %1941 to double
  %1976 = inttoptr i64 %1973 to double*
  %1977 = load double, double* %1976, align 8
  %1978 = fsub double %1975, %1977
  store double %1978, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1979 = load i64, i64* %RBP, align 8
  %1980 = add i64 %1979, -144
  %1981 = add i64 %1905, 44
  store i64 %1981, i64* %PC, align 8
  %1982 = inttoptr i64 %1980 to double*
  store double %1978, double* %1982, align 8
  %1983 = load i64, i64* %RBP, align 8
  %1984 = add i64 %1983, -16
  %1985 = load i64, i64* %PC, align 8
  %1986 = add i64 %1985, 4
  store i64 %1986, i64* %PC, align 8
  %1987 = inttoptr i64 %1984 to i64*
  %1988 = load i64, i64* %1987, align 8
  store i64 %1988, i64* %RCX, align 8, !tbaa !2428
  %1989 = add i64 %1983, -36
  %1990 = add i64 %1985, 8
  store i64 %1990, i64* %PC, align 8
  %1991 = inttoptr i64 %1989 to i32*
  %1992 = load i32, i32* %1991, align 4
  %1993 = sext i32 %1992 to i64
  store i64 %1993, i64* %RDX, align 8, !tbaa !2428
  %1994 = shl nsw i64 %1993, 3
  %1995 = add i64 %1994, %1988
  %1996 = add i64 %1985, 13
  store i64 %1996, i64* %PC, align 8
  %1997 = inttoptr i64 %1995 to i64*
  %1998 = load i64, i64* %1997, align 8
  store i64 %1998, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1999 = add i64 %1985, 17
  store i64 %1999, i64* %PC, align 8
  %2000 = load i64, i64* %1987, align 8
  store i64 %2000, i64* %RCX, align 8, !tbaa !2428
  %2001 = add i64 %1983, -40
  %2002 = add i64 %1985, 21
  store i64 %2002, i64* %PC, align 8
  %2003 = inttoptr i64 %2001 to i32*
  %2004 = load i32, i32* %2003, align 4
  %2005 = sext i32 %2004 to i64
  store i64 %2005, i64* %RDX, align 8, !tbaa !2428
  %2006 = shl nsw i64 %2005, 3
  %2007 = add i64 %2006, %2000
  %2008 = add i64 %1985, 26
  store i64 %2008, i64* %PC, align 8
  %2009 = bitcast i64 %1998 to double
  %2010 = inttoptr i64 %2007 to double*
  %2011 = load double, double* %2010, align 8
  %2012 = fadd double %2009, %2011
  store double %2012, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2013 = add i64 %1983, -152
  %2014 = add i64 %1985, 34
  store i64 %2014, i64* %PC, align 8
  %2015 = inttoptr i64 %2013 to double*
  store double %2012, double* %2015, align 8
  %2016 = load i64, i64* %RBP, align 8
  %2017 = add i64 %2016, -16
  %2018 = load i64, i64* %PC, align 8
  %2019 = add i64 %2018, 4
  store i64 %2019, i64* %PC, align 8
  %2020 = inttoptr i64 %2017 to i64*
  %2021 = load i64, i64* %2020, align 8
  store i64 %2021, i64* %RCX, align 8, !tbaa !2428
  %2022 = add i64 %2016, -36
  %2023 = add i64 %2018, 7
  store i64 %2023, i64* %PC, align 8
  %2024 = inttoptr i64 %2022 to i32*
  %2025 = load i32, i32* %2024, align 4
  %2026 = add i32 %2025, 1
  %2027 = zext i32 %2026 to i64
  store i64 %2027, i64* %RAX, align 8, !tbaa !2428
  %2028 = icmp eq i32 %2025, -1
  %2029 = icmp eq i32 %2026, 0
  %2030 = or i1 %2028, %2029
  %2031 = zext i1 %2030 to i8
  store i8 %2031, i8* %16, align 1, !tbaa !2433
  %2032 = and i32 %2026, 255
  %2033 = tail call i32 @llvm.ctpop.i32(i32 %2032) #10
  %2034 = trunc i32 %2033 to i8
  %2035 = and i8 %2034, 1
  %2036 = xor i8 %2035, 1
  store i8 %2036, i8* %23, align 1, !tbaa !2447
  %2037 = xor i32 %2026, %2025
  %2038 = lshr i32 %2037, 4
  %2039 = trunc i32 %2038 to i8
  %2040 = and i8 %2039, 1
  store i8 %2040, i8* %29, align 1, !tbaa !2451
  %2041 = zext i1 %2029 to i8
  store i8 %2041, i8* %32, align 1, !tbaa !2448
  %2042 = lshr i32 %2026, 31
  %2043 = trunc i32 %2042 to i8
  store i8 %2043, i8* %35, align 1, !tbaa !2449
  %2044 = lshr i32 %2025, 31
  %2045 = xor i32 %2042, %2044
  %2046 = add nuw nsw i32 %2045, %2042
  %2047 = icmp eq i32 %2046, 2
  %2048 = zext i1 %2047 to i8
  store i8 %2048, i8* %41, align 1, !tbaa !2450
  %2049 = sext i32 %2026 to i64
  store i64 %2049, i64* %RDX, align 8, !tbaa !2428
  %2050 = shl nsw i64 %2049, 3
  %2051 = add i64 %2021, %2050
  %2052 = add i64 %2018, 18
  store i64 %2052, i64* %PC, align 8
  %2053 = inttoptr i64 %2051 to i64*
  %2054 = load i64, i64* %2053, align 8
  store i64 %2054, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2055 = add i64 %2018, 22
  store i64 %2055, i64* %PC, align 8
  %2056 = load i64, i64* %2020, align 8
  store i64 %2056, i64* %RCX, align 8, !tbaa !2428
  %2057 = add i64 %2016, -40
  %2058 = add i64 %2018, 25
  store i64 %2058, i64* %PC, align 8
  %2059 = inttoptr i64 %2057 to i32*
  %2060 = load i32, i32* %2059, align 4
  %2061 = add i32 %2060, 1
  %2062 = zext i32 %2061 to i64
  store i64 %2062, i64* %RAX, align 8, !tbaa !2428
  %2063 = icmp eq i32 %2060, -1
  %2064 = icmp eq i32 %2061, 0
  %2065 = or i1 %2063, %2064
  %2066 = zext i1 %2065 to i8
  store i8 %2066, i8* %16, align 1, !tbaa !2433
  %2067 = and i32 %2061, 255
  %2068 = tail call i32 @llvm.ctpop.i32(i32 %2067) #10
  %2069 = trunc i32 %2068 to i8
  %2070 = and i8 %2069, 1
  %2071 = xor i8 %2070, 1
  store i8 %2071, i8* %23, align 1, !tbaa !2447
  %2072 = xor i32 %2061, %2060
  %2073 = lshr i32 %2072, 4
  %2074 = trunc i32 %2073 to i8
  %2075 = and i8 %2074, 1
  store i8 %2075, i8* %29, align 1, !tbaa !2451
  %2076 = zext i1 %2064 to i8
  store i8 %2076, i8* %32, align 1, !tbaa !2448
  %2077 = lshr i32 %2061, 31
  %2078 = trunc i32 %2077 to i8
  store i8 %2078, i8* %35, align 1, !tbaa !2449
  %2079 = lshr i32 %2060, 31
  %2080 = xor i32 %2077, %2079
  %2081 = add nuw nsw i32 %2080, %2077
  %2082 = icmp eq i32 %2081, 2
  %2083 = zext i1 %2082 to i8
  store i8 %2083, i8* %41, align 1, !tbaa !2450
  %2084 = sext i32 %2061 to i64
  store i64 %2084, i64* %RDX, align 8, !tbaa !2428
  %2085 = shl nsw i64 %2084, 3
  %2086 = add i64 %2056, %2085
  %2087 = add i64 %2018, 36
  store i64 %2087, i64* %PC, align 8
  %2088 = bitcast i64 %2054 to double
  %2089 = inttoptr i64 %2086 to double*
  %2090 = load double, double* %2089, align 8
  %2091 = fadd double %2088, %2090
  store double %2091, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2092 = load i64, i64* %RBP, align 8
  %2093 = add i64 %2092, -160
  %2094 = add i64 %2018, 44
  store i64 %2094, i64* %PC, align 8
  %2095 = inttoptr i64 %2093 to double*
  store double %2091, double* %2095, align 8
  %2096 = load i64, i64* %RBP, align 8
  %2097 = add i64 %2096, -16
  %2098 = load i64, i64* %PC, align 8
  %2099 = add i64 %2098, 4
  store i64 %2099, i64* %PC, align 8
  %2100 = inttoptr i64 %2097 to i64*
  %2101 = load i64, i64* %2100, align 8
  store i64 %2101, i64* %RCX, align 8, !tbaa !2428
  %2102 = add i64 %2096, -36
  %2103 = add i64 %2098, 8
  store i64 %2103, i64* %PC, align 8
  %2104 = inttoptr i64 %2102 to i32*
  %2105 = load i32, i32* %2104, align 4
  %2106 = sext i32 %2105 to i64
  store i64 %2106, i64* %RDX, align 8, !tbaa !2428
  %2107 = shl nsw i64 %2106, 3
  %2108 = add i64 %2107, %2101
  %2109 = add i64 %2098, 13
  store i64 %2109, i64* %PC, align 8
  %2110 = inttoptr i64 %2108 to i64*
  %2111 = load i64, i64* %2110, align 8
  store i64 %2111, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2112 = add i64 %2098, 17
  store i64 %2112, i64* %PC, align 8
  %2113 = load i64, i64* %2100, align 8
  store i64 %2113, i64* %RCX, align 8, !tbaa !2428
  %2114 = add i64 %2096, -40
  %2115 = add i64 %2098, 21
  store i64 %2115, i64* %PC, align 8
  %2116 = inttoptr i64 %2114 to i32*
  %2117 = load i32, i32* %2116, align 4
  %2118 = sext i32 %2117 to i64
  store i64 %2118, i64* %RDX, align 8, !tbaa !2428
  %2119 = shl nsw i64 %2118, 3
  %2120 = add i64 %2119, %2113
  %2121 = add i64 %2098, 26
  store i64 %2121, i64* %PC, align 8
  %2122 = bitcast i64 %2111 to double
  %2123 = inttoptr i64 %2120 to double*
  %2124 = load double, double* %2123, align 8
  %2125 = fsub double %2122, %2124
  store double %2125, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2126 = add i64 %2096, -168
  %2127 = add i64 %2098, 34
  store i64 %2127, i64* %PC, align 8
  %2128 = inttoptr i64 %2126 to double*
  store double %2125, double* %2128, align 8
  %2129 = load i64, i64* %RBP, align 8
  %2130 = add i64 %2129, -16
  %2131 = load i64, i64* %PC, align 8
  %2132 = add i64 %2131, 4
  store i64 %2132, i64* %PC, align 8
  %2133 = inttoptr i64 %2130 to i64*
  %2134 = load i64, i64* %2133, align 8
  store i64 %2134, i64* %RCX, align 8, !tbaa !2428
  %2135 = add i64 %2129, -36
  %2136 = add i64 %2131, 7
  store i64 %2136, i64* %PC, align 8
  %2137 = inttoptr i64 %2135 to i32*
  %2138 = load i32, i32* %2137, align 4
  %2139 = add i32 %2138, 1
  %2140 = zext i32 %2139 to i64
  store i64 %2140, i64* %RAX, align 8, !tbaa !2428
  %2141 = icmp eq i32 %2138, -1
  %2142 = icmp eq i32 %2139, 0
  %2143 = or i1 %2141, %2142
  %2144 = zext i1 %2143 to i8
  store i8 %2144, i8* %16, align 1, !tbaa !2433
  %2145 = and i32 %2139, 255
  %2146 = tail call i32 @llvm.ctpop.i32(i32 %2145) #10
  %2147 = trunc i32 %2146 to i8
  %2148 = and i8 %2147, 1
  %2149 = xor i8 %2148, 1
  store i8 %2149, i8* %23, align 1, !tbaa !2447
  %2150 = xor i32 %2139, %2138
  %2151 = lshr i32 %2150, 4
  %2152 = trunc i32 %2151 to i8
  %2153 = and i8 %2152, 1
  store i8 %2153, i8* %29, align 1, !tbaa !2451
  %2154 = zext i1 %2142 to i8
  store i8 %2154, i8* %32, align 1, !tbaa !2448
  %2155 = lshr i32 %2139, 31
  %2156 = trunc i32 %2155 to i8
  store i8 %2156, i8* %35, align 1, !tbaa !2449
  %2157 = lshr i32 %2138, 31
  %2158 = xor i32 %2155, %2157
  %2159 = add nuw nsw i32 %2158, %2155
  %2160 = icmp eq i32 %2159, 2
  %2161 = zext i1 %2160 to i8
  store i8 %2161, i8* %41, align 1, !tbaa !2450
  %2162 = sext i32 %2139 to i64
  store i64 %2162, i64* %RDX, align 8, !tbaa !2428
  %2163 = shl nsw i64 %2162, 3
  %2164 = add i64 %2134, %2163
  %2165 = add i64 %2131, 18
  store i64 %2165, i64* %PC, align 8
  %2166 = inttoptr i64 %2164 to i64*
  %2167 = load i64, i64* %2166, align 8
  store i64 %2167, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2168 = add i64 %2131, 22
  store i64 %2168, i64* %PC, align 8
  %2169 = load i64, i64* %2133, align 8
  store i64 %2169, i64* %RCX, align 8, !tbaa !2428
  %2170 = add i64 %2129, -40
  %2171 = add i64 %2131, 25
  store i64 %2171, i64* %PC, align 8
  %2172 = inttoptr i64 %2170 to i32*
  %2173 = load i32, i32* %2172, align 4
  %2174 = add i32 %2173, 1
  %2175 = zext i32 %2174 to i64
  store i64 %2175, i64* %RAX, align 8, !tbaa !2428
  %2176 = icmp eq i32 %2173, -1
  %2177 = icmp eq i32 %2174, 0
  %2178 = or i1 %2176, %2177
  %2179 = zext i1 %2178 to i8
  store i8 %2179, i8* %16, align 1, !tbaa !2433
  %2180 = and i32 %2174, 255
  %2181 = tail call i32 @llvm.ctpop.i32(i32 %2180) #10
  %2182 = trunc i32 %2181 to i8
  %2183 = and i8 %2182, 1
  %2184 = xor i8 %2183, 1
  store i8 %2184, i8* %23, align 1, !tbaa !2447
  %2185 = xor i32 %2174, %2173
  %2186 = lshr i32 %2185, 4
  %2187 = trunc i32 %2186 to i8
  %2188 = and i8 %2187, 1
  store i8 %2188, i8* %29, align 1, !tbaa !2451
  %2189 = zext i1 %2177 to i8
  store i8 %2189, i8* %32, align 1, !tbaa !2448
  %2190 = lshr i32 %2174, 31
  %2191 = trunc i32 %2190 to i8
  store i8 %2191, i8* %35, align 1, !tbaa !2449
  %2192 = lshr i32 %2173, 31
  %2193 = xor i32 %2190, %2192
  %2194 = add nuw nsw i32 %2193, %2190
  %2195 = icmp eq i32 %2194, 2
  %2196 = zext i1 %2195 to i8
  store i8 %2196, i8* %41, align 1, !tbaa !2450
  %2197 = sext i32 %2174 to i64
  store i64 %2197, i64* %RDX, align 8, !tbaa !2428
  %2198 = shl nsw i64 %2197, 3
  %2199 = add i64 %2169, %2198
  %2200 = add i64 %2131, 36
  store i64 %2200, i64* %PC, align 8
  %2201 = bitcast i64 %2167 to double
  %2202 = inttoptr i64 %2199 to double*
  %2203 = load double, double* %2202, align 8
  %2204 = fsub double %2201, %2203
  store double %2204, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2205 = load i64, i64* %RBP, align 8
  %2206 = add i64 %2205, -176
  %2207 = add i64 %2131, 44
  store i64 %2207, i64* %PC, align 8
  %2208 = inttoptr i64 %2206 to double*
  store double %2204, double* %2208, align 8
  %2209 = load i64, i64* %RBP, align 8
  %2210 = add i64 %2209, -120
  %2211 = load i64, i64* %PC, align 8
  %2212 = add i64 %2211, 5
  store i64 %2212, i64* %PC, align 8
  %2213 = inttoptr i64 %2210 to i64*
  %2214 = load i64, i64* %2213, align 8
  store i64 %2214, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2215 = add i64 %2209, -152
  %2216 = add i64 %2211, 13
  store i64 %2216, i64* %PC, align 8
  %2217 = bitcast i64 %2214 to double
  %2218 = inttoptr i64 %2215 to double*
  %2219 = load double, double* %2218, align 8
  %2220 = fadd double %2217, %2219
  store double %2220, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2221 = add i64 %2209, -16
  %2222 = add i64 %2211, 17
  store i64 %2222, i64* %PC, align 8
  %2223 = inttoptr i64 %2221 to i64*
  %2224 = load i64, i64* %2223, align 8
  store i64 %2224, i64* %RCX, align 8, !tbaa !2428
  %2225 = add i64 %2209, -28
  %2226 = add i64 %2211, 21
  store i64 %2226, i64* %PC, align 8
  %2227 = inttoptr i64 %2225 to i32*
  %2228 = load i32, i32* %2227, align 4
  %2229 = sext i32 %2228 to i64
  store i64 %2229, i64* %RDX, align 8, !tbaa !2428
  %2230 = shl nsw i64 %2229, 3
  %2231 = add i64 %2230, %2224
  %2232 = add i64 %2211, 26
  store i64 %2232, i64* %PC, align 8
  %2233 = inttoptr i64 %2231 to double*
  store double %2220, double* %2233, align 8
  %2234 = load i64, i64* %RBP, align 8
  %2235 = add i64 %2234, -128
  %2236 = load i64, i64* %PC, align 8
  %2237 = add i64 %2236, 5
  store i64 %2237, i64* %PC, align 8
  %2238 = inttoptr i64 %2235 to i64*
  %2239 = load i64, i64* %2238, align 8
  store i64 %2239, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2240 = add i64 %2234, -160
  %2241 = add i64 %2236, 13
  store i64 %2241, i64* %PC, align 8
  %2242 = bitcast i64 %2239 to double
  %2243 = inttoptr i64 %2240 to double*
  %2244 = load double, double* %2243, align 8
  %2245 = fadd double %2242, %2244
  store double %2245, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2246 = add i64 %2234, -16
  %2247 = add i64 %2236, 17
  store i64 %2247, i64* %PC, align 8
  %2248 = inttoptr i64 %2246 to i64*
  %2249 = load i64, i64* %2248, align 8
  store i64 %2249, i64* %RCX, align 8, !tbaa !2428
  %2250 = add i64 %2234, -28
  %2251 = add i64 %2236, 20
  store i64 %2251, i64* %PC, align 8
  %2252 = inttoptr i64 %2250 to i32*
  %2253 = load i32, i32* %2252, align 4
  %2254 = add i32 %2253, 1
  %2255 = zext i32 %2254 to i64
  store i64 %2255, i64* %RAX, align 8, !tbaa !2428
  %2256 = icmp eq i32 %2253, -1
  %2257 = icmp eq i32 %2254, 0
  %2258 = or i1 %2256, %2257
  %2259 = zext i1 %2258 to i8
  store i8 %2259, i8* %16, align 1, !tbaa !2433
  %2260 = and i32 %2254, 255
  %2261 = tail call i32 @llvm.ctpop.i32(i32 %2260) #10
  %2262 = trunc i32 %2261 to i8
  %2263 = and i8 %2262, 1
  %2264 = xor i8 %2263, 1
  store i8 %2264, i8* %23, align 1, !tbaa !2447
  %2265 = xor i32 %2254, %2253
  %2266 = lshr i32 %2265, 4
  %2267 = trunc i32 %2266 to i8
  %2268 = and i8 %2267, 1
  store i8 %2268, i8* %29, align 1, !tbaa !2451
  %2269 = zext i1 %2257 to i8
  store i8 %2269, i8* %32, align 1, !tbaa !2448
  %2270 = lshr i32 %2254, 31
  %2271 = trunc i32 %2270 to i8
  store i8 %2271, i8* %35, align 1, !tbaa !2449
  %2272 = lshr i32 %2253, 31
  %2273 = xor i32 %2270, %2272
  %2274 = add nuw nsw i32 %2273, %2270
  %2275 = icmp eq i32 %2274, 2
  %2276 = zext i1 %2275 to i8
  store i8 %2276, i8* %41, align 1, !tbaa !2450
  %2277 = sext i32 %2254 to i64
  store i64 %2277, i64* %RDX, align 8, !tbaa !2428
  %2278 = shl nsw i64 %2277, 3
  %2279 = add i64 %2249, %2278
  %2280 = add i64 %2236, 31
  store i64 %2280, i64* %PC, align 8
  %2281 = inttoptr i64 %2279 to double*
  store double %2245, double* %2281, align 8
  %2282 = load i64, i64* %RBP, align 8
  %2283 = add i64 %2282, -160
  %2284 = load i64, i64* %PC, align 8
  %2285 = add i64 %2284, 8
  store i64 %2285, i64* %PC, align 8
  %2286 = inttoptr i64 %2283 to i64*
  %2287 = load i64, i64* %2286, align 8
  store i64 %2287, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2288 = add i64 %2282, -128
  %2289 = add i64 %2284, 13
  store i64 %2289, i64* %PC, align 8
  %2290 = bitcast i64 %2287 to double
  %2291 = inttoptr i64 %2288 to double*
  %2292 = load double, double* %2291, align 8
  %2293 = fsub double %2290, %2292
  store double %2293, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2294 = add i64 %2282, -16
  %2295 = add i64 %2284, 17
  store i64 %2295, i64* %PC, align 8
  %2296 = inttoptr i64 %2294 to i64*
  %2297 = load i64, i64* %2296, align 8
  store i64 %2297, i64* %RCX, align 8, !tbaa !2428
  %2298 = add i64 %2282, -36
  %2299 = add i64 %2284, 21
  store i64 %2299, i64* %PC, align 8
  %2300 = inttoptr i64 %2298 to i32*
  %2301 = load i32, i32* %2300, align 4
  %2302 = sext i32 %2301 to i64
  store i64 %2302, i64* %RDX, align 8, !tbaa !2428
  %2303 = shl nsw i64 %2302, 3
  %2304 = add i64 %2303, %2297
  %2305 = add i64 %2284, 26
  store i64 %2305, i64* %PC, align 8
  %2306 = inttoptr i64 %2304 to double*
  store double %2293, double* %2306, align 8
  %2307 = load i64, i64* %RBP, align 8
  %2308 = add i64 %2307, -120
  %2309 = load i64, i64* %PC, align 8
  %2310 = add i64 %2309, 5
  store i64 %2310, i64* %PC, align 8
  %2311 = inttoptr i64 %2308 to i64*
  %2312 = load i64, i64* %2311, align 8
  store i64 %2312, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2313 = add i64 %2307, -152
  %2314 = add i64 %2309, 13
  store i64 %2314, i64* %PC, align 8
  %2315 = bitcast i64 %2312 to double
  %2316 = inttoptr i64 %2313 to double*
  %2317 = load double, double* %2316, align 8
  %2318 = fsub double %2315, %2317
  store double %2318, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2319 = add i64 %2307, -16
  %2320 = add i64 %2309, 17
  store i64 %2320, i64* %PC, align 8
  %2321 = inttoptr i64 %2319 to i64*
  %2322 = load i64, i64* %2321, align 8
  store i64 %2322, i64* %RCX, align 8, !tbaa !2428
  %2323 = add i64 %2307, -36
  %2324 = add i64 %2309, 20
  store i64 %2324, i64* %PC, align 8
  %2325 = inttoptr i64 %2323 to i32*
  %2326 = load i32, i32* %2325, align 4
  %2327 = add i32 %2326, 1
  %2328 = zext i32 %2327 to i64
  store i64 %2328, i64* %RAX, align 8, !tbaa !2428
  %2329 = icmp eq i32 %2326, -1
  %2330 = icmp eq i32 %2327, 0
  %2331 = or i1 %2329, %2330
  %2332 = zext i1 %2331 to i8
  store i8 %2332, i8* %16, align 1, !tbaa !2433
  %2333 = and i32 %2327, 255
  %2334 = tail call i32 @llvm.ctpop.i32(i32 %2333) #10
  %2335 = trunc i32 %2334 to i8
  %2336 = and i8 %2335, 1
  %2337 = xor i8 %2336, 1
  store i8 %2337, i8* %23, align 1, !tbaa !2447
  %2338 = xor i32 %2327, %2326
  %2339 = lshr i32 %2338, 4
  %2340 = trunc i32 %2339 to i8
  %2341 = and i8 %2340, 1
  store i8 %2341, i8* %29, align 1, !tbaa !2451
  %2342 = zext i1 %2330 to i8
  store i8 %2342, i8* %32, align 1, !tbaa !2448
  %2343 = lshr i32 %2327, 31
  %2344 = trunc i32 %2343 to i8
  store i8 %2344, i8* %35, align 1, !tbaa !2449
  %2345 = lshr i32 %2326, 31
  %2346 = xor i32 %2343, %2345
  %2347 = add nuw nsw i32 %2346, %2343
  %2348 = icmp eq i32 %2347, 2
  %2349 = zext i1 %2348 to i8
  store i8 %2349, i8* %41, align 1, !tbaa !2450
  %2350 = sext i32 %2327 to i64
  store i64 %2350, i64* %RDX, align 8, !tbaa !2428
  %2351 = shl nsw i64 %2350, 3
  %2352 = add i64 %2322, %2351
  %2353 = add i64 %2309, 31
  store i64 %2353, i64* %PC, align 8
  %2354 = inttoptr i64 %2352 to double*
  store double %2318, double* %2354, align 8
  %2355 = load i64, i64* %RBP, align 8
  %2356 = add i64 %2355, -136
  %2357 = load i64, i64* %PC, align 8
  %2358 = add i64 %2357, 8
  store i64 %2358, i64* %PC, align 8
  %2359 = inttoptr i64 %2356 to i64*
  %2360 = load i64, i64* %2359, align 8
  store i64 %2360, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2361 = add i64 %2355, -176
  %2362 = add i64 %2357, 16
  store i64 %2362, i64* %PC, align 8
  %2363 = bitcast i64 %2360 to double
  %2364 = inttoptr i64 %2361 to double*
  %2365 = load double, double* %2364, align 8
  %2366 = fsub double %2363, %2365
  store double %2366, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2367 = add i64 %2355, -120
  %2368 = add i64 %2357, 21
  store i64 %2368, i64* %PC, align 8
  %2369 = inttoptr i64 %2367 to double*
  store double %2366, double* %2369, align 8
  %2370 = load i64, i64* %RBP, align 8
  %2371 = add i64 %2370, -144
  %2372 = load i64, i64* %PC, align 8
  %2373 = add i64 %2372, 8
  store i64 %2373, i64* %PC, align 8
  %2374 = inttoptr i64 %2371 to i64*
  %2375 = load i64, i64* %2374, align 8
  store i64 %2375, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2376 = add i64 %2370, -168
  %2377 = add i64 %2372, 16
  store i64 %2377, i64* %PC, align 8
  %2378 = bitcast i64 %2375 to double
  %2379 = inttoptr i64 %2376 to double*
  %2380 = load double, double* %2379, align 8
  %2381 = fadd double %2378, %2380
  store double %2381, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2382 = add i64 %2370, -128
  %2383 = add i64 %2372, 21
  store i64 %2383, i64* %PC, align 8
  %2384 = inttoptr i64 %2382 to double*
  store double %2381, double* %2384, align 8
  %2385 = load i64, i64* %RBP, align 8
  %2386 = add i64 %2385, -72
  %2387 = load i64, i64* %PC, align 8
  %2388 = add i64 %2387, 5
  store i64 %2388, i64* %PC, align 8
  %2389 = inttoptr i64 %2386 to i64*
  %2390 = load i64, i64* %2389, align 8
  store i64 %2390, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2391 = add i64 %2385, -120
  %2392 = add i64 %2387, 10
  store i64 %2392, i64* %PC, align 8
  %2393 = inttoptr i64 %2391 to i64*
  %2394 = load i64, i64* %2393, align 8
  store i64 %2394, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %2395 = add i64 %2385, -128
  %2396 = add i64 %2387, 15
  store i64 %2396, i64* %PC, align 8
  %2397 = bitcast i64 %2394 to double
  %2398 = inttoptr i64 %2395 to double*
  %2399 = load double, double* %2398, align 8
  %2400 = fsub double %2397, %2399
  store double %2400, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %2401 = bitcast i64 %2390 to double
  %2402 = fmul double %2401, %2400
  store double %2402, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2403 = add i64 %2385, -16
  %2404 = add i64 %2387, 23
  store i64 %2404, i64* %PC, align 8
  %2405 = inttoptr i64 %2403 to i64*
  %2406 = load i64, i64* %2405, align 8
  store i64 %2406, i64* %RCX, align 8, !tbaa !2428
  %2407 = add i64 %2385, -32
  %2408 = add i64 %2387, 27
  store i64 %2408, i64* %PC, align 8
  %2409 = inttoptr i64 %2407 to i32*
  %2410 = load i32, i32* %2409, align 4
  %2411 = sext i32 %2410 to i64
  store i64 %2411, i64* %RDX, align 8, !tbaa !2428
  %2412 = shl nsw i64 %2411, 3
  %2413 = add i64 %2412, %2406
  %2414 = add i64 %2387, 32
  store i64 %2414, i64* %PC, align 8
  %2415 = inttoptr i64 %2413 to double*
  store double %2402, double* %2415, align 8
  %2416 = load i64, i64* %RBP, align 8
  %2417 = add i64 %2416, -72
  %2418 = load i64, i64* %PC, align 8
  %2419 = add i64 %2418, 5
  store i64 %2419, i64* %PC, align 8
  %2420 = inttoptr i64 %2417 to i64*
  %2421 = load i64, i64* %2420, align 8
  store i64 %2421, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2422 = add i64 %2416, -120
  %2423 = add i64 %2418, 10
  store i64 %2423, i64* %PC, align 8
  %2424 = inttoptr i64 %2422 to i64*
  %2425 = load i64, i64* %2424, align 8
  store i64 %2425, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %2426 = add i64 %2416, -128
  %2427 = add i64 %2418, 15
  store i64 %2427, i64* %PC, align 8
  %2428 = bitcast i64 %2425 to double
  %2429 = inttoptr i64 %2426 to double*
  %2430 = load double, double* %2429, align 8
  %2431 = fadd double %2428, %2430
  store double %2431, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %2432 = bitcast i64 %2421 to double
  %2433 = fmul double %2432, %2431
  store double %2433, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2434 = add i64 %2416, -16
  %2435 = add i64 %2418, 23
  store i64 %2435, i64* %PC, align 8
  %2436 = inttoptr i64 %2434 to i64*
  %2437 = load i64, i64* %2436, align 8
  store i64 %2437, i64* %RCX, align 8, !tbaa !2428
  %2438 = add i64 %2416, -32
  %2439 = add i64 %2418, 26
  store i64 %2439, i64* %PC, align 8
  %2440 = inttoptr i64 %2438 to i32*
  %2441 = load i32, i32* %2440, align 4
  %2442 = add i32 %2441, 1
  %2443 = zext i32 %2442 to i64
  store i64 %2443, i64* %RAX, align 8, !tbaa !2428
  %2444 = icmp eq i32 %2441, -1
  %2445 = icmp eq i32 %2442, 0
  %2446 = or i1 %2444, %2445
  %2447 = zext i1 %2446 to i8
  store i8 %2447, i8* %16, align 1, !tbaa !2433
  %2448 = and i32 %2442, 255
  %2449 = tail call i32 @llvm.ctpop.i32(i32 %2448) #10
  %2450 = trunc i32 %2449 to i8
  %2451 = and i8 %2450, 1
  %2452 = xor i8 %2451, 1
  store i8 %2452, i8* %23, align 1, !tbaa !2447
  %2453 = xor i32 %2442, %2441
  %2454 = lshr i32 %2453, 4
  %2455 = trunc i32 %2454 to i8
  %2456 = and i8 %2455, 1
  store i8 %2456, i8* %29, align 1, !tbaa !2451
  %2457 = zext i1 %2445 to i8
  store i8 %2457, i8* %32, align 1, !tbaa !2448
  %2458 = lshr i32 %2442, 31
  %2459 = trunc i32 %2458 to i8
  store i8 %2459, i8* %35, align 1, !tbaa !2449
  %2460 = lshr i32 %2441, 31
  %2461 = xor i32 %2458, %2460
  %2462 = add nuw nsw i32 %2461, %2458
  %2463 = icmp eq i32 %2462, 2
  %2464 = zext i1 %2463 to i8
  store i8 %2464, i8* %41, align 1, !tbaa !2450
  %2465 = sext i32 %2442 to i64
  store i64 %2465, i64* %RDX, align 8, !tbaa !2428
  %2466 = shl nsw i64 %2465, 3
  %2467 = add i64 %2437, %2466
  %2468 = add i64 %2418, 37
  store i64 %2468, i64* %PC, align 8
  %2469 = inttoptr i64 %2467 to double*
  store double %2433, double* %2469, align 8
  %2470 = load i64, i64* %RBP, align 8
  %2471 = add i64 %2470, -176
  %2472 = load i64, i64* %PC, align 8
  %2473 = add i64 %2472, 8
  store i64 %2473, i64* %PC, align 8
  %2474 = inttoptr i64 %2471 to i64*
  %2475 = load i64, i64* %2474, align 8
  store i64 %2475, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2476 = add i64 %2470, -136
  %2477 = add i64 %2472, 16
  store i64 %2477, i64* %PC, align 8
  %2478 = bitcast i64 %2475 to double
  %2479 = inttoptr i64 %2476 to double*
  %2480 = load double, double* %2479, align 8
  %2481 = fadd double %2478, %2480
  store double %2481, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2482 = add i64 %2470, -120
  %2483 = add i64 %2472, 21
  store i64 %2483, i64* %PC, align 8
  %2484 = inttoptr i64 %2482 to double*
  store double %2481, double* %2484, align 8
  %2485 = load i64, i64* %RBP, align 8
  %2486 = add i64 %2485, -168
  %2487 = load i64, i64* %PC, align 8
  %2488 = add i64 %2487, 8
  store i64 %2488, i64* %PC, align 8
  %2489 = inttoptr i64 %2486 to i64*
  %2490 = load i64, i64* %2489, align 8
  store i64 %2490, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2491 = add i64 %2485, -144
  %2492 = add i64 %2487, 16
  store i64 %2492, i64* %PC, align 8
  %2493 = bitcast i64 %2490 to double
  %2494 = inttoptr i64 %2491 to double*
  %2495 = load double, double* %2494, align 8
  %2496 = fsub double %2493, %2495
  store double %2496, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2497 = add i64 %2485, -128
  %2498 = add i64 %2487, 21
  store i64 %2498, i64* %PC, align 8
  %2499 = inttoptr i64 %2497 to double*
  store double %2496, double* %2499, align 8
  %2500 = load i64, i64* %RBP, align 8
  %2501 = add i64 %2500, -72
  %2502 = load i64, i64* %PC, align 8
  %2503 = add i64 %2502, 5
  store i64 %2503, i64* %PC, align 8
  %2504 = inttoptr i64 %2501 to i64*
  %2505 = load i64, i64* %2504, align 8
  store i64 %2505, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2506 = add i64 %2500, -128
  %2507 = add i64 %2502, 10
  store i64 %2507, i64* %PC, align 8
  %2508 = inttoptr i64 %2506 to i64*
  %2509 = load i64, i64* %2508, align 8
  store i64 %2509, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %2510 = add i64 %2500, -120
  %2511 = add i64 %2502, 15
  store i64 %2511, i64* %PC, align 8
  %2512 = bitcast i64 %2509 to double
  %2513 = inttoptr i64 %2510 to double*
  %2514 = load double, double* %2513, align 8
  %2515 = fsub double %2512, %2514
  store double %2515, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %2516 = bitcast i64 %2505 to double
  %2517 = fmul double %2516, %2515
  store double %2517, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2518 = add i64 %2500, -16
  %2519 = add i64 %2502, 23
  store i64 %2519, i64* %PC, align 8
  %2520 = inttoptr i64 %2518 to i64*
  %2521 = load i64, i64* %2520, align 8
  store i64 %2521, i64* %RCX, align 8, !tbaa !2428
  %2522 = add i64 %2500, -40
  %2523 = add i64 %2502, 27
  store i64 %2523, i64* %PC, align 8
  %2524 = inttoptr i64 %2522 to i32*
  %2525 = load i32, i32* %2524, align 4
  %2526 = sext i32 %2525 to i64
  store i64 %2526, i64* %RDX, align 8, !tbaa !2428
  %2527 = shl nsw i64 %2526, 3
  %2528 = add i64 %2527, %2521
  %2529 = add i64 %2502, 32
  store i64 %2529, i64* %PC, align 8
  %2530 = inttoptr i64 %2528 to double*
  store double %2517, double* %2530, align 8
  %2531 = load i64, i64* %RBP, align 8
  %2532 = add i64 %2531, -72
  %2533 = load i64, i64* %PC, align 8
  %2534 = add i64 %2533, 5
  store i64 %2534, i64* %PC, align 8
  %2535 = inttoptr i64 %2532 to i64*
  %2536 = load i64, i64* %2535, align 8
  store i64 %2536, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2537 = add i64 %2531, -128
  %2538 = add i64 %2533, 10
  store i64 %2538, i64* %PC, align 8
  %2539 = inttoptr i64 %2537 to i64*
  %2540 = load i64, i64* %2539, align 8
  store i64 %2540, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %2541 = add i64 %2531, -120
  %2542 = add i64 %2533, 15
  store i64 %2542, i64* %PC, align 8
  %2543 = bitcast i64 %2540 to double
  %2544 = inttoptr i64 %2541 to double*
  %2545 = load double, double* %2544, align 8
  %2546 = fadd double %2543, %2545
  store double %2546, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %2547 = bitcast i64 %2536 to double
  %2548 = fmul double %2547, %2546
  store double %2548, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2549 = add i64 %2531, -16
  %2550 = add i64 %2533, 23
  store i64 %2550, i64* %PC, align 8
  %2551 = inttoptr i64 %2549 to i64*
  %2552 = load i64, i64* %2551, align 8
  store i64 %2552, i64* %RCX, align 8, !tbaa !2428
  %2553 = add i64 %2531, -40
  %2554 = add i64 %2533, 26
  store i64 %2554, i64* %PC, align 8
  %2555 = inttoptr i64 %2553 to i32*
  %2556 = load i32, i32* %2555, align 4
  %2557 = add i32 %2556, 1
  %2558 = zext i32 %2557 to i64
  store i64 %2558, i64* %RAX, align 8, !tbaa !2428
  %2559 = icmp eq i32 %2556, -1
  %2560 = icmp eq i32 %2557, 0
  %2561 = or i1 %2559, %2560
  %2562 = zext i1 %2561 to i8
  store i8 %2562, i8* %16, align 1, !tbaa !2433
  %2563 = and i32 %2557, 255
  %2564 = tail call i32 @llvm.ctpop.i32(i32 %2563) #10
  %2565 = trunc i32 %2564 to i8
  %2566 = and i8 %2565, 1
  %2567 = xor i8 %2566, 1
  store i8 %2567, i8* %23, align 1, !tbaa !2447
  %2568 = xor i32 %2557, %2556
  %2569 = lshr i32 %2568, 4
  %2570 = trunc i32 %2569 to i8
  %2571 = and i8 %2570, 1
  store i8 %2571, i8* %29, align 1, !tbaa !2451
  %2572 = zext i1 %2560 to i8
  store i8 %2572, i8* %32, align 1, !tbaa !2448
  %2573 = lshr i32 %2557, 31
  %2574 = trunc i32 %2573 to i8
  store i8 %2574, i8* %35, align 1, !tbaa !2449
  %2575 = lshr i32 %2556, 31
  %2576 = xor i32 %2573, %2575
  %2577 = add nuw nsw i32 %2576, %2573
  %2578 = icmp eq i32 %2577, 2
  %2579 = zext i1 %2578 to i8
  store i8 %2579, i8* %41, align 1, !tbaa !2450
  %2580 = sext i32 %2557 to i64
  store i64 %2580, i64* %RDX, align 8, !tbaa !2428
  %2581 = shl nsw i64 %2580, 3
  %2582 = add i64 %2552, %2581
  %2583 = add i64 %2533, 37
  store i64 %2583, i64* %PC, align 8
  %2584 = inttoptr i64 %2582 to double*
  store double %2548, double* %2584, align 8
  %2585 = load i64, i64* %RBP, align 8
  %2586 = add i64 %2585, -28
  %2587 = load i64, i64* %PC, align 8
  %2588 = add i64 %2587, 3
  store i64 %2588, i64* %PC, align 8
  %2589 = inttoptr i64 %2586 to i32*
  %2590 = load i32, i32* %2589, align 4
  %2591 = add i32 %2590, 2
  %2592 = zext i32 %2591 to i64
  store i64 %2592, i64* %RAX, align 8, !tbaa !2428
  %2593 = icmp ugt i32 %2590, -3
  %2594 = zext i1 %2593 to i8
  store i8 %2594, i8* %16, align 1, !tbaa !2433
  %2595 = and i32 %2591, 255
  %2596 = tail call i32 @llvm.ctpop.i32(i32 %2595) #10
  %2597 = trunc i32 %2596 to i8
  %2598 = and i8 %2597, 1
  %2599 = xor i8 %2598, 1
  store i8 %2599, i8* %23, align 1, !tbaa !2447
  %2600 = xor i32 %2591, %2590
  %2601 = lshr i32 %2600, 4
  %2602 = trunc i32 %2601 to i8
  %2603 = and i8 %2602, 1
  store i8 %2603, i8* %29, align 1, !tbaa !2451
  %2604 = icmp eq i32 %2591, 0
  %2605 = zext i1 %2604 to i8
  store i8 %2605, i8* %32, align 1, !tbaa !2448
  %2606 = lshr i32 %2591, 31
  %2607 = trunc i32 %2606 to i8
  store i8 %2607, i8* %35, align 1, !tbaa !2449
  %2608 = lshr i32 %2590, 31
  %2609 = xor i32 %2606, %2608
  %2610 = add nuw nsw i32 %2609, %2606
  %2611 = icmp eq i32 %2610, 2
  %2612 = zext i1 %2611 to i8
  store i8 %2612, i8* %41, align 1, !tbaa !2450
  %2613 = add i64 %2587, 9
  store i64 %2613, i64* %PC, align 8
  store i32 %2591, i32* %2589, align 4
  %2614 = load i64, i64* %PC, align 8
  %2615 = add i64 %2614, -695
  store i64 %2615, i64* %PC, align 8, !tbaa !2428
  br label %block_4035b1

block_4035b1:                                     ; preds = %block_4035c2, %block_40359d
  %2616 = phi i64 [ %2615, %block_4035c2 ], [ %.pre23, %block_40359d ]
  %2617 = load i64, i64* %RBP, align 8
  %2618 = add i64 %2617, -28
  %2619 = add i64 %2616, 3
  store i64 %2619, i64* %PC, align 8
  %2620 = inttoptr i64 %2618 to i32*
  %2621 = load i32, i32* %2620, align 4
  %2622 = zext i32 %2621 to i64
  store i64 %2622, i64* %RAX, align 8, !tbaa !2428
  %2623 = add i64 %2617, -8
  %2624 = add i64 %2616, 6
  store i64 %2624, i64* %PC, align 8
  %2625 = inttoptr i64 %2623 to i32*
  %2626 = load i32, i32* %2625, align 4
  %2627 = zext i32 %2626 to i64
  store i64 %2627, i64* %RCX, align 8, !tbaa !2428
  %2628 = add i64 %2617, -56
  %2629 = add i64 %2616, 9
  store i64 %2629, i64* %PC, align 8
  %2630 = inttoptr i64 %2628 to i32*
  %2631 = load i32, i32* %2630, align 4
  %2632 = add i32 %2631, %2626
  %2633 = zext i32 %2632 to i64
  store i64 %2633, i64* %RCX, align 8, !tbaa !2428
  %2634 = lshr i32 %2632, 31
  %2635 = sub i32 %2621, %2632
  %2636 = icmp ult i32 %2621, %2632
  %2637 = zext i1 %2636 to i8
  store i8 %2637, i8* %16, align 1, !tbaa !2433
  %2638 = and i32 %2635, 255
  %2639 = tail call i32 @llvm.ctpop.i32(i32 %2638) #10
  %2640 = trunc i32 %2639 to i8
  %2641 = and i8 %2640, 1
  %2642 = xor i8 %2641, 1
  store i8 %2642, i8* %23, align 1, !tbaa !2447
  %2643 = xor i32 %2632, %2621
  %2644 = xor i32 %2643, %2635
  %2645 = lshr i32 %2644, 4
  %2646 = trunc i32 %2645 to i8
  %2647 = and i8 %2646, 1
  store i8 %2647, i8* %29, align 1, !tbaa !2451
  %2648 = icmp eq i32 %2635, 0
  %2649 = zext i1 %2648 to i8
  store i8 %2649, i8* %32, align 1, !tbaa !2448
  %2650 = lshr i32 %2635, 31
  %2651 = trunc i32 %2650 to i8
  store i8 %2651, i8* %35, align 1, !tbaa !2449
  %2652 = lshr i32 %2621, 31
  %2653 = xor i32 %2634, %2652
  %2654 = xor i32 %2650, %2652
  %2655 = add nuw nsw i32 %2654, %2653
  %2656 = icmp eq i32 %2655, 2
  %2657 = zext i1 %2656 to i8
  store i8 %2657, i8* %41, align 1, !tbaa !2450
  %2658 = icmp ne i8 %2651, 0
  %2659 = xor i1 %2658, %2656
  %.v27 = select i1 %2659, i64 17, i64 700
  %2660 = add i64 %2616, %.v27
  store i64 %2660, i64* %PC, align 8, !tbaa !2428
  br i1 %2659, label %block_4035c2, label %block_40386d

block_403883:                                     ; preds = %block_403feb, %block_40386d
  %2661 = phi i64 [ %1594, %block_403feb ], [ %.pre24, %block_40386d ]
  %2662 = load i64, i64* %RBP, align 8
  %2663 = add i64 %2662, -44
  %2664 = add i64 %2661, 3
  store i64 %2664, i64* %PC, align 8
  %2665 = inttoptr i64 %2663 to i32*
  %2666 = load i32, i32* %2665, align 4
  %2667 = zext i32 %2666 to i64
  store i64 %2667, i64* %RAX, align 8, !tbaa !2428
  %2668 = add i64 %2662, -4
  %2669 = add i64 %2661, 6
  store i64 %2669, i64* %PC, align 8
  %2670 = inttoptr i64 %2668 to i32*
  %2671 = load i32, i32* %2670, align 4
  %2672 = sub i32 %2666, %2671
  %2673 = icmp ult i32 %2666, %2671
  %2674 = zext i1 %2673 to i8
  store i8 %2674, i8* %16, align 1, !tbaa !2433
  %2675 = and i32 %2672, 255
  %2676 = tail call i32 @llvm.ctpop.i32(i32 %2675) #10
  %2677 = trunc i32 %2676 to i8
  %2678 = and i8 %2677, 1
  %2679 = xor i8 %2678, 1
  store i8 %2679, i8* %23, align 1, !tbaa !2447
  %2680 = xor i32 %2671, %2666
  %2681 = xor i32 %2680, %2672
  %2682 = lshr i32 %2681, 4
  %2683 = trunc i32 %2682 to i8
  %2684 = and i8 %2683, 1
  store i8 %2684, i8* %29, align 1, !tbaa !2451
  %2685 = icmp eq i32 %2672, 0
  %2686 = zext i1 %2685 to i8
  store i8 %2686, i8* %32, align 1, !tbaa !2448
  %2687 = lshr i32 %2672, 31
  %2688 = trunc i32 %2687 to i8
  store i8 %2688, i8* %35, align 1, !tbaa !2449
  %2689 = lshr i32 %2666, 31
  %2690 = lshr i32 %2671, 31
  %2691 = xor i32 %2690, %2689
  %2692 = xor i32 %2687, %2689
  %2693 = add nuw nsw i32 %2692, %2691
  %2694 = icmp eq i32 %2693, 2
  %2695 = zext i1 %2694 to i8
  store i8 %2695, i8* %41, align 1, !tbaa !2450
  %2696 = icmp ne i8 %2688, 0
  %2697 = xor i1 %2696, %2694
  %.v28 = select i1 %2697, i64 12, i64 1915
  %2698 = add i64 %2661, %.v28
  store i64 %2698, i64* %PC, align 8, !tbaa !2428
  br i1 %2697, label %block_40388f, label %block_403ffe

block_403941:                                     ; preds = %block_403930
  %2699 = add i64 %1639, 3
  store i64 %2699, i64* %PC, align 8
  %2700 = load i32, i32* %1599, align 4
  %2701 = zext i32 %2700 to i64
  store i64 %2701, i64* %RAX, align 8, !tbaa !2428
  %2702 = add i64 %1639, 6
  store i64 %2702, i64* %PC, align 8
  %2703 = load i32, i32* %1604, align 4
  %2704 = add i32 %2703, %2700
  %2705 = zext i32 %2704 to i64
  store i64 %2705, i64* %RAX, align 8, !tbaa !2428
  %2706 = icmp ult i32 %2704, %2700
  %2707 = icmp ult i32 %2704, %2703
  %2708 = or i1 %2706, %2707
  %2709 = zext i1 %2708 to i8
  store i8 %2709, i8* %16, align 1, !tbaa !2433
  %2710 = and i32 %2704, 255
  %2711 = tail call i32 @llvm.ctpop.i32(i32 %2710) #10
  %2712 = trunc i32 %2711 to i8
  %2713 = and i8 %2712, 1
  %2714 = xor i8 %2713, 1
  store i8 %2714, i8* %23, align 1, !tbaa !2447
  %2715 = xor i32 %2703, %2700
  %2716 = xor i32 %2715, %2704
  %2717 = lshr i32 %2716, 4
  %2718 = trunc i32 %2717 to i8
  %2719 = and i8 %2718, 1
  store i8 %2719, i8* %29, align 1, !tbaa !2451
  %2720 = icmp eq i32 %2704, 0
  %2721 = zext i1 %2720 to i8
  store i8 %2721, i8* %32, align 1, !tbaa !2448
  %2722 = lshr i32 %2704, 31
  %2723 = trunc i32 %2722 to i8
  store i8 %2723, i8* %35, align 1, !tbaa !2449
  %2724 = lshr i32 %2700, 31
  %2725 = lshr i32 %2703, 31
  %2726 = xor i32 %2722, %2724
  %2727 = xor i32 %2722, %2725
  %2728 = add nuw nsw i32 %2726, %2727
  %2729 = icmp eq i32 %2728, 2
  %2730 = zext i1 %2729 to i8
  store i8 %2730, i8* %41, align 1, !tbaa !2450
  %2731 = add i64 %1596, -32
  %2732 = add i64 %1639, 9
  store i64 %2732, i64* %PC, align 8
  %2733 = inttoptr i64 %2731 to i32*
  store i32 %2704, i32* %2733, align 4
  %2734 = load i64, i64* %RBP, align 8
  %2735 = add i64 %2734, -32
  %2736 = load i64, i64* %PC, align 8
  %2737 = add i64 %2736, 3
  store i64 %2737, i64* %PC, align 8
  %2738 = inttoptr i64 %2735 to i32*
  %2739 = load i32, i32* %2738, align 4
  %2740 = zext i32 %2739 to i64
  store i64 %2740, i64* %RAX, align 8, !tbaa !2428
  %2741 = add i64 %2734, -8
  %2742 = add i64 %2736, 6
  store i64 %2742, i64* %PC, align 8
  %2743 = inttoptr i64 %2741 to i32*
  %2744 = load i32, i32* %2743, align 4
  %2745 = add i32 %2744, %2739
  %2746 = zext i32 %2745 to i64
  store i64 %2746, i64* %RAX, align 8, !tbaa !2428
  %2747 = icmp ult i32 %2745, %2739
  %2748 = icmp ult i32 %2745, %2744
  %2749 = or i1 %2747, %2748
  %2750 = zext i1 %2749 to i8
  store i8 %2750, i8* %16, align 1, !tbaa !2433
  %2751 = and i32 %2745, 255
  %2752 = tail call i32 @llvm.ctpop.i32(i32 %2751) #10
  %2753 = trunc i32 %2752 to i8
  %2754 = and i8 %2753, 1
  %2755 = xor i8 %2754, 1
  store i8 %2755, i8* %23, align 1, !tbaa !2447
  %2756 = xor i32 %2744, %2739
  %2757 = xor i32 %2756, %2745
  %2758 = lshr i32 %2757, 4
  %2759 = trunc i32 %2758 to i8
  %2760 = and i8 %2759, 1
  store i8 %2760, i8* %29, align 1, !tbaa !2451
  %2761 = icmp eq i32 %2745, 0
  %2762 = zext i1 %2761 to i8
  store i8 %2762, i8* %32, align 1, !tbaa !2448
  %2763 = lshr i32 %2745, 31
  %2764 = trunc i32 %2763 to i8
  store i8 %2764, i8* %35, align 1, !tbaa !2449
  %2765 = lshr i32 %2739, 31
  %2766 = lshr i32 %2744, 31
  %2767 = xor i32 %2763, %2765
  %2768 = xor i32 %2763, %2766
  %2769 = add nuw nsw i32 %2767, %2768
  %2770 = icmp eq i32 %2769, 2
  %2771 = zext i1 %2770 to i8
  store i8 %2771, i8* %41, align 1, !tbaa !2450
  %2772 = add i64 %2734, -36
  %2773 = add i64 %2736, 9
  store i64 %2773, i64* %PC, align 8
  %2774 = inttoptr i64 %2772 to i32*
  store i32 %2745, i32* %2774, align 4
  %2775 = load i64, i64* %RBP, align 8
  %2776 = add i64 %2775, -36
  %2777 = load i64, i64* %PC, align 8
  %2778 = add i64 %2777, 3
  store i64 %2778, i64* %PC, align 8
  %2779 = inttoptr i64 %2776 to i32*
  %2780 = load i32, i32* %2779, align 4
  %2781 = zext i32 %2780 to i64
  store i64 %2781, i64* %RAX, align 8, !tbaa !2428
  %2782 = add i64 %2775, -8
  %2783 = add i64 %2777, 6
  store i64 %2783, i64* %PC, align 8
  %2784 = inttoptr i64 %2782 to i32*
  %2785 = load i32, i32* %2784, align 4
  %2786 = add i32 %2785, %2780
  %2787 = zext i32 %2786 to i64
  store i64 %2787, i64* %RAX, align 8, !tbaa !2428
  %2788 = icmp ult i32 %2786, %2780
  %2789 = icmp ult i32 %2786, %2785
  %2790 = or i1 %2788, %2789
  %2791 = zext i1 %2790 to i8
  store i8 %2791, i8* %16, align 1, !tbaa !2433
  %2792 = and i32 %2786, 255
  %2793 = tail call i32 @llvm.ctpop.i32(i32 %2792) #10
  %2794 = trunc i32 %2793 to i8
  %2795 = and i8 %2794, 1
  %2796 = xor i8 %2795, 1
  store i8 %2796, i8* %23, align 1, !tbaa !2447
  %2797 = xor i32 %2785, %2780
  %2798 = xor i32 %2797, %2786
  %2799 = lshr i32 %2798, 4
  %2800 = trunc i32 %2799 to i8
  %2801 = and i8 %2800, 1
  store i8 %2801, i8* %29, align 1, !tbaa !2451
  %2802 = icmp eq i32 %2786, 0
  %2803 = zext i1 %2802 to i8
  store i8 %2803, i8* %32, align 1, !tbaa !2448
  %2804 = lshr i32 %2786, 31
  %2805 = trunc i32 %2804 to i8
  store i8 %2805, i8* %35, align 1, !tbaa !2449
  %2806 = lshr i32 %2780, 31
  %2807 = lshr i32 %2785, 31
  %2808 = xor i32 %2804, %2806
  %2809 = xor i32 %2804, %2807
  %2810 = add nuw nsw i32 %2808, %2809
  %2811 = icmp eq i32 %2810, 2
  %2812 = zext i1 %2811 to i8
  store i8 %2812, i8* %41, align 1, !tbaa !2450
  %2813 = add i64 %2775, -40
  %2814 = add i64 %2777, 9
  store i64 %2814, i64* %PC, align 8
  %2815 = inttoptr i64 %2813 to i32*
  store i32 %2786, i32* %2815, align 4
  %2816 = load i64, i64* %RBP, align 8
  %2817 = add i64 %2816, -16
  %2818 = load i64, i64* %PC, align 8
  %2819 = add i64 %2818, 4
  store i64 %2819, i64* %PC, align 8
  %2820 = inttoptr i64 %2817 to i64*
  %2821 = load i64, i64* %2820, align 8
  store i64 %2821, i64* %RCX, align 8, !tbaa !2428
  %2822 = add i64 %2816, -28
  %2823 = add i64 %2818, 8
  store i64 %2823, i64* %PC, align 8
  %2824 = inttoptr i64 %2822 to i32*
  %2825 = load i32, i32* %2824, align 4
  %2826 = sext i32 %2825 to i64
  store i64 %2826, i64* %RDX, align 8, !tbaa !2428
  %2827 = shl nsw i64 %2826, 3
  %2828 = add i64 %2827, %2821
  %2829 = add i64 %2818, 13
  store i64 %2829, i64* %PC, align 8
  %2830 = inttoptr i64 %2828 to i64*
  %2831 = load i64, i64* %2830, align 8
  store i64 %2831, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2832 = add i64 %2818, 17
  store i64 %2832, i64* %PC, align 8
  %2833 = load i64, i64* %2820, align 8
  store i64 %2833, i64* %RCX, align 8, !tbaa !2428
  %2834 = add i64 %2816, -32
  %2835 = add i64 %2818, 21
  store i64 %2835, i64* %PC, align 8
  %2836 = inttoptr i64 %2834 to i32*
  %2837 = load i32, i32* %2836, align 4
  %2838 = sext i32 %2837 to i64
  store i64 %2838, i64* %RDX, align 8, !tbaa !2428
  %2839 = shl nsw i64 %2838, 3
  %2840 = add i64 %2839, %2833
  %2841 = add i64 %2818, 26
  store i64 %2841, i64* %PC, align 8
  %2842 = bitcast i64 %2831 to double
  %2843 = inttoptr i64 %2840 to double*
  %2844 = load double, double* %2843, align 8
  %2845 = fadd double %2842, %2844
  store double %2845, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2846 = add i64 %2816, -120
  %2847 = add i64 %2818, 31
  store i64 %2847, i64* %PC, align 8
  %2848 = inttoptr i64 %2846 to double*
  store double %2845, double* %2848, align 8
  %2849 = load i64, i64* %RBP, align 8
  %2850 = add i64 %2849, -16
  %2851 = load i64, i64* %PC, align 8
  %2852 = add i64 %2851, 4
  store i64 %2852, i64* %PC, align 8
  %2853 = inttoptr i64 %2850 to i64*
  %2854 = load i64, i64* %2853, align 8
  store i64 %2854, i64* %RCX, align 8, !tbaa !2428
  %2855 = add i64 %2849, -28
  %2856 = add i64 %2851, 7
  store i64 %2856, i64* %PC, align 8
  %2857 = inttoptr i64 %2855 to i32*
  %2858 = load i32, i32* %2857, align 4
  %2859 = add i32 %2858, 1
  %2860 = zext i32 %2859 to i64
  store i64 %2860, i64* %RAX, align 8, !tbaa !2428
  %2861 = icmp eq i32 %2858, -1
  %2862 = icmp eq i32 %2859, 0
  %2863 = or i1 %2861, %2862
  %2864 = zext i1 %2863 to i8
  store i8 %2864, i8* %16, align 1, !tbaa !2433
  %2865 = and i32 %2859, 255
  %2866 = tail call i32 @llvm.ctpop.i32(i32 %2865) #10
  %2867 = trunc i32 %2866 to i8
  %2868 = and i8 %2867, 1
  %2869 = xor i8 %2868, 1
  store i8 %2869, i8* %23, align 1, !tbaa !2447
  %2870 = xor i32 %2859, %2858
  %2871 = lshr i32 %2870, 4
  %2872 = trunc i32 %2871 to i8
  %2873 = and i8 %2872, 1
  store i8 %2873, i8* %29, align 1, !tbaa !2451
  %2874 = zext i1 %2862 to i8
  store i8 %2874, i8* %32, align 1, !tbaa !2448
  %2875 = lshr i32 %2859, 31
  %2876 = trunc i32 %2875 to i8
  store i8 %2876, i8* %35, align 1, !tbaa !2449
  %2877 = lshr i32 %2858, 31
  %2878 = xor i32 %2875, %2877
  %2879 = add nuw nsw i32 %2878, %2875
  %2880 = icmp eq i32 %2879, 2
  %2881 = zext i1 %2880 to i8
  store i8 %2881, i8* %41, align 1, !tbaa !2450
  %2882 = sext i32 %2859 to i64
  store i64 %2882, i64* %RDX, align 8, !tbaa !2428
  %2883 = shl nsw i64 %2882, 3
  %2884 = add i64 %2854, %2883
  %2885 = add i64 %2851, 18
  store i64 %2885, i64* %PC, align 8
  %2886 = inttoptr i64 %2884 to i64*
  %2887 = load i64, i64* %2886, align 8
  store i64 %2887, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2888 = add i64 %2851, 22
  store i64 %2888, i64* %PC, align 8
  %2889 = load i64, i64* %2853, align 8
  store i64 %2889, i64* %RCX, align 8, !tbaa !2428
  %2890 = add i64 %2849, -32
  %2891 = add i64 %2851, 25
  store i64 %2891, i64* %PC, align 8
  %2892 = inttoptr i64 %2890 to i32*
  %2893 = load i32, i32* %2892, align 4
  %2894 = add i32 %2893, 1
  %2895 = zext i32 %2894 to i64
  store i64 %2895, i64* %RAX, align 8, !tbaa !2428
  %2896 = icmp eq i32 %2893, -1
  %2897 = icmp eq i32 %2894, 0
  %2898 = or i1 %2896, %2897
  %2899 = zext i1 %2898 to i8
  store i8 %2899, i8* %16, align 1, !tbaa !2433
  %2900 = and i32 %2894, 255
  %2901 = tail call i32 @llvm.ctpop.i32(i32 %2900) #10
  %2902 = trunc i32 %2901 to i8
  %2903 = and i8 %2902, 1
  %2904 = xor i8 %2903, 1
  store i8 %2904, i8* %23, align 1, !tbaa !2447
  %2905 = xor i32 %2894, %2893
  %2906 = lshr i32 %2905, 4
  %2907 = trunc i32 %2906 to i8
  %2908 = and i8 %2907, 1
  store i8 %2908, i8* %29, align 1, !tbaa !2451
  %2909 = zext i1 %2897 to i8
  store i8 %2909, i8* %32, align 1, !tbaa !2448
  %2910 = lshr i32 %2894, 31
  %2911 = trunc i32 %2910 to i8
  store i8 %2911, i8* %35, align 1, !tbaa !2449
  %2912 = lshr i32 %2893, 31
  %2913 = xor i32 %2910, %2912
  %2914 = add nuw nsw i32 %2913, %2910
  %2915 = icmp eq i32 %2914, 2
  %2916 = zext i1 %2915 to i8
  store i8 %2916, i8* %41, align 1, !tbaa !2450
  %2917 = sext i32 %2894 to i64
  store i64 %2917, i64* %RDX, align 8, !tbaa !2428
  %2918 = shl nsw i64 %2917, 3
  %2919 = add i64 %2889, %2918
  %2920 = add i64 %2851, 36
  store i64 %2920, i64* %PC, align 8
  %2921 = bitcast i64 %2887 to double
  %2922 = inttoptr i64 %2919 to double*
  %2923 = load double, double* %2922, align 8
  %2924 = fadd double %2921, %2923
  store double %2924, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2925 = load i64, i64* %RBP, align 8
  %2926 = add i64 %2925, -128
  %2927 = add i64 %2851, 41
  store i64 %2927, i64* %PC, align 8
  %2928 = inttoptr i64 %2926 to double*
  store double %2924, double* %2928, align 8
  %2929 = load i64, i64* %RBP, align 8
  %2930 = add i64 %2929, -16
  %2931 = load i64, i64* %PC, align 8
  %2932 = add i64 %2931, 4
  store i64 %2932, i64* %PC, align 8
  %2933 = inttoptr i64 %2930 to i64*
  %2934 = load i64, i64* %2933, align 8
  store i64 %2934, i64* %RCX, align 8, !tbaa !2428
  %2935 = add i64 %2929, -28
  %2936 = add i64 %2931, 8
  store i64 %2936, i64* %PC, align 8
  %2937 = inttoptr i64 %2935 to i32*
  %2938 = load i32, i32* %2937, align 4
  %2939 = sext i32 %2938 to i64
  store i64 %2939, i64* %RDX, align 8, !tbaa !2428
  %2940 = shl nsw i64 %2939, 3
  %2941 = add i64 %2940, %2934
  %2942 = add i64 %2931, 13
  store i64 %2942, i64* %PC, align 8
  %2943 = inttoptr i64 %2941 to i64*
  %2944 = load i64, i64* %2943, align 8
  store i64 %2944, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2945 = add i64 %2931, 17
  store i64 %2945, i64* %PC, align 8
  %2946 = load i64, i64* %2933, align 8
  store i64 %2946, i64* %RCX, align 8, !tbaa !2428
  %2947 = add i64 %2929, -32
  %2948 = add i64 %2931, 21
  store i64 %2948, i64* %PC, align 8
  %2949 = inttoptr i64 %2947 to i32*
  %2950 = load i32, i32* %2949, align 4
  %2951 = sext i32 %2950 to i64
  store i64 %2951, i64* %RDX, align 8, !tbaa !2428
  %2952 = shl nsw i64 %2951, 3
  %2953 = add i64 %2952, %2946
  %2954 = add i64 %2931, 26
  store i64 %2954, i64* %PC, align 8
  %2955 = bitcast i64 %2944 to double
  %2956 = inttoptr i64 %2953 to double*
  %2957 = load double, double* %2956, align 8
  %2958 = fsub double %2955, %2957
  store double %2958, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2959 = add i64 %2929, -136
  %2960 = add i64 %2931, 34
  store i64 %2960, i64* %PC, align 8
  %2961 = inttoptr i64 %2959 to double*
  store double %2958, double* %2961, align 8
  %2962 = load i64, i64* %RBP, align 8
  %2963 = add i64 %2962, -16
  %2964 = load i64, i64* %PC, align 8
  %2965 = add i64 %2964, 4
  store i64 %2965, i64* %PC, align 8
  %2966 = inttoptr i64 %2963 to i64*
  %2967 = load i64, i64* %2966, align 8
  store i64 %2967, i64* %RCX, align 8, !tbaa !2428
  %2968 = add i64 %2962, -28
  %2969 = add i64 %2964, 7
  store i64 %2969, i64* %PC, align 8
  %2970 = inttoptr i64 %2968 to i32*
  %2971 = load i32, i32* %2970, align 4
  %2972 = add i32 %2971, 1
  %2973 = zext i32 %2972 to i64
  store i64 %2973, i64* %RAX, align 8, !tbaa !2428
  %2974 = icmp eq i32 %2971, -1
  %2975 = icmp eq i32 %2972, 0
  %2976 = or i1 %2974, %2975
  %2977 = zext i1 %2976 to i8
  store i8 %2977, i8* %16, align 1, !tbaa !2433
  %2978 = and i32 %2972, 255
  %2979 = tail call i32 @llvm.ctpop.i32(i32 %2978) #10
  %2980 = trunc i32 %2979 to i8
  %2981 = and i8 %2980, 1
  %2982 = xor i8 %2981, 1
  store i8 %2982, i8* %23, align 1, !tbaa !2447
  %2983 = xor i32 %2972, %2971
  %2984 = lshr i32 %2983, 4
  %2985 = trunc i32 %2984 to i8
  %2986 = and i8 %2985, 1
  store i8 %2986, i8* %29, align 1, !tbaa !2451
  %2987 = zext i1 %2975 to i8
  store i8 %2987, i8* %32, align 1, !tbaa !2448
  %2988 = lshr i32 %2972, 31
  %2989 = trunc i32 %2988 to i8
  store i8 %2989, i8* %35, align 1, !tbaa !2449
  %2990 = lshr i32 %2971, 31
  %2991 = xor i32 %2988, %2990
  %2992 = add nuw nsw i32 %2991, %2988
  %2993 = icmp eq i32 %2992, 2
  %2994 = zext i1 %2993 to i8
  store i8 %2994, i8* %41, align 1, !tbaa !2450
  %2995 = sext i32 %2972 to i64
  store i64 %2995, i64* %RDX, align 8, !tbaa !2428
  %2996 = shl nsw i64 %2995, 3
  %2997 = add i64 %2967, %2996
  %2998 = add i64 %2964, 18
  store i64 %2998, i64* %PC, align 8
  %2999 = inttoptr i64 %2997 to i64*
  %3000 = load i64, i64* %2999, align 8
  store i64 %3000, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3001 = add i64 %2964, 22
  store i64 %3001, i64* %PC, align 8
  %3002 = load i64, i64* %2966, align 8
  store i64 %3002, i64* %RCX, align 8, !tbaa !2428
  %3003 = add i64 %2962, -32
  %3004 = add i64 %2964, 25
  store i64 %3004, i64* %PC, align 8
  %3005 = inttoptr i64 %3003 to i32*
  %3006 = load i32, i32* %3005, align 4
  %3007 = add i32 %3006, 1
  %3008 = zext i32 %3007 to i64
  store i64 %3008, i64* %RAX, align 8, !tbaa !2428
  %3009 = icmp eq i32 %3006, -1
  %3010 = icmp eq i32 %3007, 0
  %3011 = or i1 %3009, %3010
  %3012 = zext i1 %3011 to i8
  store i8 %3012, i8* %16, align 1, !tbaa !2433
  %3013 = and i32 %3007, 255
  %3014 = tail call i32 @llvm.ctpop.i32(i32 %3013) #10
  %3015 = trunc i32 %3014 to i8
  %3016 = and i8 %3015, 1
  %3017 = xor i8 %3016, 1
  store i8 %3017, i8* %23, align 1, !tbaa !2447
  %3018 = xor i32 %3007, %3006
  %3019 = lshr i32 %3018, 4
  %3020 = trunc i32 %3019 to i8
  %3021 = and i8 %3020, 1
  store i8 %3021, i8* %29, align 1, !tbaa !2451
  %3022 = zext i1 %3010 to i8
  store i8 %3022, i8* %32, align 1, !tbaa !2448
  %3023 = lshr i32 %3007, 31
  %3024 = trunc i32 %3023 to i8
  store i8 %3024, i8* %35, align 1, !tbaa !2449
  %3025 = lshr i32 %3006, 31
  %3026 = xor i32 %3023, %3025
  %3027 = add nuw nsw i32 %3026, %3023
  %3028 = icmp eq i32 %3027, 2
  %3029 = zext i1 %3028 to i8
  store i8 %3029, i8* %41, align 1, !tbaa !2450
  %3030 = sext i32 %3007 to i64
  store i64 %3030, i64* %RDX, align 8, !tbaa !2428
  %3031 = shl nsw i64 %3030, 3
  %3032 = add i64 %3002, %3031
  %3033 = add i64 %2964, 36
  store i64 %3033, i64* %PC, align 8
  %3034 = bitcast i64 %3000 to double
  %3035 = inttoptr i64 %3032 to double*
  %3036 = load double, double* %3035, align 8
  %3037 = fsub double %3034, %3036
  store double %3037, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3038 = load i64, i64* %RBP, align 8
  %3039 = add i64 %3038, -144
  %3040 = add i64 %2964, 44
  store i64 %3040, i64* %PC, align 8
  %3041 = inttoptr i64 %3039 to double*
  store double %3037, double* %3041, align 8
  %3042 = load i64, i64* %RBP, align 8
  %3043 = add i64 %3042, -16
  %3044 = load i64, i64* %PC, align 8
  %3045 = add i64 %3044, 4
  store i64 %3045, i64* %PC, align 8
  %3046 = inttoptr i64 %3043 to i64*
  %3047 = load i64, i64* %3046, align 8
  store i64 %3047, i64* %RCX, align 8, !tbaa !2428
  %3048 = add i64 %3042, -36
  %3049 = add i64 %3044, 8
  store i64 %3049, i64* %PC, align 8
  %3050 = inttoptr i64 %3048 to i32*
  %3051 = load i32, i32* %3050, align 4
  %3052 = sext i32 %3051 to i64
  store i64 %3052, i64* %RDX, align 8, !tbaa !2428
  %3053 = shl nsw i64 %3052, 3
  %3054 = add i64 %3053, %3047
  %3055 = add i64 %3044, 13
  store i64 %3055, i64* %PC, align 8
  %3056 = inttoptr i64 %3054 to i64*
  %3057 = load i64, i64* %3056, align 8
  store i64 %3057, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3058 = add i64 %3044, 17
  store i64 %3058, i64* %PC, align 8
  %3059 = load i64, i64* %3046, align 8
  store i64 %3059, i64* %RCX, align 8, !tbaa !2428
  %3060 = add i64 %3042, -40
  %3061 = add i64 %3044, 21
  store i64 %3061, i64* %PC, align 8
  %3062 = inttoptr i64 %3060 to i32*
  %3063 = load i32, i32* %3062, align 4
  %3064 = sext i32 %3063 to i64
  store i64 %3064, i64* %RDX, align 8, !tbaa !2428
  %3065 = shl nsw i64 %3064, 3
  %3066 = add i64 %3065, %3059
  %3067 = add i64 %3044, 26
  store i64 %3067, i64* %PC, align 8
  %3068 = bitcast i64 %3057 to double
  %3069 = inttoptr i64 %3066 to double*
  %3070 = load double, double* %3069, align 8
  %3071 = fadd double %3068, %3070
  store double %3071, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3072 = add i64 %3042, -152
  %3073 = add i64 %3044, 34
  store i64 %3073, i64* %PC, align 8
  %3074 = inttoptr i64 %3072 to double*
  store double %3071, double* %3074, align 8
  %3075 = load i64, i64* %RBP, align 8
  %3076 = add i64 %3075, -16
  %3077 = load i64, i64* %PC, align 8
  %3078 = add i64 %3077, 4
  store i64 %3078, i64* %PC, align 8
  %3079 = inttoptr i64 %3076 to i64*
  %3080 = load i64, i64* %3079, align 8
  store i64 %3080, i64* %RCX, align 8, !tbaa !2428
  %3081 = add i64 %3075, -36
  %3082 = add i64 %3077, 7
  store i64 %3082, i64* %PC, align 8
  %3083 = inttoptr i64 %3081 to i32*
  %3084 = load i32, i32* %3083, align 4
  %3085 = add i32 %3084, 1
  %3086 = zext i32 %3085 to i64
  store i64 %3086, i64* %RAX, align 8, !tbaa !2428
  %3087 = icmp eq i32 %3084, -1
  %3088 = icmp eq i32 %3085, 0
  %3089 = or i1 %3087, %3088
  %3090 = zext i1 %3089 to i8
  store i8 %3090, i8* %16, align 1, !tbaa !2433
  %3091 = and i32 %3085, 255
  %3092 = tail call i32 @llvm.ctpop.i32(i32 %3091) #10
  %3093 = trunc i32 %3092 to i8
  %3094 = and i8 %3093, 1
  %3095 = xor i8 %3094, 1
  store i8 %3095, i8* %23, align 1, !tbaa !2447
  %3096 = xor i32 %3085, %3084
  %3097 = lshr i32 %3096, 4
  %3098 = trunc i32 %3097 to i8
  %3099 = and i8 %3098, 1
  store i8 %3099, i8* %29, align 1, !tbaa !2451
  %3100 = zext i1 %3088 to i8
  store i8 %3100, i8* %32, align 1, !tbaa !2448
  %3101 = lshr i32 %3085, 31
  %3102 = trunc i32 %3101 to i8
  store i8 %3102, i8* %35, align 1, !tbaa !2449
  %3103 = lshr i32 %3084, 31
  %3104 = xor i32 %3101, %3103
  %3105 = add nuw nsw i32 %3104, %3101
  %3106 = icmp eq i32 %3105, 2
  %3107 = zext i1 %3106 to i8
  store i8 %3107, i8* %41, align 1, !tbaa !2450
  %3108 = sext i32 %3085 to i64
  store i64 %3108, i64* %RDX, align 8, !tbaa !2428
  %3109 = shl nsw i64 %3108, 3
  %3110 = add i64 %3080, %3109
  %3111 = add i64 %3077, 18
  store i64 %3111, i64* %PC, align 8
  %3112 = inttoptr i64 %3110 to i64*
  %3113 = load i64, i64* %3112, align 8
  store i64 %3113, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3114 = add i64 %3077, 22
  store i64 %3114, i64* %PC, align 8
  %3115 = load i64, i64* %3079, align 8
  store i64 %3115, i64* %RCX, align 8, !tbaa !2428
  %3116 = add i64 %3075, -40
  %3117 = add i64 %3077, 25
  store i64 %3117, i64* %PC, align 8
  %3118 = inttoptr i64 %3116 to i32*
  %3119 = load i32, i32* %3118, align 4
  %3120 = add i32 %3119, 1
  %3121 = zext i32 %3120 to i64
  store i64 %3121, i64* %RAX, align 8, !tbaa !2428
  %3122 = icmp eq i32 %3119, -1
  %3123 = icmp eq i32 %3120, 0
  %3124 = or i1 %3122, %3123
  %3125 = zext i1 %3124 to i8
  store i8 %3125, i8* %16, align 1, !tbaa !2433
  %3126 = and i32 %3120, 255
  %3127 = tail call i32 @llvm.ctpop.i32(i32 %3126) #10
  %3128 = trunc i32 %3127 to i8
  %3129 = and i8 %3128, 1
  %3130 = xor i8 %3129, 1
  store i8 %3130, i8* %23, align 1, !tbaa !2447
  %3131 = xor i32 %3120, %3119
  %3132 = lshr i32 %3131, 4
  %3133 = trunc i32 %3132 to i8
  %3134 = and i8 %3133, 1
  store i8 %3134, i8* %29, align 1, !tbaa !2451
  %3135 = zext i1 %3123 to i8
  store i8 %3135, i8* %32, align 1, !tbaa !2448
  %3136 = lshr i32 %3120, 31
  %3137 = trunc i32 %3136 to i8
  store i8 %3137, i8* %35, align 1, !tbaa !2449
  %3138 = lshr i32 %3119, 31
  %3139 = xor i32 %3136, %3138
  %3140 = add nuw nsw i32 %3139, %3136
  %3141 = icmp eq i32 %3140, 2
  %3142 = zext i1 %3141 to i8
  store i8 %3142, i8* %41, align 1, !tbaa !2450
  %3143 = sext i32 %3120 to i64
  store i64 %3143, i64* %RDX, align 8, !tbaa !2428
  %3144 = shl nsw i64 %3143, 3
  %3145 = add i64 %3115, %3144
  %3146 = add i64 %3077, 36
  store i64 %3146, i64* %PC, align 8
  %3147 = bitcast i64 %3113 to double
  %3148 = inttoptr i64 %3145 to double*
  %3149 = load double, double* %3148, align 8
  %3150 = fadd double %3147, %3149
  store double %3150, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3151 = load i64, i64* %RBP, align 8
  %3152 = add i64 %3151, -160
  %3153 = add i64 %3077, 44
  store i64 %3153, i64* %PC, align 8
  %3154 = inttoptr i64 %3152 to double*
  store double %3150, double* %3154, align 8
  %3155 = load i64, i64* %RBP, align 8
  %3156 = add i64 %3155, -16
  %3157 = load i64, i64* %PC, align 8
  %3158 = add i64 %3157, 4
  store i64 %3158, i64* %PC, align 8
  %3159 = inttoptr i64 %3156 to i64*
  %3160 = load i64, i64* %3159, align 8
  store i64 %3160, i64* %RCX, align 8, !tbaa !2428
  %3161 = add i64 %3155, -36
  %3162 = add i64 %3157, 8
  store i64 %3162, i64* %PC, align 8
  %3163 = inttoptr i64 %3161 to i32*
  %3164 = load i32, i32* %3163, align 4
  %3165 = sext i32 %3164 to i64
  store i64 %3165, i64* %RDX, align 8, !tbaa !2428
  %3166 = shl nsw i64 %3165, 3
  %3167 = add i64 %3166, %3160
  %3168 = add i64 %3157, 13
  store i64 %3168, i64* %PC, align 8
  %3169 = inttoptr i64 %3167 to i64*
  %3170 = load i64, i64* %3169, align 8
  store i64 %3170, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3171 = add i64 %3157, 17
  store i64 %3171, i64* %PC, align 8
  %3172 = load i64, i64* %3159, align 8
  store i64 %3172, i64* %RCX, align 8, !tbaa !2428
  %3173 = add i64 %3155, -40
  %3174 = add i64 %3157, 21
  store i64 %3174, i64* %PC, align 8
  %3175 = inttoptr i64 %3173 to i32*
  %3176 = load i32, i32* %3175, align 4
  %3177 = sext i32 %3176 to i64
  store i64 %3177, i64* %RDX, align 8, !tbaa !2428
  %3178 = shl nsw i64 %3177, 3
  %3179 = add i64 %3178, %3172
  %3180 = add i64 %3157, 26
  store i64 %3180, i64* %PC, align 8
  %3181 = bitcast i64 %3170 to double
  %3182 = inttoptr i64 %3179 to double*
  %3183 = load double, double* %3182, align 8
  %3184 = fsub double %3181, %3183
  store double %3184, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3185 = add i64 %3155, -168
  %3186 = add i64 %3157, 34
  store i64 %3186, i64* %PC, align 8
  %3187 = inttoptr i64 %3185 to double*
  store double %3184, double* %3187, align 8
  %3188 = load i64, i64* %RBP, align 8
  %3189 = add i64 %3188, -16
  %3190 = load i64, i64* %PC, align 8
  %3191 = add i64 %3190, 4
  store i64 %3191, i64* %PC, align 8
  %3192 = inttoptr i64 %3189 to i64*
  %3193 = load i64, i64* %3192, align 8
  store i64 %3193, i64* %RCX, align 8, !tbaa !2428
  %3194 = add i64 %3188, -36
  %3195 = add i64 %3190, 7
  store i64 %3195, i64* %PC, align 8
  %3196 = inttoptr i64 %3194 to i32*
  %3197 = load i32, i32* %3196, align 4
  %3198 = add i32 %3197, 1
  %3199 = zext i32 %3198 to i64
  store i64 %3199, i64* %RAX, align 8, !tbaa !2428
  %3200 = icmp eq i32 %3197, -1
  %3201 = icmp eq i32 %3198, 0
  %3202 = or i1 %3200, %3201
  %3203 = zext i1 %3202 to i8
  store i8 %3203, i8* %16, align 1, !tbaa !2433
  %3204 = and i32 %3198, 255
  %3205 = tail call i32 @llvm.ctpop.i32(i32 %3204) #10
  %3206 = trunc i32 %3205 to i8
  %3207 = and i8 %3206, 1
  %3208 = xor i8 %3207, 1
  store i8 %3208, i8* %23, align 1, !tbaa !2447
  %3209 = xor i32 %3198, %3197
  %3210 = lshr i32 %3209, 4
  %3211 = trunc i32 %3210 to i8
  %3212 = and i8 %3211, 1
  store i8 %3212, i8* %29, align 1, !tbaa !2451
  %3213 = zext i1 %3201 to i8
  store i8 %3213, i8* %32, align 1, !tbaa !2448
  %3214 = lshr i32 %3198, 31
  %3215 = trunc i32 %3214 to i8
  store i8 %3215, i8* %35, align 1, !tbaa !2449
  %3216 = lshr i32 %3197, 31
  %3217 = xor i32 %3214, %3216
  %3218 = add nuw nsw i32 %3217, %3214
  %3219 = icmp eq i32 %3218, 2
  %3220 = zext i1 %3219 to i8
  store i8 %3220, i8* %41, align 1, !tbaa !2450
  %3221 = sext i32 %3198 to i64
  store i64 %3221, i64* %RDX, align 8, !tbaa !2428
  %3222 = shl nsw i64 %3221, 3
  %3223 = add i64 %3193, %3222
  %3224 = add i64 %3190, 18
  store i64 %3224, i64* %PC, align 8
  %3225 = inttoptr i64 %3223 to i64*
  %3226 = load i64, i64* %3225, align 8
  store i64 %3226, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3227 = add i64 %3190, 22
  store i64 %3227, i64* %PC, align 8
  %3228 = load i64, i64* %3192, align 8
  store i64 %3228, i64* %RCX, align 8, !tbaa !2428
  %3229 = add i64 %3188, -40
  %3230 = add i64 %3190, 25
  store i64 %3230, i64* %PC, align 8
  %3231 = inttoptr i64 %3229 to i32*
  %3232 = load i32, i32* %3231, align 4
  %3233 = add i32 %3232, 1
  %3234 = zext i32 %3233 to i64
  store i64 %3234, i64* %RAX, align 8, !tbaa !2428
  %3235 = icmp eq i32 %3232, -1
  %3236 = icmp eq i32 %3233, 0
  %3237 = or i1 %3235, %3236
  %3238 = zext i1 %3237 to i8
  store i8 %3238, i8* %16, align 1, !tbaa !2433
  %3239 = and i32 %3233, 255
  %3240 = tail call i32 @llvm.ctpop.i32(i32 %3239) #10
  %3241 = trunc i32 %3240 to i8
  %3242 = and i8 %3241, 1
  %3243 = xor i8 %3242, 1
  store i8 %3243, i8* %23, align 1, !tbaa !2447
  %3244 = xor i32 %3233, %3232
  %3245 = lshr i32 %3244, 4
  %3246 = trunc i32 %3245 to i8
  %3247 = and i8 %3246, 1
  store i8 %3247, i8* %29, align 1, !tbaa !2451
  %3248 = zext i1 %3236 to i8
  store i8 %3248, i8* %32, align 1, !tbaa !2448
  %3249 = lshr i32 %3233, 31
  %3250 = trunc i32 %3249 to i8
  store i8 %3250, i8* %35, align 1, !tbaa !2449
  %3251 = lshr i32 %3232, 31
  %3252 = xor i32 %3249, %3251
  %3253 = add nuw nsw i32 %3252, %3249
  %3254 = icmp eq i32 %3253, 2
  %3255 = zext i1 %3254 to i8
  store i8 %3255, i8* %41, align 1, !tbaa !2450
  %3256 = sext i32 %3233 to i64
  store i64 %3256, i64* %RDX, align 8, !tbaa !2428
  %3257 = shl nsw i64 %3256, 3
  %3258 = add i64 %3228, %3257
  %3259 = add i64 %3190, 36
  store i64 %3259, i64* %PC, align 8
  %3260 = bitcast i64 %3226 to double
  %3261 = inttoptr i64 %3258 to double*
  %3262 = load double, double* %3261, align 8
  %3263 = fsub double %3260, %3262
  store double %3263, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3264 = load i64, i64* %RBP, align 8
  %3265 = add i64 %3264, -176
  %3266 = add i64 %3190, 44
  store i64 %3266, i64* %PC, align 8
  %3267 = inttoptr i64 %3265 to double*
  store double %3263, double* %3267, align 8
  %3268 = load i64, i64* %RBP, align 8
  %3269 = add i64 %3268, -120
  %3270 = load i64, i64* %PC, align 8
  %3271 = add i64 %3270, 5
  store i64 %3271, i64* %PC, align 8
  %3272 = inttoptr i64 %3269 to i64*
  %3273 = load i64, i64* %3272, align 8
  store i64 %3273, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3274 = add i64 %3268, -152
  %3275 = add i64 %3270, 13
  store i64 %3275, i64* %PC, align 8
  %3276 = bitcast i64 %3273 to double
  %3277 = inttoptr i64 %3274 to double*
  %3278 = load double, double* %3277, align 8
  %3279 = fadd double %3276, %3278
  store double %3279, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3280 = add i64 %3268, -16
  %3281 = add i64 %3270, 17
  store i64 %3281, i64* %PC, align 8
  %3282 = inttoptr i64 %3280 to i64*
  %3283 = load i64, i64* %3282, align 8
  store i64 %3283, i64* %RCX, align 8, !tbaa !2428
  %3284 = add i64 %3268, -28
  %3285 = add i64 %3270, 21
  store i64 %3285, i64* %PC, align 8
  %3286 = inttoptr i64 %3284 to i32*
  %3287 = load i32, i32* %3286, align 4
  %3288 = sext i32 %3287 to i64
  store i64 %3288, i64* %RDX, align 8, !tbaa !2428
  %3289 = shl nsw i64 %3288, 3
  %3290 = add i64 %3289, %3283
  %3291 = add i64 %3270, 26
  store i64 %3291, i64* %PC, align 8
  %3292 = inttoptr i64 %3290 to double*
  store double %3279, double* %3292, align 8
  %3293 = load i64, i64* %RBP, align 8
  %3294 = add i64 %3293, -128
  %3295 = load i64, i64* %PC, align 8
  %3296 = add i64 %3295, 5
  store i64 %3296, i64* %PC, align 8
  %3297 = inttoptr i64 %3294 to i64*
  %3298 = load i64, i64* %3297, align 8
  store i64 %3298, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3299 = add i64 %3293, -160
  %3300 = add i64 %3295, 13
  store i64 %3300, i64* %PC, align 8
  %3301 = bitcast i64 %3298 to double
  %3302 = inttoptr i64 %3299 to double*
  %3303 = load double, double* %3302, align 8
  %3304 = fadd double %3301, %3303
  store double %3304, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3305 = add i64 %3293, -16
  %3306 = add i64 %3295, 17
  store i64 %3306, i64* %PC, align 8
  %3307 = inttoptr i64 %3305 to i64*
  %3308 = load i64, i64* %3307, align 8
  store i64 %3308, i64* %RCX, align 8, !tbaa !2428
  %3309 = add i64 %3293, -28
  %3310 = add i64 %3295, 20
  store i64 %3310, i64* %PC, align 8
  %3311 = inttoptr i64 %3309 to i32*
  %3312 = load i32, i32* %3311, align 4
  %3313 = add i32 %3312, 1
  %3314 = zext i32 %3313 to i64
  store i64 %3314, i64* %RAX, align 8, !tbaa !2428
  %3315 = icmp eq i32 %3312, -1
  %3316 = icmp eq i32 %3313, 0
  %3317 = or i1 %3315, %3316
  %3318 = zext i1 %3317 to i8
  store i8 %3318, i8* %16, align 1, !tbaa !2433
  %3319 = and i32 %3313, 255
  %3320 = tail call i32 @llvm.ctpop.i32(i32 %3319) #10
  %3321 = trunc i32 %3320 to i8
  %3322 = and i8 %3321, 1
  %3323 = xor i8 %3322, 1
  store i8 %3323, i8* %23, align 1, !tbaa !2447
  %3324 = xor i32 %3313, %3312
  %3325 = lshr i32 %3324, 4
  %3326 = trunc i32 %3325 to i8
  %3327 = and i8 %3326, 1
  store i8 %3327, i8* %29, align 1, !tbaa !2451
  %3328 = zext i1 %3316 to i8
  store i8 %3328, i8* %32, align 1, !tbaa !2448
  %3329 = lshr i32 %3313, 31
  %3330 = trunc i32 %3329 to i8
  store i8 %3330, i8* %35, align 1, !tbaa !2449
  %3331 = lshr i32 %3312, 31
  %3332 = xor i32 %3329, %3331
  %3333 = add nuw nsw i32 %3332, %3329
  %3334 = icmp eq i32 %3333, 2
  %3335 = zext i1 %3334 to i8
  store i8 %3335, i8* %41, align 1, !tbaa !2450
  %3336 = sext i32 %3313 to i64
  store i64 %3336, i64* %RDX, align 8, !tbaa !2428
  %3337 = shl nsw i64 %3336, 3
  %3338 = add i64 %3308, %3337
  %3339 = add i64 %3295, 31
  store i64 %3339, i64* %PC, align 8
  %3340 = inttoptr i64 %3338 to double*
  store double %3304, double* %3340, align 8
  %3341 = load i64, i64* %RBP, align 8
  %3342 = add i64 %3341, -152
  %3343 = load i64, i64* %PC, align 8
  %3344 = add i64 %3343, 8
  store i64 %3344, i64* %PC, align 8
  %3345 = inttoptr i64 %3342 to i64*
  %3346 = load i64, i64* %3345, align 8
  store i64 %3346, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3347 = add i64 %3341, -120
  %3348 = add i64 %3343, 13
  store i64 %3348, i64* %PC, align 8
  %3349 = inttoptr i64 %3347 to double*
  %3350 = load double, double* %3349, align 8
  %3351 = bitcast i64 %3346 to double
  %3352 = fsub double %3350, %3351
  store double %3352, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %3353 = add i64 %3343, 22
  store i64 %3353, i64* %PC, align 8
  %3354 = inttoptr i64 %3347 to double*
  store double %3352, double* %3354, align 8
  %3355 = load i64, i64* %RBP, align 8
  %3356 = add i64 %3355, -160
  %3357 = load i64, i64* %PC, align 8
  %3358 = add i64 %3357, 8
  store i64 %3358, i64* %PC, align 8
  %3359 = inttoptr i64 %3356 to i64*
  %3360 = load i64, i64* %3359, align 8
  store i64 %3360, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3361 = add i64 %3355, -128
  %3362 = add i64 %3357, 13
  store i64 %3362, i64* %PC, align 8
  %3363 = inttoptr i64 %3361 to double*
  %3364 = load double, double* %3363, align 8
  %3365 = bitcast i64 %3360 to double
  %3366 = fsub double %3364, %3365
  store double %3366, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %3367 = add i64 %3357, 22
  store i64 %3367, i64* %PC, align 8
  %3368 = inttoptr i64 %3361 to double*
  store double %3366, double* %3368, align 8
  %3369 = load i64, i64* %RBP, align 8
  %3370 = add i64 %3369, -88
  %3371 = load i64, i64* %PC, align 8
  %3372 = add i64 %3371, 5
  store i64 %3372, i64* %PC, align 8
  %3373 = inttoptr i64 %3370 to i64*
  %3374 = load i64, i64* %3373, align 8
  store i64 %3374, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3375 = add i64 %3369, -120
  %3376 = add i64 %3371, 10
  store i64 %3376, i64* %PC, align 8
  %3377 = bitcast i64 %3374 to double
  %3378 = inttoptr i64 %3375 to double*
  %3379 = load double, double* %3378, align 8
  %3380 = fmul double %3377, %3379
  store double %3380, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3381 = add i64 %3369, -96
  %3382 = add i64 %3371, 15
  store i64 %3382, i64* %PC, align 8
  %3383 = inttoptr i64 %3381 to i64*
  %3384 = load i64, i64* %3383, align 8
  store i64 %3384, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %3385 = add i64 %3369, -128
  %3386 = add i64 %3371, 20
  store i64 %3386, i64* %PC, align 8
  %3387 = bitcast i64 %3384 to double
  %3388 = inttoptr i64 %3385 to double*
  %3389 = load double, double* %3388, align 8
  %3390 = fmul double %3387, %3389
  store double %3390, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %3391 = fsub double %3380, %3390
  store double %3391, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3392 = add i64 %3369, -16
  %3393 = add i64 %3371, 28
  store i64 %3393, i64* %PC, align 8
  %3394 = inttoptr i64 %3392 to i64*
  %3395 = load i64, i64* %3394, align 8
  store i64 %3395, i64* %RCX, align 8, !tbaa !2428
  %3396 = add i64 %3369, -36
  %3397 = add i64 %3371, 32
  store i64 %3397, i64* %PC, align 8
  %3398 = inttoptr i64 %3396 to i32*
  %3399 = load i32, i32* %3398, align 4
  %3400 = sext i32 %3399 to i64
  store i64 %3400, i64* %RDX, align 8, !tbaa !2428
  %3401 = shl nsw i64 %3400, 3
  %3402 = add i64 %3401, %3395
  %3403 = add i64 %3371, 37
  store i64 %3403, i64* %PC, align 8
  %3404 = inttoptr i64 %3402 to double*
  store double %3391, double* %3404, align 8
  %3405 = load i64, i64* %RBP, align 8
  %3406 = add i64 %3405, -88
  %3407 = load i64, i64* %PC, align 8
  %3408 = add i64 %3407, 5
  store i64 %3408, i64* %PC, align 8
  %3409 = inttoptr i64 %3406 to i64*
  %3410 = load i64, i64* %3409, align 8
  store i64 %3410, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3411 = add i64 %3405, -128
  %3412 = add i64 %3407, 10
  store i64 %3412, i64* %PC, align 8
  %3413 = bitcast i64 %3410 to double
  %3414 = inttoptr i64 %3411 to double*
  %3415 = load double, double* %3414, align 8
  %3416 = fmul double %3413, %3415
  store double %3416, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3417 = add i64 %3405, -96
  %3418 = add i64 %3407, 15
  store i64 %3418, i64* %PC, align 8
  %3419 = inttoptr i64 %3417 to i64*
  %3420 = load i64, i64* %3419, align 8
  store i64 %3420, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %3421 = add i64 %3405, -120
  %3422 = add i64 %3407, 20
  store i64 %3422, i64* %PC, align 8
  %3423 = bitcast i64 %3420 to double
  %3424 = inttoptr i64 %3421 to double*
  %3425 = load double, double* %3424, align 8
  %3426 = fmul double %3423, %3425
  store double %3426, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %3427 = fadd double %3416, %3426
  store double %3427, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3428 = add i64 %3405, -16
  %3429 = add i64 %3407, 28
  store i64 %3429, i64* %PC, align 8
  %3430 = inttoptr i64 %3428 to i64*
  %3431 = load i64, i64* %3430, align 8
  store i64 %3431, i64* %RCX, align 8, !tbaa !2428
  %3432 = add i64 %3405, -36
  %3433 = add i64 %3407, 31
  store i64 %3433, i64* %PC, align 8
  %3434 = inttoptr i64 %3432 to i32*
  %3435 = load i32, i32* %3434, align 4
  %3436 = add i32 %3435, 1
  %3437 = zext i32 %3436 to i64
  store i64 %3437, i64* %RAX, align 8, !tbaa !2428
  %3438 = icmp eq i32 %3435, -1
  %3439 = icmp eq i32 %3436, 0
  %3440 = or i1 %3438, %3439
  %3441 = zext i1 %3440 to i8
  store i8 %3441, i8* %16, align 1, !tbaa !2433
  %3442 = and i32 %3436, 255
  %3443 = tail call i32 @llvm.ctpop.i32(i32 %3442) #10
  %3444 = trunc i32 %3443 to i8
  %3445 = and i8 %3444, 1
  %3446 = xor i8 %3445, 1
  store i8 %3446, i8* %23, align 1, !tbaa !2447
  %3447 = xor i32 %3436, %3435
  %3448 = lshr i32 %3447, 4
  %3449 = trunc i32 %3448 to i8
  %3450 = and i8 %3449, 1
  store i8 %3450, i8* %29, align 1, !tbaa !2451
  %3451 = zext i1 %3439 to i8
  store i8 %3451, i8* %32, align 1, !tbaa !2448
  %3452 = lshr i32 %3436, 31
  %3453 = trunc i32 %3452 to i8
  store i8 %3453, i8* %35, align 1, !tbaa !2449
  %3454 = lshr i32 %3435, 31
  %3455 = xor i32 %3452, %3454
  %3456 = add nuw nsw i32 %3455, %3452
  %3457 = icmp eq i32 %3456, 2
  %3458 = zext i1 %3457 to i8
  store i8 %3458, i8* %41, align 1, !tbaa !2450
  %3459 = sext i32 %3436 to i64
  store i64 %3459, i64* %RDX, align 8, !tbaa !2428
  %3460 = shl nsw i64 %3459, 3
  %3461 = add i64 %3431, %3460
  %3462 = add i64 %3407, 42
  store i64 %3462, i64* %PC, align 8
  %3463 = inttoptr i64 %3461 to double*
  store double %3427, double* %3463, align 8
  %3464 = load i64, i64* %RBP, align 8
  %3465 = add i64 %3464, -136
  %3466 = load i64, i64* %PC, align 8
  %3467 = add i64 %3466, 8
  store i64 %3467, i64* %PC, align 8
  %3468 = inttoptr i64 %3465 to i64*
  %3469 = load i64, i64* %3468, align 8
  store i64 %3469, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3470 = add i64 %3464, -176
  %3471 = add i64 %3466, 16
  store i64 %3471, i64* %PC, align 8
  %3472 = bitcast i64 %3469 to double
  %3473 = inttoptr i64 %3470 to double*
  %3474 = load double, double* %3473, align 8
  %3475 = fsub double %3472, %3474
  store double %3475, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3476 = add i64 %3464, -120
  %3477 = add i64 %3466, 21
  store i64 %3477, i64* %PC, align 8
  %3478 = inttoptr i64 %3476 to double*
  store double %3475, double* %3478, align 8
  %3479 = load i64, i64* %RBP, align 8
  %3480 = add i64 %3479, -144
  %3481 = load i64, i64* %PC, align 8
  %3482 = add i64 %3481, 8
  store i64 %3482, i64* %PC, align 8
  %3483 = inttoptr i64 %3480 to i64*
  %3484 = load i64, i64* %3483, align 8
  store i64 %3484, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3485 = add i64 %3479, -168
  %3486 = add i64 %3481, 16
  store i64 %3486, i64* %PC, align 8
  %3487 = bitcast i64 %3484 to double
  %3488 = inttoptr i64 %3485 to double*
  %3489 = load double, double* %3488, align 8
  %3490 = fadd double %3487, %3489
  store double %3490, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3491 = add i64 %3479, -128
  %3492 = add i64 %3481, 21
  store i64 %3492, i64* %PC, align 8
  %3493 = inttoptr i64 %3491 to double*
  store double %3490, double* %3493, align 8
  %3494 = load i64, i64* %RBP, align 8
  %3495 = add i64 %3494, -72
  %3496 = load i64, i64* %PC, align 8
  %3497 = add i64 %3496, 5
  store i64 %3497, i64* %PC, align 8
  %3498 = inttoptr i64 %3495 to i64*
  %3499 = load i64, i64* %3498, align 8
  store i64 %3499, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3500 = add i64 %3494, -120
  %3501 = add i64 %3496, 10
  store i64 %3501, i64* %PC, align 8
  %3502 = bitcast i64 %3499 to double
  %3503 = inttoptr i64 %3500 to double*
  %3504 = load double, double* %3503, align 8
  %3505 = fmul double %3502, %3504
  store double %3505, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3506 = add i64 %3494, -80
  %3507 = add i64 %3496, 15
  store i64 %3507, i64* %PC, align 8
  %3508 = inttoptr i64 %3506 to i64*
  %3509 = load i64, i64* %3508, align 8
  store i64 %3509, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %3510 = add i64 %3494, -128
  %3511 = add i64 %3496, 20
  store i64 %3511, i64* %PC, align 8
  %3512 = bitcast i64 %3509 to double
  %3513 = inttoptr i64 %3510 to double*
  %3514 = load double, double* %3513, align 8
  %3515 = fmul double %3512, %3514
  store double %3515, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %3516 = fsub double %3505, %3515
  store double %3516, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3517 = add i64 %3494, -16
  %3518 = add i64 %3496, 28
  store i64 %3518, i64* %PC, align 8
  %3519 = inttoptr i64 %3517 to i64*
  %3520 = load i64, i64* %3519, align 8
  store i64 %3520, i64* %RCX, align 8, !tbaa !2428
  %3521 = add i64 %3494, -32
  %3522 = add i64 %3496, 32
  store i64 %3522, i64* %PC, align 8
  %3523 = inttoptr i64 %3521 to i32*
  %3524 = load i32, i32* %3523, align 4
  %3525 = sext i32 %3524 to i64
  store i64 %3525, i64* %RDX, align 8, !tbaa !2428
  %3526 = shl nsw i64 %3525, 3
  %3527 = add i64 %3526, %3520
  %3528 = add i64 %3496, 37
  store i64 %3528, i64* %PC, align 8
  %3529 = inttoptr i64 %3527 to double*
  store double %3516, double* %3529, align 8
  %3530 = load i64, i64* %RBP, align 8
  %3531 = add i64 %3530, -72
  %3532 = load i64, i64* %PC, align 8
  %3533 = add i64 %3532, 5
  store i64 %3533, i64* %PC, align 8
  %3534 = inttoptr i64 %3531 to i64*
  %3535 = load i64, i64* %3534, align 8
  store i64 %3535, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3536 = add i64 %3530, -128
  %3537 = add i64 %3532, 10
  store i64 %3537, i64* %PC, align 8
  %3538 = bitcast i64 %3535 to double
  %3539 = inttoptr i64 %3536 to double*
  %3540 = load double, double* %3539, align 8
  %3541 = fmul double %3538, %3540
  store double %3541, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3542 = add i64 %3530, -80
  %3543 = add i64 %3532, 15
  store i64 %3543, i64* %PC, align 8
  %3544 = inttoptr i64 %3542 to i64*
  %3545 = load i64, i64* %3544, align 8
  store i64 %3545, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %3546 = add i64 %3530, -120
  %3547 = add i64 %3532, 20
  store i64 %3547, i64* %PC, align 8
  %3548 = bitcast i64 %3545 to double
  %3549 = inttoptr i64 %3546 to double*
  %3550 = load double, double* %3549, align 8
  %3551 = fmul double %3548, %3550
  store double %3551, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %3552 = fadd double %3541, %3551
  store double %3552, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3553 = add i64 %3530, -16
  %3554 = add i64 %3532, 28
  store i64 %3554, i64* %PC, align 8
  %3555 = inttoptr i64 %3553 to i64*
  %3556 = load i64, i64* %3555, align 8
  store i64 %3556, i64* %RCX, align 8, !tbaa !2428
  %3557 = add i64 %3530, -32
  %3558 = add i64 %3532, 31
  store i64 %3558, i64* %PC, align 8
  %3559 = inttoptr i64 %3557 to i32*
  %3560 = load i32, i32* %3559, align 4
  %3561 = add i32 %3560, 1
  %3562 = zext i32 %3561 to i64
  store i64 %3562, i64* %RAX, align 8, !tbaa !2428
  %3563 = icmp eq i32 %3560, -1
  %3564 = icmp eq i32 %3561, 0
  %3565 = or i1 %3563, %3564
  %3566 = zext i1 %3565 to i8
  store i8 %3566, i8* %16, align 1, !tbaa !2433
  %3567 = and i32 %3561, 255
  %3568 = tail call i32 @llvm.ctpop.i32(i32 %3567) #10
  %3569 = trunc i32 %3568 to i8
  %3570 = and i8 %3569, 1
  %3571 = xor i8 %3570, 1
  store i8 %3571, i8* %23, align 1, !tbaa !2447
  %3572 = xor i32 %3561, %3560
  %3573 = lshr i32 %3572, 4
  %3574 = trunc i32 %3573 to i8
  %3575 = and i8 %3574, 1
  store i8 %3575, i8* %29, align 1, !tbaa !2451
  %3576 = zext i1 %3564 to i8
  store i8 %3576, i8* %32, align 1, !tbaa !2448
  %3577 = lshr i32 %3561, 31
  %3578 = trunc i32 %3577 to i8
  store i8 %3578, i8* %35, align 1, !tbaa !2449
  %3579 = lshr i32 %3560, 31
  %3580 = xor i32 %3577, %3579
  %3581 = add nuw nsw i32 %3580, %3577
  %3582 = icmp eq i32 %3581, 2
  %3583 = zext i1 %3582 to i8
  store i8 %3583, i8* %41, align 1, !tbaa !2450
  %3584 = sext i32 %3561 to i64
  store i64 %3584, i64* %RDX, align 8, !tbaa !2428
  %3585 = shl nsw i64 %3584, 3
  %3586 = add i64 %3556, %3585
  %3587 = add i64 %3532, 42
  store i64 %3587, i64* %PC, align 8
  %3588 = inttoptr i64 %3586 to double*
  store double %3552, double* %3588, align 8
  %3589 = load i64, i64* %RBP, align 8
  %3590 = add i64 %3589, -136
  %3591 = load i64, i64* %PC, align 8
  %3592 = add i64 %3591, 8
  store i64 %3592, i64* %PC, align 8
  %3593 = inttoptr i64 %3590 to i64*
  %3594 = load i64, i64* %3593, align 8
  store i64 %3594, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3595 = add i64 %3589, -176
  %3596 = add i64 %3591, 16
  store i64 %3596, i64* %PC, align 8
  %3597 = bitcast i64 %3594 to double
  %3598 = inttoptr i64 %3595 to double*
  %3599 = load double, double* %3598, align 8
  %3600 = fadd double %3597, %3599
  store double %3600, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3601 = add i64 %3589, -120
  %3602 = add i64 %3591, 21
  store i64 %3602, i64* %PC, align 8
  %3603 = inttoptr i64 %3601 to double*
  store double %3600, double* %3603, align 8
  %3604 = load i64, i64* %RBP, align 8
  %3605 = add i64 %3604, -144
  %3606 = load i64, i64* %PC, align 8
  %3607 = add i64 %3606, 8
  store i64 %3607, i64* %PC, align 8
  %3608 = inttoptr i64 %3605 to i64*
  %3609 = load i64, i64* %3608, align 8
  store i64 %3609, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3610 = add i64 %3604, -168
  %3611 = add i64 %3606, 16
  store i64 %3611, i64* %PC, align 8
  %3612 = bitcast i64 %3609 to double
  %3613 = inttoptr i64 %3610 to double*
  %3614 = load double, double* %3613, align 8
  %3615 = fsub double %3612, %3614
  store double %3615, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3616 = add i64 %3604, -128
  %3617 = add i64 %3606, 21
  store i64 %3617, i64* %PC, align 8
  %3618 = inttoptr i64 %3616 to double*
  store double %3615, double* %3618, align 8
  %3619 = load i64, i64* %RBP, align 8
  %3620 = add i64 %3619, -104
  %3621 = load i64, i64* %PC, align 8
  %3622 = add i64 %3621, 5
  store i64 %3622, i64* %PC, align 8
  %3623 = inttoptr i64 %3620 to i64*
  %3624 = load i64, i64* %3623, align 8
  store i64 %3624, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3625 = add i64 %3619, -120
  %3626 = add i64 %3621, 10
  store i64 %3626, i64* %PC, align 8
  %3627 = bitcast i64 %3624 to double
  %3628 = inttoptr i64 %3625 to double*
  %3629 = load double, double* %3628, align 8
  %3630 = fmul double %3627, %3629
  store double %3630, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3631 = add i64 %3619, -112
  %3632 = add i64 %3621, 15
  store i64 %3632, i64* %PC, align 8
  %3633 = inttoptr i64 %3631 to i64*
  %3634 = load i64, i64* %3633, align 8
  store i64 %3634, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %3635 = add i64 %3619, -128
  %3636 = add i64 %3621, 20
  store i64 %3636, i64* %PC, align 8
  %3637 = bitcast i64 %3634 to double
  %3638 = inttoptr i64 %3635 to double*
  %3639 = load double, double* %3638, align 8
  %3640 = fmul double %3637, %3639
  store double %3640, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %3641 = fsub double %3630, %3640
  store double %3641, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3642 = add i64 %3619, -16
  %3643 = add i64 %3621, 28
  store i64 %3643, i64* %PC, align 8
  %3644 = inttoptr i64 %3642 to i64*
  %3645 = load i64, i64* %3644, align 8
  store i64 %3645, i64* %RCX, align 8, !tbaa !2428
  %3646 = add i64 %3619, -40
  %3647 = add i64 %3621, 32
  store i64 %3647, i64* %PC, align 8
  %3648 = inttoptr i64 %3646 to i32*
  %3649 = load i32, i32* %3648, align 4
  %3650 = sext i32 %3649 to i64
  store i64 %3650, i64* %RDX, align 8, !tbaa !2428
  %3651 = shl nsw i64 %3650, 3
  %3652 = add i64 %3651, %3645
  %3653 = add i64 %3621, 37
  store i64 %3653, i64* %PC, align 8
  %3654 = inttoptr i64 %3652 to double*
  store double %3641, double* %3654, align 8
  %3655 = load i64, i64* %RBP, align 8
  %3656 = add i64 %3655, -104
  %3657 = load i64, i64* %PC, align 8
  %3658 = add i64 %3657, 5
  store i64 %3658, i64* %PC, align 8
  %3659 = inttoptr i64 %3656 to i64*
  %3660 = load i64, i64* %3659, align 8
  store i64 %3660, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3661 = add i64 %3655, -128
  %3662 = add i64 %3657, 10
  store i64 %3662, i64* %PC, align 8
  %3663 = bitcast i64 %3660 to double
  %3664 = inttoptr i64 %3661 to double*
  %3665 = load double, double* %3664, align 8
  %3666 = fmul double %3663, %3665
  store double %3666, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3667 = add i64 %3655, -112
  %3668 = add i64 %3657, 15
  store i64 %3668, i64* %PC, align 8
  %3669 = inttoptr i64 %3667 to i64*
  %3670 = load i64, i64* %3669, align 8
  store i64 %3670, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %3671 = add i64 %3655, -120
  %3672 = add i64 %3657, 20
  store i64 %3672, i64* %PC, align 8
  %3673 = bitcast i64 %3670 to double
  %3674 = inttoptr i64 %3671 to double*
  %3675 = load double, double* %3674, align 8
  %3676 = fmul double %3673, %3675
  store double %3676, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %3677 = fadd double %3666, %3676
  store double %3677, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3678 = add i64 %3655, -16
  %3679 = add i64 %3657, 28
  store i64 %3679, i64* %PC, align 8
  %3680 = inttoptr i64 %3678 to i64*
  %3681 = load i64, i64* %3680, align 8
  store i64 %3681, i64* %RCX, align 8, !tbaa !2428
  %3682 = add i64 %3655, -40
  %3683 = add i64 %3657, 31
  store i64 %3683, i64* %PC, align 8
  %3684 = inttoptr i64 %3682 to i32*
  %3685 = load i32, i32* %3684, align 4
  %3686 = add i32 %3685, 1
  %3687 = zext i32 %3686 to i64
  store i64 %3687, i64* %RAX, align 8, !tbaa !2428
  %3688 = icmp eq i32 %3685, -1
  %3689 = icmp eq i32 %3686, 0
  %3690 = or i1 %3688, %3689
  %3691 = zext i1 %3690 to i8
  store i8 %3691, i8* %16, align 1, !tbaa !2433
  %3692 = and i32 %3686, 255
  %3693 = tail call i32 @llvm.ctpop.i32(i32 %3692) #10
  %3694 = trunc i32 %3693 to i8
  %3695 = and i8 %3694, 1
  %3696 = xor i8 %3695, 1
  store i8 %3696, i8* %23, align 1, !tbaa !2447
  %3697 = xor i32 %3686, %3685
  %3698 = lshr i32 %3697, 4
  %3699 = trunc i32 %3698 to i8
  %3700 = and i8 %3699, 1
  store i8 %3700, i8* %29, align 1, !tbaa !2451
  %3701 = zext i1 %3689 to i8
  store i8 %3701, i8* %32, align 1, !tbaa !2448
  %3702 = lshr i32 %3686, 31
  %3703 = trunc i32 %3702 to i8
  store i8 %3703, i8* %35, align 1, !tbaa !2449
  %3704 = lshr i32 %3685, 31
  %3705 = xor i32 %3702, %3704
  %3706 = add nuw nsw i32 %3705, %3702
  %3707 = icmp eq i32 %3706, 2
  %3708 = zext i1 %3707 to i8
  store i8 %3708, i8* %41, align 1, !tbaa !2450
  %3709 = sext i32 %3686 to i64
  store i64 %3709, i64* %RDX, align 8, !tbaa !2428
  %3710 = shl nsw i64 %3709, 3
  %3711 = add i64 %3681, %3710
  %3712 = add i64 %3657, 42
  store i64 %3712, i64* %PC, align 8
  %3713 = inttoptr i64 %3711 to double*
  store double %3677, double* %3713, align 8
  %3714 = load i64, i64* %RBP, align 8
  %3715 = add i64 %3714, -28
  %3716 = load i64, i64* %PC, align 8
  %3717 = add i64 %3716, 3
  store i64 %3717, i64* %PC, align 8
  %3718 = inttoptr i64 %3715 to i32*
  %3719 = load i32, i32* %3718, align 4
  %3720 = add i32 %3719, 2
  %3721 = zext i32 %3720 to i64
  store i64 %3721, i64* %RAX, align 8, !tbaa !2428
  %3722 = icmp ugt i32 %3719, -3
  %3723 = zext i1 %3722 to i8
  store i8 %3723, i8* %16, align 1, !tbaa !2433
  %3724 = and i32 %3720, 255
  %3725 = tail call i32 @llvm.ctpop.i32(i32 %3724) #10
  %3726 = trunc i32 %3725 to i8
  %3727 = and i8 %3726, 1
  %3728 = xor i8 %3727, 1
  store i8 %3728, i8* %23, align 1, !tbaa !2447
  %3729 = xor i32 %3720, %3719
  %3730 = lshr i32 %3729, 4
  %3731 = trunc i32 %3730 to i8
  %3732 = and i8 %3731, 1
  store i8 %3732, i8* %29, align 1, !tbaa !2451
  %3733 = icmp eq i32 %3720, 0
  %3734 = zext i1 %3733 to i8
  store i8 %3734, i8* %32, align 1, !tbaa !2448
  %3735 = lshr i32 %3720, 31
  %3736 = trunc i32 %3735 to i8
  store i8 %3736, i8* %35, align 1, !tbaa !2449
  %3737 = lshr i32 %3719, 31
  %3738 = xor i32 %3735, %3737
  %3739 = add nuw nsw i32 %3738, %3735
  %3740 = icmp eq i32 %3739, 2
  %3741 = zext i1 %3740 to i8
  store i8 %3741, i8* %41, align 1, !tbaa !2450
  %3742 = add i64 %3716, 9
  store i64 %3742, i64* %PC, align 8
  store i32 %3720, i32* %3718, align 4
  %3743 = load i64, i64* %PC, align 8
  %3744 = add i64 %3743, -781
  store i64 %3744, i64* %PC, align 8, !tbaa !2428
  br label %block_403930

block_403cc6:                                     ; preds = %block_403cb0
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %3745 = load i64, i64* %RBP, align 8
  %3746 = add i64 %3745, -28
  %3747 = add i64 %1522, 13
  store i64 %3747, i64* %PC, align 8
  %3748 = inttoptr i64 %3746 to i32*
  %3749 = load i32, i32* %3748, align 4
  %3750 = zext i32 %3749 to i64
  store i64 %3750, i64* %RCX, align 8, !tbaa !2428
  %3751 = add i64 %3745, -8
  %3752 = add i64 %1522, 16
  store i64 %3752, i64* %PC, align 8
  %3753 = inttoptr i64 %3751 to i32*
  %3754 = load i32, i32* %3753, align 4
  %3755 = add i32 %3754, %3749
  %3756 = zext i32 %3755 to i64
  store i64 %3756, i64* %RCX, align 8, !tbaa !2428
  %3757 = icmp ult i32 %3755, %3749
  %3758 = icmp ult i32 %3755, %3754
  %3759 = or i1 %3757, %3758
  %3760 = zext i1 %3759 to i8
  store i8 %3760, i8* %16, align 1, !tbaa !2433
  %3761 = and i32 %3755, 255
  %3762 = tail call i32 @llvm.ctpop.i32(i32 %3761) #10
  %3763 = trunc i32 %3762 to i8
  %3764 = and i8 %3763, 1
  %3765 = xor i8 %3764, 1
  store i8 %3765, i8* %23, align 1, !tbaa !2447
  %3766 = xor i32 %3754, %3749
  %3767 = xor i32 %3766, %3755
  %3768 = lshr i32 %3767, 4
  %3769 = trunc i32 %3768 to i8
  %3770 = and i8 %3769, 1
  store i8 %3770, i8* %29, align 1, !tbaa !2451
  %3771 = icmp eq i32 %3755, 0
  %3772 = zext i1 %3771 to i8
  store i8 %3772, i8* %32, align 1, !tbaa !2448
  %3773 = lshr i32 %3755, 31
  %3774 = trunc i32 %3773 to i8
  store i8 %3774, i8* %35, align 1, !tbaa !2449
  %3775 = lshr i32 %3749, 31
  %3776 = lshr i32 %3754, 31
  %3777 = xor i32 %3773, %3775
  %3778 = xor i32 %3773, %3776
  %3779 = add nuw nsw i32 %3777, %3778
  %3780 = icmp eq i32 %3779, 2
  %3781 = zext i1 %3780 to i8
  store i8 %3781, i8* %41, align 1, !tbaa !2450
  %3782 = add i64 %3745, -32
  %3783 = add i64 %1522, 19
  store i64 %3783, i64* %PC, align 8
  %3784 = inttoptr i64 %3782 to i32*
  store i32 %3755, i32* %3784, align 4
  %3785 = load i64, i64* %RBP, align 8
  %3786 = add i64 %3785, -32
  %3787 = load i64, i64* %PC, align 8
  %3788 = add i64 %3787, 3
  store i64 %3788, i64* %PC, align 8
  %3789 = inttoptr i64 %3786 to i32*
  %3790 = load i32, i32* %3789, align 4
  %3791 = zext i32 %3790 to i64
  store i64 %3791, i64* %RCX, align 8, !tbaa !2428
  %3792 = add i64 %3785, -8
  %3793 = add i64 %3787, 6
  store i64 %3793, i64* %PC, align 8
  %3794 = inttoptr i64 %3792 to i32*
  %3795 = load i32, i32* %3794, align 4
  %3796 = add i32 %3795, %3790
  %3797 = zext i32 %3796 to i64
  store i64 %3797, i64* %RCX, align 8, !tbaa !2428
  %3798 = icmp ult i32 %3796, %3790
  %3799 = icmp ult i32 %3796, %3795
  %3800 = or i1 %3798, %3799
  %3801 = zext i1 %3800 to i8
  store i8 %3801, i8* %16, align 1, !tbaa !2433
  %3802 = and i32 %3796, 255
  %3803 = tail call i32 @llvm.ctpop.i32(i32 %3802) #10
  %3804 = trunc i32 %3803 to i8
  %3805 = and i8 %3804, 1
  %3806 = xor i8 %3805, 1
  store i8 %3806, i8* %23, align 1, !tbaa !2447
  %3807 = xor i32 %3795, %3790
  %3808 = xor i32 %3807, %3796
  %3809 = lshr i32 %3808, 4
  %3810 = trunc i32 %3809 to i8
  %3811 = and i8 %3810, 1
  store i8 %3811, i8* %29, align 1, !tbaa !2451
  %3812 = icmp eq i32 %3796, 0
  %3813 = zext i1 %3812 to i8
  store i8 %3813, i8* %32, align 1, !tbaa !2448
  %3814 = lshr i32 %3796, 31
  %3815 = trunc i32 %3814 to i8
  store i8 %3815, i8* %35, align 1, !tbaa !2449
  %3816 = lshr i32 %3790, 31
  %3817 = lshr i32 %3795, 31
  %3818 = xor i32 %3814, %3816
  %3819 = xor i32 %3814, %3817
  %3820 = add nuw nsw i32 %3818, %3819
  %3821 = icmp eq i32 %3820, 2
  %3822 = zext i1 %3821 to i8
  store i8 %3822, i8* %41, align 1, !tbaa !2450
  %3823 = add i64 %3785, -36
  %3824 = add i64 %3787, 9
  store i64 %3824, i64* %PC, align 8
  %3825 = inttoptr i64 %3823 to i32*
  store i32 %3796, i32* %3825, align 4
  %3826 = load i64, i64* %RBP, align 8
  %3827 = add i64 %3826, -36
  %3828 = load i64, i64* %PC, align 8
  %3829 = add i64 %3828, 3
  store i64 %3829, i64* %PC, align 8
  %3830 = inttoptr i64 %3827 to i32*
  %3831 = load i32, i32* %3830, align 4
  %3832 = zext i32 %3831 to i64
  store i64 %3832, i64* %RCX, align 8, !tbaa !2428
  %3833 = add i64 %3826, -8
  %3834 = add i64 %3828, 6
  store i64 %3834, i64* %PC, align 8
  %3835 = inttoptr i64 %3833 to i32*
  %3836 = load i32, i32* %3835, align 4
  %3837 = add i32 %3836, %3831
  %3838 = zext i32 %3837 to i64
  store i64 %3838, i64* %RCX, align 8, !tbaa !2428
  %3839 = icmp ult i32 %3837, %3831
  %3840 = icmp ult i32 %3837, %3836
  %3841 = or i1 %3839, %3840
  %3842 = zext i1 %3841 to i8
  store i8 %3842, i8* %16, align 1, !tbaa !2433
  %3843 = and i32 %3837, 255
  %3844 = tail call i32 @llvm.ctpop.i32(i32 %3843) #10
  %3845 = trunc i32 %3844 to i8
  %3846 = and i8 %3845, 1
  %3847 = xor i8 %3846, 1
  store i8 %3847, i8* %23, align 1, !tbaa !2447
  %3848 = xor i32 %3836, %3831
  %3849 = xor i32 %3848, %3837
  %3850 = lshr i32 %3849, 4
  %3851 = trunc i32 %3850 to i8
  %3852 = and i8 %3851, 1
  store i8 %3852, i8* %29, align 1, !tbaa !2451
  %3853 = icmp eq i32 %3837, 0
  %3854 = zext i1 %3853 to i8
  store i8 %3854, i8* %32, align 1, !tbaa !2448
  %3855 = lshr i32 %3837, 31
  %3856 = trunc i32 %3855 to i8
  store i8 %3856, i8* %35, align 1, !tbaa !2449
  %3857 = lshr i32 %3831, 31
  %3858 = lshr i32 %3836, 31
  %3859 = xor i32 %3855, %3857
  %3860 = xor i32 %3855, %3858
  %3861 = add nuw nsw i32 %3859, %3860
  %3862 = icmp eq i32 %3861, 2
  %3863 = zext i1 %3862 to i8
  store i8 %3863, i8* %41, align 1, !tbaa !2450
  %3864 = add i64 %3826, -40
  %3865 = add i64 %3828, 9
  store i64 %3865, i64* %PC, align 8
  %3866 = inttoptr i64 %3864 to i32*
  store i32 %3837, i32* %3866, align 4
  %3867 = load i64, i64* %RBP, align 8
  %3868 = add i64 %3867, -16
  %3869 = load i64, i64* %PC, align 8
  %3870 = add i64 %3869, 4
  store i64 %3870, i64* %PC, align 8
  %3871 = inttoptr i64 %3868 to i64*
  %3872 = load i64, i64* %3871, align 8
  store i64 %3872, i64* %RDX, align 8, !tbaa !2428
  %3873 = add i64 %3867, -28
  %3874 = add i64 %3869, 8
  store i64 %3874, i64* %PC, align 8
  %3875 = inttoptr i64 %3873 to i32*
  %3876 = load i32, i32* %3875, align 4
  %3877 = sext i32 %3876 to i64
  store i64 %3877, i64* %RSI, align 8, !tbaa !2428
  %3878 = shl nsw i64 %3877, 3
  %3879 = add i64 %3878, %3872
  %3880 = add i64 %3869, 13
  store i64 %3880, i64* %PC, align 8
  %3881 = inttoptr i64 %3879 to i64*
  %3882 = load i64, i64* %3881, align 8
  store i64 %3882, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3883 = add i64 %3869, 17
  store i64 %3883, i64* %PC, align 8
  %3884 = load i64, i64* %3871, align 8
  store i64 %3884, i64* %RDX, align 8, !tbaa !2428
  %3885 = add i64 %3867, -32
  %3886 = add i64 %3869, 21
  store i64 %3886, i64* %PC, align 8
  %3887 = inttoptr i64 %3885 to i32*
  %3888 = load i32, i32* %3887, align 4
  %3889 = sext i32 %3888 to i64
  store i64 %3889, i64* %RSI, align 8, !tbaa !2428
  %3890 = shl nsw i64 %3889, 3
  %3891 = add i64 %3890, %3884
  %3892 = add i64 %3869, 26
  store i64 %3892, i64* %PC, align 8
  %3893 = bitcast i64 %3882 to double
  %3894 = inttoptr i64 %3891 to double*
  %3895 = load double, double* %3894, align 8
  %3896 = fadd double %3893, %3895
  store double %3896, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3897 = add i64 %3867, -120
  %3898 = add i64 %3869, 31
  store i64 %3898, i64* %PC, align 8
  %3899 = inttoptr i64 %3897 to double*
  store double %3896, double* %3899, align 8
  %3900 = load i64, i64* %RBP, align 8
  %3901 = add i64 %3900, -16
  %3902 = load i64, i64* %PC, align 8
  %3903 = add i64 %3902, 4
  store i64 %3903, i64* %PC, align 8
  %3904 = inttoptr i64 %3901 to i64*
  %3905 = load i64, i64* %3904, align 8
  store i64 %3905, i64* %RDX, align 8, !tbaa !2428
  %3906 = add i64 %3900, -28
  %3907 = add i64 %3902, 7
  store i64 %3907, i64* %PC, align 8
  %3908 = inttoptr i64 %3906 to i32*
  %3909 = load i32, i32* %3908, align 4
  %3910 = add i32 %3909, 1
  %3911 = zext i32 %3910 to i64
  store i64 %3911, i64* %RCX, align 8, !tbaa !2428
  %3912 = icmp eq i32 %3909, -1
  %3913 = icmp eq i32 %3910, 0
  %3914 = or i1 %3912, %3913
  %3915 = zext i1 %3914 to i8
  store i8 %3915, i8* %16, align 1, !tbaa !2433
  %3916 = and i32 %3910, 255
  %3917 = tail call i32 @llvm.ctpop.i32(i32 %3916) #10
  %3918 = trunc i32 %3917 to i8
  %3919 = and i8 %3918, 1
  %3920 = xor i8 %3919, 1
  store i8 %3920, i8* %23, align 1, !tbaa !2447
  %3921 = xor i32 %3910, %3909
  %3922 = lshr i32 %3921, 4
  %3923 = trunc i32 %3922 to i8
  %3924 = and i8 %3923, 1
  store i8 %3924, i8* %29, align 1, !tbaa !2451
  %3925 = zext i1 %3913 to i8
  store i8 %3925, i8* %32, align 1, !tbaa !2448
  %3926 = lshr i32 %3910, 31
  %3927 = trunc i32 %3926 to i8
  store i8 %3927, i8* %35, align 1, !tbaa !2449
  %3928 = lshr i32 %3909, 31
  %3929 = xor i32 %3926, %3928
  %3930 = add nuw nsw i32 %3929, %3926
  %3931 = icmp eq i32 %3930, 2
  %3932 = zext i1 %3931 to i8
  store i8 %3932, i8* %41, align 1, !tbaa !2450
  %3933 = sext i32 %3910 to i64
  store i64 %3933, i64* %RSI, align 8, !tbaa !2428
  %3934 = shl nsw i64 %3933, 3
  %3935 = add i64 %3905, %3934
  %3936 = add i64 %3902, 18
  store i64 %3936, i64* %PC, align 8
  %3937 = inttoptr i64 %3935 to i64*
  %3938 = load i64, i64* %3937, align 8
  store i64 %3938, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3939 = add i64 %3902, 22
  store i64 %3939, i64* %PC, align 8
  %3940 = load i64, i64* %3904, align 8
  store i64 %3940, i64* %RDX, align 8, !tbaa !2428
  %3941 = add i64 %3900, -32
  %3942 = add i64 %3902, 25
  store i64 %3942, i64* %PC, align 8
  %3943 = inttoptr i64 %3941 to i32*
  %3944 = load i32, i32* %3943, align 4
  %3945 = add i32 %3944, 1
  %3946 = zext i32 %3945 to i64
  store i64 %3946, i64* %RCX, align 8, !tbaa !2428
  %3947 = icmp eq i32 %3944, -1
  %3948 = icmp eq i32 %3945, 0
  %3949 = or i1 %3947, %3948
  %3950 = zext i1 %3949 to i8
  store i8 %3950, i8* %16, align 1, !tbaa !2433
  %3951 = and i32 %3945, 255
  %3952 = tail call i32 @llvm.ctpop.i32(i32 %3951) #10
  %3953 = trunc i32 %3952 to i8
  %3954 = and i8 %3953, 1
  %3955 = xor i8 %3954, 1
  store i8 %3955, i8* %23, align 1, !tbaa !2447
  %3956 = xor i32 %3945, %3944
  %3957 = lshr i32 %3956, 4
  %3958 = trunc i32 %3957 to i8
  %3959 = and i8 %3958, 1
  store i8 %3959, i8* %29, align 1, !tbaa !2451
  %3960 = zext i1 %3948 to i8
  store i8 %3960, i8* %32, align 1, !tbaa !2448
  %3961 = lshr i32 %3945, 31
  %3962 = trunc i32 %3961 to i8
  store i8 %3962, i8* %35, align 1, !tbaa !2449
  %3963 = lshr i32 %3944, 31
  %3964 = xor i32 %3961, %3963
  %3965 = add nuw nsw i32 %3964, %3961
  %3966 = icmp eq i32 %3965, 2
  %3967 = zext i1 %3966 to i8
  store i8 %3967, i8* %41, align 1, !tbaa !2450
  %3968 = sext i32 %3945 to i64
  store i64 %3968, i64* %RSI, align 8, !tbaa !2428
  %3969 = shl nsw i64 %3968, 3
  %3970 = add i64 %3940, %3969
  %3971 = add i64 %3902, 36
  store i64 %3971, i64* %PC, align 8
  %3972 = bitcast i64 %3938 to double
  %3973 = inttoptr i64 %3970 to double*
  %3974 = load double, double* %3973, align 8
  %3975 = fadd double %3972, %3974
  store double %3975, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3976 = load i64, i64* %RBP, align 8
  %3977 = add i64 %3976, -128
  %3978 = add i64 %3902, 41
  store i64 %3978, i64* %PC, align 8
  %3979 = inttoptr i64 %3977 to double*
  store double %3975, double* %3979, align 8
  %3980 = load i64, i64* %RBP, align 8
  %3981 = add i64 %3980, -16
  %3982 = load i64, i64* %PC, align 8
  %3983 = add i64 %3982, 4
  store i64 %3983, i64* %PC, align 8
  %3984 = inttoptr i64 %3981 to i64*
  %3985 = load i64, i64* %3984, align 8
  store i64 %3985, i64* %RDX, align 8, !tbaa !2428
  %3986 = add i64 %3980, -28
  %3987 = add i64 %3982, 8
  store i64 %3987, i64* %PC, align 8
  %3988 = inttoptr i64 %3986 to i32*
  %3989 = load i32, i32* %3988, align 4
  %3990 = sext i32 %3989 to i64
  store i64 %3990, i64* %RSI, align 8, !tbaa !2428
  %3991 = shl nsw i64 %3990, 3
  %3992 = add i64 %3991, %3985
  %3993 = add i64 %3982, 13
  store i64 %3993, i64* %PC, align 8
  %3994 = inttoptr i64 %3992 to i64*
  %3995 = load i64, i64* %3994, align 8
  store i64 %3995, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3996 = add i64 %3982, 17
  store i64 %3996, i64* %PC, align 8
  %3997 = load i64, i64* %3984, align 8
  store i64 %3997, i64* %RDX, align 8, !tbaa !2428
  %3998 = add i64 %3980, -32
  %3999 = add i64 %3982, 21
  store i64 %3999, i64* %PC, align 8
  %4000 = inttoptr i64 %3998 to i32*
  %4001 = load i32, i32* %4000, align 4
  %4002 = sext i32 %4001 to i64
  store i64 %4002, i64* %RSI, align 8, !tbaa !2428
  %4003 = shl nsw i64 %4002, 3
  %4004 = add i64 %4003, %3997
  %4005 = add i64 %3982, 26
  store i64 %4005, i64* %PC, align 8
  %4006 = bitcast i64 %3995 to double
  %4007 = inttoptr i64 %4004 to double*
  %4008 = load double, double* %4007, align 8
  %4009 = fsub double %4006, %4008
  store double %4009, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4010 = add i64 %3980, -136
  %4011 = add i64 %3982, 34
  store i64 %4011, i64* %PC, align 8
  %4012 = inttoptr i64 %4010 to double*
  store double %4009, double* %4012, align 8
  %4013 = load i64, i64* %RBP, align 8
  %4014 = add i64 %4013, -16
  %4015 = load i64, i64* %PC, align 8
  %4016 = add i64 %4015, 4
  store i64 %4016, i64* %PC, align 8
  %4017 = inttoptr i64 %4014 to i64*
  %4018 = load i64, i64* %4017, align 8
  store i64 %4018, i64* %RDX, align 8, !tbaa !2428
  %4019 = add i64 %4013, -28
  %4020 = add i64 %4015, 7
  store i64 %4020, i64* %PC, align 8
  %4021 = inttoptr i64 %4019 to i32*
  %4022 = load i32, i32* %4021, align 4
  %4023 = add i32 %4022, 1
  %4024 = zext i32 %4023 to i64
  store i64 %4024, i64* %RCX, align 8, !tbaa !2428
  %4025 = icmp eq i32 %4022, -1
  %4026 = icmp eq i32 %4023, 0
  %4027 = or i1 %4025, %4026
  %4028 = zext i1 %4027 to i8
  store i8 %4028, i8* %16, align 1, !tbaa !2433
  %4029 = and i32 %4023, 255
  %4030 = tail call i32 @llvm.ctpop.i32(i32 %4029) #10
  %4031 = trunc i32 %4030 to i8
  %4032 = and i8 %4031, 1
  %4033 = xor i8 %4032, 1
  store i8 %4033, i8* %23, align 1, !tbaa !2447
  %4034 = xor i32 %4023, %4022
  %4035 = lshr i32 %4034, 4
  %4036 = trunc i32 %4035 to i8
  %4037 = and i8 %4036, 1
  store i8 %4037, i8* %29, align 1, !tbaa !2451
  %4038 = zext i1 %4026 to i8
  store i8 %4038, i8* %32, align 1, !tbaa !2448
  %4039 = lshr i32 %4023, 31
  %4040 = trunc i32 %4039 to i8
  store i8 %4040, i8* %35, align 1, !tbaa !2449
  %4041 = lshr i32 %4022, 31
  %4042 = xor i32 %4039, %4041
  %4043 = add nuw nsw i32 %4042, %4039
  %4044 = icmp eq i32 %4043, 2
  %4045 = zext i1 %4044 to i8
  store i8 %4045, i8* %41, align 1, !tbaa !2450
  %4046 = sext i32 %4023 to i64
  store i64 %4046, i64* %RSI, align 8, !tbaa !2428
  %4047 = shl nsw i64 %4046, 3
  %4048 = add i64 %4018, %4047
  %4049 = add i64 %4015, 18
  store i64 %4049, i64* %PC, align 8
  %4050 = inttoptr i64 %4048 to i64*
  %4051 = load i64, i64* %4050, align 8
  store i64 %4051, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4052 = add i64 %4015, 22
  store i64 %4052, i64* %PC, align 8
  %4053 = load i64, i64* %4017, align 8
  store i64 %4053, i64* %RDX, align 8, !tbaa !2428
  %4054 = add i64 %4013, -32
  %4055 = add i64 %4015, 25
  store i64 %4055, i64* %PC, align 8
  %4056 = inttoptr i64 %4054 to i32*
  %4057 = load i32, i32* %4056, align 4
  %4058 = add i32 %4057, 1
  %4059 = zext i32 %4058 to i64
  store i64 %4059, i64* %RCX, align 8, !tbaa !2428
  %4060 = icmp eq i32 %4057, -1
  %4061 = icmp eq i32 %4058, 0
  %4062 = or i1 %4060, %4061
  %4063 = zext i1 %4062 to i8
  store i8 %4063, i8* %16, align 1, !tbaa !2433
  %4064 = and i32 %4058, 255
  %4065 = tail call i32 @llvm.ctpop.i32(i32 %4064) #10
  %4066 = trunc i32 %4065 to i8
  %4067 = and i8 %4066, 1
  %4068 = xor i8 %4067, 1
  store i8 %4068, i8* %23, align 1, !tbaa !2447
  %4069 = xor i32 %4058, %4057
  %4070 = lshr i32 %4069, 4
  %4071 = trunc i32 %4070 to i8
  %4072 = and i8 %4071, 1
  store i8 %4072, i8* %29, align 1, !tbaa !2451
  %4073 = zext i1 %4061 to i8
  store i8 %4073, i8* %32, align 1, !tbaa !2448
  %4074 = lshr i32 %4058, 31
  %4075 = trunc i32 %4074 to i8
  store i8 %4075, i8* %35, align 1, !tbaa !2449
  %4076 = lshr i32 %4057, 31
  %4077 = xor i32 %4074, %4076
  %4078 = add nuw nsw i32 %4077, %4074
  %4079 = icmp eq i32 %4078, 2
  %4080 = zext i1 %4079 to i8
  store i8 %4080, i8* %41, align 1, !tbaa !2450
  %4081 = sext i32 %4058 to i64
  store i64 %4081, i64* %RSI, align 8, !tbaa !2428
  %4082 = shl nsw i64 %4081, 3
  %4083 = add i64 %4053, %4082
  %4084 = add i64 %4015, 36
  store i64 %4084, i64* %PC, align 8
  %4085 = bitcast i64 %4051 to double
  %4086 = inttoptr i64 %4083 to double*
  %4087 = load double, double* %4086, align 8
  %4088 = fsub double %4085, %4087
  store double %4088, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4089 = load i64, i64* %RBP, align 8
  %4090 = add i64 %4089, -144
  %4091 = add i64 %4015, 44
  store i64 %4091, i64* %PC, align 8
  %4092 = inttoptr i64 %4090 to double*
  store double %4088, double* %4092, align 8
  %4093 = load i64, i64* %RBP, align 8
  %4094 = add i64 %4093, -16
  %4095 = load i64, i64* %PC, align 8
  %4096 = add i64 %4095, 4
  store i64 %4096, i64* %PC, align 8
  %4097 = inttoptr i64 %4094 to i64*
  %4098 = load i64, i64* %4097, align 8
  store i64 %4098, i64* %RDX, align 8, !tbaa !2428
  %4099 = add i64 %4093, -36
  %4100 = add i64 %4095, 8
  store i64 %4100, i64* %PC, align 8
  %4101 = inttoptr i64 %4099 to i32*
  %4102 = load i32, i32* %4101, align 4
  %4103 = sext i32 %4102 to i64
  store i64 %4103, i64* %RSI, align 8, !tbaa !2428
  %4104 = shl nsw i64 %4103, 3
  %4105 = add i64 %4104, %4098
  %4106 = add i64 %4095, 13
  store i64 %4106, i64* %PC, align 8
  %4107 = inttoptr i64 %4105 to i64*
  %4108 = load i64, i64* %4107, align 8
  store i64 %4108, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4109 = add i64 %4095, 17
  store i64 %4109, i64* %PC, align 8
  %4110 = load i64, i64* %4097, align 8
  store i64 %4110, i64* %RDX, align 8, !tbaa !2428
  %4111 = add i64 %4093, -40
  %4112 = add i64 %4095, 21
  store i64 %4112, i64* %PC, align 8
  %4113 = inttoptr i64 %4111 to i32*
  %4114 = load i32, i32* %4113, align 4
  %4115 = sext i32 %4114 to i64
  store i64 %4115, i64* %RSI, align 8, !tbaa !2428
  %4116 = shl nsw i64 %4115, 3
  %4117 = add i64 %4116, %4110
  %4118 = add i64 %4095, 26
  store i64 %4118, i64* %PC, align 8
  %4119 = bitcast i64 %4108 to double
  %4120 = inttoptr i64 %4117 to double*
  %4121 = load double, double* %4120, align 8
  %4122 = fadd double %4119, %4121
  store double %4122, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4123 = add i64 %4093, -152
  %4124 = add i64 %4095, 34
  store i64 %4124, i64* %PC, align 8
  %4125 = inttoptr i64 %4123 to double*
  store double %4122, double* %4125, align 8
  %4126 = load i64, i64* %RBP, align 8
  %4127 = add i64 %4126, -16
  %4128 = load i64, i64* %PC, align 8
  %4129 = add i64 %4128, 4
  store i64 %4129, i64* %PC, align 8
  %4130 = inttoptr i64 %4127 to i64*
  %4131 = load i64, i64* %4130, align 8
  store i64 %4131, i64* %RDX, align 8, !tbaa !2428
  %4132 = add i64 %4126, -36
  %4133 = add i64 %4128, 7
  store i64 %4133, i64* %PC, align 8
  %4134 = inttoptr i64 %4132 to i32*
  %4135 = load i32, i32* %4134, align 4
  %4136 = add i32 %4135, 1
  %4137 = zext i32 %4136 to i64
  store i64 %4137, i64* %RCX, align 8, !tbaa !2428
  %4138 = icmp eq i32 %4135, -1
  %4139 = icmp eq i32 %4136, 0
  %4140 = or i1 %4138, %4139
  %4141 = zext i1 %4140 to i8
  store i8 %4141, i8* %16, align 1, !tbaa !2433
  %4142 = and i32 %4136, 255
  %4143 = tail call i32 @llvm.ctpop.i32(i32 %4142) #10
  %4144 = trunc i32 %4143 to i8
  %4145 = and i8 %4144, 1
  %4146 = xor i8 %4145, 1
  store i8 %4146, i8* %23, align 1, !tbaa !2447
  %4147 = xor i32 %4136, %4135
  %4148 = lshr i32 %4147, 4
  %4149 = trunc i32 %4148 to i8
  %4150 = and i8 %4149, 1
  store i8 %4150, i8* %29, align 1, !tbaa !2451
  %4151 = zext i1 %4139 to i8
  store i8 %4151, i8* %32, align 1, !tbaa !2448
  %4152 = lshr i32 %4136, 31
  %4153 = trunc i32 %4152 to i8
  store i8 %4153, i8* %35, align 1, !tbaa !2449
  %4154 = lshr i32 %4135, 31
  %4155 = xor i32 %4152, %4154
  %4156 = add nuw nsw i32 %4155, %4152
  %4157 = icmp eq i32 %4156, 2
  %4158 = zext i1 %4157 to i8
  store i8 %4158, i8* %41, align 1, !tbaa !2450
  %4159 = sext i32 %4136 to i64
  store i64 %4159, i64* %RSI, align 8, !tbaa !2428
  %4160 = shl nsw i64 %4159, 3
  %4161 = add i64 %4131, %4160
  %4162 = add i64 %4128, 18
  store i64 %4162, i64* %PC, align 8
  %4163 = inttoptr i64 %4161 to i64*
  %4164 = load i64, i64* %4163, align 8
  store i64 %4164, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4165 = add i64 %4128, 22
  store i64 %4165, i64* %PC, align 8
  %4166 = load i64, i64* %4130, align 8
  store i64 %4166, i64* %RDX, align 8, !tbaa !2428
  %4167 = add i64 %4126, -40
  %4168 = add i64 %4128, 25
  store i64 %4168, i64* %PC, align 8
  %4169 = inttoptr i64 %4167 to i32*
  %4170 = load i32, i32* %4169, align 4
  %4171 = add i32 %4170, 1
  %4172 = zext i32 %4171 to i64
  store i64 %4172, i64* %RCX, align 8, !tbaa !2428
  %4173 = icmp eq i32 %4170, -1
  %4174 = icmp eq i32 %4171, 0
  %4175 = or i1 %4173, %4174
  %4176 = zext i1 %4175 to i8
  store i8 %4176, i8* %16, align 1, !tbaa !2433
  %4177 = and i32 %4171, 255
  %4178 = tail call i32 @llvm.ctpop.i32(i32 %4177) #10
  %4179 = trunc i32 %4178 to i8
  %4180 = and i8 %4179, 1
  %4181 = xor i8 %4180, 1
  store i8 %4181, i8* %23, align 1, !tbaa !2447
  %4182 = xor i32 %4171, %4170
  %4183 = lshr i32 %4182, 4
  %4184 = trunc i32 %4183 to i8
  %4185 = and i8 %4184, 1
  store i8 %4185, i8* %29, align 1, !tbaa !2451
  %4186 = zext i1 %4174 to i8
  store i8 %4186, i8* %32, align 1, !tbaa !2448
  %4187 = lshr i32 %4171, 31
  %4188 = trunc i32 %4187 to i8
  store i8 %4188, i8* %35, align 1, !tbaa !2449
  %4189 = lshr i32 %4170, 31
  %4190 = xor i32 %4187, %4189
  %4191 = add nuw nsw i32 %4190, %4187
  %4192 = icmp eq i32 %4191, 2
  %4193 = zext i1 %4192 to i8
  store i8 %4193, i8* %41, align 1, !tbaa !2450
  %4194 = sext i32 %4171 to i64
  store i64 %4194, i64* %RSI, align 8, !tbaa !2428
  %4195 = shl nsw i64 %4194, 3
  %4196 = add i64 %4166, %4195
  %4197 = add i64 %4128, 36
  store i64 %4197, i64* %PC, align 8
  %4198 = bitcast i64 %4164 to double
  %4199 = inttoptr i64 %4196 to double*
  %4200 = load double, double* %4199, align 8
  %4201 = fadd double %4198, %4200
  store double %4201, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4202 = load i64, i64* %RBP, align 8
  %4203 = add i64 %4202, -160
  %4204 = add i64 %4128, 44
  store i64 %4204, i64* %PC, align 8
  %4205 = inttoptr i64 %4203 to double*
  store double %4201, double* %4205, align 8
  %4206 = load i64, i64* %RBP, align 8
  %4207 = add i64 %4206, -16
  %4208 = load i64, i64* %PC, align 8
  %4209 = add i64 %4208, 4
  store i64 %4209, i64* %PC, align 8
  %4210 = inttoptr i64 %4207 to i64*
  %4211 = load i64, i64* %4210, align 8
  store i64 %4211, i64* %RDX, align 8, !tbaa !2428
  %4212 = add i64 %4206, -36
  %4213 = add i64 %4208, 8
  store i64 %4213, i64* %PC, align 8
  %4214 = inttoptr i64 %4212 to i32*
  %4215 = load i32, i32* %4214, align 4
  %4216 = sext i32 %4215 to i64
  store i64 %4216, i64* %RSI, align 8, !tbaa !2428
  %4217 = shl nsw i64 %4216, 3
  %4218 = add i64 %4217, %4211
  %4219 = add i64 %4208, 13
  store i64 %4219, i64* %PC, align 8
  %4220 = inttoptr i64 %4218 to i64*
  %4221 = load i64, i64* %4220, align 8
  store i64 %4221, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4222 = add i64 %4208, 17
  store i64 %4222, i64* %PC, align 8
  %4223 = load i64, i64* %4210, align 8
  store i64 %4223, i64* %RDX, align 8, !tbaa !2428
  %4224 = add i64 %4206, -40
  %4225 = add i64 %4208, 21
  store i64 %4225, i64* %PC, align 8
  %4226 = inttoptr i64 %4224 to i32*
  %4227 = load i32, i32* %4226, align 4
  %4228 = sext i32 %4227 to i64
  store i64 %4228, i64* %RSI, align 8, !tbaa !2428
  %4229 = shl nsw i64 %4228, 3
  %4230 = add i64 %4229, %4223
  %4231 = add i64 %4208, 26
  store i64 %4231, i64* %PC, align 8
  %4232 = bitcast i64 %4221 to double
  %4233 = inttoptr i64 %4230 to double*
  %4234 = load double, double* %4233, align 8
  %4235 = fsub double %4232, %4234
  store double %4235, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4236 = add i64 %4206, -168
  %4237 = add i64 %4208, 34
  store i64 %4237, i64* %PC, align 8
  %4238 = inttoptr i64 %4236 to double*
  store double %4235, double* %4238, align 8
  %4239 = load i64, i64* %RBP, align 8
  %4240 = add i64 %4239, -16
  %4241 = load i64, i64* %PC, align 8
  %4242 = add i64 %4241, 4
  store i64 %4242, i64* %PC, align 8
  %4243 = inttoptr i64 %4240 to i64*
  %4244 = load i64, i64* %4243, align 8
  store i64 %4244, i64* %RDX, align 8, !tbaa !2428
  %4245 = add i64 %4239, -36
  %4246 = add i64 %4241, 7
  store i64 %4246, i64* %PC, align 8
  %4247 = inttoptr i64 %4245 to i32*
  %4248 = load i32, i32* %4247, align 4
  %4249 = add i32 %4248, 1
  %4250 = zext i32 %4249 to i64
  store i64 %4250, i64* %RCX, align 8, !tbaa !2428
  %4251 = icmp eq i32 %4248, -1
  %4252 = icmp eq i32 %4249, 0
  %4253 = or i1 %4251, %4252
  %4254 = zext i1 %4253 to i8
  store i8 %4254, i8* %16, align 1, !tbaa !2433
  %4255 = and i32 %4249, 255
  %4256 = tail call i32 @llvm.ctpop.i32(i32 %4255) #10
  %4257 = trunc i32 %4256 to i8
  %4258 = and i8 %4257, 1
  %4259 = xor i8 %4258, 1
  store i8 %4259, i8* %23, align 1, !tbaa !2447
  %4260 = xor i32 %4249, %4248
  %4261 = lshr i32 %4260, 4
  %4262 = trunc i32 %4261 to i8
  %4263 = and i8 %4262, 1
  store i8 %4263, i8* %29, align 1, !tbaa !2451
  %4264 = zext i1 %4252 to i8
  store i8 %4264, i8* %32, align 1, !tbaa !2448
  %4265 = lshr i32 %4249, 31
  %4266 = trunc i32 %4265 to i8
  store i8 %4266, i8* %35, align 1, !tbaa !2449
  %4267 = lshr i32 %4248, 31
  %4268 = xor i32 %4265, %4267
  %4269 = add nuw nsw i32 %4268, %4265
  %4270 = icmp eq i32 %4269, 2
  %4271 = zext i1 %4270 to i8
  store i8 %4271, i8* %41, align 1, !tbaa !2450
  %4272 = sext i32 %4249 to i64
  store i64 %4272, i64* %RSI, align 8, !tbaa !2428
  %4273 = shl nsw i64 %4272, 3
  %4274 = add i64 %4244, %4273
  %4275 = add i64 %4241, 18
  store i64 %4275, i64* %PC, align 8
  %4276 = inttoptr i64 %4274 to i64*
  %4277 = load i64, i64* %4276, align 8
  store i64 %4277, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4278 = add i64 %4241, 22
  store i64 %4278, i64* %PC, align 8
  %4279 = load i64, i64* %4243, align 8
  store i64 %4279, i64* %RDX, align 8, !tbaa !2428
  %4280 = add i64 %4239, -40
  %4281 = add i64 %4241, 25
  store i64 %4281, i64* %PC, align 8
  %4282 = inttoptr i64 %4280 to i32*
  %4283 = load i32, i32* %4282, align 4
  %4284 = add i32 %4283, 1
  %4285 = zext i32 %4284 to i64
  store i64 %4285, i64* %RCX, align 8, !tbaa !2428
  %4286 = icmp eq i32 %4283, -1
  %4287 = icmp eq i32 %4284, 0
  %4288 = or i1 %4286, %4287
  %4289 = zext i1 %4288 to i8
  store i8 %4289, i8* %16, align 1, !tbaa !2433
  %4290 = and i32 %4284, 255
  %4291 = tail call i32 @llvm.ctpop.i32(i32 %4290) #10
  %4292 = trunc i32 %4291 to i8
  %4293 = and i8 %4292, 1
  %4294 = xor i8 %4293, 1
  store i8 %4294, i8* %23, align 1, !tbaa !2447
  %4295 = xor i32 %4284, %4283
  %4296 = lshr i32 %4295, 4
  %4297 = trunc i32 %4296 to i8
  %4298 = and i8 %4297, 1
  store i8 %4298, i8* %29, align 1, !tbaa !2451
  %4299 = zext i1 %4287 to i8
  store i8 %4299, i8* %32, align 1, !tbaa !2448
  %4300 = lshr i32 %4284, 31
  %4301 = trunc i32 %4300 to i8
  store i8 %4301, i8* %35, align 1, !tbaa !2449
  %4302 = lshr i32 %4283, 31
  %4303 = xor i32 %4300, %4302
  %4304 = add nuw nsw i32 %4303, %4300
  %4305 = icmp eq i32 %4304, 2
  %4306 = zext i1 %4305 to i8
  store i8 %4306, i8* %41, align 1, !tbaa !2450
  %4307 = sext i32 %4284 to i64
  store i64 %4307, i64* %RSI, align 8, !tbaa !2428
  %4308 = shl nsw i64 %4307, 3
  %4309 = add i64 %4279, %4308
  %4310 = add i64 %4241, 36
  store i64 %4310, i64* %PC, align 8
  %4311 = bitcast i64 %4277 to double
  %4312 = inttoptr i64 %4309 to double*
  %4313 = load double, double* %4312, align 8
  %4314 = fsub double %4311, %4313
  store double %4314, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4315 = load i64, i64* %RBP, align 8
  %4316 = add i64 %4315, -176
  %4317 = add i64 %4241, 44
  store i64 %4317, i64* %PC, align 8
  %4318 = inttoptr i64 %4316 to double*
  store double %4314, double* %4318, align 8
  %4319 = load i64, i64* %RBP, align 8
  %4320 = add i64 %4319, -120
  %4321 = load i64, i64* %PC, align 8
  %4322 = add i64 %4321, 5
  store i64 %4322, i64* %PC, align 8
  %4323 = inttoptr i64 %4320 to i64*
  %4324 = load i64, i64* %4323, align 8
  store i64 %4324, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4325 = add i64 %4319, -152
  %4326 = add i64 %4321, 13
  store i64 %4326, i64* %PC, align 8
  %4327 = bitcast i64 %4324 to double
  %4328 = inttoptr i64 %4325 to double*
  %4329 = load double, double* %4328, align 8
  %4330 = fadd double %4327, %4329
  store double %4330, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4331 = add i64 %4319, -16
  %4332 = add i64 %4321, 17
  store i64 %4332, i64* %PC, align 8
  %4333 = inttoptr i64 %4331 to i64*
  %4334 = load i64, i64* %4333, align 8
  store i64 %4334, i64* %RDX, align 8, !tbaa !2428
  %4335 = add i64 %4319, -28
  %4336 = add i64 %4321, 21
  store i64 %4336, i64* %PC, align 8
  %4337 = inttoptr i64 %4335 to i32*
  %4338 = load i32, i32* %4337, align 4
  %4339 = sext i32 %4338 to i64
  store i64 %4339, i64* %RSI, align 8, !tbaa !2428
  %4340 = shl nsw i64 %4339, 3
  %4341 = add i64 %4340, %4334
  %4342 = add i64 %4321, 26
  store i64 %4342, i64* %PC, align 8
  %4343 = inttoptr i64 %4341 to double*
  store double %4330, double* %4343, align 8
  %4344 = load i64, i64* %RBP, align 8
  %4345 = add i64 %4344, -128
  %4346 = load i64, i64* %PC, align 8
  %4347 = add i64 %4346, 5
  store i64 %4347, i64* %PC, align 8
  %4348 = inttoptr i64 %4345 to i64*
  %4349 = load i64, i64* %4348, align 8
  store i64 %4349, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4350 = add i64 %4344, -160
  %4351 = add i64 %4346, 13
  store i64 %4351, i64* %PC, align 8
  %4352 = bitcast i64 %4349 to double
  %4353 = inttoptr i64 %4350 to double*
  %4354 = load double, double* %4353, align 8
  %4355 = fadd double %4352, %4354
  store double %4355, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4356 = add i64 %4344, -16
  %4357 = add i64 %4346, 17
  store i64 %4357, i64* %PC, align 8
  %4358 = inttoptr i64 %4356 to i64*
  %4359 = load i64, i64* %4358, align 8
  store i64 %4359, i64* %RDX, align 8, !tbaa !2428
  %4360 = add i64 %4344, -28
  %4361 = add i64 %4346, 20
  store i64 %4361, i64* %PC, align 8
  %4362 = inttoptr i64 %4360 to i32*
  %4363 = load i32, i32* %4362, align 4
  %4364 = add i32 %4363, 1
  %4365 = zext i32 %4364 to i64
  store i64 %4365, i64* %RCX, align 8, !tbaa !2428
  %4366 = icmp eq i32 %4363, -1
  %4367 = icmp eq i32 %4364, 0
  %4368 = or i1 %4366, %4367
  %4369 = zext i1 %4368 to i8
  store i8 %4369, i8* %16, align 1, !tbaa !2433
  %4370 = and i32 %4364, 255
  %4371 = tail call i32 @llvm.ctpop.i32(i32 %4370) #10
  %4372 = trunc i32 %4371 to i8
  %4373 = and i8 %4372, 1
  %4374 = xor i8 %4373, 1
  store i8 %4374, i8* %23, align 1, !tbaa !2447
  %4375 = xor i32 %4364, %4363
  %4376 = lshr i32 %4375, 4
  %4377 = trunc i32 %4376 to i8
  %4378 = and i8 %4377, 1
  store i8 %4378, i8* %29, align 1, !tbaa !2451
  %4379 = zext i1 %4367 to i8
  store i8 %4379, i8* %32, align 1, !tbaa !2448
  %4380 = lshr i32 %4364, 31
  %4381 = trunc i32 %4380 to i8
  store i8 %4381, i8* %35, align 1, !tbaa !2449
  %4382 = lshr i32 %4363, 31
  %4383 = xor i32 %4380, %4382
  %4384 = add nuw nsw i32 %4383, %4380
  %4385 = icmp eq i32 %4384, 2
  %4386 = zext i1 %4385 to i8
  store i8 %4386, i8* %41, align 1, !tbaa !2450
  %4387 = sext i32 %4364 to i64
  store i64 %4387, i64* %RSI, align 8, !tbaa !2428
  %4388 = shl nsw i64 %4387, 3
  %4389 = add i64 %4359, %4388
  %4390 = add i64 %4346, 31
  store i64 %4390, i64* %PC, align 8
  %4391 = inttoptr i64 %4389 to double*
  store double %4355, double* %4391, align 8
  %4392 = load i64, i64* %RBP, align 8
  %4393 = add i64 %4392, -152
  %4394 = load i64, i64* %PC, align 8
  %4395 = add i64 %4394, 8
  store i64 %4395, i64* %PC, align 8
  %4396 = inttoptr i64 %4393 to i64*
  %4397 = load i64, i64* %4396, align 8
  store i64 %4397, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4398 = add i64 %4392, -120
  %4399 = add i64 %4394, 13
  store i64 %4399, i64* %PC, align 8
  %4400 = inttoptr i64 %4398 to double*
  %4401 = load double, double* %4400, align 8
  %4402 = bitcast i64 %4397 to double
  %4403 = fsub double %4401, %4402
  store double %4403, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %4404 = add i64 %4394, 22
  store i64 %4404, i64* %PC, align 8
  %4405 = inttoptr i64 %4398 to double*
  store double %4403, double* %4405, align 8
  %4406 = load i64, i64* %RBP, align 8
  %4407 = add i64 %4406, -160
  %4408 = load i64, i64* %PC, align 8
  %4409 = add i64 %4408, 8
  store i64 %4409, i64* %PC, align 8
  %4410 = inttoptr i64 %4407 to i64*
  %4411 = load i64, i64* %4410, align 8
  store i64 %4411, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4412 = add i64 %4406, -128
  %4413 = add i64 %4408, 13
  store i64 %4413, i64* %PC, align 8
  %4414 = inttoptr i64 %4412 to double*
  %4415 = load double, double* %4414, align 8
  %4416 = bitcast i64 %4411 to double
  %4417 = fsub double %4415, %4416
  store double %4417, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %4418 = add i64 %4408, 22
  store i64 %4418, i64* %PC, align 8
  %4419 = inttoptr i64 %4412 to double*
  store double %4417, double* %4419, align 8
  %4420 = load i64, i64* %RBP, align 8
  %4421 = add i64 %4420, -96
  %4422 = load i64, i64* %PC, align 8
  %4423 = add i64 %4422, 5
  store i64 %4423, i64* %PC, align 8
  %4424 = inttoptr i64 %4421 to i64*
  %4425 = load i64, i64* %4424, align 8
  %4426 = load i64, i64* %RAX, align 8
  %4427 = xor i64 %4426, %4425
  store i64 %4427, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2433
  %4428 = trunc i64 %4427 to i32
  %4429 = and i32 %4428, 255
  %4430 = tail call i32 @llvm.ctpop.i32(i32 %4429) #10
  %4431 = trunc i32 %4430 to i8
  %4432 = and i8 %4431, 1
  %4433 = xor i8 %4432, 1
  store i8 %4433, i8* %23, align 1, !tbaa !2447
  %4434 = icmp eq i64 %4427, 0
  %4435 = zext i1 %4434 to i8
  store i8 %4435, i8* %32, align 1, !tbaa !2448
  %4436 = lshr i64 %4427, 63
  %4437 = trunc i64 %4436 to i8
  store i8 %4437, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2451
  store i64 %4427, i64* %94, align 1, !tbaa !2428
  store i64 0, i64* %95, align 1, !tbaa !2428
  %4438 = add i64 %4420, -120
  %4439 = add i64 %4422, 23
  store i64 %4439, i64* %PC, align 8
  %.cast9 = bitcast i64 %4427 to double
  %4440 = inttoptr i64 %4438 to double*
  %4441 = load double, double* %4440, align 8
  %4442 = fmul double %.cast9, %4441
  store double %4442, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4443 = add i64 %4420, -88
  %4444 = add i64 %4422, 28
  store i64 %4444, i64* %PC, align 8
  %4445 = inttoptr i64 %4443 to i64*
  %4446 = load i64, i64* %4445, align 8
  store i64 %4446, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %4447 = add i64 %4420, -128
  %4448 = add i64 %4422, 33
  store i64 %4448, i64* %PC, align 8
  %4449 = bitcast i64 %4446 to double
  %4450 = inttoptr i64 %4447 to double*
  %4451 = load double, double* %4450, align 8
  %4452 = fmul double %4449, %4451
  store double %4452, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %4453 = fsub double %4442, %4452
  store double %4453, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4454 = add i64 %4420, -16
  %4455 = add i64 %4422, 41
  store i64 %4455, i64* %PC, align 8
  %4456 = inttoptr i64 %4454 to i64*
  %4457 = load i64, i64* %4456, align 8
  store i64 %4457, i64* %RDX, align 8, !tbaa !2428
  %4458 = add i64 %4420, -36
  %4459 = add i64 %4422, 45
  store i64 %4459, i64* %PC, align 8
  %4460 = inttoptr i64 %4458 to i32*
  %4461 = load i32, i32* %4460, align 4
  %4462 = sext i32 %4461 to i64
  store i64 %4462, i64* %RSI, align 8, !tbaa !2428
  %4463 = shl nsw i64 %4462, 3
  %4464 = add i64 %4463, %4457
  %4465 = add i64 %4422, 50
  store i64 %4465, i64* %PC, align 8
  %4466 = inttoptr i64 %4464 to double*
  store double %4453, double* %4466, align 8
  %4467 = load i64, i64* %RBP, align 8
  %4468 = add i64 %4467, -96
  %4469 = load i64, i64* %PC, align 8
  %4470 = add i64 %4469, 5
  store i64 %4470, i64* %PC, align 8
  %4471 = inttoptr i64 %4468 to i64*
  %4472 = load i64, i64* %4471, align 8
  %4473 = load i64, i64* %RAX, align 8
  %4474 = xor i64 %4473, %4472
  store i64 %4474, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2433
  %4475 = trunc i64 %4474 to i32
  %4476 = and i32 %4475, 255
  %4477 = tail call i32 @llvm.ctpop.i32(i32 %4476) #10
  %4478 = trunc i32 %4477 to i8
  %4479 = and i8 %4478, 1
  %4480 = xor i8 %4479, 1
  store i8 %4480, i8* %23, align 1, !tbaa !2447
  %4481 = icmp eq i64 %4474, 0
  %4482 = zext i1 %4481 to i8
  store i8 %4482, i8* %32, align 1, !tbaa !2448
  %4483 = lshr i64 %4474, 63
  %4484 = trunc i64 %4483 to i8
  store i8 %4484, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2451
  store i64 %4474, i64* %94, align 1, !tbaa !2428
  store i64 0, i64* %95, align 1, !tbaa !2428
  %4485 = add i64 %4467, -128
  %4486 = add i64 %4469, 23
  store i64 %4486, i64* %PC, align 8
  %.cast10 = bitcast i64 %4474 to double
  %4487 = inttoptr i64 %4485 to double*
  %4488 = load double, double* %4487, align 8
  %4489 = fmul double %.cast10, %4488
  store double %4489, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4490 = add i64 %4467, -88
  %4491 = add i64 %4469, 28
  store i64 %4491, i64* %PC, align 8
  %4492 = inttoptr i64 %4490 to i64*
  %4493 = load i64, i64* %4492, align 8
  store i64 %4493, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %4494 = add i64 %4467, -120
  %4495 = add i64 %4469, 33
  store i64 %4495, i64* %PC, align 8
  %4496 = bitcast i64 %4493 to double
  %4497 = inttoptr i64 %4494 to double*
  %4498 = load double, double* %4497, align 8
  %4499 = fmul double %4496, %4498
  store double %4499, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %4500 = fadd double %4489, %4499
  store double %4500, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4501 = add i64 %4467, -16
  %4502 = add i64 %4469, 41
  store i64 %4502, i64* %PC, align 8
  %4503 = inttoptr i64 %4501 to i64*
  %4504 = load i64, i64* %4503, align 8
  store i64 %4504, i64* %RAX, align 8, !tbaa !2428
  %4505 = add i64 %4467, -36
  %4506 = add i64 %4469, 44
  store i64 %4506, i64* %PC, align 8
  %4507 = inttoptr i64 %4505 to i32*
  %4508 = load i32, i32* %4507, align 4
  %4509 = add i32 %4508, 1
  %4510 = zext i32 %4509 to i64
  store i64 %4510, i64* %RCX, align 8, !tbaa !2428
  %4511 = icmp eq i32 %4508, -1
  %4512 = icmp eq i32 %4509, 0
  %4513 = or i1 %4511, %4512
  %4514 = zext i1 %4513 to i8
  store i8 %4514, i8* %16, align 1, !tbaa !2433
  %4515 = and i32 %4509, 255
  %4516 = tail call i32 @llvm.ctpop.i32(i32 %4515) #10
  %4517 = trunc i32 %4516 to i8
  %4518 = and i8 %4517, 1
  %4519 = xor i8 %4518, 1
  store i8 %4519, i8* %23, align 1, !tbaa !2447
  %4520 = xor i32 %4509, %4508
  %4521 = lshr i32 %4520, 4
  %4522 = trunc i32 %4521 to i8
  %4523 = and i8 %4522, 1
  store i8 %4523, i8* %29, align 1, !tbaa !2451
  %4524 = zext i1 %4512 to i8
  store i8 %4524, i8* %32, align 1, !tbaa !2448
  %4525 = lshr i32 %4509, 31
  %4526 = trunc i32 %4525 to i8
  store i8 %4526, i8* %35, align 1, !tbaa !2449
  %4527 = lshr i32 %4508, 31
  %4528 = xor i32 %4525, %4527
  %4529 = add nuw nsw i32 %4528, %4525
  %4530 = icmp eq i32 %4529, 2
  %4531 = zext i1 %4530 to i8
  store i8 %4531, i8* %41, align 1, !tbaa !2450
  %4532 = sext i32 %4509 to i64
  store i64 %4532, i64* %RDX, align 8, !tbaa !2428
  %4533 = shl nsw i64 %4532, 3
  %4534 = add i64 %4504, %4533
  %4535 = add i64 %4469, 55
  store i64 %4535, i64* %PC, align 8
  %4536 = inttoptr i64 %4534 to double*
  store double %4500, double* %4536, align 8
  %4537 = load i64, i64* %RBP, align 8
  %4538 = add i64 %4537, -136
  %4539 = load i64, i64* %PC, align 8
  %4540 = add i64 %4539, 8
  store i64 %4540, i64* %PC, align 8
  %4541 = inttoptr i64 %4538 to i64*
  %4542 = load i64, i64* %4541, align 8
  store i64 %4542, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4543 = add i64 %4537, -176
  %4544 = add i64 %4539, 16
  store i64 %4544, i64* %PC, align 8
  %4545 = bitcast i64 %4542 to double
  %4546 = inttoptr i64 %4543 to double*
  %4547 = load double, double* %4546, align 8
  %4548 = fsub double %4545, %4547
  store double %4548, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4549 = add i64 %4537, -120
  %4550 = add i64 %4539, 21
  store i64 %4550, i64* %PC, align 8
  %4551 = inttoptr i64 %4549 to double*
  store double %4548, double* %4551, align 8
  %4552 = load i64, i64* %RBP, align 8
  %4553 = add i64 %4552, -144
  %4554 = load i64, i64* %PC, align 8
  %4555 = add i64 %4554, 8
  store i64 %4555, i64* %PC, align 8
  %4556 = inttoptr i64 %4553 to i64*
  %4557 = load i64, i64* %4556, align 8
  store i64 %4557, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4558 = add i64 %4552, -168
  %4559 = add i64 %4554, 16
  store i64 %4559, i64* %PC, align 8
  %4560 = bitcast i64 %4557 to double
  %4561 = inttoptr i64 %4558 to double*
  %4562 = load double, double* %4561, align 8
  %4563 = fadd double %4560, %4562
  store double %4563, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4564 = add i64 %4552, -128
  %4565 = add i64 %4554, 21
  store i64 %4565, i64* %PC, align 8
  %4566 = inttoptr i64 %4564 to double*
  store double %4563, double* %4566, align 8
  %4567 = load i64, i64* %RBP, align 8
  %4568 = add i64 %4567, -72
  %4569 = load i64, i64* %PC, align 8
  %4570 = add i64 %4569, 5
  store i64 %4570, i64* %PC, align 8
  %4571 = inttoptr i64 %4568 to i64*
  %4572 = load i64, i64* %4571, align 8
  store i64 %4572, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4573 = add i64 %4567, -120
  %4574 = add i64 %4569, 10
  store i64 %4574, i64* %PC, align 8
  %4575 = bitcast i64 %4572 to double
  %4576 = inttoptr i64 %4573 to double*
  %4577 = load double, double* %4576, align 8
  %4578 = fmul double %4575, %4577
  store double %4578, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4579 = add i64 %4567, -80
  %4580 = add i64 %4569, 15
  store i64 %4580, i64* %PC, align 8
  %4581 = inttoptr i64 %4579 to i64*
  %4582 = load i64, i64* %4581, align 8
  store i64 %4582, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %4583 = add i64 %4567, -128
  %4584 = add i64 %4569, 20
  store i64 %4584, i64* %PC, align 8
  %4585 = bitcast i64 %4582 to double
  %4586 = inttoptr i64 %4583 to double*
  %4587 = load double, double* %4586, align 8
  %4588 = fmul double %4585, %4587
  store double %4588, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %4589 = fsub double %4578, %4588
  store double %4589, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4590 = add i64 %4567, -16
  %4591 = add i64 %4569, 28
  store i64 %4591, i64* %PC, align 8
  %4592 = inttoptr i64 %4590 to i64*
  %4593 = load i64, i64* %4592, align 8
  store i64 %4593, i64* %RAX, align 8, !tbaa !2428
  %4594 = add i64 %4567, -32
  %4595 = add i64 %4569, 32
  store i64 %4595, i64* %PC, align 8
  %4596 = inttoptr i64 %4594 to i32*
  %4597 = load i32, i32* %4596, align 4
  %4598 = sext i32 %4597 to i64
  store i64 %4598, i64* %RDX, align 8, !tbaa !2428
  %4599 = shl nsw i64 %4598, 3
  %4600 = add i64 %4599, %4593
  %4601 = add i64 %4569, 37
  store i64 %4601, i64* %PC, align 8
  %4602 = inttoptr i64 %4600 to double*
  store double %4589, double* %4602, align 8
  %4603 = load i64, i64* %RBP, align 8
  %4604 = add i64 %4603, -72
  %4605 = load i64, i64* %PC, align 8
  %4606 = add i64 %4605, 5
  store i64 %4606, i64* %PC, align 8
  %4607 = inttoptr i64 %4604 to i64*
  %4608 = load i64, i64* %4607, align 8
  store i64 %4608, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4609 = add i64 %4603, -128
  %4610 = add i64 %4605, 10
  store i64 %4610, i64* %PC, align 8
  %4611 = bitcast i64 %4608 to double
  %4612 = inttoptr i64 %4609 to double*
  %4613 = load double, double* %4612, align 8
  %4614 = fmul double %4611, %4613
  store double %4614, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4615 = add i64 %4603, -80
  %4616 = add i64 %4605, 15
  store i64 %4616, i64* %PC, align 8
  %4617 = inttoptr i64 %4615 to i64*
  %4618 = load i64, i64* %4617, align 8
  store i64 %4618, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %4619 = add i64 %4603, -120
  %4620 = add i64 %4605, 20
  store i64 %4620, i64* %PC, align 8
  %4621 = bitcast i64 %4618 to double
  %4622 = inttoptr i64 %4619 to double*
  %4623 = load double, double* %4622, align 8
  %4624 = fmul double %4621, %4623
  store double %4624, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %4625 = fadd double %4614, %4624
  store double %4625, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4626 = add i64 %4603, -16
  %4627 = add i64 %4605, 28
  store i64 %4627, i64* %PC, align 8
  %4628 = inttoptr i64 %4626 to i64*
  %4629 = load i64, i64* %4628, align 8
  store i64 %4629, i64* %RAX, align 8, !tbaa !2428
  %4630 = add i64 %4603, -32
  %4631 = add i64 %4605, 31
  store i64 %4631, i64* %PC, align 8
  %4632 = inttoptr i64 %4630 to i32*
  %4633 = load i32, i32* %4632, align 4
  %4634 = add i32 %4633, 1
  %4635 = zext i32 %4634 to i64
  store i64 %4635, i64* %RCX, align 8, !tbaa !2428
  %4636 = icmp eq i32 %4633, -1
  %4637 = icmp eq i32 %4634, 0
  %4638 = or i1 %4636, %4637
  %4639 = zext i1 %4638 to i8
  store i8 %4639, i8* %16, align 1, !tbaa !2433
  %4640 = and i32 %4634, 255
  %4641 = tail call i32 @llvm.ctpop.i32(i32 %4640) #10
  %4642 = trunc i32 %4641 to i8
  %4643 = and i8 %4642, 1
  %4644 = xor i8 %4643, 1
  store i8 %4644, i8* %23, align 1, !tbaa !2447
  %4645 = xor i32 %4634, %4633
  %4646 = lshr i32 %4645, 4
  %4647 = trunc i32 %4646 to i8
  %4648 = and i8 %4647, 1
  store i8 %4648, i8* %29, align 1, !tbaa !2451
  %4649 = zext i1 %4637 to i8
  store i8 %4649, i8* %32, align 1, !tbaa !2448
  %4650 = lshr i32 %4634, 31
  %4651 = trunc i32 %4650 to i8
  store i8 %4651, i8* %35, align 1, !tbaa !2449
  %4652 = lshr i32 %4633, 31
  %4653 = xor i32 %4650, %4652
  %4654 = add nuw nsw i32 %4653, %4650
  %4655 = icmp eq i32 %4654, 2
  %4656 = zext i1 %4655 to i8
  store i8 %4656, i8* %41, align 1, !tbaa !2450
  %4657 = sext i32 %4634 to i64
  store i64 %4657, i64* %RDX, align 8, !tbaa !2428
  %4658 = shl nsw i64 %4657, 3
  %4659 = add i64 %4629, %4658
  %4660 = add i64 %4605, 42
  store i64 %4660, i64* %PC, align 8
  %4661 = inttoptr i64 %4659 to double*
  store double %4625, double* %4661, align 8
  %4662 = load i64, i64* %RBP, align 8
  %4663 = add i64 %4662, -136
  %4664 = load i64, i64* %PC, align 8
  %4665 = add i64 %4664, 8
  store i64 %4665, i64* %PC, align 8
  %4666 = inttoptr i64 %4663 to i64*
  %4667 = load i64, i64* %4666, align 8
  store i64 %4667, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4668 = add i64 %4662, -176
  %4669 = add i64 %4664, 16
  store i64 %4669, i64* %PC, align 8
  %4670 = bitcast i64 %4667 to double
  %4671 = inttoptr i64 %4668 to double*
  %4672 = load double, double* %4671, align 8
  %4673 = fadd double %4670, %4672
  store double %4673, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4674 = add i64 %4662, -120
  %4675 = add i64 %4664, 21
  store i64 %4675, i64* %PC, align 8
  %4676 = inttoptr i64 %4674 to double*
  store double %4673, double* %4676, align 8
  %4677 = load i64, i64* %RBP, align 8
  %4678 = add i64 %4677, -144
  %4679 = load i64, i64* %PC, align 8
  %4680 = add i64 %4679, 8
  store i64 %4680, i64* %PC, align 8
  %4681 = inttoptr i64 %4678 to i64*
  %4682 = load i64, i64* %4681, align 8
  store i64 %4682, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4683 = add i64 %4677, -168
  %4684 = add i64 %4679, 16
  store i64 %4684, i64* %PC, align 8
  %4685 = bitcast i64 %4682 to double
  %4686 = inttoptr i64 %4683 to double*
  %4687 = load double, double* %4686, align 8
  %4688 = fsub double %4685, %4687
  store double %4688, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4689 = add i64 %4677, -128
  %4690 = add i64 %4679, 21
  store i64 %4690, i64* %PC, align 8
  %4691 = inttoptr i64 %4689 to double*
  store double %4688, double* %4691, align 8
  %4692 = load i64, i64* %RBP, align 8
  %4693 = add i64 %4692, -104
  %4694 = load i64, i64* %PC, align 8
  %4695 = add i64 %4694, 5
  store i64 %4695, i64* %PC, align 8
  %4696 = inttoptr i64 %4693 to i64*
  %4697 = load i64, i64* %4696, align 8
  store i64 %4697, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4698 = add i64 %4692, -120
  %4699 = add i64 %4694, 10
  store i64 %4699, i64* %PC, align 8
  %4700 = bitcast i64 %4697 to double
  %4701 = inttoptr i64 %4698 to double*
  %4702 = load double, double* %4701, align 8
  %4703 = fmul double %4700, %4702
  store double %4703, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4704 = add i64 %4692, -112
  %4705 = add i64 %4694, 15
  store i64 %4705, i64* %PC, align 8
  %4706 = inttoptr i64 %4704 to i64*
  %4707 = load i64, i64* %4706, align 8
  store i64 %4707, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %4708 = add i64 %4692, -128
  %4709 = add i64 %4694, 20
  store i64 %4709, i64* %PC, align 8
  %4710 = bitcast i64 %4707 to double
  %4711 = inttoptr i64 %4708 to double*
  %4712 = load double, double* %4711, align 8
  %4713 = fmul double %4710, %4712
  store double %4713, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %4714 = fsub double %4703, %4713
  store double %4714, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4715 = add i64 %4692, -16
  %4716 = add i64 %4694, 28
  store i64 %4716, i64* %PC, align 8
  %4717 = inttoptr i64 %4715 to i64*
  %4718 = load i64, i64* %4717, align 8
  store i64 %4718, i64* %RAX, align 8, !tbaa !2428
  %4719 = add i64 %4692, -40
  %4720 = add i64 %4694, 32
  store i64 %4720, i64* %PC, align 8
  %4721 = inttoptr i64 %4719 to i32*
  %4722 = load i32, i32* %4721, align 4
  %4723 = sext i32 %4722 to i64
  store i64 %4723, i64* %RDX, align 8, !tbaa !2428
  %4724 = shl nsw i64 %4723, 3
  %4725 = add i64 %4724, %4718
  %4726 = add i64 %4694, 37
  store i64 %4726, i64* %PC, align 8
  %4727 = inttoptr i64 %4725 to double*
  store double %4714, double* %4727, align 8
  %4728 = load i64, i64* %RBP, align 8
  %4729 = add i64 %4728, -104
  %4730 = load i64, i64* %PC, align 8
  %4731 = add i64 %4730, 5
  store i64 %4731, i64* %PC, align 8
  %4732 = inttoptr i64 %4729 to i64*
  %4733 = load i64, i64* %4732, align 8
  store i64 %4733, i64* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4734 = add i64 %4728, -128
  %4735 = add i64 %4730, 10
  store i64 %4735, i64* %PC, align 8
  %4736 = bitcast i64 %4733 to double
  %4737 = inttoptr i64 %4734 to double*
  %4738 = load double, double* %4737, align 8
  %4739 = fmul double %4736, %4738
  store double %4739, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4740 = add i64 %4728, -112
  %4741 = add i64 %4730, 15
  store i64 %4741, i64* %PC, align 8
  %4742 = inttoptr i64 %4740 to i64*
  %4743 = load i64, i64* %4742, align 8
  store i64 %4743, i64* %120, align 1, !tbaa !2452
  store double 0.000000e+00, double* %122, align 1, !tbaa !2452
  %4744 = add i64 %4728, -120
  %4745 = add i64 %4730, 20
  store i64 %4745, i64* %PC, align 8
  %4746 = bitcast i64 %4743 to double
  %4747 = inttoptr i64 %4744 to double*
  %4748 = load double, double* %4747, align 8
  %4749 = fmul double %4746, %4748
  store double %4749, double* %119, align 1, !tbaa !2452
  store i64 0, i64* %121, align 1, !tbaa !2452
  %4750 = fadd double %4739, %4749
  store double %4750, double* %93, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4751 = add i64 %4728, -16
  %4752 = add i64 %4730, 28
  store i64 %4752, i64* %PC, align 8
  %4753 = inttoptr i64 %4751 to i64*
  %4754 = load i64, i64* %4753, align 8
  store i64 %4754, i64* %RAX, align 8, !tbaa !2428
  %4755 = add i64 %4728, -40
  %4756 = add i64 %4730, 31
  store i64 %4756, i64* %PC, align 8
  %4757 = inttoptr i64 %4755 to i32*
  %4758 = load i32, i32* %4757, align 4
  %4759 = add i32 %4758, 1
  %4760 = zext i32 %4759 to i64
  store i64 %4760, i64* %RCX, align 8, !tbaa !2428
  %4761 = icmp eq i32 %4758, -1
  %4762 = icmp eq i32 %4759, 0
  %4763 = or i1 %4761, %4762
  %4764 = zext i1 %4763 to i8
  store i8 %4764, i8* %16, align 1, !tbaa !2433
  %4765 = and i32 %4759, 255
  %4766 = tail call i32 @llvm.ctpop.i32(i32 %4765) #10
  %4767 = trunc i32 %4766 to i8
  %4768 = and i8 %4767, 1
  %4769 = xor i8 %4768, 1
  store i8 %4769, i8* %23, align 1, !tbaa !2447
  %4770 = xor i32 %4759, %4758
  %4771 = lshr i32 %4770, 4
  %4772 = trunc i32 %4771 to i8
  %4773 = and i8 %4772, 1
  store i8 %4773, i8* %29, align 1, !tbaa !2451
  %4774 = zext i1 %4762 to i8
  store i8 %4774, i8* %32, align 1, !tbaa !2448
  %4775 = lshr i32 %4759, 31
  %4776 = trunc i32 %4775 to i8
  store i8 %4776, i8* %35, align 1, !tbaa !2449
  %4777 = lshr i32 %4758, 31
  %4778 = xor i32 %4775, %4777
  %4779 = add nuw nsw i32 %4778, %4775
  %4780 = icmp eq i32 %4779, 2
  %4781 = zext i1 %4780 to i8
  store i8 %4781, i8* %41, align 1, !tbaa !2450
  %4782 = sext i32 %4759 to i64
  store i64 %4782, i64* %RDX, align 8, !tbaa !2428
  %4783 = shl nsw i64 %4782, 3
  %4784 = add i64 %4754, %4783
  %4785 = add i64 %4730, 42
  store i64 %4785, i64* %PC, align 8
  %4786 = inttoptr i64 %4784 to double*
  store double %4750, double* %4786, align 8
  %4787 = load i64, i64* %RBP, align 8
  %4788 = add i64 %4787, -28
  %4789 = load i64, i64* %PC, align 8
  %4790 = add i64 %4789, 3
  store i64 %4790, i64* %PC, align 8
  %4791 = inttoptr i64 %4788 to i32*
  %4792 = load i32, i32* %4791, align 4
  %4793 = add i32 %4792, 2
  %4794 = zext i32 %4793 to i64
  store i64 %4794, i64* %RAX, align 8, !tbaa !2428
  %4795 = icmp ugt i32 %4792, -3
  %4796 = zext i1 %4795 to i8
  store i8 %4796, i8* %16, align 1, !tbaa !2433
  %4797 = and i32 %4793, 255
  %4798 = tail call i32 @llvm.ctpop.i32(i32 %4797) #10
  %4799 = trunc i32 %4798 to i8
  %4800 = and i8 %4799, 1
  %4801 = xor i8 %4800, 1
  store i8 %4801, i8* %23, align 1, !tbaa !2447
  %4802 = xor i32 %4793, %4792
  %4803 = lshr i32 %4802, 4
  %4804 = trunc i32 %4803 to i8
  %4805 = and i8 %4804, 1
  store i8 %4805, i8* %29, align 1, !tbaa !2451
  %4806 = icmp eq i32 %4793, 0
  %4807 = zext i1 %4806 to i8
  store i8 %4807, i8* %32, align 1, !tbaa !2448
  %4808 = lshr i32 %4793, 31
  %4809 = trunc i32 %4808 to i8
  store i8 %4809, i8* %35, align 1, !tbaa !2449
  %4810 = lshr i32 %4792, 31
  %4811 = xor i32 %4808, %4810
  %4812 = add nuw nsw i32 %4811, %4808
  %4813 = icmp eq i32 %4812, 2
  %4814 = zext i1 %4813 to i8
  store i8 %4814, i8* %41, align 1, !tbaa !2450
  %4815 = add i64 %4789, 9
  store i64 %4815, i64* %PC, align 8
  store i32 %4793, i32* %4791, align 4
  %4816 = load i64, i64* %PC, align 8
  %4817 = add i64 %4816, -822
  store i64 %4817, i64* %PC, align 8, !tbaa !2428
  br label %block_403cb0

block_403346:                                     ; preds = %block_403352, %block_403320
  %4818 = phi i64 [ %1249, %block_403352 ], [ %.pre, %block_403320 ]
  %4819 = load i64, i64* %RBP, align 8
  %4820 = add i64 %4819, -28
  %4821 = add i64 %4818, 3
  store i64 %4821, i64* %PC, align 8
  %4822 = inttoptr i64 %4820 to i32*
  %4823 = load i32, i32* %4822, align 4
  %4824 = zext i32 %4823 to i64
  store i64 %4824, i64* %RAX, align 8, !tbaa !2428
  %4825 = add i64 %4819, -8
  %4826 = add i64 %4818, 6
  store i64 %4826, i64* %PC, align 8
  %4827 = inttoptr i64 %4825 to i32*
  %4828 = load i32, i32* %4827, align 4
  %4829 = sub i32 %4823, %4828
  %4830 = icmp ult i32 %4823, %4828
  %4831 = zext i1 %4830 to i8
  store i8 %4831, i8* %16, align 1, !tbaa !2433
  %4832 = and i32 %4829, 255
  %4833 = tail call i32 @llvm.ctpop.i32(i32 %4832) #10
  %4834 = trunc i32 %4833 to i8
  %4835 = and i8 %4834, 1
  %4836 = xor i8 %4835, 1
  store i8 %4836, i8* %23, align 1, !tbaa !2447
  %4837 = xor i32 %4828, %4823
  %4838 = xor i32 %4837, %4829
  %4839 = lshr i32 %4838, 4
  %4840 = trunc i32 %4839 to i8
  %4841 = and i8 %4840, 1
  store i8 %4841, i8* %29, align 1, !tbaa !2451
  %4842 = icmp eq i32 %4829, 0
  %4843 = zext i1 %4842 to i8
  store i8 %4843, i8* %32, align 1, !tbaa !2448
  %4844 = lshr i32 %4829, 31
  %4845 = trunc i32 %4844 to i8
  store i8 %4845, i8* %35, align 1, !tbaa !2449
  %4846 = lshr i32 %4823, 31
  %4847 = lshr i32 %4828, 31
  %4848 = xor i32 %4847, %4846
  %4849 = xor i32 %4844, %4846
  %4850 = add nuw nsw i32 %4849, %4848
  %4851 = icmp eq i32 %4850, 2
  %4852 = zext i1 %4851 to i8
  store i8 %4852, i8* %41, align 1, !tbaa !2450
  %4853 = icmp ne i8 %4845, 0
  %4854 = xor i1 %4853, %4851
  %.v = select i1 %4854, i64 12, i64 599
  %4855 = add i64 %4818, %.v
  store i64 %4855, i64* %PC, align 8, !tbaa !2428
  br i1 %4854, label %block_403352, label %block_40359d
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_404084__term_proc(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_404084:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = xor i64 %4, %3
  %8 = lshr i64 %7, 4
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %13 = lshr i64 %4, 63
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %15 = lshr i64 %3, 63
  %16 = xor i64 %13, %15
  %17 = add nuw nsw i64 %16, %15
  %18 = icmp eq i64 %17, 2
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %3, i64* %RSP, align 8, !tbaa !2428
  %21 = icmp ult i64 %3, 8
  %22 = zext i1 %21 to i8
  store i8 %22, i8* %5, align 1, !tbaa !2433
  %23 = trunc i64 %3 to i32
  %24 = and i32 %23, 255
  %25 = tail call i32 @llvm.ctpop.i32(i32 %24) #10
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = xor i8 %27, 1
  store i8 %28, i8* %6, align 1, !tbaa !2447
  store i8 %10, i8* %11, align 1, !tbaa !2451
  %29 = icmp eq i64 %3, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %12, align 1, !tbaa !2448
  %31 = trunc i64 %15 to i8
  store i8 %31, i8* %14, align 1, !tbaa !2449
  store i8 %19, i8* %20, align 1, !tbaa !2450
  %32 = add i64 %1, 9
  store i64 %32, i64* %PC, align 8
  %33 = inttoptr i64 %3 to i64*
  %34 = load i64, i64* %33, align 8
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  %35 = add i64 %3, 8
  store i64 %35, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_401860_cftfsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #7 {
block_401860:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -120
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 112
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2433
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #10
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2447
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2451
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %7, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %10, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -44
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 7
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  store i32 2, i32* %60, align 4
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -4
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = add i32 %66, -8
  %68 = icmp ult i32 %66, 8
  %69 = zext i1 %68 to i8
  store i8 %69, i8* %14, align 1, !tbaa !2433
  %70 = and i32 %67, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #10
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %21, align 1, !tbaa !2447
  %75 = xor i32 %67, %66
  %76 = lshr i32 %75, 4
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %27, align 1, !tbaa !2451
  %79 = icmp eq i32 %67, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %30, align 1, !tbaa !2448
  %81 = lshr i32 %67, 31
  %82 = trunc i32 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2449
  %83 = lshr i32 %66, 31
  %84 = xor i32 %81, %83
  %85 = add nuw nsw i32 %84, %83
  %86 = icmp eq i32 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %39, align 1, !tbaa !2450
  %88 = icmp ne i8 %82, 0
  %89 = xor i1 %88, %86
  %90 = or i1 %79, %89
  %.v14 = select i1 %90, i64 86, i64 10
  %91 = add i64 %63, %.v14
  store i64 %91, i64* %PC, align 8, !tbaa !2428
  br i1 %90, label %block_4018d0, label %block_401884

block_401b13:                                     ; preds = %block_401b13.preheader, %block_401b1f
  %92 = phi i64 [ %1483, %block_401b1f ], [ %.pre12, %block_401b13.preheader ]
  %93 = load i64, i64* %RBP, align 8
  %94 = add i64 %93, -28
  %95 = add i64 %92, 3
  store i64 %95, i64* %PC, align 8
  %96 = inttoptr i64 %94 to i32*
  %97 = load i32, i32* %96, align 4
  %98 = zext i32 %97 to i64
  store i64 %98, i64* %RAX, align 8, !tbaa !2428
  %99 = add i64 %93, -44
  %100 = add i64 %92, 6
  store i64 %100, i64* %PC, align 8
  %101 = inttoptr i64 %99 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = sub i32 %97, %102
  %104 = icmp ult i32 %97, %102
  %105 = zext i1 %104 to i8
  store i8 %105, i8* %14, align 1, !tbaa !2433
  %106 = and i32 %103, 255
  %107 = tail call i32 @llvm.ctpop.i32(i32 %106) #10
  %108 = trunc i32 %107 to i8
  %109 = and i8 %108, 1
  %110 = xor i8 %109, 1
  store i8 %110, i8* %21, align 1, !tbaa !2447
  %111 = xor i32 %102, %97
  %112 = xor i32 %111, %103
  %113 = lshr i32 %112, 4
  %114 = trunc i32 %113 to i8
  %115 = and i8 %114, 1
  store i8 %115, i8* %27, align 1, !tbaa !2451
  %116 = icmp eq i32 %103, 0
  %117 = zext i1 %116 to i8
  store i8 %117, i8* %30, align 1, !tbaa !2448
  %118 = lshr i32 %103, 31
  %119 = trunc i32 %118 to i8
  store i8 %119, i8* %33, align 1, !tbaa !2449
  %120 = lshr i32 %97, 31
  %121 = lshr i32 %102, 31
  %122 = xor i32 %121, %120
  %123 = xor i32 %118, %120
  %124 = add nuw nsw i32 %123, %122
  %125 = icmp eq i32 %124, 2
  %126 = zext i1 %125 to i8
  store i8 %126, i8* %39, align 1, !tbaa !2450
  %127 = icmp ne i8 %119, 0
  %128 = xor i1 %127, %125
  %.v16 = select i1 %128, i64 12, i64 220
  %129 = add i64 %92, %.v16
  store i64 %129, i64* %PC, align 8, !tbaa !2428
  br i1 %128, label %block_401b1f, label %block_401bf4.loopexit26

block_4018f2:                                     ; preds = %block_4018e6
  %130 = add i64 %1599, 3
  store i64 %130, i64* %PC, align 8
  %131 = load i32, i32* %1566, align 4
  %132 = zext i32 %131 to i64
  store i64 %132, i64* %RAX, align 8, !tbaa !2428
  %133 = add i64 %1599, 6
  store i64 %133, i64* %PC, align 8
  %134 = load i32, i32* %1571, align 4
  %135 = add i32 %134, %131
  %136 = zext i32 %135 to i64
  store i64 %136, i64* %RAX, align 8, !tbaa !2428
  %137 = icmp ult i32 %135, %131
  %138 = icmp ult i32 %135, %134
  %139 = or i1 %137, %138
  %140 = zext i1 %139 to i8
  store i8 %140, i8* %14, align 1, !tbaa !2433
  %141 = and i32 %135, 255
  %142 = tail call i32 @llvm.ctpop.i32(i32 %141) #10
  %143 = trunc i32 %142 to i8
  %144 = and i8 %143, 1
  %145 = xor i8 %144, 1
  store i8 %145, i8* %21, align 1, !tbaa !2447
  %146 = xor i32 %134, %131
  %147 = xor i32 %146, %135
  %148 = lshr i32 %147, 4
  %149 = trunc i32 %148 to i8
  %150 = and i8 %149, 1
  store i8 %150, i8* %27, align 1, !tbaa !2451
  %151 = icmp eq i32 %135, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %30, align 1, !tbaa !2448
  %153 = lshr i32 %135, 31
  %154 = trunc i32 %153 to i8
  store i8 %154, i8* %33, align 1, !tbaa !2449
  %155 = lshr i32 %131, 31
  %156 = lshr i32 %134, 31
  %157 = xor i32 %153, %155
  %158 = xor i32 %153, %156
  %159 = add nuw nsw i32 %157, %158
  %160 = icmp eq i32 %159, 2
  %161 = zext i1 %160 to i8
  store i8 %161, i8* %39, align 1, !tbaa !2450
  %162 = add i64 %1563, -32
  %163 = add i64 %1599, 9
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %162 to i32*
  store i32 %135, i32* %164, align 4
  %165 = load i64, i64* %RBP, align 8
  %166 = add i64 %165, -32
  %167 = load i64, i64* %PC, align 8
  %168 = add i64 %167, 3
  store i64 %168, i64* %PC, align 8
  %169 = inttoptr i64 %166 to i32*
  %170 = load i32, i32* %169, align 4
  %171 = zext i32 %170 to i64
  store i64 %171, i64* %RAX, align 8, !tbaa !2428
  %172 = add i64 %165, -44
  %173 = add i64 %167, 6
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i32*
  %175 = load i32, i32* %174, align 4
  %176 = add i32 %175, %170
  %177 = zext i32 %176 to i64
  store i64 %177, i64* %RAX, align 8, !tbaa !2428
  %178 = icmp ult i32 %176, %170
  %179 = icmp ult i32 %176, %175
  %180 = or i1 %178, %179
  %181 = zext i1 %180 to i8
  store i8 %181, i8* %14, align 1, !tbaa !2433
  %182 = and i32 %176, 255
  %183 = tail call i32 @llvm.ctpop.i32(i32 %182) #10
  %184 = trunc i32 %183 to i8
  %185 = and i8 %184, 1
  %186 = xor i8 %185, 1
  store i8 %186, i8* %21, align 1, !tbaa !2447
  %187 = xor i32 %175, %170
  %188 = xor i32 %187, %176
  %189 = lshr i32 %188, 4
  %190 = trunc i32 %189 to i8
  %191 = and i8 %190, 1
  store i8 %191, i8* %27, align 1, !tbaa !2451
  %192 = icmp eq i32 %176, 0
  %193 = zext i1 %192 to i8
  store i8 %193, i8* %30, align 1, !tbaa !2448
  %194 = lshr i32 %176, 31
  %195 = trunc i32 %194 to i8
  store i8 %195, i8* %33, align 1, !tbaa !2449
  %196 = lshr i32 %170, 31
  %197 = lshr i32 %175, 31
  %198 = xor i32 %194, %196
  %199 = xor i32 %194, %197
  %200 = add nuw nsw i32 %198, %199
  %201 = icmp eq i32 %200, 2
  %202 = zext i1 %201 to i8
  store i8 %202, i8* %39, align 1, !tbaa !2450
  %203 = add i64 %165, -36
  %204 = add i64 %167, 9
  store i64 %204, i64* %PC, align 8
  %205 = inttoptr i64 %203 to i32*
  store i32 %176, i32* %205, align 4
  %206 = load i64, i64* %RBP, align 8
  %207 = add i64 %206, -36
  %208 = load i64, i64* %PC, align 8
  %209 = add i64 %208, 3
  store i64 %209, i64* %PC, align 8
  %210 = inttoptr i64 %207 to i32*
  %211 = load i32, i32* %210, align 4
  %212 = zext i32 %211 to i64
  store i64 %212, i64* %RAX, align 8, !tbaa !2428
  %213 = add i64 %206, -44
  %214 = add i64 %208, 6
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i32*
  %216 = load i32, i32* %215, align 4
  %217 = add i32 %216, %211
  %218 = zext i32 %217 to i64
  store i64 %218, i64* %RAX, align 8, !tbaa !2428
  %219 = icmp ult i32 %217, %211
  %220 = icmp ult i32 %217, %216
  %221 = or i1 %219, %220
  %222 = zext i1 %221 to i8
  store i8 %222, i8* %14, align 1, !tbaa !2433
  %223 = and i32 %217, 255
  %224 = tail call i32 @llvm.ctpop.i32(i32 %223) #10
  %225 = trunc i32 %224 to i8
  %226 = and i8 %225, 1
  %227 = xor i8 %226, 1
  store i8 %227, i8* %21, align 1, !tbaa !2447
  %228 = xor i32 %216, %211
  %229 = xor i32 %228, %217
  %230 = lshr i32 %229, 4
  %231 = trunc i32 %230 to i8
  %232 = and i8 %231, 1
  store i8 %232, i8* %27, align 1, !tbaa !2451
  %233 = icmp eq i32 %217, 0
  %234 = zext i1 %233 to i8
  store i8 %234, i8* %30, align 1, !tbaa !2448
  %235 = lshr i32 %217, 31
  %236 = trunc i32 %235 to i8
  store i8 %236, i8* %33, align 1, !tbaa !2449
  %237 = lshr i32 %211, 31
  %238 = lshr i32 %216, 31
  %239 = xor i32 %235, %237
  %240 = xor i32 %235, %238
  %241 = add nuw nsw i32 %239, %240
  %242 = icmp eq i32 %241, 2
  %243 = zext i1 %242 to i8
  store i8 %243, i8* %39, align 1, !tbaa !2450
  %244 = add i64 %206, -40
  %245 = add i64 %208, 9
  store i64 %245, i64* %PC, align 8
  %246 = inttoptr i64 %244 to i32*
  store i32 %217, i32* %246, align 4
  %247 = load i64, i64* %RBP, align 8
  %248 = add i64 %247, -16
  %249 = load i64, i64* %PC, align 8
  %250 = add i64 %249, 4
  store i64 %250, i64* %PC, align 8
  %251 = inttoptr i64 %248 to i64*
  %252 = load i64, i64* %251, align 8
  store i64 %252, i64* %RCX, align 8, !tbaa !2428
  %253 = add i64 %247, -28
  %254 = add i64 %249, 8
  store i64 %254, i64* %PC, align 8
  %255 = inttoptr i64 %253 to i32*
  %256 = load i32, i32* %255, align 4
  %257 = sext i32 %256 to i64
  store i64 %257, i64* %RDX, align 8, !tbaa !2428
  %258 = shl nsw i64 %257, 3
  %259 = add i64 %258, %252
  %260 = add i64 %249, 13
  store i64 %260, i64* %PC, align 8
  %261 = inttoptr i64 %259 to i64*
  %262 = load i64, i64* %261, align 8
  store i64 %262, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %263 = add i64 %249, 17
  store i64 %263, i64* %PC, align 8
  %264 = load i64, i64* %251, align 8
  store i64 %264, i64* %RCX, align 8, !tbaa !2428
  %265 = add i64 %247, -32
  %266 = add i64 %249, 21
  store i64 %266, i64* %PC, align 8
  %267 = inttoptr i64 %265 to i32*
  %268 = load i32, i32* %267, align 4
  %269 = sext i32 %268 to i64
  store i64 %269, i64* %RDX, align 8, !tbaa !2428
  %270 = shl nsw i64 %269, 3
  %271 = add i64 %270, %264
  %272 = add i64 %249, 26
  store i64 %272, i64* %PC, align 8
  %273 = bitcast i64 %262 to double
  %274 = inttoptr i64 %271 to double*
  %275 = load double, double* %274, align 8
  %276 = fadd double %273, %275
  store double %276, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %277 = add i64 %247, -56
  %278 = add i64 %249, 31
  store i64 %278, i64* %PC, align 8
  %279 = inttoptr i64 %277 to double*
  store double %276, double* %279, align 8
  %280 = load i64, i64* %RBP, align 8
  %281 = add i64 %280, -16
  %282 = load i64, i64* %PC, align 8
  %283 = add i64 %282, 4
  store i64 %283, i64* %PC, align 8
  %284 = inttoptr i64 %281 to i64*
  %285 = load i64, i64* %284, align 8
  store i64 %285, i64* %RCX, align 8, !tbaa !2428
  %286 = add i64 %280, -28
  %287 = add i64 %282, 7
  store i64 %287, i64* %PC, align 8
  %288 = inttoptr i64 %286 to i32*
  %289 = load i32, i32* %288, align 4
  %290 = add i32 %289, 1
  %291 = zext i32 %290 to i64
  store i64 %291, i64* %RAX, align 8, !tbaa !2428
  %292 = icmp eq i32 %289, -1
  %293 = icmp eq i32 %290, 0
  %294 = or i1 %292, %293
  %295 = zext i1 %294 to i8
  store i8 %295, i8* %14, align 1, !tbaa !2433
  %296 = and i32 %290, 255
  %297 = tail call i32 @llvm.ctpop.i32(i32 %296) #10
  %298 = trunc i32 %297 to i8
  %299 = and i8 %298, 1
  %300 = xor i8 %299, 1
  store i8 %300, i8* %21, align 1, !tbaa !2447
  %301 = xor i32 %290, %289
  %302 = lshr i32 %301, 4
  %303 = trunc i32 %302 to i8
  %304 = and i8 %303, 1
  store i8 %304, i8* %27, align 1, !tbaa !2451
  %305 = zext i1 %293 to i8
  store i8 %305, i8* %30, align 1, !tbaa !2448
  %306 = lshr i32 %290, 31
  %307 = trunc i32 %306 to i8
  store i8 %307, i8* %33, align 1, !tbaa !2449
  %308 = lshr i32 %289, 31
  %309 = xor i32 %306, %308
  %310 = add nuw nsw i32 %309, %306
  %311 = icmp eq i32 %310, 2
  %312 = zext i1 %311 to i8
  store i8 %312, i8* %39, align 1, !tbaa !2450
  %313 = sext i32 %290 to i64
  store i64 %313, i64* %RDX, align 8, !tbaa !2428
  %314 = shl nsw i64 %313, 3
  %315 = add i64 %285, %314
  %316 = add i64 %282, 18
  store i64 %316, i64* %PC, align 8
  %317 = inttoptr i64 %315 to i64*
  %318 = load i64, i64* %317, align 8
  store i64 %318, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %319 = add i64 %282, 22
  store i64 %319, i64* %PC, align 8
  %320 = load i64, i64* %284, align 8
  store i64 %320, i64* %RCX, align 8, !tbaa !2428
  %321 = add i64 %280, -32
  %322 = add i64 %282, 25
  store i64 %322, i64* %PC, align 8
  %323 = inttoptr i64 %321 to i32*
  %324 = load i32, i32* %323, align 4
  %325 = add i32 %324, 1
  %326 = zext i32 %325 to i64
  store i64 %326, i64* %RAX, align 8, !tbaa !2428
  %327 = icmp eq i32 %324, -1
  %328 = icmp eq i32 %325, 0
  %329 = or i1 %327, %328
  %330 = zext i1 %329 to i8
  store i8 %330, i8* %14, align 1, !tbaa !2433
  %331 = and i32 %325, 255
  %332 = tail call i32 @llvm.ctpop.i32(i32 %331) #10
  %333 = trunc i32 %332 to i8
  %334 = and i8 %333, 1
  %335 = xor i8 %334, 1
  store i8 %335, i8* %21, align 1, !tbaa !2447
  %336 = xor i32 %325, %324
  %337 = lshr i32 %336, 4
  %338 = trunc i32 %337 to i8
  %339 = and i8 %338, 1
  store i8 %339, i8* %27, align 1, !tbaa !2451
  %340 = zext i1 %328 to i8
  store i8 %340, i8* %30, align 1, !tbaa !2448
  %341 = lshr i32 %325, 31
  %342 = trunc i32 %341 to i8
  store i8 %342, i8* %33, align 1, !tbaa !2449
  %343 = lshr i32 %324, 31
  %344 = xor i32 %341, %343
  %345 = add nuw nsw i32 %344, %341
  %346 = icmp eq i32 %345, 2
  %347 = zext i1 %346 to i8
  store i8 %347, i8* %39, align 1, !tbaa !2450
  %348 = sext i32 %325 to i64
  store i64 %348, i64* %RDX, align 8, !tbaa !2428
  %349 = shl nsw i64 %348, 3
  %350 = add i64 %320, %349
  %351 = add i64 %282, 36
  store i64 %351, i64* %PC, align 8
  %352 = bitcast i64 %318 to double
  %353 = inttoptr i64 %350 to double*
  %354 = load double, double* %353, align 8
  %355 = fadd double %352, %354
  store double %355, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %356 = load i64, i64* %RBP, align 8
  %357 = add i64 %356, -64
  %358 = add i64 %282, 41
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to double*
  store double %355, double* %359, align 8
  %360 = load i64, i64* %RBP, align 8
  %361 = add i64 %360, -16
  %362 = load i64, i64* %PC, align 8
  %363 = add i64 %362, 4
  store i64 %363, i64* %PC, align 8
  %364 = inttoptr i64 %361 to i64*
  %365 = load i64, i64* %364, align 8
  store i64 %365, i64* %RCX, align 8, !tbaa !2428
  %366 = add i64 %360, -28
  %367 = add i64 %362, 8
  store i64 %367, i64* %PC, align 8
  %368 = inttoptr i64 %366 to i32*
  %369 = load i32, i32* %368, align 4
  %370 = sext i32 %369 to i64
  store i64 %370, i64* %RDX, align 8, !tbaa !2428
  %371 = shl nsw i64 %370, 3
  %372 = add i64 %371, %365
  %373 = add i64 %362, 13
  store i64 %373, i64* %PC, align 8
  %374 = inttoptr i64 %372 to i64*
  %375 = load i64, i64* %374, align 8
  store i64 %375, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %376 = add i64 %362, 17
  store i64 %376, i64* %PC, align 8
  %377 = load i64, i64* %364, align 8
  store i64 %377, i64* %RCX, align 8, !tbaa !2428
  %378 = add i64 %360, -32
  %379 = add i64 %362, 21
  store i64 %379, i64* %PC, align 8
  %380 = inttoptr i64 %378 to i32*
  %381 = load i32, i32* %380, align 4
  %382 = sext i32 %381 to i64
  store i64 %382, i64* %RDX, align 8, !tbaa !2428
  %383 = shl nsw i64 %382, 3
  %384 = add i64 %383, %377
  %385 = add i64 %362, 26
  store i64 %385, i64* %PC, align 8
  %386 = bitcast i64 %375 to double
  %387 = inttoptr i64 %384 to double*
  %388 = load double, double* %387, align 8
  %389 = fsub double %386, %388
  store double %389, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %390 = add i64 %360, -72
  %391 = add i64 %362, 31
  store i64 %391, i64* %PC, align 8
  %392 = inttoptr i64 %390 to double*
  store double %389, double* %392, align 8
  %393 = load i64, i64* %RBP, align 8
  %394 = add i64 %393, -16
  %395 = load i64, i64* %PC, align 8
  %396 = add i64 %395, 4
  store i64 %396, i64* %PC, align 8
  %397 = inttoptr i64 %394 to i64*
  %398 = load i64, i64* %397, align 8
  store i64 %398, i64* %RCX, align 8, !tbaa !2428
  %399 = add i64 %393, -28
  %400 = add i64 %395, 7
  store i64 %400, i64* %PC, align 8
  %401 = inttoptr i64 %399 to i32*
  %402 = load i32, i32* %401, align 4
  %403 = add i32 %402, 1
  %404 = zext i32 %403 to i64
  store i64 %404, i64* %RAX, align 8, !tbaa !2428
  %405 = icmp eq i32 %402, -1
  %406 = icmp eq i32 %403, 0
  %407 = or i1 %405, %406
  %408 = zext i1 %407 to i8
  store i8 %408, i8* %14, align 1, !tbaa !2433
  %409 = and i32 %403, 255
  %410 = tail call i32 @llvm.ctpop.i32(i32 %409) #10
  %411 = trunc i32 %410 to i8
  %412 = and i8 %411, 1
  %413 = xor i8 %412, 1
  store i8 %413, i8* %21, align 1, !tbaa !2447
  %414 = xor i32 %403, %402
  %415 = lshr i32 %414, 4
  %416 = trunc i32 %415 to i8
  %417 = and i8 %416, 1
  store i8 %417, i8* %27, align 1, !tbaa !2451
  %418 = zext i1 %406 to i8
  store i8 %418, i8* %30, align 1, !tbaa !2448
  %419 = lshr i32 %403, 31
  %420 = trunc i32 %419 to i8
  store i8 %420, i8* %33, align 1, !tbaa !2449
  %421 = lshr i32 %402, 31
  %422 = xor i32 %419, %421
  %423 = add nuw nsw i32 %422, %419
  %424 = icmp eq i32 %423, 2
  %425 = zext i1 %424 to i8
  store i8 %425, i8* %39, align 1, !tbaa !2450
  %426 = sext i32 %403 to i64
  store i64 %426, i64* %RDX, align 8, !tbaa !2428
  %427 = shl nsw i64 %426, 3
  %428 = add i64 %398, %427
  %429 = add i64 %395, 18
  store i64 %429, i64* %PC, align 8
  %430 = inttoptr i64 %428 to i64*
  %431 = load i64, i64* %430, align 8
  store i64 %431, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %432 = add i64 %395, 22
  store i64 %432, i64* %PC, align 8
  %433 = load i64, i64* %397, align 8
  store i64 %433, i64* %RCX, align 8, !tbaa !2428
  %434 = add i64 %393, -32
  %435 = add i64 %395, 25
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %434 to i32*
  %437 = load i32, i32* %436, align 4
  %438 = add i32 %437, 1
  %439 = zext i32 %438 to i64
  store i64 %439, i64* %RAX, align 8, !tbaa !2428
  %440 = icmp eq i32 %437, -1
  %441 = icmp eq i32 %438, 0
  %442 = or i1 %440, %441
  %443 = zext i1 %442 to i8
  store i8 %443, i8* %14, align 1, !tbaa !2433
  %444 = and i32 %438, 255
  %445 = tail call i32 @llvm.ctpop.i32(i32 %444) #10
  %446 = trunc i32 %445 to i8
  %447 = and i8 %446, 1
  %448 = xor i8 %447, 1
  store i8 %448, i8* %21, align 1, !tbaa !2447
  %449 = xor i32 %438, %437
  %450 = lshr i32 %449, 4
  %451 = trunc i32 %450 to i8
  %452 = and i8 %451, 1
  store i8 %452, i8* %27, align 1, !tbaa !2451
  %453 = zext i1 %441 to i8
  store i8 %453, i8* %30, align 1, !tbaa !2448
  %454 = lshr i32 %438, 31
  %455 = trunc i32 %454 to i8
  store i8 %455, i8* %33, align 1, !tbaa !2449
  %456 = lshr i32 %437, 31
  %457 = xor i32 %454, %456
  %458 = add nuw nsw i32 %457, %454
  %459 = icmp eq i32 %458, 2
  %460 = zext i1 %459 to i8
  store i8 %460, i8* %39, align 1, !tbaa !2450
  %461 = sext i32 %438 to i64
  store i64 %461, i64* %RDX, align 8, !tbaa !2428
  %462 = shl nsw i64 %461, 3
  %463 = add i64 %433, %462
  %464 = add i64 %395, 36
  store i64 %464, i64* %PC, align 8
  %465 = bitcast i64 %431 to double
  %466 = inttoptr i64 %463 to double*
  %467 = load double, double* %466, align 8
  %468 = fsub double %465, %467
  store double %468, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %469 = load i64, i64* %RBP, align 8
  %470 = add i64 %469, -80
  %471 = add i64 %395, 41
  store i64 %471, i64* %PC, align 8
  %472 = inttoptr i64 %470 to double*
  store double %468, double* %472, align 8
  %473 = load i64, i64* %RBP, align 8
  %474 = add i64 %473, -16
  %475 = load i64, i64* %PC, align 8
  %476 = add i64 %475, 4
  store i64 %476, i64* %PC, align 8
  %477 = inttoptr i64 %474 to i64*
  %478 = load i64, i64* %477, align 8
  store i64 %478, i64* %RCX, align 8, !tbaa !2428
  %479 = add i64 %473, -36
  %480 = add i64 %475, 8
  store i64 %480, i64* %PC, align 8
  %481 = inttoptr i64 %479 to i32*
  %482 = load i32, i32* %481, align 4
  %483 = sext i32 %482 to i64
  store i64 %483, i64* %RDX, align 8, !tbaa !2428
  %484 = shl nsw i64 %483, 3
  %485 = add i64 %484, %478
  %486 = add i64 %475, 13
  store i64 %486, i64* %PC, align 8
  %487 = inttoptr i64 %485 to i64*
  %488 = load i64, i64* %487, align 8
  store i64 %488, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %489 = add i64 %475, 17
  store i64 %489, i64* %PC, align 8
  %490 = load i64, i64* %477, align 8
  store i64 %490, i64* %RCX, align 8, !tbaa !2428
  %491 = add i64 %473, -40
  %492 = add i64 %475, 21
  store i64 %492, i64* %PC, align 8
  %493 = inttoptr i64 %491 to i32*
  %494 = load i32, i32* %493, align 4
  %495 = sext i32 %494 to i64
  store i64 %495, i64* %RDX, align 8, !tbaa !2428
  %496 = shl nsw i64 %495, 3
  %497 = add i64 %496, %490
  %498 = add i64 %475, 26
  store i64 %498, i64* %PC, align 8
  %499 = bitcast i64 %488 to double
  %500 = inttoptr i64 %497 to double*
  %501 = load double, double* %500, align 8
  %502 = fadd double %499, %501
  store double %502, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %503 = add i64 %473, -88
  %504 = add i64 %475, 31
  store i64 %504, i64* %PC, align 8
  %505 = inttoptr i64 %503 to double*
  store double %502, double* %505, align 8
  %506 = load i64, i64* %RBP, align 8
  %507 = add i64 %506, -16
  %508 = load i64, i64* %PC, align 8
  %509 = add i64 %508, 4
  store i64 %509, i64* %PC, align 8
  %510 = inttoptr i64 %507 to i64*
  %511 = load i64, i64* %510, align 8
  store i64 %511, i64* %RCX, align 8, !tbaa !2428
  %512 = add i64 %506, -36
  %513 = add i64 %508, 7
  store i64 %513, i64* %PC, align 8
  %514 = inttoptr i64 %512 to i32*
  %515 = load i32, i32* %514, align 4
  %516 = add i32 %515, 1
  %517 = zext i32 %516 to i64
  store i64 %517, i64* %RAX, align 8, !tbaa !2428
  %518 = icmp eq i32 %515, -1
  %519 = icmp eq i32 %516, 0
  %520 = or i1 %518, %519
  %521 = zext i1 %520 to i8
  store i8 %521, i8* %14, align 1, !tbaa !2433
  %522 = and i32 %516, 255
  %523 = tail call i32 @llvm.ctpop.i32(i32 %522) #10
  %524 = trunc i32 %523 to i8
  %525 = and i8 %524, 1
  %526 = xor i8 %525, 1
  store i8 %526, i8* %21, align 1, !tbaa !2447
  %527 = xor i32 %516, %515
  %528 = lshr i32 %527, 4
  %529 = trunc i32 %528 to i8
  %530 = and i8 %529, 1
  store i8 %530, i8* %27, align 1, !tbaa !2451
  %531 = zext i1 %519 to i8
  store i8 %531, i8* %30, align 1, !tbaa !2448
  %532 = lshr i32 %516, 31
  %533 = trunc i32 %532 to i8
  store i8 %533, i8* %33, align 1, !tbaa !2449
  %534 = lshr i32 %515, 31
  %535 = xor i32 %532, %534
  %536 = add nuw nsw i32 %535, %532
  %537 = icmp eq i32 %536, 2
  %538 = zext i1 %537 to i8
  store i8 %538, i8* %39, align 1, !tbaa !2450
  %539 = sext i32 %516 to i64
  store i64 %539, i64* %RDX, align 8, !tbaa !2428
  %540 = shl nsw i64 %539, 3
  %541 = add i64 %511, %540
  %542 = add i64 %508, 18
  store i64 %542, i64* %PC, align 8
  %543 = inttoptr i64 %541 to i64*
  %544 = load i64, i64* %543, align 8
  store i64 %544, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %545 = add i64 %508, 22
  store i64 %545, i64* %PC, align 8
  %546 = load i64, i64* %510, align 8
  store i64 %546, i64* %RCX, align 8, !tbaa !2428
  %547 = add i64 %506, -40
  %548 = add i64 %508, 25
  store i64 %548, i64* %PC, align 8
  %549 = inttoptr i64 %547 to i32*
  %550 = load i32, i32* %549, align 4
  %551 = add i32 %550, 1
  %552 = zext i32 %551 to i64
  store i64 %552, i64* %RAX, align 8, !tbaa !2428
  %553 = icmp eq i32 %550, -1
  %554 = icmp eq i32 %551, 0
  %555 = or i1 %553, %554
  %556 = zext i1 %555 to i8
  store i8 %556, i8* %14, align 1, !tbaa !2433
  %557 = and i32 %551, 255
  %558 = tail call i32 @llvm.ctpop.i32(i32 %557) #10
  %559 = trunc i32 %558 to i8
  %560 = and i8 %559, 1
  %561 = xor i8 %560, 1
  store i8 %561, i8* %21, align 1, !tbaa !2447
  %562 = xor i32 %551, %550
  %563 = lshr i32 %562, 4
  %564 = trunc i32 %563 to i8
  %565 = and i8 %564, 1
  store i8 %565, i8* %27, align 1, !tbaa !2451
  %566 = zext i1 %554 to i8
  store i8 %566, i8* %30, align 1, !tbaa !2448
  %567 = lshr i32 %551, 31
  %568 = trunc i32 %567 to i8
  store i8 %568, i8* %33, align 1, !tbaa !2449
  %569 = lshr i32 %550, 31
  %570 = xor i32 %567, %569
  %571 = add nuw nsw i32 %570, %567
  %572 = icmp eq i32 %571, 2
  %573 = zext i1 %572 to i8
  store i8 %573, i8* %39, align 1, !tbaa !2450
  %574 = sext i32 %551 to i64
  store i64 %574, i64* %RDX, align 8, !tbaa !2428
  %575 = shl nsw i64 %574, 3
  %576 = add i64 %546, %575
  %577 = add i64 %508, 36
  store i64 %577, i64* %PC, align 8
  %578 = bitcast i64 %544 to double
  %579 = inttoptr i64 %576 to double*
  %580 = load double, double* %579, align 8
  %581 = fadd double %578, %580
  store double %581, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %582 = load i64, i64* %RBP, align 8
  %583 = add i64 %582, -96
  %584 = add i64 %508, 41
  store i64 %584, i64* %PC, align 8
  %585 = inttoptr i64 %583 to double*
  store double %581, double* %585, align 8
  %586 = load i64, i64* %RBP, align 8
  %587 = add i64 %586, -16
  %588 = load i64, i64* %PC, align 8
  %589 = add i64 %588, 4
  store i64 %589, i64* %PC, align 8
  %590 = inttoptr i64 %587 to i64*
  %591 = load i64, i64* %590, align 8
  store i64 %591, i64* %RCX, align 8, !tbaa !2428
  %592 = add i64 %586, -36
  %593 = add i64 %588, 8
  store i64 %593, i64* %PC, align 8
  %594 = inttoptr i64 %592 to i32*
  %595 = load i32, i32* %594, align 4
  %596 = sext i32 %595 to i64
  store i64 %596, i64* %RDX, align 8, !tbaa !2428
  %597 = shl nsw i64 %596, 3
  %598 = add i64 %597, %591
  %599 = add i64 %588, 13
  store i64 %599, i64* %PC, align 8
  %600 = inttoptr i64 %598 to i64*
  %601 = load i64, i64* %600, align 8
  store i64 %601, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %602 = add i64 %588, 17
  store i64 %602, i64* %PC, align 8
  %603 = load i64, i64* %590, align 8
  store i64 %603, i64* %RCX, align 8, !tbaa !2428
  %604 = add i64 %586, -40
  %605 = add i64 %588, 21
  store i64 %605, i64* %PC, align 8
  %606 = inttoptr i64 %604 to i32*
  %607 = load i32, i32* %606, align 4
  %608 = sext i32 %607 to i64
  store i64 %608, i64* %RDX, align 8, !tbaa !2428
  %609 = shl nsw i64 %608, 3
  %610 = add i64 %609, %603
  %611 = add i64 %588, 26
  store i64 %611, i64* %PC, align 8
  %612 = bitcast i64 %601 to double
  %613 = inttoptr i64 %610 to double*
  %614 = load double, double* %613, align 8
  %615 = fsub double %612, %614
  store double %615, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %616 = add i64 %586, -104
  %617 = add i64 %588, 31
  store i64 %617, i64* %PC, align 8
  %618 = inttoptr i64 %616 to double*
  store double %615, double* %618, align 8
  %619 = load i64, i64* %RBP, align 8
  %620 = add i64 %619, -16
  %621 = load i64, i64* %PC, align 8
  %622 = add i64 %621, 4
  store i64 %622, i64* %PC, align 8
  %623 = inttoptr i64 %620 to i64*
  %624 = load i64, i64* %623, align 8
  store i64 %624, i64* %RCX, align 8, !tbaa !2428
  %625 = add i64 %619, -36
  %626 = add i64 %621, 7
  store i64 %626, i64* %PC, align 8
  %627 = inttoptr i64 %625 to i32*
  %628 = load i32, i32* %627, align 4
  %629 = add i32 %628, 1
  %630 = zext i32 %629 to i64
  store i64 %630, i64* %RAX, align 8, !tbaa !2428
  %631 = icmp eq i32 %628, -1
  %632 = icmp eq i32 %629, 0
  %633 = or i1 %631, %632
  %634 = zext i1 %633 to i8
  store i8 %634, i8* %14, align 1, !tbaa !2433
  %635 = and i32 %629, 255
  %636 = tail call i32 @llvm.ctpop.i32(i32 %635) #10
  %637 = trunc i32 %636 to i8
  %638 = and i8 %637, 1
  %639 = xor i8 %638, 1
  store i8 %639, i8* %21, align 1, !tbaa !2447
  %640 = xor i32 %629, %628
  %641 = lshr i32 %640, 4
  %642 = trunc i32 %641 to i8
  %643 = and i8 %642, 1
  store i8 %643, i8* %27, align 1, !tbaa !2451
  %644 = zext i1 %632 to i8
  store i8 %644, i8* %30, align 1, !tbaa !2448
  %645 = lshr i32 %629, 31
  %646 = trunc i32 %645 to i8
  store i8 %646, i8* %33, align 1, !tbaa !2449
  %647 = lshr i32 %628, 31
  %648 = xor i32 %645, %647
  %649 = add nuw nsw i32 %648, %645
  %650 = icmp eq i32 %649, 2
  %651 = zext i1 %650 to i8
  store i8 %651, i8* %39, align 1, !tbaa !2450
  %652 = sext i32 %629 to i64
  store i64 %652, i64* %RDX, align 8, !tbaa !2428
  %653 = shl nsw i64 %652, 3
  %654 = add i64 %624, %653
  %655 = add i64 %621, 18
  store i64 %655, i64* %PC, align 8
  %656 = inttoptr i64 %654 to i64*
  %657 = load i64, i64* %656, align 8
  store i64 %657, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %658 = add i64 %621, 22
  store i64 %658, i64* %PC, align 8
  %659 = load i64, i64* %623, align 8
  store i64 %659, i64* %RCX, align 8, !tbaa !2428
  %660 = add i64 %619, -40
  %661 = add i64 %621, 25
  store i64 %661, i64* %PC, align 8
  %662 = inttoptr i64 %660 to i32*
  %663 = load i32, i32* %662, align 4
  %664 = add i32 %663, 1
  %665 = zext i32 %664 to i64
  store i64 %665, i64* %RAX, align 8, !tbaa !2428
  %666 = icmp eq i32 %663, -1
  %667 = icmp eq i32 %664, 0
  %668 = or i1 %666, %667
  %669 = zext i1 %668 to i8
  store i8 %669, i8* %14, align 1, !tbaa !2433
  %670 = and i32 %664, 255
  %671 = tail call i32 @llvm.ctpop.i32(i32 %670) #10
  %672 = trunc i32 %671 to i8
  %673 = and i8 %672, 1
  %674 = xor i8 %673, 1
  store i8 %674, i8* %21, align 1, !tbaa !2447
  %675 = xor i32 %664, %663
  %676 = lshr i32 %675, 4
  %677 = trunc i32 %676 to i8
  %678 = and i8 %677, 1
  store i8 %678, i8* %27, align 1, !tbaa !2451
  %679 = zext i1 %667 to i8
  store i8 %679, i8* %30, align 1, !tbaa !2448
  %680 = lshr i32 %664, 31
  %681 = trunc i32 %680 to i8
  store i8 %681, i8* %33, align 1, !tbaa !2449
  %682 = lshr i32 %663, 31
  %683 = xor i32 %680, %682
  %684 = add nuw nsw i32 %683, %680
  %685 = icmp eq i32 %684, 2
  %686 = zext i1 %685 to i8
  store i8 %686, i8* %39, align 1, !tbaa !2450
  %687 = sext i32 %664 to i64
  store i64 %687, i64* %RDX, align 8, !tbaa !2428
  %688 = shl nsw i64 %687, 3
  %689 = add i64 %659, %688
  %690 = add i64 %621, 36
  store i64 %690, i64* %PC, align 8
  %691 = bitcast i64 %657 to double
  %692 = inttoptr i64 %689 to double*
  %693 = load double, double* %692, align 8
  %694 = fsub double %691, %693
  store double %694, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %695 = load i64, i64* %RBP, align 8
  %696 = add i64 %695, -112
  %697 = add i64 %621, 41
  store i64 %697, i64* %PC, align 8
  %698 = inttoptr i64 %696 to double*
  store double %694, double* %698, align 8
  %699 = load i64, i64* %RBP, align 8
  %700 = add i64 %699, -56
  %701 = load i64, i64* %PC, align 8
  %702 = add i64 %701, 5
  store i64 %702, i64* %PC, align 8
  %703 = inttoptr i64 %700 to i64*
  %704 = load i64, i64* %703, align 8
  store i64 %704, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %705 = add i64 %699, -88
  %706 = add i64 %701, 10
  store i64 %706, i64* %PC, align 8
  %707 = bitcast i64 %704 to double
  %708 = inttoptr i64 %705 to double*
  %709 = load double, double* %708, align 8
  %710 = fadd double %707, %709
  store double %710, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %711 = add i64 %699, -16
  %712 = add i64 %701, 14
  store i64 %712, i64* %PC, align 8
  %713 = inttoptr i64 %711 to i64*
  %714 = load i64, i64* %713, align 8
  store i64 %714, i64* %RCX, align 8, !tbaa !2428
  %715 = add i64 %699, -28
  %716 = add i64 %701, 18
  store i64 %716, i64* %PC, align 8
  %717 = inttoptr i64 %715 to i32*
  %718 = load i32, i32* %717, align 4
  %719 = sext i32 %718 to i64
  store i64 %719, i64* %RDX, align 8, !tbaa !2428
  %720 = shl nsw i64 %719, 3
  %721 = add i64 %720, %714
  %722 = add i64 %701, 23
  store i64 %722, i64* %PC, align 8
  %723 = inttoptr i64 %721 to double*
  store double %710, double* %723, align 8
  %724 = load i64, i64* %RBP, align 8
  %725 = add i64 %724, -64
  %726 = load i64, i64* %PC, align 8
  %727 = add i64 %726, 5
  store i64 %727, i64* %PC, align 8
  %728 = inttoptr i64 %725 to i64*
  %729 = load i64, i64* %728, align 8
  store i64 %729, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %730 = add i64 %724, -96
  %731 = add i64 %726, 10
  store i64 %731, i64* %PC, align 8
  %732 = bitcast i64 %729 to double
  %733 = inttoptr i64 %730 to double*
  %734 = load double, double* %733, align 8
  %735 = fadd double %732, %734
  store double %735, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %736 = add i64 %724, -16
  %737 = add i64 %726, 14
  store i64 %737, i64* %PC, align 8
  %738 = inttoptr i64 %736 to i64*
  %739 = load i64, i64* %738, align 8
  store i64 %739, i64* %RCX, align 8, !tbaa !2428
  %740 = add i64 %724, -28
  %741 = add i64 %726, 17
  store i64 %741, i64* %PC, align 8
  %742 = inttoptr i64 %740 to i32*
  %743 = load i32, i32* %742, align 4
  %744 = add i32 %743, 1
  %745 = zext i32 %744 to i64
  store i64 %745, i64* %RAX, align 8, !tbaa !2428
  %746 = icmp eq i32 %743, -1
  %747 = icmp eq i32 %744, 0
  %748 = or i1 %746, %747
  %749 = zext i1 %748 to i8
  store i8 %749, i8* %14, align 1, !tbaa !2433
  %750 = and i32 %744, 255
  %751 = tail call i32 @llvm.ctpop.i32(i32 %750) #10
  %752 = trunc i32 %751 to i8
  %753 = and i8 %752, 1
  %754 = xor i8 %753, 1
  store i8 %754, i8* %21, align 1, !tbaa !2447
  %755 = xor i32 %744, %743
  %756 = lshr i32 %755, 4
  %757 = trunc i32 %756 to i8
  %758 = and i8 %757, 1
  store i8 %758, i8* %27, align 1, !tbaa !2451
  %759 = zext i1 %747 to i8
  store i8 %759, i8* %30, align 1, !tbaa !2448
  %760 = lshr i32 %744, 31
  %761 = trunc i32 %760 to i8
  store i8 %761, i8* %33, align 1, !tbaa !2449
  %762 = lshr i32 %743, 31
  %763 = xor i32 %760, %762
  %764 = add nuw nsw i32 %763, %760
  %765 = icmp eq i32 %764, 2
  %766 = zext i1 %765 to i8
  store i8 %766, i8* %39, align 1, !tbaa !2450
  %767 = sext i32 %744 to i64
  store i64 %767, i64* %RDX, align 8, !tbaa !2428
  %768 = shl nsw i64 %767, 3
  %769 = add i64 %739, %768
  %770 = add i64 %726, 28
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %769 to double*
  store double %735, double* %771, align 8
  %772 = load i64, i64* %RBP, align 8
  %773 = add i64 %772, -56
  %774 = load i64, i64* %PC, align 8
  %775 = add i64 %774, 5
  store i64 %775, i64* %PC, align 8
  %776 = inttoptr i64 %773 to i64*
  %777 = load i64, i64* %776, align 8
  store i64 %777, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %778 = add i64 %772, -88
  %779 = add i64 %774, 10
  store i64 %779, i64* %PC, align 8
  %780 = bitcast i64 %777 to double
  %781 = inttoptr i64 %778 to double*
  %782 = load double, double* %781, align 8
  %783 = fsub double %780, %782
  store double %783, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %784 = add i64 %772, -16
  %785 = add i64 %774, 14
  store i64 %785, i64* %PC, align 8
  %786 = inttoptr i64 %784 to i64*
  %787 = load i64, i64* %786, align 8
  store i64 %787, i64* %RCX, align 8, !tbaa !2428
  %788 = add i64 %772, -36
  %789 = add i64 %774, 18
  store i64 %789, i64* %PC, align 8
  %790 = inttoptr i64 %788 to i32*
  %791 = load i32, i32* %790, align 4
  %792 = sext i32 %791 to i64
  store i64 %792, i64* %RDX, align 8, !tbaa !2428
  %793 = shl nsw i64 %792, 3
  %794 = add i64 %793, %787
  %795 = add i64 %774, 23
  store i64 %795, i64* %PC, align 8
  %796 = inttoptr i64 %794 to double*
  store double %783, double* %796, align 8
  %797 = load i64, i64* %RBP, align 8
  %798 = add i64 %797, -64
  %799 = load i64, i64* %PC, align 8
  %800 = add i64 %799, 5
  store i64 %800, i64* %PC, align 8
  %801 = inttoptr i64 %798 to i64*
  %802 = load i64, i64* %801, align 8
  store i64 %802, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %803 = add i64 %797, -96
  %804 = add i64 %799, 10
  store i64 %804, i64* %PC, align 8
  %805 = bitcast i64 %802 to double
  %806 = inttoptr i64 %803 to double*
  %807 = load double, double* %806, align 8
  %808 = fsub double %805, %807
  store double %808, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %809 = add i64 %797, -16
  %810 = add i64 %799, 14
  store i64 %810, i64* %PC, align 8
  %811 = inttoptr i64 %809 to i64*
  %812 = load i64, i64* %811, align 8
  store i64 %812, i64* %RCX, align 8, !tbaa !2428
  %813 = add i64 %797, -36
  %814 = add i64 %799, 17
  store i64 %814, i64* %PC, align 8
  %815 = inttoptr i64 %813 to i32*
  %816 = load i32, i32* %815, align 4
  %817 = add i32 %816, 1
  %818 = zext i32 %817 to i64
  store i64 %818, i64* %RAX, align 8, !tbaa !2428
  %819 = icmp eq i32 %816, -1
  %820 = icmp eq i32 %817, 0
  %821 = or i1 %819, %820
  %822 = zext i1 %821 to i8
  store i8 %822, i8* %14, align 1, !tbaa !2433
  %823 = and i32 %817, 255
  %824 = tail call i32 @llvm.ctpop.i32(i32 %823) #10
  %825 = trunc i32 %824 to i8
  %826 = and i8 %825, 1
  %827 = xor i8 %826, 1
  store i8 %827, i8* %21, align 1, !tbaa !2447
  %828 = xor i32 %817, %816
  %829 = lshr i32 %828, 4
  %830 = trunc i32 %829 to i8
  %831 = and i8 %830, 1
  store i8 %831, i8* %27, align 1, !tbaa !2451
  %832 = zext i1 %820 to i8
  store i8 %832, i8* %30, align 1, !tbaa !2448
  %833 = lshr i32 %817, 31
  %834 = trunc i32 %833 to i8
  store i8 %834, i8* %33, align 1, !tbaa !2449
  %835 = lshr i32 %816, 31
  %836 = xor i32 %833, %835
  %837 = add nuw nsw i32 %836, %833
  %838 = icmp eq i32 %837, 2
  %839 = zext i1 %838 to i8
  store i8 %839, i8* %39, align 1, !tbaa !2450
  %840 = sext i32 %817 to i64
  store i64 %840, i64* %RDX, align 8, !tbaa !2428
  %841 = shl nsw i64 %840, 3
  %842 = add i64 %812, %841
  %843 = add i64 %799, 28
  store i64 %843, i64* %PC, align 8
  %844 = inttoptr i64 %842 to double*
  store double %808, double* %844, align 8
  %845 = load i64, i64* %RBP, align 8
  %846 = add i64 %845, -72
  %847 = load i64, i64* %PC, align 8
  %848 = add i64 %847, 5
  store i64 %848, i64* %PC, align 8
  %849 = inttoptr i64 %846 to i64*
  %850 = load i64, i64* %849, align 8
  store i64 %850, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %851 = add i64 %845, -112
  %852 = add i64 %847, 10
  store i64 %852, i64* %PC, align 8
  %853 = bitcast i64 %850 to double
  %854 = inttoptr i64 %851 to double*
  %855 = load double, double* %854, align 8
  %856 = fsub double %853, %855
  store double %856, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %857 = add i64 %845, -16
  %858 = add i64 %847, 14
  store i64 %858, i64* %PC, align 8
  %859 = inttoptr i64 %857 to i64*
  %860 = load i64, i64* %859, align 8
  store i64 %860, i64* %RCX, align 8, !tbaa !2428
  %861 = add i64 %845, -32
  %862 = add i64 %847, 18
  store i64 %862, i64* %PC, align 8
  %863 = inttoptr i64 %861 to i32*
  %864 = load i32, i32* %863, align 4
  %865 = sext i32 %864 to i64
  store i64 %865, i64* %RDX, align 8, !tbaa !2428
  %866 = shl nsw i64 %865, 3
  %867 = add i64 %866, %860
  %868 = add i64 %847, 23
  store i64 %868, i64* %PC, align 8
  %869 = inttoptr i64 %867 to double*
  store double %856, double* %869, align 8
  %870 = load i64, i64* %RBP, align 8
  %871 = add i64 %870, -80
  %872 = load i64, i64* %PC, align 8
  %873 = add i64 %872, 5
  store i64 %873, i64* %PC, align 8
  %874 = inttoptr i64 %871 to i64*
  %875 = load i64, i64* %874, align 8
  store i64 %875, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %876 = add i64 %870, -104
  %877 = add i64 %872, 10
  store i64 %877, i64* %PC, align 8
  %878 = bitcast i64 %875 to double
  %879 = inttoptr i64 %876 to double*
  %880 = load double, double* %879, align 8
  %881 = fadd double %878, %880
  store double %881, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %882 = add i64 %870, -16
  %883 = add i64 %872, 14
  store i64 %883, i64* %PC, align 8
  %884 = inttoptr i64 %882 to i64*
  %885 = load i64, i64* %884, align 8
  store i64 %885, i64* %RCX, align 8, !tbaa !2428
  %886 = add i64 %870, -32
  %887 = add i64 %872, 17
  store i64 %887, i64* %PC, align 8
  %888 = inttoptr i64 %886 to i32*
  %889 = load i32, i32* %888, align 4
  %890 = add i32 %889, 1
  %891 = zext i32 %890 to i64
  store i64 %891, i64* %RAX, align 8, !tbaa !2428
  %892 = icmp eq i32 %889, -1
  %893 = icmp eq i32 %890, 0
  %894 = or i1 %892, %893
  %895 = zext i1 %894 to i8
  store i8 %895, i8* %14, align 1, !tbaa !2433
  %896 = and i32 %890, 255
  %897 = tail call i32 @llvm.ctpop.i32(i32 %896) #10
  %898 = trunc i32 %897 to i8
  %899 = and i8 %898, 1
  %900 = xor i8 %899, 1
  store i8 %900, i8* %21, align 1, !tbaa !2447
  %901 = xor i32 %890, %889
  %902 = lshr i32 %901, 4
  %903 = trunc i32 %902 to i8
  %904 = and i8 %903, 1
  store i8 %904, i8* %27, align 1, !tbaa !2451
  %905 = zext i1 %893 to i8
  store i8 %905, i8* %30, align 1, !tbaa !2448
  %906 = lshr i32 %890, 31
  %907 = trunc i32 %906 to i8
  store i8 %907, i8* %33, align 1, !tbaa !2449
  %908 = lshr i32 %889, 31
  %909 = xor i32 %906, %908
  %910 = add nuw nsw i32 %909, %906
  %911 = icmp eq i32 %910, 2
  %912 = zext i1 %911 to i8
  store i8 %912, i8* %39, align 1, !tbaa !2450
  %913 = sext i32 %890 to i64
  store i64 %913, i64* %RDX, align 8, !tbaa !2428
  %914 = shl nsw i64 %913, 3
  %915 = add i64 %885, %914
  %916 = add i64 %872, 28
  store i64 %916, i64* %PC, align 8
  %917 = inttoptr i64 %915 to double*
  store double %881, double* %917, align 8
  %918 = load i64, i64* %RBP, align 8
  %919 = add i64 %918, -72
  %920 = load i64, i64* %PC, align 8
  %921 = add i64 %920, 5
  store i64 %921, i64* %PC, align 8
  %922 = inttoptr i64 %919 to i64*
  %923 = load i64, i64* %922, align 8
  store i64 %923, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %924 = add i64 %918, -112
  %925 = add i64 %920, 10
  store i64 %925, i64* %PC, align 8
  %926 = bitcast i64 %923 to double
  %927 = inttoptr i64 %924 to double*
  %928 = load double, double* %927, align 8
  %929 = fadd double %926, %928
  store double %929, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %930 = add i64 %918, -16
  %931 = add i64 %920, 14
  store i64 %931, i64* %PC, align 8
  %932 = inttoptr i64 %930 to i64*
  %933 = load i64, i64* %932, align 8
  store i64 %933, i64* %RCX, align 8, !tbaa !2428
  %934 = add i64 %918, -40
  %935 = add i64 %920, 18
  store i64 %935, i64* %PC, align 8
  %936 = inttoptr i64 %934 to i32*
  %937 = load i32, i32* %936, align 4
  %938 = sext i32 %937 to i64
  store i64 %938, i64* %RDX, align 8, !tbaa !2428
  %939 = shl nsw i64 %938, 3
  %940 = add i64 %939, %933
  %941 = add i64 %920, 23
  store i64 %941, i64* %PC, align 8
  %942 = inttoptr i64 %940 to double*
  store double %929, double* %942, align 8
  %943 = load i64, i64* %RBP, align 8
  %944 = add i64 %943, -80
  %945 = load i64, i64* %PC, align 8
  %946 = add i64 %945, 5
  store i64 %946, i64* %PC, align 8
  %947 = inttoptr i64 %944 to i64*
  %948 = load i64, i64* %947, align 8
  store i64 %948, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %949 = add i64 %943, -104
  %950 = add i64 %945, 10
  store i64 %950, i64* %PC, align 8
  %951 = bitcast i64 %948 to double
  %952 = inttoptr i64 %949 to double*
  %953 = load double, double* %952, align 8
  %954 = fsub double %951, %953
  store double %954, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %955 = add i64 %943, -16
  %956 = add i64 %945, 14
  store i64 %956, i64* %PC, align 8
  %957 = inttoptr i64 %955 to i64*
  %958 = load i64, i64* %957, align 8
  store i64 %958, i64* %RCX, align 8, !tbaa !2428
  %959 = add i64 %943, -40
  %960 = add i64 %945, 17
  store i64 %960, i64* %PC, align 8
  %961 = inttoptr i64 %959 to i32*
  %962 = load i32, i32* %961, align 4
  %963 = add i32 %962, 1
  %964 = zext i32 %963 to i64
  store i64 %964, i64* %RAX, align 8, !tbaa !2428
  %965 = icmp eq i32 %962, -1
  %966 = icmp eq i32 %963, 0
  %967 = or i1 %965, %966
  %968 = zext i1 %967 to i8
  store i8 %968, i8* %14, align 1, !tbaa !2433
  %969 = and i32 %963, 255
  %970 = tail call i32 @llvm.ctpop.i32(i32 %969) #10
  %971 = trunc i32 %970 to i8
  %972 = and i8 %971, 1
  %973 = xor i8 %972, 1
  store i8 %973, i8* %21, align 1, !tbaa !2447
  %974 = xor i32 %963, %962
  %975 = lshr i32 %974, 4
  %976 = trunc i32 %975 to i8
  %977 = and i8 %976, 1
  store i8 %977, i8* %27, align 1, !tbaa !2451
  %978 = zext i1 %966 to i8
  store i8 %978, i8* %30, align 1, !tbaa !2448
  %979 = lshr i32 %963, 31
  %980 = trunc i32 %979 to i8
  store i8 %980, i8* %33, align 1, !tbaa !2449
  %981 = lshr i32 %962, 31
  %982 = xor i32 %979, %981
  %983 = add nuw nsw i32 %982, %979
  %984 = icmp eq i32 %983, 2
  %985 = zext i1 %984 to i8
  store i8 %985, i8* %39, align 1, !tbaa !2450
  %986 = sext i32 %963 to i64
  store i64 %986, i64* %RDX, align 8, !tbaa !2428
  %987 = shl nsw i64 %986, 3
  %988 = add i64 %958, %987
  %989 = add i64 %945, 28
  store i64 %989, i64* %PC, align 8
  %990 = inttoptr i64 %988 to double*
  store double %954, double* %990, align 8
  %991 = load i64, i64* %RBP, align 8
  %992 = add i64 %991, -28
  %993 = load i64, i64* %PC, align 8
  %994 = add i64 %993, 3
  store i64 %994, i64* %PC, align 8
  %995 = inttoptr i64 %992 to i32*
  %996 = load i32, i32* %995, align 4
  %997 = add i32 %996, 2
  %998 = zext i32 %997 to i64
  store i64 %998, i64* %RAX, align 8, !tbaa !2428
  %999 = icmp ugt i32 %996, -3
  %1000 = zext i1 %999 to i8
  store i8 %1000, i8* %14, align 1, !tbaa !2433
  %1001 = and i32 %997, 255
  %1002 = tail call i32 @llvm.ctpop.i32(i32 %1001) #10
  %1003 = trunc i32 %1002 to i8
  %1004 = and i8 %1003, 1
  %1005 = xor i8 %1004, 1
  store i8 %1005, i8* %21, align 1, !tbaa !2447
  %1006 = xor i32 %997, %996
  %1007 = lshr i32 %1006, 4
  %1008 = trunc i32 %1007 to i8
  %1009 = and i8 %1008, 1
  store i8 %1009, i8* %27, align 1, !tbaa !2451
  %1010 = icmp eq i32 %997, 0
  %1011 = zext i1 %1010 to i8
  store i8 %1011, i8* %30, align 1, !tbaa !2448
  %1012 = lshr i32 %997, 31
  %1013 = trunc i32 %1012 to i8
  store i8 %1013, i8* %33, align 1, !tbaa !2449
  %1014 = lshr i32 %996, 31
  %1015 = xor i32 %1012, %1014
  %1016 = add nuw nsw i32 %1015, %1012
  %1017 = icmp eq i32 %1016, 2
  %1018 = zext i1 %1017 to i8
  store i8 %1018, i8* %39, align 1, !tbaa !2450
  %1019 = add i64 %993, 9
  store i64 %1019, i64* %PC, align 8
  store i32 %997, i32* %995, align 4
  %1020 = load i64, i64* %PC, align 8
  %1021 = add i64 %1020, -540
  store i64 %1021, i64* %PC, align 8, !tbaa !2428
  br label %block_4018e6

block_4018d0:                                     ; preds = %block_4018cb, %block_401860
  %1022 = phi i64 [ %91, %block_401860 ], [ %1133, %block_4018cb ]
  %1023 = phi i64 [ %61, %block_401860 ], [ %1081, %block_4018cb ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_401860 ], [ %1616, %block_4018cb ]
  %1024 = add i64 %1023, -44
  %1025 = add i64 %1022, 3
  store i64 %1025, i64* %PC, align 8
  %1026 = inttoptr i64 %1024 to i32*
  %1027 = load i32, i32* %1026, align 4
  %1028 = shl i32 %1027, 2
  %1029 = zext i32 %1028 to i64
  store i64 %1029, i64* %RAX, align 8, !tbaa !2428
  %1030 = lshr i32 %1027, 30
  %1031 = trunc i32 %1030 to i8
  %1032 = and i8 %1031, 1
  store i8 %1032, i8* %14, align 1, !tbaa !2432
  %1033 = and i32 %1028, 252
  %1034 = tail call i32 @llvm.ctpop.i32(i32 %1033) #10
  %1035 = trunc i32 %1034 to i8
  %1036 = and i8 %1035, 1
  %1037 = xor i8 %1036, 1
  store i8 %1037, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %1038 = icmp eq i32 %1028, 0
  %1039 = zext i1 %1038 to i8
  store i8 %1039, i8* %30, align 1, !tbaa !2432
  %1040 = lshr i32 %1027, 29
  %1041 = trunc i32 %1040 to i8
  %1042 = and i8 %1041, 1
  store i8 %1042, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %1043 = add i64 %1023, -4
  %1044 = add i64 %1022, 9
  store i64 %1044, i64* %PC, align 8
  %1045 = inttoptr i64 %1043 to i32*
  %1046 = load i32, i32* %1045, align 4
  %1047 = sub i32 %1028, %1046
  %1048 = icmp ult i32 %1028, %1046
  %1049 = zext i1 %1048 to i8
  store i8 %1049, i8* %14, align 1, !tbaa !2433
  %1050 = and i32 %1047, 255
  %1051 = tail call i32 @llvm.ctpop.i32(i32 %1050) #10
  %1052 = trunc i32 %1051 to i8
  %1053 = and i8 %1052, 1
  %1054 = xor i8 %1053, 1
  store i8 %1054, i8* %21, align 1, !tbaa !2447
  %1055 = xor i32 %1046, %1028
  %1056 = xor i32 %1055, %1047
  %1057 = lshr i32 %1056, 4
  %1058 = trunc i32 %1057 to i8
  %1059 = and i8 %1058, 1
  store i8 %1059, i8* %27, align 1, !tbaa !2451
  %1060 = icmp eq i32 %1047, 0
  %1061 = zext i1 %1060 to i8
  store i8 %1061, i8* %30, align 1, !tbaa !2448
  %1062 = lshr i32 %1047, 31
  %1063 = trunc i32 %1062 to i8
  store i8 %1063, i8* %33, align 1, !tbaa !2449
  %1064 = lshr i32 %1027, 29
  %1065 = and i32 %1064, 1
  %1066 = lshr i32 %1046, 31
  %1067 = xor i32 %1066, %1065
  %1068 = xor i32 %1062, %1065
  %1069 = add nuw nsw i32 %1068, %1067
  %1070 = icmp eq i32 %1069, 2
  %1071 = zext i1 %1070 to i8
  store i8 %1071, i8* %39, align 1, !tbaa !2450
  %.v = select i1 %1060, i64 15, i64 572
  %1072 = add i64 %1022, %.v
  %1073 = add i64 %1023, -28
  %1074 = add i64 %1072, 7
  store i64 %1074, i64* %PC, align 8
  %1075 = inttoptr i64 %1073 to i32*
  store i32 0, i32* %1075, align 4
  %1076 = bitcast %union.VectorReg* %4 to double*
  %1077 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %1078 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1079 = bitcast i64* %1078 to double*
  %.pre12 = load i64, i64* %PC, align 8
  br i1 %1060, label %block_4018e6.preheader, label %block_401b13.preheader

block_401b13.preheader:                           ; preds = %block_4018d0
  br label %block_401b13

block_4018e6.preheader:                           ; preds = %block_4018d0
  br label %block_4018e6

block_40189b:                                     ; preds = %block_401884, %block_4018aa
  %1080 = phi i64 [ %.pre, %block_401884 ], [ %1527, %block_4018aa ]
  %1081 = load i64, i64* %RBP, align 8
  %1082 = add i64 %1081, -44
  %1083 = add i64 %1080, 3
  store i64 %1083, i64* %PC, align 8
  %1084 = inttoptr i64 %1082 to i32*
  %1085 = load i32, i32* %1084, align 4
  %1086 = shl i32 %1085, 2
  %1087 = zext i32 %1086 to i64
  store i64 %1087, i64* %RAX, align 8, !tbaa !2428
  %1088 = lshr i32 %1085, 30
  %1089 = trunc i32 %1088 to i8
  %1090 = and i8 %1089, 1
  store i8 %1090, i8* %14, align 1, !tbaa !2432
  %1091 = and i32 %1086, 252
  %1092 = tail call i32 @llvm.ctpop.i32(i32 %1091) #10
  %1093 = trunc i32 %1092 to i8
  %1094 = and i8 %1093, 1
  %1095 = xor i8 %1094, 1
  store i8 %1095, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %1096 = icmp eq i32 %1086, 0
  %1097 = zext i1 %1096 to i8
  store i8 %1097, i8* %30, align 1, !tbaa !2432
  %1098 = lshr i32 %1085, 29
  %1099 = trunc i32 %1098 to i8
  %1100 = and i8 %1099, 1
  store i8 %1100, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %1101 = add i64 %1081, -4
  %1102 = add i64 %1080, 9
  store i64 %1102, i64* %PC, align 8
  %1103 = inttoptr i64 %1101 to i32*
  %1104 = load i32, i32* %1103, align 4
  %1105 = sub i32 %1086, %1104
  %1106 = icmp ult i32 %1086, %1104
  %1107 = zext i1 %1106 to i8
  store i8 %1107, i8* %14, align 1, !tbaa !2433
  %1108 = and i32 %1105, 255
  %1109 = tail call i32 @llvm.ctpop.i32(i32 %1108) #10
  %1110 = trunc i32 %1109 to i8
  %1111 = and i8 %1110, 1
  %1112 = xor i8 %1111, 1
  store i8 %1112, i8* %21, align 1, !tbaa !2447
  %1113 = xor i32 %1104, %1086
  %1114 = xor i32 %1113, %1105
  %1115 = lshr i32 %1114, 4
  %1116 = trunc i32 %1115 to i8
  %1117 = and i8 %1116, 1
  store i8 %1117, i8* %27, align 1, !tbaa !2451
  %1118 = icmp eq i32 %1105, 0
  %1119 = zext i1 %1118 to i8
  store i8 %1119, i8* %30, align 1, !tbaa !2448
  %1120 = lshr i32 %1105, 31
  %1121 = trunc i32 %1120 to i8
  store i8 %1121, i8* %33, align 1, !tbaa !2449
  %1122 = lshr i32 %1085, 29
  %1123 = and i32 %1122, 1
  %1124 = lshr i32 %1104, 31
  %1125 = xor i32 %1124, %1123
  %1126 = xor i32 %1120, %1123
  %1127 = add nuw nsw i32 %1126, %1125
  %1128 = icmp eq i32 %1127, 2
  %1129 = zext i1 %1128 to i8
  store i8 %1129, i8* %39, align 1, !tbaa !2450
  %1130 = icmp ne i8 %1121, 0
  %1131 = xor i1 %1130, %1128
  %.v15 = select i1 %1131, i64 15, i64 48
  %1132 = add i64 %1080, %.v15
  store i64 %1132, i64* %PC, align 8, !tbaa !2428
  br i1 %1131, label %block_4018aa, label %block_4018cb

block_4018cb:                                     ; preds = %block_40189b
  %1133 = add i64 %1132, 5
  store i64 %1133, i64* %PC, align 8, !tbaa !2428
  br label %block_4018d0

block_401b1f:                                     ; preds = %block_401b13
  %1134 = add i64 %129, 3
  store i64 %1134, i64* %PC, align 8
  %1135 = load i32, i32* %96, align 4
  %1136 = zext i32 %1135 to i64
  store i64 %1136, i64* %RAX, align 8, !tbaa !2428
  %1137 = add i64 %129, 6
  store i64 %1137, i64* %PC, align 8
  %1138 = load i32, i32* %101, align 4
  %1139 = add i32 %1138, %1135
  %1140 = zext i32 %1139 to i64
  store i64 %1140, i64* %RAX, align 8, !tbaa !2428
  %1141 = icmp ult i32 %1139, %1135
  %1142 = icmp ult i32 %1139, %1138
  %1143 = or i1 %1141, %1142
  %1144 = zext i1 %1143 to i8
  store i8 %1144, i8* %14, align 1, !tbaa !2433
  %1145 = and i32 %1139, 255
  %1146 = tail call i32 @llvm.ctpop.i32(i32 %1145) #10
  %1147 = trunc i32 %1146 to i8
  %1148 = and i8 %1147, 1
  %1149 = xor i8 %1148, 1
  store i8 %1149, i8* %21, align 1, !tbaa !2447
  %1150 = xor i32 %1138, %1135
  %1151 = xor i32 %1150, %1139
  %1152 = lshr i32 %1151, 4
  %1153 = trunc i32 %1152 to i8
  %1154 = and i8 %1153, 1
  store i8 %1154, i8* %27, align 1, !tbaa !2451
  %1155 = icmp eq i32 %1139, 0
  %1156 = zext i1 %1155 to i8
  store i8 %1156, i8* %30, align 1, !tbaa !2448
  %1157 = lshr i32 %1139, 31
  %1158 = trunc i32 %1157 to i8
  store i8 %1158, i8* %33, align 1, !tbaa !2449
  %1159 = lshr i32 %1135, 31
  %1160 = lshr i32 %1138, 31
  %1161 = xor i32 %1157, %1159
  %1162 = xor i32 %1157, %1160
  %1163 = add nuw nsw i32 %1161, %1162
  %1164 = icmp eq i32 %1163, 2
  %1165 = zext i1 %1164 to i8
  store i8 %1165, i8* %39, align 1, !tbaa !2450
  %1166 = add i64 %93, -32
  %1167 = add i64 %129, 9
  store i64 %1167, i64* %PC, align 8
  %1168 = inttoptr i64 %1166 to i32*
  store i32 %1139, i32* %1168, align 4
  %1169 = load i64, i64* %RBP, align 8
  %1170 = add i64 %1169, -16
  %1171 = load i64, i64* %PC, align 8
  %1172 = add i64 %1171, 4
  store i64 %1172, i64* %PC, align 8
  %1173 = inttoptr i64 %1170 to i64*
  %1174 = load i64, i64* %1173, align 8
  store i64 %1174, i64* %RCX, align 8, !tbaa !2428
  %1175 = add i64 %1169, -28
  %1176 = add i64 %1171, 8
  store i64 %1176, i64* %PC, align 8
  %1177 = inttoptr i64 %1175 to i32*
  %1178 = load i32, i32* %1177, align 4
  %1179 = sext i32 %1178 to i64
  store i64 %1179, i64* %RDX, align 8, !tbaa !2428
  %1180 = shl nsw i64 %1179, 3
  %1181 = add i64 %1180, %1174
  %1182 = add i64 %1171, 13
  store i64 %1182, i64* %PC, align 8
  %1183 = inttoptr i64 %1181 to i64*
  %1184 = load i64, i64* %1183, align 8
  store i64 %1184, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %1185 = add i64 %1171, 17
  store i64 %1185, i64* %PC, align 8
  %1186 = load i64, i64* %1173, align 8
  store i64 %1186, i64* %RCX, align 8, !tbaa !2428
  %1187 = add i64 %1169, -32
  %1188 = add i64 %1171, 21
  store i64 %1188, i64* %PC, align 8
  %1189 = inttoptr i64 %1187 to i32*
  %1190 = load i32, i32* %1189, align 4
  %1191 = sext i32 %1190 to i64
  store i64 %1191, i64* %RDX, align 8, !tbaa !2428
  %1192 = shl nsw i64 %1191, 3
  %1193 = add i64 %1192, %1186
  %1194 = add i64 %1171, 26
  store i64 %1194, i64* %PC, align 8
  %1195 = bitcast i64 %1184 to double
  %1196 = inttoptr i64 %1193 to double*
  %1197 = load double, double* %1196, align 8
  %1198 = fsub double %1195, %1197
  store double %1198, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %1199 = add i64 %1169, -56
  %1200 = add i64 %1171, 31
  store i64 %1200, i64* %PC, align 8
  %1201 = inttoptr i64 %1199 to double*
  store double %1198, double* %1201, align 8
  %1202 = load i64, i64* %RBP, align 8
  %1203 = add i64 %1202, -16
  %1204 = load i64, i64* %PC, align 8
  %1205 = add i64 %1204, 4
  store i64 %1205, i64* %PC, align 8
  %1206 = inttoptr i64 %1203 to i64*
  %1207 = load i64, i64* %1206, align 8
  store i64 %1207, i64* %RCX, align 8, !tbaa !2428
  %1208 = add i64 %1202, -28
  %1209 = add i64 %1204, 7
  store i64 %1209, i64* %PC, align 8
  %1210 = inttoptr i64 %1208 to i32*
  %1211 = load i32, i32* %1210, align 4
  %1212 = add i32 %1211, 1
  %1213 = zext i32 %1212 to i64
  store i64 %1213, i64* %RAX, align 8, !tbaa !2428
  %1214 = icmp eq i32 %1211, -1
  %1215 = icmp eq i32 %1212, 0
  %1216 = or i1 %1214, %1215
  %1217 = zext i1 %1216 to i8
  store i8 %1217, i8* %14, align 1, !tbaa !2433
  %1218 = and i32 %1212, 255
  %1219 = tail call i32 @llvm.ctpop.i32(i32 %1218) #10
  %1220 = trunc i32 %1219 to i8
  %1221 = and i8 %1220, 1
  %1222 = xor i8 %1221, 1
  store i8 %1222, i8* %21, align 1, !tbaa !2447
  %1223 = xor i32 %1212, %1211
  %1224 = lshr i32 %1223, 4
  %1225 = trunc i32 %1224 to i8
  %1226 = and i8 %1225, 1
  store i8 %1226, i8* %27, align 1, !tbaa !2451
  %1227 = zext i1 %1215 to i8
  store i8 %1227, i8* %30, align 1, !tbaa !2448
  %1228 = lshr i32 %1212, 31
  %1229 = trunc i32 %1228 to i8
  store i8 %1229, i8* %33, align 1, !tbaa !2449
  %1230 = lshr i32 %1211, 31
  %1231 = xor i32 %1228, %1230
  %1232 = add nuw nsw i32 %1231, %1228
  %1233 = icmp eq i32 %1232, 2
  %1234 = zext i1 %1233 to i8
  store i8 %1234, i8* %39, align 1, !tbaa !2450
  %1235 = sext i32 %1212 to i64
  store i64 %1235, i64* %RDX, align 8, !tbaa !2428
  %1236 = shl nsw i64 %1235, 3
  %1237 = add i64 %1207, %1236
  %1238 = add i64 %1204, 18
  store i64 %1238, i64* %PC, align 8
  %1239 = inttoptr i64 %1237 to i64*
  %1240 = load i64, i64* %1239, align 8
  store i64 %1240, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %1241 = add i64 %1204, 22
  store i64 %1241, i64* %PC, align 8
  %1242 = load i64, i64* %1206, align 8
  store i64 %1242, i64* %RCX, align 8, !tbaa !2428
  %1243 = add i64 %1202, -32
  %1244 = add i64 %1204, 25
  store i64 %1244, i64* %PC, align 8
  %1245 = inttoptr i64 %1243 to i32*
  %1246 = load i32, i32* %1245, align 4
  %1247 = add i32 %1246, 1
  %1248 = zext i32 %1247 to i64
  store i64 %1248, i64* %RAX, align 8, !tbaa !2428
  %1249 = icmp eq i32 %1246, -1
  %1250 = icmp eq i32 %1247, 0
  %1251 = or i1 %1249, %1250
  %1252 = zext i1 %1251 to i8
  store i8 %1252, i8* %14, align 1, !tbaa !2433
  %1253 = and i32 %1247, 255
  %1254 = tail call i32 @llvm.ctpop.i32(i32 %1253) #10
  %1255 = trunc i32 %1254 to i8
  %1256 = and i8 %1255, 1
  %1257 = xor i8 %1256, 1
  store i8 %1257, i8* %21, align 1, !tbaa !2447
  %1258 = xor i32 %1247, %1246
  %1259 = lshr i32 %1258, 4
  %1260 = trunc i32 %1259 to i8
  %1261 = and i8 %1260, 1
  store i8 %1261, i8* %27, align 1, !tbaa !2451
  %1262 = zext i1 %1250 to i8
  store i8 %1262, i8* %30, align 1, !tbaa !2448
  %1263 = lshr i32 %1247, 31
  %1264 = trunc i32 %1263 to i8
  store i8 %1264, i8* %33, align 1, !tbaa !2449
  %1265 = lshr i32 %1246, 31
  %1266 = xor i32 %1263, %1265
  %1267 = add nuw nsw i32 %1266, %1263
  %1268 = icmp eq i32 %1267, 2
  %1269 = zext i1 %1268 to i8
  store i8 %1269, i8* %39, align 1, !tbaa !2450
  %1270 = sext i32 %1247 to i64
  store i64 %1270, i64* %RDX, align 8, !tbaa !2428
  %1271 = shl nsw i64 %1270, 3
  %1272 = add i64 %1242, %1271
  %1273 = add i64 %1204, 36
  store i64 %1273, i64* %PC, align 8
  %1274 = bitcast i64 %1240 to double
  %1275 = inttoptr i64 %1272 to double*
  %1276 = load double, double* %1275, align 8
  %1277 = fsub double %1274, %1276
  store double %1277, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %1278 = load i64, i64* %RBP, align 8
  %1279 = add i64 %1278, -64
  %1280 = add i64 %1204, 41
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to double*
  store double %1277, double* %1281, align 8
  %1282 = load i64, i64* %RBP, align 8
  %1283 = add i64 %1282, -16
  %1284 = load i64, i64* %PC, align 8
  %1285 = add i64 %1284, 4
  store i64 %1285, i64* %PC, align 8
  %1286 = inttoptr i64 %1283 to i64*
  %1287 = load i64, i64* %1286, align 8
  store i64 %1287, i64* %RCX, align 8, !tbaa !2428
  %1288 = add i64 %1282, -32
  %1289 = add i64 %1284, 8
  store i64 %1289, i64* %PC, align 8
  %1290 = inttoptr i64 %1288 to i32*
  %1291 = load i32, i32* %1290, align 4
  %1292 = sext i32 %1291 to i64
  store i64 %1292, i64* %RDX, align 8, !tbaa !2428
  %1293 = shl nsw i64 %1292, 3
  %1294 = add i64 %1293, %1287
  %1295 = add i64 %1284, 13
  store i64 %1295, i64* %PC, align 8
  %1296 = inttoptr i64 %1294 to i64*
  %1297 = load i64, i64* %1296, align 8
  store i64 %1297, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %1298 = add i64 %1284, 17
  store i64 %1298, i64* %PC, align 8
  %1299 = load i64, i64* %1286, align 8
  store i64 %1299, i64* %RCX, align 8, !tbaa !2428
  %1300 = add i64 %1282, -28
  %1301 = add i64 %1284, 21
  store i64 %1301, i64* %PC, align 8
  %1302 = inttoptr i64 %1300 to i32*
  %1303 = load i32, i32* %1302, align 4
  %1304 = sext i32 %1303 to i64
  store i64 %1304, i64* %RDX, align 8, !tbaa !2428
  %1305 = shl nsw i64 %1304, 3
  %1306 = add i64 %1305, %1299
  %1307 = add i64 %1284, 26
  store i64 %1307, i64* %PC, align 8
  %1308 = bitcast i64 %1297 to double
  %1309 = inttoptr i64 %1306 to double*
  %1310 = load double, double* %1309, align 8
  %1311 = fadd double %1308, %1310
  store double %1311, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %1312 = add i64 %1284, 31
  store i64 %1312, i64* %PC, align 8
  %1313 = inttoptr i64 %1306 to double*
  store double %1311, double* %1313, align 8
  %1314 = load i64, i64* %RBP, align 8
  %1315 = add i64 %1314, -16
  %1316 = load i64, i64* %PC, align 8
  %1317 = add i64 %1316, 4
  store i64 %1317, i64* %PC, align 8
  %1318 = inttoptr i64 %1315 to i64*
  %1319 = load i64, i64* %1318, align 8
  store i64 %1319, i64* %RCX, align 8, !tbaa !2428
  %1320 = add i64 %1314, -32
  %1321 = add i64 %1316, 7
  store i64 %1321, i64* %PC, align 8
  %1322 = inttoptr i64 %1320 to i32*
  %1323 = load i32, i32* %1322, align 4
  %1324 = add i32 %1323, 1
  %1325 = zext i32 %1324 to i64
  store i64 %1325, i64* %RAX, align 8, !tbaa !2428
  %1326 = icmp eq i32 %1323, -1
  %1327 = icmp eq i32 %1324, 0
  %1328 = or i1 %1326, %1327
  %1329 = zext i1 %1328 to i8
  store i8 %1329, i8* %14, align 1, !tbaa !2433
  %1330 = and i32 %1324, 255
  %1331 = tail call i32 @llvm.ctpop.i32(i32 %1330) #10
  %1332 = trunc i32 %1331 to i8
  %1333 = and i8 %1332, 1
  %1334 = xor i8 %1333, 1
  store i8 %1334, i8* %21, align 1, !tbaa !2447
  %1335 = xor i32 %1324, %1323
  %1336 = lshr i32 %1335, 4
  %1337 = trunc i32 %1336 to i8
  %1338 = and i8 %1337, 1
  store i8 %1338, i8* %27, align 1, !tbaa !2451
  %1339 = zext i1 %1327 to i8
  store i8 %1339, i8* %30, align 1, !tbaa !2448
  %1340 = lshr i32 %1324, 31
  %1341 = trunc i32 %1340 to i8
  store i8 %1341, i8* %33, align 1, !tbaa !2449
  %1342 = lshr i32 %1323, 31
  %1343 = xor i32 %1340, %1342
  %1344 = add nuw nsw i32 %1343, %1340
  %1345 = icmp eq i32 %1344, 2
  %1346 = zext i1 %1345 to i8
  store i8 %1346, i8* %39, align 1, !tbaa !2450
  %1347 = sext i32 %1324 to i64
  store i64 %1347, i64* %RDX, align 8, !tbaa !2428
  %1348 = shl nsw i64 %1347, 3
  %1349 = add i64 %1319, %1348
  %1350 = add i64 %1316, 18
  store i64 %1350, i64* %PC, align 8
  %1351 = inttoptr i64 %1349 to i64*
  %1352 = load i64, i64* %1351, align 8
  store i64 %1352, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %1353 = add i64 %1316, 22
  store i64 %1353, i64* %PC, align 8
  %1354 = load i64, i64* %1318, align 8
  store i64 %1354, i64* %RCX, align 8, !tbaa !2428
  %1355 = add i64 %1314, -28
  %1356 = add i64 %1316, 25
  store i64 %1356, i64* %PC, align 8
  %1357 = inttoptr i64 %1355 to i32*
  %1358 = load i32, i32* %1357, align 4
  %1359 = add i32 %1358, 1
  %1360 = zext i32 %1359 to i64
  store i64 %1360, i64* %RAX, align 8, !tbaa !2428
  %1361 = icmp eq i32 %1358, -1
  %1362 = icmp eq i32 %1359, 0
  %1363 = or i1 %1361, %1362
  %1364 = zext i1 %1363 to i8
  store i8 %1364, i8* %14, align 1, !tbaa !2433
  %1365 = and i32 %1359, 255
  %1366 = tail call i32 @llvm.ctpop.i32(i32 %1365) #10
  %1367 = trunc i32 %1366 to i8
  %1368 = and i8 %1367, 1
  %1369 = xor i8 %1368, 1
  store i8 %1369, i8* %21, align 1, !tbaa !2447
  %1370 = xor i32 %1359, %1358
  %1371 = lshr i32 %1370, 4
  %1372 = trunc i32 %1371 to i8
  %1373 = and i8 %1372, 1
  store i8 %1373, i8* %27, align 1, !tbaa !2451
  %1374 = zext i1 %1362 to i8
  store i8 %1374, i8* %30, align 1, !tbaa !2448
  %1375 = lshr i32 %1359, 31
  %1376 = trunc i32 %1375 to i8
  store i8 %1376, i8* %33, align 1, !tbaa !2449
  %1377 = lshr i32 %1358, 31
  %1378 = xor i32 %1375, %1377
  %1379 = add nuw nsw i32 %1378, %1375
  %1380 = icmp eq i32 %1379, 2
  %1381 = zext i1 %1380 to i8
  store i8 %1381, i8* %39, align 1, !tbaa !2450
  %1382 = sext i32 %1359 to i64
  store i64 %1382, i64* %RDX, align 8, !tbaa !2428
  %1383 = shl nsw i64 %1382, 3
  %1384 = add i64 %1354, %1383
  %1385 = add i64 %1316, 36
  store i64 %1385, i64* %PC, align 8
  %1386 = bitcast i64 %1352 to double
  %1387 = inttoptr i64 %1384 to double*
  %1388 = load double, double* %1387, align 8
  %1389 = fadd double %1386, %1388
  store double %1389, double* %1076, align 1, !tbaa !2452
  store i64 0, i64* %1078, align 1, !tbaa !2452
  %1390 = add i64 %1316, 41
  store i64 %1390, i64* %PC, align 8
  %1391 = inttoptr i64 %1384 to double*
  store double %1389, double* %1391, align 8
  %1392 = load i64, i64* %RBP, align 8
  %1393 = add i64 %1392, -56
  %1394 = load i64, i64* %PC, align 8
  %1395 = add i64 %1394, 5
  store i64 %1395, i64* %PC, align 8
  %1396 = inttoptr i64 %1393 to i64*
  %1397 = load i64, i64* %1396, align 8
  store i64 %1397, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %1398 = add i64 %1392, -16
  %1399 = add i64 %1394, 9
  store i64 %1399, i64* %PC, align 8
  %1400 = inttoptr i64 %1398 to i64*
  %1401 = load i64, i64* %1400, align 8
  store i64 %1401, i64* %RCX, align 8, !tbaa !2428
  %1402 = add i64 %1392, -32
  %1403 = add i64 %1394, 13
  store i64 %1403, i64* %PC, align 8
  %1404 = inttoptr i64 %1402 to i32*
  %1405 = load i32, i32* %1404, align 4
  %1406 = sext i32 %1405 to i64
  store i64 %1406, i64* %RDX, align 8, !tbaa !2428
  %1407 = shl nsw i64 %1406, 3
  %1408 = add i64 %1407, %1401
  %1409 = add i64 %1394, 18
  store i64 %1409, i64* %PC, align 8
  %1410 = inttoptr i64 %1408 to i64*
  store i64 %1397, i64* %1410, align 8
  %1411 = load i64, i64* %RBP, align 8
  %1412 = add i64 %1411, -64
  %1413 = load i64, i64* %PC, align 8
  %1414 = add i64 %1413, 5
  store i64 %1414, i64* %PC, align 8
  %1415 = inttoptr i64 %1412 to i64*
  %1416 = load i64, i64* %1415, align 8
  store i64 %1416, i64* %1077, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1079, align 1, !tbaa !2452
  %1417 = add i64 %1411, -16
  %1418 = add i64 %1413, 9
  store i64 %1418, i64* %PC, align 8
  %1419 = inttoptr i64 %1417 to i64*
  %1420 = load i64, i64* %1419, align 8
  store i64 %1420, i64* %RCX, align 8, !tbaa !2428
  %1421 = add i64 %1411, -32
  %1422 = add i64 %1413, 12
  store i64 %1422, i64* %PC, align 8
  %1423 = inttoptr i64 %1421 to i32*
  %1424 = load i32, i32* %1423, align 4
  %1425 = add i32 %1424, 1
  %1426 = zext i32 %1425 to i64
  store i64 %1426, i64* %RAX, align 8, !tbaa !2428
  %1427 = icmp eq i32 %1424, -1
  %1428 = icmp eq i32 %1425, 0
  %1429 = or i1 %1427, %1428
  %1430 = zext i1 %1429 to i8
  store i8 %1430, i8* %14, align 1, !tbaa !2433
  %1431 = and i32 %1425, 255
  %1432 = tail call i32 @llvm.ctpop.i32(i32 %1431) #10
  %1433 = trunc i32 %1432 to i8
  %1434 = and i8 %1433, 1
  %1435 = xor i8 %1434, 1
  store i8 %1435, i8* %21, align 1, !tbaa !2447
  %1436 = xor i32 %1425, %1424
  %1437 = lshr i32 %1436, 4
  %1438 = trunc i32 %1437 to i8
  %1439 = and i8 %1438, 1
  store i8 %1439, i8* %27, align 1, !tbaa !2451
  %1440 = zext i1 %1428 to i8
  store i8 %1440, i8* %30, align 1, !tbaa !2448
  %1441 = lshr i32 %1425, 31
  %1442 = trunc i32 %1441 to i8
  store i8 %1442, i8* %33, align 1, !tbaa !2449
  %1443 = lshr i32 %1424, 31
  %1444 = xor i32 %1441, %1443
  %1445 = add nuw nsw i32 %1444, %1441
  %1446 = icmp eq i32 %1445, 2
  %1447 = zext i1 %1446 to i8
  store i8 %1447, i8* %39, align 1, !tbaa !2450
  %1448 = sext i32 %1425 to i64
  store i64 %1448, i64* %RDX, align 8, !tbaa !2428
  %1449 = shl nsw i64 %1448, 3
  %1450 = add i64 %1420, %1449
  %1451 = add i64 %1413, 23
  store i64 %1451, i64* %PC, align 8
  %1452 = inttoptr i64 %1450 to i64*
  store i64 %1416, i64* %1452, align 8
  %1453 = load i64, i64* %RBP, align 8
  %1454 = add i64 %1453, -28
  %1455 = load i64, i64* %PC, align 8
  %1456 = add i64 %1455, 3
  store i64 %1456, i64* %PC, align 8
  %1457 = inttoptr i64 %1454 to i32*
  %1458 = load i32, i32* %1457, align 4
  %1459 = add i32 %1458, 2
  %1460 = zext i32 %1459 to i64
  store i64 %1460, i64* %RAX, align 8, !tbaa !2428
  %1461 = icmp ugt i32 %1458, -3
  %1462 = zext i1 %1461 to i8
  store i8 %1462, i8* %14, align 1, !tbaa !2433
  %1463 = and i32 %1459, 255
  %1464 = tail call i32 @llvm.ctpop.i32(i32 %1463) #10
  %1465 = trunc i32 %1464 to i8
  %1466 = and i8 %1465, 1
  %1467 = xor i8 %1466, 1
  store i8 %1467, i8* %21, align 1, !tbaa !2447
  %1468 = xor i32 %1459, %1458
  %1469 = lshr i32 %1468, 4
  %1470 = trunc i32 %1469 to i8
  %1471 = and i8 %1470, 1
  store i8 %1471, i8* %27, align 1, !tbaa !2451
  %1472 = icmp eq i32 %1459, 0
  %1473 = zext i1 %1472 to i8
  store i8 %1473, i8* %30, align 1, !tbaa !2448
  %1474 = lshr i32 %1459, 31
  %1475 = trunc i32 %1474 to i8
  store i8 %1475, i8* %33, align 1, !tbaa !2449
  %1476 = lshr i32 %1458, 31
  %1477 = xor i32 %1474, %1476
  %1478 = add nuw nsw i32 %1477, %1474
  %1479 = icmp eq i32 %1478, 2
  %1480 = zext i1 %1479 to i8
  store i8 %1480, i8* %39, align 1, !tbaa !2450
  %1481 = add i64 %1455, 9
  store i64 %1481, i64* %PC, align 8
  store i32 %1459, i32* %1457, align 4
  %1482 = load i64, i64* %PC, align 8
  %1483 = add i64 %1482, -215
  store i64 %1483, i64* %PC, align 8, !tbaa !2428
  br label %block_401b13

block_4018aa:                                     ; preds = %block_40189b
  %1484 = add i64 %1132, 3
  store i64 %1484, i64* %PC, align 8
  %1485 = load i32, i32* %1103, align 4
  %1486 = zext i32 %1485 to i64
  store i64 %1486, i64* %RDI, align 8, !tbaa !2428
  %1487 = add i64 %1132, 6
  store i64 %1487, i64* %PC, align 8
  %1488 = load i32, i32* %1084, align 4
  %1489 = zext i32 %1488 to i64
  store i64 %1489, i64* %RSI, align 8, !tbaa !2428
  %1490 = add i64 %1081, -16
  %1491 = add i64 %1132, 10
  store i64 %1491, i64* %PC, align 8
  %1492 = inttoptr i64 %1490 to i64*
  %1493 = load i64, i64* %1492, align 8
  store i64 %1493, i64* %RDX, align 8, !tbaa !2428
  %1494 = add i64 %1081, -24
  %1495 = add i64 %1132, 14
  store i64 %1495, i64* %PC, align 8
  %1496 = inttoptr i64 %1494 to i64*
  %1497 = load i64, i64* %1496, align 8
  store i64 %1497, i64* %RCX, align 8, !tbaa !2428
  %1498 = add i64 %1132, 6774
  %1499 = add i64 %1132, 19
  %1500 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1501 = add i64 %1500, -8
  %1502 = inttoptr i64 %1501 to i64*
  store i64 %1499, i64* %1502, align 8
  store i64 %1501, i64* %RSP, align 8, !tbaa !2428
  store i64 %1498, i64* %PC, align 8, !tbaa !2428
  %1503 = tail call %struct.Memory* @sub_403320_cftmdl(%struct.State* nonnull %0, i64 %1498, %struct.Memory* %1616)
  %1504 = load i64, i64* %RBP, align 8
  %1505 = add i64 %1504, -44
  %1506 = load i64, i64* %PC, align 8
  %1507 = add i64 %1506, 3
  store i64 %1507, i64* %PC, align 8
  %1508 = inttoptr i64 %1505 to i32*
  %1509 = load i32, i32* %1508, align 4
  %1510 = shl i32 %1509, 2
  %1511 = zext i32 %1510 to i64
  store i64 %1511, i64* %RSI, align 8, !tbaa !2428
  %1512 = lshr i32 %1509, 30
  %1513 = trunc i32 %1512 to i8
  %1514 = and i8 %1513, 1
  store i8 %1514, i8* %14, align 1, !tbaa !2432
  %1515 = and i32 %1510, 252
  %1516 = tail call i32 @llvm.ctpop.i32(i32 %1515) #10
  %1517 = trunc i32 %1516 to i8
  %1518 = and i8 %1517, 1
  %1519 = xor i8 %1518, 1
  store i8 %1519, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %1520 = icmp eq i32 %1510, 0
  %1521 = zext i1 %1520 to i8
  store i8 %1521, i8* %30, align 1, !tbaa !2432
  %1522 = lshr i32 %1509, 29
  %1523 = trunc i32 %1522 to i8
  %1524 = and i8 %1523, 1
  store i8 %1524, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %1525 = add i64 %1506, 9
  store i64 %1525, i64* %PC, align 8
  store i32 %1510, i32* %1508, align 4
  %1526 = load i64, i64* %PC, align 8
  %1527 = add i64 %1526, -43
  store i64 %1527, i64* %PC, align 8, !tbaa !2428
  br label %block_40189b

block_401bf4.loopexit:                            ; preds = %block_4018e6
  br label %block_401bf4

block_401bf4.loopexit26:                          ; preds = %block_401b13
  br label %block_401bf4

block_401bf4:                                     ; preds = %block_401bf4.loopexit26, %block_401bf4.loopexit
  %1528 = phi i64 [ %1599, %block_401bf4.loopexit ], [ %129, %block_401bf4.loopexit26 ]
  %.sink5 = phi i64 [ 237, %block_401bf4.loopexit ], [ 5, %block_401bf4.loopexit26 ]
  %1529 = add i64 %1528, %.sink5
  %1530 = load i64, i64* %RSP, align 8
  %1531 = add i64 %1530, 112
  store i64 %1531, i64* %RSP, align 8, !tbaa !2428
  %1532 = icmp ugt i64 %1530, -113
  %1533 = zext i1 %1532 to i8
  store i8 %1533, i8* %14, align 1, !tbaa !2433
  %1534 = trunc i64 %1531 to i32
  %1535 = and i32 %1534, 255
  %1536 = tail call i32 @llvm.ctpop.i32(i32 %1535) #10
  %1537 = trunc i32 %1536 to i8
  %1538 = and i8 %1537, 1
  %1539 = xor i8 %1538, 1
  store i8 %1539, i8* %21, align 1, !tbaa !2447
  %1540 = xor i64 %1530, 16
  %1541 = xor i64 %1540, %1531
  %1542 = lshr i64 %1541, 4
  %1543 = trunc i64 %1542 to i8
  %1544 = and i8 %1543, 1
  store i8 %1544, i8* %27, align 1, !tbaa !2451
  %1545 = icmp eq i64 %1531, 0
  %1546 = zext i1 %1545 to i8
  store i8 %1546, i8* %30, align 1, !tbaa !2448
  %1547 = lshr i64 %1531, 63
  %1548 = trunc i64 %1547 to i8
  store i8 %1548, i8* %33, align 1, !tbaa !2449
  %1549 = lshr i64 %1530, 63
  %1550 = xor i64 %1547, %1549
  %1551 = add nuw nsw i64 %1550, %1547
  %1552 = icmp eq i64 %1551, 2
  %1553 = zext i1 %1552 to i8
  store i8 %1553, i8* %39, align 1, !tbaa !2450
  %1554 = add i64 %1529, 5
  store i64 %1554, i64* %PC, align 8
  %1555 = add i64 %1530, 120
  %1556 = inttoptr i64 %1531 to i64*
  %1557 = load i64, i64* %1556, align 8
  store i64 %1557, i64* %RBP, align 8, !tbaa !2428
  store i64 %1555, i64* %RSP, align 8, !tbaa !2428
  %1558 = add i64 %1529, 6
  store i64 %1558, i64* %PC, align 8
  %1559 = inttoptr i64 %1555 to i64*
  %1560 = load i64, i64* %1559, align 8
  store i64 %1560, i64* %PC, align 8, !tbaa !2428
  %1561 = add i64 %1530, 128
  store i64 %1561, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_4018e6:                                     ; preds = %block_4018e6.preheader, %block_4018f2
  %1562 = phi i64 [ %1021, %block_4018f2 ], [ %.pre12, %block_4018e6.preheader ]
  %1563 = load i64, i64* %RBP, align 8
  %1564 = add i64 %1563, -28
  %1565 = add i64 %1562, 3
  store i64 %1565, i64* %PC, align 8
  %1566 = inttoptr i64 %1564 to i32*
  %1567 = load i32, i32* %1566, align 4
  %1568 = zext i32 %1567 to i64
  store i64 %1568, i64* %RAX, align 8, !tbaa !2428
  %1569 = add i64 %1563, -44
  %1570 = add i64 %1562, 6
  store i64 %1570, i64* %PC, align 8
  %1571 = inttoptr i64 %1569 to i32*
  %1572 = load i32, i32* %1571, align 4
  %1573 = sub i32 %1567, %1572
  %1574 = icmp ult i32 %1567, %1572
  %1575 = zext i1 %1574 to i8
  store i8 %1575, i8* %14, align 1, !tbaa !2433
  %1576 = and i32 %1573, 255
  %1577 = tail call i32 @llvm.ctpop.i32(i32 %1576) #10
  %1578 = trunc i32 %1577 to i8
  %1579 = and i8 %1578, 1
  %1580 = xor i8 %1579, 1
  store i8 %1580, i8* %21, align 1, !tbaa !2447
  %1581 = xor i32 %1572, %1567
  %1582 = xor i32 %1581, %1573
  %1583 = lshr i32 %1582, 4
  %1584 = trunc i32 %1583 to i8
  %1585 = and i8 %1584, 1
  store i8 %1585, i8* %27, align 1, !tbaa !2451
  %1586 = icmp eq i32 %1573, 0
  %1587 = zext i1 %1586 to i8
  store i8 %1587, i8* %30, align 1, !tbaa !2448
  %1588 = lshr i32 %1573, 31
  %1589 = trunc i32 %1588 to i8
  store i8 %1589, i8* %33, align 1, !tbaa !2449
  %1590 = lshr i32 %1567, 31
  %1591 = lshr i32 %1572, 31
  %1592 = xor i32 %1591, %1590
  %1593 = xor i32 %1588, %1590
  %1594 = add nuw nsw i32 %1593, %1592
  %1595 = icmp eq i32 %1594, 2
  %1596 = zext i1 %1595 to i8
  store i8 %1596, i8* %39, align 1, !tbaa !2450
  %1597 = icmp ne i8 %1589, 0
  %1598 = xor i1 %1597, %1595
  %.v17 = select i1 %1598, i64 12, i64 545
  %1599 = add i64 %1562, %.v17
  store i64 %1599, i64* %PC, align 8, !tbaa !2428
  br i1 %1598, label %block_4018f2, label %block_401bf4.loopexit

block_401884:                                     ; preds = %block_401860
  %1600 = add i64 %91, 3
  store i64 %1600, i64* %PC, align 8
  %1601 = load i32, i32* %65, align 4
  %1602 = zext i32 %1601 to i64
  store i64 %1602, i64* %RDI, align 8, !tbaa !2428
  %1603 = add i64 %61, -16
  %1604 = add i64 %91, 7
  store i64 %1604, i64* %PC, align 8
  %1605 = inttoptr i64 %1603 to i64*
  %1606 = load i64, i64* %1605, align 8
  store i64 %1606, i64* %RSI, align 8, !tbaa !2428
  %1607 = add i64 %61, -24
  %1608 = add i64 %91, 11
  store i64 %1608, i64* %PC, align 8
  %1609 = inttoptr i64 %1607 to i64*
  %1610 = load i64, i64* %1609, align 8
  store i64 %1610, i64* %RDX, align 8, !tbaa !2428
  %1611 = add i64 %91, 4108
  %1612 = add i64 %91, 16
  %1613 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1614 = add i64 %1613, -8
  %1615 = inttoptr i64 %1614 to i64*
  store i64 %1612, i64* %1615, align 8
  store i64 %1614, i64* %RSP, align 8, !tbaa !2428
  store i64 %1611, i64* %PC, align 8, !tbaa !2428
  %1616 = tail call %struct.Memory* @sub_402890_cft1st(%struct.State* nonnull %0, i64 %1611, %struct.Memory* %2)
  %1617 = load i64, i64* %RBP, align 8
  %1618 = add i64 %1617, -44
  %1619 = load i64, i64* %PC, align 8
  %1620 = add i64 %1619, 7
  store i64 %1620, i64* %PC, align 8
  %1621 = inttoptr i64 %1618 to i32*
  store i32 8, i32* %1621, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_40189b
}

; Function Attrs: noinline norecurse nounwind
define %struct.Memory* @sub_404080___libc_csu_fini(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #8 {
block_404080:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400790_deregister_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400790:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* %RSP, align 8, !tbaa !2428
  %6 = add i64 %5, -8
  %7 = inttoptr i64 %6 to i64*
  store i64 %3, i64* %7, align 8
  store i64 %6, i64* %RSP, align 8, !tbaa !2428
  %8 = load i64, i64* %PC, align 8
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RAX, align 8, !tbaa !2428
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 zext (i1 icmp ult (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i8), i8* %9, align 1, !tbaa !2433
  %10 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i32), i32 255)) #10
  %11 = trunc i32 %10 to i8
  %12 = and i8 %11, 1
  %13 = xor i8 %12, 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %13, i8* %14, align 1, !tbaa !2447
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295)), i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64))), i64 4) to i8), i8 1), i8* %15, align 1, !tbaa !2451
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 zext (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0) to i8), i8* %16, align 1, !tbaa !2448
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 trunc (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63) to i8), i8* %17, align 1, !tbaa !2449
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63)), i64 xor (i64 lshr (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63))), i64 2) to i8), i8* %18, align 1, !tbaa !2450
  store i64 %6, i64* %RBP, align 8, !tbaa !2428
  %19 = add i64 %8, select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16)
  store i64 %19, i64* %PC, align 8, !tbaa !2428
  br i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), label %block_4007b8, label %block_4007a1

block_4007b8:                                     ; preds = %block_4007a1, %block_400790
  %20 = phi i64 [ %27, %block_4007a1 ], [ %19, %block_400790 ]
  %21 = add i64 %20, 1
  store i64 %21, i64* %PC, align 8
  %22 = load i64, i64* %7, align 8
  store i64 %22, i64* %RBP, align 8, !tbaa !2428
  store i64 %5, i64* %RSP, align 8, !tbaa !2428
  %23 = add i64 %20, 2
  store i64 %23, i64* %PC, align 8
  %24 = inttoptr i64 %5 to i64*
  %25 = load i64, i64* %24, align 8
  store i64 %25, i64* %PC, align 8, !tbaa !2428
  %26 = add i64 %5, 8
  store i64 %26, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_4007a1:                                     ; preds = %block_400790
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %9, align 1, !tbaa !2433
  store i8 1, i8* %14, align 1, !tbaa !2447
  store i8 1, i8* %16, align 1, !tbaa !2448
  store i8 0, i8* %17, align 1, !tbaa !2449
  store i8 0, i8* %18, align 1, !tbaa !2450
  store i8 0, i8* %15, align 1, !tbaa !2451
  %27 = add i64 %8, add (i64 select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16), i64 23)
  store i64 %27, i64* %PC, align 8, !tbaa !2428
  br label %block_4007b8
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400830_frame_dummy(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400830:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %8, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %12 = add i64 %9, -113
  store i64 %12, i64* %PC, align 8, !tbaa !2428
  %13 = tail call %struct.Memory* @sub_4007c0_register_tm_clones(%struct.State* nonnull %0, i64 %12, %struct.Memory* %2)
  ret %struct.Memory* %13
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4007c0_register_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4007c0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RSI, align 8, !tbaa !2428
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 6
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* %RSP, align 8, !tbaa !2428
  %6 = add i64 %5, -8
  %7 = inttoptr i64 %6 to i64*
  store i64 %3, i64* %7, align 8
  store i64 %6, i64* %RSP, align 8, !tbaa !2428
  %8 = load i64, i64* %RSI, align 8
  %9 = load i64, i64* %PC, align 8
  %10 = sub i64 %8, ptrtoint (%__bss_start_type* @__bss_start to i64)
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %6, i64* %RBP, align 8, !tbaa !2428
  %17 = ashr i64 %10, 3
  %18 = lshr i64 %17, 63
  store i64 %18, i64* %RAX, align 8, !tbaa !2428
  %19 = add nsw i64 %18, %17
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = ashr i64 %19, 1
  store i64 %22, i64* %RSI, align 8, !tbaa !2428
  store i8 %21, i8* %11, align 1, !tbaa !2432
  %23 = trunc i64 %22 to i32
  %24 = and i32 %23, 255
  %25 = tail call i32 @llvm.ctpop.i32(i32 %24) #10
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = xor i8 %27, 1
  store i8 %28, i8* %12, align 1, !tbaa !2432
  store i8 0, i8* %13, align 1, !tbaa !2432
  %29 = icmp eq i64 %22, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %14, align 1, !tbaa !2432
  %31 = lshr i64 %22, 63
  %32 = trunc i64 %31 to i8
  store i8 %32, i8* %15, align 1, !tbaa !2432
  store i8 0, i8* %16, align 1, !tbaa !2432
  %.v = select i1 %29, i64 50, i64 29
  %33 = add i64 %9, %.v
  store i64 %33, i64* %PC, align 8, !tbaa !2428
  br i1 %29, label %block_4007f8, label %block_4007e3

block_4007f8:                                     ; preds = %block_4007e3, %block_4007c0
  %34 = phi i64 [ %44, %block_4007e3 ], [ %33, %block_4007c0 ]
  %35 = add i64 %34, 1
  store i64 %35, i64* %PC, align 8
  %36 = load i64, i64* %RSP, align 8, !tbaa !2428
  %37 = add i64 %36, 8
  %38 = inttoptr i64 %36 to i64*
  %39 = load i64, i64* %38, align 8
  store i64 %39, i64* %RBP, align 8, !tbaa !2428
  store i64 %37, i64* %RSP, align 8, !tbaa !2428
  %40 = add i64 %34, 2
  store i64 %40, i64* %PC, align 8
  %41 = inttoptr i64 %37 to i64*
  %42 = load i64, i64* %41, align 8
  store i64 %42, i64* %PC, align 8, !tbaa !2428
  %43 = add i64 %36, 16
  store i64 %43, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_4007e3:                                     ; preds = %block_4007c0
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %11, align 1, !tbaa !2433
  store i8 1, i8* %12, align 1, !tbaa !2447
  store i8 1, i8* %14, align 1, !tbaa !2448
  store i8 0, i8* %15, align 1, !tbaa !2449
  store i8 0, i8* %16, align 1, !tbaa !2450
  store i8 0, i8* %13, align 1, !tbaa !2451
  %44 = add i64 %33, 21
  store i64 %44, i64* %PC, align 8, !tbaa !2428
  br label %block_4007f8
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_402890_cft1st(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_402890:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = add i64 %9, -32
  store i64 %13, i64* %RSP, align 8, !tbaa !2428
  %14 = icmp ult i64 %10, 24
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1, !tbaa !2433
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #10
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1, !tbaa !2447
  %24 = xor i64 %10, 16
  %25 = xor i64 %24, %13
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1, !tbaa !2451
  %30 = icmp eq i64 %13, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1, !tbaa !2448
  %33 = lshr i64 %13, 63
  %34 = trunc i64 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1, !tbaa !2449
  %36 = lshr i64 %10, 63
  %37 = xor i64 %33, %36
  %38 = add nuw nsw i64 %37, %36
  %39 = icmp eq i64 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1, !tbaa !2450
  %42 = add i64 %9, -12
  %43 = load i32, i32* %EDI, align 4
  %44 = add i64 %12, 10
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %42 to i32*
  store i32 %43, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -16
  %48 = load i64, i64* %RSI, align 8
  %49 = load i64, i64* %PC, align 8
  %50 = add i64 %49, 4
  store i64 %50, i64* %PC, align 8
  %51 = inttoptr i64 %47 to i64*
  store i64 %48, i64* %51, align 8
  %52 = load i64, i64* %RBP, align 8
  %53 = add i64 %52, -24
  %54 = load i64, i64* %RDX, align 8
  %55 = load i64, i64* %PC, align 8
  %56 = add i64 %55, 4
  store i64 %56, i64* %PC, align 8
  %57 = inttoptr i64 %53 to i64*
  store i64 %54, i64* %57, align 8
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -16
  %60 = load i64, i64* %PC, align 8
  %61 = add i64 %60, 4
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %59 to i64*
  %63 = load i64, i64* %62, align 8
  store i64 %63, i64* %RDX, align 8, !tbaa !2428
  %64 = add i64 %60, 8
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %63 to i64*
  %66 = load i64, i64* %65, align 8
  %67 = bitcast [32 x %union.VectorReg]* %4 to double*
  %68 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %66, i64* %68, align 1, !tbaa !2452
  %69 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %70 = bitcast i64* %69 to double*
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %71 = add i64 %60, 12
  store i64 %71, i64* %PC, align 8
  %72 = load i64, i64* %62, align 8
  store i64 %72, i64* %RDX, align 8, !tbaa !2428
  %73 = add i64 %72, 16
  %74 = add i64 %60, 17
  store i64 %74, i64* %PC, align 8
  %75 = bitcast i64 %66 to double
  %76 = inttoptr i64 %73 to double*
  %77 = load double, double* %76, align 8
  %78 = fadd double %75, %77
  store double %78, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %79 = add i64 %58, -96
  %80 = add i64 %60, 22
  store i64 %80, i64* %PC, align 8
  %81 = inttoptr i64 %79 to double*
  store double %78, double* %81, align 8
  %82 = load i64, i64* %RBP, align 8
  %83 = add i64 %82, -16
  %84 = load i64, i64* %PC, align 8
  %85 = add i64 %84, 4
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %83 to i64*
  %87 = load i64, i64* %86, align 8
  store i64 %87, i64* %RDX, align 8, !tbaa !2428
  %88 = add i64 %87, 8
  %89 = add i64 %84, 9
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %88 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %92 = add i64 %84, 13
  store i64 %92, i64* %PC, align 8
  %93 = load i64, i64* %86, align 8
  store i64 %93, i64* %RDX, align 8, !tbaa !2428
  %94 = add i64 %93, 24
  %95 = add i64 %84, 18
  store i64 %95, i64* %PC, align 8
  %96 = bitcast i64 %91 to double
  %97 = inttoptr i64 %94 to double*
  %98 = load double, double* %97, align 8
  %99 = fadd double %96, %98
  store double %99, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %100 = add i64 %82, -104
  %101 = add i64 %84, 23
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to double*
  store double %99, double* %102, align 8
  %103 = load i64, i64* %RBP, align 8
  %104 = add i64 %103, -16
  %105 = load i64, i64* %PC, align 8
  %106 = add i64 %105, 4
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %104 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RDX, align 8, !tbaa !2428
  %109 = add i64 %105, 8
  store i64 %109, i64* %PC, align 8
  %110 = inttoptr i64 %108 to i64*
  %111 = load i64, i64* %110, align 8
  store i64 %111, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %112 = add i64 %105, 12
  store i64 %112, i64* %PC, align 8
  %113 = load i64, i64* %107, align 8
  store i64 %113, i64* %RDX, align 8, !tbaa !2428
  %114 = add i64 %113, 16
  %115 = add i64 %105, 17
  store i64 %115, i64* %PC, align 8
  %116 = bitcast i64 %111 to double
  %117 = inttoptr i64 %114 to double*
  %118 = load double, double* %117, align 8
  %119 = fsub double %116, %118
  store double %119, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %120 = add i64 %103, -112
  %121 = add i64 %105, 22
  store i64 %121, i64* %PC, align 8
  %122 = inttoptr i64 %120 to double*
  store double %119, double* %122, align 8
  %123 = load i64, i64* %RBP, align 8
  %124 = add i64 %123, -16
  %125 = load i64, i64* %PC, align 8
  %126 = add i64 %125, 4
  store i64 %126, i64* %PC, align 8
  %127 = inttoptr i64 %124 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %RDX, align 8, !tbaa !2428
  %129 = add i64 %128, 8
  %130 = add i64 %125, 9
  store i64 %130, i64* %PC, align 8
  %131 = inttoptr i64 %129 to i64*
  %132 = load i64, i64* %131, align 8
  store i64 %132, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %133 = add i64 %125, 13
  store i64 %133, i64* %PC, align 8
  %134 = load i64, i64* %127, align 8
  store i64 %134, i64* %RDX, align 8, !tbaa !2428
  %135 = add i64 %134, 24
  %136 = add i64 %125, 18
  store i64 %136, i64* %PC, align 8
  %137 = bitcast i64 %132 to double
  %138 = inttoptr i64 %135 to double*
  %139 = load double, double* %138, align 8
  %140 = fsub double %137, %139
  store double %140, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %141 = add i64 %123, -120
  %142 = add i64 %125, 23
  store i64 %142, i64* %PC, align 8
  %143 = inttoptr i64 %141 to double*
  store double %140, double* %143, align 8
  %144 = load i64, i64* %RBP, align 8
  %145 = add i64 %144, -16
  %146 = load i64, i64* %PC, align 8
  %147 = add i64 %146, 4
  store i64 %147, i64* %PC, align 8
  %148 = inttoptr i64 %145 to i64*
  %149 = load i64, i64* %148, align 8
  store i64 %149, i64* %RDX, align 8, !tbaa !2428
  %150 = add i64 %149, 32
  %151 = add i64 %146, 9
  store i64 %151, i64* %PC, align 8
  %152 = inttoptr i64 %150 to i64*
  %153 = load i64, i64* %152, align 8
  store i64 %153, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %154 = add i64 %146, 13
  store i64 %154, i64* %PC, align 8
  %155 = load i64, i64* %148, align 8
  store i64 %155, i64* %RDX, align 8, !tbaa !2428
  %156 = add i64 %155, 48
  %157 = add i64 %146, 18
  store i64 %157, i64* %PC, align 8
  %158 = bitcast i64 %153 to double
  %159 = inttoptr i64 %156 to double*
  %160 = load double, double* %159, align 8
  %161 = fadd double %158, %160
  store double %161, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %162 = add i64 %144, -128
  %163 = add i64 %146, 23
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %162 to double*
  store double %161, double* %164, align 8
  %165 = load i64, i64* %RBP, align 8
  %166 = add i64 %165, -16
  %167 = load i64, i64* %PC, align 8
  %168 = add i64 %167, 4
  store i64 %168, i64* %PC, align 8
  %169 = inttoptr i64 %166 to i64*
  %170 = load i64, i64* %169, align 8
  store i64 %170, i64* %RDX, align 8, !tbaa !2428
  %171 = add i64 %170, 40
  %172 = add i64 %167, 9
  store i64 %172, i64* %PC, align 8
  %173 = inttoptr i64 %171 to i64*
  %174 = load i64, i64* %173, align 8
  store i64 %174, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %175 = add i64 %167, 13
  store i64 %175, i64* %PC, align 8
  %176 = load i64, i64* %169, align 8
  store i64 %176, i64* %RDX, align 8, !tbaa !2428
  %177 = add i64 %176, 56
  %178 = add i64 %167, 18
  store i64 %178, i64* %PC, align 8
  %179 = bitcast i64 %174 to double
  %180 = inttoptr i64 %177 to double*
  %181 = load double, double* %180, align 8
  %182 = fadd double %179, %181
  store double %182, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %183 = add i64 %165, -136
  %184 = add i64 %167, 26
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %183 to double*
  store double %182, double* %185, align 8
  %186 = load i64, i64* %RBP, align 8
  %187 = add i64 %186, -16
  %188 = load i64, i64* %PC, align 8
  %189 = add i64 %188, 4
  store i64 %189, i64* %PC, align 8
  %190 = inttoptr i64 %187 to i64*
  %191 = load i64, i64* %190, align 8
  store i64 %191, i64* %RDX, align 8, !tbaa !2428
  %192 = add i64 %191, 32
  %193 = add i64 %188, 9
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to i64*
  %195 = load i64, i64* %194, align 8
  store i64 %195, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %196 = add i64 %188, 13
  store i64 %196, i64* %PC, align 8
  %197 = load i64, i64* %190, align 8
  store i64 %197, i64* %RDX, align 8, !tbaa !2428
  %198 = add i64 %197, 48
  %199 = add i64 %188, 18
  store i64 %199, i64* %PC, align 8
  %200 = bitcast i64 %195 to double
  %201 = inttoptr i64 %198 to double*
  %202 = load double, double* %201, align 8
  %203 = fsub double %200, %202
  store double %203, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %204 = add i64 %186, -144
  %205 = add i64 %188, 26
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %204 to double*
  store double %203, double* %206, align 8
  %207 = load i64, i64* %RBP, align 8
  %208 = add i64 %207, -16
  %209 = load i64, i64* %PC, align 8
  %210 = add i64 %209, 4
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %208 to i64*
  %212 = load i64, i64* %211, align 8
  store i64 %212, i64* %RDX, align 8, !tbaa !2428
  %213 = add i64 %212, 40
  %214 = add i64 %209, 9
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i64*
  %216 = load i64, i64* %215, align 8
  store i64 %216, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %217 = add i64 %209, 13
  store i64 %217, i64* %PC, align 8
  %218 = load i64, i64* %211, align 8
  store i64 %218, i64* %RDX, align 8, !tbaa !2428
  %219 = add i64 %218, 56
  %220 = add i64 %209, 18
  store i64 %220, i64* %PC, align 8
  %221 = bitcast i64 %216 to double
  %222 = inttoptr i64 %219 to double*
  %223 = load double, double* %222, align 8
  %224 = fsub double %221, %223
  store double %224, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %225 = add i64 %207, -152
  %226 = add i64 %209, 26
  store i64 %226, i64* %PC, align 8
  %227 = inttoptr i64 %225 to double*
  store double %224, double* %227, align 8
  %228 = load i64, i64* %RBP, align 8
  %229 = add i64 %228, -96
  %230 = load i64, i64* %PC, align 8
  %231 = add i64 %230, 5
  store i64 %231, i64* %PC, align 8
  %232 = inttoptr i64 %229 to i64*
  %233 = load i64, i64* %232, align 8
  store i64 %233, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %234 = add i64 %228, -128
  %235 = add i64 %230, 10
  store i64 %235, i64* %PC, align 8
  %236 = bitcast i64 %233 to double
  %237 = inttoptr i64 %234 to double*
  %238 = load double, double* %237, align 8
  %239 = fadd double %236, %238
  store double %239, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %240 = add i64 %228, -16
  %241 = add i64 %230, 14
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %240 to i64*
  %243 = load i64, i64* %242, align 8
  store i64 %243, i64* %RDX, align 8, !tbaa !2428
  %244 = add i64 %230, 18
  store i64 %244, i64* %PC, align 8
  %245 = inttoptr i64 %243 to double*
  store double %239, double* %245, align 8
  %246 = load i64, i64* %RBP, align 8
  %247 = add i64 %246, -104
  %248 = load i64, i64* %PC, align 8
  %249 = add i64 %248, 5
  store i64 %249, i64* %PC, align 8
  %250 = inttoptr i64 %247 to i64*
  %251 = load i64, i64* %250, align 8
  store i64 %251, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %252 = add i64 %246, -136
  %253 = add i64 %248, 13
  store i64 %253, i64* %PC, align 8
  %254 = bitcast i64 %251 to double
  %255 = inttoptr i64 %252 to double*
  %256 = load double, double* %255, align 8
  %257 = fadd double %254, %256
  store double %257, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %258 = add i64 %246, -16
  %259 = add i64 %248, 17
  store i64 %259, i64* %PC, align 8
  %260 = inttoptr i64 %258 to i64*
  %261 = load i64, i64* %260, align 8
  store i64 %261, i64* %RDX, align 8, !tbaa !2428
  %262 = add i64 %261, 8
  %263 = add i64 %248, 22
  store i64 %263, i64* %PC, align 8
  %264 = inttoptr i64 %262 to double*
  store double %257, double* %264, align 8
  %265 = load i64, i64* %RBP, align 8
  %266 = add i64 %265, -96
  %267 = load i64, i64* %PC, align 8
  %268 = add i64 %267, 5
  store i64 %268, i64* %PC, align 8
  %269 = inttoptr i64 %266 to i64*
  %270 = load i64, i64* %269, align 8
  store i64 %270, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %271 = add i64 %265, -128
  %272 = add i64 %267, 10
  store i64 %272, i64* %PC, align 8
  %273 = bitcast i64 %270 to double
  %274 = inttoptr i64 %271 to double*
  %275 = load double, double* %274, align 8
  %276 = fsub double %273, %275
  store double %276, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %277 = add i64 %265, -16
  %278 = add i64 %267, 14
  store i64 %278, i64* %PC, align 8
  %279 = inttoptr i64 %277 to i64*
  %280 = load i64, i64* %279, align 8
  store i64 %280, i64* %RDX, align 8, !tbaa !2428
  %281 = add i64 %280, 32
  %282 = add i64 %267, 19
  store i64 %282, i64* %PC, align 8
  %283 = inttoptr i64 %281 to double*
  store double %276, double* %283, align 8
  %284 = load i64, i64* %RBP, align 8
  %285 = add i64 %284, -104
  %286 = load i64, i64* %PC, align 8
  %287 = add i64 %286, 5
  store i64 %287, i64* %PC, align 8
  %288 = inttoptr i64 %285 to i64*
  %289 = load i64, i64* %288, align 8
  store i64 %289, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %290 = add i64 %284, -136
  %291 = add i64 %286, 13
  store i64 %291, i64* %PC, align 8
  %292 = bitcast i64 %289 to double
  %293 = inttoptr i64 %290 to double*
  %294 = load double, double* %293, align 8
  %295 = fsub double %292, %294
  store double %295, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %296 = add i64 %284, -16
  %297 = add i64 %286, 17
  store i64 %297, i64* %PC, align 8
  %298 = inttoptr i64 %296 to i64*
  %299 = load i64, i64* %298, align 8
  store i64 %299, i64* %RDX, align 8, !tbaa !2428
  %300 = add i64 %299, 40
  %301 = add i64 %286, 22
  store i64 %301, i64* %PC, align 8
  %302 = inttoptr i64 %300 to double*
  store double %295, double* %302, align 8
  %303 = load i64, i64* %RBP, align 8
  %304 = add i64 %303, -112
  %305 = load i64, i64* %PC, align 8
  %306 = add i64 %305, 5
  store i64 %306, i64* %PC, align 8
  %307 = inttoptr i64 %304 to i64*
  %308 = load i64, i64* %307, align 8
  store i64 %308, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %309 = add i64 %303, -152
  %310 = add i64 %305, 13
  store i64 %310, i64* %PC, align 8
  %311 = bitcast i64 %308 to double
  %312 = inttoptr i64 %309 to double*
  %313 = load double, double* %312, align 8
  %314 = fsub double %311, %313
  store double %314, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %315 = add i64 %303, -16
  %316 = add i64 %305, 17
  store i64 %316, i64* %PC, align 8
  %317 = inttoptr i64 %315 to i64*
  %318 = load i64, i64* %317, align 8
  store i64 %318, i64* %RDX, align 8, !tbaa !2428
  %319 = add i64 %318, 16
  %320 = add i64 %305, 22
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to double*
  store double %314, double* %321, align 8
  %322 = load i64, i64* %RBP, align 8
  %323 = add i64 %322, -120
  %324 = load i64, i64* %PC, align 8
  %325 = add i64 %324, 5
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %323 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %328 = add i64 %322, -144
  %329 = add i64 %324, 13
  store i64 %329, i64* %PC, align 8
  %330 = bitcast i64 %327 to double
  %331 = inttoptr i64 %328 to double*
  %332 = load double, double* %331, align 8
  %333 = fadd double %330, %332
  store double %333, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %334 = add i64 %322, -16
  %335 = add i64 %324, 17
  store i64 %335, i64* %PC, align 8
  %336 = inttoptr i64 %334 to i64*
  %337 = load i64, i64* %336, align 8
  store i64 %337, i64* %RDX, align 8, !tbaa !2428
  %338 = add i64 %337, 24
  %339 = add i64 %324, 22
  store i64 %339, i64* %PC, align 8
  %340 = inttoptr i64 %338 to double*
  store double %333, double* %340, align 8
  %341 = load i64, i64* %RBP, align 8
  %342 = add i64 %341, -112
  %343 = load i64, i64* %PC, align 8
  %344 = add i64 %343, 5
  store i64 %344, i64* %PC, align 8
  %345 = inttoptr i64 %342 to i64*
  %346 = load i64, i64* %345, align 8
  store i64 %346, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %347 = add i64 %341, -152
  %348 = add i64 %343, 13
  store i64 %348, i64* %PC, align 8
  %349 = bitcast i64 %346 to double
  %350 = inttoptr i64 %347 to double*
  %351 = load double, double* %350, align 8
  %352 = fadd double %349, %351
  store double %352, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %353 = add i64 %341, -16
  %354 = add i64 %343, 17
  store i64 %354, i64* %PC, align 8
  %355 = inttoptr i64 %353 to i64*
  %356 = load i64, i64* %355, align 8
  store i64 %356, i64* %RDX, align 8, !tbaa !2428
  %357 = add i64 %356, 48
  %358 = add i64 %343, 22
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to double*
  store double %352, double* %359, align 8
  %360 = load i64, i64* %RBP, align 8
  %361 = add i64 %360, -120
  %362 = load i64, i64* %PC, align 8
  %363 = add i64 %362, 5
  store i64 %363, i64* %PC, align 8
  %364 = inttoptr i64 %361 to i64*
  %365 = load i64, i64* %364, align 8
  store i64 %365, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %366 = add i64 %360, -144
  %367 = add i64 %362, 13
  store i64 %367, i64* %PC, align 8
  %368 = bitcast i64 %365 to double
  %369 = inttoptr i64 %366 to double*
  %370 = load double, double* %369, align 8
  %371 = fsub double %368, %370
  store double %371, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %372 = add i64 %360, -16
  %373 = add i64 %362, 17
  store i64 %373, i64* %PC, align 8
  %374 = inttoptr i64 %372 to i64*
  %375 = load i64, i64* %374, align 8
  store i64 %375, i64* %RDX, align 8, !tbaa !2428
  %376 = add i64 %375, 56
  %377 = add i64 %362, 22
  store i64 %377, i64* %PC, align 8
  %378 = inttoptr i64 %376 to double*
  store double %371, double* %378, align 8
  %379 = load i64, i64* %RBP, align 8
  %380 = add i64 %379, -24
  %381 = load i64, i64* %PC, align 8
  %382 = add i64 %381, 4
  store i64 %382, i64* %PC, align 8
  %383 = inttoptr i64 %380 to i64*
  %384 = load i64, i64* %383, align 8
  store i64 %384, i64* %RDX, align 8, !tbaa !2428
  %385 = add i64 %384, 16
  %386 = add i64 %381, 9
  store i64 %386, i64* %PC, align 8
  %387 = inttoptr i64 %385 to i64*
  %388 = load i64, i64* %387, align 8
  store i64 %388, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %389 = add i64 %379, -48
  %390 = add i64 %381, 14
  store i64 %390, i64* %PC, align 8
  %391 = inttoptr i64 %389 to i64*
  store i64 %388, i64* %391, align 8
  %392 = load i64, i64* %RBP, align 8
  %393 = add i64 %392, -16
  %394 = load i64, i64* %PC, align 8
  %395 = add i64 %394, 4
  store i64 %395, i64* %PC, align 8
  %396 = inttoptr i64 %393 to i64*
  %397 = load i64, i64* %396, align 8
  store i64 %397, i64* %RDX, align 8, !tbaa !2428
  %398 = add i64 %397, 64
  %399 = add i64 %394, 9
  store i64 %399, i64* %PC, align 8
  %400 = inttoptr i64 %398 to i64*
  %401 = load i64, i64* %400, align 8
  store i64 %401, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %402 = add i64 %394, 13
  store i64 %402, i64* %PC, align 8
  %403 = load i64, i64* %396, align 8
  store i64 %403, i64* %RDX, align 8, !tbaa !2428
  %404 = add i64 %403, 80
  %405 = add i64 %394, 18
  store i64 %405, i64* %PC, align 8
  %406 = bitcast i64 %401 to double
  %407 = inttoptr i64 %404 to double*
  %408 = load double, double* %407, align 8
  %409 = fadd double %406, %408
  store double %409, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %410 = add i64 %392, -96
  %411 = add i64 %394, 23
  store i64 %411, i64* %PC, align 8
  %412 = inttoptr i64 %410 to double*
  store double %409, double* %412, align 8
  %413 = load i64, i64* %RBP, align 8
  %414 = add i64 %413, -16
  %415 = load i64, i64* %PC, align 8
  %416 = add i64 %415, 4
  store i64 %416, i64* %PC, align 8
  %417 = inttoptr i64 %414 to i64*
  %418 = load i64, i64* %417, align 8
  store i64 %418, i64* %RDX, align 8, !tbaa !2428
  %419 = add i64 %418, 72
  %420 = add i64 %415, 9
  store i64 %420, i64* %PC, align 8
  %421 = inttoptr i64 %419 to i64*
  %422 = load i64, i64* %421, align 8
  store i64 %422, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %423 = add i64 %415, 13
  store i64 %423, i64* %PC, align 8
  %424 = load i64, i64* %417, align 8
  store i64 %424, i64* %RDX, align 8, !tbaa !2428
  %425 = add i64 %424, 88
  %426 = add i64 %415, 18
  store i64 %426, i64* %PC, align 8
  %427 = bitcast i64 %422 to double
  %428 = inttoptr i64 %425 to double*
  %429 = load double, double* %428, align 8
  %430 = fadd double %427, %429
  store double %430, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %431 = add i64 %413, -104
  %432 = add i64 %415, 23
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %431 to double*
  store double %430, double* %433, align 8
  %434 = load i64, i64* %RBP, align 8
  %435 = add i64 %434, -16
  %436 = load i64, i64* %PC, align 8
  %437 = add i64 %436, 4
  store i64 %437, i64* %PC, align 8
  %438 = inttoptr i64 %435 to i64*
  %439 = load i64, i64* %438, align 8
  store i64 %439, i64* %RDX, align 8, !tbaa !2428
  %440 = add i64 %439, 64
  %441 = add i64 %436, 9
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i64*
  %443 = load i64, i64* %442, align 8
  store i64 %443, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %444 = add i64 %436, 13
  store i64 %444, i64* %PC, align 8
  %445 = load i64, i64* %438, align 8
  store i64 %445, i64* %RDX, align 8, !tbaa !2428
  %446 = add i64 %445, 80
  %447 = add i64 %436, 18
  store i64 %447, i64* %PC, align 8
  %448 = bitcast i64 %443 to double
  %449 = inttoptr i64 %446 to double*
  %450 = load double, double* %449, align 8
  %451 = fsub double %448, %450
  store double %451, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %452 = add i64 %434, -112
  %453 = add i64 %436, 23
  store i64 %453, i64* %PC, align 8
  %454 = inttoptr i64 %452 to double*
  store double %451, double* %454, align 8
  %455 = load i64, i64* %RBP, align 8
  %456 = add i64 %455, -16
  %457 = load i64, i64* %PC, align 8
  %458 = add i64 %457, 4
  store i64 %458, i64* %PC, align 8
  %459 = inttoptr i64 %456 to i64*
  %460 = load i64, i64* %459, align 8
  store i64 %460, i64* %RDX, align 8, !tbaa !2428
  %461 = add i64 %460, 72
  %462 = add i64 %457, 9
  store i64 %462, i64* %PC, align 8
  %463 = inttoptr i64 %461 to i64*
  %464 = load i64, i64* %463, align 8
  store i64 %464, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %465 = add i64 %457, 13
  store i64 %465, i64* %PC, align 8
  %466 = load i64, i64* %459, align 8
  store i64 %466, i64* %RDX, align 8, !tbaa !2428
  %467 = add i64 %466, 88
  %468 = add i64 %457, 18
  store i64 %468, i64* %PC, align 8
  %469 = bitcast i64 %464 to double
  %470 = inttoptr i64 %467 to double*
  %471 = load double, double* %470, align 8
  %472 = fsub double %469, %471
  store double %472, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %473 = add i64 %455, -120
  %474 = add i64 %457, 23
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to double*
  store double %472, double* %475, align 8
  %476 = load i64, i64* %RBP, align 8
  %477 = add i64 %476, -16
  %478 = load i64, i64* %PC, align 8
  %479 = add i64 %478, 4
  store i64 %479, i64* %PC, align 8
  %480 = inttoptr i64 %477 to i64*
  %481 = load i64, i64* %480, align 8
  store i64 %481, i64* %RDX, align 8, !tbaa !2428
  %482 = add i64 %481, 96
  %483 = add i64 %478, 9
  store i64 %483, i64* %PC, align 8
  %484 = inttoptr i64 %482 to i64*
  %485 = load i64, i64* %484, align 8
  store i64 %485, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %486 = add i64 %478, 13
  store i64 %486, i64* %PC, align 8
  %487 = load i64, i64* %480, align 8
  store i64 %487, i64* %RDX, align 8, !tbaa !2428
  %488 = add i64 %487, 112
  %489 = add i64 %478, 18
  store i64 %489, i64* %PC, align 8
  %490 = bitcast i64 %485 to double
  %491 = inttoptr i64 %488 to double*
  %492 = load double, double* %491, align 8
  %493 = fadd double %490, %492
  store double %493, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %494 = add i64 %476, -128
  %495 = add i64 %478, 23
  store i64 %495, i64* %PC, align 8
  %496 = inttoptr i64 %494 to double*
  store double %493, double* %496, align 8
  %497 = load i64, i64* %RBP, align 8
  %498 = add i64 %497, -16
  %499 = load i64, i64* %PC, align 8
  %500 = add i64 %499, 4
  store i64 %500, i64* %PC, align 8
  %501 = inttoptr i64 %498 to i64*
  %502 = load i64, i64* %501, align 8
  store i64 %502, i64* %RDX, align 8, !tbaa !2428
  %503 = add i64 %502, 104
  %504 = add i64 %499, 9
  store i64 %504, i64* %PC, align 8
  %505 = inttoptr i64 %503 to i64*
  %506 = load i64, i64* %505, align 8
  store i64 %506, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %507 = add i64 %499, 13
  store i64 %507, i64* %PC, align 8
  %508 = load i64, i64* %501, align 8
  store i64 %508, i64* %RDX, align 8, !tbaa !2428
  %509 = add i64 %508, 120
  %510 = add i64 %499, 18
  store i64 %510, i64* %PC, align 8
  %511 = bitcast i64 %506 to double
  %512 = inttoptr i64 %509 to double*
  %513 = load double, double* %512, align 8
  %514 = fadd double %511, %513
  store double %514, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %515 = add i64 %497, -136
  %516 = add i64 %499, 26
  store i64 %516, i64* %PC, align 8
  %517 = inttoptr i64 %515 to double*
  store double %514, double* %517, align 8
  %518 = load i64, i64* %RBP, align 8
  %519 = add i64 %518, -16
  %520 = load i64, i64* %PC, align 8
  %521 = add i64 %520, 4
  store i64 %521, i64* %PC, align 8
  %522 = inttoptr i64 %519 to i64*
  %523 = load i64, i64* %522, align 8
  store i64 %523, i64* %RDX, align 8, !tbaa !2428
  %524 = add i64 %523, 96
  %525 = add i64 %520, 9
  store i64 %525, i64* %PC, align 8
  %526 = inttoptr i64 %524 to i64*
  %527 = load i64, i64* %526, align 8
  store i64 %527, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %528 = add i64 %520, 13
  store i64 %528, i64* %PC, align 8
  %529 = load i64, i64* %522, align 8
  store i64 %529, i64* %RDX, align 8, !tbaa !2428
  %530 = add i64 %529, 112
  %531 = add i64 %520, 18
  store i64 %531, i64* %PC, align 8
  %532 = bitcast i64 %527 to double
  %533 = inttoptr i64 %530 to double*
  %534 = load double, double* %533, align 8
  %535 = fsub double %532, %534
  store double %535, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %536 = add i64 %518, -144
  %537 = add i64 %520, 26
  store i64 %537, i64* %PC, align 8
  %538 = inttoptr i64 %536 to double*
  store double %535, double* %538, align 8
  %539 = load i64, i64* %RBP, align 8
  %540 = add i64 %539, -16
  %541 = load i64, i64* %PC, align 8
  %542 = add i64 %541, 4
  store i64 %542, i64* %PC, align 8
  %543 = inttoptr i64 %540 to i64*
  %544 = load i64, i64* %543, align 8
  store i64 %544, i64* %RDX, align 8, !tbaa !2428
  %545 = add i64 %544, 104
  %546 = add i64 %541, 9
  store i64 %546, i64* %PC, align 8
  %547 = inttoptr i64 %545 to i64*
  %548 = load i64, i64* %547, align 8
  store i64 %548, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %549 = add i64 %541, 13
  store i64 %549, i64* %PC, align 8
  %550 = load i64, i64* %543, align 8
  store i64 %550, i64* %RDX, align 8, !tbaa !2428
  %551 = add i64 %550, 120
  %552 = add i64 %541, 18
  store i64 %552, i64* %PC, align 8
  %553 = bitcast i64 %548 to double
  %554 = inttoptr i64 %551 to double*
  %555 = load double, double* %554, align 8
  %556 = fsub double %553, %555
  store double %556, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %557 = add i64 %539, -152
  %558 = add i64 %541, 26
  store i64 %558, i64* %PC, align 8
  %559 = inttoptr i64 %557 to double*
  store double %556, double* %559, align 8
  %560 = load i64, i64* %RBP, align 8
  %561 = add i64 %560, -96
  %562 = load i64, i64* %PC, align 8
  %563 = add i64 %562, 5
  store i64 %563, i64* %PC, align 8
  %564 = inttoptr i64 %561 to i64*
  %565 = load i64, i64* %564, align 8
  store i64 %565, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %566 = add i64 %560, -128
  %567 = add i64 %562, 10
  store i64 %567, i64* %PC, align 8
  %568 = bitcast i64 %565 to double
  %569 = inttoptr i64 %566 to double*
  %570 = load double, double* %569, align 8
  %571 = fadd double %568, %570
  store double %571, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %572 = add i64 %560, -16
  %573 = add i64 %562, 14
  store i64 %573, i64* %PC, align 8
  %574 = inttoptr i64 %572 to i64*
  %575 = load i64, i64* %574, align 8
  store i64 %575, i64* %RDX, align 8, !tbaa !2428
  %576 = add i64 %575, 64
  %577 = add i64 %562, 19
  store i64 %577, i64* %PC, align 8
  %578 = inttoptr i64 %576 to double*
  store double %571, double* %578, align 8
  %579 = load i64, i64* %RBP, align 8
  %580 = add i64 %579, -104
  %581 = load i64, i64* %PC, align 8
  %582 = add i64 %581, 5
  store i64 %582, i64* %PC, align 8
  %583 = inttoptr i64 %580 to i64*
  %584 = load i64, i64* %583, align 8
  store i64 %584, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %585 = add i64 %579, -136
  %586 = add i64 %581, 13
  store i64 %586, i64* %PC, align 8
  %587 = bitcast i64 %584 to double
  %588 = inttoptr i64 %585 to double*
  %589 = load double, double* %588, align 8
  %590 = fadd double %587, %589
  store double %590, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %591 = add i64 %579, -16
  %592 = add i64 %581, 17
  store i64 %592, i64* %PC, align 8
  %593 = inttoptr i64 %591 to i64*
  %594 = load i64, i64* %593, align 8
  store i64 %594, i64* %RDX, align 8, !tbaa !2428
  %595 = add i64 %594, 72
  %596 = add i64 %581, 22
  store i64 %596, i64* %PC, align 8
  %597 = inttoptr i64 %595 to double*
  store double %590, double* %597, align 8
  %598 = load i64, i64* %RBP, align 8
  %599 = add i64 %598, -136
  %600 = load i64, i64* %PC, align 8
  %601 = add i64 %600, 8
  store i64 %601, i64* %PC, align 8
  %602 = inttoptr i64 %599 to i64*
  %603 = load i64, i64* %602, align 8
  store i64 %603, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %604 = add i64 %598, -104
  %605 = add i64 %600, 13
  store i64 %605, i64* %PC, align 8
  %606 = bitcast i64 %603 to double
  %607 = inttoptr i64 %604 to double*
  %608 = load double, double* %607, align 8
  %609 = fsub double %606, %608
  store double %609, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %610 = add i64 %598, -16
  %611 = add i64 %600, 17
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to i64*
  %613 = load i64, i64* %612, align 8
  store i64 %613, i64* %RDX, align 8, !tbaa !2428
  %614 = add i64 %613, 96
  %615 = add i64 %600, 22
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to double*
  store double %609, double* %616, align 8
  %617 = load i64, i64* %RBP, align 8
  %618 = add i64 %617, -96
  %619 = load i64, i64* %PC, align 8
  %620 = add i64 %619, 5
  store i64 %620, i64* %PC, align 8
  %621 = inttoptr i64 %618 to i64*
  %622 = load i64, i64* %621, align 8
  store i64 %622, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %623 = add i64 %617, -128
  %624 = add i64 %619, 10
  store i64 %624, i64* %PC, align 8
  %625 = bitcast i64 %622 to double
  %626 = inttoptr i64 %623 to double*
  %627 = load double, double* %626, align 8
  %628 = fsub double %625, %627
  store double %628, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %629 = add i64 %617, -16
  %630 = add i64 %619, 14
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to i64*
  %632 = load i64, i64* %631, align 8
  store i64 %632, i64* %RDX, align 8, !tbaa !2428
  %633 = add i64 %632, 104
  %634 = add i64 %619, 19
  store i64 %634, i64* %PC, align 8
  %635 = inttoptr i64 %633 to double*
  store double %628, double* %635, align 8
  %636 = load i64, i64* %RBP, align 8
  %637 = add i64 %636, -112
  %638 = load i64, i64* %PC, align 8
  %639 = add i64 %638, 5
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %637 to i64*
  %641 = load i64, i64* %640, align 8
  store i64 %641, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %642 = add i64 %636, -152
  %643 = add i64 %638, 13
  store i64 %643, i64* %PC, align 8
  %644 = bitcast i64 %641 to double
  %645 = inttoptr i64 %642 to double*
  %646 = load double, double* %645, align 8
  %647 = fsub double %644, %646
  store double %647, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %648 = add i64 %636, -96
  %649 = add i64 %638, 18
  store i64 %649, i64* %PC, align 8
  %650 = inttoptr i64 %648 to double*
  store double %647, double* %650, align 8
  %651 = load i64, i64* %RBP, align 8
  %652 = add i64 %651, -120
  %653 = load i64, i64* %PC, align 8
  %654 = add i64 %653, 5
  store i64 %654, i64* %PC, align 8
  %655 = inttoptr i64 %652 to i64*
  %656 = load i64, i64* %655, align 8
  store i64 %656, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %657 = add i64 %651, -144
  %658 = add i64 %653, 13
  store i64 %658, i64* %PC, align 8
  %659 = bitcast i64 %656 to double
  %660 = inttoptr i64 %657 to double*
  %661 = load double, double* %660, align 8
  %662 = fadd double %659, %661
  store double %662, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %663 = add i64 %651, -104
  %664 = add i64 %653, 18
  store i64 %664, i64* %PC, align 8
  %665 = inttoptr i64 %663 to double*
  store double %662, double* %665, align 8
  %666 = load i64, i64* %RBP, align 8
  %667 = add i64 %666, -48
  %668 = load i64, i64* %PC, align 8
  %669 = add i64 %668, 5
  store i64 %669, i64* %PC, align 8
  %670 = inttoptr i64 %667 to i64*
  %671 = load i64, i64* %670, align 8
  store i64 %671, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %672 = bitcast %union.VectorReg* %5 to i8*
  %673 = add i64 %666, -96
  %674 = add i64 %668, 10
  store i64 %674, i64* %PC, align 8
  %675 = inttoptr i64 %673 to i64*
  %676 = load i64, i64* %675, align 8
  %677 = bitcast %union.VectorReg* %5 to double*
  %678 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %676, i64* %678, align 1, !tbaa !2452
  %679 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %680 = bitcast i64* %679 to double*
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %681 = add i64 %666, -104
  %682 = add i64 %668, 15
  store i64 %682, i64* %PC, align 8
  %683 = bitcast i64 %676 to double
  %684 = inttoptr i64 %681 to double*
  %685 = load double, double* %684, align 8
  %686 = fsub double %683, %685
  store double %686, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %687 = bitcast i64 %671 to double
  %688 = fmul double %687, %686
  store double %688, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %689 = add i64 %666, -16
  %690 = add i64 %668, 23
  store i64 %690, i64* %PC, align 8
  %691 = inttoptr i64 %689 to i64*
  %692 = load i64, i64* %691, align 8
  store i64 %692, i64* %RDX, align 8, !tbaa !2428
  %693 = add i64 %692, 80
  %694 = add i64 %668, 28
  store i64 %694, i64* %PC, align 8
  %695 = inttoptr i64 %693 to double*
  store double %688, double* %695, align 8
  %696 = load i64, i64* %RBP, align 8
  %697 = add i64 %696, -48
  %698 = load i64, i64* %PC, align 8
  %699 = add i64 %698, 5
  store i64 %699, i64* %PC, align 8
  %700 = inttoptr i64 %697 to i64*
  %701 = load i64, i64* %700, align 8
  store i64 %701, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %702 = add i64 %696, -96
  %703 = add i64 %698, 10
  store i64 %703, i64* %PC, align 8
  %704 = inttoptr i64 %702 to i64*
  %705 = load i64, i64* %704, align 8
  store i64 %705, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %706 = add i64 %696, -104
  %707 = add i64 %698, 15
  store i64 %707, i64* %PC, align 8
  %708 = bitcast i64 %705 to double
  %709 = inttoptr i64 %706 to double*
  %710 = load double, double* %709, align 8
  %711 = fadd double %708, %710
  store double %711, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %712 = bitcast i64 %701 to double
  %713 = fmul double %712, %711
  store double %713, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %714 = add i64 %696, -16
  %715 = add i64 %698, 23
  store i64 %715, i64* %PC, align 8
  %716 = inttoptr i64 %714 to i64*
  %717 = load i64, i64* %716, align 8
  store i64 %717, i64* %RDX, align 8, !tbaa !2428
  %718 = add i64 %717, 88
  %719 = add i64 %698, 28
  store i64 %719, i64* %PC, align 8
  %720 = inttoptr i64 %718 to double*
  store double %713, double* %720, align 8
  %721 = load i64, i64* %RBP, align 8
  %722 = add i64 %721, -152
  %723 = load i64, i64* %PC, align 8
  %724 = add i64 %723, 8
  store i64 %724, i64* %PC, align 8
  %725 = inttoptr i64 %722 to i64*
  %726 = load i64, i64* %725, align 8
  store i64 %726, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %727 = add i64 %721, -112
  %728 = add i64 %723, 13
  store i64 %728, i64* %PC, align 8
  %729 = bitcast i64 %726 to double
  %730 = inttoptr i64 %727 to double*
  %731 = load double, double* %730, align 8
  %732 = fadd double %729, %731
  store double %732, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %733 = add i64 %721, -96
  %734 = add i64 %723, 18
  store i64 %734, i64* %PC, align 8
  %735 = inttoptr i64 %733 to double*
  store double %732, double* %735, align 8
  %736 = load i64, i64* %RBP, align 8
  %737 = add i64 %736, -144
  %738 = load i64, i64* %PC, align 8
  %739 = add i64 %738, 8
  store i64 %739, i64* %PC, align 8
  %740 = inttoptr i64 %737 to i64*
  %741 = load i64, i64* %740, align 8
  store i64 %741, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %742 = add i64 %736, -120
  %743 = add i64 %738, 13
  store i64 %743, i64* %PC, align 8
  %744 = bitcast i64 %741 to double
  %745 = inttoptr i64 %742 to double*
  %746 = load double, double* %745, align 8
  %747 = fsub double %744, %746
  store double %747, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %748 = add i64 %736, -104
  %749 = add i64 %738, 18
  store i64 %749, i64* %PC, align 8
  %750 = inttoptr i64 %748 to double*
  store double %747, double* %750, align 8
  %751 = load i64, i64* %RBP, align 8
  %752 = add i64 %751, -48
  %753 = load i64, i64* %PC, align 8
  %754 = add i64 %753, 5
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %752 to i64*
  %756 = load i64, i64* %755, align 8
  store i64 %756, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %757 = add i64 %751, -104
  %758 = add i64 %753, 10
  store i64 %758, i64* %PC, align 8
  %759 = inttoptr i64 %757 to i64*
  %760 = load i64, i64* %759, align 8
  store i64 %760, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %761 = add i64 %751, -96
  %762 = add i64 %753, 15
  store i64 %762, i64* %PC, align 8
  %763 = bitcast i64 %760 to double
  %764 = inttoptr i64 %761 to double*
  %765 = load double, double* %764, align 8
  %766 = fsub double %763, %765
  store double %766, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %767 = bitcast i64 %756 to double
  %768 = fmul double %767, %766
  store double %768, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %769 = add i64 %751, -16
  %770 = add i64 %753, 23
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %769 to i64*
  %772 = load i64, i64* %771, align 8
  store i64 %772, i64* %RDX, align 8, !tbaa !2428
  %773 = add i64 %772, 112
  %774 = add i64 %753, 28
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to double*
  store double %768, double* %775, align 8
  %776 = load i64, i64* %RBP, align 8
  %777 = add i64 %776, -48
  %778 = load i64, i64* %PC, align 8
  %779 = add i64 %778, 5
  store i64 %779, i64* %PC, align 8
  %780 = inttoptr i64 %777 to i64*
  %781 = load i64, i64* %780, align 8
  store i64 %781, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %782 = add i64 %776, -104
  %783 = add i64 %778, 10
  store i64 %783, i64* %PC, align 8
  %784 = inttoptr i64 %782 to i64*
  %785 = load i64, i64* %784, align 8
  store i64 %785, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %786 = add i64 %776, -96
  %787 = add i64 %778, 15
  store i64 %787, i64* %PC, align 8
  %788 = bitcast i64 %785 to double
  %789 = inttoptr i64 %786 to double*
  %790 = load double, double* %789, align 8
  %791 = fadd double %788, %790
  store double %791, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %792 = bitcast i64 %781 to double
  %793 = fmul double %792, %791
  store double %793, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %794 = add i64 %776, -16
  %795 = add i64 %778, 23
  store i64 %795, i64* %PC, align 8
  %796 = inttoptr i64 %794 to i64*
  %797 = load i64, i64* %796, align 8
  store i64 %797, i64* %RDX, align 8, !tbaa !2428
  %798 = add i64 %797, 120
  %799 = add i64 %778, 28
  store i64 %799, i64* %PC, align 8
  %800 = inttoptr i64 %798 to double*
  store double %793, double* %800, align 8
  %801 = load i64, i64* %RBP, align 8
  %802 = add i64 %801, -32
  %803 = load i64, i64* %PC, align 8
  %804 = add i64 %803, 7
  store i64 %804, i64* %PC, align 8
  %805 = inttoptr i64 %802 to i32*
  store i32 0, i32* %805, align 4
  %806 = load i64, i64* %RBP, align 8
  %807 = add i64 %806, -28
  %808 = load i64, i64* %PC, align 8
  %809 = add i64 %808, 7
  store i64 %809, i64* %PC, align 8
  %810 = inttoptr i64 %807 to i32*
  store i32 16, i32* %810, align 4
  %811 = bitcast %union.VectorReg* %6 to i8*
  %812 = bitcast [32 x %union.VectorReg]* %4 to <2 x i32>*
  %813 = bitcast i64* %69 to <2 x i32>*
  %814 = bitcast %union.VectorReg* %6 to i32*
  %815 = getelementptr inbounds i8, i8* %811, i64 4
  %816 = bitcast i8* %815 to i32*
  %817 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %818 = bitcast i64* %817 to i32*
  %819 = getelementptr inbounds i8, i8* %811, i64 12
  %820 = bitcast i8* %819 to i32*
  %821 = bitcast %union.VectorReg* %6 to double*
  %822 = bitcast %union.VectorReg* %5 to i32*
  %823 = getelementptr inbounds i8, i8* %672, i64 4
  %824 = bitcast i8* %823 to i32*
  %825 = bitcast i64* %679 to i32*
  %826 = getelementptr inbounds i8, i8* %672, i64 12
  %827 = bitcast i8* %826 to i32*
  %828 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  %829 = bitcast i64* %817 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_402bf2

block_402bfe:                                     ; preds = %block_402bf2
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %830 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 80) to i64*), align 16
  store i64 %830, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %831 = add i64 %3458, -32
  %832 = add i64 %3494, 21
  store i64 %832, i64* %PC, align 8
  %833 = inttoptr i64 %831 to i32*
  %834 = load i32, i32* %833, align 4
  %835 = add i32 %834, 2
  %836 = zext i32 %835 to i64
  store i64 %836, i64* %RCX, align 8, !tbaa !2428
  %837 = icmp ugt i32 %834, -3
  %838 = zext i1 %837 to i8
  store i8 %838, i8* %16, align 1, !tbaa !2433
  %839 = and i32 %835, 255
  %840 = tail call i32 @llvm.ctpop.i32(i32 %839) #10
  %841 = trunc i32 %840 to i8
  %842 = and i8 %841, 1
  %843 = xor i8 %842, 1
  store i8 %843, i8* %23, align 1, !tbaa !2447
  %844 = xor i32 %835, %834
  %845 = lshr i32 %844, 4
  %846 = trunc i32 %845 to i8
  %847 = and i8 %846, 1
  store i8 %847, i8* %29, align 1, !tbaa !2451
  %848 = icmp eq i32 %835, 0
  %849 = zext i1 %848 to i8
  store i8 %849, i8* %32, align 1, !tbaa !2448
  %850 = lshr i32 %835, 31
  %851 = trunc i32 %850 to i8
  store i8 %851, i8* %35, align 1, !tbaa !2449
  %852 = lshr i32 %834, 31
  %853 = xor i32 %850, %852
  %854 = add nuw nsw i32 %853, %850
  %855 = icmp eq i32 %854, 2
  %856 = zext i1 %855 to i8
  store i8 %856, i8* %41, align 1, !tbaa !2450
  %857 = add i64 %3494, 27
  store i64 %857, i64* %PC, align 8
  store i32 %835, i32* %833, align 4
  %858 = load i64, i64* %RBP, align 8
  %859 = add i64 %858, -32
  %860 = load i64, i64* %PC, align 8
  %861 = add i64 %860, 3
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %859 to i32*
  %863 = load i32, i32* %862, align 4
  %864 = shl i32 %863, 1
  %865 = icmp slt i32 %863, 0
  %866 = icmp slt i32 %864, 0
  %867 = xor i1 %865, %866
  %868 = zext i32 %864 to i64
  store i64 %868, i64* %RCX, align 8, !tbaa !2428
  %.lobit = lshr i32 %863, 31
  %869 = trunc i32 %.lobit to i8
  store i8 %869, i8* %16, align 1, !tbaa !2432
  %870 = and i32 %864, 254
  %871 = tail call i32 @llvm.ctpop.i32(i32 %870) #10
  %872 = trunc i32 %871 to i8
  %873 = and i8 %872, 1
  %874 = xor i8 %873, 1
  store i8 %874, i8* %23, align 1, !tbaa !2432
  store i8 0, i8* %29, align 1, !tbaa !2432
  %875 = icmp eq i32 %864, 0
  %876 = zext i1 %875 to i8
  store i8 %876, i8* %32, align 1, !tbaa !2432
  %877 = lshr i32 %863, 30
  %878 = trunc i32 %877 to i8
  %879 = and i8 %878, 1
  store i8 %879, i8* %35, align 1, !tbaa !2432
  %880 = zext i1 %867 to i8
  store i8 %880, i8* %41, align 1, !tbaa !2432
  %881 = add i64 %858, -36
  %882 = add i64 %860, 9
  store i64 %882, i64* %PC, align 8
  %883 = inttoptr i64 %881 to i32*
  store i32 %864, i32* %883, align 4
  %884 = load i64, i64* %RBP, align 8
  %885 = add i64 %884, -24
  %886 = load i64, i64* %PC, align 8
  %887 = add i64 %886, 4
  store i64 %887, i64* %PC, align 8
  %888 = inttoptr i64 %885 to i64*
  %889 = load i64, i64* %888, align 8
  store i64 %889, i64* %RDX, align 8, !tbaa !2428
  %890 = add i64 %884, -32
  %891 = add i64 %886, 8
  store i64 %891, i64* %PC, align 8
  %892 = inttoptr i64 %890 to i32*
  %893 = load i32, i32* %892, align 4
  %894 = sext i32 %893 to i64
  store i64 %894, i64* %RSI, align 8, !tbaa !2428
  %895 = shl nsw i64 %894, 3
  %896 = add i64 %895, %889
  %897 = add i64 %886, 13
  store i64 %897, i64* %PC, align 8
  %898 = inttoptr i64 %896 to i64*
  %899 = load i64, i64* %898, align 8
  store i64 %899, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %900 = add i64 %884, -64
  %901 = add i64 %886, 18
  store i64 %901, i64* %PC, align 8
  %902 = inttoptr i64 %900 to i64*
  store i64 %899, i64* %902, align 8
  %903 = load i64, i64* %RBP, align 8
  %904 = add i64 %903, -24
  %905 = load i64, i64* %PC, align 8
  %906 = add i64 %905, 4
  store i64 %906, i64* %PC, align 8
  %907 = inttoptr i64 %904 to i64*
  %908 = load i64, i64* %907, align 8
  store i64 %908, i64* %RDX, align 8, !tbaa !2428
  %909 = add i64 %903, -32
  %910 = add i64 %905, 7
  store i64 %910, i64* %PC, align 8
  %911 = inttoptr i64 %909 to i32*
  %912 = load i32, i32* %911, align 4
  %913 = add i32 %912, 1
  %914 = zext i32 %913 to i64
  store i64 %914, i64* %RCX, align 8, !tbaa !2428
  %915 = icmp eq i32 %912, -1
  %916 = icmp eq i32 %913, 0
  %917 = or i1 %915, %916
  %918 = zext i1 %917 to i8
  store i8 %918, i8* %16, align 1, !tbaa !2433
  %919 = and i32 %913, 255
  %920 = tail call i32 @llvm.ctpop.i32(i32 %919) #10
  %921 = trunc i32 %920 to i8
  %922 = and i8 %921, 1
  %923 = xor i8 %922, 1
  store i8 %923, i8* %23, align 1, !tbaa !2447
  %924 = xor i32 %913, %912
  %925 = lshr i32 %924, 4
  %926 = trunc i32 %925 to i8
  %927 = and i8 %926, 1
  store i8 %927, i8* %29, align 1, !tbaa !2451
  %928 = zext i1 %916 to i8
  store i8 %928, i8* %32, align 1, !tbaa !2448
  %929 = lshr i32 %913, 31
  %930 = trunc i32 %929 to i8
  store i8 %930, i8* %35, align 1, !tbaa !2449
  %931 = lshr i32 %912, 31
  %932 = xor i32 %929, %931
  %933 = add nuw nsw i32 %932, %929
  %934 = icmp eq i32 %933, 2
  %935 = zext i1 %934 to i8
  store i8 %935, i8* %41, align 1, !tbaa !2450
  %936 = sext i32 %913 to i64
  store i64 %936, i64* %RSI, align 8, !tbaa !2428
  %937 = shl nsw i64 %936, 3
  %938 = add i64 %908, %937
  %939 = add i64 %905, 18
  store i64 %939, i64* %PC, align 8
  %940 = inttoptr i64 %938 to i64*
  %941 = load i64, i64* %940, align 8
  store i64 %941, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %942 = add i64 %903, -72
  %943 = add i64 %905, 23
  store i64 %943, i64* %PC, align 8
  %944 = inttoptr i64 %942 to i64*
  store i64 %941, i64* %944, align 8
  %945 = load i64, i64* %RBP, align 8
  %946 = add i64 %945, -24
  %947 = load i64, i64* %PC, align 8
  %948 = add i64 %947, 4
  store i64 %948, i64* %PC, align 8
  %949 = inttoptr i64 %946 to i64*
  %950 = load i64, i64* %949, align 8
  store i64 %950, i64* %RDX, align 8, !tbaa !2428
  %951 = add i64 %945, -36
  %952 = add i64 %947, 8
  store i64 %952, i64* %PC, align 8
  %953 = inttoptr i64 %951 to i32*
  %954 = load i32, i32* %953, align 4
  %955 = sext i32 %954 to i64
  store i64 %955, i64* %RSI, align 8, !tbaa !2428
  %956 = shl nsw i64 %955, 3
  %957 = add i64 %956, %950
  %958 = add i64 %947, 13
  store i64 %958, i64* %PC, align 8
  %959 = inttoptr i64 %957 to i64*
  %960 = load i64, i64* %959, align 8
  store i64 %960, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %961 = add i64 %945, -48
  %962 = add i64 %947, 18
  store i64 %962, i64* %PC, align 8
  %963 = inttoptr i64 %961 to i64*
  store i64 %960, i64* %963, align 8
  %964 = load i64, i64* %RBP, align 8
  %965 = add i64 %964, -24
  %966 = load i64, i64* %PC, align 8
  %967 = add i64 %966, 4
  store i64 %967, i64* %PC, align 8
  %968 = inttoptr i64 %965 to i64*
  %969 = load i64, i64* %968, align 8
  store i64 %969, i64* %RDX, align 8, !tbaa !2428
  %970 = add i64 %964, -36
  %971 = add i64 %966, 7
  store i64 %971, i64* %PC, align 8
  %972 = inttoptr i64 %970 to i32*
  %973 = load i32, i32* %972, align 4
  %974 = add i32 %973, 1
  %975 = zext i32 %974 to i64
  store i64 %975, i64* %RCX, align 8, !tbaa !2428
  %976 = icmp eq i32 %973, -1
  %977 = icmp eq i32 %974, 0
  %978 = or i1 %976, %977
  %979 = zext i1 %978 to i8
  store i8 %979, i8* %16, align 1, !tbaa !2433
  %980 = and i32 %974, 255
  %981 = tail call i32 @llvm.ctpop.i32(i32 %980) #10
  %982 = trunc i32 %981 to i8
  %983 = and i8 %982, 1
  %984 = xor i8 %983, 1
  store i8 %984, i8* %23, align 1, !tbaa !2447
  %985 = xor i32 %974, %973
  %986 = lshr i32 %985, 4
  %987 = trunc i32 %986 to i8
  %988 = and i8 %987, 1
  store i8 %988, i8* %29, align 1, !tbaa !2451
  %989 = zext i1 %977 to i8
  store i8 %989, i8* %32, align 1, !tbaa !2448
  %990 = lshr i32 %974, 31
  %991 = trunc i32 %990 to i8
  store i8 %991, i8* %35, align 1, !tbaa !2449
  %992 = lshr i32 %973, 31
  %993 = xor i32 %990, %992
  %994 = add nuw nsw i32 %993, %990
  %995 = icmp eq i32 %994, 2
  %996 = zext i1 %995 to i8
  store i8 %996, i8* %41, align 1, !tbaa !2450
  %997 = sext i32 %974 to i64
  store i64 %997, i64* %RSI, align 8, !tbaa !2428
  %998 = shl nsw i64 %997, 3
  %999 = add i64 %969, %998
  %1000 = add i64 %966, 18
  store i64 %1000, i64* %PC, align 8
  %1001 = inttoptr i64 %999 to i64*
  %1002 = load i64, i64* %1001, align 8
  store i64 %1002, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1003 = add i64 %964, -56
  %1004 = add i64 %966, 23
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to i64*
  store i64 %1002, i64* %1005, align 8
  %1006 = load i64, i64* %RBP, align 8
  %1007 = add i64 %1006, -48
  %1008 = load i64, i64* %PC, align 8
  %1009 = add i64 %1008, 5
  store i64 %1009, i64* %PC, align 8
  %1010 = inttoptr i64 %1007 to i64*
  %1011 = load i64, i64* %1010, align 8
  store i64 %1011, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1012 = load <2 x i32>, <2 x i32>* %812, align 1
  %1013 = load <2 x i32>, <2 x i32>* %813, align 1
  %1014 = extractelement <2 x i32> %1012, i32 0
  store i32 %1014, i32* %814, align 1, !tbaa !2454
  %1015 = extractelement <2 x i32> %1012, i32 1
  store i32 %1015, i32* %816, align 1, !tbaa !2454
  %1016 = extractelement <2 x i32> %1013, i32 0
  store i32 %1016, i32* %818, align 1, !tbaa !2454
  %1017 = extractelement <2 x i32> %1013, i32 1
  store i32 %1017, i32* %820, align 1, !tbaa !2454
  %1018 = add i64 %1006, -72
  %1019 = add i64 %1008, 13
  store i64 %1019, i64* %PC, align 8
  %1020 = load double, double* %821, align 1
  %1021 = inttoptr i64 %1018 to double*
  %1022 = load double, double* %1021, align 8
  %1023 = fmul double %1020, %1022
  store double %1023, double* %821, align 1, !tbaa !2452
  %1024 = add i64 %1006, -56
  %1025 = add i64 %1008, 18
  store i64 %1025, i64* %PC, align 8
  %1026 = inttoptr i64 %1024 to double*
  %1027 = load double, double* %1026, align 8
  %1028 = fmul double %1023, %1027
  store double %1028, double* %821, align 1, !tbaa !2452
  %1029 = bitcast i64 %1011 to double
  %1030 = fsub double %1029, %1028
  %1031 = add i64 %1006, -80
  %1032 = add i64 %1008, 27
  store i64 %1032, i64* %PC, align 8
  %1033 = inttoptr i64 %1031 to double*
  store double %1030, double* %1033, align 8
  %1034 = load i64, i64* %PC, align 8
  %1035 = load <2 x i32>, <2 x i32>* %812, align 1
  %1036 = load <2 x i32>, <2 x i32>* %813, align 1
  %1037 = extractelement <2 x i32> %1035, i32 0
  store i32 %1037, i32* %822, align 1, !tbaa !2454
  %1038 = extractelement <2 x i32> %1035, i32 1
  store i32 %1038, i32* %824, align 1, !tbaa !2454
  %1039 = extractelement <2 x i32> %1036, i32 0
  store i32 %1039, i32* %825, align 1, !tbaa !2454
  %1040 = extractelement <2 x i32> %1036, i32 1
  store i32 %1040, i32* %827, align 1, !tbaa !2454
  %1041 = load i64, i64* %RBP, align 8
  %1042 = add i64 %1041, -72
  %1043 = add i64 %1034, 8
  store i64 %1043, i64* %PC, align 8
  %1044 = load double, double* %677, align 1
  %1045 = inttoptr i64 %1042 to double*
  %1046 = load double, double* %1045, align 8
  %1047 = fmul double %1044, %1046
  store double %1047, double* %677, align 1, !tbaa !2452
  %1048 = add i64 %1041, -48
  %1049 = add i64 %1034, 13
  store i64 %1049, i64* %PC, align 8
  %1050 = inttoptr i64 %1048 to double*
  %1051 = load double, double* %1050, align 8
  %1052 = fmul double %1047, %1051
  store double %1052, double* %677, align 1, !tbaa !2452
  %1053 = add i64 %1041, -56
  %1054 = add i64 %1034, 18
  store i64 %1054, i64* %PC, align 8
  %1055 = inttoptr i64 %1053 to double*
  %1056 = load double, double* %1055, align 8
  %1057 = fsub double %1052, %1056
  store double %1057, double* %677, align 1, !tbaa !2452
  %1058 = add i64 %1041, -88
  %1059 = add i64 %1034, 23
  store i64 %1059, i64* %PC, align 8
  %1060 = inttoptr i64 %1058 to double*
  store double %1057, double* %1060, align 8
  %1061 = load i64, i64* %RBP, align 8
  %1062 = add i64 %1061, -16
  %1063 = load i64, i64* %PC, align 8
  %1064 = add i64 %1063, 4
  store i64 %1064, i64* %PC, align 8
  %1065 = inttoptr i64 %1062 to i64*
  %1066 = load i64, i64* %1065, align 8
  store i64 %1066, i64* %RDX, align 8, !tbaa !2428
  %1067 = add i64 %1061, -28
  %1068 = add i64 %1063, 8
  store i64 %1068, i64* %PC, align 8
  %1069 = inttoptr i64 %1067 to i32*
  %1070 = load i32, i32* %1069, align 4
  %1071 = sext i32 %1070 to i64
  store i64 %1071, i64* %RSI, align 8, !tbaa !2428
  %1072 = shl nsw i64 %1071, 3
  %1073 = add i64 %1072, %1066
  %1074 = add i64 %1063, 13
  store i64 %1074, i64* %PC, align 8
  %1075 = inttoptr i64 %1073 to i64*
  %1076 = load i64, i64* %1075, align 8
  store i64 %1076, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1077 = add i64 %1063, 17
  store i64 %1077, i64* %PC, align 8
  %1078 = load i64, i64* %1065, align 8
  store i64 %1078, i64* %RDX, align 8, !tbaa !2428
  %1079 = add i64 %1063, 20
  store i64 %1079, i64* %PC, align 8
  %1080 = load i32, i32* %1069, align 4
  %1081 = add i32 %1080, 2
  %1082 = zext i32 %1081 to i64
  store i64 %1082, i64* %RCX, align 8, !tbaa !2428
  %1083 = icmp ugt i32 %1080, -3
  %1084 = zext i1 %1083 to i8
  store i8 %1084, i8* %16, align 1, !tbaa !2433
  %1085 = and i32 %1081, 255
  %1086 = tail call i32 @llvm.ctpop.i32(i32 %1085) #10
  %1087 = trunc i32 %1086 to i8
  %1088 = and i8 %1087, 1
  %1089 = xor i8 %1088, 1
  store i8 %1089, i8* %23, align 1, !tbaa !2447
  %1090 = xor i32 %1081, %1080
  %1091 = lshr i32 %1090, 4
  %1092 = trunc i32 %1091 to i8
  %1093 = and i8 %1092, 1
  store i8 %1093, i8* %29, align 1, !tbaa !2451
  %1094 = icmp eq i32 %1081, 0
  %1095 = zext i1 %1094 to i8
  store i8 %1095, i8* %32, align 1, !tbaa !2448
  %1096 = lshr i32 %1081, 31
  %1097 = trunc i32 %1096 to i8
  store i8 %1097, i8* %35, align 1, !tbaa !2449
  %1098 = lshr i32 %1080, 31
  %1099 = xor i32 %1096, %1098
  %1100 = add nuw nsw i32 %1099, %1096
  %1101 = icmp eq i32 %1100, 2
  %1102 = zext i1 %1101 to i8
  store i8 %1102, i8* %41, align 1, !tbaa !2450
  %1103 = sext i32 %1081 to i64
  store i64 %1103, i64* %RSI, align 8, !tbaa !2428
  %1104 = shl nsw i64 %1103, 3
  %1105 = add i64 %1078, %1104
  %1106 = add i64 %1063, 31
  store i64 %1106, i64* %PC, align 8
  %1107 = bitcast i64 %1076 to double
  %1108 = inttoptr i64 %1105 to double*
  %1109 = load double, double* %1108, align 8
  %1110 = fadd double %1107, %1109
  store double %1110, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1111 = add i64 %1061, -96
  %1112 = add i64 %1063, 36
  store i64 %1112, i64* %PC, align 8
  %1113 = inttoptr i64 %1111 to double*
  store double %1110, double* %1113, align 8
  %1114 = load i64, i64* %RBP, align 8
  %1115 = add i64 %1114, -16
  %1116 = load i64, i64* %PC, align 8
  %1117 = add i64 %1116, 4
  store i64 %1117, i64* %PC, align 8
  %1118 = inttoptr i64 %1115 to i64*
  %1119 = load i64, i64* %1118, align 8
  store i64 %1119, i64* %RDX, align 8, !tbaa !2428
  %1120 = add i64 %1114, -28
  %1121 = add i64 %1116, 7
  store i64 %1121, i64* %PC, align 8
  %1122 = inttoptr i64 %1120 to i32*
  %1123 = load i32, i32* %1122, align 4
  %1124 = add i32 %1123, 1
  %1125 = zext i32 %1124 to i64
  store i64 %1125, i64* %RCX, align 8, !tbaa !2428
  %1126 = icmp eq i32 %1123, -1
  %1127 = icmp eq i32 %1124, 0
  %1128 = or i1 %1126, %1127
  %1129 = zext i1 %1128 to i8
  store i8 %1129, i8* %16, align 1, !tbaa !2433
  %1130 = and i32 %1124, 255
  %1131 = tail call i32 @llvm.ctpop.i32(i32 %1130) #10
  %1132 = trunc i32 %1131 to i8
  %1133 = and i8 %1132, 1
  %1134 = xor i8 %1133, 1
  store i8 %1134, i8* %23, align 1, !tbaa !2447
  %1135 = xor i32 %1124, %1123
  %1136 = lshr i32 %1135, 4
  %1137 = trunc i32 %1136 to i8
  %1138 = and i8 %1137, 1
  store i8 %1138, i8* %29, align 1, !tbaa !2451
  %1139 = zext i1 %1127 to i8
  store i8 %1139, i8* %32, align 1, !tbaa !2448
  %1140 = lshr i32 %1124, 31
  %1141 = trunc i32 %1140 to i8
  store i8 %1141, i8* %35, align 1, !tbaa !2449
  %1142 = lshr i32 %1123, 31
  %1143 = xor i32 %1140, %1142
  %1144 = add nuw nsw i32 %1143, %1140
  %1145 = icmp eq i32 %1144, 2
  %1146 = zext i1 %1145 to i8
  store i8 %1146, i8* %41, align 1, !tbaa !2450
  %1147 = sext i32 %1124 to i64
  store i64 %1147, i64* %RSI, align 8, !tbaa !2428
  %1148 = shl nsw i64 %1147, 3
  %1149 = add i64 %1119, %1148
  %1150 = add i64 %1116, 18
  store i64 %1150, i64* %PC, align 8
  %1151 = inttoptr i64 %1149 to i64*
  %1152 = load i64, i64* %1151, align 8
  store i64 %1152, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1153 = add i64 %1116, 22
  store i64 %1153, i64* %PC, align 8
  %1154 = load i64, i64* %1118, align 8
  store i64 %1154, i64* %RDX, align 8, !tbaa !2428
  %1155 = add i64 %1116, 25
  store i64 %1155, i64* %PC, align 8
  %1156 = load i32, i32* %1122, align 4
  %1157 = add i32 %1156, 3
  %1158 = zext i32 %1157 to i64
  store i64 %1158, i64* %RCX, align 8, !tbaa !2428
  %1159 = icmp ugt i32 %1156, -4
  %1160 = zext i1 %1159 to i8
  store i8 %1160, i8* %16, align 1, !tbaa !2433
  %1161 = and i32 %1157, 255
  %1162 = tail call i32 @llvm.ctpop.i32(i32 %1161) #10
  %1163 = trunc i32 %1162 to i8
  %1164 = and i8 %1163, 1
  %1165 = xor i8 %1164, 1
  store i8 %1165, i8* %23, align 1, !tbaa !2447
  %1166 = xor i32 %1157, %1156
  %1167 = lshr i32 %1166, 4
  %1168 = trunc i32 %1167 to i8
  %1169 = and i8 %1168, 1
  store i8 %1169, i8* %29, align 1, !tbaa !2451
  %1170 = icmp eq i32 %1157, 0
  %1171 = zext i1 %1170 to i8
  store i8 %1171, i8* %32, align 1, !tbaa !2448
  %1172 = lshr i32 %1157, 31
  %1173 = trunc i32 %1172 to i8
  store i8 %1173, i8* %35, align 1, !tbaa !2449
  %1174 = lshr i32 %1156, 31
  %1175 = xor i32 %1172, %1174
  %1176 = add nuw nsw i32 %1175, %1172
  %1177 = icmp eq i32 %1176, 2
  %1178 = zext i1 %1177 to i8
  store i8 %1178, i8* %41, align 1, !tbaa !2450
  %1179 = sext i32 %1157 to i64
  store i64 %1179, i64* %RSI, align 8, !tbaa !2428
  %1180 = shl nsw i64 %1179, 3
  %1181 = add i64 %1154, %1180
  %1182 = add i64 %1116, 36
  store i64 %1182, i64* %PC, align 8
  %1183 = bitcast i64 %1152 to double
  %1184 = inttoptr i64 %1181 to double*
  %1185 = load double, double* %1184, align 8
  %1186 = fadd double %1183, %1185
  store double %1186, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1187 = load i64, i64* %RBP, align 8
  %1188 = add i64 %1187, -104
  %1189 = add i64 %1116, 41
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1188 to double*
  store double %1186, double* %1190, align 8
  %1191 = load i64, i64* %RBP, align 8
  %1192 = add i64 %1191, -16
  %1193 = load i64, i64* %PC, align 8
  %1194 = add i64 %1193, 4
  store i64 %1194, i64* %PC, align 8
  %1195 = inttoptr i64 %1192 to i64*
  %1196 = load i64, i64* %1195, align 8
  store i64 %1196, i64* %RDX, align 8, !tbaa !2428
  %1197 = add i64 %1191, -28
  %1198 = add i64 %1193, 8
  store i64 %1198, i64* %PC, align 8
  %1199 = inttoptr i64 %1197 to i32*
  %1200 = load i32, i32* %1199, align 4
  %1201 = sext i32 %1200 to i64
  store i64 %1201, i64* %RSI, align 8, !tbaa !2428
  %1202 = shl nsw i64 %1201, 3
  %1203 = add i64 %1202, %1196
  %1204 = add i64 %1193, 13
  store i64 %1204, i64* %PC, align 8
  %1205 = inttoptr i64 %1203 to i64*
  %1206 = load i64, i64* %1205, align 8
  store i64 %1206, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1207 = add i64 %1193, 17
  store i64 %1207, i64* %PC, align 8
  %1208 = load i64, i64* %1195, align 8
  store i64 %1208, i64* %RDX, align 8, !tbaa !2428
  %1209 = add i64 %1193, 20
  store i64 %1209, i64* %PC, align 8
  %1210 = load i32, i32* %1199, align 4
  %1211 = add i32 %1210, 2
  %1212 = zext i32 %1211 to i64
  store i64 %1212, i64* %RCX, align 8, !tbaa !2428
  %1213 = icmp ugt i32 %1210, -3
  %1214 = zext i1 %1213 to i8
  store i8 %1214, i8* %16, align 1, !tbaa !2433
  %1215 = and i32 %1211, 255
  %1216 = tail call i32 @llvm.ctpop.i32(i32 %1215) #10
  %1217 = trunc i32 %1216 to i8
  %1218 = and i8 %1217, 1
  %1219 = xor i8 %1218, 1
  store i8 %1219, i8* %23, align 1, !tbaa !2447
  %1220 = xor i32 %1211, %1210
  %1221 = lshr i32 %1220, 4
  %1222 = trunc i32 %1221 to i8
  %1223 = and i8 %1222, 1
  store i8 %1223, i8* %29, align 1, !tbaa !2451
  %1224 = icmp eq i32 %1211, 0
  %1225 = zext i1 %1224 to i8
  store i8 %1225, i8* %32, align 1, !tbaa !2448
  %1226 = lshr i32 %1211, 31
  %1227 = trunc i32 %1226 to i8
  store i8 %1227, i8* %35, align 1, !tbaa !2449
  %1228 = lshr i32 %1210, 31
  %1229 = xor i32 %1226, %1228
  %1230 = add nuw nsw i32 %1229, %1226
  %1231 = icmp eq i32 %1230, 2
  %1232 = zext i1 %1231 to i8
  store i8 %1232, i8* %41, align 1, !tbaa !2450
  %1233 = sext i32 %1211 to i64
  store i64 %1233, i64* %RSI, align 8, !tbaa !2428
  %1234 = shl nsw i64 %1233, 3
  %1235 = add i64 %1208, %1234
  %1236 = add i64 %1193, 31
  store i64 %1236, i64* %PC, align 8
  %1237 = bitcast i64 %1206 to double
  %1238 = inttoptr i64 %1235 to double*
  %1239 = load double, double* %1238, align 8
  %1240 = fsub double %1237, %1239
  store double %1240, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1241 = add i64 %1191, -112
  %1242 = add i64 %1193, 36
  store i64 %1242, i64* %PC, align 8
  %1243 = inttoptr i64 %1241 to double*
  store double %1240, double* %1243, align 8
  %1244 = load i64, i64* %RBP, align 8
  %1245 = add i64 %1244, -16
  %1246 = load i64, i64* %PC, align 8
  %1247 = add i64 %1246, 4
  store i64 %1247, i64* %PC, align 8
  %1248 = inttoptr i64 %1245 to i64*
  %1249 = load i64, i64* %1248, align 8
  store i64 %1249, i64* %RDX, align 8, !tbaa !2428
  %1250 = add i64 %1244, -28
  %1251 = add i64 %1246, 7
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i32*
  %1253 = load i32, i32* %1252, align 4
  %1254 = add i32 %1253, 1
  %1255 = zext i32 %1254 to i64
  store i64 %1255, i64* %RCX, align 8, !tbaa !2428
  %1256 = icmp eq i32 %1253, -1
  %1257 = icmp eq i32 %1254, 0
  %1258 = or i1 %1256, %1257
  %1259 = zext i1 %1258 to i8
  store i8 %1259, i8* %16, align 1, !tbaa !2433
  %1260 = and i32 %1254, 255
  %1261 = tail call i32 @llvm.ctpop.i32(i32 %1260) #10
  %1262 = trunc i32 %1261 to i8
  %1263 = and i8 %1262, 1
  %1264 = xor i8 %1263, 1
  store i8 %1264, i8* %23, align 1, !tbaa !2447
  %1265 = xor i32 %1254, %1253
  %1266 = lshr i32 %1265, 4
  %1267 = trunc i32 %1266 to i8
  %1268 = and i8 %1267, 1
  store i8 %1268, i8* %29, align 1, !tbaa !2451
  %1269 = zext i1 %1257 to i8
  store i8 %1269, i8* %32, align 1, !tbaa !2448
  %1270 = lshr i32 %1254, 31
  %1271 = trunc i32 %1270 to i8
  store i8 %1271, i8* %35, align 1, !tbaa !2449
  %1272 = lshr i32 %1253, 31
  %1273 = xor i32 %1270, %1272
  %1274 = add nuw nsw i32 %1273, %1270
  %1275 = icmp eq i32 %1274, 2
  %1276 = zext i1 %1275 to i8
  store i8 %1276, i8* %41, align 1, !tbaa !2450
  %1277 = sext i32 %1254 to i64
  store i64 %1277, i64* %RSI, align 8, !tbaa !2428
  %1278 = shl nsw i64 %1277, 3
  %1279 = add i64 %1249, %1278
  %1280 = add i64 %1246, 18
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to i64*
  %1282 = load i64, i64* %1281, align 8
  store i64 %1282, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1283 = add i64 %1246, 22
  store i64 %1283, i64* %PC, align 8
  %1284 = load i64, i64* %1248, align 8
  store i64 %1284, i64* %RDX, align 8, !tbaa !2428
  %1285 = add i64 %1246, 25
  store i64 %1285, i64* %PC, align 8
  %1286 = load i32, i32* %1252, align 4
  %1287 = add i32 %1286, 3
  %1288 = zext i32 %1287 to i64
  store i64 %1288, i64* %RCX, align 8, !tbaa !2428
  %1289 = icmp ugt i32 %1286, -4
  %1290 = zext i1 %1289 to i8
  store i8 %1290, i8* %16, align 1, !tbaa !2433
  %1291 = and i32 %1287, 255
  %1292 = tail call i32 @llvm.ctpop.i32(i32 %1291) #10
  %1293 = trunc i32 %1292 to i8
  %1294 = and i8 %1293, 1
  %1295 = xor i8 %1294, 1
  store i8 %1295, i8* %23, align 1, !tbaa !2447
  %1296 = xor i32 %1287, %1286
  %1297 = lshr i32 %1296, 4
  %1298 = trunc i32 %1297 to i8
  %1299 = and i8 %1298, 1
  store i8 %1299, i8* %29, align 1, !tbaa !2451
  %1300 = icmp eq i32 %1287, 0
  %1301 = zext i1 %1300 to i8
  store i8 %1301, i8* %32, align 1, !tbaa !2448
  %1302 = lshr i32 %1287, 31
  %1303 = trunc i32 %1302 to i8
  store i8 %1303, i8* %35, align 1, !tbaa !2449
  %1304 = lshr i32 %1286, 31
  %1305 = xor i32 %1302, %1304
  %1306 = add nuw nsw i32 %1305, %1302
  %1307 = icmp eq i32 %1306, 2
  %1308 = zext i1 %1307 to i8
  store i8 %1308, i8* %41, align 1, !tbaa !2450
  %1309 = sext i32 %1287 to i64
  store i64 %1309, i64* %RSI, align 8, !tbaa !2428
  %1310 = shl nsw i64 %1309, 3
  %1311 = add i64 %1284, %1310
  %1312 = add i64 %1246, 36
  store i64 %1312, i64* %PC, align 8
  %1313 = bitcast i64 %1282 to double
  %1314 = inttoptr i64 %1311 to double*
  %1315 = load double, double* %1314, align 8
  %1316 = fsub double %1313, %1315
  store double %1316, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1317 = load i64, i64* %RBP, align 8
  %1318 = add i64 %1317, -120
  %1319 = add i64 %1246, 41
  store i64 %1319, i64* %PC, align 8
  %1320 = inttoptr i64 %1318 to double*
  store double %1316, double* %1320, align 8
  %1321 = load i64, i64* %RBP, align 8
  %1322 = add i64 %1321, -16
  %1323 = load i64, i64* %PC, align 8
  %1324 = add i64 %1323, 4
  store i64 %1324, i64* %PC, align 8
  %1325 = inttoptr i64 %1322 to i64*
  %1326 = load i64, i64* %1325, align 8
  store i64 %1326, i64* %RDX, align 8, !tbaa !2428
  %1327 = add i64 %1321, -28
  %1328 = add i64 %1323, 7
  store i64 %1328, i64* %PC, align 8
  %1329 = inttoptr i64 %1327 to i32*
  %1330 = load i32, i32* %1329, align 4
  %1331 = add i32 %1330, 4
  %1332 = zext i32 %1331 to i64
  store i64 %1332, i64* %RCX, align 8, !tbaa !2428
  %1333 = icmp ugt i32 %1330, -5
  %1334 = zext i1 %1333 to i8
  store i8 %1334, i8* %16, align 1, !tbaa !2433
  %1335 = and i32 %1331, 255
  %1336 = tail call i32 @llvm.ctpop.i32(i32 %1335) #10
  %1337 = trunc i32 %1336 to i8
  %1338 = and i8 %1337, 1
  %1339 = xor i8 %1338, 1
  store i8 %1339, i8* %23, align 1, !tbaa !2447
  %1340 = xor i32 %1331, %1330
  %1341 = lshr i32 %1340, 4
  %1342 = trunc i32 %1341 to i8
  %1343 = and i8 %1342, 1
  store i8 %1343, i8* %29, align 1, !tbaa !2451
  %1344 = icmp eq i32 %1331, 0
  %1345 = zext i1 %1344 to i8
  store i8 %1345, i8* %32, align 1, !tbaa !2448
  %1346 = lshr i32 %1331, 31
  %1347 = trunc i32 %1346 to i8
  store i8 %1347, i8* %35, align 1, !tbaa !2449
  %1348 = lshr i32 %1330, 31
  %1349 = xor i32 %1346, %1348
  %1350 = add nuw nsw i32 %1349, %1346
  %1351 = icmp eq i32 %1350, 2
  %1352 = zext i1 %1351 to i8
  store i8 %1352, i8* %41, align 1, !tbaa !2450
  %1353 = sext i32 %1331 to i64
  store i64 %1353, i64* %RSI, align 8, !tbaa !2428
  %1354 = shl nsw i64 %1353, 3
  %1355 = add i64 %1326, %1354
  %1356 = add i64 %1323, 18
  store i64 %1356, i64* %PC, align 8
  %1357 = inttoptr i64 %1355 to i64*
  %1358 = load i64, i64* %1357, align 8
  store i64 %1358, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1359 = add i64 %1323, 22
  store i64 %1359, i64* %PC, align 8
  %1360 = load i64, i64* %1325, align 8
  store i64 %1360, i64* %RDX, align 8, !tbaa !2428
  %1361 = add i64 %1323, 25
  store i64 %1361, i64* %PC, align 8
  %1362 = load i32, i32* %1329, align 4
  %1363 = add i32 %1362, 6
  %1364 = zext i32 %1363 to i64
  store i64 %1364, i64* %RCX, align 8, !tbaa !2428
  %1365 = icmp ugt i32 %1362, -7
  %1366 = zext i1 %1365 to i8
  store i8 %1366, i8* %16, align 1, !tbaa !2433
  %1367 = and i32 %1363, 255
  %1368 = tail call i32 @llvm.ctpop.i32(i32 %1367) #10
  %1369 = trunc i32 %1368 to i8
  %1370 = and i8 %1369, 1
  %1371 = xor i8 %1370, 1
  store i8 %1371, i8* %23, align 1, !tbaa !2447
  %1372 = xor i32 %1363, %1362
  %1373 = lshr i32 %1372, 4
  %1374 = trunc i32 %1373 to i8
  %1375 = and i8 %1374, 1
  store i8 %1375, i8* %29, align 1, !tbaa !2451
  %1376 = icmp eq i32 %1363, 0
  %1377 = zext i1 %1376 to i8
  store i8 %1377, i8* %32, align 1, !tbaa !2448
  %1378 = lshr i32 %1363, 31
  %1379 = trunc i32 %1378 to i8
  store i8 %1379, i8* %35, align 1, !tbaa !2449
  %1380 = lshr i32 %1362, 31
  %1381 = xor i32 %1378, %1380
  %1382 = add nuw nsw i32 %1381, %1378
  %1383 = icmp eq i32 %1382, 2
  %1384 = zext i1 %1383 to i8
  store i8 %1384, i8* %41, align 1, !tbaa !2450
  %1385 = sext i32 %1363 to i64
  store i64 %1385, i64* %RSI, align 8, !tbaa !2428
  %1386 = shl nsw i64 %1385, 3
  %1387 = add i64 %1360, %1386
  %1388 = add i64 %1323, 36
  store i64 %1388, i64* %PC, align 8
  %1389 = bitcast i64 %1358 to double
  %1390 = inttoptr i64 %1387 to double*
  %1391 = load double, double* %1390, align 8
  %1392 = fadd double %1389, %1391
  store double %1392, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1393 = load i64, i64* %RBP, align 8
  %1394 = add i64 %1393, -128
  %1395 = add i64 %1323, 41
  store i64 %1395, i64* %PC, align 8
  %1396 = inttoptr i64 %1394 to double*
  store double %1392, double* %1396, align 8
  %1397 = load i64, i64* %RBP, align 8
  %1398 = add i64 %1397, -16
  %1399 = load i64, i64* %PC, align 8
  %1400 = add i64 %1399, 4
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1398 to i64*
  %1402 = load i64, i64* %1401, align 8
  store i64 %1402, i64* %RDX, align 8, !tbaa !2428
  %1403 = add i64 %1397, -28
  %1404 = add i64 %1399, 7
  store i64 %1404, i64* %PC, align 8
  %1405 = inttoptr i64 %1403 to i32*
  %1406 = load i32, i32* %1405, align 4
  %1407 = add i32 %1406, 5
  %1408 = zext i32 %1407 to i64
  store i64 %1408, i64* %RCX, align 8, !tbaa !2428
  %1409 = icmp ugt i32 %1406, -6
  %1410 = zext i1 %1409 to i8
  store i8 %1410, i8* %16, align 1, !tbaa !2433
  %1411 = and i32 %1407, 255
  %1412 = tail call i32 @llvm.ctpop.i32(i32 %1411) #10
  %1413 = trunc i32 %1412 to i8
  %1414 = and i8 %1413, 1
  %1415 = xor i8 %1414, 1
  store i8 %1415, i8* %23, align 1, !tbaa !2447
  %1416 = xor i32 %1407, %1406
  %1417 = lshr i32 %1416, 4
  %1418 = trunc i32 %1417 to i8
  %1419 = and i8 %1418, 1
  store i8 %1419, i8* %29, align 1, !tbaa !2451
  %1420 = icmp eq i32 %1407, 0
  %1421 = zext i1 %1420 to i8
  store i8 %1421, i8* %32, align 1, !tbaa !2448
  %1422 = lshr i32 %1407, 31
  %1423 = trunc i32 %1422 to i8
  store i8 %1423, i8* %35, align 1, !tbaa !2449
  %1424 = lshr i32 %1406, 31
  %1425 = xor i32 %1422, %1424
  %1426 = add nuw nsw i32 %1425, %1422
  %1427 = icmp eq i32 %1426, 2
  %1428 = zext i1 %1427 to i8
  store i8 %1428, i8* %41, align 1, !tbaa !2450
  %1429 = sext i32 %1407 to i64
  store i64 %1429, i64* %RSI, align 8, !tbaa !2428
  %1430 = shl nsw i64 %1429, 3
  %1431 = add i64 %1402, %1430
  %1432 = add i64 %1399, 18
  store i64 %1432, i64* %PC, align 8
  %1433 = inttoptr i64 %1431 to i64*
  %1434 = load i64, i64* %1433, align 8
  store i64 %1434, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1435 = add i64 %1399, 22
  store i64 %1435, i64* %PC, align 8
  %1436 = load i64, i64* %1401, align 8
  store i64 %1436, i64* %RDX, align 8, !tbaa !2428
  %1437 = add i64 %1399, 25
  store i64 %1437, i64* %PC, align 8
  %1438 = load i32, i32* %1405, align 4
  %1439 = add i32 %1438, 7
  %1440 = zext i32 %1439 to i64
  store i64 %1440, i64* %RCX, align 8, !tbaa !2428
  %1441 = icmp ugt i32 %1438, -8
  %1442 = zext i1 %1441 to i8
  store i8 %1442, i8* %16, align 1, !tbaa !2433
  %1443 = and i32 %1439, 255
  %1444 = tail call i32 @llvm.ctpop.i32(i32 %1443) #10
  %1445 = trunc i32 %1444 to i8
  %1446 = and i8 %1445, 1
  %1447 = xor i8 %1446, 1
  store i8 %1447, i8* %23, align 1, !tbaa !2447
  %1448 = xor i32 %1439, %1438
  %1449 = lshr i32 %1448, 4
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  store i8 %1451, i8* %29, align 1, !tbaa !2451
  %1452 = icmp eq i32 %1439, 0
  %1453 = zext i1 %1452 to i8
  store i8 %1453, i8* %32, align 1, !tbaa !2448
  %1454 = lshr i32 %1439, 31
  %1455 = trunc i32 %1454 to i8
  store i8 %1455, i8* %35, align 1, !tbaa !2449
  %1456 = lshr i32 %1438, 31
  %1457 = xor i32 %1454, %1456
  %1458 = add nuw nsw i32 %1457, %1454
  %1459 = icmp eq i32 %1458, 2
  %1460 = zext i1 %1459 to i8
  store i8 %1460, i8* %41, align 1, !tbaa !2450
  %1461 = sext i32 %1439 to i64
  store i64 %1461, i64* %RSI, align 8, !tbaa !2428
  %1462 = shl nsw i64 %1461, 3
  %1463 = add i64 %1436, %1462
  %1464 = add i64 %1399, 36
  store i64 %1464, i64* %PC, align 8
  %1465 = bitcast i64 %1434 to double
  %1466 = inttoptr i64 %1463 to double*
  %1467 = load double, double* %1466, align 8
  %1468 = fadd double %1465, %1467
  store double %1468, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1469 = load i64, i64* %RBP, align 8
  %1470 = add i64 %1469, -136
  %1471 = add i64 %1399, 44
  store i64 %1471, i64* %PC, align 8
  %1472 = inttoptr i64 %1470 to double*
  store double %1468, double* %1472, align 8
  %1473 = load i64, i64* %RBP, align 8
  %1474 = add i64 %1473, -16
  %1475 = load i64, i64* %PC, align 8
  %1476 = add i64 %1475, 4
  store i64 %1476, i64* %PC, align 8
  %1477 = inttoptr i64 %1474 to i64*
  %1478 = load i64, i64* %1477, align 8
  store i64 %1478, i64* %RDX, align 8, !tbaa !2428
  %1479 = add i64 %1473, -28
  %1480 = add i64 %1475, 7
  store i64 %1480, i64* %PC, align 8
  %1481 = inttoptr i64 %1479 to i32*
  %1482 = load i32, i32* %1481, align 4
  %1483 = add i32 %1482, 4
  %1484 = zext i32 %1483 to i64
  store i64 %1484, i64* %RCX, align 8, !tbaa !2428
  %1485 = icmp ugt i32 %1482, -5
  %1486 = zext i1 %1485 to i8
  store i8 %1486, i8* %16, align 1, !tbaa !2433
  %1487 = and i32 %1483, 255
  %1488 = tail call i32 @llvm.ctpop.i32(i32 %1487) #10
  %1489 = trunc i32 %1488 to i8
  %1490 = and i8 %1489, 1
  %1491 = xor i8 %1490, 1
  store i8 %1491, i8* %23, align 1, !tbaa !2447
  %1492 = xor i32 %1483, %1482
  %1493 = lshr i32 %1492, 4
  %1494 = trunc i32 %1493 to i8
  %1495 = and i8 %1494, 1
  store i8 %1495, i8* %29, align 1, !tbaa !2451
  %1496 = icmp eq i32 %1483, 0
  %1497 = zext i1 %1496 to i8
  store i8 %1497, i8* %32, align 1, !tbaa !2448
  %1498 = lshr i32 %1483, 31
  %1499 = trunc i32 %1498 to i8
  store i8 %1499, i8* %35, align 1, !tbaa !2449
  %1500 = lshr i32 %1482, 31
  %1501 = xor i32 %1498, %1500
  %1502 = add nuw nsw i32 %1501, %1498
  %1503 = icmp eq i32 %1502, 2
  %1504 = zext i1 %1503 to i8
  store i8 %1504, i8* %41, align 1, !tbaa !2450
  %1505 = sext i32 %1483 to i64
  store i64 %1505, i64* %RSI, align 8, !tbaa !2428
  %1506 = shl nsw i64 %1505, 3
  %1507 = add i64 %1478, %1506
  %1508 = add i64 %1475, 18
  store i64 %1508, i64* %PC, align 8
  %1509 = inttoptr i64 %1507 to i64*
  %1510 = load i64, i64* %1509, align 8
  store i64 %1510, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1511 = add i64 %1475, 22
  store i64 %1511, i64* %PC, align 8
  %1512 = load i64, i64* %1477, align 8
  store i64 %1512, i64* %RDX, align 8, !tbaa !2428
  %1513 = add i64 %1475, 25
  store i64 %1513, i64* %PC, align 8
  %1514 = load i32, i32* %1481, align 4
  %1515 = add i32 %1514, 6
  %1516 = zext i32 %1515 to i64
  store i64 %1516, i64* %RCX, align 8, !tbaa !2428
  %1517 = icmp ugt i32 %1514, -7
  %1518 = zext i1 %1517 to i8
  store i8 %1518, i8* %16, align 1, !tbaa !2433
  %1519 = and i32 %1515, 255
  %1520 = tail call i32 @llvm.ctpop.i32(i32 %1519) #10
  %1521 = trunc i32 %1520 to i8
  %1522 = and i8 %1521, 1
  %1523 = xor i8 %1522, 1
  store i8 %1523, i8* %23, align 1, !tbaa !2447
  %1524 = xor i32 %1515, %1514
  %1525 = lshr i32 %1524, 4
  %1526 = trunc i32 %1525 to i8
  %1527 = and i8 %1526, 1
  store i8 %1527, i8* %29, align 1, !tbaa !2451
  %1528 = icmp eq i32 %1515, 0
  %1529 = zext i1 %1528 to i8
  store i8 %1529, i8* %32, align 1, !tbaa !2448
  %1530 = lshr i32 %1515, 31
  %1531 = trunc i32 %1530 to i8
  store i8 %1531, i8* %35, align 1, !tbaa !2449
  %1532 = lshr i32 %1514, 31
  %1533 = xor i32 %1530, %1532
  %1534 = add nuw nsw i32 %1533, %1530
  %1535 = icmp eq i32 %1534, 2
  %1536 = zext i1 %1535 to i8
  store i8 %1536, i8* %41, align 1, !tbaa !2450
  %1537 = sext i32 %1515 to i64
  store i64 %1537, i64* %RSI, align 8, !tbaa !2428
  %1538 = shl nsw i64 %1537, 3
  %1539 = add i64 %1512, %1538
  %1540 = add i64 %1475, 36
  store i64 %1540, i64* %PC, align 8
  %1541 = bitcast i64 %1510 to double
  %1542 = inttoptr i64 %1539 to double*
  %1543 = load double, double* %1542, align 8
  %1544 = fsub double %1541, %1543
  store double %1544, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1545 = load i64, i64* %RBP, align 8
  %1546 = add i64 %1545, -144
  %1547 = add i64 %1475, 44
  store i64 %1547, i64* %PC, align 8
  %1548 = inttoptr i64 %1546 to double*
  store double %1544, double* %1548, align 8
  %1549 = load i64, i64* %RBP, align 8
  %1550 = add i64 %1549, -16
  %1551 = load i64, i64* %PC, align 8
  %1552 = add i64 %1551, 4
  store i64 %1552, i64* %PC, align 8
  %1553 = inttoptr i64 %1550 to i64*
  %1554 = load i64, i64* %1553, align 8
  store i64 %1554, i64* %RDX, align 8, !tbaa !2428
  %1555 = add i64 %1549, -28
  %1556 = add i64 %1551, 7
  store i64 %1556, i64* %PC, align 8
  %1557 = inttoptr i64 %1555 to i32*
  %1558 = load i32, i32* %1557, align 4
  %1559 = add i32 %1558, 5
  %1560 = zext i32 %1559 to i64
  store i64 %1560, i64* %RCX, align 8, !tbaa !2428
  %1561 = icmp ugt i32 %1558, -6
  %1562 = zext i1 %1561 to i8
  store i8 %1562, i8* %16, align 1, !tbaa !2433
  %1563 = and i32 %1559, 255
  %1564 = tail call i32 @llvm.ctpop.i32(i32 %1563) #10
  %1565 = trunc i32 %1564 to i8
  %1566 = and i8 %1565, 1
  %1567 = xor i8 %1566, 1
  store i8 %1567, i8* %23, align 1, !tbaa !2447
  %1568 = xor i32 %1559, %1558
  %1569 = lshr i32 %1568, 4
  %1570 = trunc i32 %1569 to i8
  %1571 = and i8 %1570, 1
  store i8 %1571, i8* %29, align 1, !tbaa !2451
  %1572 = icmp eq i32 %1559, 0
  %1573 = zext i1 %1572 to i8
  store i8 %1573, i8* %32, align 1, !tbaa !2448
  %1574 = lshr i32 %1559, 31
  %1575 = trunc i32 %1574 to i8
  store i8 %1575, i8* %35, align 1, !tbaa !2449
  %1576 = lshr i32 %1558, 31
  %1577 = xor i32 %1574, %1576
  %1578 = add nuw nsw i32 %1577, %1574
  %1579 = icmp eq i32 %1578, 2
  %1580 = zext i1 %1579 to i8
  store i8 %1580, i8* %41, align 1, !tbaa !2450
  %1581 = sext i32 %1559 to i64
  store i64 %1581, i64* %RSI, align 8, !tbaa !2428
  %1582 = shl nsw i64 %1581, 3
  %1583 = add i64 %1554, %1582
  %1584 = add i64 %1551, 18
  store i64 %1584, i64* %PC, align 8
  %1585 = inttoptr i64 %1583 to i64*
  %1586 = load i64, i64* %1585, align 8
  store i64 %1586, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1587 = add i64 %1551, 22
  store i64 %1587, i64* %PC, align 8
  %1588 = load i64, i64* %1553, align 8
  store i64 %1588, i64* %RDX, align 8, !tbaa !2428
  %1589 = add i64 %1551, 25
  store i64 %1589, i64* %PC, align 8
  %1590 = load i32, i32* %1557, align 4
  %1591 = add i32 %1590, 7
  %1592 = zext i32 %1591 to i64
  store i64 %1592, i64* %RCX, align 8, !tbaa !2428
  %1593 = icmp ugt i32 %1590, -8
  %1594 = zext i1 %1593 to i8
  store i8 %1594, i8* %16, align 1, !tbaa !2433
  %1595 = and i32 %1591, 255
  %1596 = tail call i32 @llvm.ctpop.i32(i32 %1595) #10
  %1597 = trunc i32 %1596 to i8
  %1598 = and i8 %1597, 1
  %1599 = xor i8 %1598, 1
  store i8 %1599, i8* %23, align 1, !tbaa !2447
  %1600 = xor i32 %1591, %1590
  %1601 = lshr i32 %1600, 4
  %1602 = trunc i32 %1601 to i8
  %1603 = and i8 %1602, 1
  store i8 %1603, i8* %29, align 1, !tbaa !2451
  %1604 = icmp eq i32 %1591, 0
  %1605 = zext i1 %1604 to i8
  store i8 %1605, i8* %32, align 1, !tbaa !2448
  %1606 = lshr i32 %1591, 31
  %1607 = trunc i32 %1606 to i8
  store i8 %1607, i8* %35, align 1, !tbaa !2449
  %1608 = lshr i32 %1590, 31
  %1609 = xor i32 %1606, %1608
  %1610 = add nuw nsw i32 %1609, %1606
  %1611 = icmp eq i32 %1610, 2
  %1612 = zext i1 %1611 to i8
  store i8 %1612, i8* %41, align 1, !tbaa !2450
  %1613 = sext i32 %1591 to i64
  store i64 %1613, i64* %RSI, align 8, !tbaa !2428
  %1614 = shl nsw i64 %1613, 3
  %1615 = add i64 %1588, %1614
  %1616 = add i64 %1551, 36
  store i64 %1616, i64* %PC, align 8
  %1617 = bitcast i64 %1586 to double
  %1618 = inttoptr i64 %1615 to double*
  %1619 = load double, double* %1618, align 8
  %1620 = fsub double %1617, %1619
  store double %1620, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1621 = load i64, i64* %RBP, align 8
  %1622 = add i64 %1621, -152
  %1623 = add i64 %1551, 44
  store i64 %1623, i64* %PC, align 8
  %1624 = inttoptr i64 %1622 to double*
  store double %1620, double* %1624, align 8
  %1625 = load i64, i64* %RBP, align 8
  %1626 = add i64 %1625, -96
  %1627 = load i64, i64* %PC, align 8
  %1628 = add i64 %1627, 5
  store i64 %1628, i64* %PC, align 8
  %1629 = inttoptr i64 %1626 to i64*
  %1630 = load i64, i64* %1629, align 8
  store i64 %1630, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1631 = add i64 %1625, -128
  %1632 = add i64 %1627, 10
  store i64 %1632, i64* %PC, align 8
  %1633 = bitcast i64 %1630 to double
  %1634 = inttoptr i64 %1631 to double*
  %1635 = load double, double* %1634, align 8
  %1636 = fadd double %1633, %1635
  store double %1636, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1637 = add i64 %1625, -16
  %1638 = add i64 %1627, 14
  store i64 %1638, i64* %PC, align 8
  %1639 = inttoptr i64 %1637 to i64*
  %1640 = load i64, i64* %1639, align 8
  store i64 %1640, i64* %RDX, align 8, !tbaa !2428
  %1641 = add i64 %1625, -28
  %1642 = add i64 %1627, 18
  store i64 %1642, i64* %PC, align 8
  %1643 = inttoptr i64 %1641 to i32*
  %1644 = load i32, i32* %1643, align 4
  %1645 = sext i32 %1644 to i64
  store i64 %1645, i64* %RSI, align 8, !tbaa !2428
  %1646 = shl nsw i64 %1645, 3
  %1647 = add i64 %1646, %1640
  %1648 = add i64 %1627, 23
  store i64 %1648, i64* %PC, align 8
  %1649 = inttoptr i64 %1647 to double*
  store double %1636, double* %1649, align 8
  %1650 = load i64, i64* %RBP, align 8
  %1651 = add i64 %1650, -104
  %1652 = load i64, i64* %PC, align 8
  %1653 = add i64 %1652, 5
  store i64 %1653, i64* %PC, align 8
  %1654 = inttoptr i64 %1651 to i64*
  %1655 = load i64, i64* %1654, align 8
  store i64 %1655, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1656 = add i64 %1650, -136
  %1657 = add i64 %1652, 13
  store i64 %1657, i64* %PC, align 8
  %1658 = bitcast i64 %1655 to double
  %1659 = inttoptr i64 %1656 to double*
  %1660 = load double, double* %1659, align 8
  %1661 = fadd double %1658, %1660
  store double %1661, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1662 = add i64 %1650, -16
  %1663 = add i64 %1652, 17
  store i64 %1663, i64* %PC, align 8
  %1664 = inttoptr i64 %1662 to i64*
  %1665 = load i64, i64* %1664, align 8
  store i64 %1665, i64* %RDX, align 8, !tbaa !2428
  %1666 = add i64 %1650, -28
  %1667 = add i64 %1652, 20
  store i64 %1667, i64* %PC, align 8
  %1668 = inttoptr i64 %1666 to i32*
  %1669 = load i32, i32* %1668, align 4
  %1670 = add i32 %1669, 1
  %1671 = zext i32 %1670 to i64
  store i64 %1671, i64* %RCX, align 8, !tbaa !2428
  %1672 = icmp eq i32 %1669, -1
  %1673 = icmp eq i32 %1670, 0
  %1674 = or i1 %1672, %1673
  %1675 = zext i1 %1674 to i8
  store i8 %1675, i8* %16, align 1, !tbaa !2433
  %1676 = and i32 %1670, 255
  %1677 = tail call i32 @llvm.ctpop.i32(i32 %1676) #10
  %1678 = trunc i32 %1677 to i8
  %1679 = and i8 %1678, 1
  %1680 = xor i8 %1679, 1
  store i8 %1680, i8* %23, align 1, !tbaa !2447
  %1681 = xor i32 %1670, %1669
  %1682 = lshr i32 %1681, 4
  %1683 = trunc i32 %1682 to i8
  %1684 = and i8 %1683, 1
  store i8 %1684, i8* %29, align 1, !tbaa !2451
  %1685 = zext i1 %1673 to i8
  store i8 %1685, i8* %32, align 1, !tbaa !2448
  %1686 = lshr i32 %1670, 31
  %1687 = trunc i32 %1686 to i8
  store i8 %1687, i8* %35, align 1, !tbaa !2449
  %1688 = lshr i32 %1669, 31
  %1689 = xor i32 %1686, %1688
  %1690 = add nuw nsw i32 %1689, %1686
  %1691 = icmp eq i32 %1690, 2
  %1692 = zext i1 %1691 to i8
  store i8 %1692, i8* %41, align 1, !tbaa !2450
  %1693 = sext i32 %1670 to i64
  store i64 %1693, i64* %RSI, align 8, !tbaa !2428
  %1694 = shl nsw i64 %1693, 3
  %1695 = add i64 %1665, %1694
  %1696 = add i64 %1652, 31
  store i64 %1696, i64* %PC, align 8
  %1697 = inttoptr i64 %1695 to double*
  store double %1661, double* %1697, align 8
  %1698 = load i64, i64* %RBP, align 8
  %1699 = add i64 %1698, -128
  %1700 = load i64, i64* %PC, align 8
  %1701 = add i64 %1700, 5
  store i64 %1701, i64* %PC, align 8
  %1702 = inttoptr i64 %1699 to i64*
  %1703 = load i64, i64* %1702, align 8
  store i64 %1703, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1704 = add i64 %1698, -96
  %1705 = add i64 %1700, 10
  store i64 %1705, i64* %PC, align 8
  %1706 = inttoptr i64 %1704 to double*
  %1707 = load double, double* %1706, align 8
  %1708 = bitcast i64 %1703 to double
  %1709 = fsub double %1707, %1708
  store double %1709, double* %821, align 1, !tbaa !2452
  store i64 0, i64* %817, align 1, !tbaa !2452
  %1710 = add i64 %1700, 19
  store i64 %1710, i64* %PC, align 8
  %1711 = inttoptr i64 %1704 to double*
  store double %1709, double* %1711, align 8
  %1712 = load i64, i64* %RBP, align 8
  %1713 = add i64 %1712, -136
  %1714 = load i64, i64* %PC, align 8
  %1715 = add i64 %1714, 8
  store i64 %1715, i64* %PC, align 8
  %1716 = inttoptr i64 %1713 to i64*
  %1717 = load i64, i64* %1716, align 8
  store i64 %1717, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1718 = add i64 %1712, -104
  %1719 = add i64 %1714, 13
  store i64 %1719, i64* %PC, align 8
  %1720 = inttoptr i64 %1718 to double*
  %1721 = load double, double* %1720, align 8
  %1722 = bitcast i64 %1717 to double
  %1723 = fsub double %1721, %1722
  store double %1723, double* %821, align 1, !tbaa !2452
  store i64 0, i64* %817, align 1, !tbaa !2452
  %1724 = add i64 %1714, 22
  store i64 %1724, i64* %PC, align 8
  %1725 = inttoptr i64 %1718 to double*
  store double %1723, double* %1725, align 8
  %1726 = load i64, i64* %RBP, align 8
  %1727 = add i64 %1726, -64
  %1728 = load i64, i64* %PC, align 8
  %1729 = add i64 %1728, 5
  store i64 %1729, i64* %PC, align 8
  %1730 = inttoptr i64 %1727 to i64*
  %1731 = load i64, i64* %1730, align 8
  store i64 %1731, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1732 = add i64 %1726, -96
  %1733 = add i64 %1728, 10
  store i64 %1733, i64* %PC, align 8
  %1734 = bitcast i64 %1731 to double
  %1735 = inttoptr i64 %1732 to double*
  %1736 = load double, double* %1735, align 8
  %1737 = fmul double %1734, %1736
  store double %1737, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1738 = add i64 %1726, -72
  %1739 = add i64 %1728, 15
  store i64 %1739, i64* %PC, align 8
  %1740 = inttoptr i64 %1738 to i64*
  %1741 = load i64, i64* %1740, align 8
  store i64 %1741, i64* %828, align 1, !tbaa !2452
  store double 0.000000e+00, double* %829, align 1, !tbaa !2452
  %1742 = add i64 %1726, -104
  %1743 = add i64 %1728, 20
  store i64 %1743, i64* %PC, align 8
  %1744 = bitcast i64 %1741 to double
  %1745 = inttoptr i64 %1742 to double*
  %1746 = load double, double* %1745, align 8
  %1747 = fmul double %1744, %1746
  store double %1747, double* %821, align 1, !tbaa !2452
  store i64 0, i64* %817, align 1, !tbaa !2452
  %1748 = fsub double %1737, %1747
  store double %1748, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1749 = add i64 %1726, -16
  %1750 = add i64 %1728, 28
  store i64 %1750, i64* %PC, align 8
  %1751 = inttoptr i64 %1749 to i64*
  %1752 = load i64, i64* %1751, align 8
  store i64 %1752, i64* %RDX, align 8, !tbaa !2428
  %1753 = add i64 %1726, -28
  %1754 = add i64 %1728, 31
  store i64 %1754, i64* %PC, align 8
  %1755 = inttoptr i64 %1753 to i32*
  %1756 = load i32, i32* %1755, align 4
  %1757 = add i32 %1756, 4
  %1758 = zext i32 %1757 to i64
  store i64 %1758, i64* %RCX, align 8, !tbaa !2428
  %1759 = icmp ugt i32 %1756, -5
  %1760 = zext i1 %1759 to i8
  store i8 %1760, i8* %16, align 1, !tbaa !2433
  %1761 = and i32 %1757, 255
  %1762 = tail call i32 @llvm.ctpop.i32(i32 %1761) #10
  %1763 = trunc i32 %1762 to i8
  %1764 = and i8 %1763, 1
  %1765 = xor i8 %1764, 1
  store i8 %1765, i8* %23, align 1, !tbaa !2447
  %1766 = xor i32 %1757, %1756
  %1767 = lshr i32 %1766, 4
  %1768 = trunc i32 %1767 to i8
  %1769 = and i8 %1768, 1
  store i8 %1769, i8* %29, align 1, !tbaa !2451
  %1770 = icmp eq i32 %1757, 0
  %1771 = zext i1 %1770 to i8
  store i8 %1771, i8* %32, align 1, !tbaa !2448
  %1772 = lshr i32 %1757, 31
  %1773 = trunc i32 %1772 to i8
  store i8 %1773, i8* %35, align 1, !tbaa !2449
  %1774 = lshr i32 %1756, 31
  %1775 = xor i32 %1772, %1774
  %1776 = add nuw nsw i32 %1775, %1772
  %1777 = icmp eq i32 %1776, 2
  %1778 = zext i1 %1777 to i8
  store i8 %1778, i8* %41, align 1, !tbaa !2450
  %1779 = sext i32 %1757 to i64
  store i64 %1779, i64* %RSI, align 8, !tbaa !2428
  %1780 = shl nsw i64 %1779, 3
  %1781 = add i64 %1752, %1780
  %1782 = add i64 %1728, 42
  store i64 %1782, i64* %PC, align 8
  %1783 = inttoptr i64 %1781 to double*
  store double %1748, double* %1783, align 8
  %1784 = load i64, i64* %RBP, align 8
  %1785 = add i64 %1784, -64
  %1786 = load i64, i64* %PC, align 8
  %1787 = add i64 %1786, 5
  store i64 %1787, i64* %PC, align 8
  %1788 = inttoptr i64 %1785 to i64*
  %1789 = load i64, i64* %1788, align 8
  store i64 %1789, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1790 = add i64 %1784, -104
  %1791 = add i64 %1786, 10
  store i64 %1791, i64* %PC, align 8
  %1792 = bitcast i64 %1789 to double
  %1793 = inttoptr i64 %1790 to double*
  %1794 = load double, double* %1793, align 8
  %1795 = fmul double %1792, %1794
  store double %1795, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1796 = add i64 %1784, -72
  %1797 = add i64 %1786, 15
  store i64 %1797, i64* %PC, align 8
  %1798 = inttoptr i64 %1796 to i64*
  %1799 = load i64, i64* %1798, align 8
  store i64 %1799, i64* %828, align 1, !tbaa !2452
  store double 0.000000e+00, double* %829, align 1, !tbaa !2452
  %1800 = add i64 %1784, -96
  %1801 = add i64 %1786, 20
  store i64 %1801, i64* %PC, align 8
  %1802 = bitcast i64 %1799 to double
  %1803 = inttoptr i64 %1800 to double*
  %1804 = load double, double* %1803, align 8
  %1805 = fmul double %1802, %1804
  store double %1805, double* %821, align 1, !tbaa !2452
  store i64 0, i64* %817, align 1, !tbaa !2452
  %1806 = fadd double %1795, %1805
  store double %1806, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1807 = add i64 %1784, -16
  %1808 = add i64 %1786, 28
  store i64 %1808, i64* %PC, align 8
  %1809 = inttoptr i64 %1807 to i64*
  %1810 = load i64, i64* %1809, align 8
  store i64 %1810, i64* %RDX, align 8, !tbaa !2428
  %1811 = add i64 %1784, -28
  %1812 = add i64 %1786, 31
  store i64 %1812, i64* %PC, align 8
  %1813 = inttoptr i64 %1811 to i32*
  %1814 = load i32, i32* %1813, align 4
  %1815 = add i32 %1814, 5
  %1816 = zext i32 %1815 to i64
  store i64 %1816, i64* %RCX, align 8, !tbaa !2428
  %1817 = icmp ugt i32 %1814, -6
  %1818 = zext i1 %1817 to i8
  store i8 %1818, i8* %16, align 1, !tbaa !2433
  %1819 = and i32 %1815, 255
  %1820 = tail call i32 @llvm.ctpop.i32(i32 %1819) #10
  %1821 = trunc i32 %1820 to i8
  %1822 = and i8 %1821, 1
  %1823 = xor i8 %1822, 1
  store i8 %1823, i8* %23, align 1, !tbaa !2447
  %1824 = xor i32 %1815, %1814
  %1825 = lshr i32 %1824, 4
  %1826 = trunc i32 %1825 to i8
  %1827 = and i8 %1826, 1
  store i8 %1827, i8* %29, align 1, !tbaa !2451
  %1828 = icmp eq i32 %1815, 0
  %1829 = zext i1 %1828 to i8
  store i8 %1829, i8* %32, align 1, !tbaa !2448
  %1830 = lshr i32 %1815, 31
  %1831 = trunc i32 %1830 to i8
  store i8 %1831, i8* %35, align 1, !tbaa !2449
  %1832 = lshr i32 %1814, 31
  %1833 = xor i32 %1830, %1832
  %1834 = add nuw nsw i32 %1833, %1830
  %1835 = icmp eq i32 %1834, 2
  %1836 = zext i1 %1835 to i8
  store i8 %1836, i8* %41, align 1, !tbaa !2450
  %1837 = sext i32 %1815 to i64
  store i64 %1837, i64* %RSI, align 8, !tbaa !2428
  %1838 = shl nsw i64 %1837, 3
  %1839 = add i64 %1810, %1838
  %1840 = add i64 %1786, 42
  store i64 %1840, i64* %PC, align 8
  %1841 = inttoptr i64 %1839 to double*
  store double %1806, double* %1841, align 8
  %1842 = load i64, i64* %RBP, align 8
  %1843 = add i64 %1842, -112
  %1844 = load i64, i64* %PC, align 8
  %1845 = add i64 %1844, 5
  store i64 %1845, i64* %PC, align 8
  %1846 = inttoptr i64 %1843 to i64*
  %1847 = load i64, i64* %1846, align 8
  store i64 %1847, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1848 = add i64 %1842, -152
  %1849 = add i64 %1844, 13
  store i64 %1849, i64* %PC, align 8
  %1850 = bitcast i64 %1847 to double
  %1851 = inttoptr i64 %1848 to double*
  %1852 = load double, double* %1851, align 8
  %1853 = fsub double %1850, %1852
  store double %1853, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1854 = add i64 %1842, -96
  %1855 = add i64 %1844, 18
  store i64 %1855, i64* %PC, align 8
  %1856 = inttoptr i64 %1854 to double*
  store double %1853, double* %1856, align 8
  %1857 = load i64, i64* %RBP, align 8
  %1858 = add i64 %1857, -120
  %1859 = load i64, i64* %PC, align 8
  %1860 = add i64 %1859, 5
  store i64 %1860, i64* %PC, align 8
  %1861 = inttoptr i64 %1858 to i64*
  %1862 = load i64, i64* %1861, align 8
  store i64 %1862, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1863 = add i64 %1857, -144
  %1864 = add i64 %1859, 13
  store i64 %1864, i64* %PC, align 8
  %1865 = bitcast i64 %1862 to double
  %1866 = inttoptr i64 %1863 to double*
  %1867 = load double, double* %1866, align 8
  %1868 = fadd double %1865, %1867
  store double %1868, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1869 = add i64 %1857, -104
  %1870 = add i64 %1859, 18
  store i64 %1870, i64* %PC, align 8
  %1871 = inttoptr i64 %1869 to double*
  store double %1868, double* %1871, align 8
  %1872 = load i64, i64* %RBP, align 8
  %1873 = add i64 %1872, -48
  %1874 = load i64, i64* %PC, align 8
  %1875 = add i64 %1874, 5
  store i64 %1875, i64* %PC, align 8
  %1876 = inttoptr i64 %1873 to i64*
  %1877 = load i64, i64* %1876, align 8
  store i64 %1877, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1878 = add i64 %1872, -96
  %1879 = add i64 %1874, 10
  store i64 %1879, i64* %PC, align 8
  %1880 = bitcast i64 %1877 to double
  %1881 = inttoptr i64 %1878 to double*
  %1882 = load double, double* %1881, align 8
  %1883 = fmul double %1880, %1882
  store double %1883, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1884 = add i64 %1872, -56
  %1885 = add i64 %1874, 15
  store i64 %1885, i64* %PC, align 8
  %1886 = inttoptr i64 %1884 to i64*
  %1887 = load i64, i64* %1886, align 8
  store i64 %1887, i64* %828, align 1, !tbaa !2452
  store double 0.000000e+00, double* %829, align 1, !tbaa !2452
  %1888 = add i64 %1872, -104
  %1889 = add i64 %1874, 20
  store i64 %1889, i64* %PC, align 8
  %1890 = bitcast i64 %1887 to double
  %1891 = inttoptr i64 %1888 to double*
  %1892 = load double, double* %1891, align 8
  %1893 = fmul double %1890, %1892
  store double %1893, double* %821, align 1, !tbaa !2452
  store i64 0, i64* %817, align 1, !tbaa !2452
  %1894 = fsub double %1883, %1893
  store double %1894, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1895 = add i64 %1872, -16
  %1896 = add i64 %1874, 28
  store i64 %1896, i64* %PC, align 8
  %1897 = inttoptr i64 %1895 to i64*
  %1898 = load i64, i64* %1897, align 8
  store i64 %1898, i64* %RDX, align 8, !tbaa !2428
  %1899 = add i64 %1872, -28
  %1900 = add i64 %1874, 31
  store i64 %1900, i64* %PC, align 8
  %1901 = inttoptr i64 %1899 to i32*
  %1902 = load i32, i32* %1901, align 4
  %1903 = add i32 %1902, 2
  %1904 = zext i32 %1903 to i64
  store i64 %1904, i64* %RCX, align 8, !tbaa !2428
  %1905 = icmp ugt i32 %1902, -3
  %1906 = zext i1 %1905 to i8
  store i8 %1906, i8* %16, align 1, !tbaa !2433
  %1907 = and i32 %1903, 255
  %1908 = tail call i32 @llvm.ctpop.i32(i32 %1907) #10
  %1909 = trunc i32 %1908 to i8
  %1910 = and i8 %1909, 1
  %1911 = xor i8 %1910, 1
  store i8 %1911, i8* %23, align 1, !tbaa !2447
  %1912 = xor i32 %1903, %1902
  %1913 = lshr i32 %1912, 4
  %1914 = trunc i32 %1913 to i8
  %1915 = and i8 %1914, 1
  store i8 %1915, i8* %29, align 1, !tbaa !2451
  %1916 = icmp eq i32 %1903, 0
  %1917 = zext i1 %1916 to i8
  store i8 %1917, i8* %32, align 1, !tbaa !2448
  %1918 = lshr i32 %1903, 31
  %1919 = trunc i32 %1918 to i8
  store i8 %1919, i8* %35, align 1, !tbaa !2449
  %1920 = lshr i32 %1902, 31
  %1921 = xor i32 %1918, %1920
  %1922 = add nuw nsw i32 %1921, %1918
  %1923 = icmp eq i32 %1922, 2
  %1924 = zext i1 %1923 to i8
  store i8 %1924, i8* %41, align 1, !tbaa !2450
  %1925 = sext i32 %1903 to i64
  store i64 %1925, i64* %RSI, align 8, !tbaa !2428
  %1926 = shl nsw i64 %1925, 3
  %1927 = add i64 %1898, %1926
  %1928 = add i64 %1874, 42
  store i64 %1928, i64* %PC, align 8
  %1929 = inttoptr i64 %1927 to double*
  store double %1894, double* %1929, align 8
  %1930 = load i64, i64* %RBP, align 8
  %1931 = add i64 %1930, -48
  %1932 = load i64, i64* %PC, align 8
  %1933 = add i64 %1932, 5
  store i64 %1933, i64* %PC, align 8
  %1934 = inttoptr i64 %1931 to i64*
  %1935 = load i64, i64* %1934, align 8
  store i64 %1935, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1936 = add i64 %1930, -104
  %1937 = add i64 %1932, 10
  store i64 %1937, i64* %PC, align 8
  %1938 = bitcast i64 %1935 to double
  %1939 = inttoptr i64 %1936 to double*
  %1940 = load double, double* %1939, align 8
  %1941 = fmul double %1938, %1940
  store double %1941, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1942 = add i64 %1930, -56
  %1943 = add i64 %1932, 15
  store i64 %1943, i64* %PC, align 8
  %1944 = inttoptr i64 %1942 to i64*
  %1945 = load i64, i64* %1944, align 8
  store i64 %1945, i64* %828, align 1, !tbaa !2452
  store double 0.000000e+00, double* %829, align 1, !tbaa !2452
  %1946 = add i64 %1930, -96
  %1947 = add i64 %1932, 20
  store i64 %1947, i64* %PC, align 8
  %1948 = bitcast i64 %1945 to double
  %1949 = inttoptr i64 %1946 to double*
  %1950 = load double, double* %1949, align 8
  %1951 = fmul double %1948, %1950
  store double %1951, double* %821, align 1, !tbaa !2452
  store i64 0, i64* %817, align 1, !tbaa !2452
  %1952 = fadd double %1941, %1951
  store double %1952, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %1953 = add i64 %1930, -16
  %1954 = add i64 %1932, 28
  store i64 %1954, i64* %PC, align 8
  %1955 = inttoptr i64 %1953 to i64*
  %1956 = load i64, i64* %1955, align 8
  store i64 %1956, i64* %RDX, align 8, !tbaa !2428
  %1957 = add i64 %1930, -28
  %1958 = add i64 %1932, 31
  store i64 %1958, i64* %PC, align 8
  %1959 = inttoptr i64 %1957 to i32*
  %1960 = load i32, i32* %1959, align 4
  %1961 = add i32 %1960, 3
  %1962 = zext i32 %1961 to i64
  store i64 %1962, i64* %RCX, align 8, !tbaa !2428
  %1963 = icmp ugt i32 %1960, -4
  %1964 = zext i1 %1963 to i8
  store i8 %1964, i8* %16, align 1, !tbaa !2433
  %1965 = and i32 %1961, 255
  %1966 = tail call i32 @llvm.ctpop.i32(i32 %1965) #10
  %1967 = trunc i32 %1966 to i8
  %1968 = and i8 %1967, 1
  %1969 = xor i8 %1968, 1
  store i8 %1969, i8* %23, align 1, !tbaa !2447
  %1970 = xor i32 %1961, %1960
  %1971 = lshr i32 %1970, 4
  %1972 = trunc i32 %1971 to i8
  %1973 = and i8 %1972, 1
  store i8 %1973, i8* %29, align 1, !tbaa !2451
  %1974 = icmp eq i32 %1961, 0
  %1975 = zext i1 %1974 to i8
  store i8 %1975, i8* %32, align 1, !tbaa !2448
  %1976 = lshr i32 %1961, 31
  %1977 = trunc i32 %1976 to i8
  store i8 %1977, i8* %35, align 1, !tbaa !2449
  %1978 = lshr i32 %1960, 31
  %1979 = xor i32 %1976, %1978
  %1980 = add nuw nsw i32 %1979, %1976
  %1981 = icmp eq i32 %1980, 2
  %1982 = zext i1 %1981 to i8
  store i8 %1982, i8* %41, align 1, !tbaa !2450
  %1983 = sext i32 %1961 to i64
  store i64 %1983, i64* %RSI, align 8, !tbaa !2428
  %1984 = shl nsw i64 %1983, 3
  %1985 = add i64 %1956, %1984
  %1986 = add i64 %1932, 42
  store i64 %1986, i64* %PC, align 8
  %1987 = inttoptr i64 %1985 to double*
  store double %1952, double* %1987, align 8
  %1988 = load i64, i64* %RBP, align 8
  %1989 = add i64 %1988, -112
  %1990 = load i64, i64* %PC, align 8
  %1991 = add i64 %1990, 5
  store i64 %1991, i64* %PC, align 8
  %1992 = inttoptr i64 %1989 to i64*
  %1993 = load i64, i64* %1992, align 8
  store i64 %1993, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %1994 = add i64 %1988, -152
  %1995 = add i64 %1990, 13
  store i64 %1995, i64* %PC, align 8
  %1996 = bitcast i64 %1993 to double
  %1997 = inttoptr i64 %1994 to double*
  %1998 = load double, double* %1997, align 8
  %1999 = fadd double %1996, %1998
  store double %1999, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2000 = add i64 %1988, -96
  %2001 = add i64 %1990, 18
  store i64 %2001, i64* %PC, align 8
  %2002 = inttoptr i64 %2000 to double*
  store double %1999, double* %2002, align 8
  %2003 = load i64, i64* %RBP, align 8
  %2004 = add i64 %2003, -120
  %2005 = load i64, i64* %PC, align 8
  %2006 = add i64 %2005, 5
  store i64 %2006, i64* %PC, align 8
  %2007 = inttoptr i64 %2004 to i64*
  %2008 = load i64, i64* %2007, align 8
  store i64 %2008, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %2009 = add i64 %2003, -144
  %2010 = add i64 %2005, 13
  store i64 %2010, i64* %PC, align 8
  %2011 = bitcast i64 %2008 to double
  %2012 = inttoptr i64 %2009 to double*
  %2013 = load double, double* %2012, align 8
  %2014 = fsub double %2011, %2013
  store double %2014, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2015 = add i64 %2003, -104
  %2016 = add i64 %2005, 18
  store i64 %2016, i64* %PC, align 8
  %2017 = inttoptr i64 %2015 to double*
  store double %2014, double* %2017, align 8
  %2018 = load i64, i64* %RBP, align 8
  %2019 = add i64 %2018, -80
  %2020 = load i64, i64* %PC, align 8
  %2021 = add i64 %2020, 5
  store i64 %2021, i64* %PC, align 8
  %2022 = inttoptr i64 %2019 to i64*
  %2023 = load i64, i64* %2022, align 8
  store i64 %2023, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %2024 = add i64 %2018, -96
  %2025 = add i64 %2020, 10
  store i64 %2025, i64* %PC, align 8
  %2026 = bitcast i64 %2023 to double
  %2027 = inttoptr i64 %2024 to double*
  %2028 = load double, double* %2027, align 8
  %2029 = fmul double %2026, %2028
  store double %2029, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2030 = add i64 %2018, -88
  %2031 = add i64 %2020, 15
  store i64 %2031, i64* %PC, align 8
  %2032 = inttoptr i64 %2030 to i64*
  %2033 = load i64, i64* %2032, align 8
  store i64 %2033, i64* %828, align 1, !tbaa !2452
  store double 0.000000e+00, double* %829, align 1, !tbaa !2452
  %2034 = add i64 %2018, -104
  %2035 = add i64 %2020, 20
  store i64 %2035, i64* %PC, align 8
  %2036 = bitcast i64 %2033 to double
  %2037 = inttoptr i64 %2034 to double*
  %2038 = load double, double* %2037, align 8
  %2039 = fmul double %2036, %2038
  store double %2039, double* %821, align 1, !tbaa !2452
  store i64 0, i64* %817, align 1, !tbaa !2452
  %2040 = fsub double %2029, %2039
  store double %2040, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2041 = add i64 %2018, -16
  %2042 = add i64 %2020, 28
  store i64 %2042, i64* %PC, align 8
  %2043 = inttoptr i64 %2041 to i64*
  %2044 = load i64, i64* %2043, align 8
  store i64 %2044, i64* %RDX, align 8, !tbaa !2428
  %2045 = add i64 %2018, -28
  %2046 = add i64 %2020, 31
  store i64 %2046, i64* %PC, align 8
  %2047 = inttoptr i64 %2045 to i32*
  %2048 = load i32, i32* %2047, align 4
  %2049 = add i32 %2048, 6
  %2050 = zext i32 %2049 to i64
  store i64 %2050, i64* %RCX, align 8, !tbaa !2428
  %2051 = icmp ugt i32 %2048, -7
  %2052 = zext i1 %2051 to i8
  store i8 %2052, i8* %16, align 1, !tbaa !2433
  %2053 = and i32 %2049, 255
  %2054 = tail call i32 @llvm.ctpop.i32(i32 %2053) #10
  %2055 = trunc i32 %2054 to i8
  %2056 = and i8 %2055, 1
  %2057 = xor i8 %2056, 1
  store i8 %2057, i8* %23, align 1, !tbaa !2447
  %2058 = xor i32 %2049, %2048
  %2059 = lshr i32 %2058, 4
  %2060 = trunc i32 %2059 to i8
  %2061 = and i8 %2060, 1
  store i8 %2061, i8* %29, align 1, !tbaa !2451
  %2062 = icmp eq i32 %2049, 0
  %2063 = zext i1 %2062 to i8
  store i8 %2063, i8* %32, align 1, !tbaa !2448
  %2064 = lshr i32 %2049, 31
  %2065 = trunc i32 %2064 to i8
  store i8 %2065, i8* %35, align 1, !tbaa !2449
  %2066 = lshr i32 %2048, 31
  %2067 = xor i32 %2064, %2066
  %2068 = add nuw nsw i32 %2067, %2064
  %2069 = icmp eq i32 %2068, 2
  %2070 = zext i1 %2069 to i8
  store i8 %2070, i8* %41, align 1, !tbaa !2450
  %2071 = sext i32 %2049 to i64
  store i64 %2071, i64* %RSI, align 8, !tbaa !2428
  %2072 = shl nsw i64 %2071, 3
  %2073 = add i64 %2044, %2072
  %2074 = add i64 %2020, 42
  store i64 %2074, i64* %PC, align 8
  %2075 = inttoptr i64 %2073 to double*
  store double %2040, double* %2075, align 8
  %2076 = load i64, i64* %RBP, align 8
  %2077 = add i64 %2076, -80
  %2078 = load i64, i64* %PC, align 8
  %2079 = add i64 %2078, 5
  store i64 %2079, i64* %PC, align 8
  %2080 = inttoptr i64 %2077 to i64*
  %2081 = load i64, i64* %2080, align 8
  store i64 %2081, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %2082 = add i64 %2076, -104
  %2083 = add i64 %2078, 10
  store i64 %2083, i64* %PC, align 8
  %2084 = bitcast i64 %2081 to double
  %2085 = inttoptr i64 %2082 to double*
  %2086 = load double, double* %2085, align 8
  %2087 = fmul double %2084, %2086
  store double %2087, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2088 = add i64 %2076, -88
  %2089 = add i64 %2078, 15
  store i64 %2089, i64* %PC, align 8
  %2090 = inttoptr i64 %2088 to i64*
  %2091 = load i64, i64* %2090, align 8
  store i64 %2091, i64* %828, align 1, !tbaa !2452
  store double 0.000000e+00, double* %829, align 1, !tbaa !2452
  %2092 = add i64 %2076, -96
  %2093 = add i64 %2078, 20
  store i64 %2093, i64* %PC, align 8
  %2094 = bitcast i64 %2091 to double
  %2095 = inttoptr i64 %2092 to double*
  %2096 = load double, double* %2095, align 8
  %2097 = fmul double %2094, %2096
  store double %2097, double* %821, align 1, !tbaa !2452
  store i64 0, i64* %817, align 1, !tbaa !2452
  %2098 = fadd double %2087, %2097
  store double %2098, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2099 = add i64 %2076, -16
  %2100 = add i64 %2078, 28
  store i64 %2100, i64* %PC, align 8
  %2101 = inttoptr i64 %2099 to i64*
  %2102 = load i64, i64* %2101, align 8
  store i64 %2102, i64* %RDX, align 8, !tbaa !2428
  %2103 = add i64 %2076, -28
  %2104 = add i64 %2078, 31
  store i64 %2104, i64* %PC, align 8
  %2105 = inttoptr i64 %2103 to i32*
  %2106 = load i32, i32* %2105, align 4
  %2107 = add i32 %2106, 7
  %2108 = zext i32 %2107 to i64
  store i64 %2108, i64* %RCX, align 8, !tbaa !2428
  %2109 = icmp ugt i32 %2106, -8
  %2110 = zext i1 %2109 to i8
  store i8 %2110, i8* %16, align 1, !tbaa !2433
  %2111 = and i32 %2107, 255
  %2112 = tail call i32 @llvm.ctpop.i32(i32 %2111) #10
  %2113 = trunc i32 %2112 to i8
  %2114 = and i8 %2113, 1
  %2115 = xor i8 %2114, 1
  store i8 %2115, i8* %23, align 1, !tbaa !2447
  %2116 = xor i32 %2107, %2106
  %2117 = lshr i32 %2116, 4
  %2118 = trunc i32 %2117 to i8
  %2119 = and i8 %2118, 1
  store i8 %2119, i8* %29, align 1, !tbaa !2451
  %2120 = icmp eq i32 %2107, 0
  %2121 = zext i1 %2120 to i8
  store i8 %2121, i8* %32, align 1, !tbaa !2448
  %2122 = lshr i32 %2107, 31
  %2123 = trunc i32 %2122 to i8
  store i8 %2123, i8* %35, align 1, !tbaa !2449
  %2124 = lshr i32 %2106, 31
  %2125 = xor i32 %2122, %2124
  %2126 = add nuw nsw i32 %2125, %2122
  %2127 = icmp eq i32 %2126, 2
  %2128 = zext i1 %2127 to i8
  store i8 %2128, i8* %41, align 1, !tbaa !2450
  %2129 = sext i32 %2107 to i64
  store i64 %2129, i64* %RSI, align 8, !tbaa !2428
  %2130 = shl nsw i64 %2129, 3
  %2131 = add i64 %2102, %2130
  %2132 = add i64 %2078, 42
  store i64 %2132, i64* %PC, align 8
  %2133 = inttoptr i64 %2131 to double*
  store double %2098, double* %2133, align 8
  %2134 = load i64, i64* %RBP, align 8
  %2135 = add i64 %2134, -24
  %2136 = load i64, i64* %PC, align 8
  %2137 = add i64 %2136, 4
  store i64 %2137, i64* %PC, align 8
  %2138 = inttoptr i64 %2135 to i64*
  %2139 = load i64, i64* %2138, align 8
  store i64 %2139, i64* %RDX, align 8, !tbaa !2428
  %2140 = add i64 %2134, -36
  %2141 = add i64 %2136, 7
  store i64 %2141, i64* %PC, align 8
  %2142 = inttoptr i64 %2140 to i32*
  %2143 = load i32, i32* %2142, align 4
  %2144 = add i32 %2143, 2
  %2145 = zext i32 %2144 to i64
  store i64 %2145, i64* %RCX, align 8, !tbaa !2428
  %2146 = icmp ugt i32 %2143, -3
  %2147 = zext i1 %2146 to i8
  store i8 %2147, i8* %16, align 1, !tbaa !2433
  %2148 = and i32 %2144, 255
  %2149 = tail call i32 @llvm.ctpop.i32(i32 %2148) #10
  %2150 = trunc i32 %2149 to i8
  %2151 = and i8 %2150, 1
  %2152 = xor i8 %2151, 1
  store i8 %2152, i8* %23, align 1, !tbaa !2447
  %2153 = xor i32 %2144, %2143
  %2154 = lshr i32 %2153, 4
  %2155 = trunc i32 %2154 to i8
  %2156 = and i8 %2155, 1
  store i8 %2156, i8* %29, align 1, !tbaa !2451
  %2157 = icmp eq i32 %2144, 0
  %2158 = zext i1 %2157 to i8
  store i8 %2158, i8* %32, align 1, !tbaa !2448
  %2159 = lshr i32 %2144, 31
  %2160 = trunc i32 %2159 to i8
  store i8 %2160, i8* %35, align 1, !tbaa !2449
  %2161 = lshr i32 %2143, 31
  %2162 = xor i32 %2159, %2161
  %2163 = add nuw nsw i32 %2162, %2159
  %2164 = icmp eq i32 %2163, 2
  %2165 = zext i1 %2164 to i8
  store i8 %2165, i8* %41, align 1, !tbaa !2450
  %2166 = sext i32 %2144 to i64
  store i64 %2166, i64* %RSI, align 8, !tbaa !2428
  %2167 = shl nsw i64 %2166, 3
  %2168 = add i64 %2139, %2167
  %2169 = add i64 %2136, 18
  store i64 %2169, i64* %PC, align 8
  %2170 = inttoptr i64 %2168 to i64*
  %2171 = load i64, i64* %2170, align 8
  store i64 %2171, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %2172 = add i64 %2134, -48
  %2173 = add i64 %2136, 23
  store i64 %2173, i64* %PC, align 8
  %2174 = inttoptr i64 %2172 to i64*
  store i64 %2171, i64* %2174, align 8
  %2175 = load i64, i64* %RBP, align 8
  %2176 = add i64 %2175, -24
  %2177 = load i64, i64* %PC, align 8
  %2178 = add i64 %2177, 4
  store i64 %2178, i64* %PC, align 8
  %2179 = inttoptr i64 %2176 to i64*
  %2180 = load i64, i64* %2179, align 8
  store i64 %2180, i64* %RDX, align 8, !tbaa !2428
  %2181 = add i64 %2175, -36
  %2182 = add i64 %2177, 7
  store i64 %2182, i64* %PC, align 8
  %2183 = inttoptr i64 %2181 to i32*
  %2184 = load i32, i32* %2183, align 4
  %2185 = add i32 %2184, 3
  %2186 = zext i32 %2185 to i64
  store i64 %2186, i64* %RCX, align 8, !tbaa !2428
  %2187 = icmp ugt i32 %2184, -4
  %2188 = zext i1 %2187 to i8
  store i8 %2188, i8* %16, align 1, !tbaa !2433
  %2189 = and i32 %2185, 255
  %2190 = tail call i32 @llvm.ctpop.i32(i32 %2189) #10
  %2191 = trunc i32 %2190 to i8
  %2192 = and i8 %2191, 1
  %2193 = xor i8 %2192, 1
  store i8 %2193, i8* %23, align 1, !tbaa !2447
  %2194 = xor i32 %2185, %2184
  %2195 = lshr i32 %2194, 4
  %2196 = trunc i32 %2195 to i8
  %2197 = and i8 %2196, 1
  store i8 %2197, i8* %29, align 1, !tbaa !2451
  %2198 = icmp eq i32 %2185, 0
  %2199 = zext i1 %2198 to i8
  store i8 %2199, i8* %32, align 1, !tbaa !2448
  %2200 = lshr i32 %2185, 31
  %2201 = trunc i32 %2200 to i8
  store i8 %2201, i8* %35, align 1, !tbaa !2449
  %2202 = lshr i32 %2184, 31
  %2203 = xor i32 %2200, %2202
  %2204 = add nuw nsw i32 %2203, %2200
  %2205 = icmp eq i32 %2204, 2
  %2206 = zext i1 %2205 to i8
  store i8 %2206, i8* %41, align 1, !tbaa !2450
  %2207 = sext i32 %2185 to i64
  store i64 %2207, i64* %RSI, align 8, !tbaa !2428
  %2208 = shl nsw i64 %2207, 3
  %2209 = add i64 %2180, %2208
  %2210 = add i64 %2177, 18
  store i64 %2210, i64* %PC, align 8
  %2211 = inttoptr i64 %2209 to i64*
  %2212 = load i64, i64* %2211, align 8
  store i64 %2212, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %2213 = add i64 %2175, -56
  %2214 = add i64 %2177, 23
  store i64 %2214, i64* %PC, align 8
  %2215 = inttoptr i64 %2213 to i64*
  store i64 %2212, i64* %2215, align 8
  %2216 = load i64, i64* %RBP, align 8
  %2217 = add i64 %2216, -48
  %2218 = load i64, i64* %PC, align 8
  %2219 = add i64 %2218, 5
  store i64 %2219, i64* %PC, align 8
  %2220 = inttoptr i64 %2217 to i64*
  %2221 = load i64, i64* %2220, align 8
  store i64 %2221, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %2222 = load <2 x i32>, <2 x i32>* %812, align 1
  %2223 = load <2 x i32>, <2 x i32>* %813, align 1
  %2224 = extractelement <2 x i32> %2222, i32 0
  store i32 %2224, i32* %814, align 1, !tbaa !2454
  %2225 = extractelement <2 x i32> %2222, i32 1
  store i32 %2225, i32* %816, align 1, !tbaa !2454
  %2226 = extractelement <2 x i32> %2223, i32 0
  store i32 %2226, i32* %818, align 1, !tbaa !2454
  %2227 = extractelement <2 x i32> %2223, i32 1
  store i32 %2227, i32* %820, align 1, !tbaa !2454
  %2228 = add i64 %2216, -64
  %2229 = add i64 %2218, 13
  store i64 %2229, i64* %PC, align 8
  %2230 = load double, double* %821, align 1
  %2231 = inttoptr i64 %2228 to double*
  %2232 = load double, double* %2231, align 8
  %2233 = fmul double %2230, %2232
  store double %2233, double* %821, align 1, !tbaa !2452
  %2234 = add i64 %2216, -56
  %2235 = add i64 %2218, 18
  store i64 %2235, i64* %PC, align 8
  %2236 = inttoptr i64 %2234 to double*
  %2237 = load double, double* %2236, align 8
  %2238 = fmul double %2233, %2237
  store double %2238, double* %821, align 1, !tbaa !2452
  %2239 = bitcast i64 %2221 to double
  %2240 = fsub double %2239, %2238
  store double %2240, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2241 = add i64 %2216, -80
  %2242 = add i64 %2218, 27
  store i64 %2242, i64* %PC, align 8
  %2243 = inttoptr i64 %2241 to double*
  store double %2240, double* %2243, align 8
  %2244 = load i64, i64* %RBP, align 8
  %2245 = add i64 %2244, -64
  %2246 = load i64, i64* %PC, align 8
  %2247 = add i64 %2246, 5
  store i64 %2247, i64* %PC, align 8
  %2248 = load double, double* %67, align 1
  %2249 = inttoptr i64 %2245 to double*
  %2250 = load double, double* %2249, align 8
  %2251 = fmul double %2248, %2250
  store double %2251, double* %67, align 1, !tbaa !2452
  %2252 = add i64 %2244, -48
  %2253 = add i64 %2246, 10
  store i64 %2253, i64* %PC, align 8
  %2254 = inttoptr i64 %2252 to double*
  %2255 = load double, double* %2254, align 8
  %2256 = fmul double %2251, %2255
  store double %2256, double* %67, align 1, !tbaa !2452
  %2257 = add i64 %2244, -56
  %2258 = add i64 %2246, 15
  store i64 %2258, i64* %PC, align 8
  %2259 = inttoptr i64 %2257 to double*
  %2260 = load double, double* %2259, align 8
  %2261 = fsub double %2256, %2260
  store double %2261, double* %67, align 1, !tbaa !2452
  %2262 = add i64 %2244, -88
  %2263 = add i64 %2246, 20
  store i64 %2263, i64* %PC, align 8
  %2264 = inttoptr i64 %2262 to double*
  store double %2261, double* %2264, align 8
  %2265 = load i64, i64* %RBP, align 8
  %2266 = add i64 %2265, -16
  %2267 = load i64, i64* %PC, align 8
  %2268 = add i64 %2267, 4
  store i64 %2268, i64* %PC, align 8
  %2269 = inttoptr i64 %2266 to i64*
  %2270 = load i64, i64* %2269, align 8
  store i64 %2270, i64* %RDX, align 8, !tbaa !2428
  %2271 = add i64 %2265, -28
  %2272 = add i64 %2267, 7
  store i64 %2272, i64* %PC, align 8
  %2273 = inttoptr i64 %2271 to i32*
  %2274 = load i32, i32* %2273, align 4
  %2275 = add i32 %2274, 8
  %2276 = zext i32 %2275 to i64
  store i64 %2276, i64* %RCX, align 8, !tbaa !2428
  %2277 = icmp ugt i32 %2274, -9
  %2278 = zext i1 %2277 to i8
  store i8 %2278, i8* %16, align 1, !tbaa !2433
  %2279 = and i32 %2275, 255
  %2280 = tail call i32 @llvm.ctpop.i32(i32 %2279) #10
  %2281 = trunc i32 %2280 to i8
  %2282 = and i8 %2281, 1
  %2283 = xor i8 %2282, 1
  store i8 %2283, i8* %23, align 1, !tbaa !2447
  %2284 = xor i32 %2275, %2274
  %2285 = lshr i32 %2284, 4
  %2286 = trunc i32 %2285 to i8
  %2287 = and i8 %2286, 1
  store i8 %2287, i8* %29, align 1, !tbaa !2451
  %2288 = icmp eq i32 %2275, 0
  %2289 = zext i1 %2288 to i8
  store i8 %2289, i8* %32, align 1, !tbaa !2448
  %2290 = lshr i32 %2275, 31
  %2291 = trunc i32 %2290 to i8
  store i8 %2291, i8* %35, align 1, !tbaa !2449
  %2292 = lshr i32 %2274, 31
  %2293 = xor i32 %2290, %2292
  %2294 = add nuw nsw i32 %2293, %2290
  %2295 = icmp eq i32 %2294, 2
  %2296 = zext i1 %2295 to i8
  store i8 %2296, i8* %41, align 1, !tbaa !2450
  %2297 = sext i32 %2275 to i64
  store i64 %2297, i64* %RSI, align 8, !tbaa !2428
  %2298 = shl nsw i64 %2297, 3
  %2299 = add i64 %2270, %2298
  %2300 = add i64 %2267, 18
  store i64 %2300, i64* %PC, align 8
  %2301 = inttoptr i64 %2299 to i64*
  %2302 = load i64, i64* %2301, align 8
  store i64 %2302, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2303 = add i64 %2267, 22
  store i64 %2303, i64* %PC, align 8
  %2304 = load i64, i64* %2269, align 8
  store i64 %2304, i64* %RDX, align 8, !tbaa !2428
  %2305 = add i64 %2267, 25
  store i64 %2305, i64* %PC, align 8
  %2306 = load i32, i32* %2273, align 4
  %2307 = add i32 %2306, 10
  %2308 = zext i32 %2307 to i64
  store i64 %2308, i64* %RCX, align 8, !tbaa !2428
  %2309 = icmp ugt i32 %2306, -11
  %2310 = zext i1 %2309 to i8
  store i8 %2310, i8* %16, align 1, !tbaa !2433
  %2311 = and i32 %2307, 255
  %2312 = tail call i32 @llvm.ctpop.i32(i32 %2311) #10
  %2313 = trunc i32 %2312 to i8
  %2314 = and i8 %2313, 1
  %2315 = xor i8 %2314, 1
  store i8 %2315, i8* %23, align 1, !tbaa !2447
  %2316 = xor i32 %2307, %2306
  %2317 = lshr i32 %2316, 4
  %2318 = trunc i32 %2317 to i8
  %2319 = and i8 %2318, 1
  store i8 %2319, i8* %29, align 1, !tbaa !2451
  %2320 = icmp eq i32 %2307, 0
  %2321 = zext i1 %2320 to i8
  store i8 %2321, i8* %32, align 1, !tbaa !2448
  %2322 = lshr i32 %2307, 31
  %2323 = trunc i32 %2322 to i8
  store i8 %2323, i8* %35, align 1, !tbaa !2449
  %2324 = lshr i32 %2306, 31
  %2325 = xor i32 %2322, %2324
  %2326 = add nuw nsw i32 %2325, %2322
  %2327 = icmp eq i32 %2326, 2
  %2328 = zext i1 %2327 to i8
  store i8 %2328, i8* %41, align 1, !tbaa !2450
  %2329 = sext i32 %2307 to i64
  store i64 %2329, i64* %RSI, align 8, !tbaa !2428
  %2330 = shl nsw i64 %2329, 3
  %2331 = add i64 %2304, %2330
  %2332 = add i64 %2267, 36
  store i64 %2332, i64* %PC, align 8
  %2333 = bitcast i64 %2302 to double
  %2334 = inttoptr i64 %2331 to double*
  %2335 = load double, double* %2334, align 8
  %2336 = fadd double %2333, %2335
  store double %2336, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2337 = load i64, i64* %RBP, align 8
  %2338 = add i64 %2337, -96
  %2339 = add i64 %2267, 41
  store i64 %2339, i64* %PC, align 8
  %2340 = inttoptr i64 %2338 to double*
  store double %2336, double* %2340, align 8
  %2341 = load i64, i64* %RBP, align 8
  %2342 = add i64 %2341, -16
  %2343 = load i64, i64* %PC, align 8
  %2344 = add i64 %2343, 4
  store i64 %2344, i64* %PC, align 8
  %2345 = inttoptr i64 %2342 to i64*
  %2346 = load i64, i64* %2345, align 8
  store i64 %2346, i64* %RDX, align 8, !tbaa !2428
  %2347 = add i64 %2341, -28
  %2348 = add i64 %2343, 7
  store i64 %2348, i64* %PC, align 8
  %2349 = inttoptr i64 %2347 to i32*
  %2350 = load i32, i32* %2349, align 4
  %2351 = add i32 %2350, 9
  %2352 = zext i32 %2351 to i64
  store i64 %2352, i64* %RCX, align 8, !tbaa !2428
  %2353 = icmp ugt i32 %2350, -10
  %2354 = zext i1 %2353 to i8
  store i8 %2354, i8* %16, align 1, !tbaa !2433
  %2355 = and i32 %2351, 255
  %2356 = tail call i32 @llvm.ctpop.i32(i32 %2355) #10
  %2357 = trunc i32 %2356 to i8
  %2358 = and i8 %2357, 1
  %2359 = xor i8 %2358, 1
  store i8 %2359, i8* %23, align 1, !tbaa !2447
  %2360 = xor i32 %2351, %2350
  %2361 = lshr i32 %2360, 4
  %2362 = trunc i32 %2361 to i8
  %2363 = and i8 %2362, 1
  store i8 %2363, i8* %29, align 1, !tbaa !2451
  %2364 = icmp eq i32 %2351, 0
  %2365 = zext i1 %2364 to i8
  store i8 %2365, i8* %32, align 1, !tbaa !2448
  %2366 = lshr i32 %2351, 31
  %2367 = trunc i32 %2366 to i8
  store i8 %2367, i8* %35, align 1, !tbaa !2449
  %2368 = lshr i32 %2350, 31
  %2369 = xor i32 %2366, %2368
  %2370 = add nuw nsw i32 %2369, %2366
  %2371 = icmp eq i32 %2370, 2
  %2372 = zext i1 %2371 to i8
  store i8 %2372, i8* %41, align 1, !tbaa !2450
  %2373 = sext i32 %2351 to i64
  store i64 %2373, i64* %RSI, align 8, !tbaa !2428
  %2374 = shl nsw i64 %2373, 3
  %2375 = add i64 %2346, %2374
  %2376 = add i64 %2343, 18
  store i64 %2376, i64* %PC, align 8
  %2377 = inttoptr i64 %2375 to i64*
  %2378 = load i64, i64* %2377, align 8
  store i64 %2378, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2379 = add i64 %2343, 22
  store i64 %2379, i64* %PC, align 8
  %2380 = load i64, i64* %2345, align 8
  store i64 %2380, i64* %RDX, align 8, !tbaa !2428
  %2381 = add i64 %2343, 25
  store i64 %2381, i64* %PC, align 8
  %2382 = load i32, i32* %2349, align 4
  %2383 = add i32 %2382, 11
  %2384 = zext i32 %2383 to i64
  store i64 %2384, i64* %RCX, align 8, !tbaa !2428
  %2385 = icmp ugt i32 %2382, -12
  %2386 = zext i1 %2385 to i8
  store i8 %2386, i8* %16, align 1, !tbaa !2433
  %2387 = and i32 %2383, 255
  %2388 = tail call i32 @llvm.ctpop.i32(i32 %2387) #10
  %2389 = trunc i32 %2388 to i8
  %2390 = and i8 %2389, 1
  %2391 = xor i8 %2390, 1
  store i8 %2391, i8* %23, align 1, !tbaa !2447
  %2392 = xor i32 %2383, %2382
  %2393 = lshr i32 %2392, 4
  %2394 = trunc i32 %2393 to i8
  %2395 = and i8 %2394, 1
  store i8 %2395, i8* %29, align 1, !tbaa !2451
  %2396 = icmp eq i32 %2383, 0
  %2397 = zext i1 %2396 to i8
  store i8 %2397, i8* %32, align 1, !tbaa !2448
  %2398 = lshr i32 %2383, 31
  %2399 = trunc i32 %2398 to i8
  store i8 %2399, i8* %35, align 1, !tbaa !2449
  %2400 = lshr i32 %2382, 31
  %2401 = xor i32 %2398, %2400
  %2402 = add nuw nsw i32 %2401, %2398
  %2403 = icmp eq i32 %2402, 2
  %2404 = zext i1 %2403 to i8
  store i8 %2404, i8* %41, align 1, !tbaa !2450
  %2405 = sext i32 %2383 to i64
  store i64 %2405, i64* %RSI, align 8, !tbaa !2428
  %2406 = shl nsw i64 %2405, 3
  %2407 = add i64 %2380, %2406
  %2408 = add i64 %2343, 36
  store i64 %2408, i64* %PC, align 8
  %2409 = bitcast i64 %2378 to double
  %2410 = inttoptr i64 %2407 to double*
  %2411 = load double, double* %2410, align 8
  %2412 = fadd double %2409, %2411
  store double %2412, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2413 = load i64, i64* %RBP, align 8
  %2414 = add i64 %2413, -104
  %2415 = add i64 %2343, 41
  store i64 %2415, i64* %PC, align 8
  %2416 = inttoptr i64 %2414 to double*
  store double %2412, double* %2416, align 8
  %2417 = load i64, i64* %RBP, align 8
  %2418 = add i64 %2417, -16
  %2419 = load i64, i64* %PC, align 8
  %2420 = add i64 %2419, 4
  store i64 %2420, i64* %PC, align 8
  %2421 = inttoptr i64 %2418 to i64*
  %2422 = load i64, i64* %2421, align 8
  store i64 %2422, i64* %RDX, align 8, !tbaa !2428
  %2423 = add i64 %2417, -28
  %2424 = add i64 %2419, 7
  store i64 %2424, i64* %PC, align 8
  %2425 = inttoptr i64 %2423 to i32*
  %2426 = load i32, i32* %2425, align 4
  %2427 = add i32 %2426, 8
  %2428 = zext i32 %2427 to i64
  store i64 %2428, i64* %RCX, align 8, !tbaa !2428
  %2429 = icmp ugt i32 %2426, -9
  %2430 = zext i1 %2429 to i8
  store i8 %2430, i8* %16, align 1, !tbaa !2433
  %2431 = and i32 %2427, 255
  %2432 = tail call i32 @llvm.ctpop.i32(i32 %2431) #10
  %2433 = trunc i32 %2432 to i8
  %2434 = and i8 %2433, 1
  %2435 = xor i8 %2434, 1
  store i8 %2435, i8* %23, align 1, !tbaa !2447
  %2436 = xor i32 %2427, %2426
  %2437 = lshr i32 %2436, 4
  %2438 = trunc i32 %2437 to i8
  %2439 = and i8 %2438, 1
  store i8 %2439, i8* %29, align 1, !tbaa !2451
  %2440 = icmp eq i32 %2427, 0
  %2441 = zext i1 %2440 to i8
  store i8 %2441, i8* %32, align 1, !tbaa !2448
  %2442 = lshr i32 %2427, 31
  %2443 = trunc i32 %2442 to i8
  store i8 %2443, i8* %35, align 1, !tbaa !2449
  %2444 = lshr i32 %2426, 31
  %2445 = xor i32 %2442, %2444
  %2446 = add nuw nsw i32 %2445, %2442
  %2447 = icmp eq i32 %2446, 2
  %2448 = zext i1 %2447 to i8
  store i8 %2448, i8* %41, align 1, !tbaa !2450
  %2449 = sext i32 %2427 to i64
  store i64 %2449, i64* %RSI, align 8, !tbaa !2428
  %2450 = shl nsw i64 %2449, 3
  %2451 = add i64 %2422, %2450
  %2452 = add i64 %2419, 18
  store i64 %2452, i64* %PC, align 8
  %2453 = inttoptr i64 %2451 to i64*
  %2454 = load i64, i64* %2453, align 8
  store i64 %2454, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2455 = add i64 %2419, 22
  store i64 %2455, i64* %PC, align 8
  %2456 = load i64, i64* %2421, align 8
  store i64 %2456, i64* %RDX, align 8, !tbaa !2428
  %2457 = add i64 %2419, 25
  store i64 %2457, i64* %PC, align 8
  %2458 = load i32, i32* %2425, align 4
  %2459 = add i32 %2458, 10
  %2460 = zext i32 %2459 to i64
  store i64 %2460, i64* %RCX, align 8, !tbaa !2428
  %2461 = icmp ugt i32 %2458, -11
  %2462 = zext i1 %2461 to i8
  store i8 %2462, i8* %16, align 1, !tbaa !2433
  %2463 = and i32 %2459, 255
  %2464 = tail call i32 @llvm.ctpop.i32(i32 %2463) #10
  %2465 = trunc i32 %2464 to i8
  %2466 = and i8 %2465, 1
  %2467 = xor i8 %2466, 1
  store i8 %2467, i8* %23, align 1, !tbaa !2447
  %2468 = xor i32 %2459, %2458
  %2469 = lshr i32 %2468, 4
  %2470 = trunc i32 %2469 to i8
  %2471 = and i8 %2470, 1
  store i8 %2471, i8* %29, align 1, !tbaa !2451
  %2472 = icmp eq i32 %2459, 0
  %2473 = zext i1 %2472 to i8
  store i8 %2473, i8* %32, align 1, !tbaa !2448
  %2474 = lshr i32 %2459, 31
  %2475 = trunc i32 %2474 to i8
  store i8 %2475, i8* %35, align 1, !tbaa !2449
  %2476 = lshr i32 %2458, 31
  %2477 = xor i32 %2474, %2476
  %2478 = add nuw nsw i32 %2477, %2474
  %2479 = icmp eq i32 %2478, 2
  %2480 = zext i1 %2479 to i8
  store i8 %2480, i8* %41, align 1, !tbaa !2450
  %2481 = sext i32 %2459 to i64
  store i64 %2481, i64* %RSI, align 8, !tbaa !2428
  %2482 = shl nsw i64 %2481, 3
  %2483 = add i64 %2456, %2482
  %2484 = add i64 %2419, 36
  store i64 %2484, i64* %PC, align 8
  %2485 = bitcast i64 %2454 to double
  %2486 = inttoptr i64 %2483 to double*
  %2487 = load double, double* %2486, align 8
  %2488 = fsub double %2485, %2487
  store double %2488, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2489 = load i64, i64* %RBP, align 8
  %2490 = add i64 %2489, -112
  %2491 = add i64 %2419, 41
  store i64 %2491, i64* %PC, align 8
  %2492 = inttoptr i64 %2490 to double*
  store double %2488, double* %2492, align 8
  %2493 = load i64, i64* %RBP, align 8
  %2494 = add i64 %2493, -16
  %2495 = load i64, i64* %PC, align 8
  %2496 = add i64 %2495, 4
  store i64 %2496, i64* %PC, align 8
  %2497 = inttoptr i64 %2494 to i64*
  %2498 = load i64, i64* %2497, align 8
  store i64 %2498, i64* %RDX, align 8, !tbaa !2428
  %2499 = add i64 %2493, -28
  %2500 = add i64 %2495, 7
  store i64 %2500, i64* %PC, align 8
  %2501 = inttoptr i64 %2499 to i32*
  %2502 = load i32, i32* %2501, align 4
  %2503 = add i32 %2502, 9
  %2504 = zext i32 %2503 to i64
  store i64 %2504, i64* %RCX, align 8, !tbaa !2428
  %2505 = icmp ugt i32 %2502, -10
  %2506 = zext i1 %2505 to i8
  store i8 %2506, i8* %16, align 1, !tbaa !2433
  %2507 = and i32 %2503, 255
  %2508 = tail call i32 @llvm.ctpop.i32(i32 %2507) #10
  %2509 = trunc i32 %2508 to i8
  %2510 = and i8 %2509, 1
  %2511 = xor i8 %2510, 1
  store i8 %2511, i8* %23, align 1, !tbaa !2447
  %2512 = xor i32 %2503, %2502
  %2513 = lshr i32 %2512, 4
  %2514 = trunc i32 %2513 to i8
  %2515 = and i8 %2514, 1
  store i8 %2515, i8* %29, align 1, !tbaa !2451
  %2516 = icmp eq i32 %2503, 0
  %2517 = zext i1 %2516 to i8
  store i8 %2517, i8* %32, align 1, !tbaa !2448
  %2518 = lshr i32 %2503, 31
  %2519 = trunc i32 %2518 to i8
  store i8 %2519, i8* %35, align 1, !tbaa !2449
  %2520 = lshr i32 %2502, 31
  %2521 = xor i32 %2518, %2520
  %2522 = add nuw nsw i32 %2521, %2518
  %2523 = icmp eq i32 %2522, 2
  %2524 = zext i1 %2523 to i8
  store i8 %2524, i8* %41, align 1, !tbaa !2450
  %2525 = sext i32 %2503 to i64
  store i64 %2525, i64* %RSI, align 8, !tbaa !2428
  %2526 = shl nsw i64 %2525, 3
  %2527 = add i64 %2498, %2526
  %2528 = add i64 %2495, 18
  store i64 %2528, i64* %PC, align 8
  %2529 = inttoptr i64 %2527 to i64*
  %2530 = load i64, i64* %2529, align 8
  store i64 %2530, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2531 = add i64 %2495, 22
  store i64 %2531, i64* %PC, align 8
  %2532 = load i64, i64* %2497, align 8
  store i64 %2532, i64* %RDX, align 8, !tbaa !2428
  %2533 = add i64 %2495, 25
  store i64 %2533, i64* %PC, align 8
  %2534 = load i32, i32* %2501, align 4
  %2535 = add i32 %2534, 11
  %2536 = zext i32 %2535 to i64
  store i64 %2536, i64* %RCX, align 8, !tbaa !2428
  %2537 = icmp ugt i32 %2534, -12
  %2538 = zext i1 %2537 to i8
  store i8 %2538, i8* %16, align 1, !tbaa !2433
  %2539 = and i32 %2535, 255
  %2540 = tail call i32 @llvm.ctpop.i32(i32 %2539) #10
  %2541 = trunc i32 %2540 to i8
  %2542 = and i8 %2541, 1
  %2543 = xor i8 %2542, 1
  store i8 %2543, i8* %23, align 1, !tbaa !2447
  %2544 = xor i32 %2535, %2534
  %2545 = lshr i32 %2544, 4
  %2546 = trunc i32 %2545 to i8
  %2547 = and i8 %2546, 1
  store i8 %2547, i8* %29, align 1, !tbaa !2451
  %2548 = icmp eq i32 %2535, 0
  %2549 = zext i1 %2548 to i8
  store i8 %2549, i8* %32, align 1, !tbaa !2448
  %2550 = lshr i32 %2535, 31
  %2551 = trunc i32 %2550 to i8
  store i8 %2551, i8* %35, align 1, !tbaa !2449
  %2552 = lshr i32 %2534, 31
  %2553 = xor i32 %2550, %2552
  %2554 = add nuw nsw i32 %2553, %2550
  %2555 = icmp eq i32 %2554, 2
  %2556 = zext i1 %2555 to i8
  store i8 %2556, i8* %41, align 1, !tbaa !2450
  %2557 = sext i32 %2535 to i64
  store i64 %2557, i64* %RSI, align 8, !tbaa !2428
  %2558 = shl nsw i64 %2557, 3
  %2559 = add i64 %2532, %2558
  %2560 = add i64 %2495, 36
  store i64 %2560, i64* %PC, align 8
  %2561 = bitcast i64 %2530 to double
  %2562 = inttoptr i64 %2559 to double*
  %2563 = load double, double* %2562, align 8
  %2564 = fsub double %2561, %2563
  store double %2564, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2565 = load i64, i64* %RBP, align 8
  %2566 = add i64 %2565, -120
  %2567 = add i64 %2495, 41
  store i64 %2567, i64* %PC, align 8
  %2568 = inttoptr i64 %2566 to double*
  store double %2564, double* %2568, align 8
  %2569 = load i64, i64* %RBP, align 8
  %2570 = add i64 %2569, -16
  %2571 = load i64, i64* %PC, align 8
  %2572 = add i64 %2571, 4
  store i64 %2572, i64* %PC, align 8
  %2573 = inttoptr i64 %2570 to i64*
  %2574 = load i64, i64* %2573, align 8
  store i64 %2574, i64* %RDX, align 8, !tbaa !2428
  %2575 = add i64 %2569, -28
  %2576 = add i64 %2571, 7
  store i64 %2576, i64* %PC, align 8
  %2577 = inttoptr i64 %2575 to i32*
  %2578 = load i32, i32* %2577, align 4
  %2579 = add i32 %2578, 12
  %2580 = zext i32 %2579 to i64
  store i64 %2580, i64* %RCX, align 8, !tbaa !2428
  %2581 = icmp ugt i32 %2578, -13
  %2582 = zext i1 %2581 to i8
  store i8 %2582, i8* %16, align 1, !tbaa !2433
  %2583 = and i32 %2579, 255
  %2584 = tail call i32 @llvm.ctpop.i32(i32 %2583) #10
  %2585 = trunc i32 %2584 to i8
  %2586 = and i8 %2585, 1
  %2587 = xor i8 %2586, 1
  store i8 %2587, i8* %23, align 1, !tbaa !2447
  %2588 = xor i32 %2579, %2578
  %2589 = lshr i32 %2588, 4
  %2590 = trunc i32 %2589 to i8
  %2591 = and i8 %2590, 1
  store i8 %2591, i8* %29, align 1, !tbaa !2451
  %2592 = icmp eq i32 %2579, 0
  %2593 = zext i1 %2592 to i8
  store i8 %2593, i8* %32, align 1, !tbaa !2448
  %2594 = lshr i32 %2579, 31
  %2595 = trunc i32 %2594 to i8
  store i8 %2595, i8* %35, align 1, !tbaa !2449
  %2596 = lshr i32 %2578, 31
  %2597 = xor i32 %2594, %2596
  %2598 = add nuw nsw i32 %2597, %2594
  %2599 = icmp eq i32 %2598, 2
  %2600 = zext i1 %2599 to i8
  store i8 %2600, i8* %41, align 1, !tbaa !2450
  %2601 = sext i32 %2579 to i64
  store i64 %2601, i64* %RSI, align 8, !tbaa !2428
  %2602 = shl nsw i64 %2601, 3
  %2603 = add i64 %2574, %2602
  %2604 = add i64 %2571, 18
  store i64 %2604, i64* %PC, align 8
  %2605 = inttoptr i64 %2603 to i64*
  %2606 = load i64, i64* %2605, align 8
  store i64 %2606, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2607 = add i64 %2571, 22
  store i64 %2607, i64* %PC, align 8
  %2608 = load i64, i64* %2573, align 8
  store i64 %2608, i64* %RDX, align 8, !tbaa !2428
  %2609 = add i64 %2571, 25
  store i64 %2609, i64* %PC, align 8
  %2610 = load i32, i32* %2577, align 4
  %2611 = add i32 %2610, 14
  %2612 = zext i32 %2611 to i64
  store i64 %2612, i64* %RCX, align 8, !tbaa !2428
  %2613 = icmp ugt i32 %2610, -15
  %2614 = zext i1 %2613 to i8
  store i8 %2614, i8* %16, align 1, !tbaa !2433
  %2615 = and i32 %2611, 255
  %2616 = tail call i32 @llvm.ctpop.i32(i32 %2615) #10
  %2617 = trunc i32 %2616 to i8
  %2618 = and i8 %2617, 1
  %2619 = xor i8 %2618, 1
  store i8 %2619, i8* %23, align 1, !tbaa !2447
  %2620 = xor i32 %2611, %2610
  %2621 = lshr i32 %2620, 4
  %2622 = trunc i32 %2621 to i8
  %2623 = and i8 %2622, 1
  store i8 %2623, i8* %29, align 1, !tbaa !2451
  %2624 = icmp eq i32 %2611, 0
  %2625 = zext i1 %2624 to i8
  store i8 %2625, i8* %32, align 1, !tbaa !2448
  %2626 = lshr i32 %2611, 31
  %2627 = trunc i32 %2626 to i8
  store i8 %2627, i8* %35, align 1, !tbaa !2449
  %2628 = lshr i32 %2610, 31
  %2629 = xor i32 %2626, %2628
  %2630 = add nuw nsw i32 %2629, %2626
  %2631 = icmp eq i32 %2630, 2
  %2632 = zext i1 %2631 to i8
  store i8 %2632, i8* %41, align 1, !tbaa !2450
  %2633 = sext i32 %2611 to i64
  store i64 %2633, i64* %RSI, align 8, !tbaa !2428
  %2634 = shl nsw i64 %2633, 3
  %2635 = add i64 %2608, %2634
  %2636 = add i64 %2571, 36
  store i64 %2636, i64* %PC, align 8
  %2637 = bitcast i64 %2606 to double
  %2638 = inttoptr i64 %2635 to double*
  %2639 = load double, double* %2638, align 8
  %2640 = fadd double %2637, %2639
  store double %2640, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2641 = load i64, i64* %RBP, align 8
  %2642 = add i64 %2641, -128
  %2643 = add i64 %2571, 41
  store i64 %2643, i64* %PC, align 8
  %2644 = inttoptr i64 %2642 to double*
  store double %2640, double* %2644, align 8
  %2645 = load i64, i64* %RBP, align 8
  %2646 = add i64 %2645, -16
  %2647 = load i64, i64* %PC, align 8
  %2648 = add i64 %2647, 4
  store i64 %2648, i64* %PC, align 8
  %2649 = inttoptr i64 %2646 to i64*
  %2650 = load i64, i64* %2649, align 8
  store i64 %2650, i64* %RDX, align 8, !tbaa !2428
  %2651 = add i64 %2645, -28
  %2652 = add i64 %2647, 7
  store i64 %2652, i64* %PC, align 8
  %2653 = inttoptr i64 %2651 to i32*
  %2654 = load i32, i32* %2653, align 4
  %2655 = add i32 %2654, 13
  %2656 = zext i32 %2655 to i64
  store i64 %2656, i64* %RCX, align 8, !tbaa !2428
  %2657 = icmp ugt i32 %2654, -14
  %2658 = zext i1 %2657 to i8
  store i8 %2658, i8* %16, align 1, !tbaa !2433
  %2659 = and i32 %2655, 255
  %2660 = tail call i32 @llvm.ctpop.i32(i32 %2659) #10
  %2661 = trunc i32 %2660 to i8
  %2662 = and i8 %2661, 1
  %2663 = xor i8 %2662, 1
  store i8 %2663, i8* %23, align 1, !tbaa !2447
  %2664 = xor i32 %2655, %2654
  %2665 = lshr i32 %2664, 4
  %2666 = trunc i32 %2665 to i8
  %2667 = and i8 %2666, 1
  store i8 %2667, i8* %29, align 1, !tbaa !2451
  %2668 = icmp eq i32 %2655, 0
  %2669 = zext i1 %2668 to i8
  store i8 %2669, i8* %32, align 1, !tbaa !2448
  %2670 = lshr i32 %2655, 31
  %2671 = trunc i32 %2670 to i8
  store i8 %2671, i8* %35, align 1, !tbaa !2449
  %2672 = lshr i32 %2654, 31
  %2673 = xor i32 %2670, %2672
  %2674 = add nuw nsw i32 %2673, %2670
  %2675 = icmp eq i32 %2674, 2
  %2676 = zext i1 %2675 to i8
  store i8 %2676, i8* %41, align 1, !tbaa !2450
  %2677 = sext i32 %2655 to i64
  store i64 %2677, i64* %RSI, align 8, !tbaa !2428
  %2678 = shl nsw i64 %2677, 3
  %2679 = add i64 %2650, %2678
  %2680 = add i64 %2647, 18
  store i64 %2680, i64* %PC, align 8
  %2681 = inttoptr i64 %2679 to i64*
  %2682 = load i64, i64* %2681, align 8
  store i64 %2682, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2683 = add i64 %2647, 22
  store i64 %2683, i64* %PC, align 8
  %2684 = load i64, i64* %2649, align 8
  store i64 %2684, i64* %RDX, align 8, !tbaa !2428
  %2685 = add i64 %2647, 25
  store i64 %2685, i64* %PC, align 8
  %2686 = load i32, i32* %2653, align 4
  %2687 = add i32 %2686, 15
  %2688 = zext i32 %2687 to i64
  store i64 %2688, i64* %RCX, align 8, !tbaa !2428
  %2689 = icmp ugt i32 %2686, -16
  %2690 = zext i1 %2689 to i8
  store i8 %2690, i8* %16, align 1, !tbaa !2433
  %2691 = and i32 %2687, 255
  %2692 = tail call i32 @llvm.ctpop.i32(i32 %2691) #10
  %2693 = trunc i32 %2692 to i8
  %2694 = and i8 %2693, 1
  %2695 = xor i8 %2694, 1
  store i8 %2695, i8* %23, align 1, !tbaa !2447
  %2696 = xor i32 %2687, %2686
  %2697 = lshr i32 %2696, 4
  %2698 = trunc i32 %2697 to i8
  %2699 = and i8 %2698, 1
  store i8 %2699, i8* %29, align 1, !tbaa !2451
  %2700 = icmp eq i32 %2687, 0
  %2701 = zext i1 %2700 to i8
  store i8 %2701, i8* %32, align 1, !tbaa !2448
  %2702 = lshr i32 %2687, 31
  %2703 = trunc i32 %2702 to i8
  store i8 %2703, i8* %35, align 1, !tbaa !2449
  %2704 = lshr i32 %2686, 31
  %2705 = xor i32 %2702, %2704
  %2706 = add nuw nsw i32 %2705, %2702
  %2707 = icmp eq i32 %2706, 2
  %2708 = zext i1 %2707 to i8
  store i8 %2708, i8* %41, align 1, !tbaa !2450
  %2709 = sext i32 %2687 to i64
  store i64 %2709, i64* %RSI, align 8, !tbaa !2428
  %2710 = shl nsw i64 %2709, 3
  %2711 = add i64 %2684, %2710
  %2712 = add i64 %2647, 36
  store i64 %2712, i64* %PC, align 8
  %2713 = bitcast i64 %2682 to double
  %2714 = inttoptr i64 %2711 to double*
  %2715 = load double, double* %2714, align 8
  %2716 = fadd double %2713, %2715
  store double %2716, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2717 = load i64, i64* %RBP, align 8
  %2718 = add i64 %2717, -136
  %2719 = add i64 %2647, 44
  store i64 %2719, i64* %PC, align 8
  %2720 = inttoptr i64 %2718 to double*
  store double %2716, double* %2720, align 8
  %2721 = load i64, i64* %RBP, align 8
  %2722 = add i64 %2721, -16
  %2723 = load i64, i64* %PC, align 8
  %2724 = add i64 %2723, 4
  store i64 %2724, i64* %PC, align 8
  %2725 = inttoptr i64 %2722 to i64*
  %2726 = load i64, i64* %2725, align 8
  store i64 %2726, i64* %RDX, align 8, !tbaa !2428
  %2727 = add i64 %2721, -28
  %2728 = add i64 %2723, 7
  store i64 %2728, i64* %PC, align 8
  %2729 = inttoptr i64 %2727 to i32*
  %2730 = load i32, i32* %2729, align 4
  %2731 = add i32 %2730, 12
  %2732 = zext i32 %2731 to i64
  store i64 %2732, i64* %RCX, align 8, !tbaa !2428
  %2733 = icmp ugt i32 %2730, -13
  %2734 = zext i1 %2733 to i8
  store i8 %2734, i8* %16, align 1, !tbaa !2433
  %2735 = and i32 %2731, 255
  %2736 = tail call i32 @llvm.ctpop.i32(i32 %2735) #10
  %2737 = trunc i32 %2736 to i8
  %2738 = and i8 %2737, 1
  %2739 = xor i8 %2738, 1
  store i8 %2739, i8* %23, align 1, !tbaa !2447
  %2740 = xor i32 %2731, %2730
  %2741 = lshr i32 %2740, 4
  %2742 = trunc i32 %2741 to i8
  %2743 = and i8 %2742, 1
  store i8 %2743, i8* %29, align 1, !tbaa !2451
  %2744 = icmp eq i32 %2731, 0
  %2745 = zext i1 %2744 to i8
  store i8 %2745, i8* %32, align 1, !tbaa !2448
  %2746 = lshr i32 %2731, 31
  %2747 = trunc i32 %2746 to i8
  store i8 %2747, i8* %35, align 1, !tbaa !2449
  %2748 = lshr i32 %2730, 31
  %2749 = xor i32 %2746, %2748
  %2750 = add nuw nsw i32 %2749, %2746
  %2751 = icmp eq i32 %2750, 2
  %2752 = zext i1 %2751 to i8
  store i8 %2752, i8* %41, align 1, !tbaa !2450
  %2753 = sext i32 %2731 to i64
  store i64 %2753, i64* %RSI, align 8, !tbaa !2428
  %2754 = shl nsw i64 %2753, 3
  %2755 = add i64 %2726, %2754
  %2756 = add i64 %2723, 18
  store i64 %2756, i64* %PC, align 8
  %2757 = inttoptr i64 %2755 to i64*
  %2758 = load i64, i64* %2757, align 8
  store i64 %2758, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2759 = add i64 %2723, 22
  store i64 %2759, i64* %PC, align 8
  %2760 = load i64, i64* %2725, align 8
  store i64 %2760, i64* %RDX, align 8, !tbaa !2428
  %2761 = add i64 %2723, 25
  store i64 %2761, i64* %PC, align 8
  %2762 = load i32, i32* %2729, align 4
  %2763 = add i32 %2762, 14
  %2764 = zext i32 %2763 to i64
  store i64 %2764, i64* %RCX, align 8, !tbaa !2428
  %2765 = icmp ugt i32 %2762, -15
  %2766 = zext i1 %2765 to i8
  store i8 %2766, i8* %16, align 1, !tbaa !2433
  %2767 = and i32 %2763, 255
  %2768 = tail call i32 @llvm.ctpop.i32(i32 %2767) #10
  %2769 = trunc i32 %2768 to i8
  %2770 = and i8 %2769, 1
  %2771 = xor i8 %2770, 1
  store i8 %2771, i8* %23, align 1, !tbaa !2447
  %2772 = xor i32 %2763, %2762
  %2773 = lshr i32 %2772, 4
  %2774 = trunc i32 %2773 to i8
  %2775 = and i8 %2774, 1
  store i8 %2775, i8* %29, align 1, !tbaa !2451
  %2776 = icmp eq i32 %2763, 0
  %2777 = zext i1 %2776 to i8
  store i8 %2777, i8* %32, align 1, !tbaa !2448
  %2778 = lshr i32 %2763, 31
  %2779 = trunc i32 %2778 to i8
  store i8 %2779, i8* %35, align 1, !tbaa !2449
  %2780 = lshr i32 %2762, 31
  %2781 = xor i32 %2778, %2780
  %2782 = add nuw nsw i32 %2781, %2778
  %2783 = icmp eq i32 %2782, 2
  %2784 = zext i1 %2783 to i8
  store i8 %2784, i8* %41, align 1, !tbaa !2450
  %2785 = sext i32 %2763 to i64
  store i64 %2785, i64* %RSI, align 8, !tbaa !2428
  %2786 = shl nsw i64 %2785, 3
  %2787 = add i64 %2760, %2786
  %2788 = add i64 %2723, 36
  store i64 %2788, i64* %PC, align 8
  %2789 = bitcast i64 %2758 to double
  %2790 = inttoptr i64 %2787 to double*
  %2791 = load double, double* %2790, align 8
  %2792 = fsub double %2789, %2791
  store double %2792, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2793 = load i64, i64* %RBP, align 8
  %2794 = add i64 %2793, -144
  %2795 = add i64 %2723, 44
  store i64 %2795, i64* %PC, align 8
  %2796 = inttoptr i64 %2794 to double*
  store double %2792, double* %2796, align 8
  %2797 = load i64, i64* %RBP, align 8
  %2798 = add i64 %2797, -16
  %2799 = load i64, i64* %PC, align 8
  %2800 = add i64 %2799, 4
  store i64 %2800, i64* %PC, align 8
  %2801 = inttoptr i64 %2798 to i64*
  %2802 = load i64, i64* %2801, align 8
  store i64 %2802, i64* %RDX, align 8, !tbaa !2428
  %2803 = add i64 %2797, -28
  %2804 = add i64 %2799, 7
  store i64 %2804, i64* %PC, align 8
  %2805 = inttoptr i64 %2803 to i32*
  %2806 = load i32, i32* %2805, align 4
  %2807 = add i32 %2806, 13
  %2808 = zext i32 %2807 to i64
  store i64 %2808, i64* %RCX, align 8, !tbaa !2428
  %2809 = icmp ugt i32 %2806, -14
  %2810 = zext i1 %2809 to i8
  store i8 %2810, i8* %16, align 1, !tbaa !2433
  %2811 = and i32 %2807, 255
  %2812 = tail call i32 @llvm.ctpop.i32(i32 %2811) #10
  %2813 = trunc i32 %2812 to i8
  %2814 = and i8 %2813, 1
  %2815 = xor i8 %2814, 1
  store i8 %2815, i8* %23, align 1, !tbaa !2447
  %2816 = xor i32 %2807, %2806
  %2817 = lshr i32 %2816, 4
  %2818 = trunc i32 %2817 to i8
  %2819 = and i8 %2818, 1
  store i8 %2819, i8* %29, align 1, !tbaa !2451
  %2820 = icmp eq i32 %2807, 0
  %2821 = zext i1 %2820 to i8
  store i8 %2821, i8* %32, align 1, !tbaa !2448
  %2822 = lshr i32 %2807, 31
  %2823 = trunc i32 %2822 to i8
  store i8 %2823, i8* %35, align 1, !tbaa !2449
  %2824 = lshr i32 %2806, 31
  %2825 = xor i32 %2822, %2824
  %2826 = add nuw nsw i32 %2825, %2822
  %2827 = icmp eq i32 %2826, 2
  %2828 = zext i1 %2827 to i8
  store i8 %2828, i8* %41, align 1, !tbaa !2450
  %2829 = sext i32 %2807 to i64
  store i64 %2829, i64* %RSI, align 8, !tbaa !2428
  %2830 = shl nsw i64 %2829, 3
  %2831 = add i64 %2802, %2830
  %2832 = add i64 %2799, 18
  store i64 %2832, i64* %PC, align 8
  %2833 = inttoptr i64 %2831 to i64*
  %2834 = load i64, i64* %2833, align 8
  store i64 %2834, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2835 = add i64 %2799, 22
  store i64 %2835, i64* %PC, align 8
  %2836 = load i64, i64* %2801, align 8
  store i64 %2836, i64* %RDX, align 8, !tbaa !2428
  %2837 = add i64 %2799, 25
  store i64 %2837, i64* %PC, align 8
  %2838 = load i32, i32* %2805, align 4
  %2839 = add i32 %2838, 15
  %2840 = zext i32 %2839 to i64
  store i64 %2840, i64* %RCX, align 8, !tbaa !2428
  %2841 = icmp ugt i32 %2838, -16
  %2842 = zext i1 %2841 to i8
  store i8 %2842, i8* %16, align 1, !tbaa !2433
  %2843 = and i32 %2839, 255
  %2844 = tail call i32 @llvm.ctpop.i32(i32 %2843) #10
  %2845 = trunc i32 %2844 to i8
  %2846 = and i8 %2845, 1
  %2847 = xor i8 %2846, 1
  store i8 %2847, i8* %23, align 1, !tbaa !2447
  %2848 = xor i32 %2839, %2838
  %2849 = lshr i32 %2848, 4
  %2850 = trunc i32 %2849 to i8
  %2851 = and i8 %2850, 1
  store i8 %2851, i8* %29, align 1, !tbaa !2451
  %2852 = icmp eq i32 %2839, 0
  %2853 = zext i1 %2852 to i8
  store i8 %2853, i8* %32, align 1, !tbaa !2448
  %2854 = lshr i32 %2839, 31
  %2855 = trunc i32 %2854 to i8
  store i8 %2855, i8* %35, align 1, !tbaa !2449
  %2856 = lshr i32 %2838, 31
  %2857 = xor i32 %2854, %2856
  %2858 = add nuw nsw i32 %2857, %2854
  %2859 = icmp eq i32 %2858, 2
  %2860 = zext i1 %2859 to i8
  store i8 %2860, i8* %41, align 1, !tbaa !2450
  %2861 = sext i32 %2839 to i64
  store i64 %2861, i64* %RSI, align 8, !tbaa !2428
  %2862 = shl nsw i64 %2861, 3
  %2863 = add i64 %2836, %2862
  %2864 = add i64 %2799, 36
  store i64 %2864, i64* %PC, align 8
  %2865 = bitcast i64 %2834 to double
  %2866 = inttoptr i64 %2863 to double*
  %2867 = load double, double* %2866, align 8
  %2868 = fsub double %2865, %2867
  store double %2868, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2869 = load i64, i64* %RBP, align 8
  %2870 = add i64 %2869, -152
  %2871 = add i64 %2799, 44
  store i64 %2871, i64* %PC, align 8
  %2872 = inttoptr i64 %2870 to double*
  store double %2868, double* %2872, align 8
  %2873 = load i64, i64* %RBP, align 8
  %2874 = add i64 %2873, -96
  %2875 = load i64, i64* %PC, align 8
  %2876 = add i64 %2875, 5
  store i64 %2876, i64* %PC, align 8
  %2877 = inttoptr i64 %2874 to i64*
  %2878 = load i64, i64* %2877, align 8
  store i64 %2878, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2879 = add i64 %2873, -128
  %2880 = add i64 %2875, 10
  store i64 %2880, i64* %PC, align 8
  %2881 = bitcast i64 %2878 to double
  %2882 = inttoptr i64 %2879 to double*
  %2883 = load double, double* %2882, align 8
  %2884 = fadd double %2881, %2883
  store double %2884, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2885 = add i64 %2873, -16
  %2886 = add i64 %2875, 14
  store i64 %2886, i64* %PC, align 8
  %2887 = inttoptr i64 %2885 to i64*
  %2888 = load i64, i64* %2887, align 8
  store i64 %2888, i64* %RDX, align 8, !tbaa !2428
  %2889 = add i64 %2873, -28
  %2890 = add i64 %2875, 17
  store i64 %2890, i64* %PC, align 8
  %2891 = inttoptr i64 %2889 to i32*
  %2892 = load i32, i32* %2891, align 4
  %2893 = add i32 %2892, 8
  %2894 = zext i32 %2893 to i64
  store i64 %2894, i64* %RCX, align 8, !tbaa !2428
  %2895 = icmp ugt i32 %2892, -9
  %2896 = zext i1 %2895 to i8
  store i8 %2896, i8* %16, align 1, !tbaa !2433
  %2897 = and i32 %2893, 255
  %2898 = tail call i32 @llvm.ctpop.i32(i32 %2897) #10
  %2899 = trunc i32 %2898 to i8
  %2900 = and i8 %2899, 1
  %2901 = xor i8 %2900, 1
  store i8 %2901, i8* %23, align 1, !tbaa !2447
  %2902 = xor i32 %2893, %2892
  %2903 = lshr i32 %2902, 4
  %2904 = trunc i32 %2903 to i8
  %2905 = and i8 %2904, 1
  store i8 %2905, i8* %29, align 1, !tbaa !2451
  %2906 = icmp eq i32 %2893, 0
  %2907 = zext i1 %2906 to i8
  store i8 %2907, i8* %32, align 1, !tbaa !2448
  %2908 = lshr i32 %2893, 31
  %2909 = trunc i32 %2908 to i8
  store i8 %2909, i8* %35, align 1, !tbaa !2449
  %2910 = lshr i32 %2892, 31
  %2911 = xor i32 %2908, %2910
  %2912 = add nuw nsw i32 %2911, %2908
  %2913 = icmp eq i32 %2912, 2
  %2914 = zext i1 %2913 to i8
  store i8 %2914, i8* %41, align 1, !tbaa !2450
  %2915 = sext i32 %2893 to i64
  store i64 %2915, i64* %RSI, align 8, !tbaa !2428
  %2916 = shl nsw i64 %2915, 3
  %2917 = add i64 %2888, %2916
  %2918 = add i64 %2875, 28
  store i64 %2918, i64* %PC, align 8
  %2919 = inttoptr i64 %2917 to double*
  store double %2884, double* %2919, align 8
  %2920 = load i64, i64* %RBP, align 8
  %2921 = add i64 %2920, -104
  %2922 = load i64, i64* %PC, align 8
  %2923 = add i64 %2922, 5
  store i64 %2923, i64* %PC, align 8
  %2924 = inttoptr i64 %2921 to i64*
  %2925 = load i64, i64* %2924, align 8
  store i64 %2925, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2926 = add i64 %2920, -136
  %2927 = add i64 %2922, 13
  store i64 %2927, i64* %PC, align 8
  %2928 = bitcast i64 %2925 to double
  %2929 = inttoptr i64 %2926 to double*
  %2930 = load double, double* %2929, align 8
  %2931 = fadd double %2928, %2930
  store double %2931, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2932 = add i64 %2920, -16
  %2933 = add i64 %2922, 17
  store i64 %2933, i64* %PC, align 8
  %2934 = inttoptr i64 %2932 to i64*
  %2935 = load i64, i64* %2934, align 8
  store i64 %2935, i64* %RDX, align 8, !tbaa !2428
  %2936 = add i64 %2920, -28
  %2937 = add i64 %2922, 20
  store i64 %2937, i64* %PC, align 8
  %2938 = inttoptr i64 %2936 to i32*
  %2939 = load i32, i32* %2938, align 4
  %2940 = add i32 %2939, 9
  %2941 = zext i32 %2940 to i64
  store i64 %2941, i64* %RCX, align 8, !tbaa !2428
  %2942 = icmp ugt i32 %2939, -10
  %2943 = zext i1 %2942 to i8
  store i8 %2943, i8* %16, align 1, !tbaa !2433
  %2944 = and i32 %2940, 255
  %2945 = tail call i32 @llvm.ctpop.i32(i32 %2944) #10
  %2946 = trunc i32 %2945 to i8
  %2947 = and i8 %2946, 1
  %2948 = xor i8 %2947, 1
  store i8 %2948, i8* %23, align 1, !tbaa !2447
  %2949 = xor i32 %2940, %2939
  %2950 = lshr i32 %2949, 4
  %2951 = trunc i32 %2950 to i8
  %2952 = and i8 %2951, 1
  store i8 %2952, i8* %29, align 1, !tbaa !2451
  %2953 = icmp eq i32 %2940, 0
  %2954 = zext i1 %2953 to i8
  store i8 %2954, i8* %32, align 1, !tbaa !2448
  %2955 = lshr i32 %2940, 31
  %2956 = trunc i32 %2955 to i8
  store i8 %2956, i8* %35, align 1, !tbaa !2449
  %2957 = lshr i32 %2939, 31
  %2958 = xor i32 %2955, %2957
  %2959 = add nuw nsw i32 %2958, %2955
  %2960 = icmp eq i32 %2959, 2
  %2961 = zext i1 %2960 to i8
  store i8 %2961, i8* %41, align 1, !tbaa !2450
  %2962 = sext i32 %2940 to i64
  store i64 %2962, i64* %RSI, align 8, !tbaa !2428
  %2963 = shl nsw i64 %2962, 3
  %2964 = add i64 %2935, %2963
  %2965 = add i64 %2922, 31
  store i64 %2965, i64* %PC, align 8
  %2966 = inttoptr i64 %2964 to double*
  store double %2931, double* %2966, align 8
  %2967 = load i64, i64* %RBP, align 8
  %2968 = add i64 %2967, -128
  %2969 = load i64, i64* %PC, align 8
  %2970 = add i64 %2969, 5
  store i64 %2970, i64* %PC, align 8
  %2971 = inttoptr i64 %2968 to i64*
  %2972 = load i64, i64* %2971, align 8
  store i64 %2972, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2973 = add i64 %2967, -96
  %2974 = add i64 %2969, 10
  store i64 %2974, i64* %PC, align 8
  %2975 = inttoptr i64 %2973 to double*
  %2976 = load double, double* %2975, align 8
  %2977 = bitcast i64 %2972 to double
  %2978 = fsub double %2976, %2977
  store double %2978, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2979 = add i64 %2969, 19
  store i64 %2979, i64* %PC, align 8
  %2980 = inttoptr i64 %2973 to double*
  store double %2978, double* %2980, align 8
  %2981 = load i64, i64* %RBP, align 8
  %2982 = add i64 %2981, -136
  %2983 = load i64, i64* %PC, align 8
  %2984 = add i64 %2983, 8
  store i64 %2984, i64* %PC, align 8
  %2985 = inttoptr i64 %2982 to i64*
  %2986 = load i64, i64* %2985, align 8
  store i64 %2986, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2987 = add i64 %2981, -104
  %2988 = add i64 %2983, 13
  store i64 %2988, i64* %PC, align 8
  %2989 = inttoptr i64 %2987 to double*
  %2990 = load double, double* %2989, align 8
  %2991 = bitcast i64 %2986 to double
  %2992 = fsub double %2990, %2991
  store double %2992, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %2993 = add i64 %2983, 22
  store i64 %2993, i64* %PC, align 8
  %2994 = inttoptr i64 %2987 to double*
  store double %2992, double* %2994, align 8
  %2995 = load i64, i64* %RBP, align 8
  %2996 = add i64 %2995, -72
  %2997 = load i64, i64* %PC, align 8
  %2998 = add i64 %2997, 5
  store i64 %2998, i64* %PC, align 8
  %2999 = inttoptr i64 %2996 to i64*
  %3000 = load i64, i64* %2999, align 8
  %3001 = load i64, i64* %RAX, align 8
  %3002 = xor i64 %3001, %3000
  store i64 %3002, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2433
  %3003 = trunc i64 %3002 to i32
  %3004 = and i32 %3003, 255
  %3005 = tail call i32 @llvm.ctpop.i32(i32 %3004) #10
  %3006 = trunc i32 %3005 to i8
  %3007 = and i8 %3006, 1
  %3008 = xor i8 %3007, 1
  store i8 %3008, i8* %23, align 1, !tbaa !2447
  %3009 = icmp eq i64 %3002, 0
  %3010 = zext i1 %3009 to i8
  store i8 %3010, i8* %32, align 1, !tbaa !2448
  %3011 = lshr i64 %3002, 63
  %3012 = trunc i64 %3011 to i8
  store i8 %3012, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2451
  store i64 %3002, i64* %68, align 1, !tbaa !2428
  store i64 0, i64* %69, align 1, !tbaa !2428
  %3013 = add i64 %2995, -96
  %3014 = add i64 %2997, 23
  store i64 %3014, i64* %PC, align 8
  %.cast4 = bitcast i64 %3002 to double
  %3015 = inttoptr i64 %3013 to double*
  %3016 = load double, double* %3015, align 8
  %3017 = fmul double %.cast4, %3016
  store double %3017, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3018 = add i64 %2995, -64
  %3019 = add i64 %2997, 28
  store i64 %3019, i64* %PC, align 8
  %3020 = inttoptr i64 %3018 to i64*
  %3021 = load i64, i64* %3020, align 8
  store i64 %3021, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %3022 = add i64 %2995, -104
  %3023 = add i64 %2997, 33
  store i64 %3023, i64* %PC, align 8
  %3024 = bitcast i64 %3021 to double
  %3025 = inttoptr i64 %3022 to double*
  %3026 = load double, double* %3025, align 8
  %3027 = fmul double %3024, %3026
  store double %3027, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %3028 = fsub double %3017, %3027
  store double %3028, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3029 = add i64 %2995, -16
  %3030 = add i64 %2997, 41
  store i64 %3030, i64* %PC, align 8
  %3031 = inttoptr i64 %3029 to i64*
  %3032 = load i64, i64* %3031, align 8
  store i64 %3032, i64* %RDX, align 8, !tbaa !2428
  %3033 = add i64 %2995, -28
  %3034 = add i64 %2997, 44
  store i64 %3034, i64* %PC, align 8
  %3035 = inttoptr i64 %3033 to i32*
  %3036 = load i32, i32* %3035, align 4
  %3037 = add i32 %3036, 12
  %3038 = zext i32 %3037 to i64
  store i64 %3038, i64* %RCX, align 8, !tbaa !2428
  %3039 = icmp ugt i32 %3036, -13
  %3040 = zext i1 %3039 to i8
  store i8 %3040, i8* %16, align 1, !tbaa !2433
  %3041 = and i32 %3037, 255
  %3042 = tail call i32 @llvm.ctpop.i32(i32 %3041) #10
  %3043 = trunc i32 %3042 to i8
  %3044 = and i8 %3043, 1
  %3045 = xor i8 %3044, 1
  store i8 %3045, i8* %23, align 1, !tbaa !2447
  %3046 = xor i32 %3037, %3036
  %3047 = lshr i32 %3046, 4
  %3048 = trunc i32 %3047 to i8
  %3049 = and i8 %3048, 1
  store i8 %3049, i8* %29, align 1, !tbaa !2451
  %3050 = icmp eq i32 %3037, 0
  %3051 = zext i1 %3050 to i8
  store i8 %3051, i8* %32, align 1, !tbaa !2448
  %3052 = lshr i32 %3037, 31
  %3053 = trunc i32 %3052 to i8
  store i8 %3053, i8* %35, align 1, !tbaa !2449
  %3054 = lshr i32 %3036, 31
  %3055 = xor i32 %3052, %3054
  %3056 = add nuw nsw i32 %3055, %3052
  %3057 = icmp eq i32 %3056, 2
  %3058 = zext i1 %3057 to i8
  store i8 %3058, i8* %41, align 1, !tbaa !2450
  %3059 = sext i32 %3037 to i64
  store i64 %3059, i64* %RSI, align 8, !tbaa !2428
  %3060 = shl nsw i64 %3059, 3
  %3061 = add i64 %3032, %3060
  %3062 = add i64 %2997, 55
  store i64 %3062, i64* %PC, align 8
  %3063 = inttoptr i64 %3061 to double*
  store double %3028, double* %3063, align 8
  %3064 = load i64, i64* %RBP, align 8
  %3065 = add i64 %3064, -72
  %3066 = load i64, i64* %PC, align 8
  %3067 = add i64 %3066, 5
  store i64 %3067, i64* %PC, align 8
  %3068 = inttoptr i64 %3065 to i64*
  %3069 = load i64, i64* %3068, align 8
  %3070 = load i64, i64* %RAX, align 8
  %3071 = xor i64 %3070, %3069
  store i64 %3071, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2433
  %3072 = trunc i64 %3071 to i32
  %3073 = and i32 %3072, 255
  %3074 = tail call i32 @llvm.ctpop.i32(i32 %3073) #10
  %3075 = trunc i32 %3074 to i8
  %3076 = and i8 %3075, 1
  %3077 = xor i8 %3076, 1
  store i8 %3077, i8* %23, align 1, !tbaa !2447
  %3078 = icmp eq i64 %3071, 0
  %3079 = zext i1 %3078 to i8
  store i8 %3079, i8* %32, align 1, !tbaa !2448
  %3080 = lshr i64 %3071, 63
  %3081 = trunc i64 %3080 to i8
  store i8 %3081, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2451
  store i64 %3071, i64* %68, align 1, !tbaa !2428
  store i64 0, i64* %69, align 1, !tbaa !2428
  %3082 = add i64 %3064, -104
  %3083 = add i64 %3066, 23
  store i64 %3083, i64* %PC, align 8
  %.cast5 = bitcast i64 %3071 to double
  %3084 = inttoptr i64 %3082 to double*
  %3085 = load double, double* %3084, align 8
  %3086 = fmul double %.cast5, %3085
  store double %3086, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3087 = add i64 %3064, -64
  %3088 = add i64 %3066, 28
  store i64 %3088, i64* %PC, align 8
  %3089 = inttoptr i64 %3087 to i64*
  %3090 = load i64, i64* %3089, align 8
  store i64 %3090, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %3091 = add i64 %3064, -96
  %3092 = add i64 %3066, 33
  store i64 %3092, i64* %PC, align 8
  %3093 = bitcast i64 %3090 to double
  %3094 = inttoptr i64 %3091 to double*
  %3095 = load double, double* %3094, align 8
  %3096 = fmul double %3093, %3095
  store double %3096, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %3097 = fadd double %3086, %3096
  store double %3097, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3098 = add i64 %3064, -16
  %3099 = add i64 %3066, 41
  store i64 %3099, i64* %PC, align 8
  %3100 = inttoptr i64 %3098 to i64*
  %3101 = load i64, i64* %3100, align 8
  store i64 %3101, i64* %RAX, align 8, !tbaa !2428
  %3102 = add i64 %3064, -28
  %3103 = add i64 %3066, 44
  store i64 %3103, i64* %PC, align 8
  %3104 = inttoptr i64 %3102 to i32*
  %3105 = load i32, i32* %3104, align 4
  %3106 = add i32 %3105, 13
  %3107 = zext i32 %3106 to i64
  store i64 %3107, i64* %RCX, align 8, !tbaa !2428
  %3108 = icmp ugt i32 %3105, -14
  %3109 = zext i1 %3108 to i8
  store i8 %3109, i8* %16, align 1, !tbaa !2433
  %3110 = and i32 %3106, 255
  %3111 = tail call i32 @llvm.ctpop.i32(i32 %3110) #10
  %3112 = trunc i32 %3111 to i8
  %3113 = and i8 %3112, 1
  %3114 = xor i8 %3113, 1
  store i8 %3114, i8* %23, align 1, !tbaa !2447
  %3115 = xor i32 %3106, %3105
  %3116 = lshr i32 %3115, 4
  %3117 = trunc i32 %3116 to i8
  %3118 = and i8 %3117, 1
  store i8 %3118, i8* %29, align 1, !tbaa !2451
  %3119 = icmp eq i32 %3106, 0
  %3120 = zext i1 %3119 to i8
  store i8 %3120, i8* %32, align 1, !tbaa !2448
  %3121 = lshr i32 %3106, 31
  %3122 = trunc i32 %3121 to i8
  store i8 %3122, i8* %35, align 1, !tbaa !2449
  %3123 = lshr i32 %3105, 31
  %3124 = xor i32 %3121, %3123
  %3125 = add nuw nsw i32 %3124, %3121
  %3126 = icmp eq i32 %3125, 2
  %3127 = zext i1 %3126 to i8
  store i8 %3127, i8* %41, align 1, !tbaa !2450
  %3128 = sext i32 %3106 to i64
  store i64 %3128, i64* %RDX, align 8, !tbaa !2428
  %3129 = shl nsw i64 %3128, 3
  %3130 = add i64 %3101, %3129
  %3131 = add i64 %3066, 55
  store i64 %3131, i64* %PC, align 8
  %3132 = inttoptr i64 %3130 to double*
  store double %3097, double* %3132, align 8
  %3133 = load i64, i64* %RBP, align 8
  %3134 = add i64 %3133, -112
  %3135 = load i64, i64* %PC, align 8
  %3136 = add i64 %3135, 5
  store i64 %3136, i64* %PC, align 8
  %3137 = inttoptr i64 %3134 to i64*
  %3138 = load i64, i64* %3137, align 8
  store i64 %3138, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3139 = add i64 %3133, -152
  %3140 = add i64 %3135, 13
  store i64 %3140, i64* %PC, align 8
  %3141 = bitcast i64 %3138 to double
  %3142 = inttoptr i64 %3139 to double*
  %3143 = load double, double* %3142, align 8
  %3144 = fsub double %3141, %3143
  store double %3144, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3145 = add i64 %3133, -96
  %3146 = add i64 %3135, 18
  store i64 %3146, i64* %PC, align 8
  %3147 = inttoptr i64 %3145 to double*
  store double %3144, double* %3147, align 8
  %3148 = load i64, i64* %RBP, align 8
  %3149 = add i64 %3148, -120
  %3150 = load i64, i64* %PC, align 8
  %3151 = add i64 %3150, 5
  store i64 %3151, i64* %PC, align 8
  %3152 = inttoptr i64 %3149 to i64*
  %3153 = load i64, i64* %3152, align 8
  store i64 %3153, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3154 = add i64 %3148, -144
  %3155 = add i64 %3150, 13
  store i64 %3155, i64* %PC, align 8
  %3156 = bitcast i64 %3153 to double
  %3157 = inttoptr i64 %3154 to double*
  %3158 = load double, double* %3157, align 8
  %3159 = fadd double %3156, %3158
  store double %3159, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3160 = add i64 %3148, -104
  %3161 = add i64 %3150, 18
  store i64 %3161, i64* %PC, align 8
  %3162 = inttoptr i64 %3160 to double*
  store double %3159, double* %3162, align 8
  %3163 = load i64, i64* %RBP, align 8
  %3164 = add i64 %3163, -48
  %3165 = load i64, i64* %PC, align 8
  %3166 = add i64 %3165, 5
  store i64 %3166, i64* %PC, align 8
  %3167 = inttoptr i64 %3164 to i64*
  %3168 = load i64, i64* %3167, align 8
  store i64 %3168, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3169 = add i64 %3163, -96
  %3170 = add i64 %3165, 10
  store i64 %3170, i64* %PC, align 8
  %3171 = bitcast i64 %3168 to double
  %3172 = inttoptr i64 %3169 to double*
  %3173 = load double, double* %3172, align 8
  %3174 = fmul double %3171, %3173
  store double %3174, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3175 = add i64 %3163, -56
  %3176 = add i64 %3165, 15
  store i64 %3176, i64* %PC, align 8
  %3177 = inttoptr i64 %3175 to i64*
  %3178 = load i64, i64* %3177, align 8
  store i64 %3178, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %3179 = add i64 %3163, -104
  %3180 = add i64 %3165, 20
  store i64 %3180, i64* %PC, align 8
  %3181 = bitcast i64 %3178 to double
  %3182 = inttoptr i64 %3179 to double*
  %3183 = load double, double* %3182, align 8
  %3184 = fmul double %3181, %3183
  store double %3184, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %3185 = fsub double %3174, %3184
  store double %3185, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3186 = add i64 %3163, -16
  %3187 = add i64 %3165, 28
  store i64 %3187, i64* %PC, align 8
  %3188 = inttoptr i64 %3186 to i64*
  %3189 = load i64, i64* %3188, align 8
  store i64 %3189, i64* %RAX, align 8, !tbaa !2428
  %3190 = add i64 %3163, -28
  %3191 = add i64 %3165, 31
  store i64 %3191, i64* %PC, align 8
  %3192 = inttoptr i64 %3190 to i32*
  %3193 = load i32, i32* %3192, align 4
  %3194 = add i32 %3193, 10
  %3195 = zext i32 %3194 to i64
  store i64 %3195, i64* %RCX, align 8, !tbaa !2428
  %3196 = icmp ugt i32 %3193, -11
  %3197 = zext i1 %3196 to i8
  store i8 %3197, i8* %16, align 1, !tbaa !2433
  %3198 = and i32 %3194, 255
  %3199 = tail call i32 @llvm.ctpop.i32(i32 %3198) #10
  %3200 = trunc i32 %3199 to i8
  %3201 = and i8 %3200, 1
  %3202 = xor i8 %3201, 1
  store i8 %3202, i8* %23, align 1, !tbaa !2447
  %3203 = xor i32 %3194, %3193
  %3204 = lshr i32 %3203, 4
  %3205 = trunc i32 %3204 to i8
  %3206 = and i8 %3205, 1
  store i8 %3206, i8* %29, align 1, !tbaa !2451
  %3207 = icmp eq i32 %3194, 0
  %3208 = zext i1 %3207 to i8
  store i8 %3208, i8* %32, align 1, !tbaa !2448
  %3209 = lshr i32 %3194, 31
  %3210 = trunc i32 %3209 to i8
  store i8 %3210, i8* %35, align 1, !tbaa !2449
  %3211 = lshr i32 %3193, 31
  %3212 = xor i32 %3209, %3211
  %3213 = add nuw nsw i32 %3212, %3209
  %3214 = icmp eq i32 %3213, 2
  %3215 = zext i1 %3214 to i8
  store i8 %3215, i8* %41, align 1, !tbaa !2450
  %3216 = sext i32 %3194 to i64
  store i64 %3216, i64* %RDX, align 8, !tbaa !2428
  %3217 = shl nsw i64 %3216, 3
  %3218 = add i64 %3189, %3217
  %3219 = add i64 %3165, 42
  store i64 %3219, i64* %PC, align 8
  %3220 = inttoptr i64 %3218 to double*
  store double %3185, double* %3220, align 8
  %3221 = load i64, i64* %RBP, align 8
  %3222 = add i64 %3221, -48
  %3223 = load i64, i64* %PC, align 8
  %3224 = add i64 %3223, 5
  store i64 %3224, i64* %PC, align 8
  %3225 = inttoptr i64 %3222 to i64*
  %3226 = load i64, i64* %3225, align 8
  store i64 %3226, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3227 = add i64 %3221, -104
  %3228 = add i64 %3223, 10
  store i64 %3228, i64* %PC, align 8
  %3229 = bitcast i64 %3226 to double
  %3230 = inttoptr i64 %3227 to double*
  %3231 = load double, double* %3230, align 8
  %3232 = fmul double %3229, %3231
  store double %3232, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3233 = add i64 %3221, -56
  %3234 = add i64 %3223, 15
  store i64 %3234, i64* %PC, align 8
  %3235 = inttoptr i64 %3233 to i64*
  %3236 = load i64, i64* %3235, align 8
  store i64 %3236, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %3237 = add i64 %3221, -96
  %3238 = add i64 %3223, 20
  store i64 %3238, i64* %PC, align 8
  %3239 = bitcast i64 %3236 to double
  %3240 = inttoptr i64 %3237 to double*
  %3241 = load double, double* %3240, align 8
  %3242 = fmul double %3239, %3241
  store double %3242, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %3243 = fadd double %3232, %3242
  store double %3243, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3244 = add i64 %3221, -16
  %3245 = add i64 %3223, 28
  store i64 %3245, i64* %PC, align 8
  %3246 = inttoptr i64 %3244 to i64*
  %3247 = load i64, i64* %3246, align 8
  store i64 %3247, i64* %RAX, align 8, !tbaa !2428
  %3248 = add i64 %3221, -28
  %3249 = add i64 %3223, 31
  store i64 %3249, i64* %PC, align 8
  %3250 = inttoptr i64 %3248 to i32*
  %3251 = load i32, i32* %3250, align 4
  %3252 = add i32 %3251, 11
  %3253 = zext i32 %3252 to i64
  store i64 %3253, i64* %RCX, align 8, !tbaa !2428
  %3254 = icmp ugt i32 %3251, -12
  %3255 = zext i1 %3254 to i8
  store i8 %3255, i8* %16, align 1, !tbaa !2433
  %3256 = and i32 %3252, 255
  %3257 = tail call i32 @llvm.ctpop.i32(i32 %3256) #10
  %3258 = trunc i32 %3257 to i8
  %3259 = and i8 %3258, 1
  %3260 = xor i8 %3259, 1
  store i8 %3260, i8* %23, align 1, !tbaa !2447
  %3261 = xor i32 %3252, %3251
  %3262 = lshr i32 %3261, 4
  %3263 = trunc i32 %3262 to i8
  %3264 = and i8 %3263, 1
  store i8 %3264, i8* %29, align 1, !tbaa !2451
  %3265 = icmp eq i32 %3252, 0
  %3266 = zext i1 %3265 to i8
  store i8 %3266, i8* %32, align 1, !tbaa !2448
  %3267 = lshr i32 %3252, 31
  %3268 = trunc i32 %3267 to i8
  store i8 %3268, i8* %35, align 1, !tbaa !2449
  %3269 = lshr i32 %3251, 31
  %3270 = xor i32 %3267, %3269
  %3271 = add nuw nsw i32 %3270, %3267
  %3272 = icmp eq i32 %3271, 2
  %3273 = zext i1 %3272 to i8
  store i8 %3273, i8* %41, align 1, !tbaa !2450
  %3274 = sext i32 %3252 to i64
  store i64 %3274, i64* %RDX, align 8, !tbaa !2428
  %3275 = shl nsw i64 %3274, 3
  %3276 = add i64 %3247, %3275
  %3277 = add i64 %3223, 42
  store i64 %3277, i64* %PC, align 8
  %3278 = inttoptr i64 %3276 to double*
  store double %3243, double* %3278, align 8
  %3279 = load i64, i64* %RBP, align 8
  %3280 = add i64 %3279, -112
  %3281 = load i64, i64* %PC, align 8
  %3282 = add i64 %3281, 5
  store i64 %3282, i64* %PC, align 8
  %3283 = inttoptr i64 %3280 to i64*
  %3284 = load i64, i64* %3283, align 8
  store i64 %3284, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3285 = add i64 %3279, -152
  %3286 = add i64 %3281, 13
  store i64 %3286, i64* %PC, align 8
  %3287 = bitcast i64 %3284 to double
  %3288 = inttoptr i64 %3285 to double*
  %3289 = load double, double* %3288, align 8
  %3290 = fadd double %3287, %3289
  store double %3290, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3291 = add i64 %3279, -96
  %3292 = add i64 %3281, 18
  store i64 %3292, i64* %PC, align 8
  %3293 = inttoptr i64 %3291 to double*
  store double %3290, double* %3293, align 8
  %3294 = load i64, i64* %RBP, align 8
  %3295 = add i64 %3294, -120
  %3296 = load i64, i64* %PC, align 8
  %3297 = add i64 %3296, 5
  store i64 %3297, i64* %PC, align 8
  %3298 = inttoptr i64 %3295 to i64*
  %3299 = load i64, i64* %3298, align 8
  store i64 %3299, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3300 = add i64 %3294, -144
  %3301 = add i64 %3296, 13
  store i64 %3301, i64* %PC, align 8
  %3302 = bitcast i64 %3299 to double
  %3303 = inttoptr i64 %3300 to double*
  %3304 = load double, double* %3303, align 8
  %3305 = fsub double %3302, %3304
  store double %3305, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3306 = add i64 %3294, -104
  %3307 = add i64 %3296, 18
  store i64 %3307, i64* %PC, align 8
  %3308 = inttoptr i64 %3306 to double*
  store double %3305, double* %3308, align 8
  %3309 = load i64, i64* %RBP, align 8
  %3310 = add i64 %3309, -80
  %3311 = load i64, i64* %PC, align 8
  %3312 = add i64 %3311, 5
  store i64 %3312, i64* %PC, align 8
  %3313 = inttoptr i64 %3310 to i64*
  %3314 = load i64, i64* %3313, align 8
  store i64 %3314, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3315 = add i64 %3309, -96
  %3316 = add i64 %3311, 10
  store i64 %3316, i64* %PC, align 8
  %3317 = bitcast i64 %3314 to double
  %3318 = inttoptr i64 %3315 to double*
  %3319 = load double, double* %3318, align 8
  %3320 = fmul double %3317, %3319
  store double %3320, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3321 = add i64 %3309, -88
  %3322 = add i64 %3311, 15
  store i64 %3322, i64* %PC, align 8
  %3323 = inttoptr i64 %3321 to i64*
  %3324 = load i64, i64* %3323, align 8
  store i64 %3324, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %3325 = add i64 %3309, -104
  %3326 = add i64 %3311, 20
  store i64 %3326, i64* %PC, align 8
  %3327 = bitcast i64 %3324 to double
  %3328 = inttoptr i64 %3325 to double*
  %3329 = load double, double* %3328, align 8
  %3330 = fmul double %3327, %3329
  store double %3330, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %3331 = fsub double %3320, %3330
  store double %3331, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3332 = add i64 %3309, -16
  %3333 = add i64 %3311, 28
  store i64 %3333, i64* %PC, align 8
  %3334 = inttoptr i64 %3332 to i64*
  %3335 = load i64, i64* %3334, align 8
  store i64 %3335, i64* %RAX, align 8, !tbaa !2428
  %3336 = add i64 %3309, -28
  %3337 = add i64 %3311, 31
  store i64 %3337, i64* %PC, align 8
  %3338 = inttoptr i64 %3336 to i32*
  %3339 = load i32, i32* %3338, align 4
  %3340 = add i32 %3339, 14
  %3341 = zext i32 %3340 to i64
  store i64 %3341, i64* %RCX, align 8, !tbaa !2428
  %3342 = icmp ugt i32 %3339, -15
  %3343 = zext i1 %3342 to i8
  store i8 %3343, i8* %16, align 1, !tbaa !2433
  %3344 = and i32 %3340, 255
  %3345 = tail call i32 @llvm.ctpop.i32(i32 %3344) #10
  %3346 = trunc i32 %3345 to i8
  %3347 = and i8 %3346, 1
  %3348 = xor i8 %3347, 1
  store i8 %3348, i8* %23, align 1, !tbaa !2447
  %3349 = xor i32 %3340, %3339
  %3350 = lshr i32 %3349, 4
  %3351 = trunc i32 %3350 to i8
  %3352 = and i8 %3351, 1
  store i8 %3352, i8* %29, align 1, !tbaa !2451
  %3353 = icmp eq i32 %3340, 0
  %3354 = zext i1 %3353 to i8
  store i8 %3354, i8* %32, align 1, !tbaa !2448
  %3355 = lshr i32 %3340, 31
  %3356 = trunc i32 %3355 to i8
  store i8 %3356, i8* %35, align 1, !tbaa !2449
  %3357 = lshr i32 %3339, 31
  %3358 = xor i32 %3355, %3357
  %3359 = add nuw nsw i32 %3358, %3355
  %3360 = icmp eq i32 %3359, 2
  %3361 = zext i1 %3360 to i8
  store i8 %3361, i8* %41, align 1, !tbaa !2450
  %3362 = sext i32 %3340 to i64
  store i64 %3362, i64* %RDX, align 8, !tbaa !2428
  %3363 = shl nsw i64 %3362, 3
  %3364 = add i64 %3335, %3363
  %3365 = add i64 %3311, 42
  store i64 %3365, i64* %PC, align 8
  %3366 = inttoptr i64 %3364 to double*
  store double %3331, double* %3366, align 8
  %3367 = load i64, i64* %RBP, align 8
  %3368 = add i64 %3367, -80
  %3369 = load i64, i64* %PC, align 8
  %3370 = add i64 %3369, 5
  store i64 %3370, i64* %PC, align 8
  %3371 = inttoptr i64 %3368 to i64*
  %3372 = load i64, i64* %3371, align 8
  store i64 %3372, i64* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3373 = add i64 %3367, -104
  %3374 = add i64 %3369, 10
  store i64 %3374, i64* %PC, align 8
  %3375 = bitcast i64 %3372 to double
  %3376 = inttoptr i64 %3373 to double*
  %3377 = load double, double* %3376, align 8
  %3378 = fmul double %3375, %3377
  store double %3378, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3379 = add i64 %3367, -88
  %3380 = add i64 %3369, 15
  store i64 %3380, i64* %PC, align 8
  %3381 = inttoptr i64 %3379 to i64*
  %3382 = load i64, i64* %3381, align 8
  store i64 %3382, i64* %678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %680, align 1, !tbaa !2452
  %3383 = add i64 %3367, -96
  %3384 = add i64 %3369, 20
  store i64 %3384, i64* %PC, align 8
  %3385 = bitcast i64 %3382 to double
  %3386 = inttoptr i64 %3383 to double*
  %3387 = load double, double* %3386, align 8
  %3388 = fmul double %3385, %3387
  store double %3388, double* %677, align 1, !tbaa !2452
  store i64 0, i64* %679, align 1, !tbaa !2452
  %3389 = fadd double %3378, %3388
  store double %3389, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3390 = add i64 %3367, -16
  %3391 = add i64 %3369, 28
  store i64 %3391, i64* %PC, align 8
  %3392 = inttoptr i64 %3390 to i64*
  %3393 = load i64, i64* %3392, align 8
  store i64 %3393, i64* %RAX, align 8, !tbaa !2428
  %3394 = add i64 %3367, -28
  %3395 = add i64 %3369, 31
  store i64 %3395, i64* %PC, align 8
  %3396 = inttoptr i64 %3394 to i32*
  %3397 = load i32, i32* %3396, align 4
  %3398 = add i32 %3397, 15
  %3399 = zext i32 %3398 to i64
  store i64 %3399, i64* %RCX, align 8, !tbaa !2428
  %3400 = icmp ugt i32 %3397, -16
  %3401 = zext i1 %3400 to i8
  store i8 %3401, i8* %16, align 1, !tbaa !2433
  %3402 = and i32 %3398, 255
  %3403 = tail call i32 @llvm.ctpop.i32(i32 %3402) #10
  %3404 = trunc i32 %3403 to i8
  %3405 = and i8 %3404, 1
  %3406 = xor i8 %3405, 1
  store i8 %3406, i8* %23, align 1, !tbaa !2447
  %3407 = xor i32 %3398, %3397
  %3408 = lshr i32 %3407, 4
  %3409 = trunc i32 %3408 to i8
  %3410 = and i8 %3409, 1
  store i8 %3410, i8* %29, align 1, !tbaa !2451
  %3411 = icmp eq i32 %3398, 0
  %3412 = zext i1 %3411 to i8
  store i8 %3412, i8* %32, align 1, !tbaa !2448
  %3413 = lshr i32 %3398, 31
  %3414 = trunc i32 %3413 to i8
  store i8 %3414, i8* %35, align 1, !tbaa !2449
  %3415 = lshr i32 %3397, 31
  %3416 = xor i32 %3413, %3415
  %3417 = add nuw nsw i32 %3416, %3413
  %3418 = icmp eq i32 %3417, 2
  %3419 = zext i1 %3418 to i8
  store i8 %3419, i8* %41, align 1, !tbaa !2450
  %3420 = sext i32 %3398 to i64
  store i64 %3420, i64* %RDX, align 8, !tbaa !2428
  %3421 = shl nsw i64 %3420, 3
  %3422 = add i64 %3393, %3421
  %3423 = add i64 %3369, 42
  store i64 %3423, i64* %PC, align 8
  %3424 = inttoptr i64 %3422 to double*
  store double %3389, double* %3424, align 8
  %3425 = load i64, i64* %RBP, align 8
  %3426 = add i64 %3425, -28
  %3427 = load i64, i64* %PC, align 8
  %3428 = add i64 %3427, 3
  store i64 %3428, i64* %PC, align 8
  %3429 = inttoptr i64 %3426 to i32*
  %3430 = load i32, i32* %3429, align 4
  %3431 = add i32 %3430, 16
  %3432 = zext i32 %3431 to i64
  store i64 %3432, i64* %RAX, align 8, !tbaa !2428
  %3433 = icmp ugt i32 %3430, -17
  %3434 = zext i1 %3433 to i8
  store i8 %3434, i8* %16, align 1, !tbaa !2433
  %3435 = and i32 %3431, 255
  %3436 = tail call i32 @llvm.ctpop.i32(i32 %3435) #10
  %3437 = trunc i32 %3436 to i8
  %3438 = and i8 %3437, 1
  %3439 = xor i8 %3438, 1
  store i8 %3439, i8* %23, align 1, !tbaa !2447
  %3440 = xor i32 %3430, 16
  %3441 = xor i32 %3440, %3431
  %3442 = lshr i32 %3441, 4
  %3443 = trunc i32 %3442 to i8
  %3444 = and i8 %3443, 1
  store i8 %3444, i8* %29, align 1, !tbaa !2451
  %3445 = icmp eq i32 %3431, 0
  %3446 = zext i1 %3445 to i8
  store i8 %3446, i8* %32, align 1, !tbaa !2448
  %3447 = lshr i32 %3431, 31
  %3448 = trunc i32 %3447 to i8
  store i8 %3448, i8* %35, align 1, !tbaa !2449
  %3449 = lshr i32 %3430, 31
  %3450 = xor i32 %3447, %3449
  %3451 = add nuw nsw i32 %3450, %3447
  %3452 = icmp eq i32 %3451, 2
  %3453 = zext i1 %3452 to i8
  store i8 %3453, i8* %41, align 1, !tbaa !2450
  %3454 = add i64 %3427, 9
  store i64 %3454, i64* %PC, align 8
  store i32 %3431, i32* %3429, align 4
  %3455 = load i64, i64* %PC, align 8
  %3456 = add i64 %3455, -1815
  store i64 %3456, i64* %PC, align 8, !tbaa !2428
  br label %block_402bf2

block_402bf2:                                     ; preds = %block_402bfe, %block_402890
  %3457 = phi i64 [ %3456, %block_402bfe ], [ %.pre, %block_402890 ]
  %3458 = load i64, i64* %RBP, align 8
  %3459 = add i64 %3458, -28
  %3460 = add i64 %3457, 3
  store i64 %3460, i64* %PC, align 8
  %3461 = inttoptr i64 %3459 to i32*
  %3462 = load i32, i32* %3461, align 4
  %3463 = zext i32 %3462 to i64
  store i64 %3463, i64* %RAX, align 8, !tbaa !2428
  %3464 = add i64 %3458, -4
  %3465 = add i64 %3457, 6
  store i64 %3465, i64* %PC, align 8
  %3466 = inttoptr i64 %3464 to i32*
  %3467 = load i32, i32* %3466, align 4
  %3468 = sub i32 %3462, %3467
  %3469 = icmp ult i32 %3462, %3467
  %3470 = zext i1 %3469 to i8
  store i8 %3470, i8* %16, align 1, !tbaa !2433
  %3471 = and i32 %3468, 255
  %3472 = tail call i32 @llvm.ctpop.i32(i32 %3471) #10
  %3473 = trunc i32 %3472 to i8
  %3474 = and i8 %3473, 1
  %3475 = xor i8 %3474, 1
  store i8 %3475, i8* %23, align 1, !tbaa !2447
  %3476 = xor i32 %3467, %3462
  %3477 = xor i32 %3476, %3468
  %3478 = lshr i32 %3477, 4
  %3479 = trunc i32 %3478 to i8
  %3480 = and i8 %3479, 1
  store i8 %3480, i8* %29, align 1, !tbaa !2451
  %3481 = icmp eq i32 %3468, 0
  %3482 = zext i1 %3481 to i8
  store i8 %3482, i8* %32, align 1, !tbaa !2448
  %3483 = lshr i32 %3468, 31
  %3484 = trunc i32 %3483 to i8
  store i8 %3484, i8* %35, align 1, !tbaa !2449
  %3485 = lshr i32 %3462, 31
  %3486 = lshr i32 %3467, 31
  %3487 = xor i32 %3486, %3485
  %3488 = xor i32 %3483, %3485
  %3489 = add nuw nsw i32 %3488, %3487
  %3490 = icmp eq i32 %3489, 2
  %3491 = zext i1 %3490 to i8
  store i8 %3491, i8* %41, align 1, !tbaa !2450
  %3492 = icmp ne i8 %3484, 0
  %3493 = xor i1 %3492, %3490
  %.v = select i1 %3493, i64 12, i64 1820
  %3494 = add i64 %3457, %.v
  store i64 %3494, i64* %PC, align 8, !tbaa !2428
  br i1 %3493, label %block_402bfe, label %block_40330e

block_40330e:                                     ; preds = %block_402bf2
  %3495 = load i64, i64* %RSP, align 8
  %3496 = add i64 %3495, 24
  store i64 %3496, i64* %RSP, align 8, !tbaa !2428
  %3497 = icmp ugt i64 %3495, -25
  %3498 = zext i1 %3497 to i8
  store i8 %3498, i8* %16, align 1, !tbaa !2433
  %3499 = trunc i64 %3496 to i32
  %3500 = and i32 %3499, 255
  %3501 = tail call i32 @llvm.ctpop.i32(i32 %3500) #10
  %3502 = trunc i32 %3501 to i8
  %3503 = and i8 %3502, 1
  %3504 = xor i8 %3503, 1
  store i8 %3504, i8* %23, align 1, !tbaa !2447
  %3505 = xor i64 %3495, 16
  %3506 = xor i64 %3505, %3496
  %3507 = lshr i64 %3506, 4
  %3508 = trunc i64 %3507 to i8
  %3509 = and i8 %3508, 1
  store i8 %3509, i8* %29, align 1, !tbaa !2451
  %3510 = icmp eq i64 %3496, 0
  %3511 = zext i1 %3510 to i8
  store i8 %3511, i8* %32, align 1, !tbaa !2448
  %3512 = lshr i64 %3496, 63
  %3513 = trunc i64 %3512 to i8
  store i8 %3513, i8* %35, align 1, !tbaa !2449
  %3514 = lshr i64 %3495, 63
  %3515 = xor i64 %3512, %3514
  %3516 = add nuw nsw i64 %3515, %3512
  %3517 = icmp eq i64 %3516, 2
  %3518 = zext i1 %3517 to i8
  store i8 %3518, i8* %41, align 1, !tbaa !2450
  %3519 = add i64 %3494, 5
  store i64 %3519, i64* %PC, align 8
  %3520 = add i64 %3495, 32
  %3521 = inttoptr i64 %3496 to i64*
  %3522 = load i64, i64* %3521, align 8
  store i64 %3522, i64* %RBP, align 8, !tbaa !2428
  store i64 %3520, i64* %RSP, align 8, !tbaa !2428
  %3523 = add i64 %3494, 6
  store i64 %3523, i64* %PC, align 8
  %3524 = inttoptr i64 %3520 to i64*
  %3525 = load i64, i64* %3524, align 8
  store i64 %3525, i64* %PC, align 8, !tbaa !2428
  %3526 = add i64 %3495, 40
  store i64 %3526, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_401050_cdft(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #7 {
block_401050:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -40
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 32
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2433
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #10
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2447
  %22 = xor i64 %8, %11
  %23 = lshr i64 %22, 4
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1, !tbaa !2451
  %27 = icmp eq i64 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1, !tbaa !2448
  %30 = lshr i64 %11, 63
  %31 = trunc i64 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1, !tbaa !2449
  %33 = lshr i64 %8, 63
  %34 = xor i64 %30, %33
  %35 = add nuw nsw i64 %34, %33
  %36 = icmp eq i64 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1, !tbaa !2450
  %39 = add i64 %7, -12
  %40 = load i32, i32* %EDI, align 4
  %41 = add i64 %10, 10
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %39 to i32*
  store i32 %40, i32* %42, align 4
  %43 = load i64, i64* %RBP, align 8
  %44 = add i64 %43, -8
  %45 = load i32, i32* %ESI, align 4
  %46 = load i64, i64* %PC, align 8
  %47 = add i64 %46, 3
  store i64 %47, i64* %PC, align 8
  %48 = inttoptr i64 %44 to i32*
  store i32 %45, i32* %48, align 4
  %49 = load i64, i64* %RBP, align 8
  %50 = add i64 %49, -16
  %51 = load i64, i64* %RDX, align 8
  %52 = load i64, i64* %PC, align 8
  %53 = add i64 %52, 4
  store i64 %53, i64* %PC, align 8
  %54 = inttoptr i64 %50 to i64*
  store i64 %51, i64* %54, align 8
  %55 = load i64, i64* %RBP, align 8
  %56 = add i64 %55, -24
  %57 = load i64, i64* %RCX, align 8
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 4
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %56 to i64*
  store i64 %57, i64* %60, align 8
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -32
  %63 = load i64, i64* %R8, align 8
  %64 = load i64, i64* %PC, align 8
  %65 = add i64 %64, 4
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %62 to i64*
  store i64 %63, i64* %66, align 8
  %67 = load i64, i64* %RBP, align 8
  %68 = add i64 %67, -4
  %69 = load i64, i64* %PC, align 8
  %70 = add i64 %69, 4
  store i64 %70, i64* %PC, align 8
  %71 = inttoptr i64 %68 to i32*
  %72 = load i32, i32* %71, align 4
  %73 = add i32 %72, -4
  %74 = icmp ult i32 %72, 4
  %75 = zext i1 %74 to i8
  store i8 %75, i8* %14, align 1, !tbaa !2433
  %76 = and i32 %73, 255
  %77 = tail call i32 @llvm.ctpop.i32(i32 %76) #10
  %78 = trunc i32 %77 to i8
  %79 = and i8 %78, 1
  %80 = xor i8 %79, 1
  store i8 %80, i8* %21, align 1, !tbaa !2447
  %81 = xor i32 %73, %72
  %82 = lshr i32 %81, 4
  %83 = trunc i32 %82 to i8
  %84 = and i8 %83, 1
  store i8 %84, i8* %26, align 1, !tbaa !2451
  %85 = icmp eq i32 %73, 0
  %86 = zext i1 %85 to i8
  store i8 %86, i8* %29, align 1, !tbaa !2448
  %87 = lshr i32 %73, 31
  %88 = trunc i32 %87 to i8
  store i8 %88, i8* %32, align 1, !tbaa !2449
  %89 = lshr i32 %72, 31
  %90 = xor i32 %87, %89
  %91 = add nuw nsw i32 %90, %89
  %92 = icmp eq i32 %91, 2
  %93 = zext i1 %92 to i8
  store i8 %93, i8* %38, align 1, !tbaa !2450
  %94 = icmp ne i8 %88, 0
  %95 = xor i1 %94, %92
  %96 = or i1 %85, %95
  %.v8 = select i1 %96, i64 94, i64 10
  %97 = add i64 %69, %.v8
  store i64 %97, i64* %PC, align 8, !tbaa !2428
  br i1 %96, label %block_4010c8, label %block_401074

block_40107e:                                     ; preds = %block_401074
  %98 = add i64 %242, 354
  %99 = add i64 %242, 16
  %100 = load i64, i64* %RSP, align 8, !tbaa !2428
  %101 = add i64 %100, -8
  %102 = inttoptr i64 %101 to i64*
  store i64 %99, i64* %102, align 8
  store i64 %101, i64* %RSP, align 8, !tbaa !2428
  store i64 %98, i64* %PC, align 8, !tbaa !2428
  %103 = tail call %struct.Memory* @sub_4011e0_bitrv2(%struct.State* nonnull %0, i64 %98, %struct.Memory* %2)
  %104 = load i64, i64* %RBP, align 8
  %105 = add i64 %104, -4
  %106 = load i64, i64* %PC, align 8
  %107 = add i64 %106, 3
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %105 to i32*
  %109 = load i32, i32* %108, align 4
  %110 = zext i32 %109 to i64
  store i64 %110, i64* %RDI, align 8, !tbaa !2428
  %111 = add i64 %104, -16
  %112 = add i64 %106, 7
  store i64 %112, i64* %PC, align 8
  %113 = inttoptr i64 %111 to i64*
  %114 = load i64, i64* %113, align 8
  store i64 %114, i64* %RSI, align 8, !tbaa !2428
  %115 = add i64 %104, -32
  %116 = add i64 %106, 11
  store i64 %116, i64* %PC, align 8
  %117 = inttoptr i64 %115 to i64*
  %118 = load i64, i64* %117, align 8
  store i64 %118, i64* %RDX, align 8, !tbaa !2428
  %119 = add i64 %106, 2002
  %120 = add i64 %106, 16
  %121 = load i64, i64* %RSP, align 8, !tbaa !2428
  %122 = add i64 %121, -8
  %123 = inttoptr i64 %122 to i64*
  store i64 %120, i64* %123, align 8
  store i64 %122, i64* %RSP, align 8, !tbaa !2428
  store i64 %119, i64* %PC, align 8, !tbaa !2428
  %124 = tail call %struct.Memory* @sub_401860_cftfsub(%struct.State* nonnull %0, i64 %119, %struct.Memory* %103)
  %125 = load i64, i64* %PC, align 8
  %126 = add i64 %125, 37
  store i64 %126, i64* %PC, align 8, !tbaa !2428
  br label %block_4010e7

block_4010d2:                                     ; preds = %block_4010c8
  %127 = add i64 %167, 3
  store i64 %127, i64* %PC, align 8
  %128 = load i32, i32* %71, align 4
  %129 = zext i32 %128 to i64
  store i64 %129, i64* %RDI, align 8, !tbaa !2428
  %130 = add i64 %67, -16
  %131 = add i64 %167, 7
  store i64 %131, i64* %PC, align 8
  %132 = inttoptr i64 %130 to i64*
  %133 = load i64, i64* %132, align 8
  store i64 %133, i64* %RSI, align 8, !tbaa !2428
  %134 = add i64 %67, -32
  %135 = add i64 %167, 11
  store i64 %135, i64* %PC, align 8
  %136 = inttoptr i64 %134 to i64*
  %137 = load i64, i64* %136, align 8
  store i64 %137, i64* %RDX, align 8, !tbaa !2428
  %138 = add i64 %167, 1934
  %139 = add i64 %167, 16
  %140 = load i64, i64* %RSP, align 8, !tbaa !2428
  %141 = add i64 %140, -8
  %142 = inttoptr i64 %141 to i64*
  store i64 %139, i64* %142, align 8
  store i64 %141, i64* %RSP, align 8, !tbaa !2428
  store i64 %138, i64* %PC, align 8, !tbaa !2428
  %143 = tail call %struct.Memory* @sub_401860_cftfsub(%struct.State* nonnull %0, i64 %138, %struct.Memory* %2)
  br label %block_4010e7

block_4010c8:                                     ; preds = %block_401050
  %144 = add i64 %97, 4
  store i64 %144, i64* %PC, align 8
  %145 = load i32, i32* %71, align 4
  %146 = add i32 %145, -4
  %147 = icmp ult i32 %145, 4
  %148 = zext i1 %147 to i8
  store i8 %148, i8* %14, align 1, !tbaa !2433
  %149 = and i32 %146, 255
  %150 = tail call i32 @llvm.ctpop.i32(i32 %149) #10
  %151 = trunc i32 %150 to i8
  %152 = and i8 %151, 1
  %153 = xor i8 %152, 1
  store i8 %153, i8* %21, align 1, !tbaa !2447
  %154 = xor i32 %146, %145
  %155 = lshr i32 %154, 4
  %156 = trunc i32 %155 to i8
  %157 = and i8 %156, 1
  store i8 %157, i8* %26, align 1, !tbaa !2451
  %158 = icmp eq i32 %146, 0
  %159 = zext i1 %158 to i8
  store i8 %159, i8* %29, align 1, !tbaa !2448
  %160 = lshr i32 %146, 31
  %161 = trunc i32 %160 to i8
  store i8 %161, i8* %32, align 1, !tbaa !2449
  %162 = lshr i32 %145, 31
  %163 = xor i32 %160, %162
  %164 = add nuw nsw i32 %163, %162
  %165 = icmp eq i32 %164, 2
  %166 = zext i1 %165 to i8
  store i8 %166, i8* %38, align 1, !tbaa !2450
  %.v9 = select i1 %158, i64 10, i64 26
  %167 = add i64 %97, %.v9
  store i64 %167, i64* %PC, align 8, !tbaa !2428
  br i1 %158, label %block_4010d2, label %block_4010e7

block_4010e7:                                     ; preds = %block_4010c8, %block_40107e, %block_4010a3, %block_4010d2
  %.sink5 = phi i64 [ 5, %block_4010c8 ], [ 5, %block_4010d2 ], [ 36, %block_4010a3 ], [ 36, %block_40107e ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_4010c8 ], [ %143, %block_4010d2 ], [ %227, %block_4010a3 ], [ %124, %block_40107e ]
  %168 = load i64, i64* %PC, align 8
  %169 = add i64 %168, %.sink5
  %170 = load i64, i64* %RSP, align 8
  %171 = add i64 %170, 32
  store i64 %171, i64* %RSP, align 8, !tbaa !2428
  %172 = icmp ugt i64 %170, -33
  %173 = zext i1 %172 to i8
  store i8 %173, i8* %14, align 1, !tbaa !2433
  %174 = trunc i64 %171 to i32
  %175 = and i32 %174, 255
  %176 = tail call i32 @llvm.ctpop.i32(i32 %175) #10
  %177 = trunc i32 %176 to i8
  %178 = and i8 %177, 1
  %179 = xor i8 %178, 1
  store i8 %179, i8* %21, align 1, !tbaa !2447
  %180 = xor i64 %171, %170
  %181 = lshr i64 %180, 4
  %182 = trunc i64 %181 to i8
  %183 = and i8 %182, 1
  store i8 %183, i8* %26, align 1, !tbaa !2451
  %184 = icmp eq i64 %171, 0
  %185 = zext i1 %184 to i8
  store i8 %185, i8* %29, align 1, !tbaa !2448
  %186 = lshr i64 %171, 63
  %187 = trunc i64 %186 to i8
  store i8 %187, i8* %32, align 1, !tbaa !2449
  %188 = lshr i64 %170, 63
  %189 = xor i64 %186, %188
  %190 = add nuw nsw i64 %189, %186
  %191 = icmp eq i64 %190, 2
  %192 = zext i1 %191 to i8
  store i8 %192, i8* %38, align 1, !tbaa !2450
  %193 = add i64 %169, 5
  store i64 %193, i64* %PC, align 8
  %194 = add i64 %170, 40
  %195 = inttoptr i64 %171 to i64*
  %196 = load i64, i64* %195, align 8
  store i64 %196, i64* %RBP, align 8, !tbaa !2428
  store i64 %194, i64* %RSP, align 8, !tbaa !2428
  %197 = add i64 %169, 6
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %194 to i64*
  %199 = load i64, i64* %198, align 8
  store i64 %199, i64* %PC, align 8, !tbaa !2428
  %200 = add i64 %170, 48
  store i64 %200, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_4010a3:                                     ; preds = %block_401074
  %201 = add i64 %242, 2909
  %202 = add i64 %242, 16
  %203 = load i64, i64* %RSP, align 8, !tbaa !2428
  %204 = add i64 %203, -8
  %205 = inttoptr i64 %204 to i64*
  store i64 %202, i64* %205, align 8
  store i64 %204, i64* %RSP, align 8, !tbaa !2428
  store i64 %201, i64* %PC, align 8, !tbaa !2428
  %206 = tail call %struct.Memory* @sub_401c00_bitrv2conj(%struct.State* nonnull %0, i64 %201, %struct.Memory* %2)
  %207 = load i64, i64* %RBP, align 8
  %208 = add i64 %207, -4
  %209 = load i64, i64* %PC, align 8
  %210 = add i64 %209, 3
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %208 to i32*
  %212 = load i32, i32* %211, align 4
  %213 = zext i32 %212 to i64
  store i64 %213, i64* %RDI, align 8, !tbaa !2428
  %214 = add i64 %207, -16
  %215 = add i64 %209, 7
  store i64 %215, i64* %PC, align 8
  %216 = inttoptr i64 %214 to i64*
  %217 = load i64, i64* %216, align 8
  store i64 %217, i64* %RSI, align 8, !tbaa !2428
  %218 = add i64 %207, -32
  %219 = add i64 %209, 11
  store i64 %219, i64* %PC, align 8
  %220 = inttoptr i64 %218 to i64*
  %221 = load i64, i64* %220, align 8
  store i64 %221, i64* %RDX, align 8, !tbaa !2428
  %222 = add i64 %209, 5101
  %223 = add i64 %209, 16
  %224 = load i64, i64* %RSP, align 8, !tbaa !2428
  %225 = add i64 %224, -8
  %226 = inttoptr i64 %225 to i64*
  store i64 %223, i64* %226, align 8
  store i64 %225, i64* %RSP, align 8, !tbaa !2428
  store i64 %222, i64* %PC, align 8, !tbaa !2428
  %227 = tail call %struct.Memory* @sub_4024a0_cftbsub(%struct.State* nonnull %0, i64 %222, %struct.Memory* %206)
  br label %block_4010e7

block_401074:                                     ; preds = %block_401050
  %228 = add i64 %67, -8
  %229 = add i64 %97, 4
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %228 to i32*
  %231 = load i32, i32* %230, align 4
  store i8 0, i8* %14, align 1, !tbaa !2433
  %232 = and i32 %231, 255
  %233 = tail call i32 @llvm.ctpop.i32(i32 %232) #10
  %234 = trunc i32 %233 to i8
  %235 = and i8 %234, 1
  %236 = xor i8 %235, 1
  store i8 %236, i8* %21, align 1, !tbaa !2447
  store i8 0, i8* %26, align 1, !tbaa !2451
  %237 = icmp eq i32 %231, 0
  %238 = zext i1 %237 to i8
  store i8 %238, i8* %29, align 1, !tbaa !2448
  %239 = lshr i32 %231, 31
  %240 = trunc i32 %239 to i8
  store i8 %240, i8* %32, align 1, !tbaa !2449
  store i8 0, i8* %38, align 1, !tbaa !2450
  %241 = icmp ne i8 %240, 0
  %.v = select i1 %241, i64 43, i64 6
  %242 = add i64 %229, %.v
  %243 = add i64 %242, 3
  store i64 %243, i64* %PC, align 8
  %244 = load i32, i32* %71, align 4
  %245 = zext i32 %244 to i64
  store i64 %245, i64* %RDI, align 8, !tbaa !2428
  %246 = add i64 %67, -24
  %247 = add i64 %242, 7
  store i64 %247, i64* %PC, align 8
  %248 = inttoptr i64 %246 to i64*
  %249 = load i64, i64* %248, align 8
  store i64 %249, i64* %RSI, align 8, !tbaa !2428
  %250 = add i64 %67, -16
  %251 = add i64 %242, 11
  store i64 %251, i64* %PC, align 8
  %252 = inttoptr i64 %250 to i64*
  %253 = load i64, i64* %252, align 8
  store i64 %253, i64* %RDX, align 8, !tbaa !2428
  br i1 %241, label %block_4010a3, label %block_40107e
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400e20_get_time(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400e20:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %19 = add i64 %9, -24
  store i64 %19, i64* %RDI, align 8, !tbaa !2428
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %13, align 1, !tbaa !2433
  store i8 1, i8* %14, align 1, !tbaa !2447
  store i8 1, i8* %16, align 1, !tbaa !2448
  store i8 0, i8* %17, align 1, !tbaa !2449
  store i8 0, i8* %18, align 1, !tbaa !2450
  store i8 0, i8* %15, align 1, !tbaa !2451
  store i64 0, i64* %RSI, align 8, !tbaa !2428
  %20 = add i64 %12, -1857
  %21 = add i64 %12, 20
  %22 = add i64 %9, -48
  %23 = inttoptr i64 %22 to i64*
  store i64 %21, i64* %23, align 8
  store i64 %22, i64* %RSP, align 8, !tbaa !2428
  store i64 %20, i64* %PC, align 8, !tbaa !2428
  %24 = tail call fastcc %struct.Memory* @ext_4006e0_gettimeofday(%struct.State* nonnull %0, %struct.Memory* %2)
  %25 = bitcast [32 x %union.VectorReg]* %4 to i8*
  %26 = load i64, i64* %PC, align 8
  %27 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 56) to i64*), align 8
  %28 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %27, i64* %28, align 1, !tbaa !2452
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %30 = bitcast i64* %29 to double*
  store double 0.000000e+00, double* %30, align 1, !tbaa !2452
  %31 = load i64, i64* %RBP, align 8
  %32 = add i64 %31, -16
  %33 = add i64 %26, 14
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = sitofp i64 %35 to double
  %37 = bitcast %union.VectorReg* %5 to double*
  store double %36, double* %37, align 1, !tbaa !2452
  %38 = add i64 %31, -8
  %39 = add i64 %26, 20
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %38 to i64*
  %41 = load i64, i64* %40, align 8
  %42 = sitofp i64 %41 to double
  %43 = bitcast %union.VectorReg* %6 to double*
  %44 = bitcast i64 %27 to double
  %45 = fmul double %42, %44
  store double %45, double* %43, align 1, !tbaa !2452
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %47 = bitcast i64* %46 to <2 x i32>*
  %48 = load <2 x i32>, <2 x i32>* %47, align 1
  %49 = fadd double %36, %45
  store double %49, double* %37, align 1, !tbaa !2452
  %.cast = bitcast double %49 to <2 x i32>
  %50 = extractelement <2 x i32> %.cast, i32 0
  %51 = bitcast [32 x %union.VectorReg]* %4 to i32*
  store i32 %50, i32* %51, align 1, !tbaa !2454
  %52 = extractelement <2 x i32> %.cast, i32 1
  %53 = getelementptr inbounds i8, i8* %25, i64 4
  %54 = bitcast i8* %53 to i32*
  store i32 %52, i32* %54, align 1, !tbaa !2454
  %55 = extractelement <2 x i32> %48, i32 0
  %56 = bitcast i64* %29 to i32*
  store i32 %55, i32* %56, align 1, !tbaa !2454
  %57 = extractelement <2 x i32> %48, i32 1
  %58 = getelementptr inbounds i8, i8* %25, i64 12
  %59 = bitcast i8* %58 to i32*
  store i32 %57, i32* %59, align 1, !tbaa !2454
  %60 = add i64 %31, -20
  %61 = load i32, i32* %EAX, align 4
  %62 = add i64 %26, 34
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %60 to i32*
  store i32 %61, i32* %63, align 4
  %64 = load i64, i64* %RSP, align 8
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %64, 32
  store i64 %66, i64* %RSP, align 8, !tbaa !2428
  %67 = icmp ugt i64 %64, -33
  %68 = zext i1 %67 to i8
  store i8 %68, i8* %13, align 1, !tbaa !2433
  %69 = trunc i64 %66 to i32
  %70 = and i32 %69, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #10
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %14, align 1, !tbaa !2447
  %75 = xor i64 %66, %64
  %76 = lshr i64 %75, 4
  %77 = trunc i64 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %15, align 1, !tbaa !2451
  %79 = icmp eq i64 %66, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %16, align 1, !tbaa !2448
  %81 = lshr i64 %66, 63
  %82 = trunc i64 %81 to i8
  store i8 %82, i8* %17, align 1, !tbaa !2449
  %83 = lshr i64 %64, 63
  %84 = xor i64 %81, %83
  %85 = add nuw nsw i64 %84, %81
  %86 = icmp eq i64 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %18, align 1, !tbaa !2450
  %88 = add i64 %65, 5
  store i64 %88, i64* %PC, align 8
  %89 = add i64 %64, 40
  %90 = inttoptr i64 %66 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %RBP, align 8, !tbaa !2428
  store i64 %89, i64* %RSP, align 8, !tbaa !2428
  %92 = add i64 %65, 6
  store i64 %92, i64* %PC, align 8
  %93 = inttoptr i64 %89 to i64*
  %94 = load i64, i64* %93, align 8
  store i64 %94, i64* %PC, align 8, !tbaa !2428
  %95 = add i64 %64, 48
  store i64 %95, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %24
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400840_main(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400840:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %4 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %9 = load i64, i64* %RBP, align 8
  %10 = add i64 %1, 1
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %RSP, align 8, !tbaa !2428
  %12 = add i64 %11, -8
  %13 = inttoptr i64 %12 to i64*
  store i64 %9, i64* %13, align 8
  %14 = load i64, i64* %PC, align 8
  store i64 %12, i64* %RBP, align 8, !tbaa !2428
  %15 = add i64 %11, -232
  store i64 %15, i64* %RSP, align 8, !tbaa !2428
  %16 = icmp ult i64 %12, 224
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1, !tbaa !2433
  %19 = trunc i64 %15 to i32
  %20 = and i32 %19, 255
  %21 = tail call i32 @llvm.ctpop.i32(i32 %20) #10
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = xor i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %24, i8* %25, align 1, !tbaa !2447
  %26 = xor i64 %12, %15
  %27 = lshr i64 %26, 4
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1, !tbaa !2451
  %31 = icmp eq i64 %15, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1, !tbaa !2448
  %34 = lshr i64 %15, 63
  %35 = trunc i64 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1, !tbaa !2449
  %37 = lshr i64 %12, 63
  %38 = xor i64 %34, %37
  %39 = add nuw nsw i64 %38, %37
  %40 = icmp eq i64 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1, !tbaa !2450
  store i64 16, i64* %RAX, align 8, !tbaa !2428
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  %43 = add i64 %11, -12
  %44 = add i64 %14, 24
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %43 to i32*
  store i32 0, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -88
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 8
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %47 to i64*
  store i64 0, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -144
  %53 = load i64, i64* %RDI, align 8
  %54 = load i64, i64* %PC, align 8
  %55 = add i64 %54, 7
  store i64 %55, i64* %PC, align 8
  %56 = inttoptr i64 %52 to i64*
  store i64 %53, i64* %56, align 8
  %57 = load i64, i64* %PC, align 8
  %58 = add i64 %57, 1464
  %59 = add i64 %57, 5
  %60 = load i64, i64* %RSP, align 8, !tbaa !2428
  %61 = add i64 %60, -8
  %62 = inttoptr i64 %61 to i64*
  store i64 %59, i64* %62, align 8
  store i64 %61, i64* %RSP, align 8, !tbaa !2428
  store i64 %58, i64* %PC, align 8, !tbaa !2428
  %63 = tail call %struct.Memory* @sub_400e20_get_time(%struct.State* nonnull %0, i64 %58, %struct.Memory* %2)
  %64 = load i64, i64* %RBP, align 8
  %65 = add i64 %64, -64
  %66 = load i64, i64* %PC, align 8
  %67 = add i64 %66, 5
  store i64 %67, i64* %PC, align 8
  %68 = bitcast [32 x %union.VectorReg]* %5 to double*
  %69 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %70 = load i64, i64* %69, align 1
  %71 = inttoptr i64 %65 to i64*
  store i64 %70, i64* %71, align 8
  %72 = load i64, i64* %PC, align 8
  %73 = add i64 %72, 1454
  %74 = add i64 %72, 5
  %75 = load i64, i64* %RSP, align 8, !tbaa !2428
  %76 = add i64 %75, -8
  %77 = inttoptr i64 %76 to i64*
  store i64 %74, i64* %77, align 8
  store i64 %76, i64* %RSP, align 8, !tbaa !2428
  store i64 %73, i64* %PC, align 8, !tbaa !2428
  %78 = tail call %struct.Memory* @sub_400e20_get_time(%struct.State* nonnull %0, i64 %73, %struct.Memory* %63)
  %79 = load i64, i64* %RBP, align 8
  %80 = add i64 %79, -72
  %81 = load i64, i64* %PC, align 8
  %82 = add i64 %81, 5
  store i64 %82, i64* %PC, align 8
  %83 = load i64, i64* %69, align 1
  %84 = inttoptr i64 %80 to i64*
  store i64 %83, i64* %84, align 8
  %85 = bitcast [32 x %union.VectorReg]* %5 to i8*
  %86 = load i64, i64* %RBP, align 8
  %87 = add i64 %86, -72
  %88 = load i64, i64* %PC, align 8
  %89 = add i64 %88, 5
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %87 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %69, align 1, !tbaa !2452
  %92 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %93 = bitcast i64* %92 to double*
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %94 = bitcast %union.VectorReg* %6 to i8*
  %95 = add i64 %86, -64
  %96 = add i64 %88, 10
  store i64 %96, i64* %PC, align 8
  %97 = inttoptr i64 %95 to i64*
  %98 = load i64, i64* %97, align 8
  %99 = bitcast %union.VectorReg* %6 to double*
  %100 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %98, i64* %100, align 1, !tbaa !2452
  %101 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %102 = bitcast i64* %101 to double*
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %103 = bitcast i64 %91 to double
  %104 = bitcast i64 %98 to double
  %105 = fsub double %103, %104
  %106 = add i64 %86, -80
  %107 = add i64 %88, 19
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %106 to double*
  store double %105, double* %108, align 8
  %109 = load i64, i64* %PC, align 8
  %110 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 24) to i64*), align 8
  store i64 %110, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %111 = add i64 %109, -335
  %112 = add i64 %109, 13
  %113 = load i64, i64* %RSP, align 8, !tbaa !2428
  %114 = add i64 %113, -8
  %115 = inttoptr i64 %114 to i64*
  store i64 %112, i64* %115, align 8
  store i64 %114, i64* %RSP, align 8, !tbaa !2428
  store i64 %111, i64* %PC, align 8, !tbaa !2428
  %116 = load double, double* %68, align 8, !alias.scope !2456, !noalias !2459
  %117 = load i64, i64* %115, align 8
  store i64 %113, i64* %RSP, align 8, !alias.scope !2456, !noalias !2459
  %118 = tail call double @sqrt(double %116)
  %119 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  %120 = bitcast i64* %119 to i8*
  call void @llvm.memset.p0i8.i64(i8* %120, i8 0, i64 16, i32 8, i1 false)
  %121 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 32) to double*), align 16
  %122 = fmul double %121, %118
  store double %122, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %92, align 1, !tbaa !2452
  %123 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 40) to i64*), align 8
  store i64 %123, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %124 = bitcast %union.VectorReg* %7 to i8*
  %125 = bitcast double %122 to <2 x i32>
  %126 = extractelement <2 x i32> %125, i32 0
  %127 = bitcast %union.VectorReg* %7 to i32*
  store i32 %126, i32* %127, align 1, !tbaa !2454
  %128 = extractelement <2 x i32> %125, i32 1
  %129 = getelementptr inbounds i8, i8* %124, i64 4
  %130 = bitcast i8* %129 to i32*
  store i32 %128, i32* %130, align 1, !tbaa !2454
  %131 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %132 = bitcast i64* %131 to i32*
  store i32 0, i32* %132, align 1, !tbaa !2454
  %133 = getelementptr inbounds i8, i8* %124, i64 12
  %134 = bitcast i8* %133 to i32*
  store i32 0, i32* %134, align 1, !tbaa !2454
  %135 = bitcast %union.VectorReg* %7 to double*
  %136 = load double, double* %135, align 1
  %137 = bitcast i64 %123 to double
  %138 = fsub double %136, %137
  store double %138, double* %135, align 1, !tbaa !2452
  %139 = tail call double @llvm.trunc.f64(double %138) #10
  %140 = tail call double @llvm.fabs.f64(double %139) #10
  %141 = fcmp ogt double %140, 0x43E0000000000000
  %142 = fptosi double %139 to i64
  %143 = select i1 %141, i64 -9223372036854775808, i64 %142
  %144 = xor i64 %143, -9223372036854775808
  store i64 %144, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %145 = trunc i64 %143 to i32
  %146 = and i32 %145, 255
  %147 = tail call i32 @llvm.ctpop.i32(i32 %146) #10
  %148 = trunc i32 %147 to i8
  %149 = and i8 %148, 1
  %150 = xor i8 %149, 1
  store i8 %150, i8* %25, align 1, !tbaa !2447
  %151 = icmp eq i64 %144, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %33, align 1, !tbaa !2448
  %153 = lshr i64 %144, 63
  %154 = trunc i64 %153 to i8
  store i8 %154, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  %155 = tail call double @llvm.trunc.f64(double %122) #10
  %156 = tail call double @llvm.fabs.f64(double %155) #10
  %157 = fcmp ogt double %156, 0x43E0000000000000
  %158 = fptosi double %155 to i64
  %159 = select i1 %157, i64 -9223372036854775808, i64 %158
  store i64 %159, i64* %RCX, align 8, !tbaa !2428
  %160 = add i64 %117, 54
  store i64 %160, i64* %PC, align 8
  %161 = fcmp uno double %122, %137
  br i1 %161, label %162, label %172

; <label>:162:                                    ; preds = %block_400840
  %163 = fadd double %122, %137
  %164 = bitcast double %163 to i64
  %165 = and i64 %164, 9221120237041090560
  %166 = icmp eq i64 %165, 9218868437227405312
  %167 = and i64 %164, 2251799813685247
  %168 = icmp ne i64 %167, 0
  %169 = and i1 %166, %168
  br i1 %169, label %170, label %178

; <label>:170:                                    ; preds = %162
  %171 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %160, %struct.Memory* %78) #15
  %.pre = load i64, i64* %RCX, align 8
  %.pre71 = load i64, i64* %PC, align 8
  %.pre72 = load i8, i8* %18, align 1, !tbaa !2433
  %.pre73 = load i64, i64* %RDI, align 8, !tbaa !2428
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

; <label>:172:                                    ; preds = %block_400840
  %173 = fcmp ogt double %122, %137
  br i1 %173, label %178, label %174

; <label>:174:                                    ; preds = %172
  %175 = fcmp olt double %122, %137
  br i1 %175, label %178, label %176

; <label>:176:                                    ; preds = %174
  %177 = fcmp oeq double %122, %137
  br i1 %177, label %178, label %182

; <label>:178:                                    ; preds = %176, %174, %172, %162
  %179 = phi i8 [ 0, %172 ], [ 0, %174 ], [ 1, %176 ], [ 1, %162 ]
  %180 = phi i8 [ 0, %172 ], [ 0, %174 ], [ 0, %176 ], [ 1, %162 ]
  %181 = phi i8 [ 0, %172 ], [ 1, %174 ], [ 0, %176 ], [ 1, %162 ]
  store i8 %179, i8* %33, align 1, !tbaa !2432
  store i8 %180, i8* %25, align 1, !tbaa !2432
  store i8 %181, i8* %18, align 1, !tbaa !2432
  br label %182

; <label>:182:                                    ; preds = %178, %176
  %183 = phi i8 [ %181, %178 ], [ 0, %176 ]
  store i8 0, i8* %42, align 1, !tbaa !2432
  store i8 0, i8* %36, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3: ; preds = %182, %170
  %184 = phi i64 [ %.pre73, %170 ], [ %144, %182 ]
  %185 = phi i8 [ %.pre72, %170 ], [ %183, %182 ]
  %186 = phi i64 [ %.pre71, %170 ], [ %160, %182 ]
  %187 = phi i64 [ %.pre, %170 ], [ %159, %182 ]
  %188 = phi %struct.Memory* [ %171, %170 ], [ %78, %182 ]
  %189 = icmp ne i8 %185, 0
  %190 = select i1 %189, i64 %187, i64 %184
  store i64 %190, i64* %RDI, align 8, !tbaa !2428
  %191 = load i64, i64* %RBP, align 8
  %192 = add i64 %191, -144
  %193 = add i64 %186, 11
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to i64*
  %195 = load i64, i64* %194, align 8
  store i64 %195, i64* %RCX, align 8, !tbaa !2428
  %196 = add i64 %191, -152
  %197 = add i64 %186, 18
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %196 to i64*
  store i64 %190, i64* %198, align 8
  %199 = load i64, i64* %RCX, align 8
  %200 = load i64, i64* %PC, align 8
  store i64 %199, i64* %RDI, align 8, !tbaa !2428
  %201 = load i64, i64* %RBP, align 8
  %202 = add i64 %201, -152
  %203 = add i64 %200, 10
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %202 to i64*
  %205 = load i64, i64* %204, align 8
  store i64 %205, i64* %RSI, align 8, !tbaa !2428
  %206 = add i64 %200, -452
  %207 = add i64 %200, 15
  %208 = load i64, i64* %RSP, align 8, !tbaa !2428
  %209 = add i64 %208, -8
  %210 = inttoptr i64 %209 to i64*
  store i64 %207, i64* %210, align 8
  store i64 %209, i64* %RSP, align 8, !tbaa !2428
  store i64 %206, i64* %PC, align 8, !tbaa !2428
  %211 = tail call fastcc %struct.Memory* @ext_400720_memalign(%struct.State* nonnull %0, %struct.Memory* %188)
  %212 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 20480, i64* %RDX, align 8, !tbaa !2428
  store i64 20480, i64* %RSI, align 8, !tbaa !2428
  %213 = load i64, i64* %RBP, align 8
  %214 = add i64 %213, -24
  %215 = load i64, i64* %RAX, align 8
  %216 = add i64 %212, 18
  store i64 %216, i64* %PC, align 8
  %217 = inttoptr i64 %214 to i64*
  store i64 %215, i64* %217, align 8
  %218 = load i64, i64* %PC, align 8
  %219 = add i64 %218, -485
  %220 = add i64 %218, 5
  %221 = load i64, i64* %RSP, align 8, !tbaa !2428
  %222 = add i64 %221, -8
  %223 = inttoptr i64 %222 to i64*
  store i64 %220, i64* %223, align 8
  store i64 %222, i64* %RSP, align 8, !tbaa !2428
  store i64 %219, i64* %PC, align 8, !tbaa !2428
  %224 = tail call fastcc %struct.Memory* @ext_400720_memalign(%struct.State* nonnull %0, %struct.Memory* %211)
  %225 = load i64, i64* %PC, align 8
  store i64 512, i64* %RDI, align 8, !tbaa !2428
  %226 = load i64, i64* %RBP, align 8
  %227 = add i64 %226, -56
  %228 = load i64, i64* %RAX, align 8
  %229 = add i64 %225, 9
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %227 to i64*
  store i64 %228, i64* %230, align 8
  %231 = load i64, i64* %RBP, align 8
  %232 = add i64 %231, -24
  %233 = load i64, i64* %PC, align 8
  %234 = add i64 %233, 4
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %232 to i64*
  %236 = load i64, i64* %235, align 8
  store i64 %236, i64* %RSI, align 8, !tbaa !2428
  %237 = add i64 %231, -56
  %238 = add i64 %233, 8
  store i64 %238, i64* %PC, align 8
  %239 = inttoptr i64 %237 to i64*
  %240 = load i64, i64* %239, align 8
  store i64 %240, i64* %RDX, align 8, !tbaa !2428
  %241 = add i64 %233, 1357
  %242 = add i64 %233, 13
  %243 = load i64, i64* %RSP, align 8, !tbaa !2428
  %244 = add i64 %243, -8
  %245 = inttoptr i64 %244 to i64*
  store i64 %242, i64* %245, align 8
  store i64 %244, i64* %RSP, align 8, !tbaa !2428
  store i64 %241, i64* %PC, align 8, !tbaa !2428
  %246 = tail call %struct.Memory* @sub_400e60_makewt(%struct.State* nonnull %0, i64 %241, %struct.Memory* %224)
  %247 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %248 = add i64 %247, -512
  %249 = add i64 %247, 19
  %250 = load i64, i64* %RSP, align 8, !tbaa !2428
  %251 = add i64 %250, -8
  %252 = inttoptr i64 %251 to i64*
  store i64 %249, i64* %252, align 8
  store i64 %251, i64* %RSP, align 8, !tbaa !2428
  store i64 %248, i64* %PC, align 8, !tbaa !2428
  %253 = tail call fastcc %struct.Memory* @ext_400720_memalign(%struct.State* nonnull %0, %struct.Memory* %246)
  %254 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %255 = load i64, i64* %RBP, align 8
  %256 = add i64 %255, -32
  %257 = load i64, i64* %RAX, align 8
  %258 = add i64 %254, 22
  store i64 %258, i64* %PC, align 8
  %259 = inttoptr i64 %256 to i64*
  store i64 %257, i64* %259, align 8
  %260 = load i64, i64* %PC, align 8
  %261 = add i64 %260, -553
  %262 = add i64 %260, 5
  %263 = load i64, i64* %RSP, align 8, !tbaa !2428
  %264 = add i64 %263, -8
  %265 = inttoptr i64 %264 to i64*
  store i64 %262, i64* %265, align 8
  store i64 %264, i64* %RSP, align 8, !tbaa !2428
  store i64 %261, i64* %PC, align 8, !tbaa !2428
  %266 = tail call fastcc %struct.Memory* @ext_400720_memalign(%struct.State* nonnull %0, %struct.Memory* %253)
  %267 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %268 = load i64, i64* %RBP, align 8
  %269 = add i64 %268, -40
  %270 = load i64, i64* %RAX, align 8
  %271 = add i64 %267, 22
  store i64 %271, i64* %PC, align 8
  %272 = inttoptr i64 %269 to i64*
  store i64 %270, i64* %272, align 8
  %273 = load i64, i64* %PC, align 8
  %274 = add i64 %273, -580
  %275 = add i64 %273, 5
  %276 = load i64, i64* %RSP, align 8, !tbaa !2428
  %277 = add i64 %276, -8
  %278 = inttoptr i64 %277 to i64*
  store i64 %275, i64* %278, align 8
  store i64 %277, i64* %RSP, align 8, !tbaa !2428
  store i64 %274, i64* %PC, align 8, !tbaa !2428
  %279 = tail call fastcc %struct.Memory* @ext_400720_memalign(%struct.State* nonnull %0, %struct.Memory* %266)
  %280 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  store i8 1, i8* %25, align 1, !tbaa !2447
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %281 = load i64, i64* %RBP, align 8
  %282 = add i64 %281, -48
  %283 = load i64, i64* %RAX, align 8
  %284 = add i64 %280, 11
  store i64 %284, i64* %PC, align 8
  %285 = inttoptr i64 %282 to i64*
  store i64 %283, i64* %285, align 8
  %286 = load i64, i64* %RBP, align 8
  %287 = add i64 %286, -32
  %288 = load i64, i64* %PC, align 8
  %289 = add i64 %288, 4
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %287 to i64*
  %291 = load i64, i64* %290, align 8
  store i64 %291, i64* %RDX, align 8, !tbaa !2428
  %292 = add i64 %288, 1628
  %293 = add i64 %288, 9
  %294 = load i64, i64* %RSP, align 8, !tbaa !2428
  %295 = add i64 %294, -8
  %296 = inttoptr i64 %295 to i64*
  store i64 %293, i64* %296, align 8
  store i64 %295, i64* %RSP, align 8, !tbaa !2428
  store i64 %292, i64* %PC, align 8, !tbaa !2428
  %297 = tail call %struct.Memory* @sub_400fd0_putdata(%struct.State* nonnull %0, i64 %292, %struct.Memory* %279)
  %298 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %299 = load i64, i64* %RBP, align 8
  %300 = add i64 %299, -32
  %301 = add i64 %298, 14
  store i64 %301, i64* %PC, align 8
  %302 = inttoptr i64 %300 to i64*
  %303 = load i64, i64* %302, align 8
  store i64 %303, i64* %RDX, align 8, !tbaa !2428
  %304 = add i64 %299, -24
  %305 = add i64 %298, 18
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to i64*
  %307 = load i64, i64* %306, align 8
  store i64 %307, i64* %RCX, align 8, !tbaa !2428
  %308 = add i64 %299, -56
  %309 = add i64 %298, 22
  store i64 %309, i64* %PC, align 8
  %310 = inttoptr i64 %308 to i64*
  %311 = load i64, i64* %310, align 8
  store i64 %311, i64* %R8, align 8, !tbaa !2428
  %312 = add i64 %298, 1747
  %313 = add i64 %298, 27
  %314 = load i64, i64* %RSP, align 8, !tbaa !2428
  %315 = add i64 %314, -8
  %316 = inttoptr i64 %315 to i64*
  store i64 %313, i64* %316, align 8
  store i64 %315, i64* %RSP, align 8, !tbaa !2428
  store i64 %312, i64* %PC, align 8, !tbaa !2428
  %317 = tail call %struct.Memory* @sub_401050_cdft(%struct.State* nonnull %0, i64 %312, %struct.Memory* %297)
  %318 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %319 = load i64, i64* %RBP, align 8
  %320 = add i64 %319, -32
  %321 = add i64 %318, 14
  store i64 %321, i64* %PC, align 8
  %322 = inttoptr i64 %320 to i64*
  %323 = load i64, i64* %322, align 8
  store i64 %323, i64* %RDX, align 8, !tbaa !2428
  %324 = add i64 %319, -24
  %325 = add i64 %318, 18
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %324 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %RCX, align 8, !tbaa !2428
  %328 = add i64 %319, -56
  %329 = add i64 %318, 22
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i64*
  %331 = load i64, i64* %330, align 8
  store i64 %331, i64* %R8, align 8, !tbaa !2428
  %332 = add i64 %318, 1720
  %333 = add i64 %318, 27
  %334 = load i64, i64* %RSP, align 8, !tbaa !2428
  %335 = add i64 %334, -8
  %336 = inttoptr i64 %335 to i64*
  store i64 %333, i64* %336, align 8
  store i64 %335, i64* %RSP, align 8, !tbaa !2428
  store i64 %332, i64* %PC, align 8, !tbaa !2428
  %337 = tail call %struct.Memory* @sub_401050_cdft(%struct.State* nonnull %0, i64 %332, %struct.Memory* %317)
  %338 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  store i8 1, i8* %25, align 1, !tbaa !2447
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %339 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 16) to i64*), align 16
  store i64 %339, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %340 = load i64, i64* %RBP, align 8
  %341 = add i64 %340, -32
  %342 = add i64 %338, 19
  store i64 %342, i64* %PC, align 8
  %343 = inttoptr i64 %341 to i64*
  %344 = load i64, i64* %343, align 8
  store i64 %344, i64* %RDX, align 8, !tbaa !2428
  %345 = add i64 %338, 1853
  %346 = add i64 %338, 24
  %347 = load i64, i64* %RSP, align 8, !tbaa !2428
  %348 = add i64 %347, -8
  %349 = inttoptr i64 %348 to i64*
  store i64 %346, i64* %349, align 8
  store i64 %348, i64* %RSP, align 8, !tbaa !2428
  store i64 %345, i64* %PC, align 8, !tbaa !2428
  %350 = tail call %struct.Memory* @sub_4010f0_errorcheck(%struct.State* nonnull %0, i64 %345, %struct.Memory* %337)
  %351 = load i64, i64* %PC, align 8
  %352 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 8) to i64*), align 8
  store i64 %352, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %353 = load i64, i64* %RBP, align 8
  %354 = add i64 %353, -96
  %355 = add i64 %351, 13
  store i64 %355, i64* %PC, align 8
  %356 = load i64, i64* %69, align 1
  %357 = inttoptr i64 %354 to i64*
  store i64 %356, i64* %357, align 8
  %358 = load i64, i64* %RBP, align 8
  %359 = add i64 %358, -96
  %360 = load i64, i64* %PC, align 8
  %361 = add i64 %360, 5
  store i64 %361, i64* %PC, align 8
  %362 = inttoptr i64 %359 to i64*
  %363 = load i64, i64* %362, align 8
  %364 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 96) to i32*), align 16
  %365 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 100) to i32*), align 4
  %366 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 104) to i32*), align 8
  %367 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 108) to i32*), align 4
  store i32 %364, i32* %127, align 1, !tbaa !2454
  store i32 %365, i32* %130, align 1, !tbaa !2454
  store i32 %366, i32* %132, align 1, !tbaa !2454
  store i32 %367, i32* %134, align 1, !tbaa !2454
  %368 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  %369 = load i64, i64* %368, align 1
  %370 = and i64 %369, %363
  %371 = trunc i64 %370 to i32
  %372 = lshr i64 %370, 32
  %373 = trunc i64 %372 to i32
  %374 = bitcast [32 x %union.VectorReg]* %5 to i32*
  store i32 %371, i32* %374, align 1, !tbaa !2461
  %375 = getelementptr inbounds i8, i8* %85, i64 4
  %376 = bitcast i8* %375 to i32*
  store i32 %373, i32* %376, align 1, !tbaa !2461
  %377 = bitcast i64* %92 to i32*
  store i32 0, i32* %377, align 1, !tbaa !2461
  %378 = getelementptr inbounds i8, i8* %85, i64 12
  %379 = bitcast i8* %378 to i32*
  store i32 0, i32* %379, align 1, !tbaa !2461
  %380 = add i64 %360, 20
  store i64 %380, i64* %PC, align 8
  %381 = load double, double* %68, align 1
  %382 = load double, double* %99, align 1
  %383 = fcmp uno double %381, %382
  br i1 %383, label %384, label %394

; <label>:384:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %385 = fadd double %381, %382
  %386 = bitcast double %385 to i64
  %387 = and i64 %386, 9221120237041090560
  %388 = icmp eq i64 %387, 9218868437227405312
  %389 = and i64 %386, 2251799813685247
  %390 = icmp ne i64 %389, 0
  %391 = and i1 %388, %390
  br i1 %391, label %392, label %400

; <label>:392:                                    ; preds = %384
  %393 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %380, %struct.Memory* %350) #15
  %.pre74 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

; <label>:394:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %395 = fcmp ogt double %381, %382
  br i1 %395, label %400, label %396

; <label>:396:                                    ; preds = %394
  %397 = fcmp olt double %381, %382
  br i1 %397, label %400, label %398

; <label>:398:                                    ; preds = %396
  %399 = fcmp oeq double %381, %382
  br i1 %399, label %400, label %404

; <label>:400:                                    ; preds = %398, %396, %394, %384
  %401 = phi i8 [ 0, %394 ], [ 0, %396 ], [ 1, %398 ], [ 1, %384 ]
  %402 = phi i8 [ 0, %394 ], [ 0, %396 ], [ 0, %398 ], [ 1, %384 ]
  %403 = phi i8 [ 0, %394 ], [ 1, %396 ], [ 0, %398 ], [ 1, %384 ]
  store i8 %401, i8* %33, align 1, !tbaa !2432
  store i8 %402, i8* %25, align 1, !tbaa !2432
  store i8 %403, i8* %18, align 1, !tbaa !2432
  br label %404

; <label>:404:                                    ; preds = %400, %398
  store i8 0, i8* %42, align 1, !tbaa !2432
  store i8 0, i8* %36, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2: ; preds = %404, %392
  %405 = phi i64 [ %.pre74, %392 ], [ %380, %404 ]
  %406 = phi %struct.Memory* [ %393, %392 ], [ %350, %404 ]
  %407 = load i8, i8* %18, align 1, !tbaa !2433
  %408 = load i8, i8* %33, align 1, !tbaa !2448
  %409 = or i8 %408, %407
  %410 = icmp ne i8 %409, 0
  %.v97 = select i1 %410, i64 39, i64 6
  %411 = add i64 %405, %.v97
  store i64 %411, i64* %PC, align 8, !tbaa !2428
  br i1 %410, label %block_400a13, label %block_4009f2

block_400c7d:                                     ; preds = %block_400b16
  %412 = add i64 %1030, 419
  %413 = add i64 %1030, 5
  %414 = load i64, i64* %RSP, align 8, !tbaa !2428
  %415 = add i64 %414, -8
  %416 = inttoptr i64 %415 to i64*
  store i64 %413, i64* %416, align 8
  store i64 %415, i64* %RSP, align 8, !tbaa !2428
  store i64 %412, i64* %PC, align 8, !tbaa !2428
  %417 = tail call %struct.Memory* @sub_400e20_get_time(%struct.State* nonnull %0, i64 %412, %struct.Memory* %MEMORY.2)
  %418 = load i64, i64* %RBP, align 8
  %419 = add i64 %418, -72
  %420 = load i64, i64* %PC, align 8
  %421 = add i64 %420, 5
  store i64 %421, i64* %PC, align 8
  %422 = load i64, i64* %69, align 1
  %423 = inttoptr i64 %419 to i64*
  store i64 %422, i64* %423, align 8
  %424 = load i64, i64* %RBP, align 8
  %425 = add i64 %424, -72
  %426 = load i64, i64* %PC, align 8
  %427 = add i64 %426, 5
  store i64 %427, i64* %PC, align 8
  %428 = inttoptr i64 %425 to i64*
  %429 = load i64, i64* %428, align 8
  store i64 %429, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %430 = add i64 %424, -64
  %431 = add i64 %426, 10
  store i64 %431, i64* %PC, align 8
  %432 = bitcast i64 %429 to double
  %433 = inttoptr i64 %430 to double*
  %434 = load double, double* %433, align 8
  %435 = fsub double %432, %434
  store double %435, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %92, align 1, !tbaa !2452
  %436 = add i64 %424, -80
  %437 = add i64 %426, 15
  store i64 %437, i64* %PC, align 8
  %438 = inttoptr i64 %436 to double*
  %439 = load double, double* %438, align 8
  %440 = fsub double %435, %439
  store double %440, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %92, align 1, !tbaa !2452
  %441 = add i64 %424, -88
  %442 = add i64 %426, 20
  store i64 %442, i64* %PC, align 8
  %443 = inttoptr i64 %441 to double*
  %444 = load double, double* %443, align 8
  %445 = fadd double %440, %444
  store double %445, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %92, align 1, !tbaa !2452
  %446 = add i64 %426, 25
  store i64 %446, i64* %PC, align 8
  %447 = inttoptr i64 %441 to double*
  store double %445, double* %447, align 8
  %448 = load i64, i64* %RBP, align 8
  %449 = add i64 %448, -12
  %450 = load i64, i64* %PC, align 8
  %451 = add i64 %450, 7
  store i64 %451, i64* %PC, align 8
  %452 = inttoptr i64 %449 to i32*
  store i32 0, i32* %452, align 4
  %453 = bitcast %union.VectorReg* %6 to i32*
  %454 = getelementptr inbounds i8, i8* %94, i64 4
  %455 = bitcast i8* %454 to i32*
  %456 = bitcast i64* %101 to i32*
  %457 = getelementptr inbounds i8, i8* %94, i64 12
  %458 = bitcast i8* %457 to i32*
  %459 = bitcast %union.VectorReg* %8 to i8*
  %460 = bitcast %union.VectorReg* %8 to i32*
  %461 = getelementptr inbounds i8, i8* %459, i64 4
  %462 = bitcast i8* %461 to i32*
  %463 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3, i32 0, i32 0, i32 0, i64 1
  %464 = bitcast i64* %463 to i32*
  %465 = getelementptr inbounds i8, i8* %459, i64 12
  %466 = bitcast i8* %465 to i32*
  %467 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %468 = bitcast %union.VectorReg* %6 to <2 x i32>*
  %469 = bitcast i64* %101 to <2 x i32>*
  %.pre77 = load i64, i64* %PC, align 8
  %470 = bitcast [32 x %union.VectorReg]* %5 to <4 x i32>*
  %471 = bitcast [32 x %union.VectorReg]* %5 to <4 x i32>*
  br label %block_400ca7

block_400d54:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %472 = load i64, i64* %RBP, align 8
  %473 = add i64 %472, -40
  %474 = add i64 %1282, 4
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to i64*
  %476 = load i64, i64* %475, align 8
  store i64 %476, i64* %RAX, align 8, !tbaa !2428
  %477 = add i64 %472, -12
  %478 = add i64 %1282, 7
  store i64 %478, i64* %PC, align 8
  %479 = inttoptr i64 %477 to i32*
  %480 = load i32, i32* %479, align 4
  %481 = shl i32 %480, 1
  %482 = or i32 %481, 1
  %483 = zext i32 %482 to i64
  store i64 %483, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %484 = and i32 %482, 255
  %485 = tail call i32 @llvm.ctpop.i32(i32 %484) #10
  %486 = trunc i32 %485 to i8
  %487 = and i8 %486, 1
  %488 = xor i8 %487, 1
  store i8 %488, i8* %25, align 1, !tbaa !2447
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i8 0, i8* %33, align 1, !tbaa !2448
  %489 = lshr i32 %480, 30
  %490 = and i32 %489, 1
  %491 = trunc i32 %490 to i8
  store i8 %491, i8* %36, align 1, !tbaa !2449
  %492 = lshr i32 %480, 30
  %493 = and i32 %492, 1
  %494 = xor i32 %490, %493
  %495 = add nuw nsw i32 %494, %490
  %496 = icmp eq i32 %495, 2
  %497 = zext i1 %496 to i8
  store i8 %497, i8* %42, align 1, !tbaa !2450
  %498 = sext i32 %482 to i64
  store i64 %498, i64* %RDX, align 8, !tbaa !2428
  %499 = shl nsw i64 %498, 3
  %500 = add i64 %476, %499
  %501 = add i64 %1282, 21
  store i64 %501, i64* %PC, align 8
  %502 = inttoptr i64 %500 to i64*
  %503 = load i64, i64* %502, align 8
  store i64 %503, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  br label %block_400d86

block_400b77:                                     ; preds = %block_400b84, %block_400b23
  %504 = phi i64 [ %1636, %block_400b84 ], [ %.pre86, %block_400b23 ]
  %505 = load i64, i64* %RBP, align 8
  %506 = add i64 %505, -100
  %507 = add i64 %504, 7
  store i64 %507, i64* %PC, align 8
  %508 = inttoptr i64 %506 to i32*
  %509 = load i32, i32* %508, align 4
  %510 = add i32 %509, -1024
  %511 = icmp ult i32 %509, 1024
  %512 = zext i1 %511 to i8
  store i8 %512, i8* %18, align 1, !tbaa !2433
  %513 = and i32 %510, 255
  %514 = tail call i32 @llvm.ctpop.i32(i32 %513) #10
  %515 = trunc i32 %514 to i8
  %516 = and i8 %515, 1
  %517 = xor i8 %516, 1
  store i8 %517, i8* %25, align 1, !tbaa !2447
  %518 = xor i32 %510, %509
  %519 = lshr i32 %518, 4
  %520 = trunc i32 %519 to i8
  %521 = and i8 %520, 1
  store i8 %521, i8* %30, align 1, !tbaa !2451
  %522 = icmp eq i32 %510, 0
  %523 = zext i1 %522 to i8
  store i8 %523, i8* %33, align 1, !tbaa !2448
  %524 = lshr i32 %510, 31
  %525 = trunc i32 %524 to i8
  store i8 %525, i8* %36, align 1, !tbaa !2449
  %526 = lshr i32 %509, 31
  %527 = xor i32 %524, %526
  %528 = add nuw nsw i32 %527, %526
  %529 = icmp eq i32 %528, 2
  %530 = zext i1 %529 to i8
  store i8 %530, i8* %42, align 1, !tbaa !2450
  %531 = icmp ne i8 %525, 0
  %532 = xor i1 %531, %529
  %.v90 = select i1 %532, i64 13, i64 221
  %533 = add i64 %504, %.v90
  store i64 %533, i64* %PC, align 8, !tbaa !2428
  br i1 %532, label %block_400b84, label %block_400c54

block_400a7c:                                     ; preds = %block_400a6f
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %534 = add i64 %1032, -32
  %535 = add i64 %1060, 14
  store i64 %535, i64* %PC, align 8
  %536 = inttoptr i64 %534 to i64*
  %537 = load i64, i64* %536, align 8
  store i64 %537, i64* %RCX, align 8, !tbaa !2428
  %538 = add i64 %1060, 17
  store i64 %538, i64* %PC, align 8
  %539 = load i32, i32* %1035, align 4
  %540 = shl i32 %539, 1
  %541 = or i32 %540, 1
  %542 = zext i32 %541 to i64
  store i64 %542, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %543 = and i32 %541, 255
  %544 = tail call i32 @llvm.ctpop.i32(i32 %543) #10
  %545 = trunc i32 %544 to i8
  %546 = and i8 %545, 1
  %547 = xor i8 %546, 1
  store i8 %547, i8* %25, align 1, !tbaa !2447
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i8 0, i8* %33, align 1, !tbaa !2448
  %548 = lshr i32 %539, 30
  %549 = and i32 %548, 1
  %550 = trunc i32 %549 to i8
  store i8 %550, i8* %36, align 1, !tbaa !2449
  %551 = lshr i32 %539, 30
  %552 = and i32 %551, 1
  %553 = xor i32 %549, %552
  %554 = add nuw nsw i32 %553, %549
  %555 = icmp eq i32 %554, 2
  %556 = zext i1 %555 to i8
  store i8 %556, i8* %42, align 1, !tbaa !2450
  %557 = sext i32 %541 to i64
  store i64 %557, i64* %RSI, align 8, !tbaa !2428
  %558 = shl nsw i64 %557, 3
  %559 = add i64 %537, %558
  %560 = add i64 %1060, 31
  store i64 %560, i64* %PC, align 8
  %561 = inttoptr i64 %559 to i64*
  %562 = load i64, i64* %561, align 8
  %563 = xor i64 %562, -9223372036854775808
  store i64 %563, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %564 = trunc i64 %562 to i32
  %565 = and i32 %564, 255
  %566 = tail call i32 @llvm.ctpop.i32(i32 %565) #10
  %567 = trunc i32 %566 to i8
  %568 = and i8 %567, 1
  %569 = xor i8 %568, 1
  store i8 %569, i8* %25, align 1, !tbaa !2447
  %570 = icmp eq i64 %563, 0
  %571 = zext i1 %570 to i8
  store i8 %571, i8* %33, align 1, !tbaa !2448
  %572 = lshr i64 %563, 63
  %573 = trunc i64 %572 to i8
  store i8 %573, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 %563, i64* %69, align 1, !tbaa !2428
  store i64 0, i64* %92, align 1, !tbaa !2428
  %574 = load i64, i64* %RBP, align 8
  %575 = add i64 %574, -32
  %576 = add i64 %1060, 48
  store i64 %576, i64* %PC, align 8
  %577 = inttoptr i64 %575 to i64*
  %578 = load i64, i64* %577, align 8
  store i64 %578, i64* %RAX, align 8, !tbaa !2428
  %579 = add i64 %574, -12
  %580 = add i64 %1060, 51
  store i64 %580, i64* %PC, align 8
  %581 = inttoptr i64 %579 to i32*
  %582 = load i32, i32* %581, align 4
  %583 = shl i32 %582, 1
  %584 = or i32 %583, 1
  %585 = zext i32 %584 to i64
  store i64 %585, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %586 = and i32 %584, 255
  %587 = tail call i32 @llvm.ctpop.i32(i32 %586) #10
  %588 = trunc i32 %587 to i8
  %589 = and i8 %588, 1
  %590 = xor i8 %589, 1
  store i8 %590, i8* %25, align 1, !tbaa !2447
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i8 0, i8* %33, align 1, !tbaa !2448
  %591 = lshr i32 %582, 30
  %592 = and i32 %591, 1
  %593 = trunc i32 %592 to i8
  store i8 %593, i8* %36, align 1, !tbaa !2449
  %594 = lshr i32 %582, 30
  %595 = and i32 %594, 1
  %596 = xor i32 %592, %595
  %597 = add nuw nsw i32 %596, %592
  %598 = icmp eq i32 %597, 2
  %599 = zext i1 %598 to i8
  store i8 %599, i8* %42, align 1, !tbaa !2450
  %600 = sext i32 %584 to i64
  store i64 %600, i64* %RCX, align 8, !tbaa !2428
  %601 = shl nsw i64 %600, 3
  %602 = add i64 %578, %601
  %603 = add i64 %1060, 65
  store i64 %603, i64* %PC, align 8
  %604 = inttoptr i64 %602 to i64*
  store i64 %563, i64* %604, align 8
  %605 = load i64, i64* %RBP, align 8
  %606 = add i64 %605, -12
  %607 = load i64, i64* %PC, align 8
  %608 = add i64 %607, 3
  store i64 %608, i64* %PC, align 8
  %609 = inttoptr i64 %606 to i32*
  %610 = load i32, i32* %609, align 4
  %611 = add i32 %610, 1
  %612 = zext i32 %611 to i64
  store i64 %612, i64* %RAX, align 8, !tbaa !2428
  %613 = icmp eq i32 %610, -1
  %614 = icmp eq i32 %611, 0
  %615 = or i1 %613, %614
  %616 = zext i1 %615 to i8
  store i8 %616, i8* %18, align 1, !tbaa !2433
  %617 = and i32 %611, 255
  %618 = tail call i32 @llvm.ctpop.i32(i32 %617) #10
  %619 = trunc i32 %618 to i8
  %620 = and i8 %619, 1
  %621 = xor i8 %620, 1
  store i8 %621, i8* %25, align 1, !tbaa !2447
  %622 = xor i32 %611, %610
  %623 = lshr i32 %622, 4
  %624 = trunc i32 %623 to i8
  %625 = and i8 %624, 1
  store i8 %625, i8* %30, align 1, !tbaa !2451
  %626 = zext i1 %614 to i8
  store i8 %626, i8* %33, align 1, !tbaa !2448
  %627 = lshr i32 %611, 31
  %628 = trunc i32 %627 to i8
  store i8 %628, i8* %36, align 1, !tbaa !2449
  %629 = lshr i32 %610, 31
  %630 = xor i32 %627, %629
  %631 = add nuw nsw i32 %630, %627
  %632 = icmp eq i32 %631, 2
  %633 = zext i1 %632 to i8
  store i8 %633, i8* %42, align 1, !tbaa !2450
  %634 = add i64 %607, 9
  store i64 %634, i64* %PC, align 8
  store i32 %611, i32* %609, align 4
  %635 = load i64, i64* %PC, align 8
  %636 = add i64 %635, -87
  store i64 %636, i64* %PC, align 8, !tbaa !2428
  br label %block_400a6f

block_4009f2:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 112), i64* %RDI, align 8, !tbaa !2428
  %637 = load i64, i64* %RBP, align 8
  %638 = add i64 %637, -96
  %639 = add i64 %411, 15
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %638 to i64*
  %641 = load i64, i64* %640, align 8
  store i64 %641, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  store i8 1, i8* %AL, align 1, !tbaa !2432
  %642 = add i64 %411, -802
  %643 = add i64 %411, 22
  %644 = load i64, i64* %RSP, align 8, !tbaa !2428
  %645 = add i64 %644, -8
  %646 = inttoptr i64 %645 to i64*
  store i64 %643, i64* %646, align 8
  store i64 %645, i64* %RSP, align 8, !tbaa !2428
  store i64 %642, i64* %PC, align 8, !tbaa !2428
  %647 = tail call fastcc %struct.Memory* @ext_4006d0_printf(%struct.State* nonnull %0, %struct.Memory* %406)
  %648 = load i64, i64* %RBP, align 8
  %649 = add i64 %648, -156
  %650 = load i32, i32* %EAX, align 4
  %651 = load i64, i64* %PC, align 8
  %652 = add i64 %651, 6
  store i64 %652, i64* %PC, align 8
  %653 = inttoptr i64 %649 to i32*
  store i32 %650, i32* %653, align 4
  %654 = load i64, i64* %PC, align 8
  %655 = add i64 %654, -862
  %656 = add i64 %654, 5
  %657 = load i64, i64* %RSP, align 8, !tbaa !2428
  %658 = add i64 %657, -8
  %659 = inttoptr i64 %658 to i64*
  store i64 %656, i64* %659, align 8
  store i64 %658, i64* %RSP, align 8, !tbaa !2428
  store i64 %655, i64* %PC, align 8, !tbaa !2428
  %660 = tail call fastcc %struct.Memory* @ext_6050f0_abort(%struct.State* nonnull %0, %struct.Memory* %647)
  %661 = load i64, i64* %PC, align 8
  %662 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %661, %struct.Memory* %660)
  ret %struct.Memory* %662

block_400ce3:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  %663 = load i64, i64* %RBP, align 8
  %664 = add i64 %663, -40
  %665 = add i64 %999, 4
  store i64 %665, i64* %PC, align 8
  %666 = inttoptr i64 %664 to i64*
  %667 = load i64, i64* %666, align 8
  store i64 %667, i64* %RAX, align 8, !tbaa !2428
  %668 = add i64 %663, -12
  %669 = add i64 %999, 7
  store i64 %669, i64* %PC, align 8
  %670 = inttoptr i64 %668 to i32*
  %671 = load i32, i32* %670, align 4
  %672 = shl i32 %671, 1
  %673 = icmp slt i32 %671, 0
  %674 = icmp slt i32 %672, 0
  %675 = xor i1 %673, %674
  %676 = zext i32 %672 to i64
  store i64 %676, i64* %RCX, align 8, !tbaa !2428
  %.lobit62 = lshr i32 %671, 31
  %677 = trunc i32 %.lobit62 to i8
  store i8 %677, i8* %18, align 1, !tbaa !2432
  %678 = and i32 %672, 254
  %679 = tail call i32 @llvm.ctpop.i32(i32 %678) #10
  %680 = trunc i32 %679 to i8
  %681 = and i8 %680, 1
  %682 = xor i8 %681, 1
  store i8 %682, i8* %25, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %683 = icmp eq i32 %672, 0
  %684 = zext i1 %683 to i8
  store i8 %684, i8* %33, align 1, !tbaa !2432
  %685 = lshr i32 %671, 30
  %686 = trunc i32 %685 to i8
  %687 = and i8 %686, 1
  store i8 %687, i8* %36, align 1, !tbaa !2432
  %688 = zext i1 %675 to i8
  store i8 %688, i8* %42, align 1, !tbaa !2432
  %689 = sext i32 %672 to i64
  store i64 %689, i64* %RDX, align 8, !tbaa !2428
  %690 = shl nsw i64 %689, 3
  %691 = add i64 %667, %690
  %692 = add i64 %999, 18
  store i64 %692, i64* %PC, align 8
  %693 = inttoptr i64 %691 to i64*
  %694 = load i64, i64* %693, align 8
  store i64 %694, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  br label %block_400d12

block_400c54:                                     ; preds = %block_400b77
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %695 = add i64 %505, -40
  %696 = add i64 %533, 14
  store i64 %696, i64* %PC, align 8
  %697 = inttoptr i64 %695 to i64*
  %698 = load i64, i64* %697, align 8
  store i64 %698, i64* %RDX, align 8, !tbaa !2428
  %699 = add i64 %505, -24
  %700 = add i64 %533, 18
  store i64 %700, i64* %PC, align 8
  %701 = inttoptr i64 %699 to i64*
  %702 = load i64, i64* %701, align 8
  store i64 %702, i64* %RCX, align 8, !tbaa !2428
  %703 = add i64 %505, -56
  %704 = add i64 %533, 22
  store i64 %704, i64* %PC, align 8
  %705 = inttoptr i64 %703 to i64*
  %706 = load i64, i64* %705, align 8
  store i64 %706, i64* %R8, align 8, !tbaa !2428
  %707 = add i64 %533, 1020
  %708 = add i64 %533, 27
  %709 = load i64, i64* %RSP, align 8, !tbaa !2428
  %710 = add i64 %709, -8
  %711 = inttoptr i64 %710 to i64*
  store i64 %708, i64* %711, align 8
  store i64 %710, i64* %RSP, align 8, !tbaa !2428
  store i64 %707, i64* %PC, align 8, !tbaa !2428
  %712 = tail call %struct.Memory* @sub_401050_cdft(%struct.State* nonnull %0, i64 %707, %struct.Memory* %921)
  %713 = load i64, i64* %RBP, align 8
  %714 = add i64 %713, -8
  %715 = load i64, i64* %PC, align 8
  %716 = add i64 %715, 3
  store i64 %716, i64* %PC, align 8
  %717 = inttoptr i64 %714 to i32*
  %718 = load i32, i32* %717, align 4
  %719 = add i32 %718, 1
  %720 = zext i32 %719 to i64
  store i64 %720, i64* %RAX, align 8, !tbaa !2428
  %721 = icmp eq i32 %718, -1
  %722 = icmp eq i32 %719, 0
  %723 = or i1 %721, %722
  %724 = zext i1 %723 to i8
  store i8 %724, i8* %18, align 1, !tbaa !2433
  %725 = and i32 %719, 255
  %726 = tail call i32 @llvm.ctpop.i32(i32 %725) #10
  %727 = trunc i32 %726 to i8
  %728 = and i8 %727, 1
  %729 = xor i8 %728, 1
  store i8 %729, i8* %25, align 1, !tbaa !2447
  %730 = xor i32 %719, %718
  %731 = lshr i32 %730, 4
  %732 = trunc i32 %731 to i8
  %733 = and i8 %732, 1
  store i8 %733, i8* %30, align 1, !tbaa !2451
  %734 = zext i1 %722 to i8
  store i8 %734, i8* %33, align 1, !tbaa !2448
  %735 = lshr i32 %719, 31
  %736 = trunc i32 %735 to i8
  store i8 %736, i8* %36, align 1, !tbaa !2449
  %737 = lshr i32 %718, 31
  %738 = xor i32 %735, %737
  %739 = add nuw nsw i32 %738, %735
  %740 = icmp eq i32 %739, 2
  %741 = zext i1 %740 to i8
  store i8 %741, i8* %42, align 1, !tbaa !2450
  %742 = add i64 %715, 9
  store i64 %742, i64* %PC, align 8
  store i32 %719, i32* %717, align 4
  %743 = load i64, i64* %PC, align 8
  %744 = add i64 %743, -354
  store i64 %744, i64* %PC, align 8, !tbaa !2428
  br label %block_400b16

block_400dce:                                     ; preds = %block_400ca7
  %745 = add i64 %837, -32
  %746 = add i64 %865, 4
  store i64 %746, i64* %PC, align 8
  %747 = inttoptr i64 %745 to i64*
  %748 = load i64, i64* %747, align 8
  store i64 %748, i64* %RAX, align 8, !tbaa !2428
  store i64 %748, i64* %RDI, align 8, !tbaa !2428
  %749 = add i64 %865, -1838
  %750 = add i64 %865, 12
  %751 = load i64, i64* %RSP, align 8, !tbaa !2428
  %752 = add i64 %751, -8
  %753 = inttoptr i64 %752 to i64*
  store i64 %750, i64* %753, align 8
  store i64 %752, i64* %RSP, align 8, !tbaa !2428
  store i64 %749, i64* %PC, align 8, !tbaa !2428
  %754 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %MEMORY.1)
  %755 = load i64, i64* %RBP, align 8
  %756 = add i64 %755, -56
  %757 = load i64, i64* %PC, align 8
  %758 = add i64 %757, 4
  store i64 %758, i64* %PC, align 8
  %759 = inttoptr i64 %756 to i64*
  %760 = load i64, i64* %759, align 8
  store i64 %760, i64* %RAX, align 8, !tbaa !2428
  store i64 %760, i64* %RDI, align 8, !tbaa !2428
  %761 = add i64 %757, -1850
  %762 = add i64 %757, 12
  %763 = load i64, i64* %RSP, align 8, !tbaa !2428
  %764 = add i64 %763, -8
  %765 = inttoptr i64 %764 to i64*
  store i64 %762, i64* %765, align 8
  store i64 %764, i64* %RSP, align 8, !tbaa !2428
  store i64 %761, i64* %PC, align 8, !tbaa !2428
  %766 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %754)
  %767 = load i64, i64* %RBP, align 8
  %768 = add i64 %767, -24
  %769 = load i64, i64* %PC, align 8
  %770 = add i64 %769, 4
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %768 to i64*
  %772 = load i64, i64* %771, align 8
  store i64 %772, i64* %RAX, align 8, !tbaa !2428
  store i64 %772, i64* %RDI, align 8, !tbaa !2428
  %773 = add i64 %769, -1862
  %774 = add i64 %769, 12
  %775 = load i64, i64* %RSP, align 8, !tbaa !2428
  %776 = add i64 %775, -8
  %777 = inttoptr i64 %776 to i64*
  store i64 %774, i64* %777, align 8
  store i64 %776, i64* %RSP, align 8, !tbaa !2428
  store i64 %773, i64* %PC, align 8, !tbaa !2428
  %778 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %766)
  %779 = load i64, i64* %RBP, align 8
  %780 = add i64 %779, -40
  %781 = load i64, i64* %PC, align 8
  %782 = add i64 %781, 4
  store i64 %782, i64* %PC, align 8
  %783 = inttoptr i64 %780 to i64*
  %784 = load i64, i64* %783, align 8
  store i64 %784, i64* %RAX, align 8, !tbaa !2428
  store i64 %784, i64* %RDI, align 8, !tbaa !2428
  %785 = add i64 %781, -1874
  %786 = add i64 %781, 12
  %787 = load i64, i64* %RSP, align 8, !tbaa !2428
  %788 = add i64 %787, -8
  %789 = inttoptr i64 %788 to i64*
  store i64 %786, i64* %789, align 8
  store i64 %788, i64* %RSP, align 8, !tbaa !2428
  store i64 %785, i64* %PC, align 8, !tbaa !2428
  %790 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %778)
  %791 = load i64, i64* %RBP, align 8
  %792 = add i64 %791, -48
  %793 = load i64, i64* %PC, align 8
  %794 = add i64 %793, 4
  store i64 %794, i64* %PC, align 8
  %795 = inttoptr i64 %792 to i64*
  %796 = load i64, i64* %795, align 8
  store i64 %796, i64* %RAX, align 8, !tbaa !2428
  store i64 %796, i64* %RDI, align 8, !tbaa !2428
  %797 = add i64 %793, -1886
  %798 = add i64 %793, 12
  %799 = load i64, i64* %RSP, align 8, !tbaa !2428
  %800 = add i64 %799, -8
  %801 = inttoptr i64 %800 to i64*
  store i64 %798, i64* %801, align 8
  store i64 %800, i64* %RSP, align 8, !tbaa !2428
  store i64 %797, i64* %PC, align 8, !tbaa !2428
  %802 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %790)
  %803 = load i64, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  %804 = load i64, i64* %RSP, align 8
  %805 = add i64 %804, 224
  store i64 %805, i64* %RSP, align 8, !tbaa !2428
  %806 = icmp ugt i64 %804, -225
  %807 = zext i1 %806 to i8
  store i8 %807, i8* %18, align 1, !tbaa !2433
  %808 = trunc i64 %805 to i32
  %809 = and i32 %808, 255
  %810 = tail call i32 @llvm.ctpop.i32(i32 %809) #10
  %811 = trunc i32 %810 to i8
  %812 = and i8 %811, 1
  %813 = xor i8 %812, 1
  store i8 %813, i8* %25, align 1, !tbaa !2447
  %814 = xor i64 %805, %804
  %815 = lshr i64 %814, 4
  %816 = trunc i64 %815 to i8
  %817 = and i8 %816, 1
  store i8 %817, i8* %30, align 1, !tbaa !2451
  %818 = icmp eq i64 %805, 0
  %819 = zext i1 %818 to i8
  store i8 %819, i8* %33, align 1, !tbaa !2448
  %820 = lshr i64 %805, 63
  %821 = trunc i64 %820 to i8
  store i8 %821, i8* %36, align 1, !tbaa !2449
  %822 = lshr i64 %804, 63
  %823 = xor i64 %820, %822
  %824 = add nuw nsw i64 %823, %820
  %825 = icmp eq i64 %824, 2
  %826 = zext i1 %825 to i8
  store i8 %826, i8* %42, align 1, !tbaa !2450
  %827 = add i64 %803, 10
  store i64 %827, i64* %PC, align 8
  %828 = add i64 %804, 232
  %829 = inttoptr i64 %805 to i64*
  %830 = load i64, i64* %829, align 8
  store i64 %830, i64* %RBP, align 8, !tbaa !2428
  store i64 %828, i64* %RSP, align 8, !tbaa !2428
  %831 = add i64 %803, 11
  store i64 %831, i64* %PC, align 8
  %832 = inttoptr i64 %828 to i64*
  %833 = load i64, i64* %832, align 8
  store i64 %833, i64* %PC, align 8, !tbaa !2428
  %834 = add i64 %804, 240
  store i64 %834, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %802

block_400d76:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %835 = add i64 %1282, 3
  store i64 %835, i64* %PC, align 8
  store <4 x i32> zeroinitializer, <4 x i32>* %471, align 1, !tbaa !2461
  %.pre84 = load i64, i64* %RBP, align 8
  %.pre85 = load i64, i64* %69, align 1
  br label %block_400d86

block_400ca7:                                     ; preds = %block_400d86, %block_400c7d
  %836 = phi i64 [ %.pre77, %block_400c7d ], [ %1358, %block_400d86 ]
  %MEMORY.1 = phi %struct.Memory* [ %417, %block_400c7d ], [ %1320, %block_400d86 ]
  %837 = load i64, i64* %RBP, align 8
  %838 = add i64 %837, -12
  %839 = add i64 %836, 7
  store i64 %839, i64* %PC, align 8
  %840 = inttoptr i64 %838 to i32*
  %841 = load i32, i32* %840, align 4
  %842 = add i32 %841, -1024
  %843 = icmp ult i32 %841, 1024
  %844 = zext i1 %843 to i8
  store i8 %844, i8* %18, align 1, !tbaa !2433
  %845 = and i32 %842, 255
  %846 = tail call i32 @llvm.ctpop.i32(i32 %845) #10
  %847 = trunc i32 %846 to i8
  %848 = and i8 %847, 1
  %849 = xor i8 %848, 1
  store i8 %849, i8* %25, align 1, !tbaa !2447
  %850 = xor i32 %842, %841
  %851 = lshr i32 %850, 4
  %852 = trunc i32 %851 to i8
  %853 = and i8 %852, 1
  store i8 %853, i8* %30, align 1, !tbaa !2451
  %854 = icmp eq i32 %842, 0
  %855 = zext i1 %854 to i8
  store i8 %855, i8* %33, align 1, !tbaa !2448
  %856 = lshr i32 %842, 31
  %857 = trunc i32 %856 to i8
  store i8 %857, i8* %36, align 1, !tbaa !2449
  %858 = lshr i32 %841, 31
  %859 = xor i32 %856, %858
  %860 = add nuw nsw i32 %859, %858
  %861 = icmp eq i32 %860, 2
  %862 = zext i1 %861 to i8
  store i8 %862, i8* %42, align 1, !tbaa !2450
  %863 = icmp ne i8 %857, 0
  %864 = xor i1 %863, %861
  %.v88 = select i1 %864, i64 13, i64 295
  %865 = add i64 %836, %.v88
  store i64 %865, i64* %PC, align 8, !tbaa !2428
  br i1 %864, label %block_400cb4, label %block_400dce

block_400b23:                                     ; preds = %block_400b16
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RAX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %866 = add i64 %1001, -40
  %867 = add i64 %1030, 21
  store i64 %867, i64* %PC, align 8
  %868 = inttoptr i64 %866 to i64*
  %869 = load i64, i64* %868, align 8
  store i64 %869, i64* %RCX, align 8, !tbaa !2428
  %870 = add i64 %1001, -48
  %871 = add i64 %1030, 25
  store i64 %871, i64* %PC, align 8
  %872 = inttoptr i64 %870 to i64*
  %873 = load i64, i64* %872, align 8
  store i64 %873, i64* %R8, align 8, !tbaa !2428
  %874 = add i64 %1001, -176
  %875 = add i64 %1030, 31
  store i64 %875, i64* %PC, align 8
  %876 = inttoptr i64 %874 to i32*
  store i32 2048, i32* %876, align 4
  %877 = load i64, i64* %RCX, align 8
  %878 = load i64, i64* %PC, align 8
  store i64 %877, i64* %RDI, align 8, !tbaa !2428
  %879 = load i64, i64* %RBP, align 8
  %880 = add i64 %879, -180
  %881 = load i32, i32* %ESI, align 4
  %882 = add i64 %878, 9
  store i64 %882, i64* %PC, align 8
  %883 = inttoptr i64 %880 to i32*
  store i32 %881, i32* %883, align 4
  %884 = load i64, i64* %R8, align 8
  %885 = load i64, i64* %PC, align 8
  store i64 %884, i64* %RSI, align 8, !tbaa !2428
  %886 = add i64 %885, -1083
  %887 = add i64 %885, 8
  %888 = load i64, i64* %RSP, align 8, !tbaa !2428
  %889 = add i64 %888, -8
  %890 = inttoptr i64 %889 to i64*
  store i64 %887, i64* %890, align 8
  store i64 %889, i64* %RSP, align 8, !tbaa !2428
  store i64 %886, i64* %PC, align 8, !tbaa !2428
  %891 = tail call fastcc %struct.Memory* @ext_605128_memcpy(%struct.State* nonnull %0, %struct.Memory* %MEMORY.2)
  %892 = load i64, i64* %RBP, align 8
  %893 = add i64 %892, -40
  %894 = load i64, i64* %PC, align 8
  %895 = add i64 %894, 4
  store i64 %895, i64* %PC, align 8
  %896 = inttoptr i64 %893 to i64*
  %897 = load i64, i64* %896, align 8
  store i64 %897, i64* %RDX, align 8, !tbaa !2428
  %898 = add i64 %892, -24
  %899 = add i64 %894, 8
  store i64 %899, i64* %PC, align 8
  %900 = inttoptr i64 %898 to i64*
  %901 = load i64, i64* %900, align 8
  store i64 %901, i64* %RCX, align 8, !tbaa !2428
  %902 = add i64 %892, -56
  %903 = add i64 %894, 12
  store i64 %903, i64* %PC, align 8
  %904 = inttoptr i64 %902 to i64*
  %905 = load i64, i64* %904, align 8
  store i64 %905, i64* %R8, align 8, !tbaa !2428
  %906 = add i64 %892, -176
  %907 = add i64 %894, 18
  store i64 %907, i64* %PC, align 8
  %908 = inttoptr i64 %906 to i32*
  %909 = load i32, i32* %908, align 4
  %910 = zext i32 %909 to i64
  store i64 %910, i64* %RDI, align 8, !tbaa !2428
  %911 = add i64 %892, -180
  %912 = add i64 %894, 24
  store i64 %912, i64* %PC, align 8
  %913 = inttoptr i64 %911 to i32*
  %914 = load i32, i32* %913, align 4
  %915 = zext i32 %914 to i64
  store i64 %915, i64* %RSI, align 8, !tbaa !2428
  %916 = add i64 %894, 1277
  %917 = add i64 %894, 29
  %918 = load i64, i64* %RSP, align 8, !tbaa !2428
  %919 = add i64 %918, -8
  %920 = inttoptr i64 %919 to i64*
  store i64 %917, i64* %920, align 8
  store i64 %919, i64* %RSP, align 8, !tbaa !2428
  store i64 %916, i64* %PC, align 8, !tbaa !2428
  %921 = tail call %struct.Memory* @sub_401050_cdft(%struct.State* nonnull %0, i64 %916, %struct.Memory* %891)
  %922 = load i64, i64* %RBP, align 8
  %923 = add i64 %922, -100
  %924 = load i64, i64* %PC, align 8
  %925 = add i64 %924, 7
  store i64 %925, i64* %PC, align 8
  %926 = inttoptr i64 %923 to i32*
  store i32 0, i32* %926, align 4
  %.pre86 = load i64, i64* %PC, align 8
  br label %block_400b77

block_400cb4:                                     ; preds = %block_400ca7
  %927 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 48) to i64*), align 16
  store i64 %927, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %928 = add i64 %837, -40
  %929 = add i64 %865, 12
  store i64 %929, i64* %PC, align 8
  %930 = inttoptr i64 %928 to i64*
  %931 = load i64, i64* %930, align 8
  store i64 %931, i64* %RAX, align 8, !tbaa !2428
  %932 = add i64 %865, 15
  store i64 %932, i64* %PC, align 8
  %933 = load i32, i32* %840, align 4
  %934 = shl i32 %933, 1
  %935 = icmp slt i32 %933, 0
  %936 = icmp slt i32 %934, 0
  %937 = xor i1 %935, %936
  %938 = zext i32 %934 to i64
  store i64 %938, i64* %RCX, align 8, !tbaa !2428
  %.lobit61 = lshr i32 %933, 31
  %939 = trunc i32 %.lobit61 to i8
  store i8 %939, i8* %18, align 1, !tbaa !2432
  %940 = and i32 %934, 254
  %941 = tail call i32 @llvm.ctpop.i32(i32 %940) #10
  %942 = trunc i32 %941 to i8
  %943 = and i8 %942, 1
  %944 = xor i8 %943, 1
  store i8 %944, i8* %25, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %945 = icmp eq i32 %934, 0
  %946 = zext i1 %945 to i8
  store i8 %946, i8* %33, align 1, !tbaa !2432
  %947 = lshr i32 %933, 30
  %948 = trunc i32 %947 to i8
  %949 = and i8 %948, 1
  store i8 %949, i8* %36, align 1, !tbaa !2432
  %950 = zext i1 %937 to i8
  store i8 %950, i8* %42, align 1, !tbaa !2432
  %951 = sext i32 %934 to i64
  store i64 %951, i64* %RDX, align 8, !tbaa !2428
  %952 = shl nsw i64 %951, 3
  %953 = add i64 %931, %952
  %954 = add i64 %865, 26
  store i64 %954, i64* %PC, align 8
  %955 = inttoptr i64 %953 to i64*
  %956 = load i64, i64* %955, align 8
  %957 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 96) to i32*), align 16
  %958 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 100) to i32*), align 4
  %959 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 104) to i32*), align 8
  %960 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 108) to i32*), align 4
  store i32 %957, i32* %127, align 1, !tbaa !2454
  store i32 %958, i32* %130, align 1, !tbaa !2454
  store i32 %959, i32* %132, align 1, !tbaa !2454
  store i32 %960, i32* %134, align 1, !tbaa !2454
  %961 = load i64, i64* %368, align 1
  %962 = and i64 %961, %956
  %963 = trunc i64 %962 to i32
  %964 = lshr i64 %962, 32
  %965 = trunc i64 %964 to i32
  store i32 %963, i32* %453, align 1, !tbaa !2461
  store i32 %965, i32* %455, align 1, !tbaa !2461
  store i32 0, i32* %456, align 1, !tbaa !2461
  store i32 0, i32* %458, align 1, !tbaa !2461
  %966 = add i64 %865, 41
  store i64 %966, i64* %PC, align 8
  %967 = load double, double* %99, align 1
  %968 = bitcast i64 %927 to double
  %969 = fcmp uno double %967, %968
  br i1 %969, label %970, label %980

; <label>:970:                                    ; preds = %block_400cb4
  %971 = fadd double %967, %968
  %972 = bitcast double %971 to i64
  %973 = and i64 %972, 9221120237041090560
  %974 = icmp eq i64 %973, 9218868437227405312
  %975 = and i64 %972, 2251799813685247
  %976 = icmp ne i64 %975, 0
  %977 = and i1 %974, %976
  br i1 %977, label %978, label %986

; <label>:978:                                    ; preds = %970
  %979 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %966, %struct.Memory* %MEMORY.1) #15
  %.pre78 = load i64, i64* %PC, align 8
  %.pre79 = load i8, i8* %18, align 1, !tbaa !2433
  %.pre80 = load i8, i8* %33, align 1, !tbaa !2448
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

; <label>:980:                                    ; preds = %block_400cb4
  %981 = fcmp ogt double %967, %968
  br i1 %981, label %986, label %982

; <label>:982:                                    ; preds = %980
  %983 = fcmp olt double %967, %968
  br i1 %983, label %986, label %984

; <label>:984:                                    ; preds = %982
  %985 = fcmp oeq double %967, %968
  br i1 %985, label %986, label %990

; <label>:986:                                    ; preds = %984, %982, %980, %970
  %987 = phi i8 [ 0, %980 ], [ 0, %982 ], [ 1, %984 ], [ 1, %970 ]
  %988 = phi i8 [ 0, %980 ], [ 0, %982 ], [ 0, %984 ], [ 1, %970 ]
  %989 = phi i8 [ 0, %980 ], [ 1, %982 ], [ 0, %984 ], [ 1, %970 ]
  store i8 %987, i8* %33, align 1, !tbaa !2432
  store i8 %988, i8* %25, align 1, !tbaa !2432
  store i8 %989, i8* %18, align 1, !tbaa !2432
  br label %990

; <label>:990:                                    ; preds = %986, %984
  %991 = phi i8 [ %987, %986 ], [ %946, %984 ]
  %992 = phi i8 [ %989, %986 ], [ %939, %984 ]
  store i8 0, i8* %42, align 1, !tbaa !2432
  store i8 0, i8* %36, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1: ; preds = %990, %978
  %993 = phi i8 [ %.pre80, %978 ], [ %991, %990 ]
  %994 = phi i8 [ %.pre79, %978 ], [ %992, %990 ]
  %995 = phi i64 [ %.pre78, %978 ], [ %966, %990 ]
  %996 = phi %struct.Memory* [ %979, %978 ], [ %MEMORY.1, %990 ]
  %997 = or i8 %993, %994
  %998 = icmp ne i8 %997, 0
  %.v89 = select i1 %998, i64 37, i64 6
  %999 = add i64 %995, %.v89
  store i64 %999, i64* %PC, align 8, !tbaa !2428
  br i1 %998, label %block_400d02, label %block_400ce3

block_400b16:                                     ; preds = %block_400acb, %block_400c54
  %1000 = phi i64 [ %.pre76, %block_400acb ], [ %744, %block_400c54 ]
  %MEMORY.2 = phi %struct.Memory* [ %1110, %block_400acb ], [ %712, %block_400c54 ]
  %1001 = load i64, i64* %RBP, align 8
  %1002 = add i64 %1001, -8
  %1003 = add i64 %1000, 7
  store i64 %1003, i64* %PC, align 8
  %1004 = inttoptr i64 %1002 to i32*
  %1005 = load i32, i32* %1004, align 4
  %1006 = add i32 %1005, -150000
  %1007 = icmp ult i32 %1005, 150000
  %1008 = zext i1 %1007 to i8
  store i8 %1008, i8* %18, align 1, !tbaa !2433
  %1009 = and i32 %1006, 255
  %1010 = tail call i32 @llvm.ctpop.i32(i32 %1009) #10
  %1011 = trunc i32 %1010 to i8
  %1012 = and i8 %1011, 1
  %1013 = xor i8 %1012, 1
  store i8 %1013, i8* %25, align 1, !tbaa !2447
  %1014 = xor i32 %1005, 16
  %1015 = xor i32 %1014, %1006
  %1016 = lshr i32 %1015, 4
  %1017 = trunc i32 %1016 to i8
  %1018 = and i8 %1017, 1
  store i8 %1018, i8* %30, align 1, !tbaa !2451
  %1019 = icmp eq i32 %1006, 0
  %1020 = zext i1 %1019 to i8
  store i8 %1020, i8* %33, align 1, !tbaa !2448
  %1021 = lshr i32 %1006, 31
  %1022 = trunc i32 %1021 to i8
  store i8 %1022, i8* %36, align 1, !tbaa !2449
  %1023 = lshr i32 %1005, 31
  %1024 = xor i32 %1021, %1023
  %1025 = add nuw nsw i32 %1024, %1023
  %1026 = icmp eq i32 %1025, 2
  %1027 = zext i1 %1026 to i8
  store i8 %1027, i8* %42, align 1, !tbaa !2450
  %1028 = icmp ne i8 %1022, 0
  %1029 = xor i1 %1028, %1026
  %.v87 = select i1 %1029, i64 13, i64 359
  %1030 = add i64 %1000, %.v87
  store i64 %1030, i64* %PC, align 8, !tbaa !2428
  br i1 %1029, label %block_400b23, label %block_400c7d

block_400a6f:                                     ; preds = %block_400a13, %block_400a7c
  %1031 = phi i64 [ %.pre75, %block_400a13 ], [ %636, %block_400a7c ]
  %1032 = load i64, i64* %RBP, align 8
  %1033 = add i64 %1032, -12
  %1034 = add i64 %1031, 7
  store i64 %1034, i64* %PC, align 8
  %1035 = inttoptr i64 %1033 to i32*
  %1036 = load i32, i32* %1035, align 4
  %1037 = add i32 %1036, -1024
  %1038 = icmp ult i32 %1036, 1024
  %1039 = zext i1 %1038 to i8
  store i8 %1039, i8* %18, align 1, !tbaa !2433
  %1040 = and i32 %1037, 255
  %1041 = tail call i32 @llvm.ctpop.i32(i32 %1040) #10
  %1042 = trunc i32 %1041 to i8
  %1043 = and i8 %1042, 1
  %1044 = xor i8 %1043, 1
  store i8 %1044, i8* %25, align 1, !tbaa !2447
  %1045 = xor i32 %1037, %1036
  %1046 = lshr i32 %1045, 4
  %1047 = trunc i32 %1046 to i8
  %1048 = and i8 %1047, 1
  store i8 %1048, i8* %30, align 1, !tbaa !2451
  %1049 = icmp eq i32 %1037, 0
  %1050 = zext i1 %1049 to i8
  store i8 %1050, i8* %33, align 1, !tbaa !2448
  %1051 = lshr i32 %1037, 31
  %1052 = trunc i32 %1051 to i8
  store i8 %1052, i8* %36, align 1, !tbaa !2449
  %1053 = lshr i32 %1036, 31
  %1054 = xor i32 %1051, %1053
  %1055 = add nuw nsw i32 %1054, %1053
  %1056 = icmp eq i32 %1055, 2
  %1057 = zext i1 %1056 to i8
  store i8 %1057, i8* %42, align 1, !tbaa !2450
  %1058 = icmp ne i8 %1052, 0
  %1059 = xor i1 %1058, %1056
  %.v = select i1 %1059, i64 13, i64 92
  %1060 = add i64 %1031, %.v
  store i64 %1060, i64* %PC, align 8, !tbaa !2428
  br i1 %1059, label %block_400a7c, label %block_400acb

block_400acb:                                     ; preds = %block_400a6f
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  store i8 1, i8* %25, align 1, !tbaa !2447
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %1061 = add i64 %1032, -48
  %1062 = add i64 %1060, 18
  store i64 %1062, i64* %PC, align 8
  %1063 = inttoptr i64 %1061 to i64*
  %1064 = load i64, i64* %1063, align 8
  store i64 %1064, i64* %RDI, align 8, !tbaa !2428
  %1065 = add i64 %1032, -168
  %1066 = add i64 %1060, 24
  store i64 %1066, i64* %PC, align 8
  %1067 = inttoptr i64 %1065 to i32*
  store i32 1023, i32* %1067, align 4
  %1068 = load i32, i32* %EAX, align 4
  %1069 = zext i32 %1068 to i64
  %1070 = load i64, i64* %PC, align 8
  store i64 %1069, i64* %RSI, align 8, !tbaa !2428
  %1071 = load i64, i64* %RBP, align 8
  %1072 = add i64 %1071, -172
  %1073 = add i64 %1070, 8
  store i64 %1073, i64* %PC, align 8
  %1074 = inttoptr i64 %1072 to i32*
  store i32 %1068, i32* %1074, align 4
  %1075 = load i64, i64* %PC, align 8
  %1076 = add i64 %1075, -1019
  %1077 = add i64 %1075, 5
  %1078 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1079 = add i64 %1078, -8
  %1080 = inttoptr i64 %1079 to i64*
  store i64 %1077, i64* %1080, align 8
  store i64 %1079, i64* %RSP, align 8, !tbaa !2428
  store i64 %1076, i64* %PC, align 8, !tbaa !2428
  %1081 = tail call fastcc %struct.Memory* @ext_4006f0_memset(%struct.State* nonnull %0, %struct.Memory* %1185)
  %1082 = load i64, i64* %RBP, align 8
  %1083 = add i64 %1082, -48
  %1084 = load i64, i64* %PC, align 8
  %1085 = add i64 %1084, 4
  store i64 %1085, i64* %PC, align 8
  %1086 = inttoptr i64 %1083 to i64*
  %1087 = load i64, i64* %1086, align 8
  store i64 %1087, i64* %RDX, align 8, !tbaa !2428
  %1088 = add i64 %1082, -172
  %1089 = add i64 %1084, 10
  store i64 %1089, i64* %PC, align 8
  %1090 = inttoptr i64 %1088 to i32*
  %1091 = load i32, i32* %1090, align 4
  %1092 = zext i32 %1091 to i64
  store i64 %1092, i64* %RDI, align 8, !tbaa !2428
  %1093 = add i64 %1082, -168
  %1094 = add i64 %1084, 16
  store i64 %1094, i64* %PC, align 8
  %1095 = inttoptr i64 %1093 to i32*
  %1096 = load i32, i32* %1095, align 4
  %1097 = zext i32 %1096 to i64
  store i64 %1097, i64* %RSI, align 8, !tbaa !2428
  %1098 = add i64 %1084, 1248
  %1099 = add i64 %1084, 21
  %1100 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1101 = add i64 %1100, -8
  %1102 = inttoptr i64 %1101 to i64*
  store i64 %1099, i64* %1102, align 8
  store i64 %1101, i64* %RSP, align 8, !tbaa !2428
  store i64 %1098, i64* %PC, align 8, !tbaa !2428
  %1103 = tail call %struct.Memory* @sub_400fd0_putdata(%struct.State* nonnull %0, i64 %1098, %struct.Memory* %1081)
  %1104 = load i64, i64* %PC, align 8
  %1105 = add i64 %1104, 795
  %1106 = add i64 %1104, 5
  %1107 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1108 = add i64 %1107, -8
  %1109 = inttoptr i64 %1108 to i64*
  store i64 %1106, i64* %1109, align 8
  store i64 %1108, i64* %RSP, align 8, !tbaa !2428
  store i64 %1105, i64* %PC, align 8, !tbaa !2428
  %1110 = tail call %struct.Memory* @sub_400e20_get_time(%struct.State* nonnull %0, i64 %1105, %struct.Memory* %1103)
  %1111 = load i64, i64* %RBP, align 8
  %1112 = add i64 %1111, -64
  %1113 = load i64, i64* %PC, align 8
  %1114 = add i64 %1113, 5
  store i64 %1114, i64* %PC, align 8
  %1115 = load i64, i64* %69, align 1
  %1116 = inttoptr i64 %1112 to i64*
  store i64 %1115, i64* %1116, align 8
  %1117 = load i64, i64* %RBP, align 8
  %1118 = add i64 %1117, -8
  %1119 = load i64, i64* %PC, align 8
  %1120 = add i64 %1119, 7
  store i64 %1120, i64* %PC, align 8
  %1121 = inttoptr i64 %1118 to i32*
  store i32 0, i32* %1121, align 4
  %.pre76 = load i64, i64* %PC, align 8
  br label %block_400b16

block_400a13:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  store i8 1, i8* %25, align 1, !tbaa !2447
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %1122 = load i64, i64* %RBP, align 8
  %1123 = add i64 %1122, -32
  %1124 = add i64 %411, 18
  store i64 %1124, i64* %PC, align 8
  %1125 = inttoptr i64 %1123 to i64*
  %1126 = load i64, i64* %1125, align 8
  store i64 %1126, i64* %RDI, align 8, !tbaa !2428
  %1127 = add i64 %1122, -160
  %1128 = add i64 %411, 24
  store i64 %1128, i64* %PC, align 8
  %1129 = inttoptr i64 %1127 to i32*
  store i32 1023, i32* %1129, align 4
  %1130 = load i32, i32* %EAX, align 4
  %1131 = zext i32 %1130 to i64
  %1132 = load i64, i64* %PC, align 8
  store i64 %1131, i64* %RSI, align 8, !tbaa !2428
  %1133 = load i64, i64* %RBP, align 8
  %1134 = add i64 %1133, -164
  %1135 = add i64 %1132, 8
  store i64 %1135, i64* %PC, align 8
  %1136 = inttoptr i64 %1134 to i32*
  store i32 %1130, i32* %1136, align 4
  %1137 = load i64, i64* %PC, align 8
  %1138 = add i64 %1137, -835
  %1139 = add i64 %1137, 5
  %1140 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1141 = add i64 %1140, -8
  %1142 = inttoptr i64 %1141 to i64*
  store i64 %1139, i64* %1142, align 8
  store i64 %1141, i64* %RSP, align 8, !tbaa !2428
  store i64 %1138, i64* %PC, align 8, !tbaa !2428
  %1143 = tail call fastcc %struct.Memory* @ext_4006f0_memset(%struct.State* nonnull %0, %struct.Memory* %406)
  %1144 = load i64, i64* %RBP, align 8
  %1145 = add i64 %1144, -32
  %1146 = load i64, i64* %PC, align 8
  %1147 = add i64 %1146, 4
  store i64 %1147, i64* %PC, align 8
  %1148 = inttoptr i64 %1145 to i64*
  %1149 = load i64, i64* %1148, align 8
  store i64 %1149, i64* %RDX, align 8, !tbaa !2428
  %1150 = add i64 %1144, -164
  %1151 = add i64 %1146, 10
  store i64 %1151, i64* %PC, align 8
  %1152 = inttoptr i64 %1150 to i32*
  %1153 = load i32, i32* %1152, align 4
  %1154 = zext i32 %1153 to i64
  store i64 %1154, i64* %RDI, align 8, !tbaa !2428
  %1155 = add i64 %1144, -160
  %1156 = add i64 %1146, 16
  store i64 %1156, i64* %PC, align 8
  %1157 = inttoptr i64 %1155 to i32*
  %1158 = load i32, i32* %1157, align 4
  %1159 = zext i32 %1158 to i64
  store i64 %1159, i64* %RSI, align 8, !tbaa !2428
  %1160 = add i64 %1146, 1432
  %1161 = add i64 %1146, 21
  %1162 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1163 = add i64 %1162, -8
  %1164 = inttoptr i64 %1163 to i64*
  store i64 %1161, i64* %1164, align 8
  store i64 %1163, i64* %RSP, align 8, !tbaa !2428
  store i64 %1160, i64* %PC, align 8, !tbaa !2428
  %1165 = tail call %struct.Memory* @sub_400fd0_putdata(%struct.State* nonnull %0, i64 %1160, %struct.Memory* %1143)
  %1166 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %1167 = load i64, i64* %RBP, align 8
  %1168 = add i64 %1167, -32
  %1169 = add i64 %1166, 14
  store i64 %1169, i64* %PC, align 8
  %1170 = inttoptr i64 %1168 to i64*
  %1171 = load i64, i64* %1170, align 8
  store i64 %1171, i64* %RDX, align 8, !tbaa !2428
  %1172 = add i64 %1167, -24
  %1173 = add i64 %1166, 18
  store i64 %1173, i64* %PC, align 8
  %1174 = inttoptr i64 %1172 to i64*
  %1175 = load i64, i64* %1174, align 8
  store i64 %1175, i64* %RCX, align 8, !tbaa !2428
  %1176 = add i64 %1167, -56
  %1177 = add i64 %1166, 22
  store i64 %1177, i64* %PC, align 8
  %1178 = inttoptr i64 %1176 to i64*
  %1179 = load i64, i64* %1178, align 8
  store i64 %1179, i64* %R8, align 8, !tbaa !2428
  %1180 = add i64 %1166, 1539
  %1181 = add i64 %1166, 27
  %1182 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1183 = add i64 %1182, -8
  %1184 = inttoptr i64 %1183 to i64*
  store i64 %1181, i64* %1184, align 8
  store i64 %1183, i64* %RSP, align 8, !tbaa !2428
  store i64 %1180, i64* %PC, align 8, !tbaa !2428
  %1185 = tail call %struct.Memory* @sub_401050_cdft(%struct.State* nonnull %0, i64 %1180, %struct.Memory* %1165)
  %1186 = load i64, i64* %RBP, align 8
  %1187 = add i64 %1186, -12
  %1188 = load i64, i64* %PC, align 8
  %1189 = add i64 %1188, 7
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1187 to i32*
  store i32 0, i32* %1190, align 4
  %.pre75 = load i64, i64* %PC, align 8
  br label %block_400a6f

block_400d12:                                     ; preds = %block_400d02, %block_400ce3
  %1191 = phi i64 [ %.pre82, %block_400d02 ], [ %694, %block_400ce3 ]
  %1192 = phi i64 [ %1637, %block_400d02 ], [ %692, %block_400ce3 ]
  %1193 = phi i64 [ %.pre81, %block_400d02 ], [ %663, %block_400ce3 ]
  %.sink15 = phi i64 [ 5, %block_400d02 ], [ 21, %block_400ce3 ]
  %1194 = add i64 %1193, -192
  %1195 = add i64 %1192, 8
  store i64 %1195, i64* %PC, align 8
  %1196 = inttoptr i64 %1194 to i64*
  store i64 %1191, i64* %1196, align 8
  %1197 = load i64, i64* %PC, align 8
  %1198 = add i64 %1197, %.sink15
  %1199 = load i64, i64* %RBP, align 8
  %1200 = add i64 %1199, -192
  %1201 = add i64 %1198, 8
  store i64 %1201, i64* %PC, align 8
  %1202 = inttoptr i64 %1200 to i64*
  %1203 = load i64, i64* %1202, align 8
  store i64 %1203, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %1204 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 48) to i64*), align 16
  store i64 %1204, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %1205 = add i64 %1199, -40
  %1206 = add i64 %1198, 20
  store i64 %1206, i64* %PC, align 8
  %1207 = inttoptr i64 %1205 to i64*
  %1208 = load i64, i64* %1207, align 8
  store i64 %1208, i64* %RAX, align 8, !tbaa !2428
  %1209 = add i64 %1199, -12
  %1210 = add i64 %1198, 23
  store i64 %1210, i64* %PC, align 8
  %1211 = inttoptr i64 %1209 to i32*
  %1212 = load i32, i32* %1211, align 4
  %1213 = shl i32 %1212, 1
  %1214 = or i32 %1213, 1
  %1215 = zext i32 %1214 to i64
  store i64 %1215, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %1216 = and i32 %1214, 255
  %1217 = tail call i32 @llvm.ctpop.i32(i32 %1216) #10
  %1218 = trunc i32 %1217 to i8
  %1219 = and i8 %1218, 1
  %1220 = xor i8 %1219, 1
  store i8 %1220, i8* %25, align 1, !tbaa !2447
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1221 = lshr i32 %1212, 30
  %1222 = and i32 %1221, 1
  %1223 = trunc i32 %1222 to i8
  store i8 %1223, i8* %36, align 1, !tbaa !2449
  %1224 = lshr i32 %1212, 30
  %1225 = and i32 %1224, 1
  %1226 = xor i32 %1222, %1225
  %1227 = add nuw nsw i32 %1226, %1222
  %1228 = icmp eq i32 %1227, 2
  %1229 = zext i1 %1228 to i8
  store i8 %1229, i8* %42, align 1, !tbaa !2450
  %1230 = sext i32 %1214 to i64
  store i64 %1230, i64* %RDX, align 8, !tbaa !2428
  %1231 = shl nsw i64 %1230, 3
  %1232 = add i64 %1208, %1231
  %1233 = add i64 %1198, 37
  store i64 %1233, i64* %PC, align 8
  %1234 = inttoptr i64 %1232 to i64*
  %1235 = load i64, i64* %1234, align 8
  %1236 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 96) to i32*), align 16
  %1237 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 100) to i32*), align 4
  %1238 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 104) to i32*), align 8
  %1239 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 108) to i32*), align 4
  store i32 %1236, i32* %460, align 1, !tbaa !2454
  store i32 %1237, i32* %462, align 1, !tbaa !2454
  store i32 %1238, i32* %464, align 1, !tbaa !2454
  store i32 %1239, i32* %466, align 1, !tbaa !2454
  %1240 = load i64, i64* %467, align 1
  %1241 = and i64 %1240, %1235
  %1242 = trunc i64 %1241 to i32
  %1243 = lshr i64 %1241, 32
  %1244 = trunc i64 %1243 to i32
  store i32 %1242, i32* %127, align 1, !tbaa !2461
  store i32 %1244, i32* %130, align 1, !tbaa !2461
  store i32 0, i32* %132, align 1, !tbaa !2461
  store i32 0, i32* %134, align 1, !tbaa !2461
  %1245 = add i64 %1198, 52
  store i64 %1245, i64* %PC, align 8
  %1246 = load double, double* %135, align 1
  %1247 = load double, double* %99, align 1
  %1248 = fcmp uno double %1246, %1247
  br i1 %1248, label %1249, label %1259

; <label>:1249:                                   ; preds = %block_400d12
  %1250 = fadd double %1246, %1247
  %1251 = bitcast double %1250 to i64
  %1252 = and i64 %1251, 9221120237041090560
  %1253 = icmp eq i64 %1252, 9218868437227405312
  %1254 = and i64 %1251, 2251799813685247
  %1255 = icmp ne i64 %1254, 0
  %1256 = and i1 %1253, %1255
  br i1 %1256, label %1257, label %1265

; <label>:1257:                                   ; preds = %1249
  %1258 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %1245, %struct.Memory* %996) #15
  %.pre83 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:1259:                                   ; preds = %block_400d12
  %1260 = fcmp ogt double %1246, %1247
  br i1 %1260, label %1265, label %1261

; <label>:1261:                                   ; preds = %1259
  %1262 = fcmp olt double %1246, %1247
  br i1 %1262, label %1265, label %1263

; <label>:1263:                                   ; preds = %1261
  %1264 = fcmp oeq double %1246, %1247
  br i1 %1264, label %1265, label %1269

; <label>:1265:                                   ; preds = %1263, %1261, %1259, %1249
  %1266 = phi i8 [ 0, %1259 ], [ 0, %1261 ], [ 1, %1263 ], [ 1, %1249 ]
  %1267 = phi i8 [ 0, %1259 ], [ 0, %1261 ], [ 0, %1263 ], [ 1, %1249 ]
  %1268 = phi i8 [ 0, %1259 ], [ 1, %1261 ], [ 0, %1263 ], [ 1, %1249 ]
  store i8 %1266, i8* %33, align 1, !tbaa !2432
  store i8 %1267, i8* %25, align 1, !tbaa !2432
  store i8 %1268, i8* %18, align 1, !tbaa !2432
  br label %1269

; <label>:1269:                                   ; preds = %1265, %1263
  store i8 0, i8* %42, align 1, !tbaa !2432
  store i8 0, i8* %36, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %1269, %1257
  %1270 = phi i64 [ %.pre83, %1257 ], [ %1245, %1269 ]
  %1271 = phi %struct.Memory* [ %1258, %1257 ], [ %996, %1269 ]
  %1272 = load i64, i64* %RBP, align 8
  %1273 = add i64 %1272, -200
  %1274 = add i64 %1270, 8
  store i64 %1274, i64* %PC, align 8
  %1275 = load i64, i64* %69, align 1
  %1276 = inttoptr i64 %1273 to i64*
  store i64 %1275, i64* %1276, align 8
  %1277 = load i64, i64* %PC, align 8
  %1278 = load i8, i8* %18, align 1, !tbaa !2433
  %1279 = load i8, i8* %33, align 1, !tbaa !2448
  %1280 = or i8 %1279, %1278
  %1281 = icmp ne i8 %1280, 0
  %.v98 = select i1 %1281, i64 40, i64 6
  %1282 = add i64 %1277, %.v98
  store i64 %1282, i64* %PC, align 8, !tbaa !2428
  br i1 %1281, label %block_400d76, label %block_400d54

block_400d86:                                     ; preds = %block_400d76, %block_400d54
  %1283 = phi i64 [ %.pre85, %block_400d76 ], [ %503, %block_400d54 ]
  %1284 = phi i64 [ %835, %block_400d76 ], [ %501, %block_400d54 ]
  %1285 = phi i64 [ %.pre84, %block_400d76 ], [ %472, %block_400d54 ]
  %.sink5 = phi i64 [ 5, %block_400d76 ], [ 21, %block_400d54 ]
  %1286 = add i64 %1285, -208
  %1287 = add i64 %1284, 8
  store i64 %1287, i64* %PC, align 8
  %1288 = inttoptr i64 %1286 to i64*
  store i64 %1283, i64* %1288, align 8
  %1289 = load i64, i64* %PC, align 8
  %1290 = add i64 %1289, %.sink5
  %1291 = load i64, i64* %RBP, align 8
  %1292 = add i64 %1291, -208
  %1293 = add i64 %1290, 8
  store i64 %1293, i64* %PC, align 8
  %1294 = inttoptr i64 %1292 to i64*
  %1295 = load i64, i64* %1294, align 8
  store i64 %1295, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  store i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 157), i64* %RDI, align 8, !tbaa !2428
  %1296 = add i64 %1291, -200
  %1297 = add i64 %1290, 26
  store i64 %1297, i64* %PC, align 8
  %1298 = inttoptr i64 %1296 to i64*
  %1299 = load i64, i64* %1298, align 8
  store i64 %1299, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %1300 = add i64 %1291, -216
  %1301 = add i64 %1290, 34
  store i64 %1301, i64* %PC, align 8
  %1302 = inttoptr i64 %1300 to i64*
  store i64 %1295, i64* %1302, align 8
  %1303 = load i64, i64* %PC, align 8
  %1304 = load <2 x i32>, <2 x i32>* %468, align 1
  %1305 = load <2 x i32>, <2 x i32>* %469, align 1
  %1306 = extractelement <2 x i32> %1304, i32 0
  store i32 %1306, i32* %374, align 1, !tbaa !2454
  %1307 = extractelement <2 x i32> %1304, i32 1
  store i32 %1307, i32* %376, align 1, !tbaa !2454
  %1308 = extractelement <2 x i32> %1305, i32 0
  store i32 %1308, i32* %377, align 1, !tbaa !2454
  %1309 = extractelement <2 x i32> %1305, i32 1
  store i32 %1309, i32* %379, align 1, !tbaa !2454
  %1310 = load i64, i64* %RBP, align 8
  %1311 = add i64 %1310, -216
  %1312 = add i64 %1303, 11
  store i64 %1312, i64* %PC, align 8
  %1313 = inttoptr i64 %1311 to i64*
  %1314 = load i64, i64* %1313, align 8
  store i64 %1314, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  store i8 2, i8* %AL, align 1, !tbaa !2432
  %1315 = add i64 %1303, -1752
  %1316 = add i64 %1303, 18
  %1317 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1318 = add i64 %1317, -8
  %1319 = inttoptr i64 %1318 to i64*
  store i64 %1316, i64* %1319, align 8
  store i64 %1318, i64* %RSP, align 8, !tbaa !2428
  store i64 %1315, i64* %PC, align 8, !tbaa !2428
  %1320 = tail call fastcc %struct.Memory* @ext_4006d0_printf(%struct.State* nonnull %0, %struct.Memory* %1271)
  %1321 = load i64, i64* %RBP, align 8
  %1322 = add i64 %1321, -220
  %1323 = load i32, i32* %EAX, align 4
  %1324 = load i64, i64* %PC, align 8
  %1325 = add i64 %1324, 6
  store i64 %1325, i64* %PC, align 8
  %1326 = inttoptr i64 %1322 to i32*
  store i32 %1323, i32* %1326, align 4
  %1327 = load i64, i64* %RBP, align 8
  %1328 = add i64 %1327, -12
  %1329 = load i64, i64* %PC, align 8
  %1330 = add i64 %1329, 3
  store i64 %1330, i64* %PC, align 8
  %1331 = inttoptr i64 %1328 to i32*
  %1332 = load i32, i32* %1331, align 4
  %1333 = add i32 %1332, 1
  %1334 = zext i32 %1333 to i64
  store i64 %1334, i64* %RAX, align 8, !tbaa !2428
  %1335 = icmp eq i32 %1332, -1
  %1336 = icmp eq i32 %1333, 0
  %1337 = or i1 %1335, %1336
  %1338 = zext i1 %1337 to i8
  store i8 %1338, i8* %18, align 1, !tbaa !2433
  %1339 = and i32 %1333, 255
  %1340 = tail call i32 @llvm.ctpop.i32(i32 %1339) #10
  %1341 = trunc i32 %1340 to i8
  %1342 = and i8 %1341, 1
  %1343 = xor i8 %1342, 1
  store i8 %1343, i8* %25, align 1, !tbaa !2447
  %1344 = xor i32 %1333, %1332
  %1345 = lshr i32 %1344, 4
  %1346 = trunc i32 %1345 to i8
  %1347 = and i8 %1346, 1
  store i8 %1347, i8* %30, align 1, !tbaa !2451
  %1348 = zext i1 %1336 to i8
  store i8 %1348, i8* %33, align 1, !tbaa !2448
  %1349 = lshr i32 %1333, 31
  %1350 = trunc i32 %1349 to i8
  store i8 %1350, i8* %36, align 1, !tbaa !2449
  %1351 = lshr i32 %1332, 31
  %1352 = xor i32 %1349, %1351
  %1353 = add nuw nsw i32 %1352, %1349
  %1354 = icmp eq i32 %1353, 2
  %1355 = zext i1 %1354 to i8
  store i8 %1355, i8* %42, align 1, !tbaa !2450
  %1356 = add i64 %1329, 9
  store i64 %1356, i64* %PC, align 8
  store i32 %1333, i32* %1331, align 4
  %1357 = load i64, i64* %PC, align 8
  %1358 = add i64 %1357, -290
  store i64 %1358, i64* %PC, align 8, !tbaa !2428
  br label %block_400ca7

block_400b84:                                     ; preds = %block_400b77
  %1359 = add i64 %505, -40
  %1360 = add i64 %533, 4
  store i64 %1360, i64* %PC, align 8
  %1361 = inttoptr i64 %1359 to i64*
  %1362 = load i64, i64* %1361, align 8
  store i64 %1362, i64* %RAX, align 8, !tbaa !2428
  %1363 = add i64 %533, 7
  store i64 %1363, i64* %PC, align 8
  %1364 = load i32, i32* %508, align 4
  %1365 = shl i32 %1364, 1
  %1366 = icmp slt i32 %1364, 0
  %1367 = icmp slt i32 %1365, 0
  %1368 = xor i1 %1366, %1367
  %1369 = zext i32 %1365 to i64
  store i64 %1369, i64* %RCX, align 8, !tbaa !2428
  %.lobit55 = lshr i32 %1364, 31
  %1370 = trunc i32 %.lobit55 to i8
  store i8 %1370, i8* %18, align 1, !tbaa !2432
  %1371 = and i32 %1365, 254
  %1372 = tail call i32 @llvm.ctpop.i32(i32 %1371) #10
  %1373 = trunc i32 %1372 to i8
  %1374 = and i8 %1373, 1
  %1375 = xor i8 %1374, 1
  store i8 %1375, i8* %25, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %1376 = icmp eq i32 %1365, 0
  %1377 = zext i1 %1376 to i8
  store i8 %1377, i8* %33, align 1, !tbaa !2432
  %1378 = lshr i32 %1364, 30
  %1379 = trunc i32 %1378 to i8
  %1380 = and i8 %1379, 1
  store i8 %1380, i8* %36, align 1, !tbaa !2432
  %1381 = zext i1 %1368 to i8
  store i8 %1381, i8* %42, align 1, !tbaa !2432
  %1382 = sext i32 %1365 to i64
  store i64 %1382, i64* %RDX, align 8, !tbaa !2428
  %1383 = shl nsw i64 %1382, 3
  %1384 = add i64 %1362, %1383
  %1385 = add i64 %533, 18
  store i64 %1385, i64* %PC, align 8
  %1386 = inttoptr i64 %1384 to i64*
  %1387 = load i64, i64* %1386, align 8
  store i64 %1387, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %1388 = add i64 %505, -112
  %1389 = add i64 %533, 23
  store i64 %1389, i64* %PC, align 8
  %1390 = inttoptr i64 %1388 to i64*
  store i64 %1387, i64* %1390, align 8
  %1391 = load i64, i64* %RBP, align 8
  %1392 = add i64 %1391, -32
  %1393 = load i64, i64* %PC, align 8
  %1394 = add i64 %1393, 4
  store i64 %1394, i64* %PC, align 8
  %1395 = inttoptr i64 %1392 to i64*
  %1396 = load i64, i64* %1395, align 8
  store i64 %1396, i64* %RAX, align 8, !tbaa !2428
  %1397 = add i64 %1391, -100
  %1398 = add i64 %1393, 7
  store i64 %1398, i64* %PC, align 8
  %1399 = inttoptr i64 %1397 to i32*
  %1400 = load i32, i32* %1399, align 4
  %1401 = shl i32 %1400, 1
  %1402 = icmp slt i32 %1400, 0
  %1403 = icmp slt i32 %1401, 0
  %1404 = xor i1 %1402, %1403
  %1405 = zext i32 %1401 to i64
  store i64 %1405, i64* %RCX, align 8, !tbaa !2428
  %.lobit56 = lshr i32 %1400, 31
  %1406 = trunc i32 %.lobit56 to i8
  store i8 %1406, i8* %18, align 1, !tbaa !2432
  %1407 = and i32 %1401, 254
  %1408 = tail call i32 @llvm.ctpop.i32(i32 %1407) #10
  %1409 = trunc i32 %1408 to i8
  %1410 = and i8 %1409, 1
  %1411 = xor i8 %1410, 1
  store i8 %1411, i8* %25, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %1412 = icmp eq i32 %1401, 0
  %1413 = zext i1 %1412 to i8
  store i8 %1413, i8* %33, align 1, !tbaa !2432
  %1414 = lshr i32 %1400, 30
  %1415 = trunc i32 %1414 to i8
  %1416 = and i8 %1415, 1
  store i8 %1416, i8* %36, align 1, !tbaa !2432
  %1417 = zext i1 %1404 to i8
  store i8 %1417, i8* %42, align 1, !tbaa !2432
  %1418 = sext i32 %1401 to i64
  store i64 %1418, i64* %RDX, align 8, !tbaa !2428
  %1419 = shl nsw i64 %1418, 3
  %1420 = add i64 %1396, %1419
  %1421 = add i64 %1393, 18
  store i64 %1421, i64* %PC, align 8
  %1422 = inttoptr i64 %1420 to i64*
  %1423 = load i64, i64* %1422, align 8
  store i64 %1423, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %1424 = add i64 %1391, -120
  %1425 = add i64 %1393, 23
  store i64 %1425, i64* %PC, align 8
  %1426 = inttoptr i64 %1424 to i64*
  store i64 %1423, i64* %1426, align 8
  %1427 = load i64, i64* %RBP, align 8
  %1428 = add i64 %1427, -40
  %1429 = load i64, i64* %PC, align 8
  %1430 = add i64 %1429, 4
  store i64 %1430, i64* %PC, align 8
  %1431 = inttoptr i64 %1428 to i64*
  %1432 = load i64, i64* %1431, align 8
  store i64 %1432, i64* %RAX, align 8, !tbaa !2428
  %1433 = add i64 %1427, -100
  %1434 = add i64 %1429, 7
  store i64 %1434, i64* %PC, align 8
  %1435 = inttoptr i64 %1433 to i32*
  %1436 = load i32, i32* %1435, align 4
  %1437 = shl i32 %1436, 1
  %1438 = or i32 %1437, 1
  %1439 = zext i32 %1438 to i64
  store i64 %1439, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %1440 = and i32 %1438, 255
  %1441 = tail call i32 @llvm.ctpop.i32(i32 %1440) #10
  %1442 = trunc i32 %1441 to i8
  %1443 = and i8 %1442, 1
  %1444 = xor i8 %1443, 1
  store i8 %1444, i8* %25, align 1, !tbaa !2447
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1445 = lshr i32 %1436, 30
  %1446 = and i32 %1445, 1
  %1447 = trunc i32 %1446 to i8
  store i8 %1447, i8* %36, align 1, !tbaa !2449
  %1448 = lshr i32 %1436, 30
  %1449 = and i32 %1448, 1
  %1450 = xor i32 %1446, %1449
  %1451 = add nuw nsw i32 %1450, %1446
  %1452 = icmp eq i32 %1451, 2
  %1453 = zext i1 %1452 to i8
  store i8 %1453, i8* %42, align 1, !tbaa !2450
  %1454 = sext i32 %1438 to i64
  store i64 %1454, i64* %RDX, align 8, !tbaa !2428
  %1455 = shl nsw i64 %1454, 3
  %1456 = add i64 %1432, %1455
  %1457 = add i64 %1429, 21
  store i64 %1457, i64* %PC, align 8
  %1458 = inttoptr i64 %1456 to i64*
  %1459 = load i64, i64* %1458, align 8
  store i64 %1459, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %1460 = add i64 %1427, -128
  %1461 = add i64 %1429, 26
  store i64 %1461, i64* %PC, align 8
  %1462 = inttoptr i64 %1460 to i64*
  store i64 %1459, i64* %1462, align 8
  %1463 = load i64, i64* %RBP, align 8
  %1464 = add i64 %1463, -32
  %1465 = load i64, i64* %PC, align 8
  %1466 = add i64 %1465, 4
  store i64 %1466, i64* %PC, align 8
  %1467 = inttoptr i64 %1464 to i64*
  %1468 = load i64, i64* %1467, align 8
  store i64 %1468, i64* %RAX, align 8, !tbaa !2428
  %1469 = add i64 %1463, -100
  %1470 = add i64 %1465, 7
  store i64 %1470, i64* %PC, align 8
  %1471 = inttoptr i64 %1469 to i32*
  %1472 = load i32, i32* %1471, align 4
  %1473 = shl i32 %1472, 1
  %1474 = or i32 %1473, 1
  %1475 = zext i32 %1474 to i64
  store i64 %1475, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %1476 = and i32 %1474, 255
  %1477 = tail call i32 @llvm.ctpop.i32(i32 %1476) #10
  %1478 = trunc i32 %1477 to i8
  %1479 = and i8 %1478, 1
  %1480 = xor i8 %1479, 1
  store i8 %1480, i8* %25, align 1, !tbaa !2447
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1481 = lshr i32 %1472, 30
  %1482 = and i32 %1481, 1
  %1483 = trunc i32 %1482 to i8
  store i8 %1483, i8* %36, align 1, !tbaa !2449
  %1484 = lshr i32 %1472, 30
  %1485 = and i32 %1484, 1
  %1486 = xor i32 %1482, %1485
  %1487 = add nuw nsw i32 %1486, %1482
  %1488 = icmp eq i32 %1487, 2
  %1489 = zext i1 %1488 to i8
  store i8 %1489, i8* %42, align 1, !tbaa !2450
  %1490 = sext i32 %1474 to i64
  store i64 %1490, i64* %RDX, align 8, !tbaa !2428
  %1491 = shl nsw i64 %1490, 3
  %1492 = add i64 %1468, %1491
  %1493 = add i64 %1465, 21
  store i64 %1493, i64* %PC, align 8
  %1494 = inttoptr i64 %1492 to i64*
  %1495 = load i64, i64* %1494, align 8
  store i64 %1495, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %1496 = add i64 %1463, -136
  %1497 = add i64 %1465, 29
  store i64 %1497, i64* %PC, align 8
  %1498 = inttoptr i64 %1496 to i64*
  store i64 %1495, i64* %1498, align 8
  %1499 = load i64, i64* %RBP, align 8
  %1500 = add i64 %1499, -112
  %1501 = load i64, i64* %PC, align 8
  %1502 = add i64 %1501, 5
  store i64 %1502, i64* %PC, align 8
  %1503 = inttoptr i64 %1500 to i64*
  %1504 = load i64, i64* %1503, align 8
  store i64 %1504, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %1505 = add i64 %1499, -120
  %1506 = add i64 %1501, 10
  store i64 %1506, i64* %PC, align 8
  %1507 = bitcast i64 %1504 to double
  %1508 = inttoptr i64 %1505 to double*
  %1509 = load double, double* %1508, align 8
  %1510 = fmul double %1507, %1509
  store double %1510, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %92, align 1, !tbaa !2452
  %1511 = add i64 %1499, -128
  %1512 = add i64 %1501, 15
  store i64 %1512, i64* %PC, align 8
  %1513 = inttoptr i64 %1511 to i64*
  %1514 = load i64, i64* %1513, align 8
  store i64 %1514, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %1515 = add i64 %1499, -136
  %1516 = add i64 %1501, 23
  store i64 %1516, i64* %PC, align 8
  %1517 = bitcast i64 %1514 to double
  %1518 = inttoptr i64 %1515 to double*
  %1519 = load double, double* %1518, align 8
  %1520 = fmul double %1517, %1519
  store double %1520, double* %99, align 1, !tbaa !2452
  store i64 0, i64* %101, align 1, !tbaa !2452
  %1521 = fsub double %1510, %1520
  store double %1521, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %92, align 1, !tbaa !2452
  %1522 = add i64 %1499, -40
  %1523 = add i64 %1501, 31
  store i64 %1523, i64* %PC, align 8
  %1524 = inttoptr i64 %1522 to i64*
  %1525 = load i64, i64* %1524, align 8
  store i64 %1525, i64* %RAX, align 8, !tbaa !2428
  %1526 = add i64 %1499, -100
  %1527 = add i64 %1501, 34
  store i64 %1527, i64* %PC, align 8
  %1528 = inttoptr i64 %1526 to i32*
  %1529 = load i32, i32* %1528, align 4
  %1530 = shl i32 %1529, 1
  %1531 = icmp slt i32 %1529, 0
  %1532 = icmp slt i32 %1530, 0
  %1533 = xor i1 %1531, %1532
  %1534 = zext i32 %1530 to i64
  store i64 %1534, i64* %RCX, align 8, !tbaa !2428
  %.lobit59 = lshr i32 %1529, 31
  %1535 = trunc i32 %.lobit59 to i8
  store i8 %1535, i8* %18, align 1, !tbaa !2432
  %1536 = and i32 %1530, 254
  %1537 = tail call i32 @llvm.ctpop.i32(i32 %1536) #10
  %1538 = trunc i32 %1537 to i8
  %1539 = and i8 %1538, 1
  %1540 = xor i8 %1539, 1
  store i8 %1540, i8* %25, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %1541 = icmp eq i32 %1530, 0
  %1542 = zext i1 %1541 to i8
  store i8 %1542, i8* %33, align 1, !tbaa !2432
  %1543 = lshr i32 %1529, 30
  %1544 = trunc i32 %1543 to i8
  %1545 = and i8 %1544, 1
  store i8 %1545, i8* %36, align 1, !tbaa !2432
  %1546 = zext i1 %1533 to i8
  store i8 %1546, i8* %42, align 1, !tbaa !2432
  %1547 = sext i32 %1530 to i64
  store i64 %1547, i64* %RDX, align 8, !tbaa !2428
  %1548 = shl nsw i64 %1547, 3
  %1549 = add i64 %1525, %1548
  %1550 = add i64 %1501, 45
  store i64 %1550, i64* %PC, align 8
  %1551 = inttoptr i64 %1549 to double*
  store double %1521, double* %1551, align 8
  %1552 = load i64, i64* %RBP, align 8
  %1553 = add i64 %1552, -112
  %1554 = load i64, i64* %PC, align 8
  %1555 = add i64 %1554, 5
  store i64 %1555, i64* %PC, align 8
  %1556 = inttoptr i64 %1553 to i64*
  %1557 = load i64, i64* %1556, align 8
  store i64 %1557, i64* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %93, align 1, !tbaa !2452
  %1558 = add i64 %1552, -136
  %1559 = add i64 %1554, 13
  store i64 %1559, i64* %PC, align 8
  %1560 = bitcast i64 %1557 to double
  %1561 = inttoptr i64 %1558 to double*
  %1562 = load double, double* %1561, align 8
  %1563 = fmul double %1560, %1562
  store double %1563, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %92, align 1, !tbaa !2452
  %1564 = add i64 %1552, -128
  %1565 = add i64 %1554, 18
  store i64 %1565, i64* %PC, align 8
  %1566 = inttoptr i64 %1564 to i64*
  %1567 = load i64, i64* %1566, align 8
  store i64 %1567, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %1568 = add i64 %1552, -120
  %1569 = add i64 %1554, 23
  store i64 %1569, i64* %PC, align 8
  %1570 = bitcast i64 %1567 to double
  %1571 = inttoptr i64 %1568 to double*
  %1572 = load double, double* %1571, align 8
  %1573 = fmul double %1570, %1572
  store double %1573, double* %99, align 1, !tbaa !2452
  store i64 0, i64* %101, align 1, !tbaa !2452
  %1574 = fadd double %1563, %1573
  store double %1574, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %92, align 1, !tbaa !2452
  %1575 = add i64 %1552, -40
  %1576 = add i64 %1554, 31
  store i64 %1576, i64* %PC, align 8
  %1577 = inttoptr i64 %1575 to i64*
  %1578 = load i64, i64* %1577, align 8
  store i64 %1578, i64* %RAX, align 8, !tbaa !2428
  %1579 = add i64 %1552, -100
  %1580 = add i64 %1554, 34
  store i64 %1580, i64* %PC, align 8
  %1581 = inttoptr i64 %1579 to i32*
  %1582 = load i32, i32* %1581, align 4
  %1583 = shl i32 %1582, 1
  %1584 = or i32 %1583, 1
  %1585 = zext i32 %1584 to i64
  store i64 %1585, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %1586 = and i32 %1584, 255
  %1587 = tail call i32 @llvm.ctpop.i32(i32 %1586) #10
  %1588 = trunc i32 %1587 to i8
  %1589 = and i8 %1588, 1
  %1590 = xor i8 %1589, 1
  store i8 %1590, i8* %25, align 1, !tbaa !2447
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1591 = lshr i32 %1582, 30
  %1592 = and i32 %1591, 1
  %1593 = trunc i32 %1592 to i8
  store i8 %1593, i8* %36, align 1, !tbaa !2449
  %1594 = lshr i32 %1582, 30
  %1595 = and i32 %1594, 1
  %1596 = xor i32 %1592, %1595
  %1597 = add nuw nsw i32 %1596, %1592
  %1598 = icmp eq i32 %1597, 2
  %1599 = zext i1 %1598 to i8
  store i8 %1599, i8* %42, align 1, !tbaa !2450
  %1600 = sext i32 %1584 to i64
  store i64 %1600, i64* %RDX, align 8, !tbaa !2428
  %1601 = shl nsw i64 %1600, 3
  %1602 = add i64 %1578, %1601
  %1603 = add i64 %1554, 48
  store i64 %1603, i64* %PC, align 8
  %1604 = inttoptr i64 %1602 to double*
  store double %1574, double* %1604, align 8
  %1605 = load i64, i64* %RBP, align 8
  %1606 = add i64 %1605, -100
  %1607 = load i64, i64* %PC, align 8
  %1608 = add i64 %1607, 3
  store i64 %1608, i64* %PC, align 8
  %1609 = inttoptr i64 %1606 to i32*
  %1610 = load i32, i32* %1609, align 4
  %1611 = add i32 %1610, 1
  %1612 = zext i32 %1611 to i64
  store i64 %1612, i64* %RAX, align 8, !tbaa !2428
  %1613 = icmp eq i32 %1610, -1
  %1614 = icmp eq i32 %1611, 0
  %1615 = or i1 %1613, %1614
  %1616 = zext i1 %1615 to i8
  store i8 %1616, i8* %18, align 1, !tbaa !2433
  %1617 = and i32 %1611, 255
  %1618 = tail call i32 @llvm.ctpop.i32(i32 %1617) #10
  %1619 = trunc i32 %1618 to i8
  %1620 = and i8 %1619, 1
  %1621 = xor i8 %1620, 1
  store i8 %1621, i8* %25, align 1, !tbaa !2447
  %1622 = xor i32 %1611, %1610
  %1623 = lshr i32 %1622, 4
  %1624 = trunc i32 %1623 to i8
  %1625 = and i8 %1624, 1
  store i8 %1625, i8* %30, align 1, !tbaa !2451
  %1626 = zext i1 %1614 to i8
  store i8 %1626, i8* %33, align 1, !tbaa !2448
  %1627 = lshr i32 %1611, 31
  %1628 = trunc i32 %1627 to i8
  store i8 %1628, i8* %36, align 1, !tbaa !2449
  %1629 = lshr i32 %1610, 31
  %1630 = xor i32 %1627, %1629
  %1631 = add nuw nsw i32 %1630, %1627
  %1632 = icmp eq i32 %1631, 2
  %1633 = zext i1 %1632 to i8
  store i8 %1633, i8* %42, align 1, !tbaa !2450
  %1634 = add i64 %1607, 9
  store i64 %1634, i64* %PC, align 8
  store i32 %1611, i32* %1609, align 4
  %1635 = load i64, i64* %PC, align 8
  %1636 = add i64 %1635, -216
  store i64 %1636, i64* %PC, align 8, !tbaa !2428
  br label %block_400b77

block_400d02:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  %1637 = add i64 %999, 3
  store i64 %1637, i64* %PC, align 8
  store <4 x i32> zeroinitializer, <4 x i32>* %470, align 1, !tbaa !2461
  %.pre81 = load i64, i64* %RBP, align 8
  %.pre82 = load i64, i64* %69, align 1
  br label %block_400d12
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400750__start(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400750:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  store i64 0, i64* %RBP, align 8, !tbaa !2428
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %3, align 1, !tbaa !2433
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %4, align 1, !tbaa !2447
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %5, align 1, !tbaa !2448
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %6, align 1, !tbaa !2449
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %7, align 1, !tbaa !2450
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %8, align 1, !tbaa !2451
  %9 = load i64, i64* %RDX, align 8
  store i64 %9, i64* %R9, align 8, !tbaa !2428
  %10 = add i64 %1, 6
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %RSP, align 8, !tbaa !2428
  %12 = add i64 %11, 8
  %13 = inttoptr i64 %11 to i64*
  %14 = load i64, i64* %13, align 8
  store i64 %14, i64* %RSI, align 8, !tbaa !2428
  store i64 %12, i64* %RDX, align 8, !tbaa !2428
  %15 = and i64 %12, -16
  store i8 0, i8* %3, align 1, !tbaa !2433
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 240
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #10
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  store i8 %21, i8* %4, align 1, !tbaa !2447
  %22 = icmp eq i64 %15, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %5, align 1, !tbaa !2448
  %24 = lshr i64 %12, 63
  %25 = trunc i64 %24 to i8
  store i8 %25, i8* %6, align 1, !tbaa !2449
  store i8 0, i8* %7, align 1, !tbaa !2450
  store i8 0, i8* %8, align 1, !tbaa !2451
  %26 = load i64, i64* %RAX, align 8
  %27 = add i64 %1, 14
  store i64 %27, i64* %PC, align 8
  %28 = add i64 %15, -8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29, align 8
  %30 = load i64, i64* %PC, align 8
  %31 = add i64 %30, 1
  store i64 %31, i64* %PC, align 8
  %32 = add i64 %15, -16
  %33 = inttoptr i64 %32 to i64*
  store i64 %28, i64* %33, align 16
  %34 = load i64, i64* %PC, align 8
  store i64 ptrtoint (void ()* @callback_sub_404080___libc_csu_fini to i64), i64* %R8, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @callback_sub_404010___libc_csu_init to i64), i64* %RCX, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @main to i64), i64* %RDI, align 8, !tbaa !2428
  %35 = add i64 %34, 27
  %36 = add i64 %15, -24
  %37 = inttoptr i64 %36 to i64*
  store i64 %35, i64* %37, align 8
  store i64 %36, i64* %RSP, align 8, !tbaa !2428
  %38 = load i64, i64* getelementptr inbounds (%seg_604ff0__got_type, %seg_604ff0__got_type* @seg_604ff0__got, i64 0, i32 0), align 8
  store i64 %38, i64* %PC, align 8, !tbaa !2428
  %39 = tail call fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State* nonnull %0, %struct.Memory* %2)
  %40 = load i64, i64* %PC, align 8
  %41 = add i64 %40, 1
  store i64 %41, i64* %PC, align 8
  %42 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %41, %struct.Memory* %39)
  ret %struct.Memory* %42
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4011e0_bitrv2(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_4011e0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  store i64 %8, i64* %6, align 8, !tbaa !2428
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -12
  %12 = load i32, i32* %EDI, align 4
  %13 = add i64 %10, 6
  store i64 %13, i64* %PC, align 8
  %14 = inttoptr i64 %11 to i32*
  store i32 %12, i32* %14, align 4
  %15 = load i64, i64* %RBP, align 8
  %16 = add i64 %15, -16
  %17 = load i64, i64* %RSI, align 8
  %18 = load i64, i64* %PC, align 8
  %19 = add i64 %18, 4
  store i64 %19, i64* %PC, align 8
  %20 = inttoptr i64 %16 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %RBP, align 8
  %22 = add i64 %21, -24
  %23 = load i64, i64* %RDX, align 8
  %24 = load i64, i64* %PC, align 8
  %25 = add i64 %24, 4
  store i64 %25, i64* %PC, align 8
  %26 = inttoptr i64 %22 to i64*
  store i64 %23, i64* %26, align 8
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %27, -16
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %28 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %RDX, align 8, !tbaa !2428
  %33 = add i64 %29, 10
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i32*
  store i32 0, i32* %34, align 4
  %35 = load i64, i64* %RBP, align 8
  %36 = add i64 %35, -4
  %37 = load i64, i64* %PC, align 8
  %38 = add i64 %37, 3
  store i64 %38, i64* %PC, align 8
  %39 = inttoptr i64 %36 to i32*
  %40 = load i32, i32* %39, align 4
  %41 = zext i32 %40 to i64
  store i64 %41, i64* %RDI, align 8, !tbaa !2428
  %42 = add i64 %35, -44
  %43 = add i64 %37, 6
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -48
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 7
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %46 to i32*
  store i32 1, i32* %49, align 4
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %.pre = load i64, i64* %PC, align 8
  br label %block_401206

block_401852.loopexit:                            ; preds = %block_40128a
  br label %block_401852

block_401852.loopexit76:                          ; preds = %block_40168b
  br label %block_401852

block_401852:                                     ; preds = %block_401852.loopexit76, %block_401852.loopexit
  %56 = phi i64 [ %3045, %block_401852.loopexit ], [ %2969, %block_401852.loopexit76 ]
  %.sink5 = phi i64 [ 468, %block_401852.loopexit ], [ 6, %block_401852.loopexit76 ]
  %57 = add i64 %.sink5, %56
  store i64 %57, i64* %PC, align 8
  %58 = load i64, i64* %6, align 8, !tbaa !2428
  %59 = add i64 %58, 8
  %60 = inttoptr i64 %58 to i64*
  %61 = load i64, i64* %60, align 8
  store i64 %61, i64* %RBP, align 8, !tbaa !2428
  store i64 %59, i64* %6, align 8, !tbaa !2428
  %62 = add i64 %57, 1
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %59 to i64*
  %64 = load i64, i64* %63, align 8
  store i64 %64, i64* %PC, align 8, !tbaa !2428
  %65 = add i64 %58, 16
  store i64 %65, i64* %6, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_40183a:                                     ; preds = %block_40169e
  %66 = add i64 %3007, 8
  store i64 %66, i64* %PC, align 8
  %67 = load i32, i32* %2979, align 4
  %68 = add i32 %67, 1
  %69 = zext i32 %68 to i64
  store i64 %69, i64* %RAX, align 8, !tbaa !2428
  %70 = icmp eq i32 %67, -1
  %71 = icmp eq i32 %68, 0
  %72 = or i1 %70, %71
  %73 = zext i1 %72 to i8
  store i8 %73, i8* %50, align 1, !tbaa !2433
  %74 = and i32 %68, 255
  %75 = tail call i32 @llvm.ctpop.i32(i32 %74) #10
  %76 = trunc i32 %75 to i8
  %77 = and i8 %76, 1
  %78 = xor i8 %77, 1
  store i8 %78, i8* %51, align 1, !tbaa !2447
  %79 = xor i32 %68, %67
  %80 = lshr i32 %79, 4
  %81 = trunc i32 %80 to i8
  %82 = and i8 %81, 1
  store i8 %82, i8* %52, align 1, !tbaa !2451
  %83 = zext i1 %71 to i8
  store i8 %83, i8* %53, align 1, !tbaa !2448
  %84 = lshr i32 %68, 31
  %85 = trunc i32 %84 to i8
  store i8 %85, i8* %54, align 1, !tbaa !2449
  %86 = lshr i32 %67, 31
  %87 = xor i32 %84, %86
  %88 = add nuw nsw i32 %87, %84
  %89 = icmp eq i32 %88, 2
  %90 = zext i1 %89 to i8
  store i8 %90, i8* %55, align 1, !tbaa !2450
  %91 = add i64 %3007, 14
  store i64 %91, i64* %PC, align 8
  store i32 %68, i32* %2979, align 4
  %92 = load i64, i64* %PC, align 8
  %93 = add i64 %92, -445
  store i64 %93, i64* %PC, align 8, !tbaa !2428
  br label %block_40168b

block_40126b:                                     ; preds = %block_401206
  %94 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %95 = add i64 %3120, 3
  store i64 %95, i64* %PC, align 8
  %96 = load i32, i32* %3072, align 4
  %97 = shl i32 %96, 1
  %98 = icmp slt i32 %96, 0
  %99 = icmp slt i32 %97, 0
  %100 = xor i1 %98, %99
  %101 = zext i32 %97 to i64
  store i64 %101, i64* %RAX, align 8, !tbaa !2428
  %.lobit12 = lshr i32 %96, 31
  %102 = trunc i32 %.lobit12 to i8
  store i8 %102, i8* %50, align 1, !tbaa !2432
  %103 = and i32 %97, 254
  %104 = tail call i32 @llvm.ctpop.i32(i32 %103) #10
  %105 = trunc i32 %104 to i8
  %106 = and i8 %105, 1
  %107 = xor i8 %106, 1
  store i8 %107, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %108 = icmp eq i32 %97, 0
  %109 = zext i1 %108 to i8
  store i8 %109, i8* %53, align 1, !tbaa !2432
  %110 = lshr i32 %96, 30
  %111 = trunc i32 %110 to i8
  %112 = and i8 %111, 1
  store i8 %112, i8* %54, align 1, !tbaa !2432
  %113 = zext i1 %100 to i8
  store i8 %113, i8* %55, align 1, !tbaa !2432
  %114 = add i64 %3069, -52
  %115 = add i64 %3120, 9
  store i64 %115, i64* %PC, align 8
  %116 = inttoptr i64 %114 to i32*
  store i32 %97, i32* %116, align 4
  %117 = load i64, i64* %RBP, align 8
  %118 = add i64 %117, -48
  %119 = load i64, i64* %PC, align 8
  %120 = add i64 %119, 3
  store i64 %120, i64* %PC, align 8
  %121 = inttoptr i64 %118 to i32*
  %122 = load i32, i32* %121, align 4
  %123 = shl i32 %122, 3
  %124 = zext i32 %123 to i64
  store i64 %124, i64* %RAX, align 8, !tbaa !2428
  %125 = lshr i32 %122, 29
  %126 = trunc i32 %125 to i8
  %127 = and i8 %126, 1
  store i8 %127, i8* %50, align 1, !tbaa !2432
  %128 = and i32 %123, 248
  %129 = tail call i32 @llvm.ctpop.i32(i32 %128) #10
  %130 = trunc i32 %129 to i8
  %131 = and i8 %130, 1
  %132 = xor i8 %131, 1
  store i8 %132, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %133 = icmp eq i32 %123, 0
  %134 = zext i1 %133 to i8
  store i8 %134, i8* %53, align 1, !tbaa !2432
  %135 = lshr i32 %122, 28
  %136 = trunc i32 %135 to i8
  %137 = and i8 %136, 1
  store i8 %137, i8* %54, align 1, !tbaa !2432
  store i8 0, i8* %55, align 1, !tbaa !2432
  %138 = add i64 %117, -44
  %139 = add i64 %119, 9
  store i64 %139, i64* %PC, align 8
  %140 = inttoptr i64 %138 to i32*
  %141 = load i32, i32* %140, align 4
  %142 = sub i32 %123, %141
  %143 = icmp ult i32 %123, %141
  %144 = zext i1 %143 to i8
  store i8 %144, i8* %50, align 1, !tbaa !2433
  %145 = and i32 %142, 255
  %146 = tail call i32 @llvm.ctpop.i32(i32 %145) #10
  %147 = trunc i32 %146 to i8
  %148 = and i8 %147, 1
  %149 = xor i8 %148, 1
  store i8 %149, i8* %51, align 1, !tbaa !2447
  %150 = xor i32 %141, %123
  %151 = xor i32 %150, %142
  %152 = lshr i32 %151, 4
  %153 = trunc i32 %152 to i8
  %154 = and i8 %153, 1
  store i8 %154, i8* %52, align 1, !tbaa !2451
  %155 = icmp eq i32 %142, 0
  %156 = zext i1 %155 to i8
  store i8 %156, i8* %53, align 1, !tbaa !2448
  %157 = lshr i32 %142, 31
  %158 = trunc i32 %157 to i8
  store i8 %158, i8* %54, align 1, !tbaa !2449
  %159 = lshr i32 %122, 28
  %160 = and i32 %159, 1
  %161 = lshr i32 %141, 31
  %162 = xor i32 %161, %160
  %163 = xor i32 %157, %160
  %164 = add nuw nsw i32 %163, %162
  %165 = icmp eq i32 %164, 2
  %166 = zext i1 %165 to i8
  store i8 %166, i8* %55, align 1, !tbaa !2450
  %.v = select i1 %155, i64 15, i64 1040
  %167 = add i64 %119, %.v
  %168 = add i64 %117, -36
  %169 = add i64 %167, 7
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %168 to i32*
  br i1 %155, label %block_401283, label %block_401684

block_401231:                                     ; preds = %block_401225
  %171 = add i64 %2099, -16
  %172 = add i64 %2135, 4
  store i64 %172, i64* %PC, align 8
  %173 = inttoptr i64 %171 to i64*
  %174 = load i64, i64* %173, align 8
  store i64 %174, i64* %RAX, align 8, !tbaa !2428
  %175 = add i64 %2135, 8
  store i64 %175, i64* %PC, align 8
  %176 = load i32, i32* %2102, align 4
  %177 = sext i32 %176 to i64
  store i64 %177, i64* %RCX, align 8, !tbaa !2428
  %178 = shl nsw i64 %177, 2
  %179 = add i64 %178, %174
  %180 = add i64 %2135, 11
  store i64 %180, i64* %PC, align 8
  %181 = inttoptr i64 %179 to i32*
  %182 = load i32, i32* %181, align 4
  %183 = zext i32 %182 to i64
  store i64 %183, i64* %RDX, align 8, !tbaa !2428
  %184 = add i64 %2099, -44
  %185 = add i64 %2135, 14
  store i64 %185, i64* %PC, align 8
  %186 = inttoptr i64 %184 to i32*
  %187 = load i32, i32* %186, align 4
  %188 = add i32 %187, %182
  %189 = zext i32 %188 to i64
  store i64 %189, i64* %RDX, align 8, !tbaa !2428
  %190 = icmp ult i32 %188, %182
  %191 = icmp ult i32 %188, %187
  %192 = or i1 %190, %191
  %193 = zext i1 %192 to i8
  store i8 %193, i8* %50, align 1, !tbaa !2433
  %194 = and i32 %188, 255
  %195 = tail call i32 @llvm.ctpop.i32(i32 %194) #10
  %196 = trunc i32 %195 to i8
  %197 = and i8 %196, 1
  %198 = xor i8 %197, 1
  store i8 %198, i8* %51, align 1, !tbaa !2447
  %199 = xor i32 %187, %182
  %200 = xor i32 %199, %188
  %201 = lshr i32 %200, 4
  %202 = trunc i32 %201 to i8
  %203 = and i8 %202, 1
  store i8 %203, i8* %52, align 1, !tbaa !2451
  %204 = icmp eq i32 %188, 0
  %205 = zext i1 %204 to i8
  store i8 %205, i8* %53, align 1, !tbaa !2448
  %206 = lshr i32 %188, 31
  %207 = trunc i32 %206 to i8
  store i8 %207, i8* %54, align 1, !tbaa !2449
  %208 = lshr i32 %182, 31
  %209 = lshr i32 %187, 31
  %210 = xor i32 %206, %208
  %211 = xor i32 %206, %209
  %212 = add nuw nsw i32 %210, %211
  %213 = icmp eq i32 %212, 2
  %214 = zext i1 %213 to i8
  store i8 %214, i8* %55, align 1, !tbaa !2450
  %215 = add i64 %2135, 18
  store i64 %215, i64* %PC, align 8
  %216 = load i64, i64* %173, align 8
  store i64 %216, i64* %RAX, align 8, !tbaa !2428
  %217 = add i64 %2135, 21
  store i64 %217, i64* %PC, align 8
  %218 = load i32, i32* %2107, align 4
  %219 = zext i32 %218 to i64
  store i64 %219, i64* %RSI, align 8, !tbaa !2428
  %220 = add i64 %2135, 24
  store i64 %220, i64* %PC, align 8
  %221 = load i32, i32* %2102, align 4
  %222 = add i32 %221, %218
  %223 = zext i32 %222 to i64
  store i64 %223, i64* %RSI, align 8, !tbaa !2428
  %224 = icmp ult i32 %222, %218
  %225 = icmp ult i32 %222, %221
  %226 = or i1 %224, %225
  %227 = zext i1 %226 to i8
  store i8 %227, i8* %50, align 1, !tbaa !2433
  %228 = and i32 %222, 255
  %229 = tail call i32 @llvm.ctpop.i32(i32 %228) #10
  %230 = trunc i32 %229 to i8
  %231 = and i8 %230, 1
  %232 = xor i8 %231, 1
  store i8 %232, i8* %51, align 1, !tbaa !2447
  %233 = xor i32 %221, %218
  %234 = xor i32 %233, %222
  %235 = lshr i32 %234, 4
  %236 = trunc i32 %235 to i8
  %237 = and i8 %236, 1
  store i8 %237, i8* %52, align 1, !tbaa !2451
  %238 = icmp eq i32 %222, 0
  %239 = zext i1 %238 to i8
  store i8 %239, i8* %53, align 1, !tbaa !2448
  %240 = lshr i32 %222, 31
  %241 = trunc i32 %240 to i8
  store i8 %241, i8* %54, align 1, !tbaa !2449
  %242 = lshr i32 %218, 31
  %243 = lshr i32 %221, 31
  %244 = xor i32 %240, %242
  %245 = xor i32 %240, %243
  %246 = add nuw nsw i32 %244, %245
  %247 = icmp eq i32 %246, 2
  %248 = zext i1 %247 to i8
  store i8 %248, i8* %55, align 1, !tbaa !2450
  %249 = sext i32 %222 to i64
  store i64 %249, i64* %RCX, align 8, !tbaa !2428
  %250 = shl nsw i64 %249, 2
  %251 = add i64 %216, %250
  %252 = add i64 %2135, 30
  store i64 %252, i64* %PC, align 8
  %253 = inttoptr i64 %251 to i32*
  store i32 %188, i32* %253, align 4
  %254 = load i64, i64* %RBP, align 8
  %255 = add i64 %254, -28
  %256 = load i64, i64* %PC, align 8
  %257 = add i64 %256, 3
  store i64 %257, i64* %PC, align 8
  %258 = inttoptr i64 %255 to i32*
  %259 = load i32, i32* %258, align 4
  %260 = add i32 %259, 1
  %261 = zext i32 %260 to i64
  store i64 %261, i64* %RAX, align 8, !tbaa !2428
  %262 = icmp eq i32 %259, -1
  %263 = icmp eq i32 %260, 0
  %264 = or i1 %262, %263
  %265 = zext i1 %264 to i8
  store i8 %265, i8* %50, align 1, !tbaa !2433
  %266 = and i32 %260, 255
  %267 = tail call i32 @llvm.ctpop.i32(i32 %266) #10
  %268 = trunc i32 %267 to i8
  %269 = and i8 %268, 1
  %270 = xor i8 %269, 1
  store i8 %270, i8* %51, align 1, !tbaa !2447
  %271 = xor i32 %260, %259
  %272 = lshr i32 %271, 4
  %273 = trunc i32 %272 to i8
  %274 = and i8 %273, 1
  store i8 %274, i8* %52, align 1, !tbaa !2451
  %275 = zext i1 %263 to i8
  store i8 %275, i8* %53, align 1, !tbaa !2448
  %276 = lshr i32 %260, 31
  %277 = trunc i32 %276 to i8
  store i8 %277, i8* %54, align 1, !tbaa !2449
  %278 = lshr i32 %259, 31
  %279 = xor i32 %276, %278
  %280 = add nuw nsw i32 %279, %276
  %281 = icmp eq i32 %280, 2
  %282 = zext i1 %281 to i8
  store i8 %282, i8* %55, align 1, !tbaa !2450
  %283 = add i64 %256, 9
  store i64 %283, i64* %PC, align 8
  store i32 %260, i32* %258, align 4
  %284 = load i64, i64* %PC, align 8
  %285 = add i64 %284, -51
  store i64 %285, i64* %PC, align 8, !tbaa !2428
  br label %block_401225

block_4015ad:                                     ; preds = %block_40129d
  %286 = load i32, i32* %2145, align 4
  %287 = shl i32 %286, 1
  %288 = icmp slt i32 %286, 0
  %289 = icmp slt i32 %287, 0
  %290 = xor i1 %288, %289
  %291 = zext i32 %287 to i64
  store i64 %291, i64* %RAX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %286, 31
  %292 = trunc i32 %.lobit18 to i8
  store i8 %292, i8* %50, align 1, !tbaa !2432
  %293 = and i32 %287, 254
  %294 = tail call i32 @llvm.ctpop.i32(i32 %293) #10
  %295 = trunc i32 %294 to i8
  %296 = and i8 %295, 1
  %297 = xor i8 %296, 1
  store i8 %297, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %298 = icmp eq i32 %287, 0
  %299 = zext i1 %298 to i8
  store i8 %299, i8* %53, align 1, !tbaa !2432
  %300 = lshr i32 %286, 30
  %301 = trunc i32 %300 to i8
  %302 = and i8 %301, 1
  store i8 %302, i8* %54, align 1, !tbaa !2432
  %303 = zext i1 %290 to i8
  store i8 %303, i8* %55, align 1, !tbaa !2432
  %304 = add i64 %2137, -52
  %305 = add i64 %2173, 9
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to i32*
  %307 = load i32, i32* %306, align 4
  %308 = add i32 %307, %287
  %309 = zext i32 %308 to i64
  store i64 %309, i64* %RAX, align 8, !tbaa !2428
  %310 = icmp ult i32 %308, %287
  %311 = icmp ult i32 %308, %307
  %312 = or i1 %310, %311
  %313 = zext i1 %312 to i8
  store i8 %313, i8* %50, align 1, !tbaa !2433
  %314 = and i32 %308, 255
  %315 = tail call i32 @llvm.ctpop.i32(i32 %314) #10
  %316 = trunc i32 %315 to i8
  %317 = and i8 %316, 1
  %318 = xor i8 %317, 1
  store i8 %318, i8* %51, align 1, !tbaa !2447
  %319 = xor i32 %307, %287
  %320 = xor i32 %319, %308
  %321 = lshr i32 %320, 4
  %322 = trunc i32 %321 to i8
  %323 = and i8 %322, 1
  store i8 %323, i8* %52, align 1, !tbaa !2451
  %324 = icmp eq i32 %308, 0
  %325 = zext i1 %324 to i8
  store i8 %325, i8* %53, align 1, !tbaa !2448
  %326 = lshr i32 %308, 31
  %327 = trunc i32 %326 to i8
  store i8 %327, i8* %54, align 1, !tbaa !2449
  %328 = lshr i32 %286, 30
  %329 = and i32 %328, 1
  %330 = lshr i32 %307, 31
  %331 = xor i32 %326, %329
  %332 = xor i32 %326, %330
  %333 = add nuw nsw i32 %331, %332
  %334 = icmp eq i32 %333, 2
  %335 = zext i1 %334 to i8
  store i8 %335, i8* %55, align 1, !tbaa !2450
  %336 = add i64 %2137, -16
  %337 = add i64 %2173, 13
  store i64 %337, i64* %PC, align 8
  %338 = inttoptr i64 %336 to i64*
  %339 = load i64, i64* %338, align 8
  store i64 %339, i64* %RCX, align 8, !tbaa !2428
  %340 = add i64 %2173, 17
  store i64 %340, i64* %PC, align 8
  %341 = load i32, i32* %2145, align 4
  %342 = sext i32 %341 to i64
  store i64 %342, i64* %RDX, align 8, !tbaa !2428
  %343 = shl nsw i64 %342, 2
  %344 = add i64 %339, %343
  %345 = add i64 %2173, 20
  store i64 %345, i64* %PC, align 8
  %346 = inttoptr i64 %344 to i32*
  %347 = load i32, i32* %346, align 4
  %348 = add i32 %347, %308
  %349 = zext i32 %348 to i64
  store i64 %349, i64* %RAX, align 8, !tbaa !2428
  %350 = icmp ult i32 %348, %308
  %351 = icmp ult i32 %348, %347
  %352 = or i1 %350, %351
  %353 = zext i1 %352 to i8
  store i8 %353, i8* %50, align 1, !tbaa !2433
  %354 = and i32 %348, 255
  %355 = tail call i32 @llvm.ctpop.i32(i32 %354) #10
  %356 = trunc i32 %355 to i8
  %357 = and i8 %356, 1
  %358 = xor i8 %357, 1
  store i8 %358, i8* %51, align 1, !tbaa !2447
  %359 = xor i32 %347, %308
  %360 = xor i32 %359, %348
  %361 = lshr i32 %360, 4
  %362 = trunc i32 %361 to i8
  %363 = and i8 %362, 1
  store i8 %363, i8* %52, align 1, !tbaa !2451
  %364 = icmp eq i32 %348, 0
  %365 = zext i1 %364 to i8
  store i8 %365, i8* %53, align 1, !tbaa !2448
  %366 = lshr i32 %348, 31
  %367 = trunc i32 %366 to i8
  store i8 %367, i8* %54, align 1, !tbaa !2449
  %368 = lshr i32 %347, 31
  %369 = xor i32 %366, %326
  %370 = xor i32 %366, %368
  %371 = add nuw nsw i32 %369, %370
  %372 = icmp eq i32 %371, 2
  %373 = zext i1 %372 to i8
  store i8 %373, i8* %55, align 1, !tbaa !2450
  %374 = load i64, i64* %RBP, align 8
  %375 = add i64 %374, -32
  %376 = add i64 %2173, 23
  store i64 %376, i64* %PC, align 8
  %377 = inttoptr i64 %375 to i32*
  store i32 %348, i32* %377, align 4
  %378 = load i64, i64* %RBP, align 8
  %379 = add i64 %378, -32
  %380 = load i64, i64* %PC, align 8
  %381 = add i64 %380, 3
  store i64 %381, i64* %PC, align 8
  %382 = inttoptr i64 %379 to i32*
  %383 = load i32, i32* %382, align 4
  %384 = zext i32 %383 to i64
  store i64 %384, i64* %RAX, align 8, !tbaa !2428
  %385 = add i64 %378, -52
  %386 = add i64 %380, 6
  store i64 %386, i64* %PC, align 8
  %387 = inttoptr i64 %385 to i32*
  %388 = load i32, i32* %387, align 4
  %389 = add i32 %388, %383
  %390 = zext i32 %389 to i64
  store i64 %390, i64* %RAX, align 8, !tbaa !2428
  %391 = icmp ult i32 %389, %383
  %392 = icmp ult i32 %389, %388
  %393 = or i1 %391, %392
  %394 = zext i1 %393 to i8
  store i8 %394, i8* %50, align 1, !tbaa !2433
  %395 = and i32 %389, 255
  %396 = tail call i32 @llvm.ctpop.i32(i32 %395) #10
  %397 = trunc i32 %396 to i8
  %398 = and i8 %397, 1
  %399 = xor i8 %398, 1
  store i8 %399, i8* %51, align 1, !tbaa !2447
  %400 = xor i32 %388, %383
  %401 = xor i32 %400, %389
  %402 = lshr i32 %401, 4
  %403 = trunc i32 %402 to i8
  %404 = and i8 %403, 1
  store i8 %404, i8* %52, align 1, !tbaa !2451
  %405 = icmp eq i32 %389, 0
  %406 = zext i1 %405 to i8
  store i8 %406, i8* %53, align 1, !tbaa !2448
  %407 = lshr i32 %389, 31
  %408 = trunc i32 %407 to i8
  store i8 %408, i8* %54, align 1, !tbaa !2449
  %409 = lshr i32 %383, 31
  %410 = lshr i32 %388, 31
  %411 = xor i32 %407, %409
  %412 = xor i32 %407, %410
  %413 = add nuw nsw i32 %411, %412
  %414 = icmp eq i32 %413, 2
  %415 = zext i1 %414 to i8
  store i8 %415, i8* %55, align 1, !tbaa !2450
  %416 = add i64 %378, -40
  %417 = add i64 %380, 9
  store i64 %417, i64* %PC, align 8
  %418 = inttoptr i64 %416 to i32*
  store i32 %389, i32* %418, align 4
  %419 = load i64, i64* %RBP, align 8
  %420 = add i64 %419, -24
  %421 = load i64, i64* %PC, align 8
  %422 = add i64 %421, 4
  store i64 %422, i64* %PC, align 8
  %423 = inttoptr i64 %420 to i64*
  %424 = load i64, i64* %423, align 8
  store i64 %424, i64* %RCX, align 8, !tbaa !2428
  %425 = add i64 %419, -32
  %426 = add i64 %421, 8
  store i64 %426, i64* %PC, align 8
  %427 = inttoptr i64 %425 to i32*
  %428 = load i32, i32* %427, align 4
  %429 = sext i32 %428 to i64
  store i64 %429, i64* %RDX, align 8, !tbaa !2428
  %430 = shl nsw i64 %429, 3
  %431 = add i64 %430, %424
  %432 = add i64 %421, 13
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %431 to i64*
  %434 = load i64, i64* %433, align 8
  store i64 %434, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %435 = add i64 %419, -64
  %436 = add i64 %421, 18
  store i64 %436, i64* %PC, align 8
  %437 = inttoptr i64 %435 to i64*
  store i64 %434, i64* %437, align 8
  %438 = load i64, i64* %RBP, align 8
  %439 = add i64 %438, -24
  %440 = load i64, i64* %PC, align 8
  %441 = add i64 %440, 4
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %439 to i64*
  %443 = load i64, i64* %442, align 8
  store i64 %443, i64* %RCX, align 8, !tbaa !2428
  %444 = add i64 %438, -32
  %445 = add i64 %440, 7
  store i64 %445, i64* %PC, align 8
  %446 = inttoptr i64 %444 to i32*
  %447 = load i32, i32* %446, align 4
  %448 = add i32 %447, 1
  %449 = zext i32 %448 to i64
  store i64 %449, i64* %RAX, align 8, !tbaa !2428
  %450 = icmp eq i32 %447, -1
  %451 = icmp eq i32 %448, 0
  %452 = or i1 %450, %451
  %453 = zext i1 %452 to i8
  store i8 %453, i8* %50, align 1, !tbaa !2433
  %454 = and i32 %448, 255
  %455 = tail call i32 @llvm.ctpop.i32(i32 %454) #10
  %456 = trunc i32 %455 to i8
  %457 = and i8 %456, 1
  %458 = xor i8 %457, 1
  store i8 %458, i8* %51, align 1, !tbaa !2447
  %459 = xor i32 %448, %447
  %460 = lshr i32 %459, 4
  %461 = trunc i32 %460 to i8
  %462 = and i8 %461, 1
  store i8 %462, i8* %52, align 1, !tbaa !2451
  %463 = zext i1 %451 to i8
  store i8 %463, i8* %53, align 1, !tbaa !2448
  %464 = lshr i32 %448, 31
  %465 = trunc i32 %464 to i8
  store i8 %465, i8* %54, align 1, !tbaa !2449
  %466 = lshr i32 %447, 31
  %467 = xor i32 %464, %466
  %468 = add nuw nsw i32 %467, %464
  %469 = icmp eq i32 %468, 2
  %470 = zext i1 %469 to i8
  store i8 %470, i8* %55, align 1, !tbaa !2450
  %471 = sext i32 %448 to i64
  store i64 %471, i64* %RDX, align 8, !tbaa !2428
  %472 = shl nsw i64 %471, 3
  %473 = add i64 %443, %472
  %474 = add i64 %440, 18
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to i64*
  %476 = load i64, i64* %475, align 8
  store i64 %476, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %477 = add i64 %438, -72
  %478 = add i64 %440, 23
  store i64 %478, i64* %PC, align 8
  %479 = inttoptr i64 %477 to i64*
  store i64 %476, i64* %479, align 8
  %480 = load i64, i64* %RBP, align 8
  %481 = add i64 %480, -24
  %482 = load i64, i64* %PC, align 8
  %483 = add i64 %482, 4
  store i64 %483, i64* %PC, align 8
  %484 = inttoptr i64 %481 to i64*
  %485 = load i64, i64* %484, align 8
  store i64 %485, i64* %RCX, align 8, !tbaa !2428
  %486 = add i64 %480, -40
  %487 = add i64 %482, 8
  store i64 %487, i64* %PC, align 8
  %488 = inttoptr i64 %486 to i32*
  %489 = load i32, i32* %488, align 4
  %490 = sext i32 %489 to i64
  store i64 %490, i64* %RDX, align 8, !tbaa !2428
  %491 = shl nsw i64 %490, 3
  %492 = add i64 %491, %485
  %493 = add i64 %482, 13
  store i64 %493, i64* %PC, align 8
  %494 = inttoptr i64 %492 to i64*
  %495 = load i64, i64* %494, align 8
  store i64 %495, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %496 = add i64 %480, -80
  %497 = add i64 %482, 18
  store i64 %497, i64* %PC, align 8
  %498 = inttoptr i64 %496 to i64*
  store i64 %495, i64* %498, align 8
  %499 = load i64, i64* %RBP, align 8
  %500 = add i64 %499, -24
  %501 = load i64, i64* %PC, align 8
  %502 = add i64 %501, 4
  store i64 %502, i64* %PC, align 8
  %503 = inttoptr i64 %500 to i64*
  %504 = load i64, i64* %503, align 8
  store i64 %504, i64* %RCX, align 8, !tbaa !2428
  %505 = add i64 %499, -40
  %506 = add i64 %501, 7
  store i64 %506, i64* %PC, align 8
  %507 = inttoptr i64 %505 to i32*
  %508 = load i32, i32* %507, align 4
  %509 = add i32 %508, 1
  %510 = zext i32 %509 to i64
  store i64 %510, i64* %RAX, align 8, !tbaa !2428
  %511 = icmp eq i32 %508, -1
  %512 = icmp eq i32 %509, 0
  %513 = or i1 %511, %512
  %514 = zext i1 %513 to i8
  store i8 %514, i8* %50, align 1, !tbaa !2433
  %515 = and i32 %509, 255
  %516 = tail call i32 @llvm.ctpop.i32(i32 %515) #10
  %517 = trunc i32 %516 to i8
  %518 = and i8 %517, 1
  %519 = xor i8 %518, 1
  store i8 %519, i8* %51, align 1, !tbaa !2447
  %520 = xor i32 %509, %508
  %521 = lshr i32 %520, 4
  %522 = trunc i32 %521 to i8
  %523 = and i8 %522, 1
  store i8 %523, i8* %52, align 1, !tbaa !2451
  %524 = zext i1 %512 to i8
  store i8 %524, i8* %53, align 1, !tbaa !2448
  %525 = lshr i32 %509, 31
  %526 = trunc i32 %525 to i8
  store i8 %526, i8* %54, align 1, !tbaa !2449
  %527 = lshr i32 %508, 31
  %528 = xor i32 %525, %527
  %529 = add nuw nsw i32 %528, %525
  %530 = icmp eq i32 %529, 2
  %531 = zext i1 %530 to i8
  store i8 %531, i8* %55, align 1, !tbaa !2450
  %532 = sext i32 %509 to i64
  store i64 %532, i64* %RDX, align 8, !tbaa !2428
  %533 = shl nsw i64 %532, 3
  %534 = add i64 %504, %533
  %535 = add i64 %501, 18
  store i64 %535, i64* %PC, align 8
  %536 = inttoptr i64 %534 to i64*
  %537 = load i64, i64* %536, align 8
  store i64 %537, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %538 = add i64 %499, -88
  %539 = add i64 %501, 23
  store i64 %539, i64* %PC, align 8
  %540 = inttoptr i64 %538 to i64*
  store i64 %537, i64* %540, align 8
  %541 = load i64, i64* %RBP, align 8
  %542 = add i64 %541, -80
  %543 = load i64, i64* %PC, align 8
  %544 = add i64 %543, 5
  store i64 %544, i64* %PC, align 8
  %545 = inttoptr i64 %542 to i64*
  %546 = load i64, i64* %545, align 8
  store i64 %546, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %547 = add i64 %541, -24
  %548 = add i64 %543, 9
  store i64 %548, i64* %PC, align 8
  %549 = inttoptr i64 %547 to i64*
  %550 = load i64, i64* %549, align 8
  store i64 %550, i64* %RCX, align 8, !tbaa !2428
  %551 = add i64 %541, -32
  %552 = add i64 %543, 13
  store i64 %552, i64* %PC, align 8
  %553 = inttoptr i64 %551 to i32*
  %554 = load i32, i32* %553, align 4
  %555 = sext i32 %554 to i64
  store i64 %555, i64* %RDX, align 8, !tbaa !2428
  %556 = shl nsw i64 %555, 3
  %557 = add i64 %556, %550
  %558 = add i64 %543, 18
  store i64 %558, i64* %PC, align 8
  %559 = inttoptr i64 %557 to i64*
  store i64 %546, i64* %559, align 8
  %560 = load i64, i64* %RBP, align 8
  %561 = add i64 %560, -88
  %562 = load i64, i64* %PC, align 8
  %563 = add i64 %562, 5
  store i64 %563, i64* %PC, align 8
  %564 = inttoptr i64 %561 to i64*
  %565 = load i64, i64* %564, align 8
  store i64 %565, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %566 = add i64 %560, -24
  %567 = add i64 %562, 9
  store i64 %567, i64* %PC, align 8
  %568 = inttoptr i64 %566 to i64*
  %569 = load i64, i64* %568, align 8
  store i64 %569, i64* %RCX, align 8, !tbaa !2428
  %570 = add i64 %560, -32
  %571 = add i64 %562, 12
  store i64 %571, i64* %PC, align 8
  %572 = inttoptr i64 %570 to i32*
  %573 = load i32, i32* %572, align 4
  %574 = add i32 %573, 1
  %575 = zext i32 %574 to i64
  store i64 %575, i64* %RAX, align 8, !tbaa !2428
  %576 = icmp eq i32 %573, -1
  %577 = icmp eq i32 %574, 0
  %578 = or i1 %576, %577
  %579 = zext i1 %578 to i8
  store i8 %579, i8* %50, align 1, !tbaa !2433
  %580 = and i32 %574, 255
  %581 = tail call i32 @llvm.ctpop.i32(i32 %580) #10
  %582 = trunc i32 %581 to i8
  %583 = and i8 %582, 1
  %584 = xor i8 %583, 1
  store i8 %584, i8* %51, align 1, !tbaa !2447
  %585 = xor i32 %574, %573
  %586 = lshr i32 %585, 4
  %587 = trunc i32 %586 to i8
  %588 = and i8 %587, 1
  store i8 %588, i8* %52, align 1, !tbaa !2451
  %589 = zext i1 %577 to i8
  store i8 %589, i8* %53, align 1, !tbaa !2448
  %590 = lshr i32 %574, 31
  %591 = trunc i32 %590 to i8
  store i8 %591, i8* %54, align 1, !tbaa !2449
  %592 = lshr i32 %573, 31
  %593 = xor i32 %590, %592
  %594 = add nuw nsw i32 %593, %590
  %595 = icmp eq i32 %594, 2
  %596 = zext i1 %595 to i8
  store i8 %596, i8* %55, align 1, !tbaa !2450
  %597 = sext i32 %574 to i64
  store i64 %597, i64* %RDX, align 8, !tbaa !2428
  %598 = shl nsw i64 %597, 3
  %599 = add i64 %569, %598
  %600 = add i64 %562, 23
  store i64 %600, i64* %PC, align 8
  %601 = inttoptr i64 %599 to i64*
  store i64 %565, i64* %601, align 8
  %602 = load i64, i64* %RBP, align 8
  %603 = add i64 %602, -64
  %604 = load i64, i64* %PC, align 8
  %605 = add i64 %604, 5
  store i64 %605, i64* %PC, align 8
  %606 = inttoptr i64 %603 to i64*
  %607 = load i64, i64* %606, align 8
  store i64 %607, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %608 = add i64 %602, -24
  %609 = add i64 %604, 9
  store i64 %609, i64* %PC, align 8
  %610 = inttoptr i64 %608 to i64*
  %611 = load i64, i64* %610, align 8
  store i64 %611, i64* %RCX, align 8, !tbaa !2428
  %612 = add i64 %602, -40
  %613 = add i64 %604, 13
  store i64 %613, i64* %PC, align 8
  %614 = inttoptr i64 %612 to i32*
  %615 = load i32, i32* %614, align 4
  %616 = sext i32 %615 to i64
  store i64 %616, i64* %RDX, align 8, !tbaa !2428
  %617 = shl nsw i64 %616, 3
  %618 = add i64 %617, %611
  %619 = add i64 %604, 18
  store i64 %619, i64* %PC, align 8
  %620 = inttoptr i64 %618 to i64*
  store i64 %607, i64* %620, align 8
  %621 = load i64, i64* %RBP, align 8
  %622 = add i64 %621, -72
  %623 = load i64, i64* %PC, align 8
  %624 = add i64 %623, 5
  store i64 %624, i64* %PC, align 8
  %625 = inttoptr i64 %622 to i64*
  %626 = load i64, i64* %625, align 8
  store i64 %626, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %627 = add i64 %621, -24
  %628 = add i64 %623, 9
  store i64 %628, i64* %PC, align 8
  %629 = inttoptr i64 %627 to i64*
  %630 = load i64, i64* %629, align 8
  store i64 %630, i64* %RCX, align 8, !tbaa !2428
  %631 = add i64 %621, -40
  %632 = add i64 %623, 12
  store i64 %632, i64* %PC, align 8
  %633 = inttoptr i64 %631 to i32*
  %634 = load i32, i32* %633, align 4
  %635 = add i32 %634, 1
  %636 = zext i32 %635 to i64
  store i64 %636, i64* %RAX, align 8, !tbaa !2428
  %637 = icmp eq i32 %634, -1
  %638 = icmp eq i32 %635, 0
  %639 = or i1 %637, %638
  %640 = zext i1 %639 to i8
  store i8 %640, i8* %50, align 1, !tbaa !2433
  %641 = and i32 %635, 255
  %642 = tail call i32 @llvm.ctpop.i32(i32 %641) #10
  %643 = trunc i32 %642 to i8
  %644 = and i8 %643, 1
  %645 = xor i8 %644, 1
  store i8 %645, i8* %51, align 1, !tbaa !2447
  %646 = xor i32 %635, %634
  %647 = lshr i32 %646, 4
  %648 = trunc i32 %647 to i8
  %649 = and i8 %648, 1
  store i8 %649, i8* %52, align 1, !tbaa !2451
  %650 = zext i1 %638 to i8
  store i8 %650, i8* %53, align 1, !tbaa !2448
  %651 = lshr i32 %635, 31
  %652 = trunc i32 %651 to i8
  store i8 %652, i8* %54, align 1, !tbaa !2449
  %653 = lshr i32 %634, 31
  %654 = xor i32 %651, %653
  %655 = add nuw nsw i32 %654, %651
  %656 = icmp eq i32 %655, 2
  %657 = zext i1 %656 to i8
  store i8 %657, i8* %55, align 1, !tbaa !2450
  %658 = sext i32 %635 to i64
  store i64 %658, i64* %RDX, align 8, !tbaa !2428
  %659 = shl nsw i64 %658, 3
  %660 = add i64 %630, %659
  %661 = add i64 %623, 23
  store i64 %661, i64* %PC, align 8
  %662 = inttoptr i64 %660 to i64*
  store i64 %626, i64* %662, align 8
  %663 = load i64, i64* %RBP, align 8
  %664 = add i64 %663, -36
  %665 = load i64, i64* %PC, align 8
  %666 = add i64 %665, 3
  store i64 %666, i64* %PC, align 8
  %667 = inttoptr i64 %664 to i32*
  %668 = load i32, i32* %667, align 4
  %669 = add i32 %668, 1
  %670 = zext i32 %669 to i64
  store i64 %670, i64* %RAX, align 8, !tbaa !2428
  %671 = icmp eq i32 %668, -1
  %672 = icmp eq i32 %669, 0
  %673 = or i1 %671, %672
  %674 = zext i1 %673 to i8
  store i8 %674, i8* %50, align 1, !tbaa !2433
  %675 = and i32 %669, 255
  %676 = tail call i32 @llvm.ctpop.i32(i32 %675) #10
  %677 = trunc i32 %676 to i8
  %678 = and i8 %677, 1
  %679 = xor i8 %678, 1
  store i8 %679, i8* %51, align 1, !tbaa !2447
  %680 = xor i32 %669, %668
  %681 = lshr i32 %680, 4
  %682 = trunc i32 %681 to i8
  %683 = and i8 %682, 1
  store i8 %683, i8* %52, align 1, !tbaa !2451
  %684 = zext i1 %672 to i8
  store i8 %684, i8* %53, align 1, !tbaa !2448
  %685 = lshr i32 %669, 31
  %686 = trunc i32 %685 to i8
  store i8 %686, i8* %54, align 1, !tbaa !2449
  %687 = lshr i32 %668, 31
  %688 = xor i32 %685, %687
  %689 = add nuw nsw i32 %688, %685
  %690 = icmp eq i32 %689, 2
  %691 = zext i1 %690 to i8
  store i8 %691, i8* %55, align 1, !tbaa !2450
  %692 = add i64 %665, 9
  store i64 %692, i64* %PC, align 8
  store i32 %669, i32* %667, align 4
  %693 = load i64, i64* %PC, align 8
  %694 = add i64 %693, -1008
  store i64 %694, i64* %PC, align 8, !tbaa !2428
  br label %block_40128a

block_4012a9:                                     ; preds = %block_40129d
  %695 = load i32, i32* %2140, align 4
  %696 = shl i32 %695, 1
  %697 = icmp slt i32 %695, 0
  %698 = icmp slt i32 %696, 0
  %699 = xor i1 %697, %698
  %700 = zext i32 %696 to i64
  store i64 %700, i64* %RAX, align 8, !tbaa !2428
  %.lobit14 = lshr i32 %695, 31
  %701 = trunc i32 %.lobit14 to i8
  store i8 %701, i8* %50, align 1, !tbaa !2432
  %702 = and i32 %696, 254
  %703 = tail call i32 @llvm.ctpop.i32(i32 %702) #10
  %704 = trunc i32 %703 to i8
  %705 = and i8 %704, 1
  %706 = xor i8 %705, 1
  store i8 %706, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %707 = icmp eq i32 %696, 0
  %708 = zext i1 %707 to i8
  store i8 %708, i8* %53, align 1, !tbaa !2432
  %709 = lshr i32 %695, 30
  %710 = trunc i32 %709 to i8
  %711 = and i8 %710, 1
  store i8 %711, i8* %54, align 1, !tbaa !2432
  %712 = zext i1 %699 to i8
  store i8 %712, i8* %55, align 1, !tbaa !2432
  %713 = add i64 %2137, -16
  %714 = add i64 %2173, 10
  store i64 %714, i64* %PC, align 8
  %715 = inttoptr i64 %713 to i64*
  %716 = load i64, i64* %715, align 8
  store i64 %716, i64* %RCX, align 8, !tbaa !2428
  %717 = add i64 %2173, 14
  store i64 %717, i64* %PC, align 8
  %718 = load i32, i32* %2145, align 4
  %719 = sext i32 %718 to i64
  store i64 %719, i64* %RDX, align 8, !tbaa !2428
  %720 = shl nsw i64 %719, 2
  %721 = add i64 %716, %720
  %722 = add i64 %2173, 17
  store i64 %722, i64* %PC, align 8
  %723 = inttoptr i64 %721 to i32*
  %724 = load i32, i32* %723, align 4
  %725 = add i32 %724, %696
  %726 = zext i32 %725 to i64
  store i64 %726, i64* %RAX, align 8, !tbaa !2428
  %727 = icmp ult i32 %725, %696
  %728 = icmp ult i32 %725, %724
  %729 = or i1 %727, %728
  %730 = zext i1 %729 to i8
  store i8 %730, i8* %50, align 1, !tbaa !2433
  %731 = and i32 %725, 255
  %732 = tail call i32 @llvm.ctpop.i32(i32 %731) #10
  %733 = trunc i32 %732 to i8
  %734 = and i8 %733, 1
  %735 = xor i8 %734, 1
  store i8 %735, i8* %51, align 1, !tbaa !2447
  %736 = xor i32 %724, %696
  %737 = xor i32 %736, %725
  %738 = lshr i32 %737, 4
  %739 = trunc i32 %738 to i8
  %740 = and i8 %739, 1
  store i8 %740, i8* %52, align 1, !tbaa !2451
  %741 = icmp eq i32 %725, 0
  %742 = zext i1 %741 to i8
  store i8 %742, i8* %53, align 1, !tbaa !2448
  %743 = lshr i32 %725, 31
  %744 = trunc i32 %743 to i8
  store i8 %744, i8* %54, align 1, !tbaa !2449
  %745 = lshr i32 %695, 30
  %746 = and i32 %745, 1
  %747 = lshr i32 %724, 31
  %748 = xor i32 %743, %746
  %749 = xor i32 %743, %747
  %750 = add nuw nsw i32 %748, %749
  %751 = icmp eq i32 %750, 2
  %752 = zext i1 %751 to i8
  store i8 %752, i8* %55, align 1, !tbaa !2450
  %753 = add i64 %2137, -32
  %754 = add i64 %2173, 20
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %753 to i32*
  store i32 %725, i32* %755, align 4
  %756 = load i64, i64* %RBP, align 8
  %757 = add i64 %756, -36
  %758 = load i64, i64* %PC, align 8
  %759 = add i64 %758, 3
  store i64 %759, i64* %PC, align 8
  %760 = inttoptr i64 %757 to i32*
  %761 = load i32, i32* %760, align 4
  %762 = shl i32 %761, 1
  %763 = icmp slt i32 %761, 0
  %764 = icmp slt i32 %762, 0
  %765 = xor i1 %763, %764
  %766 = zext i32 %762 to i64
  store i64 %766, i64* %RAX, align 8, !tbaa !2428
  %.lobit15 = lshr i32 %761, 31
  %767 = trunc i32 %.lobit15 to i8
  store i8 %767, i8* %50, align 1, !tbaa !2432
  %768 = and i32 %762, 254
  %769 = tail call i32 @llvm.ctpop.i32(i32 %768) #10
  %770 = trunc i32 %769 to i8
  %771 = and i8 %770, 1
  %772 = xor i8 %771, 1
  store i8 %772, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %773 = icmp eq i32 %762, 0
  %774 = zext i1 %773 to i8
  store i8 %774, i8* %53, align 1, !tbaa !2432
  %775 = lshr i32 %761, 30
  %776 = trunc i32 %775 to i8
  %777 = and i8 %776, 1
  store i8 %777, i8* %54, align 1, !tbaa !2432
  %778 = zext i1 %765 to i8
  store i8 %778, i8* %55, align 1, !tbaa !2432
  %779 = add i64 %756, -16
  %780 = add i64 %758, 10
  store i64 %780, i64* %PC, align 8
  %781 = inttoptr i64 %779 to i64*
  %782 = load i64, i64* %781, align 8
  store i64 %782, i64* %RCX, align 8, !tbaa !2428
  %783 = add i64 %756, -28
  %784 = add i64 %758, 14
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %783 to i32*
  %786 = load i32, i32* %785, align 4
  %787 = sext i32 %786 to i64
  store i64 %787, i64* %RDX, align 8, !tbaa !2428
  %788 = shl nsw i64 %787, 2
  %789 = add i64 %782, %788
  %790 = add i64 %758, 17
  store i64 %790, i64* %PC, align 8
  %791 = inttoptr i64 %789 to i32*
  %792 = load i32, i32* %791, align 4
  %793 = add i32 %792, %762
  %794 = zext i32 %793 to i64
  store i64 %794, i64* %RAX, align 8, !tbaa !2428
  %795 = icmp ult i32 %793, %762
  %796 = icmp ult i32 %793, %792
  %797 = or i1 %795, %796
  %798 = zext i1 %797 to i8
  store i8 %798, i8* %50, align 1, !tbaa !2433
  %799 = and i32 %793, 255
  %800 = tail call i32 @llvm.ctpop.i32(i32 %799) #10
  %801 = trunc i32 %800 to i8
  %802 = and i8 %801, 1
  %803 = xor i8 %802, 1
  store i8 %803, i8* %51, align 1, !tbaa !2447
  %804 = xor i32 %792, %762
  %805 = xor i32 %804, %793
  %806 = lshr i32 %805, 4
  %807 = trunc i32 %806 to i8
  %808 = and i8 %807, 1
  store i8 %808, i8* %52, align 1, !tbaa !2451
  %809 = icmp eq i32 %793, 0
  %810 = zext i1 %809 to i8
  store i8 %810, i8* %53, align 1, !tbaa !2448
  %811 = lshr i32 %793, 31
  %812 = trunc i32 %811 to i8
  store i8 %812, i8* %54, align 1, !tbaa !2449
  %813 = lshr i32 %761, 30
  %814 = and i32 %813, 1
  %815 = lshr i32 %792, 31
  %816 = xor i32 %811, %814
  %817 = xor i32 %811, %815
  %818 = add nuw nsw i32 %816, %817
  %819 = icmp eq i32 %818, 2
  %820 = zext i1 %819 to i8
  store i8 %820, i8* %55, align 1, !tbaa !2450
  %821 = add i64 %756, -40
  %822 = add i64 %758, 20
  store i64 %822, i64* %PC, align 8
  %823 = inttoptr i64 %821 to i32*
  store i32 %793, i32* %823, align 4
  %824 = load i64, i64* %RBP, align 8
  %825 = add i64 %824, -24
  %826 = load i64, i64* %PC, align 8
  %827 = add i64 %826, 4
  store i64 %827, i64* %PC, align 8
  %828 = inttoptr i64 %825 to i64*
  %829 = load i64, i64* %828, align 8
  store i64 %829, i64* %RCX, align 8, !tbaa !2428
  %830 = add i64 %824, -32
  %831 = add i64 %826, 8
  store i64 %831, i64* %PC, align 8
  %832 = inttoptr i64 %830 to i32*
  %833 = load i32, i32* %832, align 4
  %834 = sext i32 %833 to i64
  store i64 %834, i64* %RDX, align 8, !tbaa !2428
  %835 = shl nsw i64 %834, 3
  %836 = add i64 %835, %829
  %837 = add i64 %826, 13
  store i64 %837, i64* %PC, align 8
  %838 = inttoptr i64 %836 to i64*
  %839 = load i64, i64* %838, align 8
  store i64 %839, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %840 = add i64 %824, -64
  %841 = add i64 %826, 18
  store i64 %841, i64* %PC, align 8
  %842 = inttoptr i64 %840 to i64*
  store i64 %839, i64* %842, align 8
  %843 = load i64, i64* %RBP, align 8
  %844 = add i64 %843, -24
  %845 = load i64, i64* %PC, align 8
  %846 = add i64 %845, 4
  store i64 %846, i64* %PC, align 8
  %847 = inttoptr i64 %844 to i64*
  %848 = load i64, i64* %847, align 8
  store i64 %848, i64* %RCX, align 8, !tbaa !2428
  %849 = add i64 %843, -32
  %850 = add i64 %845, 7
  store i64 %850, i64* %PC, align 8
  %851 = inttoptr i64 %849 to i32*
  %852 = load i32, i32* %851, align 4
  %853 = add i32 %852, 1
  %854 = zext i32 %853 to i64
  store i64 %854, i64* %RAX, align 8, !tbaa !2428
  %855 = icmp eq i32 %852, -1
  %856 = icmp eq i32 %853, 0
  %857 = or i1 %855, %856
  %858 = zext i1 %857 to i8
  store i8 %858, i8* %50, align 1, !tbaa !2433
  %859 = and i32 %853, 255
  %860 = tail call i32 @llvm.ctpop.i32(i32 %859) #10
  %861 = trunc i32 %860 to i8
  %862 = and i8 %861, 1
  %863 = xor i8 %862, 1
  store i8 %863, i8* %51, align 1, !tbaa !2447
  %864 = xor i32 %853, %852
  %865 = lshr i32 %864, 4
  %866 = trunc i32 %865 to i8
  %867 = and i8 %866, 1
  store i8 %867, i8* %52, align 1, !tbaa !2451
  %868 = zext i1 %856 to i8
  store i8 %868, i8* %53, align 1, !tbaa !2448
  %869 = lshr i32 %853, 31
  %870 = trunc i32 %869 to i8
  store i8 %870, i8* %54, align 1, !tbaa !2449
  %871 = lshr i32 %852, 31
  %872 = xor i32 %869, %871
  %873 = add nuw nsw i32 %872, %869
  %874 = icmp eq i32 %873, 2
  %875 = zext i1 %874 to i8
  store i8 %875, i8* %55, align 1, !tbaa !2450
  %876 = sext i32 %853 to i64
  store i64 %876, i64* %RDX, align 8, !tbaa !2428
  %877 = shl nsw i64 %876, 3
  %878 = add i64 %848, %877
  %879 = add i64 %845, 18
  store i64 %879, i64* %PC, align 8
  %880 = inttoptr i64 %878 to i64*
  %881 = load i64, i64* %880, align 8
  store i64 %881, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %882 = add i64 %843, -72
  %883 = add i64 %845, 23
  store i64 %883, i64* %PC, align 8
  %884 = inttoptr i64 %882 to i64*
  store i64 %881, i64* %884, align 8
  %885 = load i64, i64* %RBP, align 8
  %886 = add i64 %885, -24
  %887 = load i64, i64* %PC, align 8
  %888 = add i64 %887, 4
  store i64 %888, i64* %PC, align 8
  %889 = inttoptr i64 %886 to i64*
  %890 = load i64, i64* %889, align 8
  store i64 %890, i64* %RCX, align 8, !tbaa !2428
  %891 = add i64 %885, -40
  %892 = add i64 %887, 8
  store i64 %892, i64* %PC, align 8
  %893 = inttoptr i64 %891 to i32*
  %894 = load i32, i32* %893, align 4
  %895 = sext i32 %894 to i64
  store i64 %895, i64* %RDX, align 8, !tbaa !2428
  %896 = shl nsw i64 %895, 3
  %897 = add i64 %896, %890
  %898 = add i64 %887, 13
  store i64 %898, i64* %PC, align 8
  %899 = inttoptr i64 %897 to i64*
  %900 = load i64, i64* %899, align 8
  store i64 %900, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %901 = add i64 %885, -80
  %902 = add i64 %887, 18
  store i64 %902, i64* %PC, align 8
  %903 = inttoptr i64 %901 to i64*
  store i64 %900, i64* %903, align 8
  %904 = load i64, i64* %RBP, align 8
  %905 = add i64 %904, -24
  %906 = load i64, i64* %PC, align 8
  %907 = add i64 %906, 4
  store i64 %907, i64* %PC, align 8
  %908 = inttoptr i64 %905 to i64*
  %909 = load i64, i64* %908, align 8
  store i64 %909, i64* %RCX, align 8, !tbaa !2428
  %910 = add i64 %904, -40
  %911 = add i64 %906, 7
  store i64 %911, i64* %PC, align 8
  %912 = inttoptr i64 %910 to i32*
  %913 = load i32, i32* %912, align 4
  %914 = add i32 %913, 1
  %915 = zext i32 %914 to i64
  store i64 %915, i64* %RAX, align 8, !tbaa !2428
  %916 = icmp eq i32 %913, -1
  %917 = icmp eq i32 %914, 0
  %918 = or i1 %916, %917
  %919 = zext i1 %918 to i8
  store i8 %919, i8* %50, align 1, !tbaa !2433
  %920 = and i32 %914, 255
  %921 = tail call i32 @llvm.ctpop.i32(i32 %920) #10
  %922 = trunc i32 %921 to i8
  %923 = and i8 %922, 1
  %924 = xor i8 %923, 1
  store i8 %924, i8* %51, align 1, !tbaa !2447
  %925 = xor i32 %914, %913
  %926 = lshr i32 %925, 4
  %927 = trunc i32 %926 to i8
  %928 = and i8 %927, 1
  store i8 %928, i8* %52, align 1, !tbaa !2451
  %929 = zext i1 %917 to i8
  store i8 %929, i8* %53, align 1, !tbaa !2448
  %930 = lshr i32 %914, 31
  %931 = trunc i32 %930 to i8
  store i8 %931, i8* %54, align 1, !tbaa !2449
  %932 = lshr i32 %913, 31
  %933 = xor i32 %930, %932
  %934 = add nuw nsw i32 %933, %930
  %935 = icmp eq i32 %934, 2
  %936 = zext i1 %935 to i8
  store i8 %936, i8* %55, align 1, !tbaa !2450
  %937 = sext i32 %914 to i64
  store i64 %937, i64* %RDX, align 8, !tbaa !2428
  %938 = shl nsw i64 %937, 3
  %939 = add i64 %909, %938
  %940 = add i64 %906, 18
  store i64 %940, i64* %PC, align 8
  %941 = inttoptr i64 %939 to i64*
  %942 = load i64, i64* %941, align 8
  store i64 %942, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %943 = add i64 %904, -88
  %944 = add i64 %906, 23
  store i64 %944, i64* %PC, align 8
  %945 = inttoptr i64 %943 to i64*
  store i64 %942, i64* %945, align 8
  %946 = load i64, i64* %RBP, align 8
  %947 = add i64 %946, -80
  %948 = load i64, i64* %PC, align 8
  %949 = add i64 %948, 5
  store i64 %949, i64* %PC, align 8
  %950 = inttoptr i64 %947 to i64*
  %951 = load i64, i64* %950, align 8
  store i64 %951, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %952 = add i64 %946, -24
  %953 = add i64 %948, 9
  store i64 %953, i64* %PC, align 8
  %954 = inttoptr i64 %952 to i64*
  %955 = load i64, i64* %954, align 8
  store i64 %955, i64* %RCX, align 8, !tbaa !2428
  %956 = add i64 %946, -32
  %957 = add i64 %948, 13
  store i64 %957, i64* %PC, align 8
  %958 = inttoptr i64 %956 to i32*
  %959 = load i32, i32* %958, align 4
  %960 = sext i32 %959 to i64
  store i64 %960, i64* %RDX, align 8, !tbaa !2428
  %961 = shl nsw i64 %960, 3
  %962 = add i64 %961, %955
  %963 = add i64 %948, 18
  store i64 %963, i64* %PC, align 8
  %964 = inttoptr i64 %962 to i64*
  store i64 %951, i64* %964, align 8
  %965 = load i64, i64* %RBP, align 8
  %966 = add i64 %965, -88
  %967 = load i64, i64* %PC, align 8
  %968 = add i64 %967, 5
  store i64 %968, i64* %PC, align 8
  %969 = inttoptr i64 %966 to i64*
  %970 = load i64, i64* %969, align 8
  store i64 %970, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %971 = add i64 %965, -24
  %972 = add i64 %967, 9
  store i64 %972, i64* %PC, align 8
  %973 = inttoptr i64 %971 to i64*
  %974 = load i64, i64* %973, align 8
  store i64 %974, i64* %RCX, align 8, !tbaa !2428
  %975 = add i64 %965, -32
  %976 = add i64 %967, 12
  store i64 %976, i64* %PC, align 8
  %977 = inttoptr i64 %975 to i32*
  %978 = load i32, i32* %977, align 4
  %979 = add i32 %978, 1
  %980 = zext i32 %979 to i64
  store i64 %980, i64* %RAX, align 8, !tbaa !2428
  %981 = icmp eq i32 %978, -1
  %982 = icmp eq i32 %979, 0
  %983 = or i1 %981, %982
  %984 = zext i1 %983 to i8
  store i8 %984, i8* %50, align 1, !tbaa !2433
  %985 = and i32 %979, 255
  %986 = tail call i32 @llvm.ctpop.i32(i32 %985) #10
  %987 = trunc i32 %986 to i8
  %988 = and i8 %987, 1
  %989 = xor i8 %988, 1
  store i8 %989, i8* %51, align 1, !tbaa !2447
  %990 = xor i32 %979, %978
  %991 = lshr i32 %990, 4
  %992 = trunc i32 %991 to i8
  %993 = and i8 %992, 1
  store i8 %993, i8* %52, align 1, !tbaa !2451
  %994 = zext i1 %982 to i8
  store i8 %994, i8* %53, align 1, !tbaa !2448
  %995 = lshr i32 %979, 31
  %996 = trunc i32 %995 to i8
  store i8 %996, i8* %54, align 1, !tbaa !2449
  %997 = lshr i32 %978, 31
  %998 = xor i32 %995, %997
  %999 = add nuw nsw i32 %998, %995
  %1000 = icmp eq i32 %999, 2
  %1001 = zext i1 %1000 to i8
  store i8 %1001, i8* %55, align 1, !tbaa !2450
  %1002 = sext i32 %979 to i64
  store i64 %1002, i64* %RDX, align 8, !tbaa !2428
  %1003 = shl nsw i64 %1002, 3
  %1004 = add i64 %974, %1003
  %1005 = add i64 %967, 23
  store i64 %1005, i64* %PC, align 8
  %1006 = inttoptr i64 %1004 to i64*
  store i64 %970, i64* %1006, align 8
  %1007 = load i64, i64* %RBP, align 8
  %1008 = add i64 %1007, -64
  %1009 = load i64, i64* %PC, align 8
  %1010 = add i64 %1009, 5
  store i64 %1010, i64* %PC, align 8
  %1011 = inttoptr i64 %1008 to i64*
  %1012 = load i64, i64* %1011, align 8
  store i64 %1012, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1013 = add i64 %1007, -24
  %1014 = add i64 %1009, 9
  store i64 %1014, i64* %PC, align 8
  %1015 = inttoptr i64 %1013 to i64*
  %1016 = load i64, i64* %1015, align 8
  store i64 %1016, i64* %RCX, align 8, !tbaa !2428
  %1017 = add i64 %1007, -40
  %1018 = add i64 %1009, 13
  store i64 %1018, i64* %PC, align 8
  %1019 = inttoptr i64 %1017 to i32*
  %1020 = load i32, i32* %1019, align 4
  %1021 = sext i32 %1020 to i64
  store i64 %1021, i64* %RDX, align 8, !tbaa !2428
  %1022 = shl nsw i64 %1021, 3
  %1023 = add i64 %1022, %1016
  %1024 = add i64 %1009, 18
  store i64 %1024, i64* %PC, align 8
  %1025 = inttoptr i64 %1023 to i64*
  store i64 %1012, i64* %1025, align 8
  %1026 = load i64, i64* %RBP, align 8
  %1027 = add i64 %1026, -72
  %1028 = load i64, i64* %PC, align 8
  %1029 = add i64 %1028, 5
  store i64 %1029, i64* %PC, align 8
  %1030 = inttoptr i64 %1027 to i64*
  %1031 = load i64, i64* %1030, align 8
  store i64 %1031, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1032 = add i64 %1026, -24
  %1033 = add i64 %1028, 9
  store i64 %1033, i64* %PC, align 8
  %1034 = inttoptr i64 %1032 to i64*
  %1035 = load i64, i64* %1034, align 8
  store i64 %1035, i64* %RCX, align 8, !tbaa !2428
  %1036 = add i64 %1026, -40
  %1037 = add i64 %1028, 12
  store i64 %1037, i64* %PC, align 8
  %1038 = inttoptr i64 %1036 to i32*
  %1039 = load i32, i32* %1038, align 4
  %1040 = add i32 %1039, 1
  %1041 = zext i32 %1040 to i64
  store i64 %1041, i64* %RAX, align 8, !tbaa !2428
  %1042 = icmp eq i32 %1039, -1
  %1043 = icmp eq i32 %1040, 0
  %1044 = or i1 %1042, %1043
  %1045 = zext i1 %1044 to i8
  store i8 %1045, i8* %50, align 1, !tbaa !2433
  %1046 = and i32 %1040, 255
  %1047 = tail call i32 @llvm.ctpop.i32(i32 %1046) #10
  %1048 = trunc i32 %1047 to i8
  %1049 = and i8 %1048, 1
  %1050 = xor i8 %1049, 1
  store i8 %1050, i8* %51, align 1, !tbaa !2447
  %1051 = xor i32 %1040, %1039
  %1052 = lshr i32 %1051, 4
  %1053 = trunc i32 %1052 to i8
  %1054 = and i8 %1053, 1
  store i8 %1054, i8* %52, align 1, !tbaa !2451
  %1055 = zext i1 %1043 to i8
  store i8 %1055, i8* %53, align 1, !tbaa !2448
  %1056 = lshr i32 %1040, 31
  %1057 = trunc i32 %1056 to i8
  store i8 %1057, i8* %54, align 1, !tbaa !2449
  %1058 = lshr i32 %1039, 31
  %1059 = xor i32 %1056, %1058
  %1060 = add nuw nsw i32 %1059, %1056
  %1061 = icmp eq i32 %1060, 2
  %1062 = zext i1 %1061 to i8
  store i8 %1062, i8* %55, align 1, !tbaa !2450
  %1063 = sext i32 %1040 to i64
  store i64 %1063, i64* %RDX, align 8, !tbaa !2428
  %1064 = shl nsw i64 %1063, 3
  %1065 = add i64 %1035, %1064
  %1066 = add i64 %1028, 23
  store i64 %1066, i64* %PC, align 8
  %1067 = inttoptr i64 %1065 to i64*
  store i64 %1031, i64* %1067, align 8
  %1068 = load i64, i64* %RBP, align 8
  %1069 = add i64 %1068, -52
  %1070 = load i64, i64* %PC, align 8
  %1071 = add i64 %1070, 3
  store i64 %1071, i64* %PC, align 8
  %1072 = inttoptr i64 %1069 to i32*
  %1073 = load i32, i32* %1072, align 4
  %1074 = zext i32 %1073 to i64
  store i64 %1074, i64* %RAX, align 8, !tbaa !2428
  %1075 = add i64 %1068, -32
  %1076 = add i64 %1070, 6
  store i64 %1076, i64* %PC, align 8
  %1077 = inttoptr i64 %1075 to i32*
  %1078 = load i32, i32* %1077, align 4
  %1079 = add i32 %1078, %1073
  %1080 = zext i32 %1079 to i64
  store i64 %1080, i64* %RAX, align 8, !tbaa !2428
  %1081 = icmp ult i32 %1079, %1073
  %1082 = icmp ult i32 %1079, %1078
  %1083 = or i1 %1081, %1082
  %1084 = zext i1 %1083 to i8
  store i8 %1084, i8* %50, align 1, !tbaa !2433
  %1085 = and i32 %1079, 255
  %1086 = tail call i32 @llvm.ctpop.i32(i32 %1085) #10
  %1087 = trunc i32 %1086 to i8
  %1088 = and i8 %1087, 1
  %1089 = xor i8 %1088, 1
  store i8 %1089, i8* %51, align 1, !tbaa !2447
  %1090 = xor i32 %1078, %1073
  %1091 = xor i32 %1090, %1079
  %1092 = lshr i32 %1091, 4
  %1093 = trunc i32 %1092 to i8
  %1094 = and i8 %1093, 1
  store i8 %1094, i8* %52, align 1, !tbaa !2451
  %1095 = icmp eq i32 %1079, 0
  %1096 = zext i1 %1095 to i8
  store i8 %1096, i8* %53, align 1, !tbaa !2448
  %1097 = lshr i32 %1079, 31
  %1098 = trunc i32 %1097 to i8
  store i8 %1098, i8* %54, align 1, !tbaa !2449
  %1099 = lshr i32 %1073, 31
  %1100 = lshr i32 %1078, 31
  %1101 = xor i32 %1097, %1099
  %1102 = xor i32 %1097, %1100
  %1103 = add nuw nsw i32 %1101, %1102
  %1104 = icmp eq i32 %1103, 2
  %1105 = zext i1 %1104 to i8
  store i8 %1105, i8* %55, align 1, !tbaa !2450
  %1106 = add i64 %1070, 9
  store i64 %1106, i64* %PC, align 8
  store i32 %1079, i32* %1077, align 4
  %1107 = load i64, i64* %RBP, align 8
  %1108 = add i64 %1107, -52
  %1109 = load i64, i64* %PC, align 8
  %1110 = add i64 %1109, 3
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1108 to i32*
  %1112 = load i32, i32* %1111, align 4
  %1113 = shl i32 %1112, 1
  %1114 = icmp slt i32 %1112, 0
  %1115 = icmp slt i32 %1113, 0
  %1116 = xor i1 %1114, %1115
  %1117 = zext i32 %1113 to i64
  store i64 %1117, i64* %RAX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %1112, 31
  %1118 = trunc i32 %.lobit16 to i8
  store i8 %1118, i8* %50, align 1, !tbaa !2432
  %1119 = and i32 %1113, 254
  %1120 = tail call i32 @llvm.ctpop.i32(i32 %1119) #10
  %1121 = trunc i32 %1120 to i8
  %1122 = and i8 %1121, 1
  %1123 = xor i8 %1122, 1
  store i8 %1123, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %1124 = icmp eq i32 %1113, 0
  %1125 = zext i1 %1124 to i8
  store i8 %1125, i8* %53, align 1, !tbaa !2432
  %1126 = lshr i32 %1112, 30
  %1127 = trunc i32 %1126 to i8
  %1128 = and i8 %1127, 1
  store i8 %1128, i8* %54, align 1, !tbaa !2432
  %1129 = zext i1 %1116 to i8
  store i8 %1129, i8* %55, align 1, !tbaa !2432
  %1130 = add i64 %1107, -40
  %1131 = add i64 %1109, 9
  store i64 %1131, i64* %PC, align 8
  %1132 = inttoptr i64 %1130 to i32*
  %1133 = load i32, i32* %1132, align 4
  %1134 = add i32 %1133, %1113
  %1135 = zext i32 %1134 to i64
  store i64 %1135, i64* %RAX, align 8, !tbaa !2428
  %1136 = icmp ult i32 %1134, %1113
  %1137 = icmp ult i32 %1134, %1133
  %1138 = or i1 %1136, %1137
  %1139 = zext i1 %1138 to i8
  store i8 %1139, i8* %50, align 1, !tbaa !2433
  %1140 = and i32 %1134, 255
  %1141 = tail call i32 @llvm.ctpop.i32(i32 %1140) #10
  %1142 = trunc i32 %1141 to i8
  %1143 = and i8 %1142, 1
  %1144 = xor i8 %1143, 1
  store i8 %1144, i8* %51, align 1, !tbaa !2447
  %1145 = xor i32 %1133, %1113
  %1146 = xor i32 %1145, %1134
  %1147 = lshr i32 %1146, 4
  %1148 = trunc i32 %1147 to i8
  %1149 = and i8 %1148, 1
  store i8 %1149, i8* %52, align 1, !tbaa !2451
  %1150 = icmp eq i32 %1134, 0
  %1151 = zext i1 %1150 to i8
  store i8 %1151, i8* %53, align 1, !tbaa !2448
  %1152 = lshr i32 %1134, 31
  %1153 = trunc i32 %1152 to i8
  store i8 %1153, i8* %54, align 1, !tbaa !2449
  %1154 = lshr i32 %1112, 30
  %1155 = and i32 %1154, 1
  %1156 = lshr i32 %1133, 31
  %1157 = xor i32 %1152, %1155
  %1158 = xor i32 %1152, %1156
  %1159 = add nuw nsw i32 %1157, %1158
  %1160 = icmp eq i32 %1159, 2
  %1161 = zext i1 %1160 to i8
  store i8 %1161, i8* %55, align 1, !tbaa !2450
  %1162 = add i64 %1109, 12
  store i64 %1162, i64* %PC, align 8
  store i32 %1134, i32* %1132, align 4
  %1163 = load i64, i64* %RBP, align 8
  %1164 = add i64 %1163, -24
  %1165 = load i64, i64* %PC, align 8
  %1166 = add i64 %1165, 4
  store i64 %1166, i64* %PC, align 8
  %1167 = inttoptr i64 %1164 to i64*
  %1168 = load i64, i64* %1167, align 8
  store i64 %1168, i64* %RCX, align 8, !tbaa !2428
  %1169 = add i64 %1163, -32
  %1170 = add i64 %1165, 8
  store i64 %1170, i64* %PC, align 8
  %1171 = inttoptr i64 %1169 to i32*
  %1172 = load i32, i32* %1171, align 4
  %1173 = sext i32 %1172 to i64
  store i64 %1173, i64* %RDX, align 8, !tbaa !2428
  %1174 = shl nsw i64 %1173, 3
  %1175 = add i64 %1174, %1168
  %1176 = add i64 %1165, 13
  store i64 %1176, i64* %PC, align 8
  %1177 = inttoptr i64 %1175 to i64*
  %1178 = load i64, i64* %1177, align 8
  store i64 %1178, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1179 = add i64 %1163, -64
  %1180 = add i64 %1165, 18
  store i64 %1180, i64* %PC, align 8
  %1181 = inttoptr i64 %1179 to i64*
  store i64 %1178, i64* %1181, align 8
  %1182 = load i64, i64* %RBP, align 8
  %1183 = add i64 %1182, -24
  %1184 = load i64, i64* %PC, align 8
  %1185 = add i64 %1184, 4
  store i64 %1185, i64* %PC, align 8
  %1186 = inttoptr i64 %1183 to i64*
  %1187 = load i64, i64* %1186, align 8
  store i64 %1187, i64* %RCX, align 8, !tbaa !2428
  %1188 = add i64 %1182, -32
  %1189 = add i64 %1184, 7
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1188 to i32*
  %1191 = load i32, i32* %1190, align 4
  %1192 = add i32 %1191, 1
  %1193 = zext i32 %1192 to i64
  store i64 %1193, i64* %RAX, align 8, !tbaa !2428
  %1194 = icmp eq i32 %1191, -1
  %1195 = icmp eq i32 %1192, 0
  %1196 = or i1 %1194, %1195
  %1197 = zext i1 %1196 to i8
  store i8 %1197, i8* %50, align 1, !tbaa !2433
  %1198 = and i32 %1192, 255
  %1199 = tail call i32 @llvm.ctpop.i32(i32 %1198) #10
  %1200 = trunc i32 %1199 to i8
  %1201 = and i8 %1200, 1
  %1202 = xor i8 %1201, 1
  store i8 %1202, i8* %51, align 1, !tbaa !2447
  %1203 = xor i32 %1192, %1191
  %1204 = lshr i32 %1203, 4
  %1205 = trunc i32 %1204 to i8
  %1206 = and i8 %1205, 1
  store i8 %1206, i8* %52, align 1, !tbaa !2451
  %1207 = zext i1 %1195 to i8
  store i8 %1207, i8* %53, align 1, !tbaa !2448
  %1208 = lshr i32 %1192, 31
  %1209 = trunc i32 %1208 to i8
  store i8 %1209, i8* %54, align 1, !tbaa !2449
  %1210 = lshr i32 %1191, 31
  %1211 = xor i32 %1208, %1210
  %1212 = add nuw nsw i32 %1211, %1208
  %1213 = icmp eq i32 %1212, 2
  %1214 = zext i1 %1213 to i8
  store i8 %1214, i8* %55, align 1, !tbaa !2450
  %1215 = sext i32 %1192 to i64
  store i64 %1215, i64* %RDX, align 8, !tbaa !2428
  %1216 = shl nsw i64 %1215, 3
  %1217 = add i64 %1187, %1216
  %1218 = add i64 %1184, 18
  store i64 %1218, i64* %PC, align 8
  %1219 = inttoptr i64 %1217 to i64*
  %1220 = load i64, i64* %1219, align 8
  store i64 %1220, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1221 = add i64 %1182, -72
  %1222 = add i64 %1184, 23
  store i64 %1222, i64* %PC, align 8
  %1223 = inttoptr i64 %1221 to i64*
  store i64 %1220, i64* %1223, align 8
  %1224 = load i64, i64* %RBP, align 8
  %1225 = add i64 %1224, -24
  %1226 = load i64, i64* %PC, align 8
  %1227 = add i64 %1226, 4
  store i64 %1227, i64* %PC, align 8
  %1228 = inttoptr i64 %1225 to i64*
  %1229 = load i64, i64* %1228, align 8
  store i64 %1229, i64* %RCX, align 8, !tbaa !2428
  %1230 = add i64 %1224, -40
  %1231 = add i64 %1226, 8
  store i64 %1231, i64* %PC, align 8
  %1232 = inttoptr i64 %1230 to i32*
  %1233 = load i32, i32* %1232, align 4
  %1234 = sext i32 %1233 to i64
  store i64 %1234, i64* %RDX, align 8, !tbaa !2428
  %1235 = shl nsw i64 %1234, 3
  %1236 = add i64 %1235, %1229
  %1237 = add i64 %1226, 13
  store i64 %1237, i64* %PC, align 8
  %1238 = inttoptr i64 %1236 to i64*
  %1239 = load i64, i64* %1238, align 8
  store i64 %1239, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1240 = add i64 %1224, -80
  %1241 = add i64 %1226, 18
  store i64 %1241, i64* %PC, align 8
  %1242 = inttoptr i64 %1240 to i64*
  store i64 %1239, i64* %1242, align 8
  %1243 = load i64, i64* %RBP, align 8
  %1244 = add i64 %1243, -24
  %1245 = load i64, i64* %PC, align 8
  %1246 = add i64 %1245, 4
  store i64 %1246, i64* %PC, align 8
  %1247 = inttoptr i64 %1244 to i64*
  %1248 = load i64, i64* %1247, align 8
  store i64 %1248, i64* %RCX, align 8, !tbaa !2428
  %1249 = add i64 %1243, -40
  %1250 = add i64 %1245, 7
  store i64 %1250, i64* %PC, align 8
  %1251 = inttoptr i64 %1249 to i32*
  %1252 = load i32, i32* %1251, align 4
  %1253 = add i32 %1252, 1
  %1254 = zext i32 %1253 to i64
  store i64 %1254, i64* %RAX, align 8, !tbaa !2428
  %1255 = icmp eq i32 %1252, -1
  %1256 = icmp eq i32 %1253, 0
  %1257 = or i1 %1255, %1256
  %1258 = zext i1 %1257 to i8
  store i8 %1258, i8* %50, align 1, !tbaa !2433
  %1259 = and i32 %1253, 255
  %1260 = tail call i32 @llvm.ctpop.i32(i32 %1259) #10
  %1261 = trunc i32 %1260 to i8
  %1262 = and i8 %1261, 1
  %1263 = xor i8 %1262, 1
  store i8 %1263, i8* %51, align 1, !tbaa !2447
  %1264 = xor i32 %1253, %1252
  %1265 = lshr i32 %1264, 4
  %1266 = trunc i32 %1265 to i8
  %1267 = and i8 %1266, 1
  store i8 %1267, i8* %52, align 1, !tbaa !2451
  %1268 = zext i1 %1256 to i8
  store i8 %1268, i8* %53, align 1, !tbaa !2448
  %1269 = lshr i32 %1253, 31
  %1270 = trunc i32 %1269 to i8
  store i8 %1270, i8* %54, align 1, !tbaa !2449
  %1271 = lshr i32 %1252, 31
  %1272 = xor i32 %1269, %1271
  %1273 = add nuw nsw i32 %1272, %1269
  %1274 = icmp eq i32 %1273, 2
  %1275 = zext i1 %1274 to i8
  store i8 %1275, i8* %55, align 1, !tbaa !2450
  %1276 = sext i32 %1253 to i64
  store i64 %1276, i64* %RDX, align 8, !tbaa !2428
  %1277 = shl nsw i64 %1276, 3
  %1278 = add i64 %1248, %1277
  %1279 = add i64 %1245, 18
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1278 to i64*
  %1281 = load i64, i64* %1280, align 8
  store i64 %1281, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1282 = add i64 %1243, -88
  %1283 = add i64 %1245, 23
  store i64 %1283, i64* %PC, align 8
  %1284 = inttoptr i64 %1282 to i64*
  store i64 %1281, i64* %1284, align 8
  %1285 = load i64, i64* %RBP, align 8
  %1286 = add i64 %1285, -80
  %1287 = load i64, i64* %PC, align 8
  %1288 = add i64 %1287, 5
  store i64 %1288, i64* %PC, align 8
  %1289 = inttoptr i64 %1286 to i64*
  %1290 = load i64, i64* %1289, align 8
  store i64 %1290, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1291 = add i64 %1285, -24
  %1292 = add i64 %1287, 9
  store i64 %1292, i64* %PC, align 8
  %1293 = inttoptr i64 %1291 to i64*
  %1294 = load i64, i64* %1293, align 8
  store i64 %1294, i64* %RCX, align 8, !tbaa !2428
  %1295 = add i64 %1285, -32
  %1296 = add i64 %1287, 13
  store i64 %1296, i64* %PC, align 8
  %1297 = inttoptr i64 %1295 to i32*
  %1298 = load i32, i32* %1297, align 4
  %1299 = sext i32 %1298 to i64
  store i64 %1299, i64* %RDX, align 8, !tbaa !2428
  %1300 = shl nsw i64 %1299, 3
  %1301 = add i64 %1300, %1294
  %1302 = add i64 %1287, 18
  store i64 %1302, i64* %PC, align 8
  %1303 = inttoptr i64 %1301 to i64*
  store i64 %1290, i64* %1303, align 8
  %1304 = load i64, i64* %RBP, align 8
  %1305 = add i64 %1304, -88
  %1306 = load i64, i64* %PC, align 8
  %1307 = add i64 %1306, 5
  store i64 %1307, i64* %PC, align 8
  %1308 = inttoptr i64 %1305 to i64*
  %1309 = load i64, i64* %1308, align 8
  store i64 %1309, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1310 = add i64 %1304, -24
  %1311 = add i64 %1306, 9
  store i64 %1311, i64* %PC, align 8
  %1312 = inttoptr i64 %1310 to i64*
  %1313 = load i64, i64* %1312, align 8
  store i64 %1313, i64* %RCX, align 8, !tbaa !2428
  %1314 = add i64 %1304, -32
  %1315 = add i64 %1306, 12
  store i64 %1315, i64* %PC, align 8
  %1316 = inttoptr i64 %1314 to i32*
  %1317 = load i32, i32* %1316, align 4
  %1318 = add i32 %1317, 1
  %1319 = zext i32 %1318 to i64
  store i64 %1319, i64* %RAX, align 8, !tbaa !2428
  %1320 = icmp eq i32 %1317, -1
  %1321 = icmp eq i32 %1318, 0
  %1322 = or i1 %1320, %1321
  %1323 = zext i1 %1322 to i8
  store i8 %1323, i8* %50, align 1, !tbaa !2433
  %1324 = and i32 %1318, 255
  %1325 = tail call i32 @llvm.ctpop.i32(i32 %1324) #10
  %1326 = trunc i32 %1325 to i8
  %1327 = and i8 %1326, 1
  %1328 = xor i8 %1327, 1
  store i8 %1328, i8* %51, align 1, !tbaa !2447
  %1329 = xor i32 %1318, %1317
  %1330 = lshr i32 %1329, 4
  %1331 = trunc i32 %1330 to i8
  %1332 = and i8 %1331, 1
  store i8 %1332, i8* %52, align 1, !tbaa !2451
  %1333 = zext i1 %1321 to i8
  store i8 %1333, i8* %53, align 1, !tbaa !2448
  %1334 = lshr i32 %1318, 31
  %1335 = trunc i32 %1334 to i8
  store i8 %1335, i8* %54, align 1, !tbaa !2449
  %1336 = lshr i32 %1317, 31
  %1337 = xor i32 %1334, %1336
  %1338 = add nuw nsw i32 %1337, %1334
  %1339 = icmp eq i32 %1338, 2
  %1340 = zext i1 %1339 to i8
  store i8 %1340, i8* %55, align 1, !tbaa !2450
  %1341 = sext i32 %1318 to i64
  store i64 %1341, i64* %RDX, align 8, !tbaa !2428
  %1342 = shl nsw i64 %1341, 3
  %1343 = add i64 %1313, %1342
  %1344 = add i64 %1306, 23
  store i64 %1344, i64* %PC, align 8
  %1345 = inttoptr i64 %1343 to i64*
  store i64 %1309, i64* %1345, align 8
  %1346 = load i64, i64* %RBP, align 8
  %1347 = add i64 %1346, -64
  %1348 = load i64, i64* %PC, align 8
  %1349 = add i64 %1348, 5
  store i64 %1349, i64* %PC, align 8
  %1350 = inttoptr i64 %1347 to i64*
  %1351 = load i64, i64* %1350, align 8
  store i64 %1351, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1352 = add i64 %1346, -24
  %1353 = add i64 %1348, 9
  store i64 %1353, i64* %PC, align 8
  %1354 = inttoptr i64 %1352 to i64*
  %1355 = load i64, i64* %1354, align 8
  store i64 %1355, i64* %RCX, align 8, !tbaa !2428
  %1356 = add i64 %1346, -40
  %1357 = add i64 %1348, 13
  store i64 %1357, i64* %PC, align 8
  %1358 = inttoptr i64 %1356 to i32*
  %1359 = load i32, i32* %1358, align 4
  %1360 = sext i32 %1359 to i64
  store i64 %1360, i64* %RDX, align 8, !tbaa !2428
  %1361 = shl nsw i64 %1360, 3
  %1362 = add i64 %1361, %1355
  %1363 = add i64 %1348, 18
  store i64 %1363, i64* %PC, align 8
  %1364 = inttoptr i64 %1362 to i64*
  store i64 %1351, i64* %1364, align 8
  %1365 = load i64, i64* %RBP, align 8
  %1366 = add i64 %1365, -72
  %1367 = load i64, i64* %PC, align 8
  %1368 = add i64 %1367, 5
  store i64 %1368, i64* %PC, align 8
  %1369 = inttoptr i64 %1366 to i64*
  %1370 = load i64, i64* %1369, align 8
  store i64 %1370, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1371 = add i64 %1365, -24
  %1372 = add i64 %1367, 9
  store i64 %1372, i64* %PC, align 8
  %1373 = inttoptr i64 %1371 to i64*
  %1374 = load i64, i64* %1373, align 8
  store i64 %1374, i64* %RCX, align 8, !tbaa !2428
  %1375 = add i64 %1365, -40
  %1376 = add i64 %1367, 12
  store i64 %1376, i64* %PC, align 8
  %1377 = inttoptr i64 %1375 to i32*
  %1378 = load i32, i32* %1377, align 4
  %1379 = add i32 %1378, 1
  %1380 = zext i32 %1379 to i64
  store i64 %1380, i64* %RAX, align 8, !tbaa !2428
  %1381 = icmp eq i32 %1378, -1
  %1382 = icmp eq i32 %1379, 0
  %1383 = or i1 %1381, %1382
  %1384 = zext i1 %1383 to i8
  store i8 %1384, i8* %50, align 1, !tbaa !2433
  %1385 = and i32 %1379, 255
  %1386 = tail call i32 @llvm.ctpop.i32(i32 %1385) #10
  %1387 = trunc i32 %1386 to i8
  %1388 = and i8 %1387, 1
  %1389 = xor i8 %1388, 1
  store i8 %1389, i8* %51, align 1, !tbaa !2447
  %1390 = xor i32 %1379, %1378
  %1391 = lshr i32 %1390, 4
  %1392 = trunc i32 %1391 to i8
  %1393 = and i8 %1392, 1
  store i8 %1393, i8* %52, align 1, !tbaa !2451
  %1394 = zext i1 %1382 to i8
  store i8 %1394, i8* %53, align 1, !tbaa !2448
  %1395 = lshr i32 %1379, 31
  %1396 = trunc i32 %1395 to i8
  store i8 %1396, i8* %54, align 1, !tbaa !2449
  %1397 = lshr i32 %1378, 31
  %1398 = xor i32 %1395, %1397
  %1399 = add nuw nsw i32 %1398, %1395
  %1400 = icmp eq i32 %1399, 2
  %1401 = zext i1 %1400 to i8
  store i8 %1401, i8* %55, align 1, !tbaa !2450
  %1402 = sext i32 %1379 to i64
  store i64 %1402, i64* %RDX, align 8, !tbaa !2428
  %1403 = shl nsw i64 %1402, 3
  %1404 = add i64 %1374, %1403
  %1405 = add i64 %1367, 23
  store i64 %1405, i64* %PC, align 8
  %1406 = inttoptr i64 %1404 to i64*
  store i64 %1370, i64* %1406, align 8
  %1407 = load i64, i64* %RBP, align 8
  %1408 = add i64 %1407, -52
  %1409 = load i64, i64* %PC, align 8
  %1410 = add i64 %1409, 3
  store i64 %1410, i64* %PC, align 8
  %1411 = inttoptr i64 %1408 to i32*
  %1412 = load i32, i32* %1411, align 4
  %1413 = zext i32 %1412 to i64
  store i64 %1413, i64* %RAX, align 8, !tbaa !2428
  %1414 = add i64 %1407, -32
  %1415 = add i64 %1409, 6
  store i64 %1415, i64* %PC, align 8
  %1416 = inttoptr i64 %1414 to i32*
  %1417 = load i32, i32* %1416, align 4
  %1418 = add i32 %1417, %1412
  %1419 = zext i32 %1418 to i64
  store i64 %1419, i64* %RAX, align 8, !tbaa !2428
  %1420 = icmp ult i32 %1418, %1412
  %1421 = icmp ult i32 %1418, %1417
  %1422 = or i1 %1420, %1421
  %1423 = zext i1 %1422 to i8
  store i8 %1423, i8* %50, align 1, !tbaa !2433
  %1424 = and i32 %1418, 255
  %1425 = tail call i32 @llvm.ctpop.i32(i32 %1424) #10
  %1426 = trunc i32 %1425 to i8
  %1427 = and i8 %1426, 1
  %1428 = xor i8 %1427, 1
  store i8 %1428, i8* %51, align 1, !tbaa !2447
  %1429 = xor i32 %1417, %1412
  %1430 = xor i32 %1429, %1418
  %1431 = lshr i32 %1430, 4
  %1432 = trunc i32 %1431 to i8
  %1433 = and i8 %1432, 1
  store i8 %1433, i8* %52, align 1, !tbaa !2451
  %1434 = icmp eq i32 %1418, 0
  %1435 = zext i1 %1434 to i8
  store i8 %1435, i8* %53, align 1, !tbaa !2448
  %1436 = lshr i32 %1418, 31
  %1437 = trunc i32 %1436 to i8
  store i8 %1437, i8* %54, align 1, !tbaa !2449
  %1438 = lshr i32 %1412, 31
  %1439 = lshr i32 %1417, 31
  %1440 = xor i32 %1436, %1438
  %1441 = xor i32 %1436, %1439
  %1442 = add nuw nsw i32 %1440, %1441
  %1443 = icmp eq i32 %1442, 2
  %1444 = zext i1 %1443 to i8
  store i8 %1444, i8* %55, align 1, !tbaa !2450
  %1445 = add i64 %1409, 9
  store i64 %1445, i64* %PC, align 8
  store i32 %1418, i32* %1416, align 4
  %1446 = load i64, i64* %RBP, align 8
  %1447 = add i64 %1446, -52
  %1448 = load i64, i64* %PC, align 8
  %1449 = add i64 %1448, 3
  store i64 %1449, i64* %PC, align 8
  %1450 = inttoptr i64 %1447 to i32*
  %1451 = load i32, i32* %1450, align 4
  %1452 = zext i32 %1451 to i64
  store i64 %1452, i64* %RAX, align 8, !tbaa !2428
  %1453 = add i64 %1446, -40
  %1454 = add i64 %1448, 6
  store i64 %1454, i64* %PC, align 8
  %1455 = inttoptr i64 %1453 to i32*
  %1456 = load i32, i32* %1455, align 4
  %1457 = sub i32 %1456, %1451
  %1458 = zext i32 %1457 to i64
  store i64 %1458, i64* %RSI, align 8, !tbaa !2428
  %1459 = icmp ult i32 %1456, %1451
  %1460 = zext i1 %1459 to i8
  store i8 %1460, i8* %50, align 1, !tbaa !2433
  %1461 = and i32 %1457, 255
  %1462 = tail call i32 @llvm.ctpop.i32(i32 %1461) #10
  %1463 = trunc i32 %1462 to i8
  %1464 = and i8 %1463, 1
  %1465 = xor i8 %1464, 1
  store i8 %1465, i8* %51, align 1, !tbaa !2447
  %1466 = xor i32 %1451, %1456
  %1467 = xor i32 %1466, %1457
  %1468 = lshr i32 %1467, 4
  %1469 = trunc i32 %1468 to i8
  %1470 = and i8 %1469, 1
  store i8 %1470, i8* %52, align 1, !tbaa !2451
  %1471 = icmp eq i32 %1457, 0
  %1472 = zext i1 %1471 to i8
  store i8 %1472, i8* %53, align 1, !tbaa !2448
  %1473 = lshr i32 %1457, 31
  %1474 = trunc i32 %1473 to i8
  store i8 %1474, i8* %54, align 1, !tbaa !2449
  %1475 = lshr i32 %1456, 31
  %1476 = lshr i32 %1451, 31
  %1477 = xor i32 %1476, %1475
  %1478 = xor i32 %1473, %1475
  %1479 = add nuw nsw i32 %1478, %1477
  %1480 = icmp eq i32 %1479, 2
  %1481 = zext i1 %1480 to i8
  store i8 %1481, i8* %55, align 1, !tbaa !2450
  %1482 = add i64 %1448, 11
  store i64 %1482, i64* %PC, align 8
  store i32 %1457, i32* %1455, align 4
  %1483 = load i64, i64* %RBP, align 8
  %1484 = add i64 %1483, -24
  %1485 = load i64, i64* %PC, align 8
  %1486 = add i64 %1485, 4
  store i64 %1486, i64* %PC, align 8
  %1487 = inttoptr i64 %1484 to i64*
  %1488 = load i64, i64* %1487, align 8
  store i64 %1488, i64* %RCX, align 8, !tbaa !2428
  %1489 = add i64 %1483, -32
  %1490 = add i64 %1485, 8
  store i64 %1490, i64* %PC, align 8
  %1491 = inttoptr i64 %1489 to i32*
  %1492 = load i32, i32* %1491, align 4
  %1493 = sext i32 %1492 to i64
  store i64 %1493, i64* %RDX, align 8, !tbaa !2428
  %1494 = shl nsw i64 %1493, 3
  %1495 = add i64 %1494, %1488
  %1496 = add i64 %1485, 13
  store i64 %1496, i64* %PC, align 8
  %1497 = inttoptr i64 %1495 to i64*
  %1498 = load i64, i64* %1497, align 8
  store i64 %1498, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1499 = add i64 %1483, -64
  %1500 = add i64 %1485, 18
  store i64 %1500, i64* %PC, align 8
  %1501 = inttoptr i64 %1499 to i64*
  store i64 %1498, i64* %1501, align 8
  %1502 = load i64, i64* %RBP, align 8
  %1503 = add i64 %1502, -24
  %1504 = load i64, i64* %PC, align 8
  %1505 = add i64 %1504, 4
  store i64 %1505, i64* %PC, align 8
  %1506 = inttoptr i64 %1503 to i64*
  %1507 = load i64, i64* %1506, align 8
  store i64 %1507, i64* %RCX, align 8, !tbaa !2428
  %1508 = add i64 %1502, -32
  %1509 = add i64 %1504, 7
  store i64 %1509, i64* %PC, align 8
  %1510 = inttoptr i64 %1508 to i32*
  %1511 = load i32, i32* %1510, align 4
  %1512 = add i32 %1511, 1
  %1513 = zext i32 %1512 to i64
  store i64 %1513, i64* %RAX, align 8, !tbaa !2428
  %1514 = icmp eq i32 %1511, -1
  %1515 = icmp eq i32 %1512, 0
  %1516 = or i1 %1514, %1515
  %1517 = zext i1 %1516 to i8
  store i8 %1517, i8* %50, align 1, !tbaa !2433
  %1518 = and i32 %1512, 255
  %1519 = tail call i32 @llvm.ctpop.i32(i32 %1518) #10
  %1520 = trunc i32 %1519 to i8
  %1521 = and i8 %1520, 1
  %1522 = xor i8 %1521, 1
  store i8 %1522, i8* %51, align 1, !tbaa !2447
  %1523 = xor i32 %1512, %1511
  %1524 = lshr i32 %1523, 4
  %1525 = trunc i32 %1524 to i8
  %1526 = and i8 %1525, 1
  store i8 %1526, i8* %52, align 1, !tbaa !2451
  %1527 = zext i1 %1515 to i8
  store i8 %1527, i8* %53, align 1, !tbaa !2448
  %1528 = lshr i32 %1512, 31
  %1529 = trunc i32 %1528 to i8
  store i8 %1529, i8* %54, align 1, !tbaa !2449
  %1530 = lshr i32 %1511, 31
  %1531 = xor i32 %1528, %1530
  %1532 = add nuw nsw i32 %1531, %1528
  %1533 = icmp eq i32 %1532, 2
  %1534 = zext i1 %1533 to i8
  store i8 %1534, i8* %55, align 1, !tbaa !2450
  %1535 = sext i32 %1512 to i64
  store i64 %1535, i64* %RDX, align 8, !tbaa !2428
  %1536 = shl nsw i64 %1535, 3
  %1537 = add i64 %1507, %1536
  %1538 = add i64 %1504, 18
  store i64 %1538, i64* %PC, align 8
  %1539 = inttoptr i64 %1537 to i64*
  %1540 = load i64, i64* %1539, align 8
  store i64 %1540, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1541 = add i64 %1502, -72
  %1542 = add i64 %1504, 23
  store i64 %1542, i64* %PC, align 8
  %1543 = inttoptr i64 %1541 to i64*
  store i64 %1540, i64* %1543, align 8
  %1544 = load i64, i64* %RBP, align 8
  %1545 = add i64 %1544, -24
  %1546 = load i64, i64* %PC, align 8
  %1547 = add i64 %1546, 4
  store i64 %1547, i64* %PC, align 8
  %1548 = inttoptr i64 %1545 to i64*
  %1549 = load i64, i64* %1548, align 8
  store i64 %1549, i64* %RCX, align 8, !tbaa !2428
  %1550 = add i64 %1544, -40
  %1551 = add i64 %1546, 8
  store i64 %1551, i64* %PC, align 8
  %1552 = inttoptr i64 %1550 to i32*
  %1553 = load i32, i32* %1552, align 4
  %1554 = sext i32 %1553 to i64
  store i64 %1554, i64* %RDX, align 8, !tbaa !2428
  %1555 = shl nsw i64 %1554, 3
  %1556 = add i64 %1555, %1549
  %1557 = add i64 %1546, 13
  store i64 %1557, i64* %PC, align 8
  %1558 = inttoptr i64 %1556 to i64*
  %1559 = load i64, i64* %1558, align 8
  store i64 %1559, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1560 = add i64 %1544, -80
  %1561 = add i64 %1546, 18
  store i64 %1561, i64* %PC, align 8
  %1562 = inttoptr i64 %1560 to i64*
  store i64 %1559, i64* %1562, align 8
  %1563 = load i64, i64* %RBP, align 8
  %1564 = add i64 %1563, -24
  %1565 = load i64, i64* %PC, align 8
  %1566 = add i64 %1565, 4
  store i64 %1566, i64* %PC, align 8
  %1567 = inttoptr i64 %1564 to i64*
  %1568 = load i64, i64* %1567, align 8
  store i64 %1568, i64* %RCX, align 8, !tbaa !2428
  %1569 = add i64 %1563, -40
  %1570 = add i64 %1565, 7
  store i64 %1570, i64* %PC, align 8
  %1571 = inttoptr i64 %1569 to i32*
  %1572 = load i32, i32* %1571, align 4
  %1573 = add i32 %1572, 1
  %1574 = zext i32 %1573 to i64
  store i64 %1574, i64* %RAX, align 8, !tbaa !2428
  %1575 = icmp eq i32 %1572, -1
  %1576 = icmp eq i32 %1573, 0
  %1577 = or i1 %1575, %1576
  %1578 = zext i1 %1577 to i8
  store i8 %1578, i8* %50, align 1, !tbaa !2433
  %1579 = and i32 %1573, 255
  %1580 = tail call i32 @llvm.ctpop.i32(i32 %1579) #10
  %1581 = trunc i32 %1580 to i8
  %1582 = and i8 %1581, 1
  %1583 = xor i8 %1582, 1
  store i8 %1583, i8* %51, align 1, !tbaa !2447
  %1584 = xor i32 %1573, %1572
  %1585 = lshr i32 %1584, 4
  %1586 = trunc i32 %1585 to i8
  %1587 = and i8 %1586, 1
  store i8 %1587, i8* %52, align 1, !tbaa !2451
  %1588 = zext i1 %1576 to i8
  store i8 %1588, i8* %53, align 1, !tbaa !2448
  %1589 = lshr i32 %1573, 31
  %1590 = trunc i32 %1589 to i8
  store i8 %1590, i8* %54, align 1, !tbaa !2449
  %1591 = lshr i32 %1572, 31
  %1592 = xor i32 %1589, %1591
  %1593 = add nuw nsw i32 %1592, %1589
  %1594 = icmp eq i32 %1593, 2
  %1595 = zext i1 %1594 to i8
  store i8 %1595, i8* %55, align 1, !tbaa !2450
  %1596 = sext i32 %1573 to i64
  store i64 %1596, i64* %RDX, align 8, !tbaa !2428
  %1597 = shl nsw i64 %1596, 3
  %1598 = add i64 %1568, %1597
  %1599 = add i64 %1565, 18
  store i64 %1599, i64* %PC, align 8
  %1600 = inttoptr i64 %1598 to i64*
  %1601 = load i64, i64* %1600, align 8
  store i64 %1601, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1602 = add i64 %1563, -88
  %1603 = add i64 %1565, 23
  store i64 %1603, i64* %PC, align 8
  %1604 = inttoptr i64 %1602 to i64*
  store i64 %1601, i64* %1604, align 8
  %1605 = load i64, i64* %RBP, align 8
  %1606 = add i64 %1605, -80
  %1607 = load i64, i64* %PC, align 8
  %1608 = add i64 %1607, 5
  store i64 %1608, i64* %PC, align 8
  %1609 = inttoptr i64 %1606 to i64*
  %1610 = load i64, i64* %1609, align 8
  store i64 %1610, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1611 = add i64 %1605, -24
  %1612 = add i64 %1607, 9
  store i64 %1612, i64* %PC, align 8
  %1613 = inttoptr i64 %1611 to i64*
  %1614 = load i64, i64* %1613, align 8
  store i64 %1614, i64* %RCX, align 8, !tbaa !2428
  %1615 = add i64 %1605, -32
  %1616 = add i64 %1607, 13
  store i64 %1616, i64* %PC, align 8
  %1617 = inttoptr i64 %1615 to i32*
  %1618 = load i32, i32* %1617, align 4
  %1619 = sext i32 %1618 to i64
  store i64 %1619, i64* %RDX, align 8, !tbaa !2428
  %1620 = shl nsw i64 %1619, 3
  %1621 = add i64 %1620, %1614
  %1622 = add i64 %1607, 18
  store i64 %1622, i64* %PC, align 8
  %1623 = inttoptr i64 %1621 to i64*
  store i64 %1610, i64* %1623, align 8
  %1624 = load i64, i64* %RBP, align 8
  %1625 = add i64 %1624, -88
  %1626 = load i64, i64* %PC, align 8
  %1627 = add i64 %1626, 5
  store i64 %1627, i64* %PC, align 8
  %1628 = inttoptr i64 %1625 to i64*
  %1629 = load i64, i64* %1628, align 8
  store i64 %1629, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1630 = add i64 %1624, -24
  %1631 = add i64 %1626, 9
  store i64 %1631, i64* %PC, align 8
  %1632 = inttoptr i64 %1630 to i64*
  %1633 = load i64, i64* %1632, align 8
  store i64 %1633, i64* %RCX, align 8, !tbaa !2428
  %1634 = add i64 %1624, -32
  %1635 = add i64 %1626, 12
  store i64 %1635, i64* %PC, align 8
  %1636 = inttoptr i64 %1634 to i32*
  %1637 = load i32, i32* %1636, align 4
  %1638 = add i32 %1637, 1
  %1639 = zext i32 %1638 to i64
  store i64 %1639, i64* %RAX, align 8, !tbaa !2428
  %1640 = icmp eq i32 %1637, -1
  %1641 = icmp eq i32 %1638, 0
  %1642 = or i1 %1640, %1641
  %1643 = zext i1 %1642 to i8
  store i8 %1643, i8* %50, align 1, !tbaa !2433
  %1644 = and i32 %1638, 255
  %1645 = tail call i32 @llvm.ctpop.i32(i32 %1644) #10
  %1646 = trunc i32 %1645 to i8
  %1647 = and i8 %1646, 1
  %1648 = xor i8 %1647, 1
  store i8 %1648, i8* %51, align 1, !tbaa !2447
  %1649 = xor i32 %1638, %1637
  %1650 = lshr i32 %1649, 4
  %1651 = trunc i32 %1650 to i8
  %1652 = and i8 %1651, 1
  store i8 %1652, i8* %52, align 1, !tbaa !2451
  %1653 = zext i1 %1641 to i8
  store i8 %1653, i8* %53, align 1, !tbaa !2448
  %1654 = lshr i32 %1638, 31
  %1655 = trunc i32 %1654 to i8
  store i8 %1655, i8* %54, align 1, !tbaa !2449
  %1656 = lshr i32 %1637, 31
  %1657 = xor i32 %1654, %1656
  %1658 = add nuw nsw i32 %1657, %1654
  %1659 = icmp eq i32 %1658, 2
  %1660 = zext i1 %1659 to i8
  store i8 %1660, i8* %55, align 1, !tbaa !2450
  %1661 = sext i32 %1638 to i64
  store i64 %1661, i64* %RDX, align 8, !tbaa !2428
  %1662 = shl nsw i64 %1661, 3
  %1663 = add i64 %1633, %1662
  %1664 = add i64 %1626, 23
  store i64 %1664, i64* %PC, align 8
  %1665 = inttoptr i64 %1663 to i64*
  store i64 %1629, i64* %1665, align 8
  %1666 = load i64, i64* %RBP, align 8
  %1667 = add i64 %1666, -64
  %1668 = load i64, i64* %PC, align 8
  %1669 = add i64 %1668, 5
  store i64 %1669, i64* %PC, align 8
  %1670 = inttoptr i64 %1667 to i64*
  %1671 = load i64, i64* %1670, align 8
  store i64 %1671, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1672 = add i64 %1666, -24
  %1673 = add i64 %1668, 9
  store i64 %1673, i64* %PC, align 8
  %1674 = inttoptr i64 %1672 to i64*
  %1675 = load i64, i64* %1674, align 8
  store i64 %1675, i64* %RCX, align 8, !tbaa !2428
  %1676 = add i64 %1666, -40
  %1677 = add i64 %1668, 13
  store i64 %1677, i64* %PC, align 8
  %1678 = inttoptr i64 %1676 to i32*
  %1679 = load i32, i32* %1678, align 4
  %1680 = sext i32 %1679 to i64
  store i64 %1680, i64* %RDX, align 8, !tbaa !2428
  %1681 = shl nsw i64 %1680, 3
  %1682 = add i64 %1681, %1675
  %1683 = add i64 %1668, 18
  store i64 %1683, i64* %PC, align 8
  %1684 = inttoptr i64 %1682 to i64*
  store i64 %1671, i64* %1684, align 8
  %1685 = load i64, i64* %RBP, align 8
  %1686 = add i64 %1685, -72
  %1687 = load i64, i64* %PC, align 8
  %1688 = add i64 %1687, 5
  store i64 %1688, i64* %PC, align 8
  %1689 = inttoptr i64 %1686 to i64*
  %1690 = load i64, i64* %1689, align 8
  store i64 %1690, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1691 = add i64 %1685, -24
  %1692 = add i64 %1687, 9
  store i64 %1692, i64* %PC, align 8
  %1693 = inttoptr i64 %1691 to i64*
  %1694 = load i64, i64* %1693, align 8
  store i64 %1694, i64* %RCX, align 8, !tbaa !2428
  %1695 = add i64 %1685, -40
  %1696 = add i64 %1687, 12
  store i64 %1696, i64* %PC, align 8
  %1697 = inttoptr i64 %1695 to i32*
  %1698 = load i32, i32* %1697, align 4
  %1699 = add i32 %1698, 1
  %1700 = zext i32 %1699 to i64
  store i64 %1700, i64* %RAX, align 8, !tbaa !2428
  %1701 = icmp eq i32 %1698, -1
  %1702 = icmp eq i32 %1699, 0
  %1703 = or i1 %1701, %1702
  %1704 = zext i1 %1703 to i8
  store i8 %1704, i8* %50, align 1, !tbaa !2433
  %1705 = and i32 %1699, 255
  %1706 = tail call i32 @llvm.ctpop.i32(i32 %1705) #10
  %1707 = trunc i32 %1706 to i8
  %1708 = and i8 %1707, 1
  %1709 = xor i8 %1708, 1
  store i8 %1709, i8* %51, align 1, !tbaa !2447
  %1710 = xor i32 %1699, %1698
  %1711 = lshr i32 %1710, 4
  %1712 = trunc i32 %1711 to i8
  %1713 = and i8 %1712, 1
  store i8 %1713, i8* %52, align 1, !tbaa !2451
  %1714 = zext i1 %1702 to i8
  store i8 %1714, i8* %53, align 1, !tbaa !2448
  %1715 = lshr i32 %1699, 31
  %1716 = trunc i32 %1715 to i8
  store i8 %1716, i8* %54, align 1, !tbaa !2449
  %1717 = lshr i32 %1698, 31
  %1718 = xor i32 %1715, %1717
  %1719 = add nuw nsw i32 %1718, %1715
  %1720 = icmp eq i32 %1719, 2
  %1721 = zext i1 %1720 to i8
  store i8 %1721, i8* %55, align 1, !tbaa !2450
  %1722 = sext i32 %1699 to i64
  store i64 %1722, i64* %RDX, align 8, !tbaa !2428
  %1723 = shl nsw i64 %1722, 3
  %1724 = add i64 %1694, %1723
  %1725 = add i64 %1687, 23
  store i64 %1725, i64* %PC, align 8
  %1726 = inttoptr i64 %1724 to i64*
  store i64 %1690, i64* %1726, align 8
  %1727 = load i64, i64* %RBP, align 8
  %1728 = add i64 %1727, -52
  %1729 = load i64, i64* %PC, align 8
  %1730 = add i64 %1729, 3
  store i64 %1730, i64* %PC, align 8
  %1731 = inttoptr i64 %1728 to i32*
  %1732 = load i32, i32* %1731, align 4
  %1733 = zext i32 %1732 to i64
  store i64 %1733, i64* %RAX, align 8, !tbaa !2428
  %1734 = add i64 %1727, -32
  %1735 = add i64 %1729, 6
  store i64 %1735, i64* %PC, align 8
  %1736 = inttoptr i64 %1734 to i32*
  %1737 = load i32, i32* %1736, align 4
  %1738 = add i32 %1737, %1732
  %1739 = zext i32 %1738 to i64
  store i64 %1739, i64* %RAX, align 8, !tbaa !2428
  %1740 = icmp ult i32 %1738, %1732
  %1741 = icmp ult i32 %1738, %1737
  %1742 = or i1 %1740, %1741
  %1743 = zext i1 %1742 to i8
  store i8 %1743, i8* %50, align 1, !tbaa !2433
  %1744 = and i32 %1738, 255
  %1745 = tail call i32 @llvm.ctpop.i32(i32 %1744) #10
  %1746 = trunc i32 %1745 to i8
  %1747 = and i8 %1746, 1
  %1748 = xor i8 %1747, 1
  store i8 %1748, i8* %51, align 1, !tbaa !2447
  %1749 = xor i32 %1737, %1732
  %1750 = xor i32 %1749, %1738
  %1751 = lshr i32 %1750, 4
  %1752 = trunc i32 %1751 to i8
  %1753 = and i8 %1752, 1
  store i8 %1753, i8* %52, align 1, !tbaa !2451
  %1754 = icmp eq i32 %1738, 0
  %1755 = zext i1 %1754 to i8
  store i8 %1755, i8* %53, align 1, !tbaa !2448
  %1756 = lshr i32 %1738, 31
  %1757 = trunc i32 %1756 to i8
  store i8 %1757, i8* %54, align 1, !tbaa !2449
  %1758 = lshr i32 %1732, 31
  %1759 = lshr i32 %1737, 31
  %1760 = xor i32 %1756, %1758
  %1761 = xor i32 %1756, %1759
  %1762 = add nuw nsw i32 %1760, %1761
  %1763 = icmp eq i32 %1762, 2
  %1764 = zext i1 %1763 to i8
  store i8 %1764, i8* %55, align 1, !tbaa !2450
  %1765 = add i64 %1729, 9
  store i64 %1765, i64* %PC, align 8
  store i32 %1738, i32* %1736, align 4
  %1766 = load i64, i64* %RBP, align 8
  %1767 = add i64 %1766, -52
  %1768 = load i64, i64* %PC, align 8
  %1769 = add i64 %1768, 3
  store i64 %1769, i64* %PC, align 8
  %1770 = inttoptr i64 %1767 to i32*
  %1771 = load i32, i32* %1770, align 4
  %1772 = shl i32 %1771, 1
  %1773 = icmp slt i32 %1771, 0
  %1774 = icmp slt i32 %1772, 0
  %1775 = xor i1 %1773, %1774
  %1776 = zext i32 %1772 to i64
  store i64 %1776, i64* %RAX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %1771, 31
  %1777 = trunc i32 %.lobit17 to i8
  store i8 %1777, i8* %50, align 1, !tbaa !2432
  %1778 = and i32 %1772, 254
  %1779 = tail call i32 @llvm.ctpop.i32(i32 %1778) #10
  %1780 = trunc i32 %1779 to i8
  %1781 = and i8 %1780, 1
  %1782 = xor i8 %1781, 1
  store i8 %1782, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %1783 = icmp eq i32 %1772, 0
  %1784 = zext i1 %1783 to i8
  store i8 %1784, i8* %53, align 1, !tbaa !2432
  %1785 = lshr i32 %1771, 30
  %1786 = trunc i32 %1785 to i8
  %1787 = and i8 %1786, 1
  store i8 %1787, i8* %54, align 1, !tbaa !2432
  %1788 = zext i1 %1775 to i8
  store i8 %1788, i8* %55, align 1, !tbaa !2432
  %1789 = add i64 %1766, -40
  %1790 = add i64 %1768, 9
  store i64 %1790, i64* %PC, align 8
  %1791 = inttoptr i64 %1789 to i32*
  %1792 = load i32, i32* %1791, align 4
  %1793 = add i32 %1792, %1772
  %1794 = zext i32 %1793 to i64
  store i64 %1794, i64* %RAX, align 8, !tbaa !2428
  %1795 = icmp ult i32 %1793, %1772
  %1796 = icmp ult i32 %1793, %1792
  %1797 = or i1 %1795, %1796
  %1798 = zext i1 %1797 to i8
  store i8 %1798, i8* %50, align 1, !tbaa !2433
  %1799 = and i32 %1793, 255
  %1800 = tail call i32 @llvm.ctpop.i32(i32 %1799) #10
  %1801 = trunc i32 %1800 to i8
  %1802 = and i8 %1801, 1
  %1803 = xor i8 %1802, 1
  store i8 %1803, i8* %51, align 1, !tbaa !2447
  %1804 = xor i32 %1792, %1772
  %1805 = xor i32 %1804, %1793
  %1806 = lshr i32 %1805, 4
  %1807 = trunc i32 %1806 to i8
  %1808 = and i8 %1807, 1
  store i8 %1808, i8* %52, align 1, !tbaa !2451
  %1809 = icmp eq i32 %1793, 0
  %1810 = zext i1 %1809 to i8
  store i8 %1810, i8* %53, align 1, !tbaa !2448
  %1811 = lshr i32 %1793, 31
  %1812 = trunc i32 %1811 to i8
  store i8 %1812, i8* %54, align 1, !tbaa !2449
  %1813 = lshr i32 %1771, 30
  %1814 = and i32 %1813, 1
  %1815 = lshr i32 %1792, 31
  %1816 = xor i32 %1811, %1814
  %1817 = xor i32 %1811, %1815
  %1818 = add nuw nsw i32 %1816, %1817
  %1819 = icmp eq i32 %1818, 2
  %1820 = zext i1 %1819 to i8
  store i8 %1820, i8* %55, align 1, !tbaa !2450
  %1821 = add i64 %1768, 12
  store i64 %1821, i64* %PC, align 8
  store i32 %1793, i32* %1791, align 4
  %1822 = load i64, i64* %RBP, align 8
  %1823 = add i64 %1822, -24
  %1824 = load i64, i64* %PC, align 8
  %1825 = add i64 %1824, 4
  store i64 %1825, i64* %PC, align 8
  %1826 = inttoptr i64 %1823 to i64*
  %1827 = load i64, i64* %1826, align 8
  store i64 %1827, i64* %RCX, align 8, !tbaa !2428
  %1828 = add i64 %1822, -32
  %1829 = add i64 %1824, 8
  store i64 %1829, i64* %PC, align 8
  %1830 = inttoptr i64 %1828 to i32*
  %1831 = load i32, i32* %1830, align 4
  %1832 = sext i32 %1831 to i64
  store i64 %1832, i64* %RDX, align 8, !tbaa !2428
  %1833 = shl nsw i64 %1832, 3
  %1834 = add i64 %1833, %1827
  %1835 = add i64 %1824, 13
  store i64 %1835, i64* %PC, align 8
  %1836 = inttoptr i64 %1834 to i64*
  %1837 = load i64, i64* %1836, align 8
  store i64 %1837, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1838 = add i64 %1822, -64
  %1839 = add i64 %1824, 18
  store i64 %1839, i64* %PC, align 8
  %1840 = inttoptr i64 %1838 to i64*
  store i64 %1837, i64* %1840, align 8
  %1841 = load i64, i64* %RBP, align 8
  %1842 = add i64 %1841, -24
  %1843 = load i64, i64* %PC, align 8
  %1844 = add i64 %1843, 4
  store i64 %1844, i64* %PC, align 8
  %1845 = inttoptr i64 %1842 to i64*
  %1846 = load i64, i64* %1845, align 8
  store i64 %1846, i64* %RCX, align 8, !tbaa !2428
  %1847 = add i64 %1841, -32
  %1848 = add i64 %1843, 7
  store i64 %1848, i64* %PC, align 8
  %1849 = inttoptr i64 %1847 to i32*
  %1850 = load i32, i32* %1849, align 4
  %1851 = add i32 %1850, 1
  %1852 = zext i32 %1851 to i64
  store i64 %1852, i64* %RAX, align 8, !tbaa !2428
  %1853 = icmp eq i32 %1850, -1
  %1854 = icmp eq i32 %1851, 0
  %1855 = or i1 %1853, %1854
  %1856 = zext i1 %1855 to i8
  store i8 %1856, i8* %50, align 1, !tbaa !2433
  %1857 = and i32 %1851, 255
  %1858 = tail call i32 @llvm.ctpop.i32(i32 %1857) #10
  %1859 = trunc i32 %1858 to i8
  %1860 = and i8 %1859, 1
  %1861 = xor i8 %1860, 1
  store i8 %1861, i8* %51, align 1, !tbaa !2447
  %1862 = xor i32 %1851, %1850
  %1863 = lshr i32 %1862, 4
  %1864 = trunc i32 %1863 to i8
  %1865 = and i8 %1864, 1
  store i8 %1865, i8* %52, align 1, !tbaa !2451
  %1866 = zext i1 %1854 to i8
  store i8 %1866, i8* %53, align 1, !tbaa !2448
  %1867 = lshr i32 %1851, 31
  %1868 = trunc i32 %1867 to i8
  store i8 %1868, i8* %54, align 1, !tbaa !2449
  %1869 = lshr i32 %1850, 31
  %1870 = xor i32 %1867, %1869
  %1871 = add nuw nsw i32 %1870, %1867
  %1872 = icmp eq i32 %1871, 2
  %1873 = zext i1 %1872 to i8
  store i8 %1873, i8* %55, align 1, !tbaa !2450
  %1874 = sext i32 %1851 to i64
  store i64 %1874, i64* %RDX, align 8, !tbaa !2428
  %1875 = shl nsw i64 %1874, 3
  %1876 = add i64 %1846, %1875
  %1877 = add i64 %1843, 18
  store i64 %1877, i64* %PC, align 8
  %1878 = inttoptr i64 %1876 to i64*
  %1879 = load i64, i64* %1878, align 8
  store i64 %1879, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1880 = add i64 %1841, -72
  %1881 = add i64 %1843, 23
  store i64 %1881, i64* %PC, align 8
  %1882 = inttoptr i64 %1880 to i64*
  store i64 %1879, i64* %1882, align 8
  %1883 = load i64, i64* %RBP, align 8
  %1884 = add i64 %1883, -24
  %1885 = load i64, i64* %PC, align 8
  %1886 = add i64 %1885, 4
  store i64 %1886, i64* %PC, align 8
  %1887 = inttoptr i64 %1884 to i64*
  %1888 = load i64, i64* %1887, align 8
  store i64 %1888, i64* %RCX, align 8, !tbaa !2428
  %1889 = add i64 %1883, -40
  %1890 = add i64 %1885, 8
  store i64 %1890, i64* %PC, align 8
  %1891 = inttoptr i64 %1889 to i32*
  %1892 = load i32, i32* %1891, align 4
  %1893 = sext i32 %1892 to i64
  store i64 %1893, i64* %RDX, align 8, !tbaa !2428
  %1894 = shl nsw i64 %1893, 3
  %1895 = add i64 %1894, %1888
  %1896 = add i64 %1885, 13
  store i64 %1896, i64* %PC, align 8
  %1897 = inttoptr i64 %1895 to i64*
  %1898 = load i64, i64* %1897, align 8
  store i64 %1898, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1899 = add i64 %1883, -80
  %1900 = add i64 %1885, 18
  store i64 %1900, i64* %PC, align 8
  %1901 = inttoptr i64 %1899 to i64*
  store i64 %1898, i64* %1901, align 8
  %1902 = load i64, i64* %RBP, align 8
  %1903 = add i64 %1902, -24
  %1904 = load i64, i64* %PC, align 8
  %1905 = add i64 %1904, 4
  store i64 %1905, i64* %PC, align 8
  %1906 = inttoptr i64 %1903 to i64*
  %1907 = load i64, i64* %1906, align 8
  store i64 %1907, i64* %RCX, align 8, !tbaa !2428
  %1908 = add i64 %1902, -40
  %1909 = add i64 %1904, 7
  store i64 %1909, i64* %PC, align 8
  %1910 = inttoptr i64 %1908 to i32*
  %1911 = load i32, i32* %1910, align 4
  %1912 = add i32 %1911, 1
  %1913 = zext i32 %1912 to i64
  store i64 %1913, i64* %RAX, align 8, !tbaa !2428
  %1914 = icmp eq i32 %1911, -1
  %1915 = icmp eq i32 %1912, 0
  %1916 = or i1 %1914, %1915
  %1917 = zext i1 %1916 to i8
  store i8 %1917, i8* %50, align 1, !tbaa !2433
  %1918 = and i32 %1912, 255
  %1919 = tail call i32 @llvm.ctpop.i32(i32 %1918) #10
  %1920 = trunc i32 %1919 to i8
  %1921 = and i8 %1920, 1
  %1922 = xor i8 %1921, 1
  store i8 %1922, i8* %51, align 1, !tbaa !2447
  %1923 = xor i32 %1912, %1911
  %1924 = lshr i32 %1923, 4
  %1925 = trunc i32 %1924 to i8
  %1926 = and i8 %1925, 1
  store i8 %1926, i8* %52, align 1, !tbaa !2451
  %1927 = zext i1 %1915 to i8
  store i8 %1927, i8* %53, align 1, !tbaa !2448
  %1928 = lshr i32 %1912, 31
  %1929 = trunc i32 %1928 to i8
  store i8 %1929, i8* %54, align 1, !tbaa !2449
  %1930 = lshr i32 %1911, 31
  %1931 = xor i32 %1928, %1930
  %1932 = add nuw nsw i32 %1931, %1928
  %1933 = icmp eq i32 %1932, 2
  %1934 = zext i1 %1933 to i8
  store i8 %1934, i8* %55, align 1, !tbaa !2450
  %1935 = sext i32 %1912 to i64
  store i64 %1935, i64* %RDX, align 8, !tbaa !2428
  %1936 = shl nsw i64 %1935, 3
  %1937 = add i64 %1907, %1936
  %1938 = add i64 %1904, 18
  store i64 %1938, i64* %PC, align 8
  %1939 = inttoptr i64 %1937 to i64*
  %1940 = load i64, i64* %1939, align 8
  store i64 %1940, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1941 = add i64 %1902, -88
  %1942 = add i64 %1904, 23
  store i64 %1942, i64* %PC, align 8
  %1943 = inttoptr i64 %1941 to i64*
  store i64 %1940, i64* %1943, align 8
  %1944 = load i64, i64* %RBP, align 8
  %1945 = add i64 %1944, -80
  %1946 = load i64, i64* %PC, align 8
  %1947 = add i64 %1946, 5
  store i64 %1947, i64* %PC, align 8
  %1948 = inttoptr i64 %1945 to i64*
  %1949 = load i64, i64* %1948, align 8
  store i64 %1949, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1950 = add i64 %1944, -24
  %1951 = add i64 %1946, 9
  store i64 %1951, i64* %PC, align 8
  %1952 = inttoptr i64 %1950 to i64*
  %1953 = load i64, i64* %1952, align 8
  store i64 %1953, i64* %RCX, align 8, !tbaa !2428
  %1954 = add i64 %1944, -32
  %1955 = add i64 %1946, 13
  store i64 %1955, i64* %PC, align 8
  %1956 = inttoptr i64 %1954 to i32*
  %1957 = load i32, i32* %1956, align 4
  %1958 = sext i32 %1957 to i64
  store i64 %1958, i64* %RDX, align 8, !tbaa !2428
  %1959 = shl nsw i64 %1958, 3
  %1960 = add i64 %1959, %1953
  %1961 = add i64 %1946, 18
  store i64 %1961, i64* %PC, align 8
  %1962 = inttoptr i64 %1960 to i64*
  store i64 %1949, i64* %1962, align 8
  %1963 = load i64, i64* %RBP, align 8
  %1964 = add i64 %1963, -88
  %1965 = load i64, i64* %PC, align 8
  %1966 = add i64 %1965, 5
  store i64 %1966, i64* %PC, align 8
  %1967 = inttoptr i64 %1964 to i64*
  %1968 = load i64, i64* %1967, align 8
  store i64 %1968, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %1969 = add i64 %1963, -24
  %1970 = add i64 %1965, 9
  store i64 %1970, i64* %PC, align 8
  %1971 = inttoptr i64 %1969 to i64*
  %1972 = load i64, i64* %1971, align 8
  store i64 %1972, i64* %RCX, align 8, !tbaa !2428
  %1973 = add i64 %1963, -32
  %1974 = add i64 %1965, 12
  store i64 %1974, i64* %PC, align 8
  %1975 = inttoptr i64 %1973 to i32*
  %1976 = load i32, i32* %1975, align 4
  %1977 = add i32 %1976, 1
  %1978 = zext i32 %1977 to i64
  store i64 %1978, i64* %RAX, align 8, !tbaa !2428
  %1979 = icmp eq i32 %1976, -1
  %1980 = icmp eq i32 %1977, 0
  %1981 = or i1 %1979, %1980
  %1982 = zext i1 %1981 to i8
  store i8 %1982, i8* %50, align 1, !tbaa !2433
  %1983 = and i32 %1977, 255
  %1984 = tail call i32 @llvm.ctpop.i32(i32 %1983) #10
  %1985 = trunc i32 %1984 to i8
  %1986 = and i8 %1985, 1
  %1987 = xor i8 %1986, 1
  store i8 %1987, i8* %51, align 1, !tbaa !2447
  %1988 = xor i32 %1977, %1976
  %1989 = lshr i32 %1988, 4
  %1990 = trunc i32 %1989 to i8
  %1991 = and i8 %1990, 1
  store i8 %1991, i8* %52, align 1, !tbaa !2451
  %1992 = zext i1 %1980 to i8
  store i8 %1992, i8* %53, align 1, !tbaa !2448
  %1993 = lshr i32 %1977, 31
  %1994 = trunc i32 %1993 to i8
  store i8 %1994, i8* %54, align 1, !tbaa !2449
  %1995 = lshr i32 %1976, 31
  %1996 = xor i32 %1993, %1995
  %1997 = add nuw nsw i32 %1996, %1993
  %1998 = icmp eq i32 %1997, 2
  %1999 = zext i1 %1998 to i8
  store i8 %1999, i8* %55, align 1, !tbaa !2450
  %2000 = sext i32 %1977 to i64
  store i64 %2000, i64* %RDX, align 8, !tbaa !2428
  %2001 = shl nsw i64 %2000, 3
  %2002 = add i64 %1972, %2001
  %2003 = add i64 %1965, 23
  store i64 %2003, i64* %PC, align 8
  %2004 = inttoptr i64 %2002 to i64*
  store i64 %1968, i64* %2004, align 8
  %2005 = load i64, i64* %RBP, align 8
  %2006 = add i64 %2005, -64
  %2007 = load i64, i64* %PC, align 8
  %2008 = add i64 %2007, 5
  store i64 %2008, i64* %PC, align 8
  %2009 = inttoptr i64 %2006 to i64*
  %2010 = load i64, i64* %2009, align 8
  store i64 %2010, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %2011 = add i64 %2005, -24
  %2012 = add i64 %2007, 9
  store i64 %2012, i64* %PC, align 8
  %2013 = inttoptr i64 %2011 to i64*
  %2014 = load i64, i64* %2013, align 8
  store i64 %2014, i64* %RCX, align 8, !tbaa !2428
  %2015 = add i64 %2005, -40
  %2016 = add i64 %2007, 13
  store i64 %2016, i64* %PC, align 8
  %2017 = inttoptr i64 %2015 to i32*
  %2018 = load i32, i32* %2017, align 4
  %2019 = sext i32 %2018 to i64
  store i64 %2019, i64* %RDX, align 8, !tbaa !2428
  %2020 = shl nsw i64 %2019, 3
  %2021 = add i64 %2020, %2014
  %2022 = add i64 %2007, 18
  store i64 %2022, i64* %PC, align 8
  %2023 = inttoptr i64 %2021 to i64*
  store i64 %2010, i64* %2023, align 8
  %2024 = load i64, i64* %RBP, align 8
  %2025 = add i64 %2024, -72
  %2026 = load i64, i64* %PC, align 8
  %2027 = add i64 %2026, 5
  store i64 %2027, i64* %PC, align 8
  %2028 = inttoptr i64 %2025 to i64*
  %2029 = load i64, i64* %2028, align 8
  store i64 %2029, i64* %3127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3129, align 1, !tbaa !2452
  %2030 = add i64 %2024, -24
  %2031 = add i64 %2026, 9
  store i64 %2031, i64* %PC, align 8
  %2032 = inttoptr i64 %2030 to i64*
  %2033 = load i64, i64* %2032, align 8
  store i64 %2033, i64* %RCX, align 8, !tbaa !2428
  %2034 = add i64 %2024, -40
  %2035 = add i64 %2026, 12
  store i64 %2035, i64* %PC, align 8
  %2036 = inttoptr i64 %2034 to i32*
  %2037 = load i32, i32* %2036, align 4
  %2038 = add i32 %2037, 1
  %2039 = zext i32 %2038 to i64
  store i64 %2039, i64* %RAX, align 8, !tbaa !2428
  %2040 = icmp eq i32 %2037, -1
  %2041 = icmp eq i32 %2038, 0
  %2042 = or i1 %2040, %2041
  %2043 = zext i1 %2042 to i8
  store i8 %2043, i8* %50, align 1, !tbaa !2433
  %2044 = and i32 %2038, 255
  %2045 = tail call i32 @llvm.ctpop.i32(i32 %2044) #10
  %2046 = trunc i32 %2045 to i8
  %2047 = and i8 %2046, 1
  %2048 = xor i8 %2047, 1
  store i8 %2048, i8* %51, align 1, !tbaa !2447
  %2049 = xor i32 %2038, %2037
  %2050 = lshr i32 %2049, 4
  %2051 = trunc i32 %2050 to i8
  %2052 = and i8 %2051, 1
  store i8 %2052, i8* %52, align 1, !tbaa !2451
  %2053 = zext i1 %2041 to i8
  store i8 %2053, i8* %53, align 1, !tbaa !2448
  %2054 = lshr i32 %2038, 31
  %2055 = trunc i32 %2054 to i8
  store i8 %2055, i8* %54, align 1, !tbaa !2449
  %2056 = lshr i32 %2037, 31
  %2057 = xor i32 %2054, %2056
  %2058 = add nuw nsw i32 %2057, %2054
  %2059 = icmp eq i32 %2058, 2
  %2060 = zext i1 %2059 to i8
  store i8 %2060, i8* %55, align 1, !tbaa !2450
  %2061 = sext i32 %2038 to i64
  store i64 %2061, i64* %RDX, align 8, !tbaa !2428
  %2062 = shl nsw i64 %2061, 3
  %2063 = add i64 %2033, %2062
  %2064 = add i64 %2026, 23
  store i64 %2064, i64* %PC, align 8
  %2065 = inttoptr i64 %2063 to i64*
  store i64 %2029, i64* %2065, align 8
  %2066 = load i64, i64* %RBP, align 8
  %2067 = add i64 %2066, -28
  %2068 = load i64, i64* %PC, align 8
  %2069 = add i64 %2068, 3
  store i64 %2069, i64* %PC, align 8
  %2070 = inttoptr i64 %2067 to i32*
  %2071 = load i32, i32* %2070, align 4
  %2072 = add i32 %2071, 1
  %2073 = zext i32 %2072 to i64
  store i64 %2073, i64* %RAX, align 8, !tbaa !2428
  %2074 = icmp eq i32 %2071, -1
  %2075 = icmp eq i32 %2072, 0
  %2076 = or i1 %2074, %2075
  %2077 = zext i1 %2076 to i8
  store i8 %2077, i8* %50, align 1, !tbaa !2433
  %2078 = and i32 %2072, 255
  %2079 = tail call i32 @llvm.ctpop.i32(i32 %2078) #10
  %2080 = trunc i32 %2079 to i8
  %2081 = and i8 %2080, 1
  %2082 = xor i8 %2081, 1
  store i8 %2082, i8* %51, align 1, !tbaa !2447
  %2083 = xor i32 %2072, %2071
  %2084 = lshr i32 %2083, 4
  %2085 = trunc i32 %2084 to i8
  %2086 = and i8 %2085, 1
  store i8 %2086, i8* %52, align 1, !tbaa !2451
  %2087 = zext i1 %2075 to i8
  store i8 %2087, i8* %53, align 1, !tbaa !2448
  %2088 = lshr i32 %2072, 31
  %2089 = trunc i32 %2088 to i8
  store i8 %2089, i8* %54, align 1, !tbaa !2449
  %2090 = lshr i32 %2071, 31
  %2091 = xor i32 %2088, %2090
  %2092 = add nuw nsw i32 %2091, %2088
  %2093 = icmp eq i32 %2092, 2
  %2094 = zext i1 %2093 to i8
  store i8 %2094, i8* %55, align 1, !tbaa !2450
  %2095 = add i64 %2068, 9
  store i64 %2095, i64* %PC, align 8
  store i32 %2072, i32* %2070, align 4
  %2096 = load i64, i64* %PC, align 8
  %2097 = add i64 %2096, -779
  store i64 %2097, i64* %PC, align 8, !tbaa !2428
  br label %block_40129d

block_401225:                                     ; preds = %block_401215, %block_401231
  %2098 = phi i64 [ %.pre45, %block_401215 ], [ %285, %block_401231 ]
  %2099 = load i64, i64* %RBP, align 8
  %2100 = add i64 %2099, -28
  %2101 = add i64 %2098, 3
  store i64 %2101, i64* %PC, align 8
  %2102 = inttoptr i64 %2100 to i32*
  %2103 = load i32, i32* %2102, align 4
  %2104 = zext i32 %2103 to i64
  store i64 %2104, i64* %RAX, align 8, !tbaa !2428
  %2105 = add i64 %2099, -48
  %2106 = add i64 %2098, 6
  store i64 %2106, i64* %PC, align 8
  %2107 = inttoptr i64 %2105 to i32*
  %2108 = load i32, i32* %2107, align 4
  %2109 = sub i32 %2103, %2108
  %2110 = icmp ult i32 %2103, %2108
  %2111 = zext i1 %2110 to i8
  store i8 %2111, i8* %50, align 1, !tbaa !2433
  %2112 = and i32 %2109, 255
  %2113 = tail call i32 @llvm.ctpop.i32(i32 %2112) #10
  %2114 = trunc i32 %2113 to i8
  %2115 = and i8 %2114, 1
  %2116 = xor i8 %2115, 1
  store i8 %2116, i8* %51, align 1, !tbaa !2447
  %2117 = xor i32 %2108, %2103
  %2118 = xor i32 %2117, %2109
  %2119 = lshr i32 %2118, 4
  %2120 = trunc i32 %2119 to i8
  %2121 = and i8 %2120, 1
  store i8 %2121, i8* %52, align 1, !tbaa !2451
  %2122 = icmp eq i32 %2109, 0
  %2123 = zext i1 %2122 to i8
  store i8 %2123, i8* %53, align 1, !tbaa !2448
  %2124 = lshr i32 %2109, 31
  %2125 = trunc i32 %2124 to i8
  store i8 %2125, i8* %54, align 1, !tbaa !2449
  %2126 = lshr i32 %2103, 31
  %2127 = lshr i32 %2108, 31
  %2128 = xor i32 %2127, %2126
  %2129 = xor i32 %2124, %2126
  %2130 = add nuw nsw i32 %2129, %2128
  %2131 = icmp eq i32 %2130, 2
  %2132 = zext i1 %2131 to i8
  store i8 %2132, i8* %55, align 1, !tbaa !2450
  %2133 = icmp ne i8 %2125, 0
  %2134 = xor i1 %2133, %2131
  %.v51 = select i1 %2134, i64 12, i64 56
  %2135 = add i64 %2098, %.v51
  store i64 %2135, i64* %PC, align 8, !tbaa !2428
  br i1 %2134, label %block_401231, label %block_40125d

block_40129d:                                     ; preds = %block_401296, %block_4012a9
  %2136 = phi i64 [ %.pre42, %block_401296 ], [ %2097, %block_4012a9 ]
  %2137 = load i64, i64* %RBP, align 8
  %2138 = add i64 %2137, -28
  %2139 = add i64 %2136, 3
  store i64 %2139, i64* %PC, align 8
  %2140 = inttoptr i64 %2138 to i32*
  %2141 = load i32, i32* %2140, align 4
  %2142 = zext i32 %2141 to i64
  store i64 %2142, i64* %RAX, align 8, !tbaa !2428
  %2143 = add i64 %2137, -36
  %2144 = add i64 %2136, 6
  store i64 %2144, i64* %PC, align 8
  %2145 = inttoptr i64 %2143 to i32*
  %2146 = load i32, i32* %2145, align 4
  %2147 = sub i32 %2141, %2146
  %2148 = icmp ult i32 %2141, %2146
  %2149 = zext i1 %2148 to i8
  store i8 %2149, i8* %50, align 1, !tbaa !2433
  %2150 = and i32 %2147, 255
  %2151 = tail call i32 @llvm.ctpop.i32(i32 %2150) #10
  %2152 = trunc i32 %2151 to i8
  %2153 = and i8 %2152, 1
  %2154 = xor i8 %2153, 1
  store i8 %2154, i8* %51, align 1, !tbaa !2447
  %2155 = xor i32 %2146, %2141
  %2156 = xor i32 %2155, %2147
  %2157 = lshr i32 %2156, 4
  %2158 = trunc i32 %2157 to i8
  %2159 = and i8 %2158, 1
  store i8 %2159, i8* %52, align 1, !tbaa !2451
  %2160 = icmp eq i32 %2147, 0
  %2161 = zext i1 %2160 to i8
  store i8 %2161, i8* %53, align 1, !tbaa !2448
  %2162 = lshr i32 %2147, 31
  %2163 = trunc i32 %2162 to i8
  store i8 %2163, i8* %54, align 1, !tbaa !2449
  %2164 = lshr i32 %2141, 31
  %2165 = lshr i32 %2146, 31
  %2166 = xor i32 %2165, %2164
  %2167 = xor i32 %2162, %2164
  %2168 = add nuw nsw i32 %2167, %2166
  %2169 = icmp eq i32 %2168, 2
  %2170 = zext i1 %2169 to i8
  store i8 %2170, i8* %55, align 1, !tbaa !2450
  %2171 = icmp ne i8 %2163, 0
  %2172 = xor i1 %2171, %2169
  %.v50 = select i1 %2172, i64 12, i64 784
  %2173 = add i64 %2136, %.v50
  %2174 = add i64 %2173, 3
  store i64 %2174, i64* %PC, align 8
  br i1 %2172, label %block_4012a9, label %block_4015ad

block_4016aa:                                     ; preds = %block_40169e
  %2175 = add i64 %3007, 3
  store i64 %2175, i64* %PC, align 8
  %2176 = load i32, i32* %2974, align 4
  %2177 = shl i32 %2176, 1
  %2178 = icmp slt i32 %2176, 0
  %2179 = icmp slt i32 %2177, 0
  %2180 = xor i1 %2178, %2179
  %2181 = zext i32 %2177 to i64
  store i64 %2181, i64* %RAX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %2176, 31
  %2182 = trunc i32 %.lobit19 to i8
  store i8 %2182, i8* %50, align 1, !tbaa !2432
  %2183 = and i32 %2177, 254
  %2184 = tail call i32 @llvm.ctpop.i32(i32 %2183) #10
  %2185 = trunc i32 %2184 to i8
  %2186 = and i8 %2185, 1
  %2187 = xor i8 %2186, 1
  store i8 %2187, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %2188 = icmp eq i32 %2177, 0
  %2189 = zext i1 %2188 to i8
  store i8 %2189, i8* %53, align 1, !tbaa !2432
  %2190 = lshr i32 %2176, 30
  %2191 = trunc i32 %2190 to i8
  %2192 = and i8 %2191, 1
  store i8 %2192, i8* %54, align 1, !tbaa !2432
  %2193 = zext i1 %2180 to i8
  store i8 %2193, i8* %55, align 1, !tbaa !2432
  %2194 = add i64 %2971, -16
  %2195 = add i64 %3007, 10
  store i64 %2195, i64* %PC, align 8
  %2196 = inttoptr i64 %2194 to i64*
  %2197 = load i64, i64* %2196, align 8
  store i64 %2197, i64* %RCX, align 8, !tbaa !2428
  %2198 = add i64 %3007, 14
  store i64 %2198, i64* %PC, align 8
  %2199 = load i32, i32* %2979, align 4
  %2200 = sext i32 %2199 to i64
  store i64 %2200, i64* %RDX, align 8, !tbaa !2428
  %2201 = shl nsw i64 %2200, 2
  %2202 = add i64 %2197, %2201
  %2203 = add i64 %3007, 17
  store i64 %2203, i64* %PC, align 8
  %2204 = inttoptr i64 %2202 to i32*
  %2205 = load i32, i32* %2204, align 4
  %2206 = add i32 %2205, %2177
  %2207 = zext i32 %2206 to i64
  store i64 %2207, i64* %RAX, align 8, !tbaa !2428
  %2208 = icmp ult i32 %2206, %2177
  %2209 = icmp ult i32 %2206, %2205
  %2210 = or i1 %2208, %2209
  %2211 = zext i1 %2210 to i8
  store i8 %2211, i8* %50, align 1, !tbaa !2433
  %2212 = and i32 %2206, 255
  %2213 = tail call i32 @llvm.ctpop.i32(i32 %2212) #10
  %2214 = trunc i32 %2213 to i8
  %2215 = and i8 %2214, 1
  %2216 = xor i8 %2215, 1
  store i8 %2216, i8* %51, align 1, !tbaa !2447
  %2217 = xor i32 %2205, %2177
  %2218 = xor i32 %2217, %2206
  %2219 = lshr i32 %2218, 4
  %2220 = trunc i32 %2219 to i8
  %2221 = and i8 %2220, 1
  store i8 %2221, i8* %52, align 1, !tbaa !2451
  %2222 = icmp eq i32 %2206, 0
  %2223 = zext i1 %2222 to i8
  store i8 %2223, i8* %53, align 1, !tbaa !2448
  %2224 = lshr i32 %2206, 31
  %2225 = trunc i32 %2224 to i8
  store i8 %2225, i8* %54, align 1, !tbaa !2449
  %2226 = lshr i32 %2176, 30
  %2227 = and i32 %2226, 1
  %2228 = lshr i32 %2205, 31
  %2229 = xor i32 %2224, %2227
  %2230 = xor i32 %2224, %2228
  %2231 = add nuw nsw i32 %2229, %2230
  %2232 = icmp eq i32 %2231, 2
  %2233 = zext i1 %2232 to i8
  store i8 %2233, i8* %55, align 1, !tbaa !2450
  %2234 = add i64 %2971, -32
  %2235 = add i64 %3007, 20
  store i64 %2235, i64* %PC, align 8
  %2236 = inttoptr i64 %2234 to i32*
  store i32 %2206, i32* %2236, align 4
  %2237 = load i64, i64* %RBP, align 8
  %2238 = add i64 %2237, -36
  %2239 = load i64, i64* %PC, align 8
  %2240 = add i64 %2239, 3
  store i64 %2240, i64* %PC, align 8
  %2241 = inttoptr i64 %2238 to i32*
  %2242 = load i32, i32* %2241, align 4
  %2243 = shl i32 %2242, 1
  %2244 = icmp slt i32 %2242, 0
  %2245 = icmp slt i32 %2243, 0
  %2246 = xor i1 %2244, %2245
  %2247 = zext i32 %2243 to i64
  store i64 %2247, i64* %RAX, align 8, !tbaa !2428
  %.lobit20 = lshr i32 %2242, 31
  %2248 = trunc i32 %.lobit20 to i8
  store i8 %2248, i8* %50, align 1, !tbaa !2432
  %2249 = and i32 %2243, 254
  %2250 = tail call i32 @llvm.ctpop.i32(i32 %2249) #10
  %2251 = trunc i32 %2250 to i8
  %2252 = and i8 %2251, 1
  %2253 = xor i8 %2252, 1
  store i8 %2253, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %2254 = icmp eq i32 %2243, 0
  %2255 = zext i1 %2254 to i8
  store i8 %2255, i8* %53, align 1, !tbaa !2432
  %2256 = lshr i32 %2242, 30
  %2257 = trunc i32 %2256 to i8
  %2258 = and i8 %2257, 1
  store i8 %2258, i8* %54, align 1, !tbaa !2432
  %2259 = zext i1 %2246 to i8
  store i8 %2259, i8* %55, align 1, !tbaa !2432
  %2260 = add i64 %2237, -16
  %2261 = add i64 %2239, 10
  store i64 %2261, i64* %PC, align 8
  %2262 = inttoptr i64 %2260 to i64*
  %2263 = load i64, i64* %2262, align 8
  store i64 %2263, i64* %RCX, align 8, !tbaa !2428
  %2264 = add i64 %2237, -28
  %2265 = add i64 %2239, 14
  store i64 %2265, i64* %PC, align 8
  %2266 = inttoptr i64 %2264 to i32*
  %2267 = load i32, i32* %2266, align 4
  %2268 = sext i32 %2267 to i64
  store i64 %2268, i64* %RDX, align 8, !tbaa !2428
  %2269 = shl nsw i64 %2268, 2
  %2270 = add i64 %2263, %2269
  %2271 = add i64 %2239, 17
  store i64 %2271, i64* %PC, align 8
  %2272 = inttoptr i64 %2270 to i32*
  %2273 = load i32, i32* %2272, align 4
  %2274 = add i32 %2273, %2243
  %2275 = zext i32 %2274 to i64
  store i64 %2275, i64* %RAX, align 8, !tbaa !2428
  %2276 = icmp ult i32 %2274, %2243
  %2277 = icmp ult i32 %2274, %2273
  %2278 = or i1 %2276, %2277
  %2279 = zext i1 %2278 to i8
  store i8 %2279, i8* %50, align 1, !tbaa !2433
  %2280 = and i32 %2274, 255
  %2281 = tail call i32 @llvm.ctpop.i32(i32 %2280) #10
  %2282 = trunc i32 %2281 to i8
  %2283 = and i8 %2282, 1
  %2284 = xor i8 %2283, 1
  store i8 %2284, i8* %51, align 1, !tbaa !2447
  %2285 = xor i32 %2273, %2243
  %2286 = xor i32 %2285, %2274
  %2287 = lshr i32 %2286, 4
  %2288 = trunc i32 %2287 to i8
  %2289 = and i8 %2288, 1
  store i8 %2289, i8* %52, align 1, !tbaa !2451
  %2290 = icmp eq i32 %2274, 0
  %2291 = zext i1 %2290 to i8
  store i8 %2291, i8* %53, align 1, !tbaa !2448
  %2292 = lshr i32 %2274, 31
  %2293 = trunc i32 %2292 to i8
  store i8 %2293, i8* %54, align 1, !tbaa !2449
  %2294 = lshr i32 %2242, 30
  %2295 = and i32 %2294, 1
  %2296 = lshr i32 %2273, 31
  %2297 = xor i32 %2292, %2295
  %2298 = xor i32 %2292, %2296
  %2299 = add nuw nsw i32 %2297, %2298
  %2300 = icmp eq i32 %2299, 2
  %2301 = zext i1 %2300 to i8
  store i8 %2301, i8* %55, align 1, !tbaa !2450
  %2302 = add i64 %2237, -40
  %2303 = add i64 %2239, 20
  store i64 %2303, i64* %PC, align 8
  %2304 = inttoptr i64 %2302 to i32*
  store i32 %2274, i32* %2304, align 4
  %2305 = load i64, i64* %RBP, align 8
  %2306 = add i64 %2305, -24
  %2307 = load i64, i64* %PC, align 8
  %2308 = add i64 %2307, 4
  store i64 %2308, i64* %PC, align 8
  %2309 = inttoptr i64 %2306 to i64*
  %2310 = load i64, i64* %2309, align 8
  store i64 %2310, i64* %RCX, align 8, !tbaa !2428
  %2311 = add i64 %2305, -32
  %2312 = add i64 %2307, 8
  store i64 %2312, i64* %PC, align 8
  %2313 = inttoptr i64 %2311 to i32*
  %2314 = load i32, i32* %2313, align 4
  %2315 = sext i32 %2314 to i64
  store i64 %2315, i64* %RDX, align 8, !tbaa !2428
  %2316 = shl nsw i64 %2315, 3
  %2317 = add i64 %2316, %2310
  %2318 = add i64 %2307, 13
  store i64 %2318, i64* %PC, align 8
  %2319 = inttoptr i64 %2317 to i64*
  %2320 = load i64, i64* %2319, align 8
  store i64 %2320, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2321 = add i64 %2305, -64
  %2322 = add i64 %2307, 18
  store i64 %2322, i64* %PC, align 8
  %2323 = inttoptr i64 %2321 to i64*
  store i64 %2320, i64* %2323, align 8
  %2324 = load i64, i64* %RBP, align 8
  %2325 = add i64 %2324, -24
  %2326 = load i64, i64* %PC, align 8
  %2327 = add i64 %2326, 4
  store i64 %2327, i64* %PC, align 8
  %2328 = inttoptr i64 %2325 to i64*
  %2329 = load i64, i64* %2328, align 8
  store i64 %2329, i64* %RCX, align 8, !tbaa !2428
  %2330 = add i64 %2324, -32
  %2331 = add i64 %2326, 7
  store i64 %2331, i64* %PC, align 8
  %2332 = inttoptr i64 %2330 to i32*
  %2333 = load i32, i32* %2332, align 4
  %2334 = add i32 %2333, 1
  %2335 = zext i32 %2334 to i64
  store i64 %2335, i64* %RAX, align 8, !tbaa !2428
  %2336 = icmp eq i32 %2333, -1
  %2337 = icmp eq i32 %2334, 0
  %2338 = or i1 %2336, %2337
  %2339 = zext i1 %2338 to i8
  store i8 %2339, i8* %50, align 1, !tbaa !2433
  %2340 = and i32 %2334, 255
  %2341 = tail call i32 @llvm.ctpop.i32(i32 %2340) #10
  %2342 = trunc i32 %2341 to i8
  %2343 = and i8 %2342, 1
  %2344 = xor i8 %2343, 1
  store i8 %2344, i8* %51, align 1, !tbaa !2447
  %2345 = xor i32 %2334, %2333
  %2346 = lshr i32 %2345, 4
  %2347 = trunc i32 %2346 to i8
  %2348 = and i8 %2347, 1
  store i8 %2348, i8* %52, align 1, !tbaa !2451
  %2349 = zext i1 %2337 to i8
  store i8 %2349, i8* %53, align 1, !tbaa !2448
  %2350 = lshr i32 %2334, 31
  %2351 = trunc i32 %2350 to i8
  store i8 %2351, i8* %54, align 1, !tbaa !2449
  %2352 = lshr i32 %2333, 31
  %2353 = xor i32 %2350, %2352
  %2354 = add nuw nsw i32 %2353, %2350
  %2355 = icmp eq i32 %2354, 2
  %2356 = zext i1 %2355 to i8
  store i8 %2356, i8* %55, align 1, !tbaa !2450
  %2357 = sext i32 %2334 to i64
  store i64 %2357, i64* %RDX, align 8, !tbaa !2428
  %2358 = shl nsw i64 %2357, 3
  %2359 = add i64 %2329, %2358
  %2360 = add i64 %2326, 18
  store i64 %2360, i64* %PC, align 8
  %2361 = inttoptr i64 %2359 to i64*
  %2362 = load i64, i64* %2361, align 8
  store i64 %2362, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2363 = add i64 %2324, -72
  %2364 = add i64 %2326, 23
  store i64 %2364, i64* %PC, align 8
  %2365 = inttoptr i64 %2363 to i64*
  store i64 %2362, i64* %2365, align 8
  %2366 = load i64, i64* %RBP, align 8
  %2367 = add i64 %2366, -24
  %2368 = load i64, i64* %PC, align 8
  %2369 = add i64 %2368, 4
  store i64 %2369, i64* %PC, align 8
  %2370 = inttoptr i64 %2367 to i64*
  %2371 = load i64, i64* %2370, align 8
  store i64 %2371, i64* %RCX, align 8, !tbaa !2428
  %2372 = add i64 %2366, -40
  %2373 = add i64 %2368, 8
  store i64 %2373, i64* %PC, align 8
  %2374 = inttoptr i64 %2372 to i32*
  %2375 = load i32, i32* %2374, align 4
  %2376 = sext i32 %2375 to i64
  store i64 %2376, i64* %RDX, align 8, !tbaa !2428
  %2377 = shl nsw i64 %2376, 3
  %2378 = add i64 %2377, %2371
  %2379 = add i64 %2368, 13
  store i64 %2379, i64* %PC, align 8
  %2380 = inttoptr i64 %2378 to i64*
  %2381 = load i64, i64* %2380, align 8
  store i64 %2381, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2382 = add i64 %2366, -80
  %2383 = add i64 %2368, 18
  store i64 %2383, i64* %PC, align 8
  %2384 = inttoptr i64 %2382 to i64*
  store i64 %2381, i64* %2384, align 8
  %2385 = load i64, i64* %RBP, align 8
  %2386 = add i64 %2385, -24
  %2387 = load i64, i64* %PC, align 8
  %2388 = add i64 %2387, 4
  store i64 %2388, i64* %PC, align 8
  %2389 = inttoptr i64 %2386 to i64*
  %2390 = load i64, i64* %2389, align 8
  store i64 %2390, i64* %RCX, align 8, !tbaa !2428
  %2391 = add i64 %2385, -40
  %2392 = add i64 %2387, 7
  store i64 %2392, i64* %PC, align 8
  %2393 = inttoptr i64 %2391 to i32*
  %2394 = load i32, i32* %2393, align 4
  %2395 = add i32 %2394, 1
  %2396 = zext i32 %2395 to i64
  store i64 %2396, i64* %RAX, align 8, !tbaa !2428
  %2397 = icmp eq i32 %2394, -1
  %2398 = icmp eq i32 %2395, 0
  %2399 = or i1 %2397, %2398
  %2400 = zext i1 %2399 to i8
  store i8 %2400, i8* %50, align 1, !tbaa !2433
  %2401 = and i32 %2395, 255
  %2402 = tail call i32 @llvm.ctpop.i32(i32 %2401) #10
  %2403 = trunc i32 %2402 to i8
  %2404 = and i8 %2403, 1
  %2405 = xor i8 %2404, 1
  store i8 %2405, i8* %51, align 1, !tbaa !2447
  %2406 = xor i32 %2395, %2394
  %2407 = lshr i32 %2406, 4
  %2408 = trunc i32 %2407 to i8
  %2409 = and i8 %2408, 1
  store i8 %2409, i8* %52, align 1, !tbaa !2451
  %2410 = zext i1 %2398 to i8
  store i8 %2410, i8* %53, align 1, !tbaa !2448
  %2411 = lshr i32 %2395, 31
  %2412 = trunc i32 %2411 to i8
  store i8 %2412, i8* %54, align 1, !tbaa !2449
  %2413 = lshr i32 %2394, 31
  %2414 = xor i32 %2411, %2413
  %2415 = add nuw nsw i32 %2414, %2411
  %2416 = icmp eq i32 %2415, 2
  %2417 = zext i1 %2416 to i8
  store i8 %2417, i8* %55, align 1, !tbaa !2450
  %2418 = sext i32 %2395 to i64
  store i64 %2418, i64* %RDX, align 8, !tbaa !2428
  %2419 = shl nsw i64 %2418, 3
  %2420 = add i64 %2390, %2419
  %2421 = add i64 %2387, 18
  store i64 %2421, i64* %PC, align 8
  %2422 = inttoptr i64 %2420 to i64*
  %2423 = load i64, i64* %2422, align 8
  store i64 %2423, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2424 = add i64 %2385, -88
  %2425 = add i64 %2387, 23
  store i64 %2425, i64* %PC, align 8
  %2426 = inttoptr i64 %2424 to i64*
  store i64 %2423, i64* %2426, align 8
  %2427 = load i64, i64* %RBP, align 8
  %2428 = add i64 %2427, -80
  %2429 = load i64, i64* %PC, align 8
  %2430 = add i64 %2429, 5
  store i64 %2430, i64* %PC, align 8
  %2431 = inttoptr i64 %2428 to i64*
  %2432 = load i64, i64* %2431, align 8
  store i64 %2432, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2433 = add i64 %2427, -24
  %2434 = add i64 %2429, 9
  store i64 %2434, i64* %PC, align 8
  %2435 = inttoptr i64 %2433 to i64*
  %2436 = load i64, i64* %2435, align 8
  store i64 %2436, i64* %RCX, align 8, !tbaa !2428
  %2437 = add i64 %2427, -32
  %2438 = add i64 %2429, 13
  store i64 %2438, i64* %PC, align 8
  %2439 = inttoptr i64 %2437 to i32*
  %2440 = load i32, i32* %2439, align 4
  %2441 = sext i32 %2440 to i64
  store i64 %2441, i64* %RDX, align 8, !tbaa !2428
  %2442 = shl nsw i64 %2441, 3
  %2443 = add i64 %2442, %2436
  %2444 = add i64 %2429, 18
  store i64 %2444, i64* %PC, align 8
  %2445 = inttoptr i64 %2443 to i64*
  store i64 %2432, i64* %2445, align 8
  %2446 = load i64, i64* %RBP, align 8
  %2447 = add i64 %2446, -88
  %2448 = load i64, i64* %PC, align 8
  %2449 = add i64 %2448, 5
  store i64 %2449, i64* %PC, align 8
  %2450 = inttoptr i64 %2447 to i64*
  %2451 = load i64, i64* %2450, align 8
  store i64 %2451, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2452 = add i64 %2446, -24
  %2453 = add i64 %2448, 9
  store i64 %2453, i64* %PC, align 8
  %2454 = inttoptr i64 %2452 to i64*
  %2455 = load i64, i64* %2454, align 8
  store i64 %2455, i64* %RCX, align 8, !tbaa !2428
  %2456 = add i64 %2446, -32
  %2457 = add i64 %2448, 12
  store i64 %2457, i64* %PC, align 8
  %2458 = inttoptr i64 %2456 to i32*
  %2459 = load i32, i32* %2458, align 4
  %2460 = add i32 %2459, 1
  %2461 = zext i32 %2460 to i64
  store i64 %2461, i64* %RAX, align 8, !tbaa !2428
  %2462 = icmp eq i32 %2459, -1
  %2463 = icmp eq i32 %2460, 0
  %2464 = or i1 %2462, %2463
  %2465 = zext i1 %2464 to i8
  store i8 %2465, i8* %50, align 1, !tbaa !2433
  %2466 = and i32 %2460, 255
  %2467 = tail call i32 @llvm.ctpop.i32(i32 %2466) #10
  %2468 = trunc i32 %2467 to i8
  %2469 = and i8 %2468, 1
  %2470 = xor i8 %2469, 1
  store i8 %2470, i8* %51, align 1, !tbaa !2447
  %2471 = xor i32 %2460, %2459
  %2472 = lshr i32 %2471, 4
  %2473 = trunc i32 %2472 to i8
  %2474 = and i8 %2473, 1
  store i8 %2474, i8* %52, align 1, !tbaa !2451
  %2475 = zext i1 %2463 to i8
  store i8 %2475, i8* %53, align 1, !tbaa !2448
  %2476 = lshr i32 %2460, 31
  %2477 = trunc i32 %2476 to i8
  store i8 %2477, i8* %54, align 1, !tbaa !2449
  %2478 = lshr i32 %2459, 31
  %2479 = xor i32 %2476, %2478
  %2480 = add nuw nsw i32 %2479, %2476
  %2481 = icmp eq i32 %2480, 2
  %2482 = zext i1 %2481 to i8
  store i8 %2482, i8* %55, align 1, !tbaa !2450
  %2483 = sext i32 %2460 to i64
  store i64 %2483, i64* %RDX, align 8, !tbaa !2428
  %2484 = shl nsw i64 %2483, 3
  %2485 = add i64 %2455, %2484
  %2486 = add i64 %2448, 23
  store i64 %2486, i64* %PC, align 8
  %2487 = inttoptr i64 %2485 to i64*
  store i64 %2451, i64* %2487, align 8
  %2488 = load i64, i64* %RBP, align 8
  %2489 = add i64 %2488, -64
  %2490 = load i64, i64* %PC, align 8
  %2491 = add i64 %2490, 5
  store i64 %2491, i64* %PC, align 8
  %2492 = inttoptr i64 %2489 to i64*
  %2493 = load i64, i64* %2492, align 8
  store i64 %2493, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2494 = add i64 %2488, -24
  %2495 = add i64 %2490, 9
  store i64 %2495, i64* %PC, align 8
  %2496 = inttoptr i64 %2494 to i64*
  %2497 = load i64, i64* %2496, align 8
  store i64 %2497, i64* %RCX, align 8, !tbaa !2428
  %2498 = add i64 %2488, -40
  %2499 = add i64 %2490, 13
  store i64 %2499, i64* %PC, align 8
  %2500 = inttoptr i64 %2498 to i32*
  %2501 = load i32, i32* %2500, align 4
  %2502 = sext i32 %2501 to i64
  store i64 %2502, i64* %RDX, align 8, !tbaa !2428
  %2503 = shl nsw i64 %2502, 3
  %2504 = add i64 %2503, %2497
  %2505 = add i64 %2490, 18
  store i64 %2505, i64* %PC, align 8
  %2506 = inttoptr i64 %2504 to i64*
  store i64 %2493, i64* %2506, align 8
  %2507 = load i64, i64* %RBP, align 8
  %2508 = add i64 %2507, -72
  %2509 = load i64, i64* %PC, align 8
  %2510 = add i64 %2509, 5
  store i64 %2510, i64* %PC, align 8
  %2511 = inttoptr i64 %2508 to i64*
  %2512 = load i64, i64* %2511, align 8
  store i64 %2512, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2513 = add i64 %2507, -24
  %2514 = add i64 %2509, 9
  store i64 %2514, i64* %PC, align 8
  %2515 = inttoptr i64 %2513 to i64*
  %2516 = load i64, i64* %2515, align 8
  store i64 %2516, i64* %RCX, align 8, !tbaa !2428
  %2517 = add i64 %2507, -40
  %2518 = add i64 %2509, 12
  store i64 %2518, i64* %PC, align 8
  %2519 = inttoptr i64 %2517 to i32*
  %2520 = load i32, i32* %2519, align 4
  %2521 = add i32 %2520, 1
  %2522 = zext i32 %2521 to i64
  store i64 %2522, i64* %RAX, align 8, !tbaa !2428
  %2523 = icmp eq i32 %2520, -1
  %2524 = icmp eq i32 %2521, 0
  %2525 = or i1 %2523, %2524
  %2526 = zext i1 %2525 to i8
  store i8 %2526, i8* %50, align 1, !tbaa !2433
  %2527 = and i32 %2521, 255
  %2528 = tail call i32 @llvm.ctpop.i32(i32 %2527) #10
  %2529 = trunc i32 %2528 to i8
  %2530 = and i8 %2529, 1
  %2531 = xor i8 %2530, 1
  store i8 %2531, i8* %51, align 1, !tbaa !2447
  %2532 = xor i32 %2521, %2520
  %2533 = lshr i32 %2532, 4
  %2534 = trunc i32 %2533 to i8
  %2535 = and i8 %2534, 1
  store i8 %2535, i8* %52, align 1, !tbaa !2451
  %2536 = zext i1 %2524 to i8
  store i8 %2536, i8* %53, align 1, !tbaa !2448
  %2537 = lshr i32 %2521, 31
  %2538 = trunc i32 %2537 to i8
  store i8 %2538, i8* %54, align 1, !tbaa !2449
  %2539 = lshr i32 %2520, 31
  %2540 = xor i32 %2537, %2539
  %2541 = add nuw nsw i32 %2540, %2537
  %2542 = icmp eq i32 %2541, 2
  %2543 = zext i1 %2542 to i8
  store i8 %2543, i8* %55, align 1, !tbaa !2450
  %2544 = sext i32 %2521 to i64
  store i64 %2544, i64* %RDX, align 8, !tbaa !2428
  %2545 = shl nsw i64 %2544, 3
  %2546 = add i64 %2516, %2545
  %2547 = add i64 %2509, 23
  store i64 %2547, i64* %PC, align 8
  %2548 = inttoptr i64 %2546 to i64*
  store i64 %2512, i64* %2548, align 8
  %2549 = load i64, i64* %RBP, align 8
  %2550 = add i64 %2549, -52
  %2551 = load i64, i64* %PC, align 8
  %2552 = add i64 %2551, 3
  store i64 %2552, i64* %PC, align 8
  %2553 = inttoptr i64 %2550 to i32*
  %2554 = load i32, i32* %2553, align 4
  %2555 = zext i32 %2554 to i64
  store i64 %2555, i64* %RAX, align 8, !tbaa !2428
  %2556 = add i64 %2549, -32
  %2557 = add i64 %2551, 6
  store i64 %2557, i64* %PC, align 8
  %2558 = inttoptr i64 %2556 to i32*
  %2559 = load i32, i32* %2558, align 4
  %2560 = add i32 %2559, %2554
  %2561 = zext i32 %2560 to i64
  store i64 %2561, i64* %RAX, align 8, !tbaa !2428
  %2562 = icmp ult i32 %2560, %2554
  %2563 = icmp ult i32 %2560, %2559
  %2564 = or i1 %2562, %2563
  %2565 = zext i1 %2564 to i8
  store i8 %2565, i8* %50, align 1, !tbaa !2433
  %2566 = and i32 %2560, 255
  %2567 = tail call i32 @llvm.ctpop.i32(i32 %2566) #10
  %2568 = trunc i32 %2567 to i8
  %2569 = and i8 %2568, 1
  %2570 = xor i8 %2569, 1
  store i8 %2570, i8* %51, align 1, !tbaa !2447
  %2571 = xor i32 %2559, %2554
  %2572 = xor i32 %2571, %2560
  %2573 = lshr i32 %2572, 4
  %2574 = trunc i32 %2573 to i8
  %2575 = and i8 %2574, 1
  store i8 %2575, i8* %52, align 1, !tbaa !2451
  %2576 = icmp eq i32 %2560, 0
  %2577 = zext i1 %2576 to i8
  store i8 %2577, i8* %53, align 1, !tbaa !2448
  %2578 = lshr i32 %2560, 31
  %2579 = trunc i32 %2578 to i8
  store i8 %2579, i8* %54, align 1, !tbaa !2449
  %2580 = lshr i32 %2554, 31
  %2581 = lshr i32 %2559, 31
  %2582 = xor i32 %2578, %2580
  %2583 = xor i32 %2578, %2581
  %2584 = add nuw nsw i32 %2582, %2583
  %2585 = icmp eq i32 %2584, 2
  %2586 = zext i1 %2585 to i8
  store i8 %2586, i8* %55, align 1, !tbaa !2450
  %2587 = add i64 %2551, 9
  store i64 %2587, i64* %PC, align 8
  store i32 %2560, i32* %2558, align 4
  %2588 = load i64, i64* %RBP, align 8
  %2589 = add i64 %2588, -52
  %2590 = load i64, i64* %PC, align 8
  %2591 = add i64 %2590, 3
  store i64 %2591, i64* %PC, align 8
  %2592 = inttoptr i64 %2589 to i32*
  %2593 = load i32, i32* %2592, align 4
  %2594 = zext i32 %2593 to i64
  store i64 %2594, i64* %RAX, align 8, !tbaa !2428
  %2595 = add i64 %2588, -40
  %2596 = add i64 %2590, 6
  store i64 %2596, i64* %PC, align 8
  %2597 = inttoptr i64 %2595 to i32*
  %2598 = load i32, i32* %2597, align 4
  %2599 = add i32 %2598, %2593
  %2600 = zext i32 %2599 to i64
  store i64 %2600, i64* %RAX, align 8, !tbaa !2428
  %2601 = icmp ult i32 %2599, %2593
  %2602 = icmp ult i32 %2599, %2598
  %2603 = or i1 %2601, %2602
  %2604 = zext i1 %2603 to i8
  store i8 %2604, i8* %50, align 1, !tbaa !2433
  %2605 = and i32 %2599, 255
  %2606 = tail call i32 @llvm.ctpop.i32(i32 %2605) #10
  %2607 = trunc i32 %2606 to i8
  %2608 = and i8 %2607, 1
  %2609 = xor i8 %2608, 1
  store i8 %2609, i8* %51, align 1, !tbaa !2447
  %2610 = xor i32 %2598, %2593
  %2611 = xor i32 %2610, %2599
  %2612 = lshr i32 %2611, 4
  %2613 = trunc i32 %2612 to i8
  %2614 = and i8 %2613, 1
  store i8 %2614, i8* %52, align 1, !tbaa !2451
  %2615 = icmp eq i32 %2599, 0
  %2616 = zext i1 %2615 to i8
  store i8 %2616, i8* %53, align 1, !tbaa !2448
  %2617 = lshr i32 %2599, 31
  %2618 = trunc i32 %2617 to i8
  store i8 %2618, i8* %54, align 1, !tbaa !2449
  %2619 = lshr i32 %2593, 31
  %2620 = lshr i32 %2598, 31
  %2621 = xor i32 %2617, %2619
  %2622 = xor i32 %2617, %2620
  %2623 = add nuw nsw i32 %2621, %2622
  %2624 = icmp eq i32 %2623, 2
  %2625 = zext i1 %2624 to i8
  store i8 %2625, i8* %55, align 1, !tbaa !2450
  %2626 = add i64 %2590, 9
  store i64 %2626, i64* %PC, align 8
  store i32 %2599, i32* %2597, align 4
  %2627 = load i64, i64* %RBP, align 8
  %2628 = add i64 %2627, -24
  %2629 = load i64, i64* %PC, align 8
  %2630 = add i64 %2629, 4
  store i64 %2630, i64* %PC, align 8
  %2631 = inttoptr i64 %2628 to i64*
  %2632 = load i64, i64* %2631, align 8
  store i64 %2632, i64* %RCX, align 8, !tbaa !2428
  %2633 = add i64 %2627, -32
  %2634 = add i64 %2629, 8
  store i64 %2634, i64* %PC, align 8
  %2635 = inttoptr i64 %2633 to i32*
  %2636 = load i32, i32* %2635, align 4
  %2637 = sext i32 %2636 to i64
  store i64 %2637, i64* %RDX, align 8, !tbaa !2428
  %2638 = shl nsw i64 %2637, 3
  %2639 = add i64 %2638, %2632
  %2640 = add i64 %2629, 13
  store i64 %2640, i64* %PC, align 8
  %2641 = inttoptr i64 %2639 to i64*
  %2642 = load i64, i64* %2641, align 8
  store i64 %2642, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2643 = add i64 %2627, -64
  %2644 = add i64 %2629, 18
  store i64 %2644, i64* %PC, align 8
  %2645 = inttoptr i64 %2643 to i64*
  store i64 %2642, i64* %2645, align 8
  %2646 = load i64, i64* %RBP, align 8
  %2647 = add i64 %2646, -24
  %2648 = load i64, i64* %PC, align 8
  %2649 = add i64 %2648, 4
  store i64 %2649, i64* %PC, align 8
  %2650 = inttoptr i64 %2647 to i64*
  %2651 = load i64, i64* %2650, align 8
  store i64 %2651, i64* %RCX, align 8, !tbaa !2428
  %2652 = add i64 %2646, -32
  %2653 = add i64 %2648, 7
  store i64 %2653, i64* %PC, align 8
  %2654 = inttoptr i64 %2652 to i32*
  %2655 = load i32, i32* %2654, align 4
  %2656 = add i32 %2655, 1
  %2657 = zext i32 %2656 to i64
  store i64 %2657, i64* %RAX, align 8, !tbaa !2428
  %2658 = icmp eq i32 %2655, -1
  %2659 = icmp eq i32 %2656, 0
  %2660 = or i1 %2658, %2659
  %2661 = zext i1 %2660 to i8
  store i8 %2661, i8* %50, align 1, !tbaa !2433
  %2662 = and i32 %2656, 255
  %2663 = tail call i32 @llvm.ctpop.i32(i32 %2662) #10
  %2664 = trunc i32 %2663 to i8
  %2665 = and i8 %2664, 1
  %2666 = xor i8 %2665, 1
  store i8 %2666, i8* %51, align 1, !tbaa !2447
  %2667 = xor i32 %2656, %2655
  %2668 = lshr i32 %2667, 4
  %2669 = trunc i32 %2668 to i8
  %2670 = and i8 %2669, 1
  store i8 %2670, i8* %52, align 1, !tbaa !2451
  %2671 = zext i1 %2659 to i8
  store i8 %2671, i8* %53, align 1, !tbaa !2448
  %2672 = lshr i32 %2656, 31
  %2673 = trunc i32 %2672 to i8
  store i8 %2673, i8* %54, align 1, !tbaa !2449
  %2674 = lshr i32 %2655, 31
  %2675 = xor i32 %2672, %2674
  %2676 = add nuw nsw i32 %2675, %2672
  %2677 = icmp eq i32 %2676, 2
  %2678 = zext i1 %2677 to i8
  store i8 %2678, i8* %55, align 1, !tbaa !2450
  %2679 = sext i32 %2656 to i64
  store i64 %2679, i64* %RDX, align 8, !tbaa !2428
  %2680 = shl nsw i64 %2679, 3
  %2681 = add i64 %2651, %2680
  %2682 = add i64 %2648, 18
  store i64 %2682, i64* %PC, align 8
  %2683 = inttoptr i64 %2681 to i64*
  %2684 = load i64, i64* %2683, align 8
  store i64 %2684, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2685 = add i64 %2646, -72
  %2686 = add i64 %2648, 23
  store i64 %2686, i64* %PC, align 8
  %2687 = inttoptr i64 %2685 to i64*
  store i64 %2684, i64* %2687, align 8
  %2688 = load i64, i64* %RBP, align 8
  %2689 = add i64 %2688, -24
  %2690 = load i64, i64* %PC, align 8
  %2691 = add i64 %2690, 4
  store i64 %2691, i64* %PC, align 8
  %2692 = inttoptr i64 %2689 to i64*
  %2693 = load i64, i64* %2692, align 8
  store i64 %2693, i64* %RCX, align 8, !tbaa !2428
  %2694 = add i64 %2688, -40
  %2695 = add i64 %2690, 8
  store i64 %2695, i64* %PC, align 8
  %2696 = inttoptr i64 %2694 to i32*
  %2697 = load i32, i32* %2696, align 4
  %2698 = sext i32 %2697 to i64
  store i64 %2698, i64* %RDX, align 8, !tbaa !2428
  %2699 = shl nsw i64 %2698, 3
  %2700 = add i64 %2699, %2693
  %2701 = add i64 %2690, 13
  store i64 %2701, i64* %PC, align 8
  %2702 = inttoptr i64 %2700 to i64*
  %2703 = load i64, i64* %2702, align 8
  store i64 %2703, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2704 = add i64 %2688, -80
  %2705 = add i64 %2690, 18
  store i64 %2705, i64* %PC, align 8
  %2706 = inttoptr i64 %2704 to i64*
  store i64 %2703, i64* %2706, align 8
  %2707 = load i64, i64* %RBP, align 8
  %2708 = add i64 %2707, -24
  %2709 = load i64, i64* %PC, align 8
  %2710 = add i64 %2709, 4
  store i64 %2710, i64* %PC, align 8
  %2711 = inttoptr i64 %2708 to i64*
  %2712 = load i64, i64* %2711, align 8
  store i64 %2712, i64* %RCX, align 8, !tbaa !2428
  %2713 = add i64 %2707, -40
  %2714 = add i64 %2709, 7
  store i64 %2714, i64* %PC, align 8
  %2715 = inttoptr i64 %2713 to i32*
  %2716 = load i32, i32* %2715, align 4
  %2717 = add i32 %2716, 1
  %2718 = zext i32 %2717 to i64
  store i64 %2718, i64* %RAX, align 8, !tbaa !2428
  %2719 = icmp eq i32 %2716, -1
  %2720 = icmp eq i32 %2717, 0
  %2721 = or i1 %2719, %2720
  %2722 = zext i1 %2721 to i8
  store i8 %2722, i8* %50, align 1, !tbaa !2433
  %2723 = and i32 %2717, 255
  %2724 = tail call i32 @llvm.ctpop.i32(i32 %2723) #10
  %2725 = trunc i32 %2724 to i8
  %2726 = and i8 %2725, 1
  %2727 = xor i8 %2726, 1
  store i8 %2727, i8* %51, align 1, !tbaa !2447
  %2728 = xor i32 %2717, %2716
  %2729 = lshr i32 %2728, 4
  %2730 = trunc i32 %2729 to i8
  %2731 = and i8 %2730, 1
  store i8 %2731, i8* %52, align 1, !tbaa !2451
  %2732 = zext i1 %2720 to i8
  store i8 %2732, i8* %53, align 1, !tbaa !2448
  %2733 = lshr i32 %2717, 31
  %2734 = trunc i32 %2733 to i8
  store i8 %2734, i8* %54, align 1, !tbaa !2449
  %2735 = lshr i32 %2716, 31
  %2736 = xor i32 %2733, %2735
  %2737 = add nuw nsw i32 %2736, %2733
  %2738 = icmp eq i32 %2737, 2
  %2739 = zext i1 %2738 to i8
  store i8 %2739, i8* %55, align 1, !tbaa !2450
  %2740 = sext i32 %2717 to i64
  store i64 %2740, i64* %RDX, align 8, !tbaa !2428
  %2741 = shl nsw i64 %2740, 3
  %2742 = add i64 %2712, %2741
  %2743 = add i64 %2709, 18
  store i64 %2743, i64* %PC, align 8
  %2744 = inttoptr i64 %2742 to i64*
  %2745 = load i64, i64* %2744, align 8
  store i64 %2745, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2746 = add i64 %2707, -88
  %2747 = add i64 %2709, 23
  store i64 %2747, i64* %PC, align 8
  %2748 = inttoptr i64 %2746 to i64*
  store i64 %2745, i64* %2748, align 8
  %2749 = load i64, i64* %RBP, align 8
  %2750 = add i64 %2749, -80
  %2751 = load i64, i64* %PC, align 8
  %2752 = add i64 %2751, 5
  store i64 %2752, i64* %PC, align 8
  %2753 = inttoptr i64 %2750 to i64*
  %2754 = load i64, i64* %2753, align 8
  store i64 %2754, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2755 = add i64 %2749, -24
  %2756 = add i64 %2751, 9
  store i64 %2756, i64* %PC, align 8
  %2757 = inttoptr i64 %2755 to i64*
  %2758 = load i64, i64* %2757, align 8
  store i64 %2758, i64* %RCX, align 8, !tbaa !2428
  %2759 = add i64 %2749, -32
  %2760 = add i64 %2751, 13
  store i64 %2760, i64* %PC, align 8
  %2761 = inttoptr i64 %2759 to i32*
  %2762 = load i32, i32* %2761, align 4
  %2763 = sext i32 %2762 to i64
  store i64 %2763, i64* %RDX, align 8, !tbaa !2428
  %2764 = shl nsw i64 %2763, 3
  %2765 = add i64 %2764, %2758
  %2766 = add i64 %2751, 18
  store i64 %2766, i64* %PC, align 8
  %2767 = inttoptr i64 %2765 to i64*
  store i64 %2754, i64* %2767, align 8
  %2768 = load i64, i64* %RBP, align 8
  %2769 = add i64 %2768, -88
  %2770 = load i64, i64* %PC, align 8
  %2771 = add i64 %2770, 5
  store i64 %2771, i64* %PC, align 8
  %2772 = inttoptr i64 %2769 to i64*
  %2773 = load i64, i64* %2772, align 8
  store i64 %2773, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2774 = add i64 %2768, -24
  %2775 = add i64 %2770, 9
  store i64 %2775, i64* %PC, align 8
  %2776 = inttoptr i64 %2774 to i64*
  %2777 = load i64, i64* %2776, align 8
  store i64 %2777, i64* %RCX, align 8, !tbaa !2428
  %2778 = add i64 %2768, -32
  %2779 = add i64 %2770, 12
  store i64 %2779, i64* %PC, align 8
  %2780 = inttoptr i64 %2778 to i32*
  %2781 = load i32, i32* %2780, align 4
  %2782 = add i32 %2781, 1
  %2783 = zext i32 %2782 to i64
  store i64 %2783, i64* %RAX, align 8, !tbaa !2428
  %2784 = icmp eq i32 %2781, -1
  %2785 = icmp eq i32 %2782, 0
  %2786 = or i1 %2784, %2785
  %2787 = zext i1 %2786 to i8
  store i8 %2787, i8* %50, align 1, !tbaa !2433
  %2788 = and i32 %2782, 255
  %2789 = tail call i32 @llvm.ctpop.i32(i32 %2788) #10
  %2790 = trunc i32 %2789 to i8
  %2791 = and i8 %2790, 1
  %2792 = xor i8 %2791, 1
  store i8 %2792, i8* %51, align 1, !tbaa !2447
  %2793 = xor i32 %2782, %2781
  %2794 = lshr i32 %2793, 4
  %2795 = trunc i32 %2794 to i8
  %2796 = and i8 %2795, 1
  store i8 %2796, i8* %52, align 1, !tbaa !2451
  %2797 = zext i1 %2785 to i8
  store i8 %2797, i8* %53, align 1, !tbaa !2448
  %2798 = lshr i32 %2782, 31
  %2799 = trunc i32 %2798 to i8
  store i8 %2799, i8* %54, align 1, !tbaa !2449
  %2800 = lshr i32 %2781, 31
  %2801 = xor i32 %2798, %2800
  %2802 = add nuw nsw i32 %2801, %2798
  %2803 = icmp eq i32 %2802, 2
  %2804 = zext i1 %2803 to i8
  store i8 %2804, i8* %55, align 1, !tbaa !2450
  %2805 = sext i32 %2782 to i64
  store i64 %2805, i64* %RDX, align 8, !tbaa !2428
  %2806 = shl nsw i64 %2805, 3
  %2807 = add i64 %2777, %2806
  %2808 = add i64 %2770, 23
  store i64 %2808, i64* %PC, align 8
  %2809 = inttoptr i64 %2807 to i64*
  store i64 %2773, i64* %2809, align 8
  %2810 = load i64, i64* %RBP, align 8
  %2811 = add i64 %2810, -64
  %2812 = load i64, i64* %PC, align 8
  %2813 = add i64 %2812, 5
  store i64 %2813, i64* %PC, align 8
  %2814 = inttoptr i64 %2811 to i64*
  %2815 = load i64, i64* %2814, align 8
  store i64 %2815, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2816 = add i64 %2810, -24
  %2817 = add i64 %2812, 9
  store i64 %2817, i64* %PC, align 8
  %2818 = inttoptr i64 %2816 to i64*
  %2819 = load i64, i64* %2818, align 8
  store i64 %2819, i64* %RCX, align 8, !tbaa !2428
  %2820 = add i64 %2810, -40
  %2821 = add i64 %2812, 13
  store i64 %2821, i64* %PC, align 8
  %2822 = inttoptr i64 %2820 to i32*
  %2823 = load i32, i32* %2822, align 4
  %2824 = sext i32 %2823 to i64
  store i64 %2824, i64* %RDX, align 8, !tbaa !2428
  %2825 = shl nsw i64 %2824, 3
  %2826 = add i64 %2825, %2819
  %2827 = add i64 %2812, 18
  store i64 %2827, i64* %PC, align 8
  %2828 = inttoptr i64 %2826 to i64*
  store i64 %2815, i64* %2828, align 8
  %2829 = load i64, i64* %RBP, align 8
  %2830 = add i64 %2829, -72
  %2831 = load i64, i64* %PC, align 8
  %2832 = add i64 %2831, 5
  store i64 %2832, i64* %PC, align 8
  %2833 = inttoptr i64 %2830 to i64*
  %2834 = load i64, i64* %2833, align 8
  store i64 %2834, i64* %3121, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3123, align 1, !tbaa !2452
  %2835 = add i64 %2829, -24
  %2836 = add i64 %2831, 9
  store i64 %2836, i64* %PC, align 8
  %2837 = inttoptr i64 %2835 to i64*
  %2838 = load i64, i64* %2837, align 8
  store i64 %2838, i64* %RCX, align 8, !tbaa !2428
  %2839 = add i64 %2829, -40
  %2840 = add i64 %2831, 12
  store i64 %2840, i64* %PC, align 8
  %2841 = inttoptr i64 %2839 to i32*
  %2842 = load i32, i32* %2841, align 4
  %2843 = add i32 %2842, 1
  %2844 = zext i32 %2843 to i64
  store i64 %2844, i64* %RAX, align 8, !tbaa !2428
  %2845 = icmp eq i32 %2842, -1
  %2846 = icmp eq i32 %2843, 0
  %2847 = or i1 %2845, %2846
  %2848 = zext i1 %2847 to i8
  store i8 %2848, i8* %50, align 1, !tbaa !2433
  %2849 = and i32 %2843, 255
  %2850 = tail call i32 @llvm.ctpop.i32(i32 %2849) #10
  %2851 = trunc i32 %2850 to i8
  %2852 = and i8 %2851, 1
  %2853 = xor i8 %2852, 1
  store i8 %2853, i8* %51, align 1, !tbaa !2447
  %2854 = xor i32 %2843, %2842
  %2855 = lshr i32 %2854, 4
  %2856 = trunc i32 %2855 to i8
  %2857 = and i8 %2856, 1
  store i8 %2857, i8* %52, align 1, !tbaa !2451
  %2858 = zext i1 %2846 to i8
  store i8 %2858, i8* %53, align 1, !tbaa !2448
  %2859 = lshr i32 %2843, 31
  %2860 = trunc i32 %2859 to i8
  store i8 %2860, i8* %54, align 1, !tbaa !2449
  %2861 = lshr i32 %2842, 31
  %2862 = xor i32 %2859, %2861
  %2863 = add nuw nsw i32 %2862, %2859
  %2864 = icmp eq i32 %2863, 2
  %2865 = zext i1 %2864 to i8
  store i8 %2865, i8* %55, align 1, !tbaa !2450
  %2866 = sext i32 %2843 to i64
  store i64 %2866, i64* %RDX, align 8, !tbaa !2428
  %2867 = shl nsw i64 %2866, 3
  %2868 = add i64 %2838, %2867
  %2869 = add i64 %2831, 23
  store i64 %2869, i64* %PC, align 8
  %2870 = inttoptr i64 %2868 to i64*
  store i64 %2834, i64* %2870, align 8
  %2871 = load i64, i64* %RBP, align 8
  %2872 = add i64 %2871, -28
  %2873 = load i64, i64* %PC, align 8
  %2874 = add i64 %2873, 3
  store i64 %2874, i64* %PC, align 8
  %2875 = inttoptr i64 %2872 to i32*
  %2876 = load i32, i32* %2875, align 4
  %2877 = add i32 %2876, 1
  %2878 = zext i32 %2877 to i64
  store i64 %2878, i64* %RAX, align 8, !tbaa !2428
  %2879 = icmp eq i32 %2876, -1
  %2880 = icmp eq i32 %2877, 0
  %2881 = or i1 %2879, %2880
  %2882 = zext i1 %2881 to i8
  store i8 %2882, i8* %50, align 1, !tbaa !2433
  %2883 = and i32 %2877, 255
  %2884 = tail call i32 @llvm.ctpop.i32(i32 %2883) #10
  %2885 = trunc i32 %2884 to i8
  %2886 = and i8 %2885, 1
  %2887 = xor i8 %2886, 1
  store i8 %2887, i8* %51, align 1, !tbaa !2447
  %2888 = xor i32 %2877, %2876
  %2889 = lshr i32 %2888, 4
  %2890 = trunc i32 %2889 to i8
  %2891 = and i8 %2890, 1
  store i8 %2891, i8* %52, align 1, !tbaa !2451
  %2892 = zext i1 %2880 to i8
  store i8 %2892, i8* %53, align 1, !tbaa !2448
  %2893 = lshr i32 %2877, 31
  %2894 = trunc i32 %2893 to i8
  store i8 %2894, i8* %54, align 1, !tbaa !2449
  %2895 = lshr i32 %2876, 31
  %2896 = xor i32 %2893, %2895
  %2897 = add nuw nsw i32 %2896, %2893
  %2898 = icmp eq i32 %2897, 2
  %2899 = zext i1 %2898 to i8
  store i8 %2899, i8* %55, align 1, !tbaa !2450
  %2900 = add i64 %2873, 9
  store i64 %2900, i64* %PC, align 8
  store i32 %2877, i32* %2875, align 4
  %2901 = load i64, i64* %PC, align 8
  %2902 = add i64 %2901, -407
  store i64 %2902, i64* %PC, align 8, !tbaa !2428
  br label %block_40169e

block_401296:                                     ; preds = %block_40128a
  %2903 = add i64 %3009, -28
  %2904 = add i64 %3045, 7
  store i64 %2904, i64* %PC, align 8
  %2905 = inttoptr i64 %2903 to i32*
  store i32 0, i32* %2905, align 4
  %.pre42 = load i64, i64* %PC, align 8
  br label %block_40129d

block_401215:                                     ; preds = %block_401206
  %2906 = add i64 %3120, 3
  store i64 %2906, i64* %PC, align 8
  %2907 = load i32, i32* %3091, align 4
  %2908 = zext i32 %2907 to i64
  %2909 = shl nuw i64 %2908, 32
  %2910 = ashr i64 %2909, 33
  %2911 = trunc i32 %2907 to i8
  %2912 = and i8 %2911, 1
  %2913 = trunc i64 %2910 to i32
  %2914 = and i64 %2910, 4294967295
  store i64 %2914, i64* %RAX, align 8, !tbaa !2428
  store i8 %2912, i8* %50, align 1, !tbaa !2432
  %2915 = and i32 %2913, 255
  %2916 = tail call i32 @llvm.ctpop.i32(i32 %2915) #10
  %2917 = trunc i32 %2916 to i8
  %2918 = and i8 %2917, 1
  %2919 = xor i8 %2918, 1
  store i8 %2919, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %2920 = icmp eq i32 %2913, 0
  %2921 = zext i1 %2920 to i8
  store i8 %2921, i8* %53, align 1, !tbaa !2432
  %2922 = lshr i64 %2910, 31
  %2923 = trunc i64 %2922 to i8
  %2924 = and i8 %2923, 1
  store i8 %2924, i8* %54, align 1, !tbaa !2432
  store i8 0, i8* %55, align 1, !tbaa !2432
  %2925 = trunc i64 %2910 to i32
  %2926 = add i64 %3120, 9
  store i64 %2926, i64* %PC, align 8
  store i32 %2925, i32* %3091, align 4
  %2927 = load i64, i64* %RBP, align 8
  %2928 = add i64 %2927, -28
  %2929 = load i64, i64* %PC, align 8
  %2930 = add i64 %2929, 7
  store i64 %2930, i64* %PC, align 8
  %2931 = inttoptr i64 %2928 to i32*
  store i32 0, i32* %2931, align 4
  %.pre45 = load i64, i64* %PC, align 8
  br label %block_401225

block_40168b:                                     ; preds = %block_401684, %block_40183a
  %2932 = phi i64 [ %.pre43, %block_401684 ], [ %93, %block_40183a ]
  %2933 = load i64, i64* %RBP, align 8
  %2934 = add i64 %2933, -36
  %2935 = add i64 %2932, 3
  store i64 %2935, i64* %PC, align 8
  %2936 = inttoptr i64 %2934 to i32*
  %2937 = load i32, i32* %2936, align 4
  %2938 = zext i32 %2937 to i64
  store i64 %2938, i64* %RAX, align 8, !tbaa !2428
  %2939 = add i64 %2933, -48
  %2940 = add i64 %2932, 6
  store i64 %2940, i64* %PC, align 8
  %2941 = inttoptr i64 %2939 to i32*
  %2942 = load i32, i32* %2941, align 4
  %2943 = sub i32 %2937, %2942
  %2944 = icmp ult i32 %2937, %2942
  %2945 = zext i1 %2944 to i8
  store i8 %2945, i8* %50, align 1, !tbaa !2433
  %2946 = and i32 %2943, 255
  %2947 = tail call i32 @llvm.ctpop.i32(i32 %2946) #10
  %2948 = trunc i32 %2947 to i8
  %2949 = and i8 %2948, 1
  %2950 = xor i8 %2949, 1
  store i8 %2950, i8* %51, align 1, !tbaa !2447
  %2951 = xor i32 %2942, %2937
  %2952 = xor i32 %2951, %2943
  %2953 = lshr i32 %2952, 4
  %2954 = trunc i32 %2953 to i8
  %2955 = and i8 %2954, 1
  store i8 %2955, i8* %52, align 1, !tbaa !2451
  %2956 = icmp eq i32 %2943, 0
  %2957 = zext i1 %2956 to i8
  store i8 %2957, i8* %53, align 1, !tbaa !2448
  %2958 = lshr i32 %2943, 31
  %2959 = trunc i32 %2958 to i8
  store i8 %2959, i8* %54, align 1, !tbaa !2449
  %2960 = lshr i32 %2937, 31
  %2961 = lshr i32 %2942, 31
  %2962 = xor i32 %2961, %2960
  %2963 = xor i32 %2958, %2960
  %2964 = add nuw nsw i32 %2963, %2962
  %2965 = icmp eq i32 %2964, 2
  %2966 = zext i1 %2965 to i8
  store i8 %2966, i8* %55, align 1, !tbaa !2450
  %2967 = icmp ne i8 %2959, 0
  %2968 = xor i1 %2967, %2965
  %.v48 = select i1 %2968, i64 12, i64 450
  %2969 = add i64 %2932, %.v48
  store i64 %2969, i64* %PC, align 8, !tbaa !2428
  br i1 %2968, label %block_401697, label %block_401852.loopexit76

block_40169e:                                     ; preds = %block_401697, %block_4016aa
  %2970 = phi i64 [ %.pre44, %block_401697 ], [ %2902, %block_4016aa ]
  %2971 = load i64, i64* %RBP, align 8
  %2972 = add i64 %2971, -28
  %2973 = add i64 %2970, 3
  store i64 %2973, i64* %PC, align 8
  %2974 = inttoptr i64 %2972 to i32*
  %2975 = load i32, i32* %2974, align 4
  %2976 = zext i32 %2975 to i64
  store i64 %2976, i64* %RAX, align 8, !tbaa !2428
  %2977 = add i64 %2971, -36
  %2978 = add i64 %2970, 6
  store i64 %2978, i64* %PC, align 8
  %2979 = inttoptr i64 %2977 to i32*
  %2980 = load i32, i32* %2979, align 4
  %2981 = sub i32 %2975, %2980
  %2982 = icmp ult i32 %2975, %2980
  %2983 = zext i1 %2982 to i8
  store i8 %2983, i8* %50, align 1, !tbaa !2433
  %2984 = and i32 %2981, 255
  %2985 = tail call i32 @llvm.ctpop.i32(i32 %2984) #10
  %2986 = trunc i32 %2985 to i8
  %2987 = and i8 %2986, 1
  %2988 = xor i8 %2987, 1
  store i8 %2988, i8* %51, align 1, !tbaa !2447
  %2989 = xor i32 %2980, %2975
  %2990 = xor i32 %2989, %2981
  %2991 = lshr i32 %2990, 4
  %2992 = trunc i32 %2991 to i8
  %2993 = and i8 %2992, 1
  store i8 %2993, i8* %52, align 1, !tbaa !2451
  %2994 = icmp eq i32 %2981, 0
  %2995 = zext i1 %2994 to i8
  store i8 %2995, i8* %53, align 1, !tbaa !2448
  %2996 = lshr i32 %2981, 31
  %2997 = trunc i32 %2996 to i8
  store i8 %2997, i8* %54, align 1, !tbaa !2449
  %2998 = lshr i32 %2975, 31
  %2999 = lshr i32 %2980, 31
  %3000 = xor i32 %2999, %2998
  %3001 = xor i32 %2996, %2998
  %3002 = add nuw nsw i32 %3001, %3000
  %3003 = icmp eq i32 %3002, 2
  %3004 = zext i1 %3003 to i8
  store i8 %3004, i8* %55, align 1, !tbaa !2450
  %3005 = icmp ne i8 %2997, 0
  %3006 = xor i1 %3005, %3003
  %.v46 = select i1 %3006, i64 12, i64 412
  %3007 = add i64 %2970, %.v46
  store i64 %3007, i64* %PC, align 8, !tbaa !2428
  br i1 %3006, label %block_4016aa, label %block_40183a

block_40128a:                                     ; preds = %block_401283, %block_4015ad
  %3008 = phi i64 [ %.pre41, %block_401283 ], [ %694, %block_4015ad ]
  %3009 = load i64, i64* %RBP, align 8
  %3010 = add i64 %3009, -36
  %3011 = add i64 %3008, 3
  store i64 %3011, i64* %PC, align 8
  %3012 = inttoptr i64 %3010 to i32*
  %3013 = load i32, i32* %3012, align 4
  %3014 = zext i32 %3013 to i64
  store i64 %3014, i64* %RAX, align 8, !tbaa !2428
  %3015 = add i64 %3009, -48
  %3016 = add i64 %3008, 6
  store i64 %3016, i64* %PC, align 8
  %3017 = inttoptr i64 %3015 to i32*
  %3018 = load i32, i32* %3017, align 4
  %3019 = sub i32 %3013, %3018
  %3020 = icmp ult i32 %3013, %3018
  %3021 = zext i1 %3020 to i8
  store i8 %3021, i8* %50, align 1, !tbaa !2433
  %3022 = and i32 %3019, 255
  %3023 = tail call i32 @llvm.ctpop.i32(i32 %3022) #10
  %3024 = trunc i32 %3023 to i8
  %3025 = and i8 %3024, 1
  %3026 = xor i8 %3025, 1
  store i8 %3026, i8* %51, align 1, !tbaa !2447
  %3027 = xor i32 %3018, %3013
  %3028 = xor i32 %3027, %3019
  %3029 = lshr i32 %3028, 4
  %3030 = trunc i32 %3029 to i8
  %3031 = and i8 %3030, 1
  store i8 %3031, i8* %52, align 1, !tbaa !2451
  %3032 = icmp eq i32 %3019, 0
  %3033 = zext i1 %3032 to i8
  store i8 %3033, i8* %53, align 1, !tbaa !2448
  %3034 = lshr i32 %3019, 31
  %3035 = trunc i32 %3034 to i8
  store i8 %3035, i8* %54, align 1, !tbaa !2449
  %3036 = lshr i32 %3013, 31
  %3037 = lshr i32 %3018, 31
  %3038 = xor i32 %3037, %3036
  %3039 = xor i32 %3034, %3036
  %3040 = add nuw nsw i32 %3039, %3038
  %3041 = icmp eq i32 %3040, 2
  %3042 = zext i1 %3041 to i8
  store i8 %3042, i8* %55, align 1, !tbaa !2450
  %3043 = icmp ne i8 %3035, 0
  %3044 = xor i1 %3043, %3041
  %.v49 = select i1 %3044, i64 12, i64 1013
  %3045 = add i64 %3008, %.v49
  store i64 %3045, i64* %PC, align 8, !tbaa !2428
  br i1 %3044, label %block_401296, label %block_401852.loopexit

block_40125d:                                     ; preds = %block_401225
  %3046 = add i64 %2135, 3
  store i64 %3046, i64* %PC, align 8
  %3047 = load i32, i32* %2107, align 4
  %3048 = shl i32 %3047, 1
  %3049 = icmp slt i32 %3047, 0
  %3050 = icmp slt i32 %3048, 0
  %3051 = xor i1 %3049, %3050
  %3052 = zext i32 %3048 to i64
  store i64 %3052, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %3047, 31
  %3053 = trunc i32 %.lobit to i8
  store i8 %3053, i8* %50, align 1, !tbaa !2432
  %3054 = and i32 %3048, 254
  %3055 = tail call i32 @llvm.ctpop.i32(i32 %3054) #10
  %3056 = trunc i32 %3055 to i8
  %3057 = and i8 %3056, 1
  %3058 = xor i8 %3057, 1
  store i8 %3058, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %3059 = icmp eq i32 %3048, 0
  %3060 = zext i1 %3059 to i8
  store i8 %3060, i8* %53, align 1, !tbaa !2432
  %3061 = lshr i32 %3047, 30
  %3062 = trunc i32 %3061 to i8
  %3063 = and i8 %3062, 1
  store i8 %3063, i8* %54, align 1, !tbaa !2432
  %3064 = zext i1 %3051 to i8
  store i8 %3064, i8* %55, align 1, !tbaa !2432
  %3065 = add i64 %2135, 9
  store i64 %3065, i64* %PC, align 8
  store i32 %3048, i32* %2107, align 4
  %3066 = load i64, i64* %PC, align 8
  %3067 = add i64 %3066, -96
  store i64 %3067, i64* %PC, align 8, !tbaa !2428
  br label %block_401206

block_401206:                                     ; preds = %block_40125d, %block_4011e0
  %3068 = phi i64 [ %3067, %block_40125d ], [ %.pre, %block_4011e0 ]
  %3069 = load i64, i64* %RBP, align 8
  %3070 = add i64 %3069, -48
  %3071 = add i64 %3068, 3
  store i64 %3071, i64* %PC, align 8
  %3072 = inttoptr i64 %3070 to i32*
  %3073 = load i32, i32* %3072, align 4
  %3074 = shl i32 %3073, 3
  %3075 = zext i32 %3074 to i64
  store i64 %3075, i64* %RAX, align 8, !tbaa !2428
  %3076 = lshr i32 %3073, 29
  %3077 = trunc i32 %3076 to i8
  %3078 = and i8 %3077, 1
  store i8 %3078, i8* %50, align 1, !tbaa !2432
  %3079 = and i32 %3074, 248
  %3080 = tail call i32 @llvm.ctpop.i32(i32 %3079) #10
  %3081 = trunc i32 %3080 to i8
  %3082 = and i8 %3081, 1
  %3083 = xor i8 %3082, 1
  store i8 %3083, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %3084 = icmp eq i32 %3074, 0
  %3085 = zext i1 %3084 to i8
  store i8 %3085, i8* %53, align 1, !tbaa !2432
  %3086 = lshr i32 %3073, 28
  %3087 = trunc i32 %3086 to i8
  %3088 = and i8 %3087, 1
  store i8 %3088, i8* %54, align 1, !tbaa !2432
  store i8 0, i8* %55, align 1, !tbaa !2432
  %3089 = add i64 %3069, -44
  %3090 = add i64 %3068, 9
  store i64 %3090, i64* %PC, align 8
  %3091 = inttoptr i64 %3089 to i32*
  %3092 = load i32, i32* %3091, align 4
  %3093 = sub i32 %3074, %3092
  %3094 = icmp ult i32 %3074, %3092
  %3095 = zext i1 %3094 to i8
  store i8 %3095, i8* %50, align 1, !tbaa !2433
  %3096 = and i32 %3093, 255
  %3097 = tail call i32 @llvm.ctpop.i32(i32 %3096) #10
  %3098 = trunc i32 %3097 to i8
  %3099 = and i8 %3098, 1
  %3100 = xor i8 %3099, 1
  store i8 %3100, i8* %51, align 1, !tbaa !2447
  %3101 = xor i32 %3092, %3074
  %3102 = xor i32 %3101, %3093
  %3103 = lshr i32 %3102, 4
  %3104 = trunc i32 %3103 to i8
  %3105 = and i8 %3104, 1
  store i8 %3105, i8* %52, align 1, !tbaa !2451
  %3106 = icmp eq i32 %3093, 0
  %3107 = zext i1 %3106 to i8
  store i8 %3107, i8* %53, align 1, !tbaa !2448
  %3108 = lshr i32 %3093, 31
  %3109 = trunc i32 %3108 to i8
  store i8 %3109, i8* %54, align 1, !tbaa !2449
  %3110 = lshr i32 %3073, 28
  %3111 = and i32 %3110, 1
  %3112 = lshr i32 %3092, 31
  %3113 = xor i32 %3112, %3111
  %3114 = xor i32 %3108, %3111
  %3115 = add nuw nsw i32 %3114, %3113
  %3116 = icmp eq i32 %3115, 2
  %3117 = zext i1 %3116 to i8
  store i8 %3117, i8* %55, align 1, !tbaa !2450
  %3118 = icmp ne i8 %3109, 0
  %3119 = xor i1 %3118, %3116
  %.v47 = select i1 %3119, i64 15, i64 101
  %3120 = add i64 %3068, %.v47
  store i64 %3120, i64* %PC, align 8, !tbaa !2428
  br i1 %3119, label %block_401215, label %block_40126b

block_401684:                                     ; preds = %block_40126b
  store i32 1, i32* %170, align 4
  %3121 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %94, i64 0, i32 0, i32 0, i32 0, i64 0
  %3122 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %3123 = bitcast i64* %3122 to double*
  %.pre43 = load i64, i64* %PC, align 8
  br label %block_40168b

block_401697:                                     ; preds = %block_40168b
  %3124 = add i64 %2933, -28
  %3125 = add i64 %2969, 7
  store i64 %3125, i64* %PC, align 8
  %3126 = inttoptr i64 %3124 to i32*
  store i32 0, i32* %3126, align 4
  %.pre44 = load i64, i64* %PC, align 8
  br label %block_40169e

block_401283:                                     ; preds = %block_40126b
  store i32 0, i32* %170, align 4
  %3127 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %94, i64 0, i32 0, i32 0, i32 0, i64 0
  %3128 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %3129 = bitcast i64* %3128 to double*
  %.pre41 = load i64, i64* %PC, align 8
  br label %block_40128a
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400e60_makewt(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #7 {
block_400e60:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %1, 1
  store i64 %7, i64* %PC, align 8
  %8 = load i64, i64* %RSP, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %6, i64* %10, align 8
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -72
  store i64 %12, i64* %RSP, align 8, !tbaa !2428
  %13 = icmp ult i64 %9, 64
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1, !tbaa !2433
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #10
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1, !tbaa !2447
  %23 = xor i64 %9, %12
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2451
  %28 = icmp eq i64 %12, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %12, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %9, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %8, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %11, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -4
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 4
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  %61 = load i32, i32* %60, align 4
  %62 = add i32 %61, -2
  %63 = icmp ult i32 %61, 2
  %64 = zext i1 %63 to i8
  store i8 %64, i8* %15, align 1, !tbaa !2433
  %65 = and i32 %62, 255
  %66 = tail call i32 @llvm.ctpop.i32(i32 %65) #10
  %67 = trunc i32 %66 to i8
  %68 = and i8 %67, 1
  %69 = xor i8 %68, 1
  store i8 %69, i8* %22, align 1, !tbaa !2447
  %70 = xor i32 %62, %61
  %71 = lshr i32 %70, 4
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  store i8 %73, i8* %27, align 1, !tbaa !2451
  %74 = icmp eq i32 %62, 0
  %75 = zext i1 %74 to i8
  store i8 %75, i8* %30, align 1, !tbaa !2448
  %76 = lshr i32 %62, 31
  %77 = trunc i32 %76 to i8
  store i8 %77, i8* %33, align 1, !tbaa !2449
  %78 = lshr i32 %61, 31
  %79 = xor i32 %76, %78
  %80 = add nuw nsw i32 %79, %78
  %81 = icmp eq i32 %80, 2
  %82 = zext i1 %81 to i8
  store i8 %82, i8* %39, align 1, !tbaa !2450
  %83 = icmp ne i8 %77, 0
  %84 = xor i1 %83, %81
  %85 = or i1 %74, %84
  %.v = select i1 %85, i64 339, i64 10
  %86 = add i64 %58, %.v
  store i64 %86, i64* %PC, align 8, !tbaa !2428
  br i1 %85, label %block_400fc6, label %block_400e7d

block_400f19:                                     ; preds = %block_400f0d
  %87 = add i64 %542, -40
  %88 = add i64 %578, 5
  store i64 %88, i64* %PC, align 8
  %89 = inttoptr i64 %87 to i64*
  %90 = load i64, i64* %89, align 8
  store i64 %90, i64* %325, align 1, !tbaa !2452
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %91 = add i64 %578, 10
  store i64 %91, i64* %PC, align 8
  %92 = load i32, i32* %545, align 4
  %93 = sitofp i32 %92 to double
  store double %93, double* %416, align 1, !tbaa !2452
  %94 = bitcast i64 %90 to double
  %95 = fmul double %93, %94
  store double %95, double* %324, align 1, !tbaa !2452
  store i64 0, i64* %326, align 1, !tbaa !2452
  %96 = add i64 %578, -2073
  %97 = add i64 %578, 19
  %98 = load i64, i64* %RSP, align 8, !tbaa !2428
  %99 = add i64 %98, -8
  %100 = inttoptr i64 %99 to i64*
  store i64 %97, i64* %100, align 8
  store i64 %99, i64* %RSP, align 8, !tbaa !2428
  store i64 %96, i64* %PC, align 8, !tbaa !2428
  %101 = load double, double* %324, align 8, !alias.scope !2462, !noalias !2465
  %102 = load i64, i64* %100, align 8
  store i64 %98, i64* %RSP, align 8, !alias.scope !2462, !noalias !2465
  %103 = tail call double @cos(double %101)
  call void @llvm.memset.p0i8.i64(i8* %615, i8 0, i64 24, i32 8, i1 false)
  store double %103, double* %324, align 8, !alias.scope !2462, !noalias !2465
  %104 = load i64, i64* %RBP, align 8
  %105 = add i64 %104, -48
  %106 = add i64 %102, 5
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %105 to double*
  store double %103, double* %107, align 8
  %108 = load i64, i64* %RBP, align 8
  %109 = add i64 %108, -40
  %110 = load i64, i64* %PC, align 8
  %111 = add i64 %110, 5
  store i64 %111, i64* %PC, align 8
  %112 = inttoptr i64 %109 to i64*
  %113 = load i64, i64* %112, align 8
  store i64 %113, i64* %325, align 1, !tbaa !2452
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %114 = add i64 %108, -28
  %115 = add i64 %110, 10
  store i64 %115, i64* %PC, align 8
  %116 = inttoptr i64 %114 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = sitofp i32 %117 to double
  store double %118, double* %416, align 1, !tbaa !2452
  %119 = bitcast i64 %113 to double
  %120 = fmul double %118, %119
  store double %120, double* %324, align 1, !tbaa !2452
  store i64 0, i64* %326, align 1, !tbaa !2452
  %121 = add i64 %110, -2049
  %122 = add i64 %110, 19
  %123 = load i64, i64* %RSP, align 8, !tbaa !2428
  %124 = add i64 %123, -8
  %125 = inttoptr i64 %124 to i64*
  store i64 %122, i64* %125, align 8
  store i64 %124, i64* %RSP, align 8, !tbaa !2428
  store i64 %121, i64* %PC, align 8, !tbaa !2428
  %126 = load double, double* %324, align 8, !alias.scope !2467, !noalias !2470
  %127 = load i64, i64* %125, align 8
  store i64 %123, i64* %RSP, align 8, !alias.scope !2467, !noalias !2470
  %128 = tail call double @sin(double %126)
  call void @llvm.memset.p0i8.i64(i8* %617, i8 0, i64 24, i32 8, i1 false)
  store double %128, double* %324, align 8, !alias.scope !2467, !noalias !2470
  %129 = load i64, i64* %RBP, align 8
  %130 = add i64 %129, -56
  %131 = add i64 %127, 5
  store i64 %131, i64* %PC, align 8
  %132 = inttoptr i64 %130 to double*
  store double %128, double* %132, align 8
  %133 = load i64, i64* %RBP, align 8
  %134 = add i64 %133, -48
  %135 = load i64, i64* %PC, align 8
  %136 = add i64 %135, 5
  store i64 %136, i64* %PC, align 8
  %137 = inttoptr i64 %134 to i64*
  %138 = load i64, i64* %137, align 8
  store i64 %138, i64* %325, align 1, !tbaa !2452
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %139 = add i64 %133, -24
  %140 = add i64 %135, 9
  store i64 %140, i64* %PC, align 8
  %141 = inttoptr i64 %139 to i64*
  %142 = load i64, i64* %141, align 8
  store i64 %142, i64* %RAX, align 8, !tbaa !2428
  %143 = add i64 %133, -28
  %144 = add i64 %135, 13
  store i64 %144, i64* %PC, align 8
  %145 = inttoptr i64 %143 to i32*
  %146 = load i32, i32* %145, align 4
  %147 = sext i32 %146 to i64
  store i64 %147, i64* %RCX, align 8, !tbaa !2428
  %148 = shl nsw i64 %147, 3
  %149 = add i64 %148, %142
  %150 = add i64 %135, 18
  store i64 %150, i64* %PC, align 8
  %151 = inttoptr i64 %149 to i64*
  store i64 %138, i64* %151, align 8
  %152 = load i64, i64* %RBP, align 8
  %153 = add i64 %152, -56
  %154 = load i64, i64* %PC, align 8
  %155 = add i64 %154, 5
  store i64 %155, i64* %PC, align 8
  %156 = inttoptr i64 %153 to i64*
  %157 = load i64, i64* %156, align 8
  store i64 %157, i64* %325, align 1, !tbaa !2452
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %158 = add i64 %152, -24
  %159 = add i64 %154, 9
  store i64 %159, i64* %PC, align 8
  %160 = inttoptr i64 %158 to i64*
  %161 = load i64, i64* %160, align 8
  store i64 %161, i64* %RAX, align 8, !tbaa !2428
  %162 = add i64 %152, -28
  %163 = add i64 %154, 12
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %162 to i32*
  %165 = load i32, i32* %164, align 4
  %166 = add i32 %165, 1
  %167 = zext i32 %166 to i64
  store i64 %167, i64* %RDX, align 8, !tbaa !2428
  %168 = icmp eq i32 %165, -1
  %169 = icmp eq i32 %166, 0
  %170 = or i1 %168, %169
  %171 = zext i1 %170 to i8
  store i8 %171, i8* %15, align 1, !tbaa !2433
  %172 = and i32 %166, 255
  %173 = tail call i32 @llvm.ctpop.i32(i32 %172) #10
  %174 = trunc i32 %173 to i8
  %175 = and i8 %174, 1
  %176 = xor i8 %175, 1
  store i8 %176, i8* %22, align 1, !tbaa !2447
  %177 = xor i32 %166, %165
  %178 = lshr i32 %177, 4
  %179 = trunc i32 %178 to i8
  %180 = and i8 %179, 1
  store i8 %180, i8* %27, align 1, !tbaa !2451
  %181 = zext i1 %169 to i8
  store i8 %181, i8* %30, align 1, !tbaa !2448
  %182 = lshr i32 %166, 31
  %183 = trunc i32 %182 to i8
  store i8 %183, i8* %33, align 1, !tbaa !2449
  %184 = lshr i32 %165, 31
  %185 = xor i32 %182, %184
  %186 = add nuw nsw i32 %185, %182
  %187 = icmp eq i32 %186, 2
  %188 = zext i1 %187 to i8
  store i8 %188, i8* %39, align 1, !tbaa !2450
  %189 = sext i32 %166 to i64
  store i64 %189, i64* %RCX, align 8, !tbaa !2428
  %190 = shl nsw i64 %189, 3
  %191 = add i64 %161, %190
  %192 = add i64 %154, 23
  store i64 %192, i64* %PC, align 8
  %193 = inttoptr i64 %191 to i64*
  store i64 %157, i64* %193, align 8
  %194 = load i64, i64* %RBP, align 8
  %195 = add i64 %194, -56
  %196 = load i64, i64* %PC, align 8
  %197 = add i64 %196, 5
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %195 to i64*
  %199 = load i64, i64* %198, align 8
  store i64 %199, i64* %325, align 1, !tbaa !2452
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %200 = add i64 %194, -24
  %201 = add i64 %196, 9
  store i64 %201, i64* %PC, align 8
  %202 = inttoptr i64 %200 to i64*
  %203 = load i64, i64* %202, align 8
  store i64 %203, i64* %RAX, align 8, !tbaa !2428
  %204 = add i64 %194, -4
  %205 = add i64 %196, 12
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %204 to i32*
  %207 = load i32, i32* %206, align 4
  %208 = zext i32 %207 to i64
  store i64 %208, i64* %RDX, align 8, !tbaa !2428
  %209 = add i64 %194, -28
  %210 = add i64 %196, 15
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %209 to i32*
  %212 = load i32, i32* %211, align 4
  %213 = sub i32 %207, %212
  %214 = zext i32 %213 to i64
  store i64 %214, i64* %RDX, align 8, !tbaa !2428
  %215 = icmp ult i32 %207, %212
  %216 = zext i1 %215 to i8
  store i8 %216, i8* %15, align 1, !tbaa !2433
  %217 = and i32 %213, 255
  %218 = tail call i32 @llvm.ctpop.i32(i32 %217) #10
  %219 = trunc i32 %218 to i8
  %220 = and i8 %219, 1
  %221 = xor i8 %220, 1
  store i8 %221, i8* %22, align 1, !tbaa !2447
  %222 = xor i32 %212, %207
  %223 = xor i32 %222, %213
  %224 = lshr i32 %223, 4
  %225 = trunc i32 %224 to i8
  %226 = and i8 %225, 1
  store i8 %226, i8* %27, align 1, !tbaa !2451
  %227 = icmp eq i32 %213, 0
  %228 = zext i1 %227 to i8
  store i8 %228, i8* %30, align 1, !tbaa !2448
  %229 = lshr i32 %213, 31
  %230 = trunc i32 %229 to i8
  store i8 %230, i8* %33, align 1, !tbaa !2449
  %231 = lshr i32 %207, 31
  %232 = lshr i32 %212, 31
  %233 = xor i32 %232, %231
  %234 = xor i32 %229, %231
  %235 = add nuw nsw i32 %234, %233
  %236 = icmp eq i32 %235, 2
  %237 = zext i1 %236 to i8
  store i8 %237, i8* %39, align 1, !tbaa !2450
  %238 = sext i32 %213 to i64
  store i64 %238, i64* %RCX, align 8, !tbaa !2428
  %239 = shl nsw i64 %238, 3
  %240 = add i64 %203, %239
  %241 = add i64 %196, 23
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %240 to i64*
  store i64 %199, i64* %242, align 8
  %243 = load i64, i64* %RBP, align 8
  %244 = add i64 %243, -48
  %245 = load i64, i64* %PC, align 8
  %246 = add i64 %245, 5
  store i64 %246, i64* %PC, align 8
  %247 = inttoptr i64 %244 to i64*
  %248 = load i64, i64* %247, align 8
  store i64 %248, i64* %325, align 1, !tbaa !2452
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %249 = add i64 %243, -24
  %250 = add i64 %245, 9
  store i64 %250, i64* %PC, align 8
  %251 = inttoptr i64 %249 to i64*
  %252 = load i64, i64* %251, align 8
  store i64 %252, i64* %RAX, align 8, !tbaa !2428
  %253 = add i64 %243, -4
  %254 = add i64 %245, 12
  store i64 %254, i64* %PC, align 8
  %255 = inttoptr i64 %253 to i32*
  %256 = load i32, i32* %255, align 4
  %257 = zext i32 %256 to i64
  store i64 %257, i64* %RDX, align 8, !tbaa !2428
  %258 = add i64 %243, -28
  %259 = add i64 %245, 15
  store i64 %259, i64* %PC, align 8
  %260 = inttoptr i64 %258 to i32*
  %261 = load i32, i32* %260, align 4
  %262 = sub i32 %256, %261
  %263 = lshr i32 %262, 31
  %264 = add i32 %262, 1
  %265 = zext i32 %264 to i64
  store i64 %265, i64* %RDX, align 8, !tbaa !2428
  %266 = icmp eq i32 %262, -1
  %267 = icmp eq i32 %264, 0
  %268 = or i1 %266, %267
  %269 = zext i1 %268 to i8
  store i8 %269, i8* %15, align 1, !tbaa !2433
  %270 = and i32 %264, 255
  %271 = tail call i32 @llvm.ctpop.i32(i32 %270) #10
  %272 = trunc i32 %271 to i8
  %273 = and i8 %272, 1
  %274 = xor i8 %273, 1
  store i8 %274, i8* %22, align 1, !tbaa !2447
  %275 = xor i32 %264, %262
  %276 = lshr i32 %275, 4
  %277 = trunc i32 %276 to i8
  %278 = and i8 %277, 1
  store i8 %278, i8* %27, align 1, !tbaa !2451
  %279 = zext i1 %267 to i8
  store i8 %279, i8* %30, align 1, !tbaa !2448
  %280 = lshr i32 %264, 31
  %281 = trunc i32 %280 to i8
  store i8 %281, i8* %33, align 1, !tbaa !2449
  %282 = xor i32 %280, %263
  %283 = add nuw nsw i32 %282, %280
  %284 = icmp eq i32 %283, 2
  %285 = zext i1 %284 to i8
  store i8 %285, i8* %39, align 1, !tbaa !2450
  %286 = sext i32 %264 to i64
  store i64 %286, i64* %RCX, align 8, !tbaa !2428
  %287 = shl nsw i64 %286, 3
  %288 = add i64 %252, %287
  %289 = add i64 %245, 26
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %288 to i64*
  store i64 %248, i64* %290, align 8
  %291 = load i64, i64* %RBP, align 8
  %292 = add i64 %291, -28
  %293 = load i64, i64* %PC, align 8
  %294 = add i64 %293, 3
  store i64 %294, i64* %PC, align 8
  %295 = inttoptr i64 %292 to i32*
  %296 = load i32, i32* %295, align 4
  %297 = add i32 %296, 2
  %298 = zext i32 %297 to i64
  store i64 %298, i64* %RAX, align 8, !tbaa !2428
  %299 = icmp ugt i32 %296, -3
  %300 = zext i1 %299 to i8
  store i8 %300, i8* %15, align 1, !tbaa !2433
  %301 = and i32 %297, 255
  %302 = tail call i32 @llvm.ctpop.i32(i32 %301) #10
  %303 = trunc i32 %302 to i8
  %304 = and i8 %303, 1
  %305 = xor i8 %304, 1
  store i8 %305, i8* %22, align 1, !tbaa !2447
  %306 = xor i32 %297, %296
  %307 = lshr i32 %306, 4
  %308 = trunc i32 %307 to i8
  %309 = and i8 %308, 1
  store i8 %309, i8* %27, align 1, !tbaa !2451
  %310 = icmp eq i32 %297, 0
  %311 = zext i1 %310 to i8
  store i8 %311, i8* %30, align 1, !tbaa !2448
  %312 = lshr i32 %297, 31
  %313 = trunc i32 %312 to i8
  store i8 %313, i8* %33, align 1, !tbaa !2449
  %314 = lshr i32 %296, 31
  %315 = xor i32 %312, %314
  %316 = add nuw nsw i32 %315, %312
  %317 = icmp eq i32 %316, 2
  %318 = zext i1 %317 to i8
  store i8 %318, i8* %39, align 1, !tbaa !2450
  %319 = add i64 %293, 9
  store i64 %319, i64* %PC, align 8
  store i32 %297, i32* %295, align 4
  %320 = load i64, i64* %PC, align 8
  %321 = add i64 %320, -159
  store i64 %321, i64* %PC, align 8, !tbaa !2428
  br label %block_400f0d

block_400e7d:                                     ; preds = %block_400e60
  %322 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %323 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 64) to i64*), align 16
  %324 = bitcast [32 x %union.VectorReg]* %4 to double*
  %325 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %323, i64* %325, align 1, !tbaa !2452
  %326 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %327 = bitcast i64* %326 to double*
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %328 = add i64 %86, 11
  store i64 %328, i64* %PC, align 8
  %329 = load i32, i32* %60, align 4
  %330 = zext i32 %329 to i64
  %331 = shl nuw i64 %330, 32
  %332 = ashr i64 %331, 33
  %333 = trunc i32 %329 to i8
  %334 = and i8 %333, 1
  %335 = trunc i64 %332 to i32
  %336 = and i64 %332, 4294967295
  store i64 %336, i64* %RAX, align 8, !tbaa !2428
  store i8 %334, i8* %15, align 1, !tbaa !2432
  %337 = and i32 %335, 255
  %338 = tail call i32 @llvm.ctpop.i32(i32 %337) #10
  %339 = trunc i32 %338 to i8
  %340 = and i8 %339, 1
  %341 = xor i8 %340, 1
  store i8 %341, i8* %22, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %342 = icmp eq i32 %335, 0
  %343 = zext i1 %342 to i8
  store i8 %343, i8* %30, align 1, !tbaa !2432
  %344 = lshr i64 %332, 31
  %345 = trunc i64 %344 to i8
  %346 = and i8 %345, 1
  store i8 %346, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %347 = add i64 %56, -32
  %348 = trunc i64 %332 to i32
  %349 = add i64 %86, 17
  store i64 %349, i64* %PC, align 8
  %350 = inttoptr i64 %347 to i32*
  store i32 %348, i32* %350, align 4
  %351 = load i64, i64* %PC, align 8
  %352 = add i64 %351, -1998
  %353 = add i64 %351, 5
  %354 = load i64, i64* %RSP, align 8, !tbaa !2428
  %355 = add i64 %354, -8
  %356 = inttoptr i64 %355 to i64*
  store i64 %353, i64* %356, align 8
  store i64 %355, i64* %RSP, align 8, !tbaa !2428
  store i64 %352, i64* %PC, align 8, !tbaa !2428
  %357 = load double, double* %324, align 8, !alias.scope !2472, !noalias !2475
  %358 = load i64, i64* %356, align 8
  store i64 %354, i64* %RSP, align 8, !alias.scope !2472, !noalias !2475
  %359 = tail call double @atan(double %357)
  %360 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %361 = bitcast i64* %360 to i8*
  call void @llvm.memset.p0i8.i64(i8* %361, i8 0, i64 24, i32 8, i1 false)
  store double %359, double* %324, align 8, !alias.scope !2472, !noalias !2475
  %362 = bitcast %union.VectorReg* %5 to i8*
  %363 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %364 = bitcast %union.VectorReg* %5 to i32*
  store i32 0, i32* %364, align 1, !tbaa !2461
  %365 = getelementptr inbounds i8, i8* %362, i64 4
  %366 = bitcast i8* %365 to i32*
  store i32 0, i32* %366, align 1, !tbaa !2461
  %367 = bitcast i64* %363 to i32*
  store i32 0, i32* %367, align 1, !tbaa !2461
  %368 = getelementptr inbounds i8, i8* %362, i64 12
  %369 = bitcast i8* %368 to i32*
  store i32 0, i32* %369, align 1, !tbaa !2461
  %370 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 64) to i64*), align 16
  %371 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 0
  store i64 %370, i64* %371, align 1, !tbaa !2452
  %372 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %373 = bitcast i64* %372 to double*
  store double 0.000000e+00, double* %373, align 1, !tbaa !2452
  %374 = load i64, i64* %RBP, align 8
  %375 = add i64 %374, -32
  %376 = add i64 %358, 16
  store i64 %376, i64* %PC, align 8
  %377 = inttoptr i64 %375 to i32*
  %378 = load i32, i32* %377, align 4
  %379 = sitofp i32 %378 to double
  %380 = bitcast %union.VectorReg* %322 to double*
  store double %379, double* %380, align 1, !tbaa !2452
  %381 = fdiv double %359, %379
  store double %381, double* %324, align 1, !tbaa !2452
  store i64 0, i64* %326, align 1, !tbaa !2452
  %382 = add i64 %374, -40
  %383 = add i64 %358, 25
  store i64 %383, i64* %PC, align 8
  %384 = inttoptr i64 %382 to double*
  store double %381, double* %384, align 8
  %385 = load i64, i64* %RBP, align 8
  %386 = add i64 %385, -24
  %387 = load i64, i64* %PC, align 8
  %388 = add i64 %387, 4
  store i64 %388, i64* %PC, align 8
  %389 = inttoptr i64 %386 to i64*
  %390 = load i64, i64* %389, align 8
  store i64 %390, i64* %RCX, align 8, !tbaa !2428
  %391 = add i64 %387, 8
  store i64 %391, i64* %PC, align 8
  %392 = load i64, i64* %371, align 1
  %393 = inttoptr i64 %390 to i64*
  store i64 %392, i64* %393, align 8
  %394 = load i64, i64* %RBP, align 8
  %395 = add i64 %394, -24
  %396 = load i64, i64* %PC, align 8
  %397 = add i64 %396, 4
  store i64 %397, i64* %PC, align 8
  %398 = inttoptr i64 %395 to i64*
  %399 = load i64, i64* %398, align 8
  store i64 %399, i64* %RCX, align 8, !tbaa !2428
  %400 = add i64 %399, 8
  %401 = add i64 %396, 9
  store i64 %401, i64* %PC, align 8
  %402 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  %403 = load i64, i64* %402, align 1
  %404 = inttoptr i64 %400 to i64*
  store i64 %403, i64* %404, align 8
  %405 = load i64, i64* %RBP, align 8
  %406 = add i64 %405, -40
  %407 = load i64, i64* %PC, align 8
  %408 = add i64 %407, 5
  store i64 %408, i64* %PC, align 8
  %409 = inttoptr i64 %406 to i64*
  %410 = load i64, i64* %409, align 8
  store i64 %410, i64* %325, align 1, !tbaa !2452
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %411 = add i64 %405, -32
  %412 = add i64 %407, 10
  store i64 %412, i64* %PC, align 8
  %413 = inttoptr i64 %411 to i32*
  %414 = load i32, i32* %413, align 4
  %415 = sitofp i32 %414 to double
  %416 = bitcast %union.VectorReg* %5 to double*
  store double %415, double* %416, align 1, !tbaa !2452
  %417 = bitcast i64 %410 to double
  %418 = fmul double %415, %417
  store double %418, double* %324, align 1, !tbaa !2452
  store i64 0, i64* %326, align 1, !tbaa !2452
  %419 = add i64 %407, -1981
  %420 = add i64 %407, 19
  %421 = load i64, i64* %RSP, align 8, !tbaa !2428
  %422 = add i64 %421, -8
  %423 = inttoptr i64 %422 to i64*
  store i64 %420, i64* %423, align 8
  store i64 %422, i64* %RSP, align 8, !tbaa !2428
  store i64 %419, i64* %PC, align 8, !tbaa !2428
  %424 = load double, double* %324, align 8, !alias.scope !2477, !noalias !2480
  %425 = load i64, i64* %423, align 8
  store i64 %421, i64* %RSP, align 8, !alias.scope !2477, !noalias !2480
  %426 = tail call double @cos(double %424)
  %427 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %428 = bitcast i64* %427 to i8*
  call void @llvm.memset.p0i8.i64(i8* %428, i8 0, i64 24, i32 8, i1 false)
  store double %426, double* %324, align 8, !alias.scope !2477, !noalias !2480
  %429 = load i64, i64* %RBP, align 8
  %430 = add i64 %429, -24
  %431 = add i64 %425, 4
  store i64 %431, i64* %PC, align 8
  %432 = inttoptr i64 %430 to i64*
  %433 = load i64, i64* %432, align 8
  store i64 %433, i64* %RCX, align 8, !tbaa !2428
  %434 = add i64 %429, -32
  %435 = add i64 %425, 8
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %434 to i32*
  %437 = load i32, i32* %436, align 4
  %438 = sext i32 %437 to i64
  store i64 %438, i64* %RDX, align 8, !tbaa !2428
  %439 = shl nsw i64 %438, 3
  %440 = add i64 %439, %433
  %441 = add i64 %425, 13
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to double*
  store double %426, double* %442, align 8
  %443 = load i64, i64* %RBP, align 8
  %444 = add i64 %443, -24
  %445 = load i64, i64* %PC, align 8
  %446 = add i64 %445, 4
  store i64 %446, i64* %PC, align 8
  %447 = inttoptr i64 %444 to i64*
  %448 = load i64, i64* %447, align 8
  store i64 %448, i64* %RCX, align 8, !tbaa !2428
  %449 = add i64 %443, -32
  %450 = add i64 %445, 8
  store i64 %450, i64* %PC, align 8
  %451 = inttoptr i64 %449 to i32*
  %452 = load i32, i32* %451, align 4
  %453 = sext i32 %452 to i64
  store i64 %453, i64* %RDX, align 8, !tbaa !2428
  %454 = shl nsw i64 %453, 3
  %455 = add i64 %454, %448
  %456 = add i64 %445, 13
  store i64 %456, i64* %PC, align 8
  %457 = inttoptr i64 %455 to i64*
  %458 = load i64, i64* %457, align 8
  store i64 %458, i64* %325, align 1, !tbaa !2452
  store double 0.000000e+00, double* %327, align 1, !tbaa !2452
  %459 = add i64 %445, 17
  store i64 %459, i64* %PC, align 8
  %460 = load i64, i64* %447, align 8
  store i64 %460, i64* %RCX, align 8, !tbaa !2428
  %461 = add i64 %445, 20
  store i64 %461, i64* %PC, align 8
  %462 = load i32, i32* %451, align 4
  %463 = add i32 %462, 1
  %464 = zext i32 %463 to i64
  store i64 %464, i64* %RAX, align 8, !tbaa !2428
  %465 = icmp eq i32 %462, -1
  %466 = icmp eq i32 %463, 0
  %467 = or i1 %465, %466
  %468 = zext i1 %467 to i8
  store i8 %468, i8* %15, align 1, !tbaa !2433
  %469 = and i32 %463, 255
  %470 = tail call i32 @llvm.ctpop.i32(i32 %469) #10
  %471 = trunc i32 %470 to i8
  %472 = and i8 %471, 1
  %473 = xor i8 %472, 1
  store i8 %473, i8* %22, align 1, !tbaa !2447
  %474 = xor i32 %463, %462
  %475 = lshr i32 %474, 4
  %476 = trunc i32 %475 to i8
  %477 = and i8 %476, 1
  store i8 %477, i8* %27, align 1, !tbaa !2451
  %478 = zext i1 %466 to i8
  store i8 %478, i8* %30, align 1, !tbaa !2448
  %479 = lshr i32 %463, 31
  %480 = trunc i32 %479 to i8
  store i8 %480, i8* %33, align 1, !tbaa !2449
  %481 = lshr i32 %462, 31
  %482 = xor i32 %479, %481
  %483 = add nuw nsw i32 %482, %479
  %484 = icmp eq i32 %483, 2
  %485 = zext i1 %484 to i8
  store i8 %485, i8* %39, align 1, !tbaa !2450
  %486 = sext i32 %463 to i64
  store i64 %486, i64* %RDX, align 8, !tbaa !2428
  %487 = shl nsw i64 %486, 3
  %488 = add i64 %460, %487
  %489 = add i64 %445, 31
  store i64 %489, i64* %PC, align 8
  %490 = inttoptr i64 %488 to i64*
  store i64 %458, i64* %490, align 8
  %491 = load i64, i64* %RBP, align 8
  %492 = add i64 %491, -32
  %493 = load i64, i64* %PC, align 8
  %494 = add i64 %493, 4
  store i64 %494, i64* %PC, align 8
  %495 = inttoptr i64 %492 to i32*
  %496 = load i32, i32* %495, align 4
  %497 = add i32 %496, -2
  %498 = icmp ult i32 %496, 2
  %499 = zext i1 %498 to i8
  store i8 %499, i8* %15, align 1, !tbaa !2433
  %500 = and i32 %497, 255
  %501 = tail call i32 @llvm.ctpop.i32(i32 %500) #10
  %502 = trunc i32 %501 to i8
  %503 = and i8 %502, 1
  %504 = xor i8 %503, 1
  store i8 %504, i8* %22, align 1, !tbaa !2447
  %505 = xor i32 %497, %496
  %506 = lshr i32 %505, 4
  %507 = trunc i32 %506 to i8
  %508 = and i8 %507, 1
  store i8 %508, i8* %27, align 1, !tbaa !2451
  %509 = icmp eq i32 %497, 0
  %510 = zext i1 %509 to i8
  store i8 %510, i8* %30, align 1, !tbaa !2448
  %511 = lshr i32 %497, 31
  %512 = trunc i32 %511 to i8
  store i8 %512, i8* %33, align 1, !tbaa !2449
  %513 = lshr i32 %496, 31
  %514 = xor i32 %511, %513
  %515 = add nuw nsw i32 %514, %513
  %516 = icmp eq i32 %515, 2
  %517 = zext i1 %516 to i8
  store i8 %517, i8* %39, align 1, !tbaa !2450
  %518 = icmp ne i8 %512, 0
  %519 = xor i1 %518, %516
  %520 = or i1 %509, %519
  %.v117 = select i1 %520, i64 197, i64 10
  %521 = add i64 %493, %.v117
  store i64 %521, i64* %PC, align 8, !tbaa !2428
  br i1 %520, label %block_400fc1, label %block_400f06

block_400fb1:                                     ; preds = %block_400f0d
  %522 = add i64 %542, -4
  %523 = add i64 %578, 3
  store i64 %523, i64* %PC, align 8
  %524 = inttoptr i64 %522 to i32*
  %525 = load i32, i32* %524, align 4
  %526 = zext i32 %525 to i64
  store i64 %526, i64* %RDI, align 8, !tbaa !2428
  %527 = add i64 %542, -16
  %528 = add i64 %578, 7
  store i64 %528, i64* %PC, align 8
  %529 = inttoptr i64 %527 to i64*
  %530 = load i64, i64* %529, align 8
  store i64 %530, i64* %RSI, align 8, !tbaa !2428
  %531 = add i64 %542, -24
  %532 = add i64 %578, 11
  store i64 %532, i64* %PC, align 8
  %533 = inttoptr i64 %531 to i64*
  %534 = load i64, i64* %533, align 8
  store i64 %534, i64* %RDX, align 8, !tbaa !2428
  %535 = add i64 %578, 559
  %536 = add i64 %578, 16
  %537 = load i64, i64* %RSP, align 8, !tbaa !2428
  %538 = add i64 %537, -8
  %539 = inttoptr i64 %538 to i64*
  store i64 %536, i64* %539, align 8
  store i64 %538, i64* %RSP, align 8, !tbaa !2428
  store i64 %535, i64* %PC, align 8, !tbaa !2428
  %540 = tail call %struct.Memory* @sub_4011e0_bitrv2(%struct.State* nonnull %0, i64 %535, %struct.Memory* %2)
  %.pre116 = load i64, i64* %PC, align 8
  br label %block_400fc1

block_400f0d:                                     ; preds = %block_400f06, %block_400f19
  %541 = phi i64 [ %.pre, %block_400f06 ], [ %321, %block_400f19 ]
  %542 = load i64, i64* %RBP, align 8
  %543 = add i64 %542, -28
  %544 = add i64 %541, 3
  store i64 %544, i64* %PC, align 8
  %545 = inttoptr i64 %543 to i32*
  %546 = load i32, i32* %545, align 4
  %547 = zext i32 %546 to i64
  store i64 %547, i64* %RAX, align 8, !tbaa !2428
  %548 = add i64 %542, -32
  %549 = add i64 %541, 6
  store i64 %549, i64* %PC, align 8
  %550 = inttoptr i64 %548 to i32*
  %551 = load i32, i32* %550, align 4
  %552 = sub i32 %546, %551
  %553 = icmp ult i32 %546, %551
  %554 = zext i1 %553 to i8
  store i8 %554, i8* %15, align 1, !tbaa !2433
  %555 = and i32 %552, 255
  %556 = tail call i32 @llvm.ctpop.i32(i32 %555) #10
  %557 = trunc i32 %556 to i8
  %558 = and i8 %557, 1
  %559 = xor i8 %558, 1
  store i8 %559, i8* %22, align 1, !tbaa !2447
  %560 = xor i32 %551, %546
  %561 = xor i32 %560, %552
  %562 = lshr i32 %561, 4
  %563 = trunc i32 %562 to i8
  %564 = and i8 %563, 1
  store i8 %564, i8* %27, align 1, !tbaa !2451
  %565 = icmp eq i32 %552, 0
  %566 = zext i1 %565 to i8
  store i8 %566, i8* %30, align 1, !tbaa !2448
  %567 = lshr i32 %552, 31
  %568 = trunc i32 %567 to i8
  store i8 %568, i8* %33, align 1, !tbaa !2449
  %569 = lshr i32 %546, 31
  %570 = lshr i32 %551, 31
  %571 = xor i32 %570, %569
  %572 = xor i32 %567, %569
  %573 = add nuw nsw i32 %572, %571
  %574 = icmp eq i32 %573, 2
  %575 = zext i1 %574 to i8
  store i8 %575, i8* %39, align 1, !tbaa !2450
  %576 = icmp ne i8 %568, 0
  %577 = xor i1 %576, %574
  %.v118 = select i1 %577, i64 12, i64 164
  %578 = add i64 %541, %.v118
  store i64 %578, i64* %PC, align 8, !tbaa !2428
  br i1 %577, label %block_400f19, label %block_400fb1

block_400fc6:                                     ; preds = %block_400fc1, %block_400e60
  %579 = phi i64 [ %86, %block_400e60 ], [ %619, %block_400fc1 ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_400e60 ], [ %MEMORY.2, %block_400fc1 ]
  %580 = load i64, i64* %RSP, align 8
  %581 = add i64 %580, 64
  store i64 %581, i64* %RSP, align 8, !tbaa !2428
  %582 = icmp ugt i64 %580, -65
  %583 = zext i1 %582 to i8
  store i8 %583, i8* %15, align 1, !tbaa !2433
  %584 = trunc i64 %581 to i32
  %585 = and i32 %584, 255
  %586 = tail call i32 @llvm.ctpop.i32(i32 %585) #10
  %587 = trunc i32 %586 to i8
  %588 = and i8 %587, 1
  %589 = xor i8 %588, 1
  store i8 %589, i8* %22, align 1, !tbaa !2447
  %590 = xor i64 %581, %580
  %591 = lshr i64 %590, 4
  %592 = trunc i64 %591 to i8
  %593 = and i8 %592, 1
  store i8 %593, i8* %27, align 1, !tbaa !2451
  %594 = icmp eq i64 %581, 0
  %595 = zext i1 %594 to i8
  store i8 %595, i8* %30, align 1, !tbaa !2448
  %596 = lshr i64 %581, 63
  %597 = trunc i64 %596 to i8
  store i8 %597, i8* %33, align 1, !tbaa !2449
  %598 = lshr i64 %580, 63
  %599 = xor i64 %596, %598
  %600 = add nuw nsw i64 %599, %596
  %601 = icmp eq i64 %600, 2
  %602 = zext i1 %601 to i8
  store i8 %602, i8* %39, align 1, !tbaa !2450
  %603 = add i64 %579, 5
  store i64 %603, i64* %PC, align 8
  %604 = add i64 %580, 72
  %605 = inttoptr i64 %581 to i64*
  %606 = load i64, i64* %605, align 8
  store i64 %606, i64* %RBP, align 8, !tbaa !2428
  store i64 %604, i64* %RSP, align 8, !tbaa !2428
  %607 = add i64 %579, 6
  store i64 %607, i64* %PC, align 8
  %608 = inttoptr i64 %604 to i64*
  %609 = load i64, i64* %608, align 8
  store i64 %609, i64* %PC, align 8, !tbaa !2428
  %610 = add i64 %580, 80
  store i64 %610, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_400f06:                                     ; preds = %block_400e7d
  %611 = add i64 %491, -28
  %612 = add i64 %521, 7
  store i64 %612, i64* %PC, align 8
  %613 = inttoptr i64 %611 to i32*
  store i32 2, i32* %613, align 4
  %.pre = load i64, i64* %PC, align 8
  %614 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %615 = bitcast i64* %614 to i8*
  %616 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %617 = bitcast i64* %616 to i8*
  br label %block_400f0d

block_400fc1:                                     ; preds = %block_400fb1, %block_400e7d
  %618 = phi i64 [ %521, %block_400e7d ], [ %.pre116, %block_400fb1 ]
  %MEMORY.2 = phi %struct.Memory* [ %2, %block_400e7d ], [ %540, %block_400fb1 ]
  %619 = add i64 %618, 5
  store i64 %619, i64* %PC, align 8, !tbaa !2428
  br label %block_400fc6
}

; Function Attrs: noinline norecurse nounwind
define %struct.Memory* @sub_400780__dl_relocate_static_pie(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #8 {
block_400780:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_401c00_bitrv2conj(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_401c00:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  store i64 %8, i64* %6, align 8, !tbaa !2428
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -12
  %12 = load i32, i32* %EDI, align 4
  %13 = add i64 %10, 6
  store i64 %13, i64* %PC, align 8
  %14 = inttoptr i64 %11 to i32*
  store i32 %12, i32* %14, align 4
  %15 = load i64, i64* %RBP, align 8
  %16 = add i64 %15, -16
  %17 = load i64, i64* %RSI, align 8
  %18 = load i64, i64* %PC, align 8
  %19 = add i64 %18, 4
  store i64 %19, i64* %PC, align 8
  %20 = inttoptr i64 %16 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %RBP, align 8
  %22 = add i64 %21, -24
  %23 = load i64, i64* %RDX, align 8
  %24 = load i64, i64* %PC, align 8
  %25 = add i64 %24, 4
  store i64 %25, i64* %PC, align 8
  %26 = inttoptr i64 %22 to i64*
  store i64 %23, i64* %26, align 8
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %27, -16
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %28 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %RDX, align 8, !tbaa !2428
  %33 = add i64 %29, 10
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i32*
  store i32 0, i32* %34, align 4
  %35 = load i64, i64* %RBP, align 8
  %36 = add i64 %35, -4
  %37 = load i64, i64* %PC, align 8
  %38 = add i64 %37, 3
  store i64 %38, i64* %PC, align 8
  %39 = inttoptr i64 %36 to i32*
  %40 = load i32, i32* %39, align 4
  %41 = zext i32 %40 to i64
  store i64 %41, i64* %RDI, align 8, !tbaa !2428
  %42 = add i64 %35, -44
  %43 = add i64 %37, 6
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -48
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 7
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %46 to i32*
  store i32 1, i32* %49, align 4
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %.pre = load i64, i64* %PC, align 8
  br label %block_401c26

block_401c7d:                                     ; preds = %block_401c45
  %56 = add i64 %3874, 3
  store i64 %56, i64* %PC, align 8
  %57 = load i32, i32* %3846, align 4
  %58 = shl i32 %57, 1
  %59 = icmp slt i32 %57, 0
  %60 = icmp slt i32 %58, 0
  %61 = xor i1 %59, %60
  %62 = zext i32 %58 to i64
  store i64 %62, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %57, 31
  %63 = trunc i32 %.lobit to i8
  store i8 %63, i8* %50, align 1, !tbaa !2432
  %64 = and i32 %58, 254
  %65 = tail call i32 @llvm.ctpop.i32(i32 %64) #10
  %66 = trunc i32 %65 to i8
  %67 = and i8 %66, 1
  %68 = xor i8 %67, 1
  store i8 %68, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %69 = icmp eq i32 %58, 0
  %70 = zext i1 %69 to i8
  store i8 %70, i8* %53, align 1, !tbaa !2432
  %71 = lshr i32 %57, 30
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  store i8 %73, i8* %54, align 1, !tbaa !2432
  %74 = zext i1 %61 to i8
  store i8 %74, i8* %55, align 1, !tbaa !2432
  %75 = add i64 %3874, 9
  store i64 %75, i64* %PC, align 8
  store i32 %58, i32* %3846, align 4
  %76 = load i64, i64* %PC, align 8
  %77 = add i64 %76, -96
  store i64 %77, i64* %PC, align 8, !tbaa !2428
  br label %block_401c26

block_401c51:                                     ; preds = %block_401c45
  %78 = add i64 %3838, -16
  %79 = add i64 %3874, 4
  store i64 %79, i64* %PC, align 8
  %80 = inttoptr i64 %78 to i64*
  %81 = load i64, i64* %80, align 8
  store i64 %81, i64* %RAX, align 8, !tbaa !2428
  %82 = add i64 %3874, 8
  store i64 %82, i64* %PC, align 8
  %83 = load i32, i32* %3841, align 4
  %84 = sext i32 %83 to i64
  store i64 %84, i64* %RCX, align 8, !tbaa !2428
  %85 = shl nsw i64 %84, 2
  %86 = add i64 %85, %81
  %87 = add i64 %3874, 11
  store i64 %87, i64* %PC, align 8
  %88 = inttoptr i64 %86 to i32*
  %89 = load i32, i32* %88, align 4
  %90 = zext i32 %89 to i64
  store i64 %90, i64* %RDX, align 8, !tbaa !2428
  %91 = add i64 %3838, -44
  %92 = add i64 %3874, 14
  store i64 %92, i64* %PC, align 8
  %93 = inttoptr i64 %91 to i32*
  %94 = load i32, i32* %93, align 4
  %95 = add i32 %94, %89
  %96 = zext i32 %95 to i64
  store i64 %96, i64* %RDX, align 8, !tbaa !2428
  %97 = icmp ult i32 %95, %89
  %98 = icmp ult i32 %95, %94
  %99 = or i1 %97, %98
  %100 = zext i1 %99 to i8
  store i8 %100, i8* %50, align 1, !tbaa !2433
  %101 = and i32 %95, 255
  %102 = tail call i32 @llvm.ctpop.i32(i32 %101) #10
  %103 = trunc i32 %102 to i8
  %104 = and i8 %103, 1
  %105 = xor i8 %104, 1
  store i8 %105, i8* %51, align 1, !tbaa !2447
  %106 = xor i32 %94, %89
  %107 = xor i32 %106, %95
  %108 = lshr i32 %107, 4
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  store i8 %110, i8* %52, align 1, !tbaa !2451
  %111 = icmp eq i32 %95, 0
  %112 = zext i1 %111 to i8
  store i8 %112, i8* %53, align 1, !tbaa !2448
  %113 = lshr i32 %95, 31
  %114 = trunc i32 %113 to i8
  store i8 %114, i8* %54, align 1, !tbaa !2449
  %115 = lshr i32 %89, 31
  %116 = lshr i32 %94, 31
  %117 = xor i32 %113, %115
  %118 = xor i32 %113, %116
  %119 = add nuw nsw i32 %117, %118
  %120 = icmp eq i32 %119, 2
  %121 = zext i1 %120 to i8
  store i8 %121, i8* %55, align 1, !tbaa !2450
  %122 = add i64 %3874, 18
  store i64 %122, i64* %PC, align 8
  %123 = load i64, i64* %80, align 8
  store i64 %123, i64* %RAX, align 8, !tbaa !2428
  %124 = add i64 %3874, 21
  store i64 %124, i64* %PC, align 8
  %125 = load i32, i32* %3846, align 4
  %126 = zext i32 %125 to i64
  store i64 %126, i64* %RSI, align 8, !tbaa !2428
  %127 = add i64 %3874, 24
  store i64 %127, i64* %PC, align 8
  %128 = load i32, i32* %3841, align 4
  %129 = add i32 %128, %125
  %130 = zext i32 %129 to i64
  store i64 %130, i64* %RSI, align 8, !tbaa !2428
  %131 = icmp ult i32 %129, %125
  %132 = icmp ult i32 %129, %128
  %133 = or i1 %131, %132
  %134 = zext i1 %133 to i8
  store i8 %134, i8* %50, align 1, !tbaa !2433
  %135 = and i32 %129, 255
  %136 = tail call i32 @llvm.ctpop.i32(i32 %135) #10
  %137 = trunc i32 %136 to i8
  %138 = and i8 %137, 1
  %139 = xor i8 %138, 1
  store i8 %139, i8* %51, align 1, !tbaa !2447
  %140 = xor i32 %128, %125
  %141 = xor i32 %140, %129
  %142 = lshr i32 %141, 4
  %143 = trunc i32 %142 to i8
  %144 = and i8 %143, 1
  store i8 %144, i8* %52, align 1, !tbaa !2451
  %145 = icmp eq i32 %129, 0
  %146 = zext i1 %145 to i8
  store i8 %146, i8* %53, align 1, !tbaa !2448
  %147 = lshr i32 %129, 31
  %148 = trunc i32 %147 to i8
  store i8 %148, i8* %54, align 1, !tbaa !2449
  %149 = lshr i32 %125, 31
  %150 = lshr i32 %128, 31
  %151 = xor i32 %147, %149
  %152 = xor i32 %147, %150
  %153 = add nuw nsw i32 %151, %152
  %154 = icmp eq i32 %153, 2
  %155 = zext i1 %154 to i8
  store i8 %155, i8* %55, align 1, !tbaa !2450
  %156 = sext i32 %129 to i64
  store i64 %156, i64* %RCX, align 8, !tbaa !2428
  %157 = shl nsw i64 %156, 2
  %158 = add i64 %123, %157
  %159 = add i64 %3874, 30
  store i64 %159, i64* %PC, align 8
  %160 = inttoptr i64 %158 to i32*
  store i32 %95, i32* %160, align 4
  %161 = load i64, i64* %RBP, align 8
  %162 = add i64 %161, -28
  %163 = load i64, i64* %PC, align 8
  %164 = add i64 %163, 3
  store i64 %164, i64* %PC, align 8
  %165 = inttoptr i64 %162 to i32*
  %166 = load i32, i32* %165, align 4
  %167 = add i32 %166, 1
  %168 = zext i32 %167 to i64
  store i64 %168, i64* %RAX, align 8, !tbaa !2428
  %169 = icmp eq i32 %166, -1
  %170 = icmp eq i32 %167, 0
  %171 = or i1 %169, %170
  %172 = zext i1 %171 to i8
  store i8 %172, i8* %50, align 1, !tbaa !2433
  %173 = and i32 %167, 255
  %174 = tail call i32 @llvm.ctpop.i32(i32 %173) #10
  %175 = trunc i32 %174 to i8
  %176 = and i8 %175, 1
  %177 = xor i8 %176, 1
  store i8 %177, i8* %51, align 1, !tbaa !2447
  %178 = xor i32 %167, %166
  %179 = lshr i32 %178, 4
  %180 = trunc i32 %179 to i8
  %181 = and i8 %180, 1
  store i8 %181, i8* %52, align 1, !tbaa !2451
  %182 = zext i1 %170 to i8
  store i8 %182, i8* %53, align 1, !tbaa !2448
  %183 = lshr i32 %167, 31
  %184 = trunc i32 %183 to i8
  store i8 %184, i8* %54, align 1, !tbaa !2449
  %185 = lshr i32 %166, 31
  %186 = xor i32 %183, %185
  %187 = add nuw nsw i32 %186, %183
  %188 = icmp eq i32 %187, 2
  %189 = zext i1 %188 to i8
  store i8 %189, i8* %55, align 1, !tbaa !2450
  %190 = add i64 %163, 9
  store i64 %190, i64* %PC, align 8
  store i32 %167, i32* %165, align 4
  %191 = load i64, i64* %PC, align 8
  %192 = add i64 %191, -51
  store i64 %192, i64* %PC, align 8, !tbaa !2428
  br label %block_401c45

block_4023f9:                                     ; preds = %block_40221f
  %193 = load i32, i32* %3496, align 4
  %194 = shl i32 %193, 1
  %195 = icmp slt i32 %193, 0
  %196 = icmp slt i32 %194, 0
  %197 = xor i1 %195, %196
  %198 = zext i32 %194 to i64
  store i64 %198, i64* %RCX, align 8, !tbaa !2428
  %.lobit21 = lshr i32 %193, 31
  %199 = trunc i32 %.lobit21 to i8
  store i8 %199, i8* %50, align 1, !tbaa !2432
  %200 = and i32 %194, 254
  %201 = tail call i32 @llvm.ctpop.i32(i32 %200) #10
  %202 = trunc i32 %201 to i8
  %203 = and i8 %202, 1
  %204 = xor i8 %203, 1
  store i8 %204, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %205 = icmp eq i32 %194, 0
  %206 = zext i1 %205 to i8
  store i8 %206, i8* %53, align 1, !tbaa !2432
  %207 = lshr i32 %193, 30
  %208 = trunc i32 %207 to i8
  %209 = and i8 %208, 1
  store i8 %209, i8* %54, align 1, !tbaa !2432
  %210 = zext i1 %197 to i8
  store i8 %210, i8* %55, align 1, !tbaa !2432
  %211 = add i64 %3488, -16
  %212 = add i64 %3524, 20
  store i64 %212, i64* %PC, align 8
  %213 = inttoptr i64 %211 to i64*
  %214 = load i64, i64* %213, align 8
  store i64 %214, i64* %RDX, align 8, !tbaa !2428
  %215 = add i64 %3524, 24
  store i64 %215, i64* %PC, align 8
  %216 = load i32, i32* %3496, align 4
  %217 = sext i32 %216 to i64
  store i64 %217, i64* %RSI, align 8, !tbaa !2428
  %218 = shl nsw i64 %217, 2
  %219 = add i64 %214, %218
  %220 = add i64 %3524, 27
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %219 to i32*
  %222 = load i32, i32* %221, align 4
  %223 = add i32 %222, %194
  %224 = zext i32 %223 to i64
  store i64 %224, i64* %RCX, align 8, !tbaa !2428
  %225 = icmp ult i32 %223, %194
  %226 = icmp ult i32 %223, %222
  %227 = or i1 %225, %226
  %228 = zext i1 %227 to i8
  store i8 %228, i8* %50, align 1, !tbaa !2433
  %229 = and i32 %223, 255
  %230 = tail call i32 @llvm.ctpop.i32(i32 %229) #10
  %231 = trunc i32 %230 to i8
  %232 = and i8 %231, 1
  %233 = xor i8 %232, 1
  store i8 %233, i8* %51, align 1, !tbaa !2447
  %234 = xor i32 %222, %194
  %235 = xor i32 %234, %223
  %236 = lshr i32 %235, 4
  %237 = trunc i32 %236 to i8
  %238 = and i8 %237, 1
  store i8 %238, i8* %52, align 1, !tbaa !2451
  %239 = icmp eq i32 %223, 0
  %240 = zext i1 %239 to i8
  store i8 %240, i8* %53, align 1, !tbaa !2448
  %241 = lshr i32 %223, 31
  %242 = trunc i32 %241 to i8
  store i8 %242, i8* %54, align 1, !tbaa !2449
  %243 = lshr i32 %193, 30
  %244 = and i32 %243, 1
  %245 = lshr i32 %222, 31
  %246 = xor i32 %241, %244
  %247 = xor i32 %241, %245
  %248 = add nuw nsw i32 %246, %247
  %249 = icmp eq i32 %248, 2
  %250 = zext i1 %249 to i8
  store i8 %250, i8* %55, align 1, !tbaa !2450
  %251 = add i64 %3488, -40
  %252 = add i64 %3524, 30
  store i64 %252, i64* %PC, align 8
  %253 = inttoptr i64 %251 to i32*
  store i32 %223, i32* %253, align 4
  %254 = load i64, i64* %RBP, align 8
  %255 = add i64 %254, -24
  %256 = load i64, i64* %PC, align 8
  %257 = add i64 %256, 4
  store i64 %257, i64* %PC, align 8
  %258 = inttoptr i64 %255 to i64*
  %259 = load i64, i64* %258, align 8
  store i64 %259, i64* %RDX, align 8, !tbaa !2428
  %260 = add i64 %254, -40
  %261 = add i64 %256, 7
  store i64 %261, i64* %PC, align 8
  %262 = inttoptr i64 %260 to i32*
  %263 = load i32, i32* %262, align 4
  %264 = add i32 %263, 1
  %265 = zext i32 %264 to i64
  store i64 %265, i64* %RCX, align 8, !tbaa !2428
  %266 = icmp eq i32 %263, -1
  %267 = icmp eq i32 %264, 0
  %268 = or i1 %266, %267
  %269 = zext i1 %268 to i8
  store i8 %269, i8* %50, align 1, !tbaa !2433
  %270 = and i32 %264, 255
  %271 = tail call i32 @llvm.ctpop.i32(i32 %270) #10
  %272 = trunc i32 %271 to i8
  %273 = and i8 %272, 1
  %274 = xor i8 %273, 1
  store i8 %274, i8* %51, align 1, !tbaa !2447
  %275 = xor i32 %264, %263
  %276 = lshr i32 %275, 4
  %277 = trunc i32 %276 to i8
  %278 = and i8 %277, 1
  store i8 %278, i8* %52, align 1, !tbaa !2451
  %279 = zext i1 %267 to i8
  store i8 %279, i8* %53, align 1, !tbaa !2448
  %280 = lshr i32 %264, 31
  %281 = trunc i32 %280 to i8
  store i8 %281, i8* %54, align 1, !tbaa !2449
  %282 = lshr i32 %263, 31
  %283 = xor i32 %280, %282
  %284 = add nuw nsw i32 %283, %280
  %285 = icmp eq i32 %284, 2
  %286 = zext i1 %285 to i8
  store i8 %286, i8* %55, align 1, !tbaa !2450
  %287 = sext i32 %264 to i64
  store i64 %287, i64* %RSI, align 8, !tbaa !2428
  %288 = shl nsw i64 %287, 3
  %289 = add i64 %259, %288
  %290 = add i64 %256, 18
  store i64 %290, i64* %PC, align 8
  %291 = inttoptr i64 %289 to i64*
  %292 = load i64, i64* %291, align 8
  %293 = load i64, i64* %RAX, align 8
  %294 = xor i64 %293, %292
  store i64 %294, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %295 = trunc i64 %294 to i32
  %296 = and i32 %295, 255
  %297 = tail call i32 @llvm.ctpop.i32(i32 %296) #10
  %298 = trunc i32 %297 to i8
  %299 = and i8 %298, 1
  %300 = xor i8 %299, 1
  store i8 %300, i8* %51, align 1, !tbaa !2447
  %301 = icmp eq i64 %294, 0
  %302 = zext i1 %301 to i8
  store i8 %302, i8* %53, align 1, !tbaa !2448
  %303 = lshr i64 %294, 63
  %304 = trunc i64 %303 to i8
  store i8 %304, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %294, i64* %3730, align 1, !tbaa !2428
  store i64 0, i64* %3731, align 1, !tbaa !2428
  %305 = add i64 %256, 35
  store i64 %305, i64* %PC, align 8
  %306 = load i64, i64* %258, align 8
  store i64 %306, i64* %RDX, align 8, !tbaa !2428
  %307 = add i64 %256, 38
  store i64 %307, i64* %PC, align 8
  %308 = load i32, i32* %262, align 4
  %309 = add i32 %308, 1
  %310 = zext i32 %309 to i64
  store i64 %310, i64* %RCX, align 8, !tbaa !2428
  %311 = icmp eq i32 %308, -1
  %312 = icmp eq i32 %309, 0
  %313 = or i1 %311, %312
  %314 = zext i1 %313 to i8
  store i8 %314, i8* %50, align 1, !tbaa !2433
  %315 = and i32 %309, 255
  %316 = tail call i32 @llvm.ctpop.i32(i32 %315) #10
  %317 = trunc i32 %316 to i8
  %318 = and i8 %317, 1
  %319 = xor i8 %318, 1
  store i8 %319, i8* %51, align 1, !tbaa !2447
  %320 = xor i32 %309, %308
  %321 = lshr i32 %320, 4
  %322 = trunc i32 %321 to i8
  %323 = and i8 %322, 1
  store i8 %323, i8* %52, align 1, !tbaa !2451
  %324 = zext i1 %312 to i8
  store i8 %324, i8* %53, align 1, !tbaa !2448
  %325 = lshr i32 %309, 31
  %326 = trunc i32 %325 to i8
  store i8 %326, i8* %54, align 1, !tbaa !2449
  %327 = lshr i32 %308, 31
  %328 = xor i32 %325, %327
  %329 = add nuw nsw i32 %328, %325
  %330 = icmp eq i32 %329, 2
  %331 = zext i1 %330 to i8
  store i8 %331, i8* %55, align 1, !tbaa !2450
  %332 = sext i32 %309 to i64
  store i64 %332, i64* %RSI, align 8, !tbaa !2428
  %333 = shl nsw i64 %332, 3
  %334 = add i64 %306, %333
  %335 = add i64 %256, 49
  store i64 %335, i64* %PC, align 8
  %336 = inttoptr i64 %334 to i64*
  store i64 %294, i64* %336, align 8
  %337 = load i64, i64* %RBP, align 8
  %338 = add i64 %337, -24
  %339 = load i64, i64* %PC, align 8
  %340 = add i64 %339, 4
  store i64 %340, i64* %PC, align 8
  %341 = inttoptr i64 %338 to i64*
  %342 = load i64, i64* %341, align 8
  store i64 %342, i64* %RDX, align 8, !tbaa !2428
  %343 = add i64 %337, -40
  %344 = add i64 %339, 7
  store i64 %344, i64* %PC, align 8
  %345 = inttoptr i64 %343 to i32*
  %346 = load i32, i32* %345, align 4
  %347 = zext i32 %346 to i64
  store i64 %347, i64* %RCX, align 8, !tbaa !2428
  %348 = add i64 %337, -52
  %349 = add i64 %339, 10
  store i64 %349, i64* %PC, align 8
  %350 = inttoptr i64 %348 to i32*
  %351 = load i32, i32* %350, align 4
  %352 = add i32 %351, %346
  %353 = lshr i32 %352, 31
  %354 = add i32 %352, 1
  %355 = zext i32 %354 to i64
  store i64 %355, i64* %RCX, align 8, !tbaa !2428
  %356 = icmp eq i32 %352, -1
  %357 = icmp eq i32 %354, 0
  %358 = or i1 %356, %357
  %359 = zext i1 %358 to i8
  store i8 %359, i8* %50, align 1, !tbaa !2433
  %360 = and i32 %354, 255
  %361 = tail call i32 @llvm.ctpop.i32(i32 %360) #10
  %362 = trunc i32 %361 to i8
  %363 = and i8 %362, 1
  %364 = xor i8 %363, 1
  store i8 %364, i8* %51, align 1, !tbaa !2447
  %365 = xor i32 %354, %352
  %366 = lshr i32 %365, 4
  %367 = trunc i32 %366 to i8
  %368 = and i8 %367, 1
  store i8 %368, i8* %52, align 1, !tbaa !2451
  %369 = zext i1 %357 to i8
  store i8 %369, i8* %53, align 1, !tbaa !2448
  %370 = lshr i32 %354, 31
  %371 = trunc i32 %370 to i8
  store i8 %371, i8* %54, align 1, !tbaa !2449
  %372 = xor i32 %370, %353
  %373 = add nuw nsw i32 %372, %370
  %374 = icmp eq i32 %373, 2
  %375 = zext i1 %374 to i8
  store i8 %375, i8* %55, align 1, !tbaa !2450
  %376 = sext i32 %354 to i64
  store i64 %376, i64* %RSI, align 8, !tbaa !2428
  %377 = shl nsw i64 %376, 3
  %378 = add i64 %342, %377
  %379 = add i64 %339, 21
  store i64 %379, i64* %PC, align 8
  %380 = inttoptr i64 %378 to i64*
  %381 = load i64, i64* %380, align 8
  %382 = load i64, i64* %RAX, align 8
  %383 = xor i64 %382, %381
  store i64 %383, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %384 = trunc i64 %383 to i32
  %385 = and i32 %384, 255
  %386 = tail call i32 @llvm.ctpop.i32(i32 %385) #10
  %387 = trunc i32 %386 to i8
  %388 = and i8 %387, 1
  %389 = xor i8 %388, 1
  store i8 %389, i8* %51, align 1, !tbaa !2447
  %390 = icmp eq i64 %383, 0
  %391 = zext i1 %390 to i8
  store i8 %391, i8* %53, align 1, !tbaa !2448
  %392 = lshr i64 %383, 63
  %393 = trunc i64 %392 to i8
  store i8 %393, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %383, i64* %3730, align 1, !tbaa !2428
  store i64 0, i64* %3731, align 1, !tbaa !2428
  %394 = load i64, i64* %RBP, align 8
  %395 = add i64 %394, -24
  %396 = add i64 %339, 38
  store i64 %396, i64* %PC, align 8
  %397 = inttoptr i64 %395 to i64*
  %398 = load i64, i64* %397, align 8
  store i64 %398, i64* %RAX, align 8, !tbaa !2428
  %399 = add i64 %394, -40
  %400 = add i64 %339, 41
  store i64 %400, i64* %PC, align 8
  %401 = inttoptr i64 %399 to i32*
  %402 = load i32, i32* %401, align 4
  %403 = zext i32 %402 to i64
  store i64 %403, i64* %RCX, align 8, !tbaa !2428
  %404 = add i64 %394, -52
  %405 = add i64 %339, 44
  store i64 %405, i64* %PC, align 8
  %406 = inttoptr i64 %404 to i32*
  %407 = load i32, i32* %406, align 4
  %408 = add i32 %407, %402
  %409 = lshr i32 %408, 31
  %410 = add i32 %408, 1
  %411 = zext i32 %410 to i64
  store i64 %411, i64* %RCX, align 8, !tbaa !2428
  %412 = icmp eq i32 %408, -1
  %413 = icmp eq i32 %410, 0
  %414 = or i1 %412, %413
  %415 = zext i1 %414 to i8
  store i8 %415, i8* %50, align 1, !tbaa !2433
  %416 = and i32 %410, 255
  %417 = tail call i32 @llvm.ctpop.i32(i32 %416) #10
  %418 = trunc i32 %417 to i8
  %419 = and i8 %418, 1
  %420 = xor i8 %419, 1
  store i8 %420, i8* %51, align 1, !tbaa !2447
  %421 = xor i32 %410, %408
  %422 = lshr i32 %421, 4
  %423 = trunc i32 %422 to i8
  %424 = and i8 %423, 1
  store i8 %424, i8* %52, align 1, !tbaa !2451
  %425 = zext i1 %413 to i8
  store i8 %425, i8* %53, align 1, !tbaa !2448
  %426 = lshr i32 %410, 31
  %427 = trunc i32 %426 to i8
  store i8 %427, i8* %54, align 1, !tbaa !2449
  %428 = xor i32 %426, %409
  %429 = add nuw nsw i32 %428, %426
  %430 = icmp eq i32 %429, 2
  %431 = zext i1 %430 to i8
  store i8 %431, i8* %55, align 1, !tbaa !2450
  %432 = sext i32 %410 to i64
  store i64 %432, i64* %RDX, align 8, !tbaa !2428
  %433 = shl nsw i64 %432, 3
  %434 = add i64 %398, %433
  %435 = add i64 %339, 55
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %434 to i64*
  store i64 %383, i64* %436, align 8
  %437 = load i64, i64* %RBP, align 8
  %438 = add i64 %437, -36
  %439 = load i64, i64* %PC, align 8
  %440 = add i64 %439, 3
  store i64 %440, i64* %PC, align 8
  %441 = inttoptr i64 %438 to i32*
  %442 = load i32, i32* %441, align 4
  %443 = add i32 %442, 1
  %444 = zext i32 %443 to i64
  store i64 %444, i64* %RAX, align 8, !tbaa !2428
  %445 = icmp eq i32 %442, -1
  %446 = icmp eq i32 %443, 0
  %447 = or i1 %445, %446
  %448 = zext i1 %447 to i8
  store i8 %448, i8* %50, align 1, !tbaa !2433
  %449 = and i32 %443, 255
  %450 = tail call i32 @llvm.ctpop.i32(i32 %449) #10
  %451 = trunc i32 %450 to i8
  %452 = and i8 %451, 1
  %453 = xor i8 %452, 1
  store i8 %453, i8* %51, align 1, !tbaa !2447
  %454 = xor i32 %443, %442
  %455 = lshr i32 %454, 4
  %456 = trunc i32 %455 to i8
  %457 = and i8 %456, 1
  store i8 %457, i8* %52, align 1, !tbaa !2451
  %458 = zext i1 %446 to i8
  store i8 %458, i8* %53, align 1, !tbaa !2448
  %459 = lshr i32 %443, 31
  %460 = trunc i32 %459 to i8
  store i8 %460, i8* %54, align 1, !tbaa !2449
  %461 = lshr i32 %442, 31
  %462 = xor i32 %459, %461
  %463 = add nuw nsw i32 %462, %459
  %464 = icmp eq i32 %463, 2
  %465 = zext i1 %464 to i8
  store i8 %465, i8* %55, align 1, !tbaa !2450
  %466 = add i64 %439, 9
  store i64 %466, i64* %PC, align 8
  store i32 %443, i32* %441, align 4
  %467 = load i64, i64* %PC, align 8
  %468 = add i64 %467, -636
  store i64 %468, i64* %PC, align 8, !tbaa !2428
  br label %block_40220c

block_401cc9:                                     ; preds = %block_401cbd
  %469 = load i32, i32* %2620, align 4
  %470 = shl i32 %469, 1
  %471 = icmp slt i32 %469, 0
  %472 = icmp slt i32 %470, 0
  %473 = xor i1 %471, %472
  %474 = zext i32 %470 to i64
  store i64 %474, i64* %RCX, align 8, !tbaa !2428
  %.lobit14 = lshr i32 %469, 31
  %475 = trunc i32 %.lobit14 to i8
  store i8 %475, i8* %50, align 1, !tbaa !2432
  %476 = and i32 %470, 254
  %477 = tail call i32 @llvm.ctpop.i32(i32 %476) #10
  %478 = trunc i32 %477 to i8
  %479 = and i8 %478, 1
  %480 = xor i8 %479, 1
  store i8 %480, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %481 = icmp eq i32 %470, 0
  %482 = zext i1 %481 to i8
  store i8 %482, i8* %53, align 1, !tbaa !2432
  %483 = lshr i32 %469, 30
  %484 = trunc i32 %483 to i8
  %485 = and i8 %484, 1
  store i8 %485, i8* %54, align 1, !tbaa !2432
  %486 = zext i1 %473 to i8
  store i8 %486, i8* %55, align 1, !tbaa !2432
  %487 = add i64 %2617, -16
  %488 = add i64 %2653, 20
  store i64 %488, i64* %PC, align 8
  %489 = inttoptr i64 %487 to i64*
  %490 = load i64, i64* %489, align 8
  store i64 %490, i64* %RDX, align 8, !tbaa !2428
  %491 = add i64 %2653, 24
  store i64 %491, i64* %PC, align 8
  %492 = load i32, i32* %2625, align 4
  %493 = sext i32 %492 to i64
  store i64 %493, i64* %RSI, align 8, !tbaa !2428
  %494 = shl nsw i64 %493, 2
  %495 = add i64 %490, %494
  %496 = add i64 %2653, 27
  store i64 %496, i64* %PC, align 8
  %497 = inttoptr i64 %495 to i32*
  %498 = load i32, i32* %497, align 4
  %499 = add i32 %498, %470
  %500 = zext i32 %499 to i64
  store i64 %500, i64* %RCX, align 8, !tbaa !2428
  %501 = icmp ult i32 %499, %470
  %502 = icmp ult i32 %499, %498
  %503 = or i1 %501, %502
  %504 = zext i1 %503 to i8
  store i8 %504, i8* %50, align 1, !tbaa !2433
  %505 = and i32 %499, 255
  %506 = tail call i32 @llvm.ctpop.i32(i32 %505) #10
  %507 = trunc i32 %506 to i8
  %508 = and i8 %507, 1
  %509 = xor i8 %508, 1
  store i8 %509, i8* %51, align 1, !tbaa !2447
  %510 = xor i32 %498, %470
  %511 = xor i32 %510, %499
  %512 = lshr i32 %511, 4
  %513 = trunc i32 %512 to i8
  %514 = and i8 %513, 1
  store i8 %514, i8* %52, align 1, !tbaa !2451
  %515 = icmp eq i32 %499, 0
  %516 = zext i1 %515 to i8
  store i8 %516, i8* %53, align 1, !tbaa !2448
  %517 = lshr i32 %499, 31
  %518 = trunc i32 %517 to i8
  store i8 %518, i8* %54, align 1, !tbaa !2449
  %519 = lshr i32 %469, 30
  %520 = and i32 %519, 1
  %521 = lshr i32 %498, 31
  %522 = xor i32 %517, %520
  %523 = xor i32 %517, %521
  %524 = add nuw nsw i32 %522, %523
  %525 = icmp eq i32 %524, 2
  %526 = zext i1 %525 to i8
  store i8 %526, i8* %55, align 1, !tbaa !2450
  %527 = add i64 %2617, -32
  %528 = add i64 %2653, 30
  store i64 %528, i64* %PC, align 8
  %529 = inttoptr i64 %527 to i32*
  store i32 %499, i32* %529, align 4
  %530 = load i64, i64* %RBP, align 8
  %531 = add i64 %530, -36
  %532 = load i64, i64* %PC, align 8
  %533 = add i64 %532, 3
  store i64 %533, i64* %PC, align 8
  %534 = inttoptr i64 %531 to i32*
  %535 = load i32, i32* %534, align 4
  %536 = shl i32 %535, 1
  %537 = icmp slt i32 %535, 0
  %538 = icmp slt i32 %536, 0
  %539 = xor i1 %537, %538
  %540 = zext i32 %536 to i64
  store i64 %540, i64* %RCX, align 8, !tbaa !2428
  %.lobit15 = lshr i32 %535, 31
  %541 = trunc i32 %.lobit15 to i8
  store i8 %541, i8* %50, align 1, !tbaa !2432
  %542 = and i32 %536, 254
  %543 = tail call i32 @llvm.ctpop.i32(i32 %542) #10
  %544 = trunc i32 %543 to i8
  %545 = and i8 %544, 1
  %546 = xor i8 %545, 1
  store i8 %546, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %547 = icmp eq i32 %536, 0
  %548 = zext i1 %547 to i8
  store i8 %548, i8* %53, align 1, !tbaa !2432
  %549 = lshr i32 %535, 30
  %550 = trunc i32 %549 to i8
  %551 = and i8 %550, 1
  store i8 %551, i8* %54, align 1, !tbaa !2432
  %552 = zext i1 %539 to i8
  store i8 %552, i8* %55, align 1, !tbaa !2432
  %553 = add i64 %530, -16
  %554 = add i64 %532, 10
  store i64 %554, i64* %PC, align 8
  %555 = inttoptr i64 %553 to i64*
  %556 = load i64, i64* %555, align 8
  store i64 %556, i64* %RDX, align 8, !tbaa !2428
  %557 = add i64 %530, -28
  %558 = add i64 %532, 14
  store i64 %558, i64* %PC, align 8
  %559 = inttoptr i64 %557 to i32*
  %560 = load i32, i32* %559, align 4
  %561 = sext i32 %560 to i64
  store i64 %561, i64* %RSI, align 8, !tbaa !2428
  %562 = shl nsw i64 %561, 2
  %563 = add i64 %556, %562
  %564 = add i64 %532, 17
  store i64 %564, i64* %PC, align 8
  %565 = inttoptr i64 %563 to i32*
  %566 = load i32, i32* %565, align 4
  %567 = add i32 %566, %536
  %568 = zext i32 %567 to i64
  store i64 %568, i64* %RCX, align 8, !tbaa !2428
  %569 = icmp ult i32 %567, %536
  %570 = icmp ult i32 %567, %566
  %571 = or i1 %569, %570
  %572 = zext i1 %571 to i8
  store i8 %572, i8* %50, align 1, !tbaa !2433
  %573 = and i32 %567, 255
  %574 = tail call i32 @llvm.ctpop.i32(i32 %573) #10
  %575 = trunc i32 %574 to i8
  %576 = and i8 %575, 1
  %577 = xor i8 %576, 1
  store i8 %577, i8* %51, align 1, !tbaa !2447
  %578 = xor i32 %566, %536
  %579 = xor i32 %578, %567
  %580 = lshr i32 %579, 4
  %581 = trunc i32 %580 to i8
  %582 = and i8 %581, 1
  store i8 %582, i8* %52, align 1, !tbaa !2451
  %583 = icmp eq i32 %567, 0
  %584 = zext i1 %583 to i8
  store i8 %584, i8* %53, align 1, !tbaa !2448
  %585 = lshr i32 %567, 31
  %586 = trunc i32 %585 to i8
  store i8 %586, i8* %54, align 1, !tbaa !2449
  %587 = lshr i32 %535, 30
  %588 = and i32 %587, 1
  %589 = lshr i32 %566, 31
  %590 = xor i32 %585, %588
  %591 = xor i32 %585, %589
  %592 = add nuw nsw i32 %590, %591
  %593 = icmp eq i32 %592, 2
  %594 = zext i1 %593 to i8
  store i8 %594, i8* %55, align 1, !tbaa !2450
  %595 = add i64 %530, -40
  %596 = add i64 %532, 20
  store i64 %596, i64* %PC, align 8
  %597 = inttoptr i64 %595 to i32*
  store i32 %567, i32* %597, align 4
  %598 = load i64, i64* %RBP, align 8
  %599 = add i64 %598, -24
  %600 = load i64, i64* %PC, align 8
  %601 = add i64 %600, 4
  store i64 %601, i64* %PC, align 8
  %602 = inttoptr i64 %599 to i64*
  %603 = load i64, i64* %602, align 8
  store i64 %603, i64* %RDX, align 8, !tbaa !2428
  %604 = add i64 %598, -32
  %605 = add i64 %600, 8
  store i64 %605, i64* %PC, align 8
  %606 = inttoptr i64 %604 to i32*
  %607 = load i32, i32* %606, align 4
  %608 = sext i32 %607 to i64
  store i64 %608, i64* %RSI, align 8, !tbaa !2428
  %609 = shl nsw i64 %608, 3
  %610 = add i64 %609, %603
  %611 = add i64 %600, 13
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to i64*
  %613 = load i64, i64* %612, align 8
  store i64 %613, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %614 = add i64 %598, -64
  %615 = add i64 %600, 18
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to i64*
  store i64 %613, i64* %616, align 8
  %617 = load i64, i64* %RBP, align 8
  %618 = add i64 %617, -24
  %619 = load i64, i64* %PC, align 8
  %620 = add i64 %619, 4
  store i64 %620, i64* %PC, align 8
  %621 = inttoptr i64 %618 to i64*
  %622 = load i64, i64* %621, align 8
  store i64 %622, i64* %RDX, align 8, !tbaa !2428
  %623 = add i64 %617, -32
  %624 = add i64 %619, 7
  store i64 %624, i64* %PC, align 8
  %625 = inttoptr i64 %623 to i32*
  %626 = load i32, i32* %625, align 4
  %627 = add i32 %626, 1
  %628 = zext i32 %627 to i64
  store i64 %628, i64* %RCX, align 8, !tbaa !2428
  %629 = icmp eq i32 %626, -1
  %630 = icmp eq i32 %627, 0
  %631 = or i1 %629, %630
  %632 = zext i1 %631 to i8
  store i8 %632, i8* %50, align 1, !tbaa !2433
  %633 = and i32 %627, 255
  %634 = tail call i32 @llvm.ctpop.i32(i32 %633) #10
  %635 = trunc i32 %634 to i8
  %636 = and i8 %635, 1
  %637 = xor i8 %636, 1
  store i8 %637, i8* %51, align 1, !tbaa !2447
  %638 = xor i32 %627, %626
  %639 = lshr i32 %638, 4
  %640 = trunc i32 %639 to i8
  %641 = and i8 %640, 1
  store i8 %641, i8* %52, align 1, !tbaa !2451
  %642 = zext i1 %630 to i8
  store i8 %642, i8* %53, align 1, !tbaa !2448
  %643 = lshr i32 %627, 31
  %644 = trunc i32 %643 to i8
  store i8 %644, i8* %54, align 1, !tbaa !2449
  %645 = lshr i32 %626, 31
  %646 = xor i32 %643, %645
  %647 = add nuw nsw i32 %646, %643
  %648 = icmp eq i32 %647, 2
  %649 = zext i1 %648 to i8
  store i8 %649, i8* %55, align 1, !tbaa !2450
  %650 = sext i32 %627 to i64
  store i64 %650, i64* %RSI, align 8, !tbaa !2428
  %651 = shl nsw i64 %650, 3
  %652 = add i64 %622, %651
  %653 = add i64 %619, 18
  store i64 %653, i64* %PC, align 8
  %654 = inttoptr i64 %652 to i64*
  %655 = load i64, i64* %654, align 8
  %656 = load i64, i64* %RAX, align 8
  %657 = xor i64 %656, %655
  store i64 %657, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %658 = trunc i64 %657 to i32
  %659 = and i32 %658, 255
  %660 = tail call i32 @llvm.ctpop.i32(i32 %659) #10
  %661 = trunc i32 %660 to i8
  %662 = and i8 %661, 1
  %663 = xor i8 %662, 1
  store i8 %663, i8* %51, align 1, !tbaa !2447
  %664 = icmp eq i64 %657, 0
  %665 = zext i1 %664 to i8
  store i8 %665, i8* %53, align 1, !tbaa !2448
  %666 = lshr i64 %657, 63
  %667 = trunc i64 %666 to i8
  store i8 %667, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %657, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %668 = add i64 %617, -72
  %669 = add i64 %619, 36
  store i64 %669, i64* %PC, align 8
  %670 = inttoptr i64 %668 to i64*
  store i64 %657, i64* %670, align 8
  %671 = load i64, i64* %RBP, align 8
  %672 = add i64 %671, -24
  %673 = load i64, i64* %PC, align 8
  %674 = add i64 %673, 4
  store i64 %674, i64* %PC, align 8
  %675 = inttoptr i64 %672 to i64*
  %676 = load i64, i64* %675, align 8
  store i64 %676, i64* %RDX, align 8, !tbaa !2428
  %677 = add i64 %671, -40
  %678 = add i64 %673, 8
  store i64 %678, i64* %PC, align 8
  %679 = inttoptr i64 %677 to i32*
  %680 = load i32, i32* %679, align 4
  %681 = sext i32 %680 to i64
  store i64 %681, i64* %RSI, align 8, !tbaa !2428
  %682 = shl nsw i64 %681, 3
  %683 = add i64 %682, %676
  %684 = add i64 %673, 13
  store i64 %684, i64* %PC, align 8
  %685 = inttoptr i64 %683 to i64*
  %686 = load i64, i64* %685, align 8
  store i64 %686, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %687 = add i64 %671, -80
  %688 = add i64 %673, 18
  store i64 %688, i64* %PC, align 8
  %689 = inttoptr i64 %687 to i64*
  store i64 %686, i64* %689, align 8
  %690 = load i64, i64* %RBP, align 8
  %691 = add i64 %690, -24
  %692 = load i64, i64* %PC, align 8
  %693 = add i64 %692, 4
  store i64 %693, i64* %PC, align 8
  %694 = inttoptr i64 %691 to i64*
  %695 = load i64, i64* %694, align 8
  store i64 %695, i64* %RDX, align 8, !tbaa !2428
  %696 = add i64 %690, -40
  %697 = add i64 %692, 7
  store i64 %697, i64* %PC, align 8
  %698 = inttoptr i64 %696 to i32*
  %699 = load i32, i32* %698, align 4
  %700 = add i32 %699, 1
  %701 = zext i32 %700 to i64
  store i64 %701, i64* %RCX, align 8, !tbaa !2428
  %702 = icmp eq i32 %699, -1
  %703 = icmp eq i32 %700, 0
  %704 = or i1 %702, %703
  %705 = zext i1 %704 to i8
  store i8 %705, i8* %50, align 1, !tbaa !2433
  %706 = and i32 %700, 255
  %707 = tail call i32 @llvm.ctpop.i32(i32 %706) #10
  %708 = trunc i32 %707 to i8
  %709 = and i8 %708, 1
  %710 = xor i8 %709, 1
  store i8 %710, i8* %51, align 1, !tbaa !2447
  %711 = xor i32 %700, %699
  %712 = lshr i32 %711, 4
  %713 = trunc i32 %712 to i8
  %714 = and i8 %713, 1
  store i8 %714, i8* %52, align 1, !tbaa !2451
  %715 = zext i1 %703 to i8
  store i8 %715, i8* %53, align 1, !tbaa !2448
  %716 = lshr i32 %700, 31
  %717 = trunc i32 %716 to i8
  store i8 %717, i8* %54, align 1, !tbaa !2449
  %718 = lshr i32 %699, 31
  %719 = xor i32 %716, %718
  %720 = add nuw nsw i32 %719, %716
  %721 = icmp eq i32 %720, 2
  %722 = zext i1 %721 to i8
  store i8 %722, i8* %55, align 1, !tbaa !2450
  %723 = sext i32 %700 to i64
  store i64 %723, i64* %RSI, align 8, !tbaa !2428
  %724 = shl nsw i64 %723, 3
  %725 = add i64 %695, %724
  %726 = add i64 %692, 18
  store i64 %726, i64* %PC, align 8
  %727 = inttoptr i64 %725 to i64*
  %728 = load i64, i64* %727, align 8
  %729 = load i64, i64* %RAX, align 8
  %730 = xor i64 %729, %728
  store i64 %730, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %731 = trunc i64 %730 to i32
  %732 = and i32 %731, 255
  %733 = tail call i32 @llvm.ctpop.i32(i32 %732) #10
  %734 = trunc i32 %733 to i8
  %735 = and i8 %734, 1
  %736 = xor i8 %735, 1
  store i8 %736, i8* %51, align 1, !tbaa !2447
  %737 = icmp eq i64 %730, 0
  %738 = zext i1 %737 to i8
  store i8 %738, i8* %53, align 1, !tbaa !2448
  %739 = lshr i64 %730, 63
  %740 = trunc i64 %739 to i8
  store i8 %740, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %730, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %741 = add i64 %690, -88
  %742 = add i64 %692, 36
  store i64 %742, i64* %PC, align 8
  %743 = inttoptr i64 %741 to i64*
  store i64 %730, i64* %743, align 8
  %744 = load i64, i64* %RBP, align 8
  %745 = add i64 %744, -80
  %746 = load i64, i64* %PC, align 8
  %747 = add i64 %746, 5
  store i64 %747, i64* %PC, align 8
  %748 = inttoptr i64 %745 to i64*
  %749 = load i64, i64* %748, align 8
  store i64 %749, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %750 = add i64 %744, -24
  %751 = add i64 %746, 9
  store i64 %751, i64* %PC, align 8
  %752 = inttoptr i64 %750 to i64*
  %753 = load i64, i64* %752, align 8
  store i64 %753, i64* %RDX, align 8, !tbaa !2428
  %754 = add i64 %744, -32
  %755 = add i64 %746, 13
  store i64 %755, i64* %PC, align 8
  %756 = inttoptr i64 %754 to i32*
  %757 = load i32, i32* %756, align 4
  %758 = sext i32 %757 to i64
  store i64 %758, i64* %RSI, align 8, !tbaa !2428
  %759 = shl nsw i64 %758, 3
  %760 = add i64 %759, %753
  %761 = add i64 %746, 18
  store i64 %761, i64* %PC, align 8
  %762 = inttoptr i64 %760 to i64*
  store i64 %749, i64* %762, align 8
  %763 = load i64, i64* %RBP, align 8
  %764 = add i64 %763, -88
  %765 = load i64, i64* %PC, align 8
  %766 = add i64 %765, 5
  store i64 %766, i64* %PC, align 8
  %767 = inttoptr i64 %764 to i64*
  %768 = load i64, i64* %767, align 8
  store i64 %768, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %769 = add i64 %763, -24
  %770 = add i64 %765, 9
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %769 to i64*
  %772 = load i64, i64* %771, align 8
  store i64 %772, i64* %RDX, align 8, !tbaa !2428
  %773 = add i64 %763, -32
  %774 = add i64 %765, 12
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to i32*
  %776 = load i32, i32* %775, align 4
  %777 = add i32 %776, 1
  %778 = zext i32 %777 to i64
  store i64 %778, i64* %RCX, align 8, !tbaa !2428
  %779 = icmp eq i32 %776, -1
  %780 = icmp eq i32 %777, 0
  %781 = or i1 %779, %780
  %782 = zext i1 %781 to i8
  store i8 %782, i8* %50, align 1, !tbaa !2433
  %783 = and i32 %777, 255
  %784 = tail call i32 @llvm.ctpop.i32(i32 %783) #10
  %785 = trunc i32 %784 to i8
  %786 = and i8 %785, 1
  %787 = xor i8 %786, 1
  store i8 %787, i8* %51, align 1, !tbaa !2447
  %788 = xor i32 %777, %776
  %789 = lshr i32 %788, 4
  %790 = trunc i32 %789 to i8
  %791 = and i8 %790, 1
  store i8 %791, i8* %52, align 1, !tbaa !2451
  %792 = zext i1 %780 to i8
  store i8 %792, i8* %53, align 1, !tbaa !2448
  %793 = lshr i32 %777, 31
  %794 = trunc i32 %793 to i8
  store i8 %794, i8* %54, align 1, !tbaa !2449
  %795 = lshr i32 %776, 31
  %796 = xor i32 %793, %795
  %797 = add nuw nsw i32 %796, %793
  %798 = icmp eq i32 %797, 2
  %799 = zext i1 %798 to i8
  store i8 %799, i8* %55, align 1, !tbaa !2450
  %800 = sext i32 %777 to i64
  store i64 %800, i64* %RSI, align 8, !tbaa !2428
  %801 = shl nsw i64 %800, 3
  %802 = add i64 %772, %801
  %803 = add i64 %765, 23
  store i64 %803, i64* %PC, align 8
  %804 = inttoptr i64 %802 to i64*
  store i64 %768, i64* %804, align 8
  %805 = load i64, i64* %RBP, align 8
  %806 = add i64 %805, -64
  %807 = load i64, i64* %PC, align 8
  %808 = add i64 %807, 5
  store i64 %808, i64* %PC, align 8
  %809 = inttoptr i64 %806 to i64*
  %810 = load i64, i64* %809, align 8
  store i64 %810, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %811 = add i64 %805, -24
  %812 = add i64 %807, 9
  store i64 %812, i64* %PC, align 8
  %813 = inttoptr i64 %811 to i64*
  %814 = load i64, i64* %813, align 8
  store i64 %814, i64* %RDX, align 8, !tbaa !2428
  %815 = add i64 %805, -40
  %816 = add i64 %807, 13
  store i64 %816, i64* %PC, align 8
  %817 = inttoptr i64 %815 to i32*
  %818 = load i32, i32* %817, align 4
  %819 = sext i32 %818 to i64
  store i64 %819, i64* %RSI, align 8, !tbaa !2428
  %820 = shl nsw i64 %819, 3
  %821 = add i64 %820, %814
  %822 = add i64 %807, 18
  store i64 %822, i64* %PC, align 8
  %823 = inttoptr i64 %821 to i64*
  store i64 %810, i64* %823, align 8
  %824 = load i64, i64* %RBP, align 8
  %825 = add i64 %824, -72
  %826 = load i64, i64* %PC, align 8
  %827 = add i64 %826, 5
  store i64 %827, i64* %PC, align 8
  %828 = inttoptr i64 %825 to i64*
  %829 = load i64, i64* %828, align 8
  store i64 %829, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %830 = add i64 %824, -24
  %831 = add i64 %826, 9
  store i64 %831, i64* %PC, align 8
  %832 = inttoptr i64 %830 to i64*
  %833 = load i64, i64* %832, align 8
  store i64 %833, i64* %RDX, align 8, !tbaa !2428
  %834 = add i64 %824, -40
  %835 = add i64 %826, 12
  store i64 %835, i64* %PC, align 8
  %836 = inttoptr i64 %834 to i32*
  %837 = load i32, i32* %836, align 4
  %838 = add i32 %837, 1
  %839 = zext i32 %838 to i64
  store i64 %839, i64* %RCX, align 8, !tbaa !2428
  %840 = icmp eq i32 %837, -1
  %841 = icmp eq i32 %838, 0
  %842 = or i1 %840, %841
  %843 = zext i1 %842 to i8
  store i8 %843, i8* %50, align 1, !tbaa !2433
  %844 = and i32 %838, 255
  %845 = tail call i32 @llvm.ctpop.i32(i32 %844) #10
  %846 = trunc i32 %845 to i8
  %847 = and i8 %846, 1
  %848 = xor i8 %847, 1
  store i8 %848, i8* %51, align 1, !tbaa !2447
  %849 = xor i32 %838, %837
  %850 = lshr i32 %849, 4
  %851 = trunc i32 %850 to i8
  %852 = and i8 %851, 1
  store i8 %852, i8* %52, align 1, !tbaa !2451
  %853 = zext i1 %841 to i8
  store i8 %853, i8* %53, align 1, !tbaa !2448
  %854 = lshr i32 %838, 31
  %855 = trunc i32 %854 to i8
  store i8 %855, i8* %54, align 1, !tbaa !2449
  %856 = lshr i32 %837, 31
  %857 = xor i32 %854, %856
  %858 = add nuw nsw i32 %857, %854
  %859 = icmp eq i32 %858, 2
  %860 = zext i1 %859 to i8
  store i8 %860, i8* %55, align 1, !tbaa !2450
  %861 = sext i32 %838 to i64
  store i64 %861, i64* %RSI, align 8, !tbaa !2428
  %862 = shl nsw i64 %861, 3
  %863 = add i64 %833, %862
  %864 = add i64 %826, 23
  store i64 %864, i64* %PC, align 8
  %865 = inttoptr i64 %863 to i64*
  store i64 %829, i64* %865, align 8
  %866 = load i64, i64* %RBP, align 8
  %867 = add i64 %866, -52
  %868 = load i64, i64* %PC, align 8
  %869 = add i64 %868, 3
  store i64 %869, i64* %PC, align 8
  %870 = inttoptr i64 %867 to i32*
  %871 = load i32, i32* %870, align 4
  %872 = zext i32 %871 to i64
  store i64 %872, i64* %RCX, align 8, !tbaa !2428
  %873 = add i64 %866, -32
  %874 = add i64 %868, 6
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to i32*
  %876 = load i32, i32* %875, align 4
  %877 = add i32 %876, %871
  %878 = zext i32 %877 to i64
  store i64 %878, i64* %RCX, align 8, !tbaa !2428
  %879 = icmp ult i32 %877, %871
  %880 = icmp ult i32 %877, %876
  %881 = or i1 %879, %880
  %882 = zext i1 %881 to i8
  store i8 %882, i8* %50, align 1, !tbaa !2433
  %883 = and i32 %877, 255
  %884 = tail call i32 @llvm.ctpop.i32(i32 %883) #10
  %885 = trunc i32 %884 to i8
  %886 = and i8 %885, 1
  %887 = xor i8 %886, 1
  store i8 %887, i8* %51, align 1, !tbaa !2447
  %888 = xor i32 %876, %871
  %889 = xor i32 %888, %877
  %890 = lshr i32 %889, 4
  %891 = trunc i32 %890 to i8
  %892 = and i8 %891, 1
  store i8 %892, i8* %52, align 1, !tbaa !2451
  %893 = icmp eq i32 %877, 0
  %894 = zext i1 %893 to i8
  store i8 %894, i8* %53, align 1, !tbaa !2448
  %895 = lshr i32 %877, 31
  %896 = trunc i32 %895 to i8
  store i8 %896, i8* %54, align 1, !tbaa !2449
  %897 = lshr i32 %871, 31
  %898 = lshr i32 %876, 31
  %899 = xor i32 %895, %897
  %900 = xor i32 %895, %898
  %901 = add nuw nsw i32 %899, %900
  %902 = icmp eq i32 %901, 2
  %903 = zext i1 %902 to i8
  store i8 %903, i8* %55, align 1, !tbaa !2450
  %904 = add i64 %868, 9
  store i64 %904, i64* %PC, align 8
  store i32 %877, i32* %875, align 4
  %905 = load i64, i64* %RBP, align 8
  %906 = add i64 %905, -52
  %907 = load i64, i64* %PC, align 8
  %908 = add i64 %907, 3
  store i64 %908, i64* %PC, align 8
  %909 = inttoptr i64 %906 to i32*
  %910 = load i32, i32* %909, align 4
  %911 = shl i32 %910, 1
  %912 = icmp slt i32 %910, 0
  %913 = icmp slt i32 %911, 0
  %914 = xor i1 %912, %913
  %915 = zext i32 %911 to i64
  store i64 %915, i64* %RCX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %910, 31
  %916 = trunc i32 %.lobit16 to i8
  store i8 %916, i8* %50, align 1, !tbaa !2432
  %917 = and i32 %911, 254
  %918 = tail call i32 @llvm.ctpop.i32(i32 %917) #10
  %919 = trunc i32 %918 to i8
  %920 = and i8 %919, 1
  %921 = xor i8 %920, 1
  store i8 %921, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %922 = icmp eq i32 %911, 0
  %923 = zext i1 %922 to i8
  store i8 %923, i8* %53, align 1, !tbaa !2432
  %924 = lshr i32 %910, 30
  %925 = trunc i32 %924 to i8
  %926 = and i8 %925, 1
  store i8 %926, i8* %54, align 1, !tbaa !2432
  %927 = zext i1 %914 to i8
  store i8 %927, i8* %55, align 1, !tbaa !2432
  %928 = add i64 %905, -40
  %929 = add i64 %907, 9
  store i64 %929, i64* %PC, align 8
  %930 = inttoptr i64 %928 to i32*
  %931 = load i32, i32* %930, align 4
  %932 = add i32 %931, %911
  %933 = zext i32 %932 to i64
  store i64 %933, i64* %RCX, align 8, !tbaa !2428
  %934 = icmp ult i32 %932, %911
  %935 = icmp ult i32 %932, %931
  %936 = or i1 %934, %935
  %937 = zext i1 %936 to i8
  store i8 %937, i8* %50, align 1, !tbaa !2433
  %938 = and i32 %932, 255
  %939 = tail call i32 @llvm.ctpop.i32(i32 %938) #10
  %940 = trunc i32 %939 to i8
  %941 = and i8 %940, 1
  %942 = xor i8 %941, 1
  store i8 %942, i8* %51, align 1, !tbaa !2447
  %943 = xor i32 %931, %911
  %944 = xor i32 %943, %932
  %945 = lshr i32 %944, 4
  %946 = trunc i32 %945 to i8
  %947 = and i8 %946, 1
  store i8 %947, i8* %52, align 1, !tbaa !2451
  %948 = icmp eq i32 %932, 0
  %949 = zext i1 %948 to i8
  store i8 %949, i8* %53, align 1, !tbaa !2448
  %950 = lshr i32 %932, 31
  %951 = trunc i32 %950 to i8
  store i8 %951, i8* %54, align 1, !tbaa !2449
  %952 = lshr i32 %910, 30
  %953 = and i32 %952, 1
  %954 = lshr i32 %931, 31
  %955 = xor i32 %950, %953
  %956 = xor i32 %950, %954
  %957 = add nuw nsw i32 %955, %956
  %958 = icmp eq i32 %957, 2
  %959 = zext i1 %958 to i8
  store i8 %959, i8* %55, align 1, !tbaa !2450
  %960 = add i64 %907, 12
  store i64 %960, i64* %PC, align 8
  store i32 %932, i32* %930, align 4
  %961 = load i64, i64* %RBP, align 8
  %962 = add i64 %961, -24
  %963 = load i64, i64* %PC, align 8
  %964 = add i64 %963, 4
  store i64 %964, i64* %PC, align 8
  %965 = inttoptr i64 %962 to i64*
  %966 = load i64, i64* %965, align 8
  store i64 %966, i64* %RDX, align 8, !tbaa !2428
  %967 = add i64 %961, -32
  %968 = add i64 %963, 8
  store i64 %968, i64* %PC, align 8
  %969 = inttoptr i64 %967 to i32*
  %970 = load i32, i32* %969, align 4
  %971 = sext i32 %970 to i64
  store i64 %971, i64* %RSI, align 8, !tbaa !2428
  %972 = shl nsw i64 %971, 3
  %973 = add i64 %972, %966
  %974 = add i64 %963, 13
  store i64 %974, i64* %PC, align 8
  %975 = inttoptr i64 %973 to i64*
  %976 = load i64, i64* %975, align 8
  store i64 %976, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %977 = add i64 %961, -64
  %978 = add i64 %963, 18
  store i64 %978, i64* %PC, align 8
  %979 = inttoptr i64 %977 to i64*
  store i64 %976, i64* %979, align 8
  %980 = load i64, i64* %RBP, align 8
  %981 = add i64 %980, -24
  %982 = load i64, i64* %PC, align 8
  %983 = add i64 %982, 4
  store i64 %983, i64* %PC, align 8
  %984 = inttoptr i64 %981 to i64*
  %985 = load i64, i64* %984, align 8
  store i64 %985, i64* %RDX, align 8, !tbaa !2428
  %986 = add i64 %980, -32
  %987 = add i64 %982, 7
  store i64 %987, i64* %PC, align 8
  %988 = inttoptr i64 %986 to i32*
  %989 = load i32, i32* %988, align 4
  %990 = add i32 %989, 1
  %991 = zext i32 %990 to i64
  store i64 %991, i64* %RCX, align 8, !tbaa !2428
  %992 = icmp eq i32 %989, -1
  %993 = icmp eq i32 %990, 0
  %994 = or i1 %992, %993
  %995 = zext i1 %994 to i8
  store i8 %995, i8* %50, align 1, !tbaa !2433
  %996 = and i32 %990, 255
  %997 = tail call i32 @llvm.ctpop.i32(i32 %996) #10
  %998 = trunc i32 %997 to i8
  %999 = and i8 %998, 1
  %1000 = xor i8 %999, 1
  store i8 %1000, i8* %51, align 1, !tbaa !2447
  %1001 = xor i32 %990, %989
  %1002 = lshr i32 %1001, 4
  %1003 = trunc i32 %1002 to i8
  %1004 = and i8 %1003, 1
  store i8 %1004, i8* %52, align 1, !tbaa !2451
  %1005 = zext i1 %993 to i8
  store i8 %1005, i8* %53, align 1, !tbaa !2448
  %1006 = lshr i32 %990, 31
  %1007 = trunc i32 %1006 to i8
  store i8 %1007, i8* %54, align 1, !tbaa !2449
  %1008 = lshr i32 %989, 31
  %1009 = xor i32 %1006, %1008
  %1010 = add nuw nsw i32 %1009, %1006
  %1011 = icmp eq i32 %1010, 2
  %1012 = zext i1 %1011 to i8
  store i8 %1012, i8* %55, align 1, !tbaa !2450
  %1013 = sext i32 %990 to i64
  store i64 %1013, i64* %RSI, align 8, !tbaa !2428
  %1014 = shl nsw i64 %1013, 3
  %1015 = add i64 %985, %1014
  %1016 = add i64 %982, 18
  store i64 %1016, i64* %PC, align 8
  %1017 = inttoptr i64 %1015 to i64*
  %1018 = load i64, i64* %1017, align 8
  %1019 = load i64, i64* %RAX, align 8
  %1020 = xor i64 %1019, %1018
  store i64 %1020, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %1021 = trunc i64 %1020 to i32
  %1022 = and i32 %1021, 255
  %1023 = tail call i32 @llvm.ctpop.i32(i32 %1022) #10
  %1024 = trunc i32 %1023 to i8
  %1025 = and i8 %1024, 1
  %1026 = xor i8 %1025, 1
  store i8 %1026, i8* %51, align 1, !tbaa !2447
  %1027 = icmp eq i64 %1020, 0
  %1028 = zext i1 %1027 to i8
  store i8 %1028, i8* %53, align 1, !tbaa !2448
  %1029 = lshr i64 %1020, 63
  %1030 = trunc i64 %1029 to i8
  store i8 %1030, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %1020, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %1031 = add i64 %980, -72
  %1032 = add i64 %982, 36
  store i64 %1032, i64* %PC, align 8
  %1033 = inttoptr i64 %1031 to i64*
  store i64 %1020, i64* %1033, align 8
  %1034 = load i64, i64* %RBP, align 8
  %1035 = add i64 %1034, -24
  %1036 = load i64, i64* %PC, align 8
  %1037 = add i64 %1036, 4
  store i64 %1037, i64* %PC, align 8
  %1038 = inttoptr i64 %1035 to i64*
  %1039 = load i64, i64* %1038, align 8
  store i64 %1039, i64* %RDX, align 8, !tbaa !2428
  %1040 = add i64 %1034, -40
  %1041 = add i64 %1036, 8
  store i64 %1041, i64* %PC, align 8
  %1042 = inttoptr i64 %1040 to i32*
  %1043 = load i32, i32* %1042, align 4
  %1044 = sext i32 %1043 to i64
  store i64 %1044, i64* %RSI, align 8, !tbaa !2428
  %1045 = shl nsw i64 %1044, 3
  %1046 = add i64 %1045, %1039
  %1047 = add i64 %1036, 13
  store i64 %1047, i64* %PC, align 8
  %1048 = inttoptr i64 %1046 to i64*
  %1049 = load i64, i64* %1048, align 8
  store i64 %1049, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1050 = add i64 %1034, -80
  %1051 = add i64 %1036, 18
  store i64 %1051, i64* %PC, align 8
  %1052 = inttoptr i64 %1050 to i64*
  store i64 %1049, i64* %1052, align 8
  %1053 = load i64, i64* %RBP, align 8
  %1054 = add i64 %1053, -24
  %1055 = load i64, i64* %PC, align 8
  %1056 = add i64 %1055, 4
  store i64 %1056, i64* %PC, align 8
  %1057 = inttoptr i64 %1054 to i64*
  %1058 = load i64, i64* %1057, align 8
  store i64 %1058, i64* %RDX, align 8, !tbaa !2428
  %1059 = add i64 %1053, -40
  %1060 = add i64 %1055, 7
  store i64 %1060, i64* %PC, align 8
  %1061 = inttoptr i64 %1059 to i32*
  %1062 = load i32, i32* %1061, align 4
  %1063 = add i32 %1062, 1
  %1064 = zext i32 %1063 to i64
  store i64 %1064, i64* %RCX, align 8, !tbaa !2428
  %1065 = icmp eq i32 %1062, -1
  %1066 = icmp eq i32 %1063, 0
  %1067 = or i1 %1065, %1066
  %1068 = zext i1 %1067 to i8
  store i8 %1068, i8* %50, align 1, !tbaa !2433
  %1069 = and i32 %1063, 255
  %1070 = tail call i32 @llvm.ctpop.i32(i32 %1069) #10
  %1071 = trunc i32 %1070 to i8
  %1072 = and i8 %1071, 1
  %1073 = xor i8 %1072, 1
  store i8 %1073, i8* %51, align 1, !tbaa !2447
  %1074 = xor i32 %1063, %1062
  %1075 = lshr i32 %1074, 4
  %1076 = trunc i32 %1075 to i8
  %1077 = and i8 %1076, 1
  store i8 %1077, i8* %52, align 1, !tbaa !2451
  %1078 = zext i1 %1066 to i8
  store i8 %1078, i8* %53, align 1, !tbaa !2448
  %1079 = lshr i32 %1063, 31
  %1080 = trunc i32 %1079 to i8
  store i8 %1080, i8* %54, align 1, !tbaa !2449
  %1081 = lshr i32 %1062, 31
  %1082 = xor i32 %1079, %1081
  %1083 = add nuw nsw i32 %1082, %1079
  %1084 = icmp eq i32 %1083, 2
  %1085 = zext i1 %1084 to i8
  store i8 %1085, i8* %55, align 1, !tbaa !2450
  %1086 = sext i32 %1063 to i64
  store i64 %1086, i64* %RSI, align 8, !tbaa !2428
  %1087 = shl nsw i64 %1086, 3
  %1088 = add i64 %1058, %1087
  %1089 = add i64 %1055, 18
  store i64 %1089, i64* %PC, align 8
  %1090 = inttoptr i64 %1088 to i64*
  %1091 = load i64, i64* %1090, align 8
  %1092 = load i64, i64* %RAX, align 8
  %1093 = xor i64 %1092, %1091
  store i64 %1093, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %1094 = trunc i64 %1093 to i32
  %1095 = and i32 %1094, 255
  %1096 = tail call i32 @llvm.ctpop.i32(i32 %1095) #10
  %1097 = trunc i32 %1096 to i8
  %1098 = and i8 %1097, 1
  %1099 = xor i8 %1098, 1
  store i8 %1099, i8* %51, align 1, !tbaa !2447
  %1100 = icmp eq i64 %1093, 0
  %1101 = zext i1 %1100 to i8
  store i8 %1101, i8* %53, align 1, !tbaa !2448
  %1102 = lshr i64 %1093, 63
  %1103 = trunc i64 %1102 to i8
  store i8 %1103, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %1093, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %1104 = add i64 %1053, -88
  %1105 = add i64 %1055, 36
  store i64 %1105, i64* %PC, align 8
  %1106 = inttoptr i64 %1104 to i64*
  store i64 %1093, i64* %1106, align 8
  %1107 = load i64, i64* %RBP, align 8
  %1108 = add i64 %1107, -80
  %1109 = load i64, i64* %PC, align 8
  %1110 = add i64 %1109, 5
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1108 to i64*
  %1112 = load i64, i64* %1111, align 8
  store i64 %1112, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1113 = add i64 %1107, -24
  %1114 = add i64 %1109, 9
  store i64 %1114, i64* %PC, align 8
  %1115 = inttoptr i64 %1113 to i64*
  %1116 = load i64, i64* %1115, align 8
  store i64 %1116, i64* %RDX, align 8, !tbaa !2428
  %1117 = add i64 %1107, -32
  %1118 = add i64 %1109, 13
  store i64 %1118, i64* %PC, align 8
  %1119 = inttoptr i64 %1117 to i32*
  %1120 = load i32, i32* %1119, align 4
  %1121 = sext i32 %1120 to i64
  store i64 %1121, i64* %RSI, align 8, !tbaa !2428
  %1122 = shl nsw i64 %1121, 3
  %1123 = add i64 %1122, %1116
  %1124 = add i64 %1109, 18
  store i64 %1124, i64* %PC, align 8
  %1125 = inttoptr i64 %1123 to i64*
  store i64 %1112, i64* %1125, align 8
  %1126 = load i64, i64* %RBP, align 8
  %1127 = add i64 %1126, -88
  %1128 = load i64, i64* %PC, align 8
  %1129 = add i64 %1128, 5
  store i64 %1129, i64* %PC, align 8
  %1130 = inttoptr i64 %1127 to i64*
  %1131 = load i64, i64* %1130, align 8
  store i64 %1131, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1132 = add i64 %1126, -24
  %1133 = add i64 %1128, 9
  store i64 %1133, i64* %PC, align 8
  %1134 = inttoptr i64 %1132 to i64*
  %1135 = load i64, i64* %1134, align 8
  store i64 %1135, i64* %RDX, align 8, !tbaa !2428
  %1136 = add i64 %1126, -32
  %1137 = add i64 %1128, 12
  store i64 %1137, i64* %PC, align 8
  %1138 = inttoptr i64 %1136 to i32*
  %1139 = load i32, i32* %1138, align 4
  %1140 = add i32 %1139, 1
  %1141 = zext i32 %1140 to i64
  store i64 %1141, i64* %RCX, align 8, !tbaa !2428
  %1142 = icmp eq i32 %1139, -1
  %1143 = icmp eq i32 %1140, 0
  %1144 = or i1 %1142, %1143
  %1145 = zext i1 %1144 to i8
  store i8 %1145, i8* %50, align 1, !tbaa !2433
  %1146 = and i32 %1140, 255
  %1147 = tail call i32 @llvm.ctpop.i32(i32 %1146) #10
  %1148 = trunc i32 %1147 to i8
  %1149 = and i8 %1148, 1
  %1150 = xor i8 %1149, 1
  store i8 %1150, i8* %51, align 1, !tbaa !2447
  %1151 = xor i32 %1140, %1139
  %1152 = lshr i32 %1151, 4
  %1153 = trunc i32 %1152 to i8
  %1154 = and i8 %1153, 1
  store i8 %1154, i8* %52, align 1, !tbaa !2451
  %1155 = zext i1 %1143 to i8
  store i8 %1155, i8* %53, align 1, !tbaa !2448
  %1156 = lshr i32 %1140, 31
  %1157 = trunc i32 %1156 to i8
  store i8 %1157, i8* %54, align 1, !tbaa !2449
  %1158 = lshr i32 %1139, 31
  %1159 = xor i32 %1156, %1158
  %1160 = add nuw nsw i32 %1159, %1156
  %1161 = icmp eq i32 %1160, 2
  %1162 = zext i1 %1161 to i8
  store i8 %1162, i8* %55, align 1, !tbaa !2450
  %1163 = sext i32 %1140 to i64
  store i64 %1163, i64* %RSI, align 8, !tbaa !2428
  %1164 = shl nsw i64 %1163, 3
  %1165 = add i64 %1135, %1164
  %1166 = add i64 %1128, 23
  store i64 %1166, i64* %PC, align 8
  %1167 = inttoptr i64 %1165 to i64*
  store i64 %1131, i64* %1167, align 8
  %1168 = load i64, i64* %RBP, align 8
  %1169 = add i64 %1168, -64
  %1170 = load i64, i64* %PC, align 8
  %1171 = add i64 %1170, 5
  store i64 %1171, i64* %PC, align 8
  %1172 = inttoptr i64 %1169 to i64*
  %1173 = load i64, i64* %1172, align 8
  store i64 %1173, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1174 = add i64 %1168, -24
  %1175 = add i64 %1170, 9
  store i64 %1175, i64* %PC, align 8
  %1176 = inttoptr i64 %1174 to i64*
  %1177 = load i64, i64* %1176, align 8
  store i64 %1177, i64* %RDX, align 8, !tbaa !2428
  %1178 = add i64 %1168, -40
  %1179 = add i64 %1170, 13
  store i64 %1179, i64* %PC, align 8
  %1180 = inttoptr i64 %1178 to i32*
  %1181 = load i32, i32* %1180, align 4
  %1182 = sext i32 %1181 to i64
  store i64 %1182, i64* %RSI, align 8, !tbaa !2428
  %1183 = shl nsw i64 %1182, 3
  %1184 = add i64 %1183, %1177
  %1185 = add i64 %1170, 18
  store i64 %1185, i64* %PC, align 8
  %1186 = inttoptr i64 %1184 to i64*
  store i64 %1173, i64* %1186, align 8
  %1187 = load i64, i64* %RBP, align 8
  %1188 = add i64 %1187, -72
  %1189 = load i64, i64* %PC, align 8
  %1190 = add i64 %1189, 5
  store i64 %1190, i64* %PC, align 8
  %1191 = inttoptr i64 %1188 to i64*
  %1192 = load i64, i64* %1191, align 8
  store i64 %1192, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1193 = add i64 %1187, -24
  %1194 = add i64 %1189, 9
  store i64 %1194, i64* %PC, align 8
  %1195 = inttoptr i64 %1193 to i64*
  %1196 = load i64, i64* %1195, align 8
  store i64 %1196, i64* %RDX, align 8, !tbaa !2428
  %1197 = add i64 %1187, -40
  %1198 = add i64 %1189, 12
  store i64 %1198, i64* %PC, align 8
  %1199 = inttoptr i64 %1197 to i32*
  %1200 = load i32, i32* %1199, align 4
  %1201 = add i32 %1200, 1
  %1202 = zext i32 %1201 to i64
  store i64 %1202, i64* %RCX, align 8, !tbaa !2428
  %1203 = icmp eq i32 %1200, -1
  %1204 = icmp eq i32 %1201, 0
  %1205 = or i1 %1203, %1204
  %1206 = zext i1 %1205 to i8
  store i8 %1206, i8* %50, align 1, !tbaa !2433
  %1207 = and i32 %1201, 255
  %1208 = tail call i32 @llvm.ctpop.i32(i32 %1207) #10
  %1209 = trunc i32 %1208 to i8
  %1210 = and i8 %1209, 1
  %1211 = xor i8 %1210, 1
  store i8 %1211, i8* %51, align 1, !tbaa !2447
  %1212 = xor i32 %1201, %1200
  %1213 = lshr i32 %1212, 4
  %1214 = trunc i32 %1213 to i8
  %1215 = and i8 %1214, 1
  store i8 %1215, i8* %52, align 1, !tbaa !2451
  %1216 = zext i1 %1204 to i8
  store i8 %1216, i8* %53, align 1, !tbaa !2448
  %1217 = lshr i32 %1201, 31
  %1218 = trunc i32 %1217 to i8
  store i8 %1218, i8* %54, align 1, !tbaa !2449
  %1219 = lshr i32 %1200, 31
  %1220 = xor i32 %1217, %1219
  %1221 = add nuw nsw i32 %1220, %1217
  %1222 = icmp eq i32 %1221, 2
  %1223 = zext i1 %1222 to i8
  store i8 %1223, i8* %55, align 1, !tbaa !2450
  %1224 = sext i32 %1201 to i64
  store i64 %1224, i64* %RSI, align 8, !tbaa !2428
  %1225 = shl nsw i64 %1224, 3
  %1226 = add i64 %1196, %1225
  %1227 = add i64 %1189, 23
  store i64 %1227, i64* %PC, align 8
  %1228 = inttoptr i64 %1226 to i64*
  store i64 %1192, i64* %1228, align 8
  %1229 = load i64, i64* %RBP, align 8
  %1230 = add i64 %1229, -52
  %1231 = load i64, i64* %PC, align 8
  %1232 = add i64 %1231, 3
  store i64 %1232, i64* %PC, align 8
  %1233 = inttoptr i64 %1230 to i32*
  %1234 = load i32, i32* %1233, align 4
  %1235 = zext i32 %1234 to i64
  store i64 %1235, i64* %RCX, align 8, !tbaa !2428
  %1236 = add i64 %1229, -32
  %1237 = add i64 %1231, 6
  store i64 %1237, i64* %PC, align 8
  %1238 = inttoptr i64 %1236 to i32*
  %1239 = load i32, i32* %1238, align 4
  %1240 = add i32 %1239, %1234
  %1241 = zext i32 %1240 to i64
  store i64 %1241, i64* %RCX, align 8, !tbaa !2428
  %1242 = icmp ult i32 %1240, %1234
  %1243 = icmp ult i32 %1240, %1239
  %1244 = or i1 %1242, %1243
  %1245 = zext i1 %1244 to i8
  store i8 %1245, i8* %50, align 1, !tbaa !2433
  %1246 = and i32 %1240, 255
  %1247 = tail call i32 @llvm.ctpop.i32(i32 %1246) #10
  %1248 = trunc i32 %1247 to i8
  %1249 = and i8 %1248, 1
  %1250 = xor i8 %1249, 1
  store i8 %1250, i8* %51, align 1, !tbaa !2447
  %1251 = xor i32 %1239, %1234
  %1252 = xor i32 %1251, %1240
  %1253 = lshr i32 %1252, 4
  %1254 = trunc i32 %1253 to i8
  %1255 = and i8 %1254, 1
  store i8 %1255, i8* %52, align 1, !tbaa !2451
  %1256 = icmp eq i32 %1240, 0
  %1257 = zext i1 %1256 to i8
  store i8 %1257, i8* %53, align 1, !tbaa !2448
  %1258 = lshr i32 %1240, 31
  %1259 = trunc i32 %1258 to i8
  store i8 %1259, i8* %54, align 1, !tbaa !2449
  %1260 = lshr i32 %1234, 31
  %1261 = lshr i32 %1239, 31
  %1262 = xor i32 %1258, %1260
  %1263 = xor i32 %1258, %1261
  %1264 = add nuw nsw i32 %1262, %1263
  %1265 = icmp eq i32 %1264, 2
  %1266 = zext i1 %1265 to i8
  store i8 %1266, i8* %55, align 1, !tbaa !2450
  %1267 = add i64 %1231, 9
  store i64 %1267, i64* %PC, align 8
  store i32 %1240, i32* %1238, align 4
  %1268 = load i64, i64* %RBP, align 8
  %1269 = add i64 %1268, -52
  %1270 = load i64, i64* %PC, align 8
  %1271 = add i64 %1270, 3
  store i64 %1271, i64* %PC, align 8
  %1272 = inttoptr i64 %1269 to i32*
  %1273 = load i32, i32* %1272, align 4
  %1274 = zext i32 %1273 to i64
  store i64 %1274, i64* %RCX, align 8, !tbaa !2428
  %1275 = add i64 %1268, -40
  %1276 = add i64 %1270, 6
  store i64 %1276, i64* %PC, align 8
  %1277 = inttoptr i64 %1275 to i32*
  %1278 = load i32, i32* %1277, align 4
  %1279 = sub i32 %1278, %1273
  %1280 = zext i32 %1279 to i64
  store i64 %1280, i64* %RDI, align 8, !tbaa !2428
  %1281 = icmp ult i32 %1278, %1273
  %1282 = zext i1 %1281 to i8
  store i8 %1282, i8* %50, align 1, !tbaa !2433
  %1283 = and i32 %1279, 255
  %1284 = tail call i32 @llvm.ctpop.i32(i32 %1283) #10
  %1285 = trunc i32 %1284 to i8
  %1286 = and i8 %1285, 1
  %1287 = xor i8 %1286, 1
  store i8 %1287, i8* %51, align 1, !tbaa !2447
  %1288 = xor i32 %1273, %1278
  %1289 = xor i32 %1288, %1279
  %1290 = lshr i32 %1289, 4
  %1291 = trunc i32 %1290 to i8
  %1292 = and i8 %1291, 1
  store i8 %1292, i8* %52, align 1, !tbaa !2451
  %1293 = icmp eq i32 %1279, 0
  %1294 = zext i1 %1293 to i8
  store i8 %1294, i8* %53, align 1, !tbaa !2448
  %1295 = lshr i32 %1279, 31
  %1296 = trunc i32 %1295 to i8
  store i8 %1296, i8* %54, align 1, !tbaa !2449
  %1297 = lshr i32 %1278, 31
  %1298 = lshr i32 %1273, 31
  %1299 = xor i32 %1298, %1297
  %1300 = xor i32 %1295, %1297
  %1301 = add nuw nsw i32 %1300, %1299
  %1302 = icmp eq i32 %1301, 2
  %1303 = zext i1 %1302 to i8
  store i8 %1303, i8* %55, align 1, !tbaa !2450
  %1304 = add i64 %1270, 11
  store i64 %1304, i64* %PC, align 8
  store i32 %1279, i32* %1277, align 4
  %1305 = load i64, i64* %RBP, align 8
  %1306 = add i64 %1305, -24
  %1307 = load i64, i64* %PC, align 8
  %1308 = add i64 %1307, 4
  store i64 %1308, i64* %PC, align 8
  %1309 = inttoptr i64 %1306 to i64*
  %1310 = load i64, i64* %1309, align 8
  store i64 %1310, i64* %RDX, align 8, !tbaa !2428
  %1311 = add i64 %1305, -32
  %1312 = add i64 %1307, 8
  store i64 %1312, i64* %PC, align 8
  %1313 = inttoptr i64 %1311 to i32*
  %1314 = load i32, i32* %1313, align 4
  %1315 = sext i32 %1314 to i64
  store i64 %1315, i64* %RSI, align 8, !tbaa !2428
  %1316 = shl nsw i64 %1315, 3
  %1317 = add i64 %1316, %1310
  %1318 = add i64 %1307, 13
  store i64 %1318, i64* %PC, align 8
  %1319 = inttoptr i64 %1317 to i64*
  %1320 = load i64, i64* %1319, align 8
  store i64 %1320, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1321 = add i64 %1305, -64
  %1322 = add i64 %1307, 18
  store i64 %1322, i64* %PC, align 8
  %1323 = inttoptr i64 %1321 to i64*
  store i64 %1320, i64* %1323, align 8
  %1324 = load i64, i64* %RBP, align 8
  %1325 = add i64 %1324, -24
  %1326 = load i64, i64* %PC, align 8
  %1327 = add i64 %1326, 4
  store i64 %1327, i64* %PC, align 8
  %1328 = inttoptr i64 %1325 to i64*
  %1329 = load i64, i64* %1328, align 8
  store i64 %1329, i64* %RDX, align 8, !tbaa !2428
  %1330 = add i64 %1324, -32
  %1331 = add i64 %1326, 7
  store i64 %1331, i64* %PC, align 8
  %1332 = inttoptr i64 %1330 to i32*
  %1333 = load i32, i32* %1332, align 4
  %1334 = add i32 %1333, 1
  %1335 = zext i32 %1334 to i64
  store i64 %1335, i64* %RCX, align 8, !tbaa !2428
  %1336 = icmp eq i32 %1333, -1
  %1337 = icmp eq i32 %1334, 0
  %1338 = or i1 %1336, %1337
  %1339 = zext i1 %1338 to i8
  store i8 %1339, i8* %50, align 1, !tbaa !2433
  %1340 = and i32 %1334, 255
  %1341 = tail call i32 @llvm.ctpop.i32(i32 %1340) #10
  %1342 = trunc i32 %1341 to i8
  %1343 = and i8 %1342, 1
  %1344 = xor i8 %1343, 1
  store i8 %1344, i8* %51, align 1, !tbaa !2447
  %1345 = xor i32 %1334, %1333
  %1346 = lshr i32 %1345, 4
  %1347 = trunc i32 %1346 to i8
  %1348 = and i8 %1347, 1
  store i8 %1348, i8* %52, align 1, !tbaa !2451
  %1349 = zext i1 %1337 to i8
  store i8 %1349, i8* %53, align 1, !tbaa !2448
  %1350 = lshr i32 %1334, 31
  %1351 = trunc i32 %1350 to i8
  store i8 %1351, i8* %54, align 1, !tbaa !2449
  %1352 = lshr i32 %1333, 31
  %1353 = xor i32 %1350, %1352
  %1354 = add nuw nsw i32 %1353, %1350
  %1355 = icmp eq i32 %1354, 2
  %1356 = zext i1 %1355 to i8
  store i8 %1356, i8* %55, align 1, !tbaa !2450
  %1357 = sext i32 %1334 to i64
  store i64 %1357, i64* %RSI, align 8, !tbaa !2428
  %1358 = shl nsw i64 %1357, 3
  %1359 = add i64 %1329, %1358
  %1360 = add i64 %1326, 18
  store i64 %1360, i64* %PC, align 8
  %1361 = inttoptr i64 %1359 to i64*
  %1362 = load i64, i64* %1361, align 8
  %1363 = load i64, i64* %RAX, align 8
  %1364 = xor i64 %1363, %1362
  store i64 %1364, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %1365 = trunc i64 %1364 to i32
  %1366 = and i32 %1365, 255
  %1367 = tail call i32 @llvm.ctpop.i32(i32 %1366) #10
  %1368 = trunc i32 %1367 to i8
  %1369 = and i8 %1368, 1
  %1370 = xor i8 %1369, 1
  store i8 %1370, i8* %51, align 1, !tbaa !2447
  %1371 = icmp eq i64 %1364, 0
  %1372 = zext i1 %1371 to i8
  store i8 %1372, i8* %53, align 1, !tbaa !2448
  %1373 = lshr i64 %1364, 63
  %1374 = trunc i64 %1373 to i8
  store i8 %1374, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %1364, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %1375 = add i64 %1324, -72
  %1376 = add i64 %1326, 36
  store i64 %1376, i64* %PC, align 8
  %1377 = inttoptr i64 %1375 to i64*
  store i64 %1364, i64* %1377, align 8
  %1378 = load i64, i64* %RBP, align 8
  %1379 = add i64 %1378, -24
  %1380 = load i64, i64* %PC, align 8
  %1381 = add i64 %1380, 4
  store i64 %1381, i64* %PC, align 8
  %1382 = inttoptr i64 %1379 to i64*
  %1383 = load i64, i64* %1382, align 8
  store i64 %1383, i64* %RDX, align 8, !tbaa !2428
  %1384 = add i64 %1378, -40
  %1385 = add i64 %1380, 8
  store i64 %1385, i64* %PC, align 8
  %1386 = inttoptr i64 %1384 to i32*
  %1387 = load i32, i32* %1386, align 4
  %1388 = sext i32 %1387 to i64
  store i64 %1388, i64* %RSI, align 8, !tbaa !2428
  %1389 = shl nsw i64 %1388, 3
  %1390 = add i64 %1389, %1383
  %1391 = add i64 %1380, 13
  store i64 %1391, i64* %PC, align 8
  %1392 = inttoptr i64 %1390 to i64*
  %1393 = load i64, i64* %1392, align 8
  store i64 %1393, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1394 = add i64 %1378, -80
  %1395 = add i64 %1380, 18
  store i64 %1395, i64* %PC, align 8
  %1396 = inttoptr i64 %1394 to i64*
  store i64 %1393, i64* %1396, align 8
  %1397 = load i64, i64* %RBP, align 8
  %1398 = add i64 %1397, -24
  %1399 = load i64, i64* %PC, align 8
  %1400 = add i64 %1399, 4
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1398 to i64*
  %1402 = load i64, i64* %1401, align 8
  store i64 %1402, i64* %RDX, align 8, !tbaa !2428
  %1403 = add i64 %1397, -40
  %1404 = add i64 %1399, 7
  store i64 %1404, i64* %PC, align 8
  %1405 = inttoptr i64 %1403 to i32*
  %1406 = load i32, i32* %1405, align 4
  %1407 = add i32 %1406, 1
  %1408 = zext i32 %1407 to i64
  store i64 %1408, i64* %RCX, align 8, !tbaa !2428
  %1409 = icmp eq i32 %1406, -1
  %1410 = icmp eq i32 %1407, 0
  %1411 = or i1 %1409, %1410
  %1412 = zext i1 %1411 to i8
  store i8 %1412, i8* %50, align 1, !tbaa !2433
  %1413 = and i32 %1407, 255
  %1414 = tail call i32 @llvm.ctpop.i32(i32 %1413) #10
  %1415 = trunc i32 %1414 to i8
  %1416 = and i8 %1415, 1
  %1417 = xor i8 %1416, 1
  store i8 %1417, i8* %51, align 1, !tbaa !2447
  %1418 = xor i32 %1407, %1406
  %1419 = lshr i32 %1418, 4
  %1420 = trunc i32 %1419 to i8
  %1421 = and i8 %1420, 1
  store i8 %1421, i8* %52, align 1, !tbaa !2451
  %1422 = zext i1 %1410 to i8
  store i8 %1422, i8* %53, align 1, !tbaa !2448
  %1423 = lshr i32 %1407, 31
  %1424 = trunc i32 %1423 to i8
  store i8 %1424, i8* %54, align 1, !tbaa !2449
  %1425 = lshr i32 %1406, 31
  %1426 = xor i32 %1423, %1425
  %1427 = add nuw nsw i32 %1426, %1423
  %1428 = icmp eq i32 %1427, 2
  %1429 = zext i1 %1428 to i8
  store i8 %1429, i8* %55, align 1, !tbaa !2450
  %1430 = sext i32 %1407 to i64
  store i64 %1430, i64* %RSI, align 8, !tbaa !2428
  %1431 = shl nsw i64 %1430, 3
  %1432 = add i64 %1402, %1431
  %1433 = add i64 %1399, 18
  store i64 %1433, i64* %PC, align 8
  %1434 = inttoptr i64 %1432 to i64*
  %1435 = load i64, i64* %1434, align 8
  %1436 = load i64, i64* %RAX, align 8
  %1437 = xor i64 %1436, %1435
  store i64 %1437, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %1438 = trunc i64 %1437 to i32
  %1439 = and i32 %1438, 255
  %1440 = tail call i32 @llvm.ctpop.i32(i32 %1439) #10
  %1441 = trunc i32 %1440 to i8
  %1442 = and i8 %1441, 1
  %1443 = xor i8 %1442, 1
  store i8 %1443, i8* %51, align 1, !tbaa !2447
  %1444 = icmp eq i64 %1437, 0
  %1445 = zext i1 %1444 to i8
  store i8 %1445, i8* %53, align 1, !tbaa !2448
  %1446 = lshr i64 %1437, 63
  %1447 = trunc i64 %1446 to i8
  store i8 %1447, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %1437, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %1448 = add i64 %1397, -88
  %1449 = add i64 %1399, 36
  store i64 %1449, i64* %PC, align 8
  %1450 = inttoptr i64 %1448 to i64*
  store i64 %1437, i64* %1450, align 8
  %1451 = load i64, i64* %RBP, align 8
  %1452 = add i64 %1451, -80
  %1453 = load i64, i64* %PC, align 8
  %1454 = add i64 %1453, 5
  store i64 %1454, i64* %PC, align 8
  %1455 = inttoptr i64 %1452 to i64*
  %1456 = load i64, i64* %1455, align 8
  store i64 %1456, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1457 = add i64 %1451, -24
  %1458 = add i64 %1453, 9
  store i64 %1458, i64* %PC, align 8
  %1459 = inttoptr i64 %1457 to i64*
  %1460 = load i64, i64* %1459, align 8
  store i64 %1460, i64* %RDX, align 8, !tbaa !2428
  %1461 = add i64 %1451, -32
  %1462 = add i64 %1453, 13
  store i64 %1462, i64* %PC, align 8
  %1463 = inttoptr i64 %1461 to i32*
  %1464 = load i32, i32* %1463, align 4
  %1465 = sext i32 %1464 to i64
  store i64 %1465, i64* %RSI, align 8, !tbaa !2428
  %1466 = shl nsw i64 %1465, 3
  %1467 = add i64 %1466, %1460
  %1468 = add i64 %1453, 18
  store i64 %1468, i64* %PC, align 8
  %1469 = inttoptr i64 %1467 to i64*
  store i64 %1456, i64* %1469, align 8
  %1470 = load i64, i64* %RBP, align 8
  %1471 = add i64 %1470, -88
  %1472 = load i64, i64* %PC, align 8
  %1473 = add i64 %1472, 5
  store i64 %1473, i64* %PC, align 8
  %1474 = inttoptr i64 %1471 to i64*
  %1475 = load i64, i64* %1474, align 8
  store i64 %1475, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1476 = add i64 %1470, -24
  %1477 = add i64 %1472, 9
  store i64 %1477, i64* %PC, align 8
  %1478 = inttoptr i64 %1476 to i64*
  %1479 = load i64, i64* %1478, align 8
  store i64 %1479, i64* %RDX, align 8, !tbaa !2428
  %1480 = add i64 %1470, -32
  %1481 = add i64 %1472, 12
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to i32*
  %1483 = load i32, i32* %1482, align 4
  %1484 = add i32 %1483, 1
  %1485 = zext i32 %1484 to i64
  store i64 %1485, i64* %RCX, align 8, !tbaa !2428
  %1486 = icmp eq i32 %1483, -1
  %1487 = icmp eq i32 %1484, 0
  %1488 = or i1 %1486, %1487
  %1489 = zext i1 %1488 to i8
  store i8 %1489, i8* %50, align 1, !tbaa !2433
  %1490 = and i32 %1484, 255
  %1491 = tail call i32 @llvm.ctpop.i32(i32 %1490) #10
  %1492 = trunc i32 %1491 to i8
  %1493 = and i8 %1492, 1
  %1494 = xor i8 %1493, 1
  store i8 %1494, i8* %51, align 1, !tbaa !2447
  %1495 = xor i32 %1484, %1483
  %1496 = lshr i32 %1495, 4
  %1497 = trunc i32 %1496 to i8
  %1498 = and i8 %1497, 1
  store i8 %1498, i8* %52, align 1, !tbaa !2451
  %1499 = zext i1 %1487 to i8
  store i8 %1499, i8* %53, align 1, !tbaa !2448
  %1500 = lshr i32 %1484, 31
  %1501 = trunc i32 %1500 to i8
  store i8 %1501, i8* %54, align 1, !tbaa !2449
  %1502 = lshr i32 %1483, 31
  %1503 = xor i32 %1500, %1502
  %1504 = add nuw nsw i32 %1503, %1500
  %1505 = icmp eq i32 %1504, 2
  %1506 = zext i1 %1505 to i8
  store i8 %1506, i8* %55, align 1, !tbaa !2450
  %1507 = sext i32 %1484 to i64
  store i64 %1507, i64* %RSI, align 8, !tbaa !2428
  %1508 = shl nsw i64 %1507, 3
  %1509 = add i64 %1479, %1508
  %1510 = add i64 %1472, 23
  store i64 %1510, i64* %PC, align 8
  %1511 = inttoptr i64 %1509 to i64*
  store i64 %1475, i64* %1511, align 8
  %1512 = load i64, i64* %RBP, align 8
  %1513 = add i64 %1512, -64
  %1514 = load i64, i64* %PC, align 8
  %1515 = add i64 %1514, 5
  store i64 %1515, i64* %PC, align 8
  %1516 = inttoptr i64 %1513 to i64*
  %1517 = load i64, i64* %1516, align 8
  store i64 %1517, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1518 = add i64 %1512, -24
  %1519 = add i64 %1514, 9
  store i64 %1519, i64* %PC, align 8
  %1520 = inttoptr i64 %1518 to i64*
  %1521 = load i64, i64* %1520, align 8
  store i64 %1521, i64* %RDX, align 8, !tbaa !2428
  %1522 = add i64 %1512, -40
  %1523 = add i64 %1514, 13
  store i64 %1523, i64* %PC, align 8
  %1524 = inttoptr i64 %1522 to i32*
  %1525 = load i32, i32* %1524, align 4
  %1526 = sext i32 %1525 to i64
  store i64 %1526, i64* %RSI, align 8, !tbaa !2428
  %1527 = shl nsw i64 %1526, 3
  %1528 = add i64 %1527, %1521
  %1529 = add i64 %1514, 18
  store i64 %1529, i64* %PC, align 8
  %1530 = inttoptr i64 %1528 to i64*
  store i64 %1517, i64* %1530, align 8
  %1531 = load i64, i64* %RBP, align 8
  %1532 = add i64 %1531, -72
  %1533 = load i64, i64* %PC, align 8
  %1534 = add i64 %1533, 5
  store i64 %1534, i64* %PC, align 8
  %1535 = inttoptr i64 %1532 to i64*
  %1536 = load i64, i64* %1535, align 8
  store i64 %1536, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1537 = add i64 %1531, -24
  %1538 = add i64 %1533, 9
  store i64 %1538, i64* %PC, align 8
  %1539 = inttoptr i64 %1537 to i64*
  %1540 = load i64, i64* %1539, align 8
  store i64 %1540, i64* %RDX, align 8, !tbaa !2428
  %1541 = add i64 %1531, -40
  %1542 = add i64 %1533, 12
  store i64 %1542, i64* %PC, align 8
  %1543 = inttoptr i64 %1541 to i32*
  %1544 = load i32, i32* %1543, align 4
  %1545 = add i32 %1544, 1
  %1546 = zext i32 %1545 to i64
  store i64 %1546, i64* %RCX, align 8, !tbaa !2428
  %1547 = icmp eq i32 %1544, -1
  %1548 = icmp eq i32 %1545, 0
  %1549 = or i1 %1547, %1548
  %1550 = zext i1 %1549 to i8
  store i8 %1550, i8* %50, align 1, !tbaa !2433
  %1551 = and i32 %1545, 255
  %1552 = tail call i32 @llvm.ctpop.i32(i32 %1551) #10
  %1553 = trunc i32 %1552 to i8
  %1554 = and i8 %1553, 1
  %1555 = xor i8 %1554, 1
  store i8 %1555, i8* %51, align 1, !tbaa !2447
  %1556 = xor i32 %1545, %1544
  %1557 = lshr i32 %1556, 4
  %1558 = trunc i32 %1557 to i8
  %1559 = and i8 %1558, 1
  store i8 %1559, i8* %52, align 1, !tbaa !2451
  %1560 = zext i1 %1548 to i8
  store i8 %1560, i8* %53, align 1, !tbaa !2448
  %1561 = lshr i32 %1545, 31
  %1562 = trunc i32 %1561 to i8
  store i8 %1562, i8* %54, align 1, !tbaa !2449
  %1563 = lshr i32 %1544, 31
  %1564 = xor i32 %1561, %1563
  %1565 = add nuw nsw i32 %1564, %1561
  %1566 = icmp eq i32 %1565, 2
  %1567 = zext i1 %1566 to i8
  store i8 %1567, i8* %55, align 1, !tbaa !2450
  %1568 = sext i32 %1545 to i64
  store i64 %1568, i64* %RSI, align 8, !tbaa !2428
  %1569 = shl nsw i64 %1568, 3
  %1570 = add i64 %1540, %1569
  %1571 = add i64 %1533, 23
  store i64 %1571, i64* %PC, align 8
  %1572 = inttoptr i64 %1570 to i64*
  store i64 %1536, i64* %1572, align 8
  %1573 = load i64, i64* %RBP, align 8
  %1574 = add i64 %1573, -52
  %1575 = load i64, i64* %PC, align 8
  %1576 = add i64 %1575, 3
  store i64 %1576, i64* %PC, align 8
  %1577 = inttoptr i64 %1574 to i32*
  %1578 = load i32, i32* %1577, align 4
  %1579 = zext i32 %1578 to i64
  store i64 %1579, i64* %RCX, align 8, !tbaa !2428
  %1580 = add i64 %1573, -32
  %1581 = add i64 %1575, 6
  store i64 %1581, i64* %PC, align 8
  %1582 = inttoptr i64 %1580 to i32*
  %1583 = load i32, i32* %1582, align 4
  %1584 = add i32 %1583, %1578
  %1585 = zext i32 %1584 to i64
  store i64 %1585, i64* %RCX, align 8, !tbaa !2428
  %1586 = icmp ult i32 %1584, %1578
  %1587 = icmp ult i32 %1584, %1583
  %1588 = or i1 %1586, %1587
  %1589 = zext i1 %1588 to i8
  store i8 %1589, i8* %50, align 1, !tbaa !2433
  %1590 = and i32 %1584, 255
  %1591 = tail call i32 @llvm.ctpop.i32(i32 %1590) #10
  %1592 = trunc i32 %1591 to i8
  %1593 = and i8 %1592, 1
  %1594 = xor i8 %1593, 1
  store i8 %1594, i8* %51, align 1, !tbaa !2447
  %1595 = xor i32 %1583, %1578
  %1596 = xor i32 %1595, %1584
  %1597 = lshr i32 %1596, 4
  %1598 = trunc i32 %1597 to i8
  %1599 = and i8 %1598, 1
  store i8 %1599, i8* %52, align 1, !tbaa !2451
  %1600 = icmp eq i32 %1584, 0
  %1601 = zext i1 %1600 to i8
  store i8 %1601, i8* %53, align 1, !tbaa !2448
  %1602 = lshr i32 %1584, 31
  %1603 = trunc i32 %1602 to i8
  store i8 %1603, i8* %54, align 1, !tbaa !2449
  %1604 = lshr i32 %1578, 31
  %1605 = lshr i32 %1583, 31
  %1606 = xor i32 %1602, %1604
  %1607 = xor i32 %1602, %1605
  %1608 = add nuw nsw i32 %1606, %1607
  %1609 = icmp eq i32 %1608, 2
  %1610 = zext i1 %1609 to i8
  store i8 %1610, i8* %55, align 1, !tbaa !2450
  %1611 = add i64 %1575, 9
  store i64 %1611, i64* %PC, align 8
  store i32 %1584, i32* %1582, align 4
  %1612 = load i64, i64* %RBP, align 8
  %1613 = add i64 %1612, -52
  %1614 = load i64, i64* %PC, align 8
  %1615 = add i64 %1614, 3
  store i64 %1615, i64* %PC, align 8
  %1616 = inttoptr i64 %1613 to i32*
  %1617 = load i32, i32* %1616, align 4
  %1618 = shl i32 %1617, 1
  %1619 = icmp slt i32 %1617, 0
  %1620 = icmp slt i32 %1618, 0
  %1621 = xor i1 %1619, %1620
  %1622 = zext i32 %1618 to i64
  store i64 %1622, i64* %RCX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %1617, 31
  %1623 = trunc i32 %.lobit17 to i8
  store i8 %1623, i8* %50, align 1, !tbaa !2432
  %1624 = and i32 %1618, 254
  %1625 = tail call i32 @llvm.ctpop.i32(i32 %1624) #10
  %1626 = trunc i32 %1625 to i8
  %1627 = and i8 %1626, 1
  %1628 = xor i8 %1627, 1
  store i8 %1628, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %1629 = icmp eq i32 %1618, 0
  %1630 = zext i1 %1629 to i8
  store i8 %1630, i8* %53, align 1, !tbaa !2432
  %1631 = lshr i32 %1617, 30
  %1632 = trunc i32 %1631 to i8
  %1633 = and i8 %1632, 1
  store i8 %1633, i8* %54, align 1, !tbaa !2432
  %1634 = zext i1 %1621 to i8
  store i8 %1634, i8* %55, align 1, !tbaa !2432
  %1635 = add i64 %1612, -40
  %1636 = add i64 %1614, 9
  store i64 %1636, i64* %PC, align 8
  %1637 = inttoptr i64 %1635 to i32*
  %1638 = load i32, i32* %1637, align 4
  %1639 = add i32 %1638, %1618
  %1640 = zext i32 %1639 to i64
  store i64 %1640, i64* %RCX, align 8, !tbaa !2428
  %1641 = icmp ult i32 %1639, %1618
  %1642 = icmp ult i32 %1639, %1638
  %1643 = or i1 %1641, %1642
  %1644 = zext i1 %1643 to i8
  store i8 %1644, i8* %50, align 1, !tbaa !2433
  %1645 = and i32 %1639, 255
  %1646 = tail call i32 @llvm.ctpop.i32(i32 %1645) #10
  %1647 = trunc i32 %1646 to i8
  %1648 = and i8 %1647, 1
  %1649 = xor i8 %1648, 1
  store i8 %1649, i8* %51, align 1, !tbaa !2447
  %1650 = xor i32 %1638, %1618
  %1651 = xor i32 %1650, %1639
  %1652 = lshr i32 %1651, 4
  %1653 = trunc i32 %1652 to i8
  %1654 = and i8 %1653, 1
  store i8 %1654, i8* %52, align 1, !tbaa !2451
  %1655 = icmp eq i32 %1639, 0
  %1656 = zext i1 %1655 to i8
  store i8 %1656, i8* %53, align 1, !tbaa !2448
  %1657 = lshr i32 %1639, 31
  %1658 = trunc i32 %1657 to i8
  store i8 %1658, i8* %54, align 1, !tbaa !2449
  %1659 = lshr i32 %1617, 30
  %1660 = and i32 %1659, 1
  %1661 = lshr i32 %1638, 31
  %1662 = xor i32 %1657, %1660
  %1663 = xor i32 %1657, %1661
  %1664 = add nuw nsw i32 %1662, %1663
  %1665 = icmp eq i32 %1664, 2
  %1666 = zext i1 %1665 to i8
  store i8 %1666, i8* %55, align 1, !tbaa !2450
  %1667 = add i64 %1614, 12
  store i64 %1667, i64* %PC, align 8
  store i32 %1639, i32* %1637, align 4
  %1668 = load i64, i64* %RBP, align 8
  %1669 = add i64 %1668, -24
  %1670 = load i64, i64* %PC, align 8
  %1671 = add i64 %1670, 4
  store i64 %1671, i64* %PC, align 8
  %1672 = inttoptr i64 %1669 to i64*
  %1673 = load i64, i64* %1672, align 8
  store i64 %1673, i64* %RDX, align 8, !tbaa !2428
  %1674 = add i64 %1668, -32
  %1675 = add i64 %1670, 8
  store i64 %1675, i64* %PC, align 8
  %1676 = inttoptr i64 %1674 to i32*
  %1677 = load i32, i32* %1676, align 4
  %1678 = sext i32 %1677 to i64
  store i64 %1678, i64* %RSI, align 8, !tbaa !2428
  %1679 = shl nsw i64 %1678, 3
  %1680 = add i64 %1679, %1673
  %1681 = add i64 %1670, 13
  store i64 %1681, i64* %PC, align 8
  %1682 = inttoptr i64 %1680 to i64*
  %1683 = load i64, i64* %1682, align 8
  store i64 %1683, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1684 = add i64 %1668, -64
  %1685 = add i64 %1670, 18
  store i64 %1685, i64* %PC, align 8
  %1686 = inttoptr i64 %1684 to i64*
  store i64 %1683, i64* %1686, align 8
  %1687 = load i64, i64* %RBP, align 8
  %1688 = add i64 %1687, -24
  %1689 = load i64, i64* %PC, align 8
  %1690 = add i64 %1689, 4
  store i64 %1690, i64* %PC, align 8
  %1691 = inttoptr i64 %1688 to i64*
  %1692 = load i64, i64* %1691, align 8
  store i64 %1692, i64* %RDX, align 8, !tbaa !2428
  %1693 = add i64 %1687, -32
  %1694 = add i64 %1689, 7
  store i64 %1694, i64* %PC, align 8
  %1695 = inttoptr i64 %1693 to i32*
  %1696 = load i32, i32* %1695, align 4
  %1697 = add i32 %1696, 1
  %1698 = zext i32 %1697 to i64
  store i64 %1698, i64* %RCX, align 8, !tbaa !2428
  %1699 = icmp eq i32 %1696, -1
  %1700 = icmp eq i32 %1697, 0
  %1701 = or i1 %1699, %1700
  %1702 = zext i1 %1701 to i8
  store i8 %1702, i8* %50, align 1, !tbaa !2433
  %1703 = and i32 %1697, 255
  %1704 = tail call i32 @llvm.ctpop.i32(i32 %1703) #10
  %1705 = trunc i32 %1704 to i8
  %1706 = and i8 %1705, 1
  %1707 = xor i8 %1706, 1
  store i8 %1707, i8* %51, align 1, !tbaa !2447
  %1708 = xor i32 %1697, %1696
  %1709 = lshr i32 %1708, 4
  %1710 = trunc i32 %1709 to i8
  %1711 = and i8 %1710, 1
  store i8 %1711, i8* %52, align 1, !tbaa !2451
  %1712 = zext i1 %1700 to i8
  store i8 %1712, i8* %53, align 1, !tbaa !2448
  %1713 = lshr i32 %1697, 31
  %1714 = trunc i32 %1713 to i8
  store i8 %1714, i8* %54, align 1, !tbaa !2449
  %1715 = lshr i32 %1696, 31
  %1716 = xor i32 %1713, %1715
  %1717 = add nuw nsw i32 %1716, %1713
  %1718 = icmp eq i32 %1717, 2
  %1719 = zext i1 %1718 to i8
  store i8 %1719, i8* %55, align 1, !tbaa !2450
  %1720 = sext i32 %1697 to i64
  store i64 %1720, i64* %RSI, align 8, !tbaa !2428
  %1721 = shl nsw i64 %1720, 3
  %1722 = add i64 %1692, %1721
  %1723 = add i64 %1689, 18
  store i64 %1723, i64* %PC, align 8
  %1724 = inttoptr i64 %1722 to i64*
  %1725 = load i64, i64* %1724, align 8
  %1726 = load i64, i64* %RAX, align 8
  %1727 = xor i64 %1726, %1725
  store i64 %1727, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %1728 = trunc i64 %1727 to i32
  %1729 = and i32 %1728, 255
  %1730 = tail call i32 @llvm.ctpop.i32(i32 %1729) #10
  %1731 = trunc i32 %1730 to i8
  %1732 = and i8 %1731, 1
  %1733 = xor i8 %1732, 1
  store i8 %1733, i8* %51, align 1, !tbaa !2447
  %1734 = icmp eq i64 %1727, 0
  %1735 = zext i1 %1734 to i8
  store i8 %1735, i8* %53, align 1, !tbaa !2448
  %1736 = lshr i64 %1727, 63
  %1737 = trunc i64 %1736 to i8
  store i8 %1737, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %1727, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %1738 = add i64 %1687, -72
  %1739 = add i64 %1689, 36
  store i64 %1739, i64* %PC, align 8
  %1740 = inttoptr i64 %1738 to i64*
  store i64 %1727, i64* %1740, align 8
  %1741 = load i64, i64* %RBP, align 8
  %1742 = add i64 %1741, -24
  %1743 = load i64, i64* %PC, align 8
  %1744 = add i64 %1743, 4
  store i64 %1744, i64* %PC, align 8
  %1745 = inttoptr i64 %1742 to i64*
  %1746 = load i64, i64* %1745, align 8
  store i64 %1746, i64* %RDX, align 8, !tbaa !2428
  %1747 = add i64 %1741, -40
  %1748 = add i64 %1743, 8
  store i64 %1748, i64* %PC, align 8
  %1749 = inttoptr i64 %1747 to i32*
  %1750 = load i32, i32* %1749, align 4
  %1751 = sext i32 %1750 to i64
  store i64 %1751, i64* %RSI, align 8, !tbaa !2428
  %1752 = shl nsw i64 %1751, 3
  %1753 = add i64 %1752, %1746
  %1754 = add i64 %1743, 13
  store i64 %1754, i64* %PC, align 8
  %1755 = inttoptr i64 %1753 to i64*
  %1756 = load i64, i64* %1755, align 8
  store i64 %1756, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1757 = add i64 %1741, -80
  %1758 = add i64 %1743, 18
  store i64 %1758, i64* %PC, align 8
  %1759 = inttoptr i64 %1757 to i64*
  store i64 %1756, i64* %1759, align 8
  %1760 = load i64, i64* %RBP, align 8
  %1761 = add i64 %1760, -24
  %1762 = load i64, i64* %PC, align 8
  %1763 = add i64 %1762, 4
  store i64 %1763, i64* %PC, align 8
  %1764 = inttoptr i64 %1761 to i64*
  %1765 = load i64, i64* %1764, align 8
  store i64 %1765, i64* %RDX, align 8, !tbaa !2428
  %1766 = add i64 %1760, -40
  %1767 = add i64 %1762, 7
  store i64 %1767, i64* %PC, align 8
  %1768 = inttoptr i64 %1766 to i32*
  %1769 = load i32, i32* %1768, align 4
  %1770 = add i32 %1769, 1
  %1771 = zext i32 %1770 to i64
  store i64 %1771, i64* %RCX, align 8, !tbaa !2428
  %1772 = icmp eq i32 %1769, -1
  %1773 = icmp eq i32 %1770, 0
  %1774 = or i1 %1772, %1773
  %1775 = zext i1 %1774 to i8
  store i8 %1775, i8* %50, align 1, !tbaa !2433
  %1776 = and i32 %1770, 255
  %1777 = tail call i32 @llvm.ctpop.i32(i32 %1776) #10
  %1778 = trunc i32 %1777 to i8
  %1779 = and i8 %1778, 1
  %1780 = xor i8 %1779, 1
  store i8 %1780, i8* %51, align 1, !tbaa !2447
  %1781 = xor i32 %1770, %1769
  %1782 = lshr i32 %1781, 4
  %1783 = trunc i32 %1782 to i8
  %1784 = and i8 %1783, 1
  store i8 %1784, i8* %52, align 1, !tbaa !2451
  %1785 = zext i1 %1773 to i8
  store i8 %1785, i8* %53, align 1, !tbaa !2448
  %1786 = lshr i32 %1770, 31
  %1787 = trunc i32 %1786 to i8
  store i8 %1787, i8* %54, align 1, !tbaa !2449
  %1788 = lshr i32 %1769, 31
  %1789 = xor i32 %1786, %1788
  %1790 = add nuw nsw i32 %1789, %1786
  %1791 = icmp eq i32 %1790, 2
  %1792 = zext i1 %1791 to i8
  store i8 %1792, i8* %55, align 1, !tbaa !2450
  %1793 = sext i32 %1770 to i64
  store i64 %1793, i64* %RSI, align 8, !tbaa !2428
  %1794 = shl nsw i64 %1793, 3
  %1795 = add i64 %1765, %1794
  %1796 = add i64 %1762, 18
  store i64 %1796, i64* %PC, align 8
  %1797 = inttoptr i64 %1795 to i64*
  %1798 = load i64, i64* %1797, align 8
  %1799 = load i64, i64* %RAX, align 8
  %1800 = xor i64 %1799, %1798
  store i64 %1800, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %1801 = trunc i64 %1800 to i32
  %1802 = and i32 %1801, 255
  %1803 = tail call i32 @llvm.ctpop.i32(i32 %1802) #10
  %1804 = trunc i32 %1803 to i8
  %1805 = and i8 %1804, 1
  %1806 = xor i8 %1805, 1
  store i8 %1806, i8* %51, align 1, !tbaa !2447
  %1807 = icmp eq i64 %1800, 0
  %1808 = zext i1 %1807 to i8
  store i8 %1808, i8* %53, align 1, !tbaa !2448
  %1809 = lshr i64 %1800, 63
  %1810 = trunc i64 %1809 to i8
  store i8 %1810, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %1800, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %1811 = add i64 %1760, -88
  %1812 = add i64 %1762, 36
  store i64 %1812, i64* %PC, align 8
  %1813 = inttoptr i64 %1811 to i64*
  store i64 %1800, i64* %1813, align 8
  %1814 = load i64, i64* %RBP, align 8
  %1815 = add i64 %1814, -80
  %1816 = load i64, i64* %PC, align 8
  %1817 = add i64 %1816, 5
  store i64 %1817, i64* %PC, align 8
  %1818 = inttoptr i64 %1815 to i64*
  %1819 = load i64, i64* %1818, align 8
  store i64 %1819, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1820 = add i64 %1814, -24
  %1821 = add i64 %1816, 9
  store i64 %1821, i64* %PC, align 8
  %1822 = inttoptr i64 %1820 to i64*
  %1823 = load i64, i64* %1822, align 8
  store i64 %1823, i64* %RAX, align 8, !tbaa !2428
  %1824 = add i64 %1814, -32
  %1825 = add i64 %1816, 13
  store i64 %1825, i64* %PC, align 8
  %1826 = inttoptr i64 %1824 to i32*
  %1827 = load i32, i32* %1826, align 4
  %1828 = sext i32 %1827 to i64
  store i64 %1828, i64* %RDX, align 8, !tbaa !2428
  %1829 = shl nsw i64 %1828, 3
  %1830 = add i64 %1829, %1823
  %1831 = add i64 %1816, 18
  store i64 %1831, i64* %PC, align 8
  %1832 = inttoptr i64 %1830 to i64*
  store i64 %1819, i64* %1832, align 8
  %1833 = load i64, i64* %RBP, align 8
  %1834 = add i64 %1833, -88
  %1835 = load i64, i64* %PC, align 8
  %1836 = add i64 %1835, 5
  store i64 %1836, i64* %PC, align 8
  %1837 = inttoptr i64 %1834 to i64*
  %1838 = load i64, i64* %1837, align 8
  store i64 %1838, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1839 = add i64 %1833, -24
  %1840 = add i64 %1835, 9
  store i64 %1840, i64* %PC, align 8
  %1841 = inttoptr i64 %1839 to i64*
  %1842 = load i64, i64* %1841, align 8
  store i64 %1842, i64* %RAX, align 8, !tbaa !2428
  %1843 = add i64 %1833, -32
  %1844 = add i64 %1835, 12
  store i64 %1844, i64* %PC, align 8
  %1845 = inttoptr i64 %1843 to i32*
  %1846 = load i32, i32* %1845, align 4
  %1847 = add i32 %1846, 1
  %1848 = zext i32 %1847 to i64
  store i64 %1848, i64* %RCX, align 8, !tbaa !2428
  %1849 = icmp eq i32 %1846, -1
  %1850 = icmp eq i32 %1847, 0
  %1851 = or i1 %1849, %1850
  %1852 = zext i1 %1851 to i8
  store i8 %1852, i8* %50, align 1, !tbaa !2433
  %1853 = and i32 %1847, 255
  %1854 = tail call i32 @llvm.ctpop.i32(i32 %1853) #10
  %1855 = trunc i32 %1854 to i8
  %1856 = and i8 %1855, 1
  %1857 = xor i8 %1856, 1
  store i8 %1857, i8* %51, align 1, !tbaa !2447
  %1858 = xor i32 %1847, %1846
  %1859 = lshr i32 %1858, 4
  %1860 = trunc i32 %1859 to i8
  %1861 = and i8 %1860, 1
  store i8 %1861, i8* %52, align 1, !tbaa !2451
  %1862 = zext i1 %1850 to i8
  store i8 %1862, i8* %53, align 1, !tbaa !2448
  %1863 = lshr i32 %1847, 31
  %1864 = trunc i32 %1863 to i8
  store i8 %1864, i8* %54, align 1, !tbaa !2449
  %1865 = lshr i32 %1846, 31
  %1866 = xor i32 %1863, %1865
  %1867 = add nuw nsw i32 %1866, %1863
  %1868 = icmp eq i32 %1867, 2
  %1869 = zext i1 %1868 to i8
  store i8 %1869, i8* %55, align 1, !tbaa !2450
  %1870 = sext i32 %1847 to i64
  store i64 %1870, i64* %RDX, align 8, !tbaa !2428
  %1871 = shl nsw i64 %1870, 3
  %1872 = add i64 %1842, %1871
  %1873 = add i64 %1835, 23
  store i64 %1873, i64* %PC, align 8
  %1874 = inttoptr i64 %1872 to i64*
  store i64 %1838, i64* %1874, align 8
  %1875 = load i64, i64* %RBP, align 8
  %1876 = add i64 %1875, -64
  %1877 = load i64, i64* %PC, align 8
  %1878 = add i64 %1877, 5
  store i64 %1878, i64* %PC, align 8
  %1879 = inttoptr i64 %1876 to i64*
  %1880 = load i64, i64* %1879, align 8
  store i64 %1880, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1881 = add i64 %1875, -24
  %1882 = add i64 %1877, 9
  store i64 %1882, i64* %PC, align 8
  %1883 = inttoptr i64 %1881 to i64*
  %1884 = load i64, i64* %1883, align 8
  store i64 %1884, i64* %RAX, align 8, !tbaa !2428
  %1885 = add i64 %1875, -40
  %1886 = add i64 %1877, 13
  store i64 %1886, i64* %PC, align 8
  %1887 = inttoptr i64 %1885 to i32*
  %1888 = load i32, i32* %1887, align 4
  %1889 = sext i32 %1888 to i64
  store i64 %1889, i64* %RDX, align 8, !tbaa !2428
  %1890 = shl nsw i64 %1889, 3
  %1891 = add i64 %1890, %1884
  %1892 = add i64 %1877, 18
  store i64 %1892, i64* %PC, align 8
  %1893 = inttoptr i64 %1891 to i64*
  store i64 %1880, i64* %1893, align 8
  %1894 = load i64, i64* %RBP, align 8
  %1895 = add i64 %1894, -72
  %1896 = load i64, i64* %PC, align 8
  %1897 = add i64 %1896, 5
  store i64 %1897, i64* %PC, align 8
  %1898 = inttoptr i64 %1895 to i64*
  %1899 = load i64, i64* %1898, align 8
  store i64 %1899, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %1900 = add i64 %1894, -24
  %1901 = add i64 %1896, 9
  store i64 %1901, i64* %PC, align 8
  %1902 = inttoptr i64 %1900 to i64*
  %1903 = load i64, i64* %1902, align 8
  store i64 %1903, i64* %RAX, align 8, !tbaa !2428
  %1904 = add i64 %1894, -40
  %1905 = add i64 %1896, 12
  store i64 %1905, i64* %PC, align 8
  %1906 = inttoptr i64 %1904 to i32*
  %1907 = load i32, i32* %1906, align 4
  %1908 = add i32 %1907, 1
  %1909 = zext i32 %1908 to i64
  store i64 %1909, i64* %RCX, align 8, !tbaa !2428
  %1910 = icmp eq i32 %1907, -1
  %1911 = icmp eq i32 %1908, 0
  %1912 = or i1 %1910, %1911
  %1913 = zext i1 %1912 to i8
  store i8 %1913, i8* %50, align 1, !tbaa !2433
  %1914 = and i32 %1908, 255
  %1915 = tail call i32 @llvm.ctpop.i32(i32 %1914) #10
  %1916 = trunc i32 %1915 to i8
  %1917 = and i8 %1916, 1
  %1918 = xor i8 %1917, 1
  store i8 %1918, i8* %51, align 1, !tbaa !2447
  %1919 = xor i32 %1908, %1907
  %1920 = lshr i32 %1919, 4
  %1921 = trunc i32 %1920 to i8
  %1922 = and i8 %1921, 1
  store i8 %1922, i8* %52, align 1, !tbaa !2451
  %1923 = zext i1 %1911 to i8
  store i8 %1923, i8* %53, align 1, !tbaa !2448
  %1924 = lshr i32 %1908, 31
  %1925 = trunc i32 %1924 to i8
  store i8 %1925, i8* %54, align 1, !tbaa !2449
  %1926 = lshr i32 %1907, 31
  %1927 = xor i32 %1924, %1926
  %1928 = add nuw nsw i32 %1927, %1924
  %1929 = icmp eq i32 %1928, 2
  %1930 = zext i1 %1929 to i8
  store i8 %1930, i8* %55, align 1, !tbaa !2450
  %1931 = sext i32 %1908 to i64
  store i64 %1931, i64* %RDX, align 8, !tbaa !2428
  %1932 = shl nsw i64 %1931, 3
  %1933 = add i64 %1903, %1932
  %1934 = add i64 %1896, 23
  store i64 %1934, i64* %PC, align 8
  %1935 = inttoptr i64 %1933 to i64*
  store i64 %1899, i64* %1935, align 8
  %1936 = load i64, i64* %RBP, align 8
  %1937 = add i64 %1936, -28
  %1938 = load i64, i64* %PC, align 8
  %1939 = add i64 %1938, 3
  store i64 %1939, i64* %PC, align 8
  %1940 = inttoptr i64 %1937 to i32*
  %1941 = load i32, i32* %1940, align 4
  %1942 = add i32 %1941, 1
  %1943 = zext i32 %1942 to i64
  store i64 %1943, i64* %RAX, align 8, !tbaa !2428
  %1944 = icmp eq i32 %1941, -1
  %1945 = icmp eq i32 %1942, 0
  %1946 = or i1 %1944, %1945
  %1947 = zext i1 %1946 to i8
  store i8 %1947, i8* %50, align 1, !tbaa !2433
  %1948 = and i32 %1942, 255
  %1949 = tail call i32 @llvm.ctpop.i32(i32 %1948) #10
  %1950 = trunc i32 %1949 to i8
  %1951 = and i8 %1950, 1
  %1952 = xor i8 %1951, 1
  store i8 %1952, i8* %51, align 1, !tbaa !2447
  %1953 = xor i32 %1942, %1941
  %1954 = lshr i32 %1953, 4
  %1955 = trunc i32 %1954 to i8
  %1956 = and i8 %1955, 1
  store i8 %1956, i8* %52, align 1, !tbaa !2451
  %1957 = zext i1 %1945 to i8
  store i8 %1957, i8* %53, align 1, !tbaa !2448
  %1958 = lshr i32 %1942, 31
  %1959 = trunc i32 %1958 to i8
  store i8 %1959, i8* %54, align 1, !tbaa !2449
  %1960 = lshr i32 %1941, 31
  %1961 = xor i32 %1958, %1960
  %1962 = add nuw nsw i32 %1961, %1958
  %1963 = icmp eq i32 %1962, 2
  %1964 = zext i1 %1963 to i8
  store i8 %1964, i8* %55, align 1, !tbaa !2450
  %1965 = add i64 %1938, 9
  store i64 %1965, i64* %PC, align 8
  store i32 %1942, i32* %1940, align 4
  %1966 = load i64, i64* %PC, align 8
  %1967 = add i64 %1966, -893
  store i64 %1967, i64* %PC, align 8, !tbaa !2428
  br label %block_401cbd

block_40203f:                                     ; preds = %block_401cbd
  %1968 = load i32, i32* %2625, align 4
  %1969 = shl i32 %1968, 1
  %1970 = icmp slt i32 %1968, 0
  %1971 = icmp slt i32 %1969, 0
  %1972 = xor i1 %1970, %1971
  %1973 = zext i32 %1969 to i64
  store i64 %1973, i64* %RCX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %1968, 31
  %1974 = trunc i32 %.lobit18 to i8
  store i8 %1974, i8* %50, align 1, !tbaa !2432
  %1975 = and i32 %1969, 254
  %1976 = tail call i32 @llvm.ctpop.i32(i32 %1975) #10
  %1977 = trunc i32 %1976 to i8
  %1978 = and i8 %1977, 1
  %1979 = xor i8 %1978, 1
  store i8 %1979, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %1980 = icmp eq i32 %1969, 0
  %1981 = zext i1 %1980 to i8
  store i8 %1981, i8* %53, align 1, !tbaa !2432
  %1982 = lshr i32 %1968, 30
  %1983 = trunc i32 %1982 to i8
  %1984 = and i8 %1983, 1
  store i8 %1984, i8* %54, align 1, !tbaa !2432
  %1985 = zext i1 %1972 to i8
  store i8 %1985, i8* %55, align 1, !tbaa !2432
  %1986 = add i64 %2617, -16
  %1987 = add i64 %2653, 20
  store i64 %1987, i64* %PC, align 8
  %1988 = inttoptr i64 %1986 to i64*
  %1989 = load i64, i64* %1988, align 8
  store i64 %1989, i64* %RDX, align 8, !tbaa !2428
  %1990 = add i64 %2653, 24
  store i64 %1990, i64* %PC, align 8
  %1991 = load i32, i32* %2625, align 4
  %1992 = sext i32 %1991 to i64
  store i64 %1992, i64* %RSI, align 8, !tbaa !2428
  %1993 = shl nsw i64 %1992, 2
  %1994 = add i64 %1989, %1993
  %1995 = add i64 %2653, 27
  store i64 %1995, i64* %PC, align 8
  %1996 = inttoptr i64 %1994 to i32*
  %1997 = load i32, i32* %1996, align 4
  %1998 = add i32 %1997, %1969
  %1999 = zext i32 %1998 to i64
  store i64 %1999, i64* %RCX, align 8, !tbaa !2428
  %2000 = icmp ult i32 %1998, %1969
  %2001 = icmp ult i32 %1998, %1997
  %2002 = or i1 %2000, %2001
  %2003 = zext i1 %2002 to i8
  store i8 %2003, i8* %50, align 1, !tbaa !2433
  %2004 = and i32 %1998, 255
  %2005 = tail call i32 @llvm.ctpop.i32(i32 %2004) #10
  %2006 = trunc i32 %2005 to i8
  %2007 = and i8 %2006, 1
  %2008 = xor i8 %2007, 1
  store i8 %2008, i8* %51, align 1, !tbaa !2447
  %2009 = xor i32 %1997, %1969
  %2010 = xor i32 %2009, %1998
  %2011 = lshr i32 %2010, 4
  %2012 = trunc i32 %2011 to i8
  %2013 = and i8 %2012, 1
  store i8 %2013, i8* %52, align 1, !tbaa !2451
  %2014 = icmp eq i32 %1998, 0
  %2015 = zext i1 %2014 to i8
  store i8 %2015, i8* %53, align 1, !tbaa !2448
  %2016 = lshr i32 %1998, 31
  %2017 = trunc i32 %2016 to i8
  store i8 %2017, i8* %54, align 1, !tbaa !2449
  %2018 = lshr i32 %1968, 30
  %2019 = and i32 %2018, 1
  %2020 = lshr i32 %1997, 31
  %2021 = xor i32 %2016, %2019
  %2022 = xor i32 %2016, %2020
  %2023 = add nuw nsw i32 %2021, %2022
  %2024 = icmp eq i32 %2023, 2
  %2025 = zext i1 %2024 to i8
  store i8 %2025, i8* %55, align 1, !tbaa !2450
  %2026 = add i64 %2617, -40
  %2027 = add i64 %2653, 30
  store i64 %2027, i64* %PC, align 8
  %2028 = inttoptr i64 %2026 to i32*
  store i32 %1998, i32* %2028, align 4
  %2029 = load i64, i64* %RBP, align 8
  %2030 = add i64 %2029, -24
  %2031 = load i64, i64* %PC, align 8
  %2032 = add i64 %2031, 4
  store i64 %2032, i64* %PC, align 8
  %2033 = inttoptr i64 %2030 to i64*
  %2034 = load i64, i64* %2033, align 8
  store i64 %2034, i64* %RDX, align 8, !tbaa !2428
  %2035 = add i64 %2029, -40
  %2036 = add i64 %2031, 7
  store i64 %2036, i64* %PC, align 8
  %2037 = inttoptr i64 %2035 to i32*
  %2038 = load i32, i32* %2037, align 4
  %2039 = add i32 %2038, 1
  %2040 = zext i32 %2039 to i64
  store i64 %2040, i64* %RCX, align 8, !tbaa !2428
  %2041 = icmp eq i32 %2038, -1
  %2042 = icmp eq i32 %2039, 0
  %2043 = or i1 %2041, %2042
  %2044 = zext i1 %2043 to i8
  store i8 %2044, i8* %50, align 1, !tbaa !2433
  %2045 = and i32 %2039, 255
  %2046 = tail call i32 @llvm.ctpop.i32(i32 %2045) #10
  %2047 = trunc i32 %2046 to i8
  %2048 = and i8 %2047, 1
  %2049 = xor i8 %2048, 1
  store i8 %2049, i8* %51, align 1, !tbaa !2447
  %2050 = xor i32 %2039, %2038
  %2051 = lshr i32 %2050, 4
  %2052 = trunc i32 %2051 to i8
  %2053 = and i8 %2052, 1
  store i8 %2053, i8* %52, align 1, !tbaa !2451
  %2054 = zext i1 %2042 to i8
  store i8 %2054, i8* %53, align 1, !tbaa !2448
  %2055 = lshr i32 %2039, 31
  %2056 = trunc i32 %2055 to i8
  store i8 %2056, i8* %54, align 1, !tbaa !2449
  %2057 = lshr i32 %2038, 31
  %2058 = xor i32 %2055, %2057
  %2059 = add nuw nsw i32 %2058, %2055
  %2060 = icmp eq i32 %2059, 2
  %2061 = zext i1 %2060 to i8
  store i8 %2061, i8* %55, align 1, !tbaa !2450
  %2062 = sext i32 %2039 to i64
  store i64 %2062, i64* %RSI, align 8, !tbaa !2428
  %2063 = shl nsw i64 %2062, 3
  %2064 = add i64 %2034, %2063
  %2065 = add i64 %2031, 18
  store i64 %2065, i64* %PC, align 8
  %2066 = inttoptr i64 %2064 to i64*
  %2067 = load i64, i64* %2066, align 8
  %2068 = load i64, i64* %RAX, align 8
  %2069 = xor i64 %2068, %2067
  store i64 %2069, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %2070 = trunc i64 %2069 to i32
  %2071 = and i32 %2070, 255
  %2072 = tail call i32 @llvm.ctpop.i32(i32 %2071) #10
  %2073 = trunc i32 %2072 to i8
  %2074 = and i8 %2073, 1
  %2075 = xor i8 %2074, 1
  store i8 %2075, i8* %51, align 1, !tbaa !2447
  %2076 = icmp eq i64 %2069, 0
  %2077 = zext i1 %2076 to i8
  store i8 %2077, i8* %53, align 1, !tbaa !2448
  %2078 = lshr i64 %2069, 63
  %2079 = trunc i64 %2078 to i8
  store i8 %2079, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %2069, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %2080 = add i64 %2031, 35
  store i64 %2080, i64* %PC, align 8
  %2081 = load i64, i64* %2033, align 8
  store i64 %2081, i64* %RDX, align 8, !tbaa !2428
  %2082 = add i64 %2031, 38
  store i64 %2082, i64* %PC, align 8
  %2083 = load i32, i32* %2037, align 4
  %2084 = add i32 %2083, 1
  %2085 = zext i32 %2084 to i64
  store i64 %2085, i64* %RCX, align 8, !tbaa !2428
  %2086 = icmp eq i32 %2083, -1
  %2087 = icmp eq i32 %2084, 0
  %2088 = or i1 %2086, %2087
  %2089 = zext i1 %2088 to i8
  store i8 %2089, i8* %50, align 1, !tbaa !2433
  %2090 = and i32 %2084, 255
  %2091 = tail call i32 @llvm.ctpop.i32(i32 %2090) #10
  %2092 = trunc i32 %2091 to i8
  %2093 = and i8 %2092, 1
  %2094 = xor i8 %2093, 1
  store i8 %2094, i8* %51, align 1, !tbaa !2447
  %2095 = xor i32 %2084, %2083
  %2096 = lshr i32 %2095, 4
  %2097 = trunc i32 %2096 to i8
  %2098 = and i8 %2097, 1
  store i8 %2098, i8* %52, align 1, !tbaa !2451
  %2099 = zext i1 %2087 to i8
  store i8 %2099, i8* %53, align 1, !tbaa !2448
  %2100 = lshr i32 %2084, 31
  %2101 = trunc i32 %2100 to i8
  store i8 %2101, i8* %54, align 1, !tbaa !2449
  %2102 = lshr i32 %2083, 31
  %2103 = xor i32 %2100, %2102
  %2104 = add nuw nsw i32 %2103, %2100
  %2105 = icmp eq i32 %2104, 2
  %2106 = zext i1 %2105 to i8
  store i8 %2106, i8* %55, align 1, !tbaa !2450
  %2107 = sext i32 %2084 to i64
  store i64 %2107, i64* %RSI, align 8, !tbaa !2428
  %2108 = shl nsw i64 %2107, 3
  %2109 = add i64 %2081, %2108
  %2110 = add i64 %2031, 49
  store i64 %2110, i64* %PC, align 8
  %2111 = inttoptr i64 %2109 to i64*
  store i64 %2069, i64* %2111, align 8
  %2112 = load i64, i64* %RBP, align 8
  %2113 = add i64 %2112, -40
  %2114 = load i64, i64* %PC, align 8
  %2115 = add i64 %2114, 3
  store i64 %2115, i64* %PC, align 8
  %2116 = inttoptr i64 %2113 to i32*
  %2117 = load i32, i32* %2116, align 4
  %2118 = zext i32 %2117 to i64
  store i64 %2118, i64* %RCX, align 8, !tbaa !2428
  %2119 = add i64 %2112, -52
  %2120 = add i64 %2114, 6
  store i64 %2120, i64* %PC, align 8
  %2121 = inttoptr i64 %2119 to i32*
  %2122 = load i32, i32* %2121, align 4
  %2123 = add i32 %2122, %2117
  %2124 = zext i32 %2123 to i64
  store i64 %2124, i64* %RCX, align 8, !tbaa !2428
  %2125 = icmp ult i32 %2123, %2117
  %2126 = icmp ult i32 %2123, %2122
  %2127 = or i1 %2125, %2126
  %2128 = zext i1 %2127 to i8
  store i8 %2128, i8* %50, align 1, !tbaa !2433
  %2129 = and i32 %2123, 255
  %2130 = tail call i32 @llvm.ctpop.i32(i32 %2129) #10
  %2131 = trunc i32 %2130 to i8
  %2132 = and i8 %2131, 1
  %2133 = xor i8 %2132, 1
  store i8 %2133, i8* %51, align 1, !tbaa !2447
  %2134 = xor i32 %2122, %2117
  %2135 = xor i32 %2134, %2123
  %2136 = lshr i32 %2135, 4
  %2137 = trunc i32 %2136 to i8
  %2138 = and i8 %2137, 1
  store i8 %2138, i8* %52, align 1, !tbaa !2451
  %2139 = icmp eq i32 %2123, 0
  %2140 = zext i1 %2139 to i8
  store i8 %2140, i8* %53, align 1, !tbaa !2448
  %2141 = lshr i32 %2123, 31
  %2142 = trunc i32 %2141 to i8
  store i8 %2142, i8* %54, align 1, !tbaa !2449
  %2143 = lshr i32 %2117, 31
  %2144 = lshr i32 %2122, 31
  %2145 = xor i32 %2141, %2143
  %2146 = xor i32 %2141, %2144
  %2147 = add nuw nsw i32 %2145, %2146
  %2148 = icmp eq i32 %2147, 2
  %2149 = zext i1 %2148 to i8
  store i8 %2149, i8* %55, align 1, !tbaa !2450
  %2150 = add i64 %2112, -32
  %2151 = add i64 %2114, 9
  store i64 %2151, i64* %PC, align 8
  %2152 = inttoptr i64 %2150 to i32*
  store i32 %2123, i32* %2152, align 4
  %2153 = load i64, i64* %RBP, align 8
  %2154 = add i64 %2153, -32
  %2155 = load i64, i64* %PC, align 8
  %2156 = add i64 %2155, 3
  store i64 %2156, i64* %PC, align 8
  %2157 = inttoptr i64 %2154 to i32*
  %2158 = load i32, i32* %2157, align 4
  %2159 = zext i32 %2158 to i64
  store i64 %2159, i64* %RCX, align 8, !tbaa !2428
  %2160 = add i64 %2153, -52
  %2161 = add i64 %2155, 6
  store i64 %2161, i64* %PC, align 8
  %2162 = inttoptr i64 %2160 to i32*
  %2163 = load i32, i32* %2162, align 4
  %2164 = add i32 %2163, %2158
  %2165 = zext i32 %2164 to i64
  store i64 %2165, i64* %RCX, align 8, !tbaa !2428
  %2166 = icmp ult i32 %2164, %2158
  %2167 = icmp ult i32 %2164, %2163
  %2168 = or i1 %2166, %2167
  %2169 = zext i1 %2168 to i8
  store i8 %2169, i8* %50, align 1, !tbaa !2433
  %2170 = and i32 %2164, 255
  %2171 = tail call i32 @llvm.ctpop.i32(i32 %2170) #10
  %2172 = trunc i32 %2171 to i8
  %2173 = and i8 %2172, 1
  %2174 = xor i8 %2173, 1
  store i8 %2174, i8* %51, align 1, !tbaa !2447
  %2175 = xor i32 %2163, %2158
  %2176 = xor i32 %2175, %2164
  %2177 = lshr i32 %2176, 4
  %2178 = trunc i32 %2177 to i8
  %2179 = and i8 %2178, 1
  store i8 %2179, i8* %52, align 1, !tbaa !2451
  %2180 = icmp eq i32 %2164, 0
  %2181 = zext i1 %2180 to i8
  store i8 %2181, i8* %53, align 1, !tbaa !2448
  %2182 = lshr i32 %2164, 31
  %2183 = trunc i32 %2182 to i8
  store i8 %2183, i8* %54, align 1, !tbaa !2449
  %2184 = lshr i32 %2158, 31
  %2185 = lshr i32 %2163, 31
  %2186 = xor i32 %2182, %2184
  %2187 = xor i32 %2182, %2185
  %2188 = add nuw nsw i32 %2186, %2187
  %2189 = icmp eq i32 %2188, 2
  %2190 = zext i1 %2189 to i8
  store i8 %2190, i8* %55, align 1, !tbaa !2450
  %2191 = add i64 %2153, -40
  %2192 = add i64 %2155, 9
  store i64 %2192, i64* %PC, align 8
  %2193 = inttoptr i64 %2191 to i32*
  store i32 %2164, i32* %2193, align 4
  %2194 = load i64, i64* %RBP, align 8
  %2195 = add i64 %2194, -24
  %2196 = load i64, i64* %PC, align 8
  %2197 = add i64 %2196, 4
  store i64 %2197, i64* %PC, align 8
  %2198 = inttoptr i64 %2195 to i64*
  %2199 = load i64, i64* %2198, align 8
  store i64 %2199, i64* %RDX, align 8, !tbaa !2428
  %2200 = add i64 %2194, -32
  %2201 = add i64 %2196, 8
  store i64 %2201, i64* %PC, align 8
  %2202 = inttoptr i64 %2200 to i32*
  %2203 = load i32, i32* %2202, align 4
  %2204 = sext i32 %2203 to i64
  store i64 %2204, i64* %RSI, align 8, !tbaa !2428
  %2205 = shl nsw i64 %2204, 3
  %2206 = add i64 %2205, %2199
  %2207 = add i64 %2196, 13
  store i64 %2207, i64* %PC, align 8
  %2208 = inttoptr i64 %2206 to i64*
  %2209 = load i64, i64* %2208, align 8
  store i64 %2209, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %2210 = add i64 %2194, -64
  %2211 = add i64 %2196, 18
  store i64 %2211, i64* %PC, align 8
  %2212 = inttoptr i64 %2210 to i64*
  store i64 %2209, i64* %2212, align 8
  %2213 = load i64, i64* %RBP, align 8
  %2214 = add i64 %2213, -24
  %2215 = load i64, i64* %PC, align 8
  %2216 = add i64 %2215, 4
  store i64 %2216, i64* %PC, align 8
  %2217 = inttoptr i64 %2214 to i64*
  %2218 = load i64, i64* %2217, align 8
  store i64 %2218, i64* %RDX, align 8, !tbaa !2428
  %2219 = add i64 %2213, -32
  %2220 = add i64 %2215, 7
  store i64 %2220, i64* %PC, align 8
  %2221 = inttoptr i64 %2219 to i32*
  %2222 = load i32, i32* %2221, align 4
  %2223 = add i32 %2222, 1
  %2224 = zext i32 %2223 to i64
  store i64 %2224, i64* %RCX, align 8, !tbaa !2428
  %2225 = icmp eq i32 %2222, -1
  %2226 = icmp eq i32 %2223, 0
  %2227 = or i1 %2225, %2226
  %2228 = zext i1 %2227 to i8
  store i8 %2228, i8* %50, align 1, !tbaa !2433
  %2229 = and i32 %2223, 255
  %2230 = tail call i32 @llvm.ctpop.i32(i32 %2229) #10
  %2231 = trunc i32 %2230 to i8
  %2232 = and i8 %2231, 1
  %2233 = xor i8 %2232, 1
  store i8 %2233, i8* %51, align 1, !tbaa !2447
  %2234 = xor i32 %2223, %2222
  %2235 = lshr i32 %2234, 4
  %2236 = trunc i32 %2235 to i8
  %2237 = and i8 %2236, 1
  store i8 %2237, i8* %52, align 1, !tbaa !2451
  %2238 = zext i1 %2226 to i8
  store i8 %2238, i8* %53, align 1, !tbaa !2448
  %2239 = lshr i32 %2223, 31
  %2240 = trunc i32 %2239 to i8
  store i8 %2240, i8* %54, align 1, !tbaa !2449
  %2241 = lshr i32 %2222, 31
  %2242 = xor i32 %2239, %2241
  %2243 = add nuw nsw i32 %2242, %2239
  %2244 = icmp eq i32 %2243, 2
  %2245 = zext i1 %2244 to i8
  store i8 %2245, i8* %55, align 1, !tbaa !2450
  %2246 = sext i32 %2223 to i64
  store i64 %2246, i64* %RSI, align 8, !tbaa !2428
  %2247 = shl nsw i64 %2246, 3
  %2248 = add i64 %2218, %2247
  %2249 = add i64 %2215, 18
  store i64 %2249, i64* %PC, align 8
  %2250 = inttoptr i64 %2248 to i64*
  %2251 = load i64, i64* %2250, align 8
  %2252 = load i64, i64* %RAX, align 8
  %2253 = xor i64 %2252, %2251
  store i64 %2253, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %2254 = trunc i64 %2253 to i32
  %2255 = and i32 %2254, 255
  %2256 = tail call i32 @llvm.ctpop.i32(i32 %2255) #10
  %2257 = trunc i32 %2256 to i8
  %2258 = and i8 %2257, 1
  %2259 = xor i8 %2258, 1
  store i8 %2259, i8* %51, align 1, !tbaa !2447
  %2260 = icmp eq i64 %2253, 0
  %2261 = zext i1 %2260 to i8
  store i8 %2261, i8* %53, align 1, !tbaa !2448
  %2262 = lshr i64 %2253, 63
  %2263 = trunc i64 %2262 to i8
  store i8 %2263, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %2253, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %2264 = add i64 %2213, -72
  %2265 = add i64 %2215, 36
  store i64 %2265, i64* %PC, align 8
  %2266 = inttoptr i64 %2264 to i64*
  store i64 %2253, i64* %2266, align 8
  %2267 = load i64, i64* %RBP, align 8
  %2268 = add i64 %2267, -24
  %2269 = load i64, i64* %PC, align 8
  %2270 = add i64 %2269, 4
  store i64 %2270, i64* %PC, align 8
  %2271 = inttoptr i64 %2268 to i64*
  %2272 = load i64, i64* %2271, align 8
  store i64 %2272, i64* %RDX, align 8, !tbaa !2428
  %2273 = add i64 %2267, -40
  %2274 = add i64 %2269, 8
  store i64 %2274, i64* %PC, align 8
  %2275 = inttoptr i64 %2273 to i32*
  %2276 = load i32, i32* %2275, align 4
  %2277 = sext i32 %2276 to i64
  store i64 %2277, i64* %RSI, align 8, !tbaa !2428
  %2278 = shl nsw i64 %2277, 3
  %2279 = add i64 %2278, %2272
  %2280 = add i64 %2269, 13
  store i64 %2280, i64* %PC, align 8
  %2281 = inttoptr i64 %2279 to i64*
  %2282 = load i64, i64* %2281, align 8
  store i64 %2282, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %2283 = add i64 %2267, -80
  %2284 = add i64 %2269, 18
  store i64 %2284, i64* %PC, align 8
  %2285 = inttoptr i64 %2283 to i64*
  store i64 %2282, i64* %2285, align 8
  %2286 = load i64, i64* %RBP, align 8
  %2287 = add i64 %2286, -24
  %2288 = load i64, i64* %PC, align 8
  %2289 = add i64 %2288, 4
  store i64 %2289, i64* %PC, align 8
  %2290 = inttoptr i64 %2287 to i64*
  %2291 = load i64, i64* %2290, align 8
  store i64 %2291, i64* %RDX, align 8, !tbaa !2428
  %2292 = add i64 %2286, -40
  %2293 = add i64 %2288, 7
  store i64 %2293, i64* %PC, align 8
  %2294 = inttoptr i64 %2292 to i32*
  %2295 = load i32, i32* %2294, align 4
  %2296 = add i32 %2295, 1
  %2297 = zext i32 %2296 to i64
  store i64 %2297, i64* %RCX, align 8, !tbaa !2428
  %2298 = icmp eq i32 %2295, -1
  %2299 = icmp eq i32 %2296, 0
  %2300 = or i1 %2298, %2299
  %2301 = zext i1 %2300 to i8
  store i8 %2301, i8* %50, align 1, !tbaa !2433
  %2302 = and i32 %2296, 255
  %2303 = tail call i32 @llvm.ctpop.i32(i32 %2302) #10
  %2304 = trunc i32 %2303 to i8
  %2305 = and i8 %2304, 1
  %2306 = xor i8 %2305, 1
  store i8 %2306, i8* %51, align 1, !tbaa !2447
  %2307 = xor i32 %2296, %2295
  %2308 = lshr i32 %2307, 4
  %2309 = trunc i32 %2308 to i8
  %2310 = and i8 %2309, 1
  store i8 %2310, i8* %52, align 1, !tbaa !2451
  %2311 = zext i1 %2299 to i8
  store i8 %2311, i8* %53, align 1, !tbaa !2448
  %2312 = lshr i32 %2296, 31
  %2313 = trunc i32 %2312 to i8
  store i8 %2313, i8* %54, align 1, !tbaa !2449
  %2314 = lshr i32 %2295, 31
  %2315 = xor i32 %2312, %2314
  %2316 = add nuw nsw i32 %2315, %2312
  %2317 = icmp eq i32 %2316, 2
  %2318 = zext i1 %2317 to i8
  store i8 %2318, i8* %55, align 1, !tbaa !2450
  %2319 = sext i32 %2296 to i64
  store i64 %2319, i64* %RSI, align 8, !tbaa !2428
  %2320 = shl nsw i64 %2319, 3
  %2321 = add i64 %2291, %2320
  %2322 = add i64 %2288, 18
  store i64 %2322, i64* %PC, align 8
  %2323 = inttoptr i64 %2321 to i64*
  %2324 = load i64, i64* %2323, align 8
  %2325 = load i64, i64* %RAX, align 8
  %2326 = xor i64 %2325, %2324
  store i64 %2326, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %2327 = trunc i64 %2326 to i32
  %2328 = and i32 %2327, 255
  %2329 = tail call i32 @llvm.ctpop.i32(i32 %2328) #10
  %2330 = trunc i32 %2329 to i8
  %2331 = and i8 %2330, 1
  %2332 = xor i8 %2331, 1
  store i8 %2332, i8* %51, align 1, !tbaa !2447
  %2333 = icmp eq i64 %2326, 0
  %2334 = zext i1 %2333 to i8
  store i8 %2334, i8* %53, align 1, !tbaa !2448
  %2335 = lshr i64 %2326, 63
  %2336 = trunc i64 %2335 to i8
  store i8 %2336, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %2326, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %2337 = add i64 %2286, -88
  %2338 = add i64 %2288, 36
  store i64 %2338, i64* %PC, align 8
  %2339 = inttoptr i64 %2337 to i64*
  store i64 %2326, i64* %2339, align 8
  %2340 = load i64, i64* %RBP, align 8
  %2341 = add i64 %2340, -80
  %2342 = load i64, i64* %PC, align 8
  %2343 = add i64 %2342, 5
  store i64 %2343, i64* %PC, align 8
  %2344 = inttoptr i64 %2341 to i64*
  %2345 = load i64, i64* %2344, align 8
  store i64 %2345, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %2346 = add i64 %2340, -24
  %2347 = add i64 %2342, 9
  store i64 %2347, i64* %PC, align 8
  %2348 = inttoptr i64 %2346 to i64*
  %2349 = load i64, i64* %2348, align 8
  store i64 %2349, i64* %RDX, align 8, !tbaa !2428
  %2350 = add i64 %2340, -32
  %2351 = add i64 %2342, 13
  store i64 %2351, i64* %PC, align 8
  %2352 = inttoptr i64 %2350 to i32*
  %2353 = load i32, i32* %2352, align 4
  %2354 = sext i32 %2353 to i64
  store i64 %2354, i64* %RSI, align 8, !tbaa !2428
  %2355 = shl nsw i64 %2354, 3
  %2356 = add i64 %2355, %2349
  %2357 = add i64 %2342, 18
  store i64 %2357, i64* %PC, align 8
  %2358 = inttoptr i64 %2356 to i64*
  store i64 %2345, i64* %2358, align 8
  %2359 = load i64, i64* %RBP, align 8
  %2360 = add i64 %2359, -88
  %2361 = load i64, i64* %PC, align 8
  %2362 = add i64 %2361, 5
  store i64 %2362, i64* %PC, align 8
  %2363 = inttoptr i64 %2360 to i64*
  %2364 = load i64, i64* %2363, align 8
  store i64 %2364, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %2365 = add i64 %2359, -24
  %2366 = add i64 %2361, 9
  store i64 %2366, i64* %PC, align 8
  %2367 = inttoptr i64 %2365 to i64*
  %2368 = load i64, i64* %2367, align 8
  store i64 %2368, i64* %RDX, align 8, !tbaa !2428
  %2369 = add i64 %2359, -32
  %2370 = add i64 %2361, 12
  store i64 %2370, i64* %PC, align 8
  %2371 = inttoptr i64 %2369 to i32*
  %2372 = load i32, i32* %2371, align 4
  %2373 = add i32 %2372, 1
  %2374 = zext i32 %2373 to i64
  store i64 %2374, i64* %RCX, align 8, !tbaa !2428
  %2375 = icmp eq i32 %2372, -1
  %2376 = icmp eq i32 %2373, 0
  %2377 = or i1 %2375, %2376
  %2378 = zext i1 %2377 to i8
  store i8 %2378, i8* %50, align 1, !tbaa !2433
  %2379 = and i32 %2373, 255
  %2380 = tail call i32 @llvm.ctpop.i32(i32 %2379) #10
  %2381 = trunc i32 %2380 to i8
  %2382 = and i8 %2381, 1
  %2383 = xor i8 %2382, 1
  store i8 %2383, i8* %51, align 1, !tbaa !2447
  %2384 = xor i32 %2373, %2372
  %2385 = lshr i32 %2384, 4
  %2386 = trunc i32 %2385 to i8
  %2387 = and i8 %2386, 1
  store i8 %2387, i8* %52, align 1, !tbaa !2451
  %2388 = zext i1 %2376 to i8
  store i8 %2388, i8* %53, align 1, !tbaa !2448
  %2389 = lshr i32 %2373, 31
  %2390 = trunc i32 %2389 to i8
  store i8 %2390, i8* %54, align 1, !tbaa !2449
  %2391 = lshr i32 %2372, 31
  %2392 = xor i32 %2389, %2391
  %2393 = add nuw nsw i32 %2392, %2389
  %2394 = icmp eq i32 %2393, 2
  %2395 = zext i1 %2394 to i8
  store i8 %2395, i8* %55, align 1, !tbaa !2450
  %2396 = sext i32 %2373 to i64
  store i64 %2396, i64* %RSI, align 8, !tbaa !2428
  %2397 = shl nsw i64 %2396, 3
  %2398 = add i64 %2368, %2397
  %2399 = add i64 %2361, 23
  store i64 %2399, i64* %PC, align 8
  %2400 = inttoptr i64 %2398 to i64*
  store i64 %2364, i64* %2400, align 8
  %2401 = load i64, i64* %RBP, align 8
  %2402 = add i64 %2401, -64
  %2403 = load i64, i64* %PC, align 8
  %2404 = add i64 %2403, 5
  store i64 %2404, i64* %PC, align 8
  %2405 = inttoptr i64 %2402 to i64*
  %2406 = load i64, i64* %2405, align 8
  store i64 %2406, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %2407 = add i64 %2401, -24
  %2408 = add i64 %2403, 9
  store i64 %2408, i64* %PC, align 8
  %2409 = inttoptr i64 %2407 to i64*
  %2410 = load i64, i64* %2409, align 8
  store i64 %2410, i64* %RDX, align 8, !tbaa !2428
  %2411 = add i64 %2401, -40
  %2412 = add i64 %2403, 13
  store i64 %2412, i64* %PC, align 8
  %2413 = inttoptr i64 %2411 to i32*
  %2414 = load i32, i32* %2413, align 4
  %2415 = sext i32 %2414 to i64
  store i64 %2415, i64* %RSI, align 8, !tbaa !2428
  %2416 = shl nsw i64 %2415, 3
  %2417 = add i64 %2416, %2410
  %2418 = add i64 %2403, 18
  store i64 %2418, i64* %PC, align 8
  %2419 = inttoptr i64 %2417 to i64*
  store i64 %2406, i64* %2419, align 8
  %2420 = load i64, i64* %RBP, align 8
  %2421 = add i64 %2420, -72
  %2422 = load i64, i64* %PC, align 8
  %2423 = add i64 %2422, 5
  store i64 %2423, i64* %PC, align 8
  %2424 = inttoptr i64 %2421 to i64*
  %2425 = load i64, i64* %2424, align 8
  store i64 %2425, i64* %3719, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3721, align 1, !tbaa !2452
  %2426 = add i64 %2420, -24
  %2427 = add i64 %2422, 9
  store i64 %2427, i64* %PC, align 8
  %2428 = inttoptr i64 %2426 to i64*
  %2429 = load i64, i64* %2428, align 8
  store i64 %2429, i64* %RDX, align 8, !tbaa !2428
  %2430 = add i64 %2420, -40
  %2431 = add i64 %2422, 12
  store i64 %2431, i64* %PC, align 8
  %2432 = inttoptr i64 %2430 to i32*
  %2433 = load i32, i32* %2432, align 4
  %2434 = add i32 %2433, 1
  %2435 = zext i32 %2434 to i64
  store i64 %2435, i64* %RCX, align 8, !tbaa !2428
  %2436 = icmp eq i32 %2433, -1
  %2437 = icmp eq i32 %2434, 0
  %2438 = or i1 %2436, %2437
  %2439 = zext i1 %2438 to i8
  store i8 %2439, i8* %50, align 1, !tbaa !2433
  %2440 = and i32 %2434, 255
  %2441 = tail call i32 @llvm.ctpop.i32(i32 %2440) #10
  %2442 = trunc i32 %2441 to i8
  %2443 = and i8 %2442, 1
  %2444 = xor i8 %2443, 1
  store i8 %2444, i8* %51, align 1, !tbaa !2447
  %2445 = xor i32 %2434, %2433
  %2446 = lshr i32 %2445, 4
  %2447 = trunc i32 %2446 to i8
  %2448 = and i8 %2447, 1
  store i8 %2448, i8* %52, align 1, !tbaa !2451
  %2449 = zext i1 %2437 to i8
  store i8 %2449, i8* %53, align 1, !tbaa !2448
  %2450 = lshr i32 %2434, 31
  %2451 = trunc i32 %2450 to i8
  store i8 %2451, i8* %54, align 1, !tbaa !2449
  %2452 = lshr i32 %2433, 31
  %2453 = xor i32 %2450, %2452
  %2454 = add nuw nsw i32 %2453, %2450
  %2455 = icmp eq i32 %2454, 2
  %2456 = zext i1 %2455 to i8
  store i8 %2456, i8* %55, align 1, !tbaa !2450
  %2457 = sext i32 %2434 to i64
  store i64 %2457, i64* %RSI, align 8, !tbaa !2428
  %2458 = shl nsw i64 %2457, 3
  %2459 = add i64 %2429, %2458
  %2460 = add i64 %2422, 23
  store i64 %2460, i64* %PC, align 8
  %2461 = inttoptr i64 %2459 to i64*
  store i64 %2425, i64* %2461, align 8
  %2462 = load i64, i64* %RBP, align 8
  %2463 = add i64 %2462, -52
  %2464 = load i64, i64* %PC, align 8
  %2465 = add i64 %2464, 3
  store i64 %2465, i64* %PC, align 8
  %2466 = inttoptr i64 %2463 to i32*
  %2467 = load i32, i32* %2466, align 4
  %2468 = zext i32 %2467 to i64
  store i64 %2468, i64* %RCX, align 8, !tbaa !2428
  %2469 = add i64 %2462, -40
  %2470 = add i64 %2464, 6
  store i64 %2470, i64* %PC, align 8
  %2471 = inttoptr i64 %2469 to i32*
  %2472 = load i32, i32* %2471, align 4
  %2473 = add i32 %2472, %2467
  %2474 = zext i32 %2473 to i64
  store i64 %2474, i64* %RCX, align 8, !tbaa !2428
  %2475 = icmp ult i32 %2473, %2467
  %2476 = icmp ult i32 %2473, %2472
  %2477 = or i1 %2475, %2476
  %2478 = zext i1 %2477 to i8
  store i8 %2478, i8* %50, align 1, !tbaa !2433
  %2479 = and i32 %2473, 255
  %2480 = tail call i32 @llvm.ctpop.i32(i32 %2479) #10
  %2481 = trunc i32 %2480 to i8
  %2482 = and i8 %2481, 1
  %2483 = xor i8 %2482, 1
  store i8 %2483, i8* %51, align 1, !tbaa !2447
  %2484 = xor i32 %2472, %2467
  %2485 = xor i32 %2484, %2473
  %2486 = lshr i32 %2485, 4
  %2487 = trunc i32 %2486 to i8
  %2488 = and i8 %2487, 1
  store i8 %2488, i8* %52, align 1, !tbaa !2451
  %2489 = icmp eq i32 %2473, 0
  %2490 = zext i1 %2489 to i8
  store i8 %2490, i8* %53, align 1, !tbaa !2448
  %2491 = lshr i32 %2473, 31
  %2492 = trunc i32 %2491 to i8
  store i8 %2492, i8* %54, align 1, !tbaa !2449
  %2493 = lshr i32 %2467, 31
  %2494 = lshr i32 %2472, 31
  %2495 = xor i32 %2491, %2493
  %2496 = xor i32 %2491, %2494
  %2497 = add nuw nsw i32 %2495, %2496
  %2498 = icmp eq i32 %2497, 2
  %2499 = zext i1 %2498 to i8
  store i8 %2499, i8* %55, align 1, !tbaa !2450
  %2500 = add i64 %2464, 9
  store i64 %2500, i64* %PC, align 8
  store i32 %2473, i32* %2471, align 4
  %2501 = load i64, i64* %RBP, align 8
  %2502 = add i64 %2501, -24
  %2503 = load i64, i64* %PC, align 8
  %2504 = add i64 %2503, 4
  store i64 %2504, i64* %PC, align 8
  %2505 = inttoptr i64 %2502 to i64*
  %2506 = load i64, i64* %2505, align 8
  store i64 %2506, i64* %RDX, align 8, !tbaa !2428
  %2507 = add i64 %2501, -40
  %2508 = add i64 %2503, 7
  store i64 %2508, i64* %PC, align 8
  %2509 = inttoptr i64 %2507 to i32*
  %2510 = load i32, i32* %2509, align 4
  %2511 = add i32 %2510, 1
  %2512 = zext i32 %2511 to i64
  store i64 %2512, i64* %RCX, align 8, !tbaa !2428
  %2513 = icmp eq i32 %2510, -1
  %2514 = icmp eq i32 %2511, 0
  %2515 = or i1 %2513, %2514
  %2516 = zext i1 %2515 to i8
  store i8 %2516, i8* %50, align 1, !tbaa !2433
  %2517 = and i32 %2511, 255
  %2518 = tail call i32 @llvm.ctpop.i32(i32 %2517) #10
  %2519 = trunc i32 %2518 to i8
  %2520 = and i8 %2519, 1
  %2521 = xor i8 %2520, 1
  store i8 %2521, i8* %51, align 1, !tbaa !2447
  %2522 = xor i32 %2511, %2510
  %2523 = lshr i32 %2522, 4
  %2524 = trunc i32 %2523 to i8
  %2525 = and i8 %2524, 1
  store i8 %2525, i8* %52, align 1, !tbaa !2451
  %2526 = zext i1 %2514 to i8
  store i8 %2526, i8* %53, align 1, !tbaa !2448
  %2527 = lshr i32 %2511, 31
  %2528 = trunc i32 %2527 to i8
  store i8 %2528, i8* %54, align 1, !tbaa !2449
  %2529 = lshr i32 %2510, 31
  %2530 = xor i32 %2527, %2529
  %2531 = add nuw nsw i32 %2530, %2527
  %2532 = icmp eq i32 %2531, 2
  %2533 = zext i1 %2532 to i8
  store i8 %2533, i8* %55, align 1, !tbaa !2450
  %2534 = sext i32 %2511 to i64
  store i64 %2534, i64* %RSI, align 8, !tbaa !2428
  %2535 = shl nsw i64 %2534, 3
  %2536 = add i64 %2506, %2535
  %2537 = add i64 %2503, 18
  store i64 %2537, i64* %PC, align 8
  %2538 = inttoptr i64 %2536 to i64*
  %2539 = load i64, i64* %2538, align 8
  %2540 = load i64, i64* %RAX, align 8
  %2541 = xor i64 %2540, %2539
  store i64 %2541, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %2542 = trunc i64 %2541 to i32
  %2543 = and i32 %2542, 255
  %2544 = tail call i32 @llvm.ctpop.i32(i32 %2543) #10
  %2545 = trunc i32 %2544 to i8
  %2546 = and i8 %2545, 1
  %2547 = xor i8 %2546, 1
  store i8 %2547, i8* %51, align 1, !tbaa !2447
  %2548 = icmp eq i64 %2541, 0
  %2549 = zext i1 %2548 to i8
  store i8 %2549, i8* %53, align 1, !tbaa !2448
  %2550 = lshr i64 %2541, 63
  %2551 = trunc i64 %2550 to i8
  store i8 %2551, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %2541, i64* %3719, align 1, !tbaa !2428
  store i64 0, i64* %3720, align 1, !tbaa !2428
  %2552 = add i64 %2503, 35
  store i64 %2552, i64* %PC, align 8
  %2553 = load i64, i64* %2505, align 8
  store i64 %2553, i64* %RAX, align 8, !tbaa !2428
  %2554 = add i64 %2503, 38
  store i64 %2554, i64* %PC, align 8
  %2555 = load i32, i32* %2509, align 4
  %2556 = add i32 %2555, 1
  %2557 = zext i32 %2556 to i64
  store i64 %2557, i64* %RCX, align 8, !tbaa !2428
  %2558 = icmp eq i32 %2555, -1
  %2559 = icmp eq i32 %2556, 0
  %2560 = or i1 %2558, %2559
  %2561 = zext i1 %2560 to i8
  store i8 %2561, i8* %50, align 1, !tbaa !2433
  %2562 = and i32 %2556, 255
  %2563 = tail call i32 @llvm.ctpop.i32(i32 %2562) #10
  %2564 = trunc i32 %2563 to i8
  %2565 = and i8 %2564, 1
  %2566 = xor i8 %2565, 1
  store i8 %2566, i8* %51, align 1, !tbaa !2447
  %2567 = xor i32 %2556, %2555
  %2568 = lshr i32 %2567, 4
  %2569 = trunc i32 %2568 to i8
  %2570 = and i8 %2569, 1
  store i8 %2570, i8* %52, align 1, !tbaa !2451
  %2571 = zext i1 %2559 to i8
  store i8 %2571, i8* %53, align 1, !tbaa !2448
  %2572 = lshr i32 %2556, 31
  %2573 = trunc i32 %2572 to i8
  store i8 %2573, i8* %54, align 1, !tbaa !2449
  %2574 = lshr i32 %2555, 31
  %2575 = xor i32 %2572, %2574
  %2576 = add nuw nsw i32 %2575, %2572
  %2577 = icmp eq i32 %2576, 2
  %2578 = zext i1 %2577 to i8
  store i8 %2578, i8* %55, align 1, !tbaa !2450
  %2579 = sext i32 %2556 to i64
  store i64 %2579, i64* %RDX, align 8, !tbaa !2428
  %2580 = shl nsw i64 %2579, 3
  %2581 = add i64 %2553, %2580
  %2582 = add i64 %2503, 49
  store i64 %2582, i64* %PC, align 8
  %2583 = inttoptr i64 %2581 to i64*
  store i64 %2541, i64* %2583, align 8
  %2584 = load i64, i64* %RBP, align 8
  %2585 = add i64 %2584, -36
  %2586 = load i64, i64* %PC, align 8
  %2587 = add i64 %2586, 3
  store i64 %2587, i64* %PC, align 8
  %2588 = inttoptr i64 %2585 to i32*
  %2589 = load i32, i32* %2588, align 4
  %2590 = add i32 %2589, 1
  %2591 = zext i32 %2590 to i64
  store i64 %2591, i64* %RAX, align 8, !tbaa !2428
  %2592 = icmp eq i32 %2589, -1
  %2593 = icmp eq i32 %2590, 0
  %2594 = or i1 %2592, %2593
  %2595 = zext i1 %2594 to i8
  store i8 %2595, i8* %50, align 1, !tbaa !2433
  %2596 = and i32 %2590, 255
  %2597 = tail call i32 @llvm.ctpop.i32(i32 %2596) #10
  %2598 = trunc i32 %2597 to i8
  %2599 = and i8 %2598, 1
  %2600 = xor i8 %2599, 1
  store i8 %2600, i8* %51, align 1, !tbaa !2447
  %2601 = xor i32 %2590, %2589
  %2602 = lshr i32 %2601, 4
  %2603 = trunc i32 %2602 to i8
  %2604 = and i8 %2603, 1
  store i8 %2604, i8* %52, align 1, !tbaa !2451
  %2605 = zext i1 %2593 to i8
  store i8 %2605, i8* %53, align 1, !tbaa !2448
  %2606 = lshr i32 %2590, 31
  %2607 = trunc i32 %2606 to i8
  store i8 %2607, i8* %54, align 1, !tbaa !2449
  %2608 = lshr i32 %2589, 31
  %2609 = xor i32 %2606, %2608
  %2610 = add nuw nsw i32 %2609, %2606
  %2611 = icmp eq i32 %2610, 2
  %2612 = zext i1 %2611 to i8
  store i8 %2612, i8* %55, align 1, !tbaa !2450
  %2613 = add i64 %2586, 9
  store i64 %2613, i64* %PC, align 8
  store i32 %2590, i32* %2588, align 4
  %2614 = load i64, i64* %PC, align 8
  %2615 = add i64 %2614, -1271
  store i64 %2615, i64* %PC, align 8, !tbaa !2428
  br label %block_401caa

block_401cbd:                                     ; preds = %block_401cb6, %block_401cc9
  %2616 = phi i64 [ %.pre41, %block_401cb6 ], [ %1967, %block_401cc9 ]
  %2617 = load i64, i64* %RBP, align 8
  %2618 = add i64 %2617, -28
  %2619 = add i64 %2616, 3
  store i64 %2619, i64* %PC, align 8
  %2620 = inttoptr i64 %2618 to i32*
  %2621 = load i32, i32* %2620, align 4
  %2622 = zext i32 %2621 to i64
  store i64 %2622, i64* %RAX, align 8, !tbaa !2428
  %2623 = add i64 %2617, -36
  %2624 = add i64 %2616, 6
  store i64 %2624, i64* %PC, align 8
  %2625 = inttoptr i64 %2623 to i32*
  %2626 = load i32, i32* %2625, align 4
  %2627 = sub i32 %2621, %2626
  %2628 = icmp ult i32 %2621, %2626
  %2629 = zext i1 %2628 to i8
  store i8 %2629, i8* %50, align 1, !tbaa !2433
  %2630 = and i32 %2627, 255
  %2631 = tail call i32 @llvm.ctpop.i32(i32 %2630) #10
  %2632 = trunc i32 %2631 to i8
  %2633 = and i8 %2632, 1
  %2634 = xor i8 %2633, 1
  store i8 %2634, i8* %51, align 1, !tbaa !2447
  %2635 = xor i32 %2626, %2621
  %2636 = xor i32 %2635, %2627
  %2637 = lshr i32 %2636, 4
  %2638 = trunc i32 %2637 to i8
  %2639 = and i8 %2638, 1
  store i8 %2639, i8* %52, align 1, !tbaa !2451
  %2640 = icmp eq i32 %2627, 0
  %2641 = zext i1 %2640 to i8
  store i8 %2641, i8* %53, align 1, !tbaa !2448
  %2642 = lshr i32 %2627, 31
  %2643 = trunc i32 %2642 to i8
  store i8 %2643, i8* %54, align 1, !tbaa !2449
  %2644 = lshr i32 %2621, 31
  %2645 = lshr i32 %2626, 31
  %2646 = xor i32 %2645, %2644
  %2647 = xor i32 %2642, %2644
  %2648 = add nuw nsw i32 %2647, %2646
  %2649 = icmp eq i32 %2648, 2
  %2650 = zext i1 %2649 to i8
  store i8 %2650, i8* %55, align 1, !tbaa !2450
  %2651 = icmp ne i8 %2643, 0
  %2652 = xor i1 %2651, %2649
  %.v49 = select i1 %2652, i64 12, i64 898
  %2653 = add i64 %2616, %.v49
  %2654 = add i64 %2653, 10
  store i64 %2654, i64* %PC, align 8
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %2655 = add i64 %2653, 13
  store i64 %2655, i64* %PC, align 8
  br i1 %2652, label %block_401cc9, label %block_40203f

block_401cb6:                                     ; preds = %block_401caa
  %2656 = add i64 %3531, -28
  %2657 = add i64 %3567, 7
  store i64 %2657, i64* %PC, align 8
  %2658 = inttoptr i64 %2656 to i32*
  store i32 0, i32* %2658, align 4
  %.pre41 = load i64, i64* %PC, align 8
  br label %block_401cbd

block_40222b:                                     ; preds = %block_40221f
  %2659 = load i32, i32* %3491, align 4
  %2660 = shl i32 %2659, 1
  %2661 = icmp slt i32 %2659, 0
  %2662 = icmp slt i32 %2660, 0
  %2663 = xor i1 %2661, %2662
  %2664 = zext i32 %2660 to i64
  store i64 %2664, i64* %RCX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %2659, 31
  %2665 = trunc i32 %.lobit19 to i8
  store i8 %2665, i8* %50, align 1, !tbaa !2432
  %2666 = and i32 %2660, 254
  %2667 = tail call i32 @llvm.ctpop.i32(i32 %2666) #10
  %2668 = trunc i32 %2667 to i8
  %2669 = and i8 %2668, 1
  %2670 = xor i8 %2669, 1
  store i8 %2670, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %2671 = icmp eq i32 %2660, 0
  %2672 = zext i1 %2671 to i8
  store i8 %2672, i8* %53, align 1, !tbaa !2432
  %2673 = lshr i32 %2659, 30
  %2674 = trunc i32 %2673 to i8
  %2675 = and i8 %2674, 1
  store i8 %2675, i8* %54, align 1, !tbaa !2432
  %2676 = zext i1 %2663 to i8
  store i8 %2676, i8* %55, align 1, !tbaa !2432
  %2677 = add i64 %3488, -16
  %2678 = add i64 %3524, 20
  store i64 %2678, i64* %PC, align 8
  %2679 = inttoptr i64 %2677 to i64*
  %2680 = load i64, i64* %2679, align 8
  store i64 %2680, i64* %RDX, align 8, !tbaa !2428
  %2681 = add i64 %3524, 24
  store i64 %2681, i64* %PC, align 8
  %2682 = load i32, i32* %3496, align 4
  %2683 = sext i32 %2682 to i64
  store i64 %2683, i64* %RSI, align 8, !tbaa !2428
  %2684 = shl nsw i64 %2683, 2
  %2685 = add i64 %2680, %2684
  %2686 = add i64 %3524, 27
  store i64 %2686, i64* %PC, align 8
  %2687 = inttoptr i64 %2685 to i32*
  %2688 = load i32, i32* %2687, align 4
  %2689 = add i32 %2688, %2660
  %2690 = zext i32 %2689 to i64
  store i64 %2690, i64* %RCX, align 8, !tbaa !2428
  %2691 = icmp ult i32 %2689, %2660
  %2692 = icmp ult i32 %2689, %2688
  %2693 = or i1 %2691, %2692
  %2694 = zext i1 %2693 to i8
  store i8 %2694, i8* %50, align 1, !tbaa !2433
  %2695 = and i32 %2689, 255
  %2696 = tail call i32 @llvm.ctpop.i32(i32 %2695) #10
  %2697 = trunc i32 %2696 to i8
  %2698 = and i8 %2697, 1
  %2699 = xor i8 %2698, 1
  store i8 %2699, i8* %51, align 1, !tbaa !2447
  %2700 = xor i32 %2688, %2660
  %2701 = xor i32 %2700, %2689
  %2702 = lshr i32 %2701, 4
  %2703 = trunc i32 %2702 to i8
  %2704 = and i8 %2703, 1
  store i8 %2704, i8* %52, align 1, !tbaa !2451
  %2705 = icmp eq i32 %2689, 0
  %2706 = zext i1 %2705 to i8
  store i8 %2706, i8* %53, align 1, !tbaa !2448
  %2707 = lshr i32 %2689, 31
  %2708 = trunc i32 %2707 to i8
  store i8 %2708, i8* %54, align 1, !tbaa !2449
  %2709 = lshr i32 %2659, 30
  %2710 = and i32 %2709, 1
  %2711 = lshr i32 %2688, 31
  %2712 = xor i32 %2707, %2710
  %2713 = xor i32 %2707, %2711
  %2714 = add nuw nsw i32 %2712, %2713
  %2715 = icmp eq i32 %2714, 2
  %2716 = zext i1 %2715 to i8
  store i8 %2716, i8* %55, align 1, !tbaa !2450
  %2717 = add i64 %3488, -32
  %2718 = add i64 %3524, 30
  store i64 %2718, i64* %PC, align 8
  %2719 = inttoptr i64 %2717 to i32*
  store i32 %2689, i32* %2719, align 4
  %2720 = load i64, i64* %RBP, align 8
  %2721 = add i64 %2720, -36
  %2722 = load i64, i64* %PC, align 8
  %2723 = add i64 %2722, 3
  store i64 %2723, i64* %PC, align 8
  %2724 = inttoptr i64 %2721 to i32*
  %2725 = load i32, i32* %2724, align 4
  %2726 = shl i32 %2725, 1
  %2727 = icmp slt i32 %2725, 0
  %2728 = icmp slt i32 %2726, 0
  %2729 = xor i1 %2727, %2728
  %2730 = zext i32 %2726 to i64
  store i64 %2730, i64* %RCX, align 8, !tbaa !2428
  %.lobit20 = lshr i32 %2725, 31
  %2731 = trunc i32 %.lobit20 to i8
  store i8 %2731, i8* %50, align 1, !tbaa !2432
  %2732 = and i32 %2726, 254
  %2733 = tail call i32 @llvm.ctpop.i32(i32 %2732) #10
  %2734 = trunc i32 %2733 to i8
  %2735 = and i8 %2734, 1
  %2736 = xor i8 %2735, 1
  store i8 %2736, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %2737 = icmp eq i32 %2726, 0
  %2738 = zext i1 %2737 to i8
  store i8 %2738, i8* %53, align 1, !tbaa !2432
  %2739 = lshr i32 %2725, 30
  %2740 = trunc i32 %2739 to i8
  %2741 = and i8 %2740, 1
  store i8 %2741, i8* %54, align 1, !tbaa !2432
  %2742 = zext i1 %2729 to i8
  store i8 %2742, i8* %55, align 1, !tbaa !2432
  %2743 = add i64 %2720, -16
  %2744 = add i64 %2722, 10
  store i64 %2744, i64* %PC, align 8
  %2745 = inttoptr i64 %2743 to i64*
  %2746 = load i64, i64* %2745, align 8
  store i64 %2746, i64* %RDX, align 8, !tbaa !2428
  %2747 = add i64 %2720, -28
  %2748 = add i64 %2722, 14
  store i64 %2748, i64* %PC, align 8
  %2749 = inttoptr i64 %2747 to i32*
  %2750 = load i32, i32* %2749, align 4
  %2751 = sext i32 %2750 to i64
  store i64 %2751, i64* %RSI, align 8, !tbaa !2428
  %2752 = shl nsw i64 %2751, 2
  %2753 = add i64 %2746, %2752
  %2754 = add i64 %2722, 17
  store i64 %2754, i64* %PC, align 8
  %2755 = inttoptr i64 %2753 to i32*
  %2756 = load i32, i32* %2755, align 4
  %2757 = add i32 %2756, %2726
  %2758 = zext i32 %2757 to i64
  store i64 %2758, i64* %RCX, align 8, !tbaa !2428
  %2759 = icmp ult i32 %2757, %2726
  %2760 = icmp ult i32 %2757, %2756
  %2761 = or i1 %2759, %2760
  %2762 = zext i1 %2761 to i8
  store i8 %2762, i8* %50, align 1, !tbaa !2433
  %2763 = and i32 %2757, 255
  %2764 = tail call i32 @llvm.ctpop.i32(i32 %2763) #10
  %2765 = trunc i32 %2764 to i8
  %2766 = and i8 %2765, 1
  %2767 = xor i8 %2766, 1
  store i8 %2767, i8* %51, align 1, !tbaa !2447
  %2768 = xor i32 %2756, %2726
  %2769 = xor i32 %2768, %2757
  %2770 = lshr i32 %2769, 4
  %2771 = trunc i32 %2770 to i8
  %2772 = and i8 %2771, 1
  store i8 %2772, i8* %52, align 1, !tbaa !2451
  %2773 = icmp eq i32 %2757, 0
  %2774 = zext i1 %2773 to i8
  store i8 %2774, i8* %53, align 1, !tbaa !2448
  %2775 = lshr i32 %2757, 31
  %2776 = trunc i32 %2775 to i8
  store i8 %2776, i8* %54, align 1, !tbaa !2449
  %2777 = lshr i32 %2725, 30
  %2778 = and i32 %2777, 1
  %2779 = lshr i32 %2756, 31
  %2780 = xor i32 %2775, %2778
  %2781 = xor i32 %2775, %2779
  %2782 = add nuw nsw i32 %2780, %2781
  %2783 = icmp eq i32 %2782, 2
  %2784 = zext i1 %2783 to i8
  store i8 %2784, i8* %55, align 1, !tbaa !2450
  %2785 = add i64 %2720, -40
  %2786 = add i64 %2722, 20
  store i64 %2786, i64* %PC, align 8
  %2787 = inttoptr i64 %2785 to i32*
  store i32 %2757, i32* %2787, align 4
  %2788 = load i64, i64* %RBP, align 8
  %2789 = add i64 %2788, -24
  %2790 = load i64, i64* %PC, align 8
  %2791 = add i64 %2790, 4
  store i64 %2791, i64* %PC, align 8
  %2792 = inttoptr i64 %2789 to i64*
  %2793 = load i64, i64* %2792, align 8
  store i64 %2793, i64* %RDX, align 8, !tbaa !2428
  %2794 = add i64 %2788, -32
  %2795 = add i64 %2790, 8
  store i64 %2795, i64* %PC, align 8
  %2796 = inttoptr i64 %2794 to i32*
  %2797 = load i32, i32* %2796, align 4
  %2798 = sext i32 %2797 to i64
  store i64 %2798, i64* %RSI, align 8, !tbaa !2428
  %2799 = shl nsw i64 %2798, 3
  %2800 = add i64 %2799, %2793
  %2801 = add i64 %2790, 13
  store i64 %2801, i64* %PC, align 8
  %2802 = inttoptr i64 %2800 to i64*
  %2803 = load i64, i64* %2802, align 8
  store i64 %2803, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %2804 = add i64 %2788, -64
  %2805 = add i64 %2790, 18
  store i64 %2805, i64* %PC, align 8
  %2806 = inttoptr i64 %2804 to i64*
  store i64 %2803, i64* %2806, align 8
  %2807 = load i64, i64* %RBP, align 8
  %2808 = add i64 %2807, -24
  %2809 = load i64, i64* %PC, align 8
  %2810 = add i64 %2809, 4
  store i64 %2810, i64* %PC, align 8
  %2811 = inttoptr i64 %2808 to i64*
  %2812 = load i64, i64* %2811, align 8
  store i64 %2812, i64* %RDX, align 8, !tbaa !2428
  %2813 = add i64 %2807, -32
  %2814 = add i64 %2809, 7
  store i64 %2814, i64* %PC, align 8
  %2815 = inttoptr i64 %2813 to i32*
  %2816 = load i32, i32* %2815, align 4
  %2817 = add i32 %2816, 1
  %2818 = zext i32 %2817 to i64
  store i64 %2818, i64* %RCX, align 8, !tbaa !2428
  %2819 = icmp eq i32 %2816, -1
  %2820 = icmp eq i32 %2817, 0
  %2821 = or i1 %2819, %2820
  %2822 = zext i1 %2821 to i8
  store i8 %2822, i8* %50, align 1, !tbaa !2433
  %2823 = and i32 %2817, 255
  %2824 = tail call i32 @llvm.ctpop.i32(i32 %2823) #10
  %2825 = trunc i32 %2824 to i8
  %2826 = and i8 %2825, 1
  %2827 = xor i8 %2826, 1
  store i8 %2827, i8* %51, align 1, !tbaa !2447
  %2828 = xor i32 %2817, %2816
  %2829 = lshr i32 %2828, 4
  %2830 = trunc i32 %2829 to i8
  %2831 = and i8 %2830, 1
  store i8 %2831, i8* %52, align 1, !tbaa !2451
  %2832 = zext i1 %2820 to i8
  store i8 %2832, i8* %53, align 1, !tbaa !2448
  %2833 = lshr i32 %2817, 31
  %2834 = trunc i32 %2833 to i8
  store i8 %2834, i8* %54, align 1, !tbaa !2449
  %2835 = lshr i32 %2816, 31
  %2836 = xor i32 %2833, %2835
  %2837 = add nuw nsw i32 %2836, %2833
  %2838 = icmp eq i32 %2837, 2
  %2839 = zext i1 %2838 to i8
  store i8 %2839, i8* %55, align 1, !tbaa !2450
  %2840 = sext i32 %2817 to i64
  store i64 %2840, i64* %RSI, align 8, !tbaa !2428
  %2841 = shl nsw i64 %2840, 3
  %2842 = add i64 %2812, %2841
  %2843 = add i64 %2809, 18
  store i64 %2843, i64* %PC, align 8
  %2844 = inttoptr i64 %2842 to i64*
  %2845 = load i64, i64* %2844, align 8
  %2846 = load i64, i64* %RAX, align 8
  %2847 = xor i64 %2846, %2845
  store i64 %2847, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %2848 = trunc i64 %2847 to i32
  %2849 = and i32 %2848, 255
  %2850 = tail call i32 @llvm.ctpop.i32(i32 %2849) #10
  %2851 = trunc i32 %2850 to i8
  %2852 = and i8 %2851, 1
  %2853 = xor i8 %2852, 1
  store i8 %2853, i8* %51, align 1, !tbaa !2447
  %2854 = icmp eq i64 %2847, 0
  %2855 = zext i1 %2854 to i8
  store i8 %2855, i8* %53, align 1, !tbaa !2448
  %2856 = lshr i64 %2847, 63
  %2857 = trunc i64 %2856 to i8
  store i8 %2857, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %2847, i64* %3730, align 1, !tbaa !2428
  store i64 0, i64* %3731, align 1, !tbaa !2428
  %2858 = add i64 %2807, -72
  %2859 = add i64 %2809, 36
  store i64 %2859, i64* %PC, align 8
  %2860 = inttoptr i64 %2858 to i64*
  store i64 %2847, i64* %2860, align 8
  %2861 = load i64, i64* %RBP, align 8
  %2862 = add i64 %2861, -24
  %2863 = load i64, i64* %PC, align 8
  %2864 = add i64 %2863, 4
  store i64 %2864, i64* %PC, align 8
  %2865 = inttoptr i64 %2862 to i64*
  %2866 = load i64, i64* %2865, align 8
  store i64 %2866, i64* %RDX, align 8, !tbaa !2428
  %2867 = add i64 %2861, -40
  %2868 = add i64 %2863, 8
  store i64 %2868, i64* %PC, align 8
  %2869 = inttoptr i64 %2867 to i32*
  %2870 = load i32, i32* %2869, align 4
  %2871 = sext i32 %2870 to i64
  store i64 %2871, i64* %RSI, align 8, !tbaa !2428
  %2872 = shl nsw i64 %2871, 3
  %2873 = add i64 %2872, %2866
  %2874 = add i64 %2863, 13
  store i64 %2874, i64* %PC, align 8
  %2875 = inttoptr i64 %2873 to i64*
  %2876 = load i64, i64* %2875, align 8
  store i64 %2876, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %2877 = add i64 %2861, -80
  %2878 = add i64 %2863, 18
  store i64 %2878, i64* %PC, align 8
  %2879 = inttoptr i64 %2877 to i64*
  store i64 %2876, i64* %2879, align 8
  %2880 = load i64, i64* %RBP, align 8
  %2881 = add i64 %2880, -24
  %2882 = load i64, i64* %PC, align 8
  %2883 = add i64 %2882, 4
  store i64 %2883, i64* %PC, align 8
  %2884 = inttoptr i64 %2881 to i64*
  %2885 = load i64, i64* %2884, align 8
  store i64 %2885, i64* %RDX, align 8, !tbaa !2428
  %2886 = add i64 %2880, -40
  %2887 = add i64 %2882, 7
  store i64 %2887, i64* %PC, align 8
  %2888 = inttoptr i64 %2886 to i32*
  %2889 = load i32, i32* %2888, align 4
  %2890 = add i32 %2889, 1
  %2891 = zext i32 %2890 to i64
  store i64 %2891, i64* %RCX, align 8, !tbaa !2428
  %2892 = icmp eq i32 %2889, -1
  %2893 = icmp eq i32 %2890, 0
  %2894 = or i1 %2892, %2893
  %2895 = zext i1 %2894 to i8
  store i8 %2895, i8* %50, align 1, !tbaa !2433
  %2896 = and i32 %2890, 255
  %2897 = tail call i32 @llvm.ctpop.i32(i32 %2896) #10
  %2898 = trunc i32 %2897 to i8
  %2899 = and i8 %2898, 1
  %2900 = xor i8 %2899, 1
  store i8 %2900, i8* %51, align 1, !tbaa !2447
  %2901 = xor i32 %2890, %2889
  %2902 = lshr i32 %2901, 4
  %2903 = trunc i32 %2902 to i8
  %2904 = and i8 %2903, 1
  store i8 %2904, i8* %52, align 1, !tbaa !2451
  %2905 = zext i1 %2893 to i8
  store i8 %2905, i8* %53, align 1, !tbaa !2448
  %2906 = lshr i32 %2890, 31
  %2907 = trunc i32 %2906 to i8
  store i8 %2907, i8* %54, align 1, !tbaa !2449
  %2908 = lshr i32 %2889, 31
  %2909 = xor i32 %2906, %2908
  %2910 = add nuw nsw i32 %2909, %2906
  %2911 = icmp eq i32 %2910, 2
  %2912 = zext i1 %2911 to i8
  store i8 %2912, i8* %55, align 1, !tbaa !2450
  %2913 = sext i32 %2890 to i64
  store i64 %2913, i64* %RSI, align 8, !tbaa !2428
  %2914 = shl nsw i64 %2913, 3
  %2915 = add i64 %2885, %2914
  %2916 = add i64 %2882, 18
  store i64 %2916, i64* %PC, align 8
  %2917 = inttoptr i64 %2915 to i64*
  %2918 = load i64, i64* %2917, align 8
  %2919 = load i64, i64* %RAX, align 8
  %2920 = xor i64 %2919, %2918
  store i64 %2920, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %2921 = trunc i64 %2920 to i32
  %2922 = and i32 %2921, 255
  %2923 = tail call i32 @llvm.ctpop.i32(i32 %2922) #10
  %2924 = trunc i32 %2923 to i8
  %2925 = and i8 %2924, 1
  %2926 = xor i8 %2925, 1
  store i8 %2926, i8* %51, align 1, !tbaa !2447
  %2927 = icmp eq i64 %2920, 0
  %2928 = zext i1 %2927 to i8
  store i8 %2928, i8* %53, align 1, !tbaa !2448
  %2929 = lshr i64 %2920, 63
  %2930 = trunc i64 %2929 to i8
  store i8 %2930, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %2920, i64* %3730, align 1, !tbaa !2428
  store i64 0, i64* %3731, align 1, !tbaa !2428
  %2931 = add i64 %2880, -88
  %2932 = add i64 %2882, 36
  store i64 %2932, i64* %PC, align 8
  %2933 = inttoptr i64 %2931 to i64*
  store i64 %2920, i64* %2933, align 8
  %2934 = load i64, i64* %RBP, align 8
  %2935 = add i64 %2934, -80
  %2936 = load i64, i64* %PC, align 8
  %2937 = add i64 %2936, 5
  store i64 %2937, i64* %PC, align 8
  %2938 = inttoptr i64 %2935 to i64*
  %2939 = load i64, i64* %2938, align 8
  store i64 %2939, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %2940 = add i64 %2934, -24
  %2941 = add i64 %2936, 9
  store i64 %2941, i64* %PC, align 8
  %2942 = inttoptr i64 %2940 to i64*
  %2943 = load i64, i64* %2942, align 8
  store i64 %2943, i64* %RDX, align 8, !tbaa !2428
  %2944 = add i64 %2934, -32
  %2945 = add i64 %2936, 13
  store i64 %2945, i64* %PC, align 8
  %2946 = inttoptr i64 %2944 to i32*
  %2947 = load i32, i32* %2946, align 4
  %2948 = sext i32 %2947 to i64
  store i64 %2948, i64* %RSI, align 8, !tbaa !2428
  %2949 = shl nsw i64 %2948, 3
  %2950 = add i64 %2949, %2943
  %2951 = add i64 %2936, 18
  store i64 %2951, i64* %PC, align 8
  %2952 = inttoptr i64 %2950 to i64*
  store i64 %2939, i64* %2952, align 8
  %2953 = load i64, i64* %RBP, align 8
  %2954 = add i64 %2953, -88
  %2955 = load i64, i64* %PC, align 8
  %2956 = add i64 %2955, 5
  store i64 %2956, i64* %PC, align 8
  %2957 = inttoptr i64 %2954 to i64*
  %2958 = load i64, i64* %2957, align 8
  store i64 %2958, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %2959 = add i64 %2953, -24
  %2960 = add i64 %2955, 9
  store i64 %2960, i64* %PC, align 8
  %2961 = inttoptr i64 %2959 to i64*
  %2962 = load i64, i64* %2961, align 8
  store i64 %2962, i64* %RDX, align 8, !tbaa !2428
  %2963 = add i64 %2953, -32
  %2964 = add i64 %2955, 12
  store i64 %2964, i64* %PC, align 8
  %2965 = inttoptr i64 %2963 to i32*
  %2966 = load i32, i32* %2965, align 4
  %2967 = add i32 %2966, 1
  %2968 = zext i32 %2967 to i64
  store i64 %2968, i64* %RCX, align 8, !tbaa !2428
  %2969 = icmp eq i32 %2966, -1
  %2970 = icmp eq i32 %2967, 0
  %2971 = or i1 %2969, %2970
  %2972 = zext i1 %2971 to i8
  store i8 %2972, i8* %50, align 1, !tbaa !2433
  %2973 = and i32 %2967, 255
  %2974 = tail call i32 @llvm.ctpop.i32(i32 %2973) #10
  %2975 = trunc i32 %2974 to i8
  %2976 = and i8 %2975, 1
  %2977 = xor i8 %2976, 1
  store i8 %2977, i8* %51, align 1, !tbaa !2447
  %2978 = xor i32 %2967, %2966
  %2979 = lshr i32 %2978, 4
  %2980 = trunc i32 %2979 to i8
  %2981 = and i8 %2980, 1
  store i8 %2981, i8* %52, align 1, !tbaa !2451
  %2982 = zext i1 %2970 to i8
  store i8 %2982, i8* %53, align 1, !tbaa !2448
  %2983 = lshr i32 %2967, 31
  %2984 = trunc i32 %2983 to i8
  store i8 %2984, i8* %54, align 1, !tbaa !2449
  %2985 = lshr i32 %2966, 31
  %2986 = xor i32 %2983, %2985
  %2987 = add nuw nsw i32 %2986, %2983
  %2988 = icmp eq i32 %2987, 2
  %2989 = zext i1 %2988 to i8
  store i8 %2989, i8* %55, align 1, !tbaa !2450
  %2990 = sext i32 %2967 to i64
  store i64 %2990, i64* %RSI, align 8, !tbaa !2428
  %2991 = shl nsw i64 %2990, 3
  %2992 = add i64 %2962, %2991
  %2993 = add i64 %2955, 23
  store i64 %2993, i64* %PC, align 8
  %2994 = inttoptr i64 %2992 to i64*
  store i64 %2958, i64* %2994, align 8
  %2995 = load i64, i64* %RBP, align 8
  %2996 = add i64 %2995, -64
  %2997 = load i64, i64* %PC, align 8
  %2998 = add i64 %2997, 5
  store i64 %2998, i64* %PC, align 8
  %2999 = inttoptr i64 %2996 to i64*
  %3000 = load i64, i64* %2999, align 8
  store i64 %3000, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %3001 = add i64 %2995, -24
  %3002 = add i64 %2997, 9
  store i64 %3002, i64* %PC, align 8
  %3003 = inttoptr i64 %3001 to i64*
  %3004 = load i64, i64* %3003, align 8
  store i64 %3004, i64* %RDX, align 8, !tbaa !2428
  %3005 = add i64 %2995, -40
  %3006 = add i64 %2997, 13
  store i64 %3006, i64* %PC, align 8
  %3007 = inttoptr i64 %3005 to i32*
  %3008 = load i32, i32* %3007, align 4
  %3009 = sext i32 %3008 to i64
  store i64 %3009, i64* %RSI, align 8, !tbaa !2428
  %3010 = shl nsw i64 %3009, 3
  %3011 = add i64 %3010, %3004
  %3012 = add i64 %2997, 18
  store i64 %3012, i64* %PC, align 8
  %3013 = inttoptr i64 %3011 to i64*
  store i64 %3000, i64* %3013, align 8
  %3014 = load i64, i64* %RBP, align 8
  %3015 = add i64 %3014, -72
  %3016 = load i64, i64* %PC, align 8
  %3017 = add i64 %3016, 5
  store i64 %3017, i64* %PC, align 8
  %3018 = inttoptr i64 %3015 to i64*
  %3019 = load i64, i64* %3018, align 8
  store i64 %3019, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %3020 = add i64 %3014, -24
  %3021 = add i64 %3016, 9
  store i64 %3021, i64* %PC, align 8
  %3022 = inttoptr i64 %3020 to i64*
  %3023 = load i64, i64* %3022, align 8
  store i64 %3023, i64* %RDX, align 8, !tbaa !2428
  %3024 = add i64 %3014, -40
  %3025 = add i64 %3016, 12
  store i64 %3025, i64* %PC, align 8
  %3026 = inttoptr i64 %3024 to i32*
  %3027 = load i32, i32* %3026, align 4
  %3028 = add i32 %3027, 1
  %3029 = zext i32 %3028 to i64
  store i64 %3029, i64* %RCX, align 8, !tbaa !2428
  %3030 = icmp eq i32 %3027, -1
  %3031 = icmp eq i32 %3028, 0
  %3032 = or i1 %3030, %3031
  %3033 = zext i1 %3032 to i8
  store i8 %3033, i8* %50, align 1, !tbaa !2433
  %3034 = and i32 %3028, 255
  %3035 = tail call i32 @llvm.ctpop.i32(i32 %3034) #10
  %3036 = trunc i32 %3035 to i8
  %3037 = and i8 %3036, 1
  %3038 = xor i8 %3037, 1
  store i8 %3038, i8* %51, align 1, !tbaa !2447
  %3039 = xor i32 %3028, %3027
  %3040 = lshr i32 %3039, 4
  %3041 = trunc i32 %3040 to i8
  %3042 = and i8 %3041, 1
  store i8 %3042, i8* %52, align 1, !tbaa !2451
  %3043 = zext i1 %3031 to i8
  store i8 %3043, i8* %53, align 1, !tbaa !2448
  %3044 = lshr i32 %3028, 31
  %3045 = trunc i32 %3044 to i8
  store i8 %3045, i8* %54, align 1, !tbaa !2449
  %3046 = lshr i32 %3027, 31
  %3047 = xor i32 %3044, %3046
  %3048 = add nuw nsw i32 %3047, %3044
  %3049 = icmp eq i32 %3048, 2
  %3050 = zext i1 %3049 to i8
  store i8 %3050, i8* %55, align 1, !tbaa !2450
  %3051 = sext i32 %3028 to i64
  store i64 %3051, i64* %RSI, align 8, !tbaa !2428
  %3052 = shl nsw i64 %3051, 3
  %3053 = add i64 %3023, %3052
  %3054 = add i64 %3016, 23
  store i64 %3054, i64* %PC, align 8
  %3055 = inttoptr i64 %3053 to i64*
  store i64 %3019, i64* %3055, align 8
  %3056 = load i64, i64* %RBP, align 8
  %3057 = add i64 %3056, -52
  %3058 = load i64, i64* %PC, align 8
  %3059 = add i64 %3058, 3
  store i64 %3059, i64* %PC, align 8
  %3060 = inttoptr i64 %3057 to i32*
  %3061 = load i32, i32* %3060, align 4
  %3062 = zext i32 %3061 to i64
  store i64 %3062, i64* %RCX, align 8, !tbaa !2428
  %3063 = add i64 %3056, -32
  %3064 = add i64 %3058, 6
  store i64 %3064, i64* %PC, align 8
  %3065 = inttoptr i64 %3063 to i32*
  %3066 = load i32, i32* %3065, align 4
  %3067 = add i32 %3066, %3061
  %3068 = zext i32 %3067 to i64
  store i64 %3068, i64* %RCX, align 8, !tbaa !2428
  %3069 = icmp ult i32 %3067, %3061
  %3070 = icmp ult i32 %3067, %3066
  %3071 = or i1 %3069, %3070
  %3072 = zext i1 %3071 to i8
  store i8 %3072, i8* %50, align 1, !tbaa !2433
  %3073 = and i32 %3067, 255
  %3074 = tail call i32 @llvm.ctpop.i32(i32 %3073) #10
  %3075 = trunc i32 %3074 to i8
  %3076 = and i8 %3075, 1
  %3077 = xor i8 %3076, 1
  store i8 %3077, i8* %51, align 1, !tbaa !2447
  %3078 = xor i32 %3066, %3061
  %3079 = xor i32 %3078, %3067
  %3080 = lshr i32 %3079, 4
  %3081 = trunc i32 %3080 to i8
  %3082 = and i8 %3081, 1
  store i8 %3082, i8* %52, align 1, !tbaa !2451
  %3083 = icmp eq i32 %3067, 0
  %3084 = zext i1 %3083 to i8
  store i8 %3084, i8* %53, align 1, !tbaa !2448
  %3085 = lshr i32 %3067, 31
  %3086 = trunc i32 %3085 to i8
  store i8 %3086, i8* %54, align 1, !tbaa !2449
  %3087 = lshr i32 %3061, 31
  %3088 = lshr i32 %3066, 31
  %3089 = xor i32 %3085, %3087
  %3090 = xor i32 %3085, %3088
  %3091 = add nuw nsw i32 %3089, %3090
  %3092 = icmp eq i32 %3091, 2
  %3093 = zext i1 %3092 to i8
  store i8 %3093, i8* %55, align 1, !tbaa !2450
  %3094 = add i64 %3058, 9
  store i64 %3094, i64* %PC, align 8
  store i32 %3067, i32* %3065, align 4
  %3095 = load i64, i64* %RBP, align 8
  %3096 = add i64 %3095, -52
  %3097 = load i64, i64* %PC, align 8
  %3098 = add i64 %3097, 3
  store i64 %3098, i64* %PC, align 8
  %3099 = inttoptr i64 %3096 to i32*
  %3100 = load i32, i32* %3099, align 4
  %3101 = zext i32 %3100 to i64
  store i64 %3101, i64* %RCX, align 8, !tbaa !2428
  %3102 = add i64 %3095, -40
  %3103 = add i64 %3097, 6
  store i64 %3103, i64* %PC, align 8
  %3104 = inttoptr i64 %3102 to i32*
  %3105 = load i32, i32* %3104, align 4
  %3106 = add i32 %3105, %3100
  %3107 = zext i32 %3106 to i64
  store i64 %3107, i64* %RCX, align 8, !tbaa !2428
  %3108 = icmp ult i32 %3106, %3100
  %3109 = icmp ult i32 %3106, %3105
  %3110 = or i1 %3108, %3109
  %3111 = zext i1 %3110 to i8
  store i8 %3111, i8* %50, align 1, !tbaa !2433
  %3112 = and i32 %3106, 255
  %3113 = tail call i32 @llvm.ctpop.i32(i32 %3112) #10
  %3114 = trunc i32 %3113 to i8
  %3115 = and i8 %3114, 1
  %3116 = xor i8 %3115, 1
  store i8 %3116, i8* %51, align 1, !tbaa !2447
  %3117 = xor i32 %3105, %3100
  %3118 = xor i32 %3117, %3106
  %3119 = lshr i32 %3118, 4
  %3120 = trunc i32 %3119 to i8
  %3121 = and i8 %3120, 1
  store i8 %3121, i8* %52, align 1, !tbaa !2451
  %3122 = icmp eq i32 %3106, 0
  %3123 = zext i1 %3122 to i8
  store i8 %3123, i8* %53, align 1, !tbaa !2448
  %3124 = lshr i32 %3106, 31
  %3125 = trunc i32 %3124 to i8
  store i8 %3125, i8* %54, align 1, !tbaa !2449
  %3126 = lshr i32 %3100, 31
  %3127 = lshr i32 %3105, 31
  %3128 = xor i32 %3124, %3126
  %3129 = xor i32 %3124, %3127
  %3130 = add nuw nsw i32 %3128, %3129
  %3131 = icmp eq i32 %3130, 2
  %3132 = zext i1 %3131 to i8
  store i8 %3132, i8* %55, align 1, !tbaa !2450
  %3133 = add i64 %3097, 9
  store i64 %3133, i64* %PC, align 8
  store i32 %3106, i32* %3104, align 4
  %3134 = load i64, i64* %RBP, align 8
  %3135 = add i64 %3134, -24
  %3136 = load i64, i64* %PC, align 8
  %3137 = add i64 %3136, 4
  store i64 %3137, i64* %PC, align 8
  %3138 = inttoptr i64 %3135 to i64*
  %3139 = load i64, i64* %3138, align 8
  store i64 %3139, i64* %RDX, align 8, !tbaa !2428
  %3140 = add i64 %3134, -32
  %3141 = add i64 %3136, 8
  store i64 %3141, i64* %PC, align 8
  %3142 = inttoptr i64 %3140 to i32*
  %3143 = load i32, i32* %3142, align 4
  %3144 = sext i32 %3143 to i64
  store i64 %3144, i64* %RSI, align 8, !tbaa !2428
  %3145 = shl nsw i64 %3144, 3
  %3146 = add i64 %3145, %3139
  %3147 = add i64 %3136, 13
  store i64 %3147, i64* %PC, align 8
  %3148 = inttoptr i64 %3146 to i64*
  %3149 = load i64, i64* %3148, align 8
  store i64 %3149, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %3150 = add i64 %3134, -64
  %3151 = add i64 %3136, 18
  store i64 %3151, i64* %PC, align 8
  %3152 = inttoptr i64 %3150 to i64*
  store i64 %3149, i64* %3152, align 8
  %3153 = load i64, i64* %RBP, align 8
  %3154 = add i64 %3153, -24
  %3155 = load i64, i64* %PC, align 8
  %3156 = add i64 %3155, 4
  store i64 %3156, i64* %PC, align 8
  %3157 = inttoptr i64 %3154 to i64*
  %3158 = load i64, i64* %3157, align 8
  store i64 %3158, i64* %RDX, align 8, !tbaa !2428
  %3159 = add i64 %3153, -32
  %3160 = add i64 %3155, 7
  store i64 %3160, i64* %PC, align 8
  %3161 = inttoptr i64 %3159 to i32*
  %3162 = load i32, i32* %3161, align 4
  %3163 = add i32 %3162, 1
  %3164 = zext i32 %3163 to i64
  store i64 %3164, i64* %RCX, align 8, !tbaa !2428
  %3165 = icmp eq i32 %3162, -1
  %3166 = icmp eq i32 %3163, 0
  %3167 = or i1 %3165, %3166
  %3168 = zext i1 %3167 to i8
  store i8 %3168, i8* %50, align 1, !tbaa !2433
  %3169 = and i32 %3163, 255
  %3170 = tail call i32 @llvm.ctpop.i32(i32 %3169) #10
  %3171 = trunc i32 %3170 to i8
  %3172 = and i8 %3171, 1
  %3173 = xor i8 %3172, 1
  store i8 %3173, i8* %51, align 1, !tbaa !2447
  %3174 = xor i32 %3163, %3162
  %3175 = lshr i32 %3174, 4
  %3176 = trunc i32 %3175 to i8
  %3177 = and i8 %3176, 1
  store i8 %3177, i8* %52, align 1, !tbaa !2451
  %3178 = zext i1 %3166 to i8
  store i8 %3178, i8* %53, align 1, !tbaa !2448
  %3179 = lshr i32 %3163, 31
  %3180 = trunc i32 %3179 to i8
  store i8 %3180, i8* %54, align 1, !tbaa !2449
  %3181 = lshr i32 %3162, 31
  %3182 = xor i32 %3179, %3181
  %3183 = add nuw nsw i32 %3182, %3179
  %3184 = icmp eq i32 %3183, 2
  %3185 = zext i1 %3184 to i8
  store i8 %3185, i8* %55, align 1, !tbaa !2450
  %3186 = sext i32 %3163 to i64
  store i64 %3186, i64* %RSI, align 8, !tbaa !2428
  %3187 = shl nsw i64 %3186, 3
  %3188 = add i64 %3158, %3187
  %3189 = add i64 %3155, 18
  store i64 %3189, i64* %PC, align 8
  %3190 = inttoptr i64 %3188 to i64*
  %3191 = load i64, i64* %3190, align 8
  %3192 = load i64, i64* %RAX, align 8
  %3193 = xor i64 %3192, %3191
  store i64 %3193, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %3194 = trunc i64 %3193 to i32
  %3195 = and i32 %3194, 255
  %3196 = tail call i32 @llvm.ctpop.i32(i32 %3195) #10
  %3197 = trunc i32 %3196 to i8
  %3198 = and i8 %3197, 1
  %3199 = xor i8 %3198, 1
  store i8 %3199, i8* %51, align 1, !tbaa !2447
  %3200 = icmp eq i64 %3193, 0
  %3201 = zext i1 %3200 to i8
  store i8 %3201, i8* %53, align 1, !tbaa !2448
  %3202 = lshr i64 %3193, 63
  %3203 = trunc i64 %3202 to i8
  store i8 %3203, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %3193, i64* %3730, align 1, !tbaa !2428
  store i64 0, i64* %3731, align 1, !tbaa !2428
  %3204 = add i64 %3153, -72
  %3205 = add i64 %3155, 36
  store i64 %3205, i64* %PC, align 8
  %3206 = inttoptr i64 %3204 to i64*
  store i64 %3193, i64* %3206, align 8
  %3207 = load i64, i64* %RBP, align 8
  %3208 = add i64 %3207, -24
  %3209 = load i64, i64* %PC, align 8
  %3210 = add i64 %3209, 4
  store i64 %3210, i64* %PC, align 8
  %3211 = inttoptr i64 %3208 to i64*
  %3212 = load i64, i64* %3211, align 8
  store i64 %3212, i64* %RDX, align 8, !tbaa !2428
  %3213 = add i64 %3207, -40
  %3214 = add i64 %3209, 8
  store i64 %3214, i64* %PC, align 8
  %3215 = inttoptr i64 %3213 to i32*
  %3216 = load i32, i32* %3215, align 4
  %3217 = sext i32 %3216 to i64
  store i64 %3217, i64* %RSI, align 8, !tbaa !2428
  %3218 = shl nsw i64 %3217, 3
  %3219 = add i64 %3218, %3212
  %3220 = add i64 %3209, 13
  store i64 %3220, i64* %PC, align 8
  %3221 = inttoptr i64 %3219 to i64*
  %3222 = load i64, i64* %3221, align 8
  store i64 %3222, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %3223 = add i64 %3207, -80
  %3224 = add i64 %3209, 18
  store i64 %3224, i64* %PC, align 8
  %3225 = inttoptr i64 %3223 to i64*
  store i64 %3222, i64* %3225, align 8
  %3226 = load i64, i64* %RBP, align 8
  %3227 = add i64 %3226, -24
  %3228 = load i64, i64* %PC, align 8
  %3229 = add i64 %3228, 4
  store i64 %3229, i64* %PC, align 8
  %3230 = inttoptr i64 %3227 to i64*
  %3231 = load i64, i64* %3230, align 8
  store i64 %3231, i64* %RDX, align 8, !tbaa !2428
  %3232 = add i64 %3226, -40
  %3233 = add i64 %3228, 7
  store i64 %3233, i64* %PC, align 8
  %3234 = inttoptr i64 %3232 to i32*
  %3235 = load i32, i32* %3234, align 4
  %3236 = add i32 %3235, 1
  %3237 = zext i32 %3236 to i64
  store i64 %3237, i64* %RCX, align 8, !tbaa !2428
  %3238 = icmp eq i32 %3235, -1
  %3239 = icmp eq i32 %3236, 0
  %3240 = or i1 %3238, %3239
  %3241 = zext i1 %3240 to i8
  store i8 %3241, i8* %50, align 1, !tbaa !2433
  %3242 = and i32 %3236, 255
  %3243 = tail call i32 @llvm.ctpop.i32(i32 %3242) #10
  %3244 = trunc i32 %3243 to i8
  %3245 = and i8 %3244, 1
  %3246 = xor i8 %3245, 1
  store i8 %3246, i8* %51, align 1, !tbaa !2447
  %3247 = xor i32 %3236, %3235
  %3248 = lshr i32 %3247, 4
  %3249 = trunc i32 %3248 to i8
  %3250 = and i8 %3249, 1
  store i8 %3250, i8* %52, align 1, !tbaa !2451
  %3251 = zext i1 %3239 to i8
  store i8 %3251, i8* %53, align 1, !tbaa !2448
  %3252 = lshr i32 %3236, 31
  %3253 = trunc i32 %3252 to i8
  store i8 %3253, i8* %54, align 1, !tbaa !2449
  %3254 = lshr i32 %3235, 31
  %3255 = xor i32 %3252, %3254
  %3256 = add nuw nsw i32 %3255, %3252
  %3257 = icmp eq i32 %3256, 2
  %3258 = zext i1 %3257 to i8
  store i8 %3258, i8* %55, align 1, !tbaa !2450
  %3259 = sext i32 %3236 to i64
  store i64 %3259, i64* %RSI, align 8, !tbaa !2428
  %3260 = shl nsw i64 %3259, 3
  %3261 = add i64 %3231, %3260
  %3262 = add i64 %3228, 18
  store i64 %3262, i64* %PC, align 8
  %3263 = inttoptr i64 %3261 to i64*
  %3264 = load i64, i64* %3263, align 8
  %3265 = load i64, i64* %RAX, align 8
  %3266 = xor i64 %3265, %3264
  store i64 %3266, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %3267 = trunc i64 %3266 to i32
  %3268 = and i32 %3267, 255
  %3269 = tail call i32 @llvm.ctpop.i32(i32 %3268) #10
  %3270 = trunc i32 %3269 to i8
  %3271 = and i8 %3270, 1
  %3272 = xor i8 %3271, 1
  store i8 %3272, i8* %51, align 1, !tbaa !2447
  %3273 = icmp eq i64 %3266, 0
  %3274 = zext i1 %3273 to i8
  store i8 %3274, i8* %53, align 1, !tbaa !2448
  %3275 = lshr i64 %3266, 63
  %3276 = trunc i64 %3275 to i8
  store i8 %3276, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %3266, i64* %3730, align 1, !tbaa !2428
  store i64 0, i64* %3731, align 1, !tbaa !2428
  %3277 = add i64 %3226, -88
  %3278 = add i64 %3228, 36
  store i64 %3278, i64* %PC, align 8
  %3279 = inttoptr i64 %3277 to i64*
  store i64 %3266, i64* %3279, align 8
  %3280 = load i64, i64* %RBP, align 8
  %3281 = add i64 %3280, -80
  %3282 = load i64, i64* %PC, align 8
  %3283 = add i64 %3282, 5
  store i64 %3283, i64* %PC, align 8
  %3284 = inttoptr i64 %3281 to i64*
  %3285 = load i64, i64* %3284, align 8
  store i64 %3285, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %3286 = add i64 %3280, -24
  %3287 = add i64 %3282, 9
  store i64 %3287, i64* %PC, align 8
  %3288 = inttoptr i64 %3286 to i64*
  %3289 = load i64, i64* %3288, align 8
  store i64 %3289, i64* %RAX, align 8, !tbaa !2428
  %3290 = add i64 %3280, -32
  %3291 = add i64 %3282, 13
  store i64 %3291, i64* %PC, align 8
  %3292 = inttoptr i64 %3290 to i32*
  %3293 = load i32, i32* %3292, align 4
  %3294 = sext i32 %3293 to i64
  store i64 %3294, i64* %RDX, align 8, !tbaa !2428
  %3295 = shl nsw i64 %3294, 3
  %3296 = add i64 %3295, %3289
  %3297 = add i64 %3282, 18
  store i64 %3297, i64* %PC, align 8
  %3298 = inttoptr i64 %3296 to i64*
  store i64 %3285, i64* %3298, align 8
  %3299 = load i64, i64* %RBP, align 8
  %3300 = add i64 %3299, -88
  %3301 = load i64, i64* %PC, align 8
  %3302 = add i64 %3301, 5
  store i64 %3302, i64* %PC, align 8
  %3303 = inttoptr i64 %3300 to i64*
  %3304 = load i64, i64* %3303, align 8
  store i64 %3304, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %3305 = add i64 %3299, -24
  %3306 = add i64 %3301, 9
  store i64 %3306, i64* %PC, align 8
  %3307 = inttoptr i64 %3305 to i64*
  %3308 = load i64, i64* %3307, align 8
  store i64 %3308, i64* %RAX, align 8, !tbaa !2428
  %3309 = add i64 %3299, -32
  %3310 = add i64 %3301, 12
  store i64 %3310, i64* %PC, align 8
  %3311 = inttoptr i64 %3309 to i32*
  %3312 = load i32, i32* %3311, align 4
  %3313 = add i32 %3312, 1
  %3314 = zext i32 %3313 to i64
  store i64 %3314, i64* %RCX, align 8, !tbaa !2428
  %3315 = icmp eq i32 %3312, -1
  %3316 = icmp eq i32 %3313, 0
  %3317 = or i1 %3315, %3316
  %3318 = zext i1 %3317 to i8
  store i8 %3318, i8* %50, align 1, !tbaa !2433
  %3319 = and i32 %3313, 255
  %3320 = tail call i32 @llvm.ctpop.i32(i32 %3319) #10
  %3321 = trunc i32 %3320 to i8
  %3322 = and i8 %3321, 1
  %3323 = xor i8 %3322, 1
  store i8 %3323, i8* %51, align 1, !tbaa !2447
  %3324 = xor i32 %3313, %3312
  %3325 = lshr i32 %3324, 4
  %3326 = trunc i32 %3325 to i8
  %3327 = and i8 %3326, 1
  store i8 %3327, i8* %52, align 1, !tbaa !2451
  %3328 = zext i1 %3316 to i8
  store i8 %3328, i8* %53, align 1, !tbaa !2448
  %3329 = lshr i32 %3313, 31
  %3330 = trunc i32 %3329 to i8
  store i8 %3330, i8* %54, align 1, !tbaa !2449
  %3331 = lshr i32 %3312, 31
  %3332 = xor i32 %3329, %3331
  %3333 = add nuw nsw i32 %3332, %3329
  %3334 = icmp eq i32 %3333, 2
  %3335 = zext i1 %3334 to i8
  store i8 %3335, i8* %55, align 1, !tbaa !2450
  %3336 = sext i32 %3313 to i64
  store i64 %3336, i64* %RDX, align 8, !tbaa !2428
  %3337 = shl nsw i64 %3336, 3
  %3338 = add i64 %3308, %3337
  %3339 = add i64 %3301, 23
  store i64 %3339, i64* %PC, align 8
  %3340 = inttoptr i64 %3338 to i64*
  store i64 %3304, i64* %3340, align 8
  %3341 = load i64, i64* %RBP, align 8
  %3342 = add i64 %3341, -64
  %3343 = load i64, i64* %PC, align 8
  %3344 = add i64 %3343, 5
  store i64 %3344, i64* %PC, align 8
  %3345 = inttoptr i64 %3342 to i64*
  %3346 = load i64, i64* %3345, align 8
  store i64 %3346, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %3347 = add i64 %3341, -24
  %3348 = add i64 %3343, 9
  store i64 %3348, i64* %PC, align 8
  %3349 = inttoptr i64 %3347 to i64*
  %3350 = load i64, i64* %3349, align 8
  store i64 %3350, i64* %RAX, align 8, !tbaa !2428
  %3351 = add i64 %3341, -40
  %3352 = add i64 %3343, 13
  store i64 %3352, i64* %PC, align 8
  %3353 = inttoptr i64 %3351 to i32*
  %3354 = load i32, i32* %3353, align 4
  %3355 = sext i32 %3354 to i64
  store i64 %3355, i64* %RDX, align 8, !tbaa !2428
  %3356 = shl nsw i64 %3355, 3
  %3357 = add i64 %3356, %3350
  %3358 = add i64 %3343, 18
  store i64 %3358, i64* %PC, align 8
  %3359 = inttoptr i64 %3357 to i64*
  store i64 %3346, i64* %3359, align 8
  %3360 = load i64, i64* %RBP, align 8
  %3361 = add i64 %3360, -72
  %3362 = load i64, i64* %PC, align 8
  %3363 = add i64 %3362, 5
  store i64 %3363, i64* %PC, align 8
  %3364 = inttoptr i64 %3361 to i64*
  %3365 = load i64, i64* %3364, align 8
  store i64 %3365, i64* %3730, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3732, align 1, !tbaa !2452
  %3366 = add i64 %3360, -24
  %3367 = add i64 %3362, 9
  store i64 %3367, i64* %PC, align 8
  %3368 = inttoptr i64 %3366 to i64*
  %3369 = load i64, i64* %3368, align 8
  store i64 %3369, i64* %RAX, align 8, !tbaa !2428
  %3370 = add i64 %3360, -40
  %3371 = add i64 %3362, 12
  store i64 %3371, i64* %PC, align 8
  %3372 = inttoptr i64 %3370 to i32*
  %3373 = load i32, i32* %3372, align 4
  %3374 = add i32 %3373, 1
  %3375 = zext i32 %3374 to i64
  store i64 %3375, i64* %RCX, align 8, !tbaa !2428
  %3376 = icmp eq i32 %3373, -1
  %3377 = icmp eq i32 %3374, 0
  %3378 = or i1 %3376, %3377
  %3379 = zext i1 %3378 to i8
  store i8 %3379, i8* %50, align 1, !tbaa !2433
  %3380 = and i32 %3374, 255
  %3381 = tail call i32 @llvm.ctpop.i32(i32 %3380) #10
  %3382 = trunc i32 %3381 to i8
  %3383 = and i8 %3382, 1
  %3384 = xor i8 %3383, 1
  store i8 %3384, i8* %51, align 1, !tbaa !2447
  %3385 = xor i32 %3374, %3373
  %3386 = lshr i32 %3385, 4
  %3387 = trunc i32 %3386 to i8
  %3388 = and i8 %3387, 1
  store i8 %3388, i8* %52, align 1, !tbaa !2451
  %3389 = zext i1 %3377 to i8
  store i8 %3389, i8* %53, align 1, !tbaa !2448
  %3390 = lshr i32 %3374, 31
  %3391 = trunc i32 %3390 to i8
  store i8 %3391, i8* %54, align 1, !tbaa !2449
  %3392 = lshr i32 %3373, 31
  %3393 = xor i32 %3390, %3392
  %3394 = add nuw nsw i32 %3393, %3390
  %3395 = icmp eq i32 %3394, 2
  %3396 = zext i1 %3395 to i8
  store i8 %3396, i8* %55, align 1, !tbaa !2450
  %3397 = sext i32 %3374 to i64
  store i64 %3397, i64* %RDX, align 8, !tbaa !2428
  %3398 = shl nsw i64 %3397, 3
  %3399 = add i64 %3369, %3398
  %3400 = add i64 %3362, 23
  store i64 %3400, i64* %PC, align 8
  %3401 = inttoptr i64 %3399 to i64*
  store i64 %3365, i64* %3401, align 8
  %3402 = load i64, i64* %RBP, align 8
  %3403 = add i64 %3402, -28
  %3404 = load i64, i64* %PC, align 8
  %3405 = add i64 %3404, 3
  store i64 %3405, i64* %PC, align 8
  %3406 = inttoptr i64 %3403 to i32*
  %3407 = load i32, i32* %3406, align 4
  %3408 = add i32 %3407, 1
  %3409 = zext i32 %3408 to i64
  store i64 %3409, i64* %RAX, align 8, !tbaa !2428
  %3410 = icmp eq i32 %3407, -1
  %3411 = icmp eq i32 %3408, 0
  %3412 = or i1 %3410, %3411
  %3413 = zext i1 %3412 to i8
  store i8 %3413, i8* %50, align 1, !tbaa !2433
  %3414 = and i32 %3408, 255
  %3415 = tail call i32 @llvm.ctpop.i32(i32 %3414) #10
  %3416 = trunc i32 %3415 to i8
  %3417 = and i8 %3416, 1
  %3418 = xor i8 %3417, 1
  store i8 %3418, i8* %51, align 1, !tbaa !2447
  %3419 = xor i32 %3408, %3407
  %3420 = lshr i32 %3419, 4
  %3421 = trunc i32 %3420 to i8
  %3422 = and i8 %3421, 1
  store i8 %3422, i8* %52, align 1, !tbaa !2451
  %3423 = zext i1 %3411 to i8
  store i8 %3423, i8* %53, align 1, !tbaa !2448
  %3424 = lshr i32 %3408, 31
  %3425 = trunc i32 %3424 to i8
  store i8 %3425, i8* %54, align 1, !tbaa !2449
  %3426 = lshr i32 %3407, 31
  %3427 = xor i32 %3424, %3426
  %3428 = add nuw nsw i32 %3427, %3424
  %3429 = icmp eq i32 %3428, 2
  %3430 = zext i1 %3429 to i8
  store i8 %3430, i8* %55, align 1, !tbaa !2450
  %3431 = add i64 %3404, 9
  store i64 %3431, i64* %PC, align 8
  store i32 %3408, i32* %3406, align 4
  %3432 = load i64, i64* %PC, align 8
  %3433 = add i64 %3432, -469
  store i64 %3433, i64* %PC, align 8, !tbaa !2428
  br label %block_40221f

block_401c26:                                     ; preds = %block_401c7d, %block_401c00
  %3434 = phi i64 [ %77, %block_401c7d ], [ %.pre, %block_401c00 ]
  %3435 = load i64, i64* %RBP, align 8
  %3436 = add i64 %3435, -48
  %3437 = add i64 %3434, 3
  store i64 %3437, i64* %PC, align 8
  %3438 = inttoptr i64 %3436 to i32*
  %3439 = load i32, i32* %3438, align 4
  %3440 = shl i32 %3439, 3
  %3441 = zext i32 %3440 to i64
  store i64 %3441, i64* %RAX, align 8, !tbaa !2428
  %3442 = lshr i32 %3439, 29
  %3443 = trunc i32 %3442 to i8
  %3444 = and i8 %3443, 1
  store i8 %3444, i8* %50, align 1, !tbaa !2432
  %3445 = and i32 %3440, 248
  %3446 = tail call i32 @llvm.ctpop.i32(i32 %3445) #10
  %3447 = trunc i32 %3446 to i8
  %3448 = and i8 %3447, 1
  %3449 = xor i8 %3448, 1
  store i8 %3449, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %3450 = icmp eq i32 %3440, 0
  %3451 = zext i1 %3450 to i8
  store i8 %3451, i8* %53, align 1, !tbaa !2432
  %3452 = lshr i32 %3439, 28
  %3453 = trunc i32 %3452 to i8
  %3454 = and i8 %3453, 1
  store i8 %3454, i8* %54, align 1, !tbaa !2432
  store i8 0, i8* %55, align 1, !tbaa !2432
  %3455 = add i64 %3435, -44
  %3456 = add i64 %3434, 9
  store i64 %3456, i64* %PC, align 8
  %3457 = inttoptr i64 %3455 to i32*
  %3458 = load i32, i32* %3457, align 4
  %3459 = sub i32 %3440, %3458
  %3460 = icmp ult i32 %3440, %3458
  %3461 = zext i1 %3460 to i8
  store i8 %3461, i8* %50, align 1, !tbaa !2433
  %3462 = and i32 %3459, 255
  %3463 = tail call i32 @llvm.ctpop.i32(i32 %3462) #10
  %3464 = trunc i32 %3463 to i8
  %3465 = and i8 %3464, 1
  %3466 = xor i8 %3465, 1
  store i8 %3466, i8* %51, align 1, !tbaa !2447
  %3467 = xor i32 %3458, %3440
  %3468 = xor i32 %3467, %3459
  %3469 = lshr i32 %3468, 4
  %3470 = trunc i32 %3469 to i8
  %3471 = and i8 %3470, 1
  store i8 %3471, i8* %52, align 1, !tbaa !2451
  %3472 = icmp eq i32 %3459, 0
  %3473 = zext i1 %3472 to i8
  store i8 %3473, i8* %53, align 1, !tbaa !2448
  %3474 = lshr i32 %3459, 31
  %3475 = trunc i32 %3474 to i8
  store i8 %3475, i8* %54, align 1, !tbaa !2449
  %3476 = lshr i32 %3439, 28
  %3477 = and i32 %3476, 1
  %3478 = lshr i32 %3458, 31
  %3479 = xor i32 %3478, %3477
  %3480 = xor i32 %3474, %3477
  %3481 = add nuw nsw i32 %3480, %3479
  %3482 = icmp eq i32 %3481, 2
  %3483 = zext i1 %3482 to i8
  store i8 %3483, i8* %55, align 1, !tbaa !2450
  %3484 = icmp ne i8 %3475, 0
  %3485 = xor i1 %3484, %3482
  %.v = select i1 %3485, i64 15, i64 101
  %3486 = add i64 %3434, %.v
  store i64 %3486, i64* %PC, align 8, !tbaa !2428
  br i1 %3485, label %block_401c35, label %block_401c8b

block_40221f:                                     ; preds = %block_402218, %block_40222b
  %3487 = phi i64 [ %.pre43, %block_402218 ], [ %3433, %block_40222b ]
  %3488 = load i64, i64* %RBP, align 8
  %3489 = add i64 %3488, -28
  %3490 = add i64 %3487, 3
  store i64 %3490, i64* %PC, align 8
  %3491 = inttoptr i64 %3489 to i32*
  %3492 = load i32, i32* %3491, align 4
  %3493 = zext i32 %3492 to i64
  store i64 %3493, i64* %RAX, align 8, !tbaa !2428
  %3494 = add i64 %3488, -36
  %3495 = add i64 %3487, 6
  store i64 %3495, i64* %PC, align 8
  %3496 = inttoptr i64 %3494 to i32*
  %3497 = load i32, i32* %3496, align 4
  %3498 = sub i32 %3492, %3497
  %3499 = icmp ult i32 %3492, %3497
  %3500 = zext i1 %3499 to i8
  store i8 %3500, i8* %50, align 1, !tbaa !2433
  %3501 = and i32 %3498, 255
  %3502 = tail call i32 @llvm.ctpop.i32(i32 %3501) #10
  %3503 = trunc i32 %3502 to i8
  %3504 = and i8 %3503, 1
  %3505 = xor i8 %3504, 1
  store i8 %3505, i8* %51, align 1, !tbaa !2447
  %3506 = xor i32 %3497, %3492
  %3507 = xor i32 %3506, %3498
  %3508 = lshr i32 %3507, 4
  %3509 = trunc i32 %3508 to i8
  %3510 = and i8 %3509, 1
  store i8 %3510, i8* %52, align 1, !tbaa !2451
  %3511 = icmp eq i32 %3498, 0
  %3512 = zext i1 %3511 to i8
  store i8 %3512, i8* %53, align 1, !tbaa !2448
  %3513 = lshr i32 %3498, 31
  %3514 = trunc i32 %3513 to i8
  store i8 %3514, i8* %54, align 1, !tbaa !2449
  %3515 = lshr i32 %3492, 31
  %3516 = lshr i32 %3497, 31
  %3517 = xor i32 %3516, %3515
  %3518 = xor i32 %3513, %3515
  %3519 = add nuw nsw i32 %3518, %3517
  %3520 = icmp eq i32 %3519, 2
  %3521 = zext i1 %3520 to i8
  store i8 %3521, i8* %55, align 1, !tbaa !2450
  %3522 = icmp ne i8 %3514, 0
  %3523 = xor i1 %3522, %3520
  %.v47 = select i1 %3523, i64 12, i64 474
  %3524 = add i64 %3487, %.v47
  %3525 = add i64 %3524, 10
  store i64 %3525, i64* %PC, align 8
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %3526 = add i64 %3524, 13
  store i64 %3526, i64* %PC, align 8
  br i1 %3523, label %block_40222b, label %block_4023f9

block_402218:                                     ; preds = %block_40220c
  %3527 = add i64 %3605, -28
  %3528 = add i64 %3641, 7
  store i64 %3528, i64* %PC, align 8
  %3529 = inttoptr i64 %3527 to i32*
  store i32 0, i32* %3529, align 4
  %.pre43 = load i64, i64* %PC, align 8
  br label %block_40221f

block_401caa:                                     ; preds = %block_401ca3, %block_40203f
  %3530 = phi i64 [ %.pre40, %block_401ca3 ], [ %2615, %block_40203f ]
  %3531 = load i64, i64* %RBP, align 8
  %3532 = add i64 %3531, -36
  %3533 = add i64 %3530, 3
  store i64 %3533, i64* %PC, align 8
  %3534 = inttoptr i64 %3532 to i32*
  %3535 = load i32, i32* %3534, align 4
  %3536 = zext i32 %3535 to i64
  store i64 %3536, i64* %RAX, align 8, !tbaa !2428
  %3537 = add i64 %3531, -48
  %3538 = add i64 %3530, 6
  store i64 %3538, i64* %PC, align 8
  %3539 = inttoptr i64 %3537 to i32*
  %3540 = load i32, i32* %3539, align 4
  %3541 = sub i32 %3535, %3540
  %3542 = icmp ult i32 %3535, %3540
  %3543 = zext i1 %3542 to i8
  store i8 %3543, i8* %50, align 1, !tbaa !2433
  %3544 = and i32 %3541, 255
  %3545 = tail call i32 @llvm.ctpop.i32(i32 %3544) #10
  %3546 = trunc i32 %3545 to i8
  %3547 = and i8 %3546, 1
  %3548 = xor i8 %3547, 1
  store i8 %3548, i8* %51, align 1, !tbaa !2447
  %3549 = xor i32 %3540, %3535
  %3550 = xor i32 %3549, %3541
  %3551 = lshr i32 %3550, 4
  %3552 = trunc i32 %3551 to i8
  %3553 = and i8 %3552, 1
  store i8 %3553, i8* %52, align 1, !tbaa !2451
  %3554 = icmp eq i32 %3541, 0
  %3555 = zext i1 %3554 to i8
  store i8 %3555, i8* %53, align 1, !tbaa !2448
  %3556 = lshr i32 %3541, 31
  %3557 = trunc i32 %3556 to i8
  store i8 %3557, i8* %54, align 1, !tbaa !2449
  %3558 = lshr i32 %3535, 31
  %3559 = lshr i32 %3540, 31
  %3560 = xor i32 %3559, %3558
  %3561 = xor i32 %3556, %3558
  %3562 = add nuw nsw i32 %3561, %3560
  %3563 = icmp eq i32 %3562, 2
  %3564 = zext i1 %3563 to i8
  store i8 %3564, i8* %55, align 1, !tbaa !2450
  %3565 = icmp ne i8 %3557, 0
  %3566 = xor i1 %3565, %3563
  %.v48 = select i1 %3566, i64 12, i64 1276
  %3567 = add i64 %3530, %.v48
  store i64 %3567, i64* %PC, align 8, !tbaa !2428
  br i1 %3566, label %block_401cb6, label %block_402492.loopexit

block_402492.loopexit:                            ; preds = %block_401caa
  br label %block_402492

block_402492.loopexit77:                          ; preds = %block_40220c
  br label %block_402492

block_402492:                                     ; preds = %block_402492.loopexit77, %block_402492.loopexit
  %3568 = phi i64 [ %3567, %block_402492.loopexit ], [ %3641, %block_402492.loopexit77 ]
  %.sink5 = phi i64 [ 749, %block_402492.loopexit ], [ 6, %block_402492.loopexit77 ]
  %3569 = add i64 %.sink5, %3568
  store i64 %3569, i64* %PC, align 8
  %3570 = load i64, i64* %6, align 8, !tbaa !2428
  %3571 = add i64 %3570, 8
  %3572 = inttoptr i64 %3570 to i64*
  %3573 = load i64, i64* %3572, align 8
  store i64 %3573, i64* %RBP, align 8, !tbaa !2428
  store i64 %3571, i64* %6, align 8, !tbaa !2428
  %3574 = add i64 %3569, 1
  store i64 %3574, i64* %PC, align 8
  %3575 = inttoptr i64 %3571 to i64*
  %3576 = load i64, i64* %3575, align 8
  store i64 %3576, i64* %PC, align 8, !tbaa !2428
  %3577 = add i64 %3570, 16
  store i64 %3577, i64* %6, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_401c35:                                     ; preds = %block_401c26
  %3578 = add i64 %3486, 3
  store i64 %3578, i64* %PC, align 8
  %3579 = load i32, i32* %3457, align 4
  %3580 = zext i32 %3579 to i64
  %3581 = shl nuw i64 %3580, 32
  %3582 = ashr i64 %3581, 33
  %3583 = trunc i32 %3579 to i8
  %3584 = and i8 %3583, 1
  %3585 = trunc i64 %3582 to i32
  %3586 = and i64 %3582, 4294967295
  store i64 %3586, i64* %RAX, align 8, !tbaa !2428
  store i8 %3584, i8* %50, align 1, !tbaa !2432
  %3587 = and i32 %3585, 255
  %3588 = tail call i32 @llvm.ctpop.i32(i32 %3587) #10
  %3589 = trunc i32 %3588 to i8
  %3590 = and i8 %3589, 1
  %3591 = xor i8 %3590, 1
  store i8 %3591, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %3592 = icmp eq i32 %3585, 0
  %3593 = zext i1 %3592 to i8
  store i8 %3593, i8* %53, align 1, !tbaa !2432
  %3594 = lshr i64 %3582, 31
  %3595 = trunc i64 %3594 to i8
  %3596 = and i8 %3595, 1
  store i8 %3596, i8* %54, align 1, !tbaa !2432
  store i8 0, i8* %55, align 1, !tbaa !2432
  %3597 = trunc i64 %3582 to i32
  %3598 = add i64 %3486, 9
  store i64 %3598, i64* %PC, align 8
  store i32 %3597, i32* %3457, align 4
  %3599 = load i64, i64* %RBP, align 8
  %3600 = add i64 %3599, -28
  %3601 = load i64, i64* %PC, align 8
  %3602 = add i64 %3601, 7
  store i64 %3602, i64* %PC, align 8
  %3603 = inttoptr i64 %3600 to i32*
  store i32 0, i32* %3603, align 4
  %.pre44 = load i64, i64* %PC, align 8
  br label %block_401c45

block_40220c:                                     ; preds = %block_4021ab, %block_4023f9
  %3604 = phi i64 [ %.pre42, %block_4021ab ], [ %468, %block_4023f9 ]
  %3605 = load i64, i64* %RBP, align 8
  %3606 = add i64 %3605, -36
  %3607 = add i64 %3604, 3
  store i64 %3607, i64* %PC, align 8
  %3608 = inttoptr i64 %3606 to i32*
  %3609 = load i32, i32* %3608, align 4
  %3610 = zext i32 %3609 to i64
  store i64 %3610, i64* %RAX, align 8, !tbaa !2428
  %3611 = add i64 %3605, -48
  %3612 = add i64 %3604, 6
  store i64 %3612, i64* %PC, align 8
  %3613 = inttoptr i64 %3611 to i32*
  %3614 = load i32, i32* %3613, align 4
  %3615 = sub i32 %3609, %3614
  %3616 = icmp ult i32 %3609, %3614
  %3617 = zext i1 %3616 to i8
  store i8 %3617, i8* %50, align 1, !tbaa !2433
  %3618 = and i32 %3615, 255
  %3619 = tail call i32 @llvm.ctpop.i32(i32 %3618) #10
  %3620 = trunc i32 %3619 to i8
  %3621 = and i8 %3620, 1
  %3622 = xor i8 %3621, 1
  store i8 %3622, i8* %51, align 1, !tbaa !2447
  %3623 = xor i32 %3614, %3609
  %3624 = xor i32 %3623, %3615
  %3625 = lshr i32 %3624, 4
  %3626 = trunc i32 %3625 to i8
  %3627 = and i8 %3626, 1
  store i8 %3627, i8* %52, align 1, !tbaa !2451
  %3628 = icmp eq i32 %3615, 0
  %3629 = zext i1 %3628 to i8
  store i8 %3629, i8* %53, align 1, !tbaa !2448
  %3630 = lshr i32 %3615, 31
  %3631 = trunc i32 %3630 to i8
  store i8 %3631, i8* %54, align 1, !tbaa !2449
  %3632 = lshr i32 %3609, 31
  %3633 = lshr i32 %3614, 31
  %3634 = xor i32 %3633, %3632
  %3635 = xor i32 %3630, %3632
  %3636 = add nuw nsw i32 %3635, %3634
  %3637 = icmp eq i32 %3636, 2
  %3638 = zext i1 %3637 to i8
  store i8 %3638, i8* %55, align 1, !tbaa !2450
  %3639 = icmp ne i8 %3631, 0
  %3640 = xor i1 %3639, %3637
  %.v46 = select i1 %3640, i64 12, i64 641
  %3641 = add i64 %3604, %.v46
  store i64 %3641, i64* %PC, align 8, !tbaa !2428
  br i1 %3640, label %block_402218, label %block_402492.loopexit77

block_401c8b:                                     ; preds = %block_401c26
  %3642 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %3643 = add i64 %3486, 3
  store i64 %3643, i64* %PC, align 8
  %3644 = load i32, i32* %3438, align 4
  %3645 = shl i32 %3644, 1
  %3646 = icmp slt i32 %3644, 0
  %3647 = icmp slt i32 %3645, 0
  %3648 = xor i1 %3646, %3647
  %3649 = zext i32 %3645 to i64
  store i64 %3649, i64* %RAX, align 8, !tbaa !2428
  %.lobit12 = lshr i32 %3644, 31
  %3650 = trunc i32 %.lobit12 to i8
  store i8 %3650, i8* %50, align 1, !tbaa !2432
  %3651 = and i32 %3645, 254
  %3652 = tail call i32 @llvm.ctpop.i32(i32 %3651) #10
  %3653 = trunc i32 %3652 to i8
  %3654 = and i8 %3653, 1
  %3655 = xor i8 %3654, 1
  store i8 %3655, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %3656 = icmp eq i32 %3645, 0
  %3657 = zext i1 %3656 to i8
  store i8 %3657, i8* %53, align 1, !tbaa !2432
  %3658 = lshr i32 %3644, 30
  %3659 = trunc i32 %3658 to i8
  %3660 = and i8 %3659, 1
  store i8 %3660, i8* %54, align 1, !tbaa !2432
  %3661 = zext i1 %3648 to i8
  store i8 %3661, i8* %55, align 1, !tbaa !2432
  %3662 = add i64 %3435, -52
  %3663 = add i64 %3486, 9
  store i64 %3663, i64* %PC, align 8
  %3664 = inttoptr i64 %3662 to i32*
  store i32 %3645, i32* %3664, align 4
  %3665 = load i64, i64* %RBP, align 8
  %3666 = add i64 %3665, -48
  %3667 = load i64, i64* %PC, align 8
  %3668 = add i64 %3667, 3
  store i64 %3668, i64* %PC, align 8
  %3669 = inttoptr i64 %3666 to i32*
  %3670 = load i32, i32* %3669, align 4
  %3671 = shl i32 %3670, 3
  %3672 = zext i32 %3671 to i64
  store i64 %3672, i64* %RAX, align 8, !tbaa !2428
  %3673 = lshr i32 %3670, 29
  %3674 = trunc i32 %3673 to i8
  %3675 = and i8 %3674, 1
  store i8 %3675, i8* %50, align 1, !tbaa !2432
  %3676 = and i32 %3671, 248
  %3677 = tail call i32 @llvm.ctpop.i32(i32 %3676) #10
  %3678 = trunc i32 %3677 to i8
  %3679 = and i8 %3678, 1
  %3680 = xor i8 %3679, 1
  store i8 %3680, i8* %51, align 1, !tbaa !2432
  store i8 0, i8* %52, align 1, !tbaa !2432
  %3681 = icmp eq i32 %3671, 0
  %3682 = zext i1 %3681 to i8
  store i8 %3682, i8* %53, align 1, !tbaa !2432
  %3683 = lshr i32 %3670, 28
  %3684 = trunc i32 %3683 to i8
  %3685 = and i8 %3684, 1
  store i8 %3685, i8* %54, align 1, !tbaa !2432
  store i8 0, i8* %55, align 1, !tbaa !2432
  %3686 = add i64 %3665, -44
  %3687 = add i64 %3667, 9
  store i64 %3687, i64* %PC, align 8
  %3688 = inttoptr i64 %3686 to i32*
  %3689 = load i32, i32* %3688, align 4
  %3690 = sub i32 %3671, %3689
  %3691 = icmp ult i32 %3671, %3689
  %3692 = zext i1 %3691 to i8
  store i8 %3692, i8* %50, align 1, !tbaa !2433
  %3693 = and i32 %3690, 255
  %3694 = tail call i32 @llvm.ctpop.i32(i32 %3693) #10
  %3695 = trunc i32 %3694 to i8
  %3696 = and i8 %3695, 1
  %3697 = xor i8 %3696, 1
  store i8 %3697, i8* %51, align 1, !tbaa !2447
  %3698 = xor i32 %3689, %3671
  %3699 = xor i32 %3698, %3690
  %3700 = lshr i32 %3699, 4
  %3701 = trunc i32 %3700 to i8
  %3702 = and i8 %3701, 1
  store i8 %3702, i8* %52, align 1, !tbaa !2451
  %3703 = icmp eq i32 %3690, 0
  %3704 = zext i1 %3703 to i8
  store i8 %3704, i8* %53, align 1, !tbaa !2448
  %3705 = lshr i32 %3690, 31
  %3706 = trunc i32 %3705 to i8
  store i8 %3706, i8* %54, align 1, !tbaa !2449
  %3707 = lshr i32 %3670, 28
  %3708 = and i32 %3707, 1
  %3709 = lshr i32 %3689, 31
  %3710 = xor i32 %3709, %3708
  %3711 = xor i32 %3705, %3708
  %3712 = add nuw nsw i32 %3711, %3710
  %3713 = icmp eq i32 %3712, 2
  %3714 = zext i1 %3713 to i8
  store i8 %3714, i8* %55, align 1, !tbaa !2450
  %.v45 = select i1 %3703, i64 15, i64 1303
  %3715 = add i64 %3667, %.v45
  store i64 %3715, i64* %PC, align 8, !tbaa !2428
  br i1 %3703, label %block_401ca3, label %block_4021ab

block_401ca3:                                     ; preds = %block_401c8b
  %3716 = add i64 %3665, -36
  %3717 = add i64 %3715, 7
  store i64 %3717, i64* %PC, align 8
  %3718 = inttoptr i64 %3716 to i32*
  store i32 0, i32* %3718, align 4
  %3719 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %3642, i64 0, i32 0, i32 0, i32 0, i64 0
  %3720 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %3721 = bitcast i64* %3720 to double*
  %.pre40 = load i64, i64* %PC, align 8
  br label %block_401caa

block_4021ab:                                     ; preds = %block_401c8b
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %3722 = add i64 %3665, -24
  %3723 = add i64 %3715, 14
  store i64 %3723, i64* %PC, align 8
  %3724 = inttoptr i64 %3722 to i64*
  %3725 = load i64, i64* %3724, align 8
  store i64 %3725, i64* %RCX, align 8, !tbaa !2428
  %3726 = add i64 %3725, 8
  %3727 = add i64 %3715, 19
  store i64 %3727, i64* %PC, align 8
  %3728 = inttoptr i64 %3726 to i64*
  %3729 = load i64, i64* %3728, align 8
  %3730 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %3642, i64 0, i32 0, i32 0, i32 0, i64 0
  %3731 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %3732 = bitcast i64* %3731 to double*
  %3733 = xor i64 %3729, -9223372036854775808
  store i64 %3733, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %3734 = trunc i64 %3729 to i32
  %3735 = and i32 %3734, 255
  %3736 = tail call i32 @llvm.ctpop.i32(i32 %3735) #10
  %3737 = trunc i32 %3736 to i8
  %3738 = and i8 %3737, 1
  %3739 = xor i8 %3738, 1
  store i8 %3739, i8* %51, align 1, !tbaa !2447
  %3740 = icmp eq i64 %3733, 0
  %3741 = zext i1 %3740 to i8
  store i8 %3741, i8* %53, align 1, !tbaa !2448
  %3742 = lshr i64 %3733, 63
  %3743 = trunc i64 %3742 to i8
  store i8 %3743, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %3733, i64* %3730, align 1, !tbaa !2428
  store i64 0, i64* %3731, align 1, !tbaa !2428
  %3744 = add i64 %3715, 36
  store i64 %3744, i64* %PC, align 8
  %3745 = load i64, i64* %3724, align 8
  store i64 %3745, i64* %RCX, align 8, !tbaa !2428
  %3746 = add i64 %3745, 8
  %3747 = add i64 %3715, 41
  store i64 %3747, i64* %PC, align 8
  %3748 = inttoptr i64 %3746 to i64*
  store i64 %3733, i64* %3748, align 8
  %3749 = load i64, i64* %RBP, align 8
  %3750 = add i64 %3749, -24
  %3751 = load i64, i64* %PC, align 8
  %3752 = add i64 %3751, 4
  store i64 %3752, i64* %PC, align 8
  %3753 = inttoptr i64 %3750 to i64*
  %3754 = load i64, i64* %3753, align 8
  store i64 %3754, i64* %RCX, align 8, !tbaa !2428
  %3755 = add i64 %3749, -52
  %3756 = add i64 %3751, 7
  store i64 %3756, i64* %PC, align 8
  %3757 = inttoptr i64 %3755 to i32*
  %3758 = load i32, i32* %3757, align 4
  %3759 = add i32 %3758, 1
  %3760 = zext i32 %3759 to i64
  store i64 %3760, i64* %RDX, align 8, !tbaa !2428
  %3761 = icmp eq i32 %3758, -1
  %3762 = icmp eq i32 %3759, 0
  %3763 = or i1 %3761, %3762
  %3764 = zext i1 %3763 to i8
  store i8 %3764, i8* %50, align 1, !tbaa !2433
  %3765 = and i32 %3759, 255
  %3766 = tail call i32 @llvm.ctpop.i32(i32 %3765) #10
  %3767 = trunc i32 %3766 to i8
  %3768 = and i8 %3767, 1
  %3769 = xor i8 %3768, 1
  store i8 %3769, i8* %51, align 1, !tbaa !2447
  %3770 = xor i32 %3759, %3758
  %3771 = lshr i32 %3770, 4
  %3772 = trunc i32 %3771 to i8
  %3773 = and i8 %3772, 1
  store i8 %3773, i8* %52, align 1, !tbaa !2451
  %3774 = zext i1 %3762 to i8
  store i8 %3774, i8* %53, align 1, !tbaa !2448
  %3775 = lshr i32 %3759, 31
  %3776 = trunc i32 %3775 to i8
  store i8 %3776, i8* %54, align 1, !tbaa !2449
  %3777 = lshr i32 %3758, 31
  %3778 = xor i32 %3775, %3777
  %3779 = add nuw nsw i32 %3778, %3775
  %3780 = icmp eq i32 %3779, 2
  %3781 = zext i1 %3780 to i8
  store i8 %3781, i8* %55, align 1, !tbaa !2450
  %3782 = sext i32 %3759 to i64
  store i64 %3782, i64* %RSI, align 8, !tbaa !2428
  %3783 = shl nsw i64 %3782, 3
  %3784 = add i64 %3754, %3783
  %3785 = add i64 %3751, 18
  store i64 %3785, i64* %PC, align 8
  %3786 = inttoptr i64 %3784 to i64*
  %3787 = load i64, i64* %3786, align 8
  %3788 = load i64, i64* %RAX, align 8
  %3789 = xor i64 %3788, %3787
  store i64 %3789, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2433
  %3790 = trunc i64 %3789 to i32
  %3791 = and i32 %3790, 255
  %3792 = tail call i32 @llvm.ctpop.i32(i32 %3791) #10
  %3793 = trunc i32 %3792 to i8
  %3794 = and i8 %3793, 1
  %3795 = xor i8 %3794, 1
  store i8 %3795, i8* %51, align 1, !tbaa !2447
  %3796 = icmp eq i64 %3789, 0
  %3797 = zext i1 %3796 to i8
  store i8 %3797, i8* %53, align 1, !tbaa !2448
  %3798 = lshr i64 %3789, 63
  %3799 = trunc i64 %3798 to i8
  store i8 %3799, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2451
  store i64 %3789, i64* %3730, align 1, !tbaa !2428
  store i64 0, i64* %3731, align 1, !tbaa !2428
  %3800 = add i64 %3751, 35
  store i64 %3800, i64* %PC, align 8
  %3801 = load i64, i64* %3753, align 8
  store i64 %3801, i64* %RAX, align 8, !tbaa !2428
  %3802 = add i64 %3751, 38
  store i64 %3802, i64* %PC, align 8
  %3803 = load i32, i32* %3757, align 4
  %3804 = add i32 %3803, 1
  %3805 = zext i32 %3804 to i64
  store i64 %3805, i64* %RDX, align 8, !tbaa !2428
  %3806 = icmp eq i32 %3803, -1
  %3807 = icmp eq i32 %3804, 0
  %3808 = or i1 %3806, %3807
  %3809 = zext i1 %3808 to i8
  store i8 %3809, i8* %50, align 1, !tbaa !2433
  %3810 = and i32 %3804, 255
  %3811 = tail call i32 @llvm.ctpop.i32(i32 %3810) #10
  %3812 = trunc i32 %3811 to i8
  %3813 = and i8 %3812, 1
  %3814 = xor i8 %3813, 1
  store i8 %3814, i8* %51, align 1, !tbaa !2447
  %3815 = xor i32 %3804, %3803
  %3816 = lshr i32 %3815, 4
  %3817 = trunc i32 %3816 to i8
  %3818 = and i8 %3817, 1
  store i8 %3818, i8* %52, align 1, !tbaa !2451
  %3819 = zext i1 %3807 to i8
  store i8 %3819, i8* %53, align 1, !tbaa !2448
  %3820 = lshr i32 %3804, 31
  %3821 = trunc i32 %3820 to i8
  store i8 %3821, i8* %54, align 1, !tbaa !2449
  %3822 = lshr i32 %3803, 31
  %3823 = xor i32 %3820, %3822
  %3824 = add nuw nsw i32 %3823, %3820
  %3825 = icmp eq i32 %3824, 2
  %3826 = zext i1 %3825 to i8
  store i8 %3826, i8* %55, align 1, !tbaa !2450
  %3827 = sext i32 %3804 to i64
  store i64 %3827, i64* %RCX, align 8, !tbaa !2428
  %3828 = shl nsw i64 %3827, 3
  %3829 = add i64 %3801, %3828
  %3830 = add i64 %3751, 49
  store i64 %3830, i64* %PC, align 8
  %3831 = inttoptr i64 %3829 to i64*
  store i64 %3789, i64* %3831, align 8
  %3832 = load i64, i64* %RBP, align 8
  %3833 = add i64 %3832, -36
  %3834 = load i64, i64* %PC, align 8
  %3835 = add i64 %3834, 7
  store i64 %3835, i64* %PC, align 8
  %3836 = inttoptr i64 %3833 to i32*
  store i32 1, i32* %3836, align 4
  %.pre42 = load i64, i64* %PC, align 8
  br label %block_40220c

block_401c45:                                     ; preds = %block_401c35, %block_401c51
  %3837 = phi i64 [ %.pre44, %block_401c35 ], [ %192, %block_401c51 ]
  %3838 = load i64, i64* %RBP, align 8
  %3839 = add i64 %3838, -28
  %3840 = add i64 %3837, 3
  store i64 %3840, i64* %PC, align 8
  %3841 = inttoptr i64 %3839 to i32*
  %3842 = load i32, i32* %3841, align 4
  %3843 = zext i32 %3842 to i64
  store i64 %3843, i64* %RAX, align 8, !tbaa !2428
  %3844 = add i64 %3838, -48
  %3845 = add i64 %3837, 6
  store i64 %3845, i64* %PC, align 8
  %3846 = inttoptr i64 %3844 to i32*
  %3847 = load i32, i32* %3846, align 4
  %3848 = sub i32 %3842, %3847
  %3849 = icmp ult i32 %3842, %3847
  %3850 = zext i1 %3849 to i8
  store i8 %3850, i8* %50, align 1, !tbaa !2433
  %3851 = and i32 %3848, 255
  %3852 = tail call i32 @llvm.ctpop.i32(i32 %3851) #10
  %3853 = trunc i32 %3852 to i8
  %3854 = and i8 %3853, 1
  %3855 = xor i8 %3854, 1
  store i8 %3855, i8* %51, align 1, !tbaa !2447
  %3856 = xor i32 %3847, %3842
  %3857 = xor i32 %3856, %3848
  %3858 = lshr i32 %3857, 4
  %3859 = trunc i32 %3858 to i8
  %3860 = and i8 %3859, 1
  store i8 %3860, i8* %52, align 1, !tbaa !2451
  %3861 = icmp eq i32 %3848, 0
  %3862 = zext i1 %3861 to i8
  store i8 %3862, i8* %53, align 1, !tbaa !2448
  %3863 = lshr i32 %3848, 31
  %3864 = trunc i32 %3863 to i8
  store i8 %3864, i8* %54, align 1, !tbaa !2449
  %3865 = lshr i32 %3842, 31
  %3866 = lshr i32 %3847, 31
  %3867 = xor i32 %3866, %3865
  %3868 = xor i32 %3863, %3865
  %3869 = add nuw nsw i32 %3868, %3867
  %3870 = icmp eq i32 %3869, 2
  %3871 = zext i1 %3870 to i8
  store i8 %3871, i8* %55, align 1, !tbaa !2450
  %3872 = icmp ne i8 %3864, 0
  %3873 = xor i1 %3872, %3870
  %.v50 = select i1 %3873, i64 12, i64 56
  %3874 = add i64 %3837, %.v50
  store i64 %3874, i64* %PC, align 8, !tbaa !2428
  br i1 %3873, label %block_401c51, label %block_401c7d
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4010f0_errorcheck(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4010f0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %10 = load i64, i64* %RBP, align 8
  %11 = add i64 %1, 1
  store i64 %11, i64* %PC, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %13 = load i64, i64* %12, align 8, !tbaa !2428
  %14 = add i64 %13, -8
  %15 = inttoptr i64 %14 to i64*
  store i64 %10, i64* %15, align 8
  store i64 %14, i64* %12, align 8, !tbaa !2428
  %16 = load i64, i64* %PC, align 8
  store i64 %14, i64* %RBP, align 8, !tbaa !2428
  %17 = bitcast %union.VectorReg* %8 to i8*
  %18 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %20 = bitcast %union.VectorReg* %8 to i32*
  %21 = getelementptr inbounds i8, i8* %17, i64 4
  %22 = bitcast i8* %21 to i32*
  %23 = bitcast i64* %19 to i32*
  %24 = getelementptr inbounds i8, i8* %17, i64 12
  %25 = bitcast i8* %24 to i32*
  %26 = bitcast %union.VectorReg* %8 to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %26, align 1, !tbaa !2461
  %27 = add i64 %13, -12
  %28 = load i32, i32* %EDI, align 4
  %29 = add i64 %16, 9
  store i64 %29, i64* %PC, align 8
  %30 = inttoptr i64 %27 to i32*
  store i32 %28, i32* %30, align 4
  %31 = load i64, i64* %RBP, align 8
  %32 = add i64 %31, -8
  %33 = load i32, i32* %ESI, align 4
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 3
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %32 to i32*
  store i32 %33, i32* %36, align 4
  %37 = load i64, i64* %RBP, align 8
  %38 = add i64 %37, -16
  %39 = load i64, i64* %PC, align 8
  %40 = add i64 %39, 5
  store i64 %40, i64* %PC, align 8
  %41 = bitcast [32 x %union.VectorReg]* %7 to double*
  %42 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %43 = load i64, i64* %42, align 1
  %44 = inttoptr i64 %38 to i64*
  store i64 %43, i64* %44, align 8
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -24
  %47 = load i64, i64* %RDX, align 8
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 4
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %46 to i64*
  store i64 %47, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -32
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 7
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %52 to i32*
  store i32 0, i32* %55, align 4
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -40
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 5
  store i64 %59, i64* %PC, align 8
  %60 = bitcast %union.VectorReg* %8 to double*
  %61 = load i64, i64* %18, align 1
  %62 = inttoptr i64 %57 to i64*
  store i64 %61, i64* %62, align 8
  %63 = load i64, i64* %RBP, align 8
  %64 = add i64 %63, -4
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %65, 3
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %64 to i32*
  %68 = load i32, i32* %67, align 4
  %69 = zext i32 %68 to i64
  store i64 %69, i64* %RSI, align 8, !tbaa !2428
  %70 = add i64 %63, -28
  %71 = add i64 %65, 6
  store i64 %71, i64* %PC, align 8
  %72 = inttoptr i64 %70 to i32*
  store i32 %68, i32* %72, align 4
  %73 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %74 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %76 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %77 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %78 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %79 = bitcast [32 x %union.VectorReg]* %7 to i8*
  %80 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %81 = bitcast i64* %80 to double*
  %82 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %83 = bitcast %union.VectorReg* %9 to i8*
  %84 = bitcast %union.VectorReg* %9 to i32*
  %85 = getelementptr inbounds i8, i8* %83, i64 4
  %86 = bitcast i8* %85 to i32*
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %88 = bitcast i64* %87 to i32*
  %89 = getelementptr inbounds i8, i8* %83, i64 12
  %90 = bitcast i8* %89 to i32*
  %91 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  %92 = bitcast [32 x %union.VectorReg]* %7 to i32*
  %93 = getelementptr inbounds i8, i8* %79, i64 4
  %94 = bitcast i8* %93 to i32*
  %95 = bitcast i64* %80 to i32*
  %96 = getelementptr inbounds i8, i8* %79, i64 12
  %97 = bitcast i8* %96 to i32*
  %.pre = load i64, i64* %PC, align 8
  br label %block_401118

block_401118:                                     ; preds = %block_4011b2, %block_4010f0
  %98 = phi i64 [ %.pre, %block_4010f0 ], [ %176, %block_4011b2 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_4010f0 ], [ %357, %block_4011b2 ]
  %99 = load i64, i64* %RBP, align 8
  %100 = add i64 %99, -28
  %101 = add i64 %98, 3
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to i32*
  %103 = load i32, i32* %102, align 4
  %104 = zext i32 %103 to i64
  store i64 %104, i64* %RAX, align 8, !tbaa !2428
  %105 = add i64 %99, -8
  %106 = add i64 %98, 6
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %105 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = sub i32 %103, %108
  %110 = icmp ult i32 %103, %108
  %111 = zext i1 %110 to i8
  store i8 %111, i8* %73, align 1, !tbaa !2433
  %112 = and i32 %109, 255
  %113 = tail call i32 @llvm.ctpop.i32(i32 %112) #10
  %114 = trunc i32 %113 to i8
  %115 = and i8 %114, 1
  %116 = xor i8 %115, 1
  store i8 %116, i8* %74, align 1, !tbaa !2447
  %117 = xor i32 %108, %103
  %118 = xor i32 %117, %109
  %119 = lshr i32 %118, 4
  %120 = trunc i32 %119 to i8
  %121 = and i8 %120, 1
  store i8 %121, i8* %75, align 1, !tbaa !2451
  %122 = icmp eq i32 %109, 0
  %123 = zext i1 %122 to i8
  store i8 %123, i8* %76, align 1, !tbaa !2448
  %124 = lshr i32 %109, 31
  %125 = trunc i32 %124 to i8
  store i8 %125, i8* %77, align 1, !tbaa !2449
  %126 = lshr i32 %103, 31
  %127 = lshr i32 %108, 31
  %128 = xor i32 %127, %126
  %129 = xor i32 %124, %126
  %130 = add nuw nsw i32 %129, %128
  %131 = icmp eq i32 %130, 2
  %132 = zext i1 %131 to i8
  store i8 %132, i8* %78, align 1, !tbaa !2450
  %133 = icmp ne i8 %125, 0
  %134 = xor i1 %133, %131
  %.demorgan = or i1 %122, %134
  %.v = select i1 %.demorgan, i64 12, i64 178
  %135 = add i64 %98, %.v
  store i64 %135, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_401124, label %block_4011ca

block_4011b2:                                     ; preds = %block_40119d, %block_40118e
  %136 = phi i64 [ %.pre7, %block_40119d ], [ %185, %block_40118e ]
  %137 = load i64, i64* %RBP, align 8
  %138 = add i64 %137, -64
  %139 = add i64 %136, 5
  store i64 %139, i64* %PC, align 8
  %140 = inttoptr i64 %138 to i64*
  %141 = load i64, i64* %140, align 8
  store i64 %141, i64* %42, align 1, !tbaa !2452
  store double 0.000000e+00, double* %81, align 1, !tbaa !2452
  %142 = add i64 %137, -40
  %143 = add i64 %136, 10
  store i64 %143, i64* %PC, align 8
  %144 = inttoptr i64 %142 to i64*
  store i64 %141, i64* %144, align 8
  %145 = load i64, i64* %RBP, align 8
  %146 = add i64 %145, -28
  %147 = load i64, i64* %PC, align 8
  %148 = add i64 %147, 3
  store i64 %148, i64* %PC, align 8
  %149 = inttoptr i64 %146 to i32*
  %150 = load i32, i32* %149, align 4
  %151 = add i32 %150, 1
  %152 = zext i32 %151 to i64
  store i64 %152, i64* %RAX, align 8, !tbaa !2428
  %153 = icmp eq i32 %150, -1
  %154 = icmp eq i32 %151, 0
  %155 = or i1 %153, %154
  %156 = zext i1 %155 to i8
  store i8 %156, i8* %73, align 1, !tbaa !2433
  %157 = and i32 %151, 255
  %158 = tail call i32 @llvm.ctpop.i32(i32 %157) #10
  %159 = trunc i32 %158 to i8
  %160 = and i8 %159, 1
  %161 = xor i8 %160, 1
  store i8 %161, i8* %74, align 1, !tbaa !2447
  %162 = xor i32 %151, %150
  %163 = lshr i32 %162, 4
  %164 = trunc i32 %163 to i8
  %165 = and i8 %164, 1
  store i8 %165, i8* %75, align 1, !tbaa !2451
  %166 = zext i1 %154 to i8
  store i8 %166, i8* %76, align 1, !tbaa !2448
  %167 = lshr i32 %151, 31
  %168 = trunc i32 %167 to i8
  store i8 %168, i8* %77, align 1, !tbaa !2449
  %169 = lshr i32 %150, 31
  %170 = xor i32 %167, %169
  %171 = add nuw nsw i32 %170, %167
  %172 = icmp eq i32 %171, 2
  %173 = zext i1 %172 to i8
  store i8 %173, i8* %78, align 1, !tbaa !2450
  %174 = add i64 %147, 9
  store i64 %174, i64* %PC, align 8
  store i32 %151, i32* %149, align 4
  %175 = load i64, i64* %PC, align 8
  %176 = add i64 %175, -173
  store i64 %176, i64* %PC, align 8, !tbaa !2428
  br label %block_401118

block_40118e:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %177 = add i64 %355, -40
  %178 = add i64 %362, 5
  store i64 %178, i64* %PC, align 8
  %179 = inttoptr i64 %177 to i64*
  %180 = load i64, i64* %179, align 8
  store i64 %180, i64* %42, align 1, !tbaa !2452
  store double 0.000000e+00, double* %81, align 1, !tbaa !2452
  %181 = add i64 %355, -64
  %182 = add i64 %362, 10
  store i64 %182, i64* %PC, align 8
  %183 = inttoptr i64 %181 to i64*
  store i64 %180, i64* %183, align 8
  %184 = load i64, i64* %PC, align 8
  %185 = add i64 %184, 26
  store i64 %185, i64* %PC, align 8, !tbaa !2428
  br label %block_4011b2

block_4011ca:                                     ; preds = %block_401118
  %186 = add i64 %99, -40
  %187 = add i64 %135, 5
  store i64 %187, i64* %PC, align 8
  %188 = inttoptr i64 %186 to i64*
  %189 = load i64, i64* %188, align 8
  store i64 %189, i64* %42, align 1, !tbaa !2452
  store double 0.000000e+00, double* %81, align 1, !tbaa !2452
  %190 = add i64 %135, 6
  store i64 %190, i64* %PC, align 8
  %191 = load i64, i64* %12, align 8, !tbaa !2428
  %192 = add i64 %191, 8
  %193 = inttoptr i64 %191 to i64*
  %194 = load i64, i64* %193, align 8
  store i64 %194, i64* %RBP, align 8, !tbaa !2428
  store i64 %192, i64* %12, align 8, !tbaa !2428
  %195 = add i64 %135, 7
  store i64 %195, i64* %PC, align 8
  %196 = inttoptr i64 %192 to i64*
  %197 = load i64, i64* %196, align 8
  store i64 %197, i64* %PC, align 8, !tbaa !2428
  %198 = add i64 %191, 16
  store i64 %198, i64* %12, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_40119d:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %199 = add i64 %355, -48
  %200 = add i64 %362, 5
  store i64 %200, i64* %PC, align 8
  %201 = inttoptr i64 %199 to i64*
  %202 = load i64, i64* %201, align 8
  %203 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 96) to i32*), align 16
  %204 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 100) to i32*), align 4
  %205 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 104) to i32*), align 8
  %206 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 108) to i32*), align 4
  store i32 %203, i32* %20, align 1, !tbaa !2454
  store i32 %204, i32* %22, align 1, !tbaa !2454
  store i32 %205, i32* %23, align 1, !tbaa !2454
  store i32 %206, i32* %25, align 1, !tbaa !2454
  %207 = load i64, i64* %18, align 1
  %208 = and i64 %207, %202
  %209 = trunc i64 %208 to i32
  %210 = lshr i64 %208, 32
  %211 = trunc i64 %210 to i32
  store i32 %209, i32* %92, align 1, !tbaa !2461
  store i32 %211, i32* %94, align 1, !tbaa !2461
  store i32 0, i32* %95, align 1, !tbaa !2461
  store i32 0, i32* %97, align 1, !tbaa !2461
  %212 = add i64 %355, -64
  %213 = add i64 %362, 21
  store i64 %213, i64* %PC, align 8
  %214 = load i64, i64* %42, align 1
  %215 = inttoptr i64 %212 to i64*
  store i64 %214, i64* %215, align 8
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_4011b2

block_401124:                                     ; preds = %block_401118
  %216 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 72) to i64*), align 8
  store i64 %216, i64* %42, align 1, !tbaa !2452
  store double 0.000000e+00, double* %81, align 1, !tbaa !2452
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %217 = add i64 %99, -32
  %218 = add i64 %135, 20
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %217 to i32*
  %220 = load i32, i32* %219, align 4
  %221 = mul i32 %220, 7141
  %222 = add i32 %221, 54773
  %223 = zext i32 %222 to i64
  store i64 %223, i64* %RCX, align 8, !tbaa !2428
  %224 = icmp ugt i32 %221, -54774
  %225 = zext i1 %224 to i8
  store i8 %225, i8* %73, align 1, !tbaa !2433
  %226 = and i32 %222, 255
  %227 = tail call i32 @llvm.ctpop.i32(i32 %226) #10
  %228 = trunc i32 %227 to i8
  %229 = and i8 %228, 1
  %230 = xor i8 %229, 1
  store i8 %230, i8* %74, align 1, !tbaa !2447
  %231 = xor i32 %221, 16
  %232 = xor i32 %231, %222
  %233 = lshr i32 %232, 4
  %234 = trunc i32 %233 to i8
  %235 = and i8 %234, 1
  store i8 %235, i8* %75, align 1, !tbaa !2451
  %236 = icmp eq i32 %222, 0
  %237 = zext i1 %236 to i8
  store i8 %237, i8* %76, align 1, !tbaa !2448
  %238 = lshr i32 %222, 31
  %239 = trunc i32 %238 to i8
  store i8 %239, i8* %77, align 1, !tbaa !2449
  %240 = lshr i32 %221, 31
  %241 = xor i32 %238, %240
  %242 = add nuw nsw i32 %241, %238
  %243 = icmp eq i32 %242, 2
  %244 = zext i1 %243 to i8
  store i8 %244, i8* %78, align 1, !tbaa !2450
  %245 = add i64 %99, -52
  %246 = add i64 %135, 29
  store i64 %246, i64* %PC, align 8
  %247 = inttoptr i64 %245 to i32*
  store i32 259200, i32* %247, align 4
  %248 = load i32, i32* %ECX, align 4
  %249 = zext i32 %248 to i64
  %250 = load i64, i64* %PC, align 8
  store i64 %249, i64* %RAX, align 8, !tbaa !2428
  %251 = sext i32 %248 to i64
  %252 = lshr i64 %251, 32
  store i64 %252, i64* %82, align 8, !tbaa !2428
  %253 = load i64, i64* %RBP, align 8
  %254 = add i64 %253, -52
  %255 = add i64 %250, 6
  store i64 %255, i64* %PC, align 8
  %256 = inttoptr i64 %254 to i32*
  %257 = load i32, i32* %256, align 4
  %258 = zext i32 %257 to i64
  store i64 %258, i64* %RCX, align 8, !tbaa !2428
  %259 = add i64 %250, 8
  store i64 %259, i64* %PC, align 8
  %260 = sext i32 %257 to i64
  %261 = shl nuw i64 %252, 32
  %262 = or i64 %261, %249
  %263 = sdiv i64 %262, %260
  %264 = shl i64 %263, 32
  %265 = ashr exact i64 %264, 32
  %266 = icmp eq i64 %263, %265
  br i1 %266, label %269, label %267

; <label>:267:                                    ; preds = %block_401124
  %268 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %259, %struct.Memory* %MEMORY.0) #15
  %.pre2 = load i64, i64* %RBP, align 8
  %.pre3 = load i32, i32* %EDX, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:269:                                    ; preds = %block_401124
  %270 = srem i64 %262, %260
  %271 = and i64 %263, 4294967295
  store i64 %271, i64* %RAX, align 8, !tbaa !2428
  %272 = and i64 %270, 4294967295
  store i64 %272, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %73, align 1, !tbaa !2433
  store i8 0, i8* %74, align 1, !tbaa !2447
  store i8 0, i8* %75, align 1, !tbaa !2451
  store i8 0, i8* %76, align 1, !tbaa !2448
  store i8 0, i8* %77, align 1, !tbaa !2449
  store i8 0, i8* %78, align 1, !tbaa !2450
  %273 = trunc i64 %270 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %269, %267
  %274 = phi i64 [ %.pre4, %267 ], [ %259, %269 ]
  %275 = phi i32 [ %.pre3, %267 ], [ %273, %269 ]
  %276 = phi i64 [ %.pre2, %267 ], [ %253, %269 ]
  %277 = phi %struct.Memory* [ %268, %267 ], [ %MEMORY.0, %269 ]
  %278 = add i64 %276, -32
  %279 = add i64 %274, 3
  store i64 %279, i64* %PC, align 8
  %280 = inttoptr i64 %278 to i32*
  store i32 %275, i32* %280, align 4
  %281 = load i32, i32* %EDX, align 4
  %282 = load i64, i64* %PC, align 8
  %283 = sitofp i32 %281 to double
  %284 = load double, double* %41, align 1
  %285 = fmul double %283, %284
  store double %285, double* %60, align 1, !tbaa !2452
  %286 = load i64, i64* %RBP, align 8
  %287 = add i64 %286, -24
  %288 = add i64 %282, 12
  store i64 %288, i64* %PC, align 8
  %289 = inttoptr i64 %287 to i64*
  %290 = load i64, i64* %289, align 8
  store i64 %290, i64* %RSI, align 8, !tbaa !2428
  %291 = add i64 %286, -28
  %292 = add i64 %282, 16
  store i64 %292, i64* %PC, align 8
  %293 = inttoptr i64 %291 to i32*
  %294 = load i32, i32* %293, align 4
  %295 = sext i32 %294 to i64
  store i64 %295, i64* %RDI, align 8, !tbaa !2428
  %296 = shl nsw i64 %295, 3
  %297 = add i64 %296, %290
  %298 = add i64 %282, 21
  store i64 %298, i64* %PC, align 8
  %299 = inttoptr i64 %297 to i64*
  %300 = load i64, i64* %299, align 8
  store i64 %300, i64* %42, align 1, !tbaa !2452
  store double 0.000000e+00, double* %81, align 1, !tbaa !2452
  %301 = add i64 %286, -16
  %302 = add i64 %282, 26
  store i64 %302, i64* %PC, align 8
  %303 = bitcast i64 %300 to double
  %304 = inttoptr i64 %301 to double*
  %305 = load double, double* %304, align 8
  %306 = fmul double %303, %305
  store double %306, double* %41, align 1, !tbaa !2452
  store i64 0, i64* %80, align 1, !tbaa !2452
  %307 = fsub double %285, %306
  store double %307, double* %60, align 1, !tbaa !2452
  %308 = add i64 %286, -48
  %309 = add i64 %282, 35
  store i64 %309, i64* %PC, align 8
  %310 = inttoptr i64 %308 to double*
  store double %307, double* %310, align 8
  %311 = load i64, i64* %RBP, align 8
  %312 = add i64 %311, -40
  %313 = load i64, i64* %PC, align 8
  %314 = add i64 %313, 5
  store i64 %314, i64* %PC, align 8
  %315 = inttoptr i64 %312 to i64*
  %316 = load i64, i64* %315, align 8
  store i64 %316, i64* %42, align 1, !tbaa !2452
  store double 0.000000e+00, double* %81, align 1, !tbaa !2452
  %317 = add i64 %311, -48
  %318 = add i64 %313, 10
  store i64 %318, i64* %PC, align 8
  %319 = inttoptr i64 %317 to i64*
  %320 = load i64, i64* %319, align 8
  %321 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 96) to i32*), align 16
  %322 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 100) to i32*), align 4
  %323 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 104) to i32*), align 8
  %324 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404090__rodata_type* @seg_404090__rodata to i64), i64 108) to i32*), align 4
  store i32 %321, i32* %84, align 1, !tbaa !2454
  store i32 %322, i32* %86, align 1, !tbaa !2454
  store i32 %323, i32* %88, align 1, !tbaa !2454
  store i32 %324, i32* %90, align 1, !tbaa !2454
  %325 = load i64, i64* %91, align 1
  %326 = and i64 %325, %320
  %327 = trunc i64 %326 to i32
  %328 = lshr i64 %326, 32
  %329 = trunc i64 %328 to i32
  store i32 %327, i32* %20, align 1, !tbaa !2461
  store i32 %329, i32* %22, align 1, !tbaa !2461
  store i32 0, i32* %23, align 1, !tbaa !2461
  store i32 0, i32* %25, align 1, !tbaa !2461
  %330 = add i64 %313, 25
  store i64 %330, i64* %PC, align 8
  %331 = bitcast i64 %316 to double
  %332 = load double, double* %60, align 1
  %333 = fcmp uno double %331, %332
  br i1 %333, label %334, label %344

; <label>:334:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %335 = fadd double %331, %332
  %336 = bitcast double %335 to i64
  %337 = and i64 %336, 9221120237041090560
  %338 = icmp eq i64 %337, 9218868437227405312
  %339 = and i64 %336, 2251799813685247
  %340 = icmp ne i64 %339, 0
  %341 = and i1 %338, %340
  br i1 %341, label %342, label %350

; <label>:342:                                    ; preds = %334
  %343 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %330, %struct.Memory* %277) #15
  %.pre5 = load i64, i64* %PC, align 8
  %.pre6 = load i64, i64* %RBP, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:344:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %345 = fcmp ogt double %331, %332
  br i1 %345, label %350, label %346

; <label>:346:                                    ; preds = %344
  %347 = fcmp olt double %331, %332
  br i1 %347, label %350, label %348

; <label>:348:                                    ; preds = %346
  %349 = fcmp oeq double %331, %332
  br i1 %349, label %350, label %354

; <label>:350:                                    ; preds = %348, %346, %344, %334
  %351 = phi i8 [ 0, %344 ], [ 0, %346 ], [ 1, %348 ], [ 1, %334 ]
  %352 = phi i8 [ 0, %344 ], [ 0, %346 ], [ 0, %348 ], [ 1, %334 ]
  %353 = phi i8 [ 0, %344 ], [ 1, %346 ], [ 0, %348 ], [ 1, %334 ]
  store i8 %351, i8* %76, align 1, !tbaa !2432
  store i8 %352, i8* %74, align 1, !tbaa !2432
  store i8 %353, i8* %73, align 1, !tbaa !2432
  br label %354

; <label>:354:                                    ; preds = %350, %348
  store i8 0, i8* %78, align 1, !tbaa !2432
  store i8 0, i8* %77, align 1, !tbaa !2432
  store i8 0, i8* %75, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %354, %342
  %355 = phi i64 [ %.pre6, %342 ], [ %311, %354 ]
  %356 = phi i64 [ %.pre5, %342 ], [ %330, %354 ]
  %357 = phi %struct.Memory* [ %343, %342 ], [ %277, %354 ]
  %358 = load i8, i8* %73, align 1, !tbaa !2433
  %359 = load i8, i8* %76, align 1, !tbaa !2448
  %360 = or i8 %359, %358
  %361 = icmp ne i8 %360, 0
  %.v9 = select i1 %361, i64 21, i64 6
  %362 = add i64 %356, %.v9
  store i64 %362, i64* %PC, align 8, !tbaa !2428
  br i1 %361, label %block_40119d, label %block_40118e
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4024a0_cftbsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #7 {
block_4024a0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -120
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 112
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2433
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #10
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2447
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2451
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %7, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %10, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -44
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 7
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  store i32 2, i32* %60, align 4
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -4
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = add i32 %66, -8
  %68 = icmp ult i32 %66, 8
  %69 = zext i1 %68 to i8
  store i8 %69, i8* %14, align 1, !tbaa !2433
  %70 = and i32 %67, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #10
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %21, align 1, !tbaa !2447
  %75 = xor i32 %67, %66
  %76 = lshr i32 %75, 4
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %27, align 1, !tbaa !2451
  %79 = icmp eq i32 %67, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %30, align 1, !tbaa !2448
  %81 = lshr i32 %67, 31
  %82 = trunc i32 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2449
  %83 = lshr i32 %66, 31
  %84 = xor i32 %81, %83
  %85 = add nuw nsw i32 %84, %83
  %86 = icmp eq i32 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %39, align 1, !tbaa !2450
  %88 = icmp ne i8 %82, 0
  %89 = xor i1 %88, %86
  %90 = or i1 %79, %89
  %.v14 = select i1 %90, i64 86, i64 10
  %91 = add i64 %63, %.v14
  store i64 %91, i64* %PC, align 8, !tbaa !2428
  br i1 %90, label %block_402510, label %block_4024c4

block_402777:                                     ; preds = %block_402777.preheader, %block_402783
  %92 = phi i64 [ %591, %block_402783 ], [ %.pre12, %block_402777.preheader ]
  %93 = load i64, i64* %RBP, align 8
  %94 = add i64 %93, -28
  %95 = add i64 %92, 3
  store i64 %95, i64* %PC, align 8
  %96 = inttoptr i64 %94 to i32*
  %97 = load i32, i32* %96, align 4
  %98 = zext i32 %97 to i64
  store i64 %98, i64* %RAX, align 8, !tbaa !2428
  %99 = add i64 %93, -44
  %100 = add i64 %92, 6
  store i64 %100, i64* %PC, align 8
  %101 = inttoptr i64 %99 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = sub i32 %97, %102
  %104 = icmp ult i32 %97, %102
  %105 = zext i1 %104 to i8
  store i8 %105, i8* %14, align 1, !tbaa !2433
  %106 = and i32 %103, 255
  %107 = tail call i32 @llvm.ctpop.i32(i32 %106) #10
  %108 = trunc i32 %107 to i8
  %109 = and i8 %108, 1
  %110 = xor i8 %109, 1
  store i8 %110, i8* %21, align 1, !tbaa !2447
  %111 = xor i32 %102, %97
  %112 = xor i32 %111, %103
  %113 = lshr i32 %112, 4
  %114 = trunc i32 %113 to i8
  %115 = and i8 %114, 1
  store i8 %115, i8* %27, align 1, !tbaa !2451
  %116 = icmp eq i32 %103, 0
  %117 = zext i1 %116 to i8
  store i8 %117, i8* %30, align 1, !tbaa !2448
  %118 = lshr i32 %103, 31
  %119 = trunc i32 %118 to i8
  store i8 %119, i8* %33, align 1, !tbaa !2449
  %120 = lshr i32 %97, 31
  %121 = lshr i32 %102, 31
  %122 = xor i32 %121, %120
  %123 = xor i32 %118, %120
  %124 = add nuw nsw i32 %123, %122
  %125 = icmp eq i32 %124, 2
  %126 = zext i1 %125 to i8
  store i8 %126, i8* %39, align 1, !tbaa !2450
  %127 = icmp ne i8 %119, 0
  %128 = xor i1 %127, %125
  %.v16 = select i1 %128, i64 12, i64 269
  %129 = add i64 %92, %.v16
  store i64 %129, i64* %PC, align 8, !tbaa !2428
  br i1 %128, label %block_402783, label %block_402884

block_4024db:                                     ; preds = %block_4024c4, %block_4024ea
  %130 = phi i64 [ %.pre, %block_4024c4 ], [ %636, %block_4024ea ]
  %131 = load i64, i64* %RBP, align 8
  %132 = add i64 %131, -44
  %133 = add i64 %130, 3
  store i64 %133, i64* %PC, align 8
  %134 = inttoptr i64 %132 to i32*
  %135 = load i32, i32* %134, align 4
  %136 = shl i32 %135, 2
  %137 = zext i32 %136 to i64
  store i64 %137, i64* %RAX, align 8, !tbaa !2428
  %138 = lshr i32 %135, 30
  %139 = trunc i32 %138 to i8
  %140 = and i8 %139, 1
  store i8 %140, i8* %14, align 1, !tbaa !2432
  %141 = and i32 %136, 252
  %142 = tail call i32 @llvm.ctpop.i32(i32 %141) #10
  %143 = trunc i32 %142 to i8
  %144 = and i8 %143, 1
  %145 = xor i8 %144, 1
  store i8 %145, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %146 = icmp eq i32 %136, 0
  %147 = zext i1 %146 to i8
  store i8 %147, i8* %30, align 1, !tbaa !2432
  %148 = lshr i32 %135, 29
  %149 = trunc i32 %148 to i8
  %150 = and i8 %149, 1
  store i8 %150, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %151 = add i64 %131, -4
  %152 = add i64 %130, 9
  store i64 %152, i64* %PC, align 8
  %153 = inttoptr i64 %151 to i32*
  %154 = load i32, i32* %153, align 4
  %155 = sub i32 %136, %154
  %156 = icmp ult i32 %136, %154
  %157 = zext i1 %156 to i8
  store i8 %157, i8* %14, align 1, !tbaa !2433
  %158 = and i32 %155, 255
  %159 = tail call i32 @llvm.ctpop.i32(i32 %158) #10
  %160 = trunc i32 %159 to i8
  %161 = and i8 %160, 1
  %162 = xor i8 %161, 1
  store i8 %162, i8* %21, align 1, !tbaa !2447
  %163 = xor i32 %154, %136
  %164 = xor i32 %163, %155
  %165 = lshr i32 %164, 4
  %166 = trunc i32 %165 to i8
  %167 = and i8 %166, 1
  store i8 %167, i8* %27, align 1, !tbaa !2451
  %168 = icmp eq i32 %155, 0
  %169 = zext i1 %168 to i8
  store i8 %169, i8* %30, align 1, !tbaa !2448
  %170 = lshr i32 %155, 31
  %171 = trunc i32 %170 to i8
  store i8 %171, i8* %33, align 1, !tbaa !2449
  %172 = lshr i32 %135, 29
  %173 = and i32 %172, 1
  %174 = lshr i32 %154, 31
  %175 = xor i32 %174, %173
  %176 = xor i32 %170, %173
  %177 = add nuw nsw i32 %176, %175
  %178 = icmp eq i32 %177, 2
  %179 = zext i1 %178 to i8
  store i8 %179, i8* %39, align 1, !tbaa !2450
  %180 = icmp ne i8 %171, 0
  %181 = xor i1 %180, %178
  %.v15 = select i1 %181, i64 15, i64 48
  %182 = add i64 %130, %.v15
  store i64 %182, i64* %PC, align 8, !tbaa !2428
  br i1 %181, label %block_4024ea, label %block_40250b

block_402783:                                     ; preds = %block_402777
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %183 = add i64 %129, 13
  store i64 %183, i64* %PC, align 8
  %184 = load i32, i32* %96, align 4
  %185 = zext i32 %184 to i64
  store i64 %185, i64* %RCX, align 8, !tbaa !2428
  %186 = add i64 %129, 16
  store i64 %186, i64* %PC, align 8
  %187 = load i32, i32* %101, align 4
  %188 = add i32 %187, %184
  %189 = zext i32 %188 to i64
  store i64 %189, i64* %RCX, align 8, !tbaa !2428
  %190 = icmp ult i32 %188, %184
  %191 = icmp ult i32 %188, %187
  %192 = or i1 %190, %191
  %193 = zext i1 %192 to i8
  store i8 %193, i8* %14, align 1, !tbaa !2433
  %194 = and i32 %188, 255
  %195 = tail call i32 @llvm.ctpop.i32(i32 %194) #10
  %196 = trunc i32 %195 to i8
  %197 = and i8 %196, 1
  %198 = xor i8 %197, 1
  store i8 %198, i8* %21, align 1, !tbaa !2447
  %199 = xor i32 %187, %184
  %200 = xor i32 %199, %188
  %201 = lshr i32 %200, 4
  %202 = trunc i32 %201 to i8
  %203 = and i8 %202, 1
  store i8 %203, i8* %27, align 1, !tbaa !2451
  %204 = icmp eq i32 %188, 0
  %205 = zext i1 %204 to i8
  store i8 %205, i8* %30, align 1, !tbaa !2448
  %206 = lshr i32 %188, 31
  %207 = trunc i32 %206 to i8
  store i8 %207, i8* %33, align 1, !tbaa !2449
  %208 = lshr i32 %184, 31
  %209 = lshr i32 %187, 31
  %210 = xor i32 %206, %208
  %211 = xor i32 %206, %209
  %212 = add nuw nsw i32 %210, %211
  %213 = icmp eq i32 %212, 2
  %214 = zext i1 %213 to i8
  store i8 %214, i8* %39, align 1, !tbaa !2450
  %215 = add i64 %93, -32
  %216 = add i64 %129, 19
  store i64 %216, i64* %PC, align 8
  %217 = inttoptr i64 %215 to i32*
  store i32 %188, i32* %217, align 4
  %218 = load i64, i64* %RBP, align 8
  %219 = add i64 %218, -16
  %220 = load i64, i64* %PC, align 8
  %221 = add i64 %220, 4
  store i64 %221, i64* %PC, align 8
  %222 = inttoptr i64 %219 to i64*
  %223 = load i64, i64* %222, align 8
  store i64 %223, i64* %RDX, align 8, !tbaa !2428
  %224 = add i64 %218, -28
  %225 = add i64 %220, 8
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %224 to i32*
  %227 = load i32, i32* %226, align 4
  %228 = sext i32 %227 to i64
  store i64 %228, i64* %RSI, align 8, !tbaa !2428
  %229 = shl nsw i64 %228, 3
  %230 = add i64 %229, %223
  %231 = add i64 %220, 13
  store i64 %231, i64* %PC, align 8
  %232 = inttoptr i64 %230 to i64*
  %233 = load i64, i64* %232, align 8
  store i64 %233, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %234 = add i64 %220, 17
  store i64 %234, i64* %PC, align 8
  %235 = load i64, i64* %222, align 8
  store i64 %235, i64* %RDX, align 8, !tbaa !2428
  %236 = add i64 %218, -32
  %237 = add i64 %220, 21
  store i64 %237, i64* %PC, align 8
  %238 = inttoptr i64 %236 to i32*
  %239 = load i32, i32* %238, align 4
  %240 = sext i32 %239 to i64
  store i64 %240, i64* %RSI, align 8, !tbaa !2428
  %241 = shl nsw i64 %240, 3
  %242 = add i64 %241, %235
  %243 = add i64 %220, 26
  store i64 %243, i64* %PC, align 8
  %244 = bitcast i64 %233 to double
  %245 = inttoptr i64 %242 to double*
  %246 = load double, double* %245, align 8
  %247 = fsub double %244, %246
  store double %247, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %248 = add i64 %218, -56
  %249 = add i64 %220, 31
  store i64 %249, i64* %PC, align 8
  %250 = inttoptr i64 %248 to double*
  store double %247, double* %250, align 8
  %251 = load i64, i64* %RBP, align 8
  %252 = add i64 %251, -16
  %253 = load i64, i64* %PC, align 8
  %254 = add i64 %253, 4
  store i64 %254, i64* %PC, align 8
  %255 = inttoptr i64 %252 to i64*
  %256 = load i64, i64* %255, align 8
  store i64 %256, i64* %RDX, align 8, !tbaa !2428
  %257 = add i64 %251, -28
  %258 = add i64 %253, 7
  store i64 %258, i64* %PC, align 8
  %259 = inttoptr i64 %257 to i32*
  %260 = load i32, i32* %259, align 4
  %261 = add i32 %260, 1
  %262 = zext i32 %261 to i64
  store i64 %262, i64* %RCX, align 8, !tbaa !2428
  %263 = icmp eq i32 %260, -1
  %264 = icmp eq i32 %261, 0
  %265 = or i1 %263, %264
  %266 = zext i1 %265 to i8
  store i8 %266, i8* %14, align 1, !tbaa !2433
  %267 = and i32 %261, 255
  %268 = tail call i32 @llvm.ctpop.i32(i32 %267) #10
  %269 = trunc i32 %268 to i8
  %270 = and i8 %269, 1
  %271 = xor i8 %270, 1
  store i8 %271, i8* %21, align 1, !tbaa !2447
  %272 = xor i32 %261, %260
  %273 = lshr i32 %272, 4
  %274 = trunc i32 %273 to i8
  %275 = and i8 %274, 1
  store i8 %275, i8* %27, align 1, !tbaa !2451
  %276 = zext i1 %264 to i8
  store i8 %276, i8* %30, align 1, !tbaa !2448
  %277 = lshr i32 %261, 31
  %278 = trunc i32 %277 to i8
  store i8 %278, i8* %33, align 1, !tbaa !2449
  %279 = lshr i32 %260, 31
  %280 = xor i32 %277, %279
  %281 = add nuw nsw i32 %280, %277
  %282 = icmp eq i32 %281, 2
  %283 = zext i1 %282 to i8
  store i8 %283, i8* %39, align 1, !tbaa !2450
  %284 = sext i32 %261 to i64
  store i64 %284, i64* %RSI, align 8, !tbaa !2428
  %285 = shl nsw i64 %284, 3
  %286 = add i64 %256, %285
  %287 = add i64 %253, 18
  store i64 %287, i64* %PC, align 8
  %288 = inttoptr i64 %286 to i64*
  %289 = load i64, i64* %288, align 8
  %290 = load i64, i64* %RAX, align 8
  %291 = xor i64 %290, %289
  store i64 %291, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  %292 = trunc i64 %291 to i32
  %293 = and i32 %292, 255
  %294 = tail call i32 @llvm.ctpop.i32(i32 %293) #10
  %295 = trunc i32 %294 to i8
  %296 = and i8 %295, 1
  %297 = xor i8 %296, 1
  store i8 %297, i8* %21, align 1, !tbaa !2447
  %298 = icmp eq i64 %291, 0
  %299 = zext i1 %298 to i8
  store i8 %299, i8* %30, align 1, !tbaa !2448
  %300 = lshr i64 %291, 63
  %301 = trunc i64 %300 to i8
  store i8 %301, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2451
  store i64 %291, i64* %1702, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %302 = add i64 %253, 35
  store i64 %302, i64* %PC, align 8
  %303 = load i64, i64* %255, align 8
  store i64 %303, i64* %RDX, align 8, !tbaa !2428
  %304 = add i64 %251, -32
  %305 = add i64 %253, 38
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to i32*
  %307 = load i32, i32* %306, align 4
  %308 = add i32 %307, 1
  %309 = zext i32 %308 to i64
  store i64 %309, i64* %RCX, align 8, !tbaa !2428
  %310 = icmp eq i32 %307, -1
  %311 = icmp eq i32 %308, 0
  %312 = or i1 %310, %311
  %313 = zext i1 %312 to i8
  store i8 %313, i8* %14, align 1, !tbaa !2433
  %314 = and i32 %308, 255
  %315 = tail call i32 @llvm.ctpop.i32(i32 %314) #10
  %316 = trunc i32 %315 to i8
  %317 = and i8 %316, 1
  %318 = xor i8 %317, 1
  store i8 %318, i8* %21, align 1, !tbaa !2447
  %319 = xor i32 %308, %307
  %320 = lshr i32 %319, 4
  %321 = trunc i32 %320 to i8
  %322 = and i8 %321, 1
  store i8 %322, i8* %27, align 1, !tbaa !2451
  %323 = zext i1 %311 to i8
  store i8 %323, i8* %30, align 1, !tbaa !2448
  %324 = lshr i32 %308, 31
  %325 = trunc i32 %324 to i8
  store i8 %325, i8* %33, align 1, !tbaa !2449
  %326 = lshr i32 %307, 31
  %327 = xor i32 %324, %326
  %328 = add nuw nsw i32 %327, %324
  %329 = icmp eq i32 %328, 2
  %330 = zext i1 %329 to i8
  store i8 %330, i8* %39, align 1, !tbaa !2450
  %331 = sext i32 %308 to i64
  store i64 %331, i64* %RSI, align 8, !tbaa !2428
  %332 = shl nsw i64 %331, 3
  %333 = add i64 %303, %332
  %334 = add i64 %253, 49
  store i64 %334, i64* %PC, align 8
  %335 = bitcast i64 %291 to double
  %336 = inttoptr i64 %333 to double*
  %337 = load double, double* %336, align 8
  %338 = fadd double %335, %337
  store double %338, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %339 = load i64, i64* %RBP, align 8
  %340 = add i64 %339, -64
  %341 = add i64 %253, 54
  store i64 %341, i64* %PC, align 8
  %342 = inttoptr i64 %340 to double*
  store double %338, double* %342, align 8
  %343 = load i64, i64* %RBP, align 8
  %344 = add i64 %343, -16
  %345 = load i64, i64* %PC, align 8
  %346 = add i64 %345, 4
  store i64 %346, i64* %PC, align 8
  %347 = inttoptr i64 %344 to i64*
  %348 = load i64, i64* %347, align 8
  store i64 %348, i64* %RDX, align 8, !tbaa !2428
  %349 = add i64 %343, -32
  %350 = add i64 %345, 8
  store i64 %350, i64* %PC, align 8
  %351 = inttoptr i64 %349 to i32*
  %352 = load i32, i32* %351, align 4
  %353 = sext i32 %352 to i64
  store i64 %353, i64* %RSI, align 8, !tbaa !2428
  %354 = shl nsw i64 %353, 3
  %355 = add i64 %354, %348
  %356 = add i64 %345, 13
  store i64 %356, i64* %PC, align 8
  %357 = inttoptr i64 %355 to i64*
  %358 = load i64, i64* %357, align 8
  store i64 %358, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %359 = add i64 %345, 17
  store i64 %359, i64* %PC, align 8
  %360 = load i64, i64* %347, align 8
  store i64 %360, i64* %RDX, align 8, !tbaa !2428
  %361 = add i64 %343, -28
  %362 = add i64 %345, 21
  store i64 %362, i64* %PC, align 8
  %363 = inttoptr i64 %361 to i32*
  %364 = load i32, i32* %363, align 4
  %365 = sext i32 %364 to i64
  store i64 %365, i64* %RSI, align 8, !tbaa !2428
  %366 = shl nsw i64 %365, 3
  %367 = add i64 %366, %360
  %368 = add i64 %345, 26
  store i64 %368, i64* %PC, align 8
  %369 = bitcast i64 %358 to double
  %370 = inttoptr i64 %367 to double*
  %371 = load double, double* %370, align 8
  %372 = fadd double %369, %371
  store double %372, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %373 = add i64 %345, 31
  store i64 %373, i64* %PC, align 8
  %374 = inttoptr i64 %367 to double*
  store double %372, double* %374, align 8
  %375 = load i64, i64* %RBP, align 8
  %376 = add i64 %375, -16
  %377 = load i64, i64* %PC, align 8
  %378 = add i64 %377, 4
  store i64 %378, i64* %PC, align 8
  %379 = inttoptr i64 %376 to i64*
  %380 = load i64, i64* %379, align 8
  store i64 %380, i64* %RDX, align 8, !tbaa !2428
  %381 = add i64 %375, -28
  %382 = add i64 %377, 7
  store i64 %382, i64* %PC, align 8
  %383 = inttoptr i64 %381 to i32*
  %384 = load i32, i32* %383, align 4
  %385 = add i32 %384, 1
  %386 = zext i32 %385 to i64
  store i64 %386, i64* %RCX, align 8, !tbaa !2428
  %387 = icmp eq i32 %384, -1
  %388 = icmp eq i32 %385, 0
  %389 = or i1 %387, %388
  %390 = zext i1 %389 to i8
  store i8 %390, i8* %14, align 1, !tbaa !2433
  %391 = and i32 %385, 255
  %392 = tail call i32 @llvm.ctpop.i32(i32 %391) #10
  %393 = trunc i32 %392 to i8
  %394 = and i8 %393, 1
  %395 = xor i8 %394, 1
  store i8 %395, i8* %21, align 1, !tbaa !2447
  %396 = xor i32 %385, %384
  %397 = lshr i32 %396, 4
  %398 = trunc i32 %397 to i8
  %399 = and i8 %398, 1
  store i8 %399, i8* %27, align 1, !tbaa !2451
  %400 = zext i1 %388 to i8
  store i8 %400, i8* %30, align 1, !tbaa !2448
  %401 = lshr i32 %385, 31
  %402 = trunc i32 %401 to i8
  store i8 %402, i8* %33, align 1, !tbaa !2449
  %403 = lshr i32 %384, 31
  %404 = xor i32 %401, %403
  %405 = add nuw nsw i32 %404, %401
  %406 = icmp eq i32 %405, 2
  %407 = zext i1 %406 to i8
  store i8 %407, i8* %39, align 1, !tbaa !2450
  %408 = sext i32 %385 to i64
  store i64 %408, i64* %RSI, align 8, !tbaa !2428
  %409 = shl nsw i64 %408, 3
  %410 = add i64 %380, %409
  %411 = add i64 %377, 18
  store i64 %411, i64* %PC, align 8
  %412 = inttoptr i64 %410 to i64*
  %413 = load i64, i64* %412, align 8
  %414 = load i64, i64* %RAX, align 8
  %415 = xor i64 %414, %413
  store i64 %415, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  %416 = trunc i64 %415 to i32
  %417 = and i32 %416, 255
  %418 = tail call i32 @llvm.ctpop.i32(i32 %417) #10
  %419 = trunc i32 %418 to i8
  %420 = and i8 %419, 1
  %421 = xor i8 %420, 1
  store i8 %421, i8* %21, align 1, !tbaa !2447
  %422 = icmp eq i64 %415, 0
  %423 = zext i1 %422 to i8
  store i8 %423, i8* %30, align 1, !tbaa !2448
  %424 = lshr i64 %415, 63
  %425 = trunc i64 %424 to i8
  store i8 %425, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2451
  store i64 %415, i64* %1702, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %426 = add i64 %377, 35
  store i64 %426, i64* %PC, align 8
  %427 = load i64, i64* %379, align 8
  store i64 %427, i64* %RAX, align 8, !tbaa !2428
  %428 = add i64 %375, -32
  %429 = add i64 %377, 38
  store i64 %429, i64* %PC, align 8
  %430 = inttoptr i64 %428 to i32*
  %431 = load i32, i32* %430, align 4
  %432 = add i32 %431, 1
  %433 = zext i32 %432 to i64
  store i64 %433, i64* %RCX, align 8, !tbaa !2428
  %434 = icmp eq i32 %431, -1
  %435 = icmp eq i32 %432, 0
  %436 = or i1 %434, %435
  %437 = zext i1 %436 to i8
  store i8 %437, i8* %14, align 1, !tbaa !2433
  %438 = and i32 %432, 255
  %439 = tail call i32 @llvm.ctpop.i32(i32 %438) #10
  %440 = trunc i32 %439 to i8
  %441 = and i8 %440, 1
  %442 = xor i8 %441, 1
  store i8 %442, i8* %21, align 1, !tbaa !2447
  %443 = xor i32 %432, %431
  %444 = lshr i32 %443, 4
  %445 = trunc i32 %444 to i8
  %446 = and i8 %445, 1
  store i8 %446, i8* %27, align 1, !tbaa !2451
  %447 = zext i1 %435 to i8
  store i8 %447, i8* %30, align 1, !tbaa !2448
  %448 = lshr i32 %432, 31
  %449 = trunc i32 %448 to i8
  store i8 %449, i8* %33, align 1, !tbaa !2449
  %450 = lshr i32 %431, 31
  %451 = xor i32 %448, %450
  %452 = add nuw nsw i32 %451, %448
  %453 = icmp eq i32 %452, 2
  %454 = zext i1 %453 to i8
  store i8 %454, i8* %39, align 1, !tbaa !2450
  %455 = sext i32 %432 to i64
  store i64 %455, i64* %RDX, align 8, !tbaa !2428
  %456 = shl nsw i64 %455, 3
  %457 = add i64 %427, %456
  %458 = add i64 %377, 49
  store i64 %458, i64* %PC, align 8
  %459 = bitcast i64 %415 to double
  %460 = inttoptr i64 %457 to double*
  %461 = load double, double* %460, align 8
  %462 = fsub double %459, %461
  store double %462, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %463 = load i64, i64* %RBP, align 8
  %464 = add i64 %463, -16
  %465 = add i64 %377, 53
  store i64 %465, i64* %PC, align 8
  %466 = inttoptr i64 %464 to i64*
  %467 = load i64, i64* %466, align 8
  store i64 %467, i64* %RAX, align 8, !tbaa !2428
  %468 = add i64 %463, -28
  %469 = add i64 %377, 56
  store i64 %469, i64* %PC, align 8
  %470 = inttoptr i64 %468 to i32*
  %471 = load i32, i32* %470, align 4
  %472 = add i32 %471, 1
  %473 = zext i32 %472 to i64
  store i64 %473, i64* %RCX, align 8, !tbaa !2428
  %474 = icmp eq i32 %471, -1
  %475 = icmp eq i32 %472, 0
  %476 = or i1 %474, %475
  %477 = zext i1 %476 to i8
  store i8 %477, i8* %14, align 1, !tbaa !2433
  %478 = and i32 %472, 255
  %479 = tail call i32 @llvm.ctpop.i32(i32 %478) #10
  %480 = trunc i32 %479 to i8
  %481 = and i8 %480, 1
  %482 = xor i8 %481, 1
  store i8 %482, i8* %21, align 1, !tbaa !2447
  %483 = xor i32 %472, %471
  %484 = lshr i32 %483, 4
  %485 = trunc i32 %484 to i8
  %486 = and i8 %485, 1
  store i8 %486, i8* %27, align 1, !tbaa !2451
  %487 = zext i1 %475 to i8
  store i8 %487, i8* %30, align 1, !tbaa !2448
  %488 = lshr i32 %472, 31
  %489 = trunc i32 %488 to i8
  store i8 %489, i8* %33, align 1, !tbaa !2449
  %490 = lshr i32 %471, 31
  %491 = xor i32 %488, %490
  %492 = add nuw nsw i32 %491, %488
  %493 = icmp eq i32 %492, 2
  %494 = zext i1 %493 to i8
  store i8 %494, i8* %39, align 1, !tbaa !2450
  %495 = sext i32 %472 to i64
  store i64 %495, i64* %RDX, align 8, !tbaa !2428
  %496 = shl nsw i64 %495, 3
  %497 = add i64 %467, %496
  %498 = add i64 %377, 67
  store i64 %498, i64* %PC, align 8
  %499 = inttoptr i64 %497 to double*
  store double %462, double* %499, align 8
  %500 = load i64, i64* %RBP, align 8
  %501 = add i64 %500, -56
  %502 = load i64, i64* %PC, align 8
  %503 = add i64 %502, 5
  store i64 %503, i64* %PC, align 8
  %504 = inttoptr i64 %501 to i64*
  %505 = load i64, i64* %504, align 8
  store i64 %505, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %506 = add i64 %500, -16
  %507 = add i64 %502, 9
  store i64 %507, i64* %PC, align 8
  %508 = inttoptr i64 %506 to i64*
  %509 = load i64, i64* %508, align 8
  store i64 %509, i64* %RAX, align 8, !tbaa !2428
  %510 = add i64 %500, -32
  %511 = add i64 %502, 13
  store i64 %511, i64* %PC, align 8
  %512 = inttoptr i64 %510 to i32*
  %513 = load i32, i32* %512, align 4
  %514 = sext i32 %513 to i64
  store i64 %514, i64* %RDX, align 8, !tbaa !2428
  %515 = shl nsw i64 %514, 3
  %516 = add i64 %515, %509
  %517 = add i64 %502, 18
  store i64 %517, i64* %PC, align 8
  %518 = inttoptr i64 %516 to i64*
  store i64 %505, i64* %518, align 8
  %519 = load i64, i64* %RBP, align 8
  %520 = add i64 %519, -64
  %521 = load i64, i64* %PC, align 8
  %522 = add i64 %521, 5
  store i64 %522, i64* %PC, align 8
  %523 = inttoptr i64 %520 to i64*
  %524 = load i64, i64* %523, align 8
  store i64 %524, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %525 = add i64 %519, -16
  %526 = add i64 %521, 9
  store i64 %526, i64* %PC, align 8
  %527 = inttoptr i64 %525 to i64*
  %528 = load i64, i64* %527, align 8
  store i64 %528, i64* %RAX, align 8, !tbaa !2428
  %529 = add i64 %519, -32
  %530 = add i64 %521, 12
  store i64 %530, i64* %PC, align 8
  %531 = inttoptr i64 %529 to i32*
  %532 = load i32, i32* %531, align 4
  %533 = add i32 %532, 1
  %534 = zext i32 %533 to i64
  store i64 %534, i64* %RCX, align 8, !tbaa !2428
  %535 = icmp eq i32 %532, -1
  %536 = icmp eq i32 %533, 0
  %537 = or i1 %535, %536
  %538 = zext i1 %537 to i8
  store i8 %538, i8* %14, align 1, !tbaa !2433
  %539 = and i32 %533, 255
  %540 = tail call i32 @llvm.ctpop.i32(i32 %539) #10
  %541 = trunc i32 %540 to i8
  %542 = and i8 %541, 1
  %543 = xor i8 %542, 1
  store i8 %543, i8* %21, align 1, !tbaa !2447
  %544 = xor i32 %533, %532
  %545 = lshr i32 %544, 4
  %546 = trunc i32 %545 to i8
  %547 = and i8 %546, 1
  store i8 %547, i8* %27, align 1, !tbaa !2451
  %548 = zext i1 %536 to i8
  store i8 %548, i8* %30, align 1, !tbaa !2448
  %549 = lshr i32 %533, 31
  %550 = trunc i32 %549 to i8
  store i8 %550, i8* %33, align 1, !tbaa !2449
  %551 = lshr i32 %532, 31
  %552 = xor i32 %549, %551
  %553 = add nuw nsw i32 %552, %549
  %554 = icmp eq i32 %553, 2
  %555 = zext i1 %554 to i8
  store i8 %555, i8* %39, align 1, !tbaa !2450
  %556 = sext i32 %533 to i64
  store i64 %556, i64* %RDX, align 8, !tbaa !2428
  %557 = shl nsw i64 %556, 3
  %558 = add i64 %528, %557
  %559 = add i64 %521, 23
  store i64 %559, i64* %PC, align 8
  %560 = inttoptr i64 %558 to i64*
  store i64 %524, i64* %560, align 8
  %561 = load i64, i64* %RBP, align 8
  %562 = add i64 %561, -28
  %563 = load i64, i64* %PC, align 8
  %564 = add i64 %563, 3
  store i64 %564, i64* %PC, align 8
  %565 = inttoptr i64 %562 to i32*
  %566 = load i32, i32* %565, align 4
  %567 = add i32 %566, 2
  %568 = zext i32 %567 to i64
  store i64 %568, i64* %RAX, align 8, !tbaa !2428
  %569 = icmp ugt i32 %566, -3
  %570 = zext i1 %569 to i8
  store i8 %570, i8* %14, align 1, !tbaa !2433
  %571 = and i32 %567, 255
  %572 = tail call i32 @llvm.ctpop.i32(i32 %571) #10
  %573 = trunc i32 %572 to i8
  %574 = and i8 %573, 1
  %575 = xor i8 %574, 1
  store i8 %575, i8* %21, align 1, !tbaa !2447
  %576 = xor i32 %567, %566
  %577 = lshr i32 %576, 4
  %578 = trunc i32 %577 to i8
  %579 = and i8 %578, 1
  store i8 %579, i8* %27, align 1, !tbaa !2451
  %580 = icmp eq i32 %567, 0
  %581 = zext i1 %580 to i8
  store i8 %581, i8* %30, align 1, !tbaa !2448
  %582 = lshr i32 %567, 31
  %583 = trunc i32 %582 to i8
  store i8 %583, i8* %33, align 1, !tbaa !2449
  %584 = lshr i32 %566, 31
  %585 = xor i32 %582, %584
  %586 = add nuw nsw i32 %585, %582
  %587 = icmp eq i32 %586, 2
  %588 = zext i1 %587 to i8
  store i8 %588, i8* %39, align 1, !tbaa !2450
  %589 = add i64 %563, 9
  store i64 %589, i64* %PC, align 8
  store i32 %567, i32* %565, align 4
  %590 = load i64, i64* %PC, align 8
  %591 = add i64 %590, -264
  store i64 %591, i64* %PC, align 8, !tbaa !2428
  br label %block_402777

block_40276b:                                     ; preds = %block_402526
  %592 = add i64 %706, 286
  br label %block_402889

block_4024ea:                                     ; preds = %block_4024db
  %593 = add i64 %182, 3
  store i64 %593, i64* %PC, align 8
  %594 = load i32, i32* %153, align 4
  %595 = zext i32 %594 to i64
  store i64 %595, i64* %RDI, align 8, !tbaa !2428
  %596 = add i64 %182, 6
  store i64 %596, i64* %PC, align 8
  %597 = load i32, i32* %134, align 4
  %598 = zext i32 %597 to i64
  store i64 %598, i64* %RSI, align 8, !tbaa !2428
  %599 = add i64 %131, -16
  %600 = add i64 %182, 10
  store i64 %600, i64* %PC, align 8
  %601 = inttoptr i64 %599 to i64*
  %602 = load i64, i64* %601, align 8
  store i64 %602, i64* %RDX, align 8, !tbaa !2428
  %603 = add i64 %131, -24
  %604 = add i64 %182, 14
  store i64 %604, i64* %PC, align 8
  %605 = inttoptr i64 %603 to i64*
  %606 = load i64, i64* %605, align 8
  store i64 %606, i64* %RCX, align 8, !tbaa !2428
  %607 = add i64 %182, 3638
  %608 = add i64 %182, 19
  %609 = load i64, i64* %RSP, align 8, !tbaa !2428
  %610 = add i64 %609, -8
  %611 = inttoptr i64 %610 to i64*
  store i64 %608, i64* %611, align 8
  store i64 %610, i64* %RSP, align 8, !tbaa !2428
  store i64 %607, i64* %PC, align 8, !tbaa !2428
  %612 = tail call %struct.Memory* @sub_403320_cftmdl(%struct.State* nonnull %0, i64 %607, %struct.Memory* %723)
  %613 = load i64, i64* %RBP, align 8
  %614 = add i64 %613, -44
  %615 = load i64, i64* %PC, align 8
  %616 = add i64 %615, 3
  store i64 %616, i64* %PC, align 8
  %617 = inttoptr i64 %614 to i32*
  %618 = load i32, i32* %617, align 4
  %619 = shl i32 %618, 2
  %620 = zext i32 %619 to i64
  store i64 %620, i64* %RSI, align 8, !tbaa !2428
  %621 = lshr i32 %618, 30
  %622 = trunc i32 %621 to i8
  %623 = and i8 %622, 1
  store i8 %623, i8* %14, align 1, !tbaa !2432
  %624 = and i32 %619, 252
  %625 = tail call i32 @llvm.ctpop.i32(i32 %624) #10
  %626 = trunc i32 %625 to i8
  %627 = and i8 %626, 1
  %628 = xor i8 %627, 1
  store i8 %628, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %629 = icmp eq i32 %619, 0
  %630 = zext i1 %629 to i8
  store i8 %630, i8* %30, align 1, !tbaa !2432
  %631 = lshr i32 %618, 29
  %632 = trunc i32 %631 to i8
  %633 = and i8 %632, 1
  store i8 %633, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %634 = add i64 %615, 9
  store i64 %634, i64* %PC, align 8
  store i32 %619, i32* %617, align 4
  %635 = load i64, i64* %PC, align 8
  %636 = add i64 %635, -43
  store i64 %636, i64* %PC, align 8, !tbaa !2428
  br label %block_4024db

block_402889:                                     ; preds = %block_402884, %block_40276b
  %.sink = phi i64 [ %730, %block_402884 ], [ %592, %block_40276b ]
  %637 = load i64, i64* %RSP, align 8
  %638 = add i64 %637, 112
  store i64 %638, i64* %RSP, align 8, !tbaa !2428
  %639 = icmp ugt i64 %637, -113
  %640 = zext i1 %639 to i8
  store i8 %640, i8* %14, align 1, !tbaa !2433
  %641 = trunc i64 %638 to i32
  %642 = and i32 %641, 255
  %643 = tail call i32 @llvm.ctpop.i32(i32 %642) #10
  %644 = trunc i32 %643 to i8
  %645 = and i8 %644, 1
  %646 = xor i8 %645, 1
  store i8 %646, i8* %21, align 1, !tbaa !2447
  %647 = xor i64 %637, 16
  %648 = xor i64 %647, %638
  %649 = lshr i64 %648, 4
  %650 = trunc i64 %649 to i8
  %651 = and i8 %650, 1
  store i8 %651, i8* %27, align 1, !tbaa !2451
  %652 = icmp eq i64 %638, 0
  %653 = zext i1 %652 to i8
  store i8 %653, i8* %30, align 1, !tbaa !2448
  %654 = lshr i64 %638, 63
  %655 = trunc i64 %654 to i8
  store i8 %655, i8* %33, align 1, !tbaa !2449
  %656 = lshr i64 %637, 63
  %657 = xor i64 %654, %656
  %658 = add nuw nsw i64 %657, %654
  %659 = icmp eq i64 %658, 2
  %660 = zext i1 %659 to i8
  store i8 %660, i8* %39, align 1, !tbaa !2450
  %661 = add i64 %.sink, 5
  store i64 %661, i64* %PC, align 8
  %662 = add i64 %637, 120
  %663 = inttoptr i64 %638 to i64*
  %664 = load i64, i64* %663, align 8
  store i64 %664, i64* %RBP, align 8, !tbaa !2428
  store i64 %662, i64* %RSP, align 8, !tbaa !2428
  %665 = add i64 %.sink, 6
  store i64 %665, i64* %PC, align 8
  %666 = inttoptr i64 %662 to i64*
  %667 = load i64, i64* %666, align 8
  store i64 %667, i64* %PC, align 8, !tbaa !2428
  %668 = add i64 %637, 128
  store i64 %668, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.4

block_402526:                                     ; preds = %block_402526.preheader, %block_402532
  %669 = phi i64 [ %1646, %block_402532 ], [ %.pre12, %block_402526.preheader ]
  %670 = load i64, i64* %RBP, align 8
  %671 = add i64 %670, -28
  %672 = add i64 %669, 3
  store i64 %672, i64* %PC, align 8
  %673 = inttoptr i64 %671 to i32*
  %674 = load i32, i32* %673, align 4
  %675 = zext i32 %674 to i64
  store i64 %675, i64* %RAX, align 8, !tbaa !2428
  %676 = add i64 %670, -44
  %677 = add i64 %669, 6
  store i64 %677, i64* %PC, align 8
  %678 = inttoptr i64 %676 to i32*
  %679 = load i32, i32* %678, align 4
  %680 = sub i32 %674, %679
  %681 = icmp ult i32 %674, %679
  %682 = zext i1 %681 to i8
  store i8 %682, i8* %14, align 1, !tbaa !2433
  %683 = and i32 %680, 255
  %684 = tail call i32 @llvm.ctpop.i32(i32 %683) #10
  %685 = trunc i32 %684 to i8
  %686 = and i8 %685, 1
  %687 = xor i8 %686, 1
  store i8 %687, i8* %21, align 1, !tbaa !2447
  %688 = xor i32 %679, %674
  %689 = xor i32 %688, %680
  %690 = lshr i32 %689, 4
  %691 = trunc i32 %690 to i8
  %692 = and i8 %691, 1
  store i8 %692, i8* %27, align 1, !tbaa !2451
  %693 = icmp eq i32 %680, 0
  %694 = zext i1 %693 to i8
  store i8 %694, i8* %30, align 1, !tbaa !2448
  %695 = lshr i32 %680, 31
  %696 = trunc i32 %695 to i8
  store i8 %696, i8* %33, align 1, !tbaa !2449
  %697 = lshr i32 %674, 31
  %698 = lshr i32 %679, 31
  %699 = xor i32 %698, %697
  %700 = xor i32 %695, %697
  %701 = add nuw nsw i32 %700, %699
  %702 = icmp eq i32 %701, 2
  %703 = zext i1 %702 to i8
  store i8 %703, i8* %39, align 1, !tbaa !2450
  %704 = icmp ne i8 %696, 0
  %705 = xor i1 %704, %702
  %.v17 = select i1 %705, i64 12, i64 581
  %706 = add i64 %669, %.v17
  store i64 %706, i64* %PC, align 8, !tbaa !2428
  br i1 %705, label %block_402532, label %block_40276b

block_4024c4:                                     ; preds = %block_4024a0
  %707 = add i64 %91, 3
  store i64 %707, i64* %PC, align 8
  %708 = load i32, i32* %65, align 4
  %709 = zext i32 %708 to i64
  store i64 %709, i64* %RDI, align 8, !tbaa !2428
  %710 = add i64 %61, -16
  %711 = add i64 %91, 7
  store i64 %711, i64* %PC, align 8
  %712 = inttoptr i64 %710 to i64*
  %713 = load i64, i64* %712, align 8
  store i64 %713, i64* %RSI, align 8, !tbaa !2428
  %714 = add i64 %61, -24
  %715 = add i64 %91, 11
  store i64 %715, i64* %PC, align 8
  %716 = inttoptr i64 %714 to i64*
  %717 = load i64, i64* %716, align 8
  store i64 %717, i64* %RDX, align 8, !tbaa !2428
  %718 = add i64 %91, 972
  %719 = add i64 %91, 16
  %720 = load i64, i64* %RSP, align 8, !tbaa !2428
  %721 = add i64 %720, -8
  %722 = inttoptr i64 %721 to i64*
  store i64 %719, i64* %722, align 8
  store i64 %721, i64* %RSP, align 8, !tbaa !2428
  store i64 %718, i64* %PC, align 8, !tbaa !2428
  %723 = tail call %struct.Memory* @sub_402890_cft1st(%struct.State* nonnull %0, i64 %718, %struct.Memory* %2)
  %724 = load i64, i64* %RBP, align 8
  %725 = add i64 %724, -44
  %726 = load i64, i64* %PC, align 8
  %727 = add i64 %726, 7
  store i64 %727, i64* %PC, align 8
  %728 = inttoptr i64 %725 to i32*
  store i32 8, i32* %728, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_4024db

block_40250b:                                     ; preds = %block_4024db
  %729 = add i64 %182, 5
  store i64 %729, i64* %PC, align 8, !tbaa !2428
  br label %block_402510

block_402884:                                     ; preds = %block_402777
  %730 = add i64 %129, 5
  br label %block_402889

block_402532:                                     ; preds = %block_402526
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %731 = add i64 %706, 13
  store i64 %731, i64* %PC, align 8
  %732 = load i32, i32* %673, align 4
  %733 = zext i32 %732 to i64
  store i64 %733, i64* %RCX, align 8, !tbaa !2428
  %734 = add i64 %706, 16
  store i64 %734, i64* %PC, align 8
  %735 = load i32, i32* %678, align 4
  %736 = add i32 %735, %732
  %737 = zext i32 %736 to i64
  store i64 %737, i64* %RCX, align 8, !tbaa !2428
  %738 = icmp ult i32 %736, %732
  %739 = icmp ult i32 %736, %735
  %740 = or i1 %738, %739
  %741 = zext i1 %740 to i8
  store i8 %741, i8* %14, align 1, !tbaa !2433
  %742 = and i32 %736, 255
  %743 = tail call i32 @llvm.ctpop.i32(i32 %742) #10
  %744 = trunc i32 %743 to i8
  %745 = and i8 %744, 1
  %746 = xor i8 %745, 1
  store i8 %746, i8* %21, align 1, !tbaa !2447
  %747 = xor i32 %735, %732
  %748 = xor i32 %747, %736
  %749 = lshr i32 %748, 4
  %750 = trunc i32 %749 to i8
  %751 = and i8 %750, 1
  store i8 %751, i8* %27, align 1, !tbaa !2451
  %752 = icmp eq i32 %736, 0
  %753 = zext i1 %752 to i8
  store i8 %753, i8* %30, align 1, !tbaa !2448
  %754 = lshr i32 %736, 31
  %755 = trunc i32 %754 to i8
  store i8 %755, i8* %33, align 1, !tbaa !2449
  %756 = lshr i32 %732, 31
  %757 = lshr i32 %735, 31
  %758 = xor i32 %754, %756
  %759 = xor i32 %754, %757
  %760 = add nuw nsw i32 %758, %759
  %761 = icmp eq i32 %760, 2
  %762 = zext i1 %761 to i8
  store i8 %762, i8* %39, align 1, !tbaa !2450
  %763 = add i64 %670, -32
  %764 = add i64 %706, 19
  store i64 %764, i64* %PC, align 8
  %765 = inttoptr i64 %763 to i32*
  store i32 %736, i32* %765, align 4
  %766 = load i64, i64* %RBP, align 8
  %767 = add i64 %766, -32
  %768 = load i64, i64* %PC, align 8
  %769 = add i64 %768, 3
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %767 to i32*
  %771 = load i32, i32* %770, align 4
  %772 = zext i32 %771 to i64
  store i64 %772, i64* %RCX, align 8, !tbaa !2428
  %773 = add i64 %766, -44
  %774 = add i64 %768, 6
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to i32*
  %776 = load i32, i32* %775, align 4
  %777 = add i32 %776, %771
  %778 = zext i32 %777 to i64
  store i64 %778, i64* %RCX, align 8, !tbaa !2428
  %779 = icmp ult i32 %777, %771
  %780 = icmp ult i32 %777, %776
  %781 = or i1 %779, %780
  %782 = zext i1 %781 to i8
  store i8 %782, i8* %14, align 1, !tbaa !2433
  %783 = and i32 %777, 255
  %784 = tail call i32 @llvm.ctpop.i32(i32 %783) #10
  %785 = trunc i32 %784 to i8
  %786 = and i8 %785, 1
  %787 = xor i8 %786, 1
  store i8 %787, i8* %21, align 1, !tbaa !2447
  %788 = xor i32 %776, %771
  %789 = xor i32 %788, %777
  %790 = lshr i32 %789, 4
  %791 = trunc i32 %790 to i8
  %792 = and i8 %791, 1
  store i8 %792, i8* %27, align 1, !tbaa !2451
  %793 = icmp eq i32 %777, 0
  %794 = zext i1 %793 to i8
  store i8 %794, i8* %30, align 1, !tbaa !2448
  %795 = lshr i32 %777, 31
  %796 = trunc i32 %795 to i8
  store i8 %796, i8* %33, align 1, !tbaa !2449
  %797 = lshr i32 %771, 31
  %798 = lshr i32 %776, 31
  %799 = xor i32 %795, %797
  %800 = xor i32 %795, %798
  %801 = add nuw nsw i32 %799, %800
  %802 = icmp eq i32 %801, 2
  %803 = zext i1 %802 to i8
  store i8 %803, i8* %39, align 1, !tbaa !2450
  %804 = add i64 %766, -36
  %805 = add i64 %768, 9
  store i64 %805, i64* %PC, align 8
  %806 = inttoptr i64 %804 to i32*
  store i32 %777, i32* %806, align 4
  %807 = load i64, i64* %RBP, align 8
  %808 = add i64 %807, -36
  %809 = load i64, i64* %PC, align 8
  %810 = add i64 %809, 3
  store i64 %810, i64* %PC, align 8
  %811 = inttoptr i64 %808 to i32*
  %812 = load i32, i32* %811, align 4
  %813 = zext i32 %812 to i64
  store i64 %813, i64* %RCX, align 8, !tbaa !2428
  %814 = add i64 %807, -44
  %815 = add i64 %809, 6
  store i64 %815, i64* %PC, align 8
  %816 = inttoptr i64 %814 to i32*
  %817 = load i32, i32* %816, align 4
  %818 = add i32 %817, %812
  %819 = zext i32 %818 to i64
  store i64 %819, i64* %RCX, align 8, !tbaa !2428
  %820 = icmp ult i32 %818, %812
  %821 = icmp ult i32 %818, %817
  %822 = or i1 %820, %821
  %823 = zext i1 %822 to i8
  store i8 %823, i8* %14, align 1, !tbaa !2433
  %824 = and i32 %818, 255
  %825 = tail call i32 @llvm.ctpop.i32(i32 %824) #10
  %826 = trunc i32 %825 to i8
  %827 = and i8 %826, 1
  %828 = xor i8 %827, 1
  store i8 %828, i8* %21, align 1, !tbaa !2447
  %829 = xor i32 %817, %812
  %830 = xor i32 %829, %818
  %831 = lshr i32 %830, 4
  %832 = trunc i32 %831 to i8
  %833 = and i8 %832, 1
  store i8 %833, i8* %27, align 1, !tbaa !2451
  %834 = icmp eq i32 %818, 0
  %835 = zext i1 %834 to i8
  store i8 %835, i8* %30, align 1, !tbaa !2448
  %836 = lshr i32 %818, 31
  %837 = trunc i32 %836 to i8
  store i8 %837, i8* %33, align 1, !tbaa !2449
  %838 = lshr i32 %812, 31
  %839 = lshr i32 %817, 31
  %840 = xor i32 %836, %838
  %841 = xor i32 %836, %839
  %842 = add nuw nsw i32 %840, %841
  %843 = icmp eq i32 %842, 2
  %844 = zext i1 %843 to i8
  store i8 %844, i8* %39, align 1, !tbaa !2450
  %845 = add i64 %807, -40
  %846 = add i64 %809, 9
  store i64 %846, i64* %PC, align 8
  %847 = inttoptr i64 %845 to i32*
  store i32 %818, i32* %847, align 4
  %848 = load i64, i64* %RBP, align 8
  %849 = add i64 %848, -16
  %850 = load i64, i64* %PC, align 8
  %851 = add i64 %850, 4
  store i64 %851, i64* %PC, align 8
  %852 = inttoptr i64 %849 to i64*
  %853 = load i64, i64* %852, align 8
  store i64 %853, i64* %RDX, align 8, !tbaa !2428
  %854 = add i64 %848, -28
  %855 = add i64 %850, 8
  store i64 %855, i64* %PC, align 8
  %856 = inttoptr i64 %854 to i32*
  %857 = load i32, i32* %856, align 4
  %858 = sext i32 %857 to i64
  store i64 %858, i64* %RSI, align 8, !tbaa !2428
  %859 = shl nsw i64 %858, 3
  %860 = add i64 %859, %853
  %861 = add i64 %850, 13
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %860 to i64*
  %863 = load i64, i64* %862, align 8
  store i64 %863, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %864 = add i64 %850, 17
  store i64 %864, i64* %PC, align 8
  %865 = load i64, i64* %852, align 8
  store i64 %865, i64* %RDX, align 8, !tbaa !2428
  %866 = add i64 %848, -32
  %867 = add i64 %850, 21
  store i64 %867, i64* %PC, align 8
  %868 = inttoptr i64 %866 to i32*
  %869 = load i32, i32* %868, align 4
  %870 = sext i32 %869 to i64
  store i64 %870, i64* %RSI, align 8, !tbaa !2428
  %871 = shl nsw i64 %870, 3
  %872 = add i64 %871, %865
  %873 = add i64 %850, 26
  store i64 %873, i64* %PC, align 8
  %874 = bitcast i64 %863 to double
  %875 = inttoptr i64 %872 to double*
  %876 = load double, double* %875, align 8
  %877 = fadd double %874, %876
  store double %877, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %878 = add i64 %848, -56
  %879 = add i64 %850, 31
  store i64 %879, i64* %PC, align 8
  %880 = inttoptr i64 %878 to double*
  store double %877, double* %880, align 8
  %881 = load i64, i64* %RBP, align 8
  %882 = add i64 %881, -16
  %883 = load i64, i64* %PC, align 8
  %884 = add i64 %883, 4
  store i64 %884, i64* %PC, align 8
  %885 = inttoptr i64 %882 to i64*
  %886 = load i64, i64* %885, align 8
  store i64 %886, i64* %RDX, align 8, !tbaa !2428
  %887 = add i64 %881, -28
  %888 = add i64 %883, 7
  store i64 %888, i64* %PC, align 8
  %889 = inttoptr i64 %887 to i32*
  %890 = load i32, i32* %889, align 4
  %891 = add i32 %890, 1
  %892 = zext i32 %891 to i64
  store i64 %892, i64* %RCX, align 8, !tbaa !2428
  %893 = icmp eq i32 %890, -1
  %894 = icmp eq i32 %891, 0
  %895 = or i1 %893, %894
  %896 = zext i1 %895 to i8
  store i8 %896, i8* %14, align 1, !tbaa !2433
  %897 = and i32 %891, 255
  %898 = tail call i32 @llvm.ctpop.i32(i32 %897) #10
  %899 = trunc i32 %898 to i8
  %900 = and i8 %899, 1
  %901 = xor i8 %900, 1
  store i8 %901, i8* %21, align 1, !tbaa !2447
  %902 = xor i32 %891, %890
  %903 = lshr i32 %902, 4
  %904 = trunc i32 %903 to i8
  %905 = and i8 %904, 1
  store i8 %905, i8* %27, align 1, !tbaa !2451
  %906 = zext i1 %894 to i8
  store i8 %906, i8* %30, align 1, !tbaa !2448
  %907 = lshr i32 %891, 31
  %908 = trunc i32 %907 to i8
  store i8 %908, i8* %33, align 1, !tbaa !2449
  %909 = lshr i32 %890, 31
  %910 = xor i32 %907, %909
  %911 = add nuw nsw i32 %910, %907
  %912 = icmp eq i32 %911, 2
  %913 = zext i1 %912 to i8
  store i8 %913, i8* %39, align 1, !tbaa !2450
  %914 = sext i32 %891 to i64
  store i64 %914, i64* %RSI, align 8, !tbaa !2428
  %915 = shl nsw i64 %914, 3
  %916 = add i64 %886, %915
  %917 = add i64 %883, 18
  store i64 %917, i64* %PC, align 8
  %918 = inttoptr i64 %916 to i64*
  %919 = load i64, i64* %918, align 8
  %920 = load i64, i64* %RAX, align 8
  %921 = xor i64 %920, %919
  store i64 %921, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  %922 = trunc i64 %921 to i32
  %923 = and i32 %922, 255
  %924 = tail call i32 @llvm.ctpop.i32(i32 %923) #10
  %925 = trunc i32 %924 to i8
  %926 = and i8 %925, 1
  %927 = xor i8 %926, 1
  store i8 %927, i8* %21, align 1, !tbaa !2447
  %928 = icmp eq i64 %921, 0
  %929 = zext i1 %928 to i8
  store i8 %929, i8* %30, align 1, !tbaa !2448
  %930 = lshr i64 %921, 63
  %931 = trunc i64 %930 to i8
  store i8 %931, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2451
  store i64 %921, i64* %1702, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %932 = add i64 %883, 35
  store i64 %932, i64* %PC, align 8
  %933 = load i64, i64* %885, align 8
  store i64 %933, i64* %RDX, align 8, !tbaa !2428
  %934 = add i64 %881, -32
  %935 = add i64 %883, 38
  store i64 %935, i64* %PC, align 8
  %936 = inttoptr i64 %934 to i32*
  %937 = load i32, i32* %936, align 4
  %938 = add i32 %937, 1
  %939 = zext i32 %938 to i64
  store i64 %939, i64* %RCX, align 8, !tbaa !2428
  %940 = icmp eq i32 %937, -1
  %941 = icmp eq i32 %938, 0
  %942 = or i1 %940, %941
  %943 = zext i1 %942 to i8
  store i8 %943, i8* %14, align 1, !tbaa !2433
  %944 = and i32 %938, 255
  %945 = tail call i32 @llvm.ctpop.i32(i32 %944) #10
  %946 = trunc i32 %945 to i8
  %947 = and i8 %946, 1
  %948 = xor i8 %947, 1
  store i8 %948, i8* %21, align 1, !tbaa !2447
  %949 = xor i32 %938, %937
  %950 = lshr i32 %949, 4
  %951 = trunc i32 %950 to i8
  %952 = and i8 %951, 1
  store i8 %952, i8* %27, align 1, !tbaa !2451
  %953 = zext i1 %941 to i8
  store i8 %953, i8* %30, align 1, !tbaa !2448
  %954 = lshr i32 %938, 31
  %955 = trunc i32 %954 to i8
  store i8 %955, i8* %33, align 1, !tbaa !2449
  %956 = lshr i32 %937, 31
  %957 = xor i32 %954, %956
  %958 = add nuw nsw i32 %957, %954
  %959 = icmp eq i32 %958, 2
  %960 = zext i1 %959 to i8
  store i8 %960, i8* %39, align 1, !tbaa !2450
  %961 = sext i32 %938 to i64
  store i64 %961, i64* %RSI, align 8, !tbaa !2428
  %962 = shl nsw i64 %961, 3
  %963 = add i64 %933, %962
  %964 = add i64 %883, 49
  store i64 %964, i64* %PC, align 8
  %965 = bitcast i64 %921 to double
  %966 = inttoptr i64 %963 to double*
  %967 = load double, double* %966, align 8
  %968 = fsub double %965, %967
  store double %968, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %969 = load i64, i64* %RBP, align 8
  %970 = add i64 %969, -64
  %971 = add i64 %883, 54
  store i64 %971, i64* %PC, align 8
  %972 = inttoptr i64 %970 to double*
  store double %968, double* %972, align 8
  %973 = load i64, i64* %RBP, align 8
  %974 = add i64 %973, -16
  %975 = load i64, i64* %PC, align 8
  %976 = add i64 %975, 4
  store i64 %976, i64* %PC, align 8
  %977 = inttoptr i64 %974 to i64*
  %978 = load i64, i64* %977, align 8
  store i64 %978, i64* %RDX, align 8, !tbaa !2428
  %979 = add i64 %973, -28
  %980 = add i64 %975, 8
  store i64 %980, i64* %PC, align 8
  %981 = inttoptr i64 %979 to i32*
  %982 = load i32, i32* %981, align 4
  %983 = sext i32 %982 to i64
  store i64 %983, i64* %RSI, align 8, !tbaa !2428
  %984 = shl nsw i64 %983, 3
  %985 = add i64 %984, %978
  %986 = add i64 %975, 13
  store i64 %986, i64* %PC, align 8
  %987 = inttoptr i64 %985 to i64*
  %988 = load i64, i64* %987, align 8
  store i64 %988, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %989 = add i64 %975, 17
  store i64 %989, i64* %PC, align 8
  %990 = load i64, i64* %977, align 8
  store i64 %990, i64* %RDX, align 8, !tbaa !2428
  %991 = add i64 %973, -32
  %992 = add i64 %975, 21
  store i64 %992, i64* %PC, align 8
  %993 = inttoptr i64 %991 to i32*
  %994 = load i32, i32* %993, align 4
  %995 = sext i32 %994 to i64
  store i64 %995, i64* %RSI, align 8, !tbaa !2428
  %996 = shl nsw i64 %995, 3
  %997 = add i64 %996, %990
  %998 = add i64 %975, 26
  store i64 %998, i64* %PC, align 8
  %999 = bitcast i64 %988 to double
  %1000 = inttoptr i64 %997 to double*
  %1001 = load double, double* %1000, align 8
  %1002 = fsub double %999, %1001
  store double %1002, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1003 = add i64 %973, -72
  %1004 = add i64 %975, 31
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to double*
  store double %1002, double* %1005, align 8
  %1006 = load i64, i64* %RBP, align 8
  %1007 = add i64 %1006, -16
  %1008 = load i64, i64* %PC, align 8
  %1009 = add i64 %1008, 4
  store i64 %1009, i64* %PC, align 8
  %1010 = inttoptr i64 %1007 to i64*
  %1011 = load i64, i64* %1010, align 8
  store i64 %1011, i64* %RDX, align 8, !tbaa !2428
  %1012 = add i64 %1006, -28
  %1013 = add i64 %1008, 7
  store i64 %1013, i64* %PC, align 8
  %1014 = inttoptr i64 %1012 to i32*
  %1015 = load i32, i32* %1014, align 4
  %1016 = add i32 %1015, 1
  %1017 = zext i32 %1016 to i64
  store i64 %1017, i64* %RCX, align 8, !tbaa !2428
  %1018 = icmp eq i32 %1015, -1
  %1019 = icmp eq i32 %1016, 0
  %1020 = or i1 %1018, %1019
  %1021 = zext i1 %1020 to i8
  store i8 %1021, i8* %14, align 1, !tbaa !2433
  %1022 = and i32 %1016, 255
  %1023 = tail call i32 @llvm.ctpop.i32(i32 %1022) #10
  %1024 = trunc i32 %1023 to i8
  %1025 = and i8 %1024, 1
  %1026 = xor i8 %1025, 1
  store i8 %1026, i8* %21, align 1, !tbaa !2447
  %1027 = xor i32 %1016, %1015
  %1028 = lshr i32 %1027, 4
  %1029 = trunc i32 %1028 to i8
  %1030 = and i8 %1029, 1
  store i8 %1030, i8* %27, align 1, !tbaa !2451
  %1031 = zext i1 %1019 to i8
  store i8 %1031, i8* %30, align 1, !tbaa !2448
  %1032 = lshr i32 %1016, 31
  %1033 = trunc i32 %1032 to i8
  store i8 %1033, i8* %33, align 1, !tbaa !2449
  %1034 = lshr i32 %1015, 31
  %1035 = xor i32 %1032, %1034
  %1036 = add nuw nsw i32 %1035, %1032
  %1037 = icmp eq i32 %1036, 2
  %1038 = zext i1 %1037 to i8
  store i8 %1038, i8* %39, align 1, !tbaa !2450
  %1039 = sext i32 %1016 to i64
  store i64 %1039, i64* %RSI, align 8, !tbaa !2428
  %1040 = shl nsw i64 %1039, 3
  %1041 = add i64 %1011, %1040
  %1042 = add i64 %1008, 18
  store i64 %1042, i64* %PC, align 8
  %1043 = inttoptr i64 %1041 to i64*
  %1044 = load i64, i64* %1043, align 8
  %1045 = load i64, i64* %RAX, align 8
  %1046 = xor i64 %1045, %1044
  store i64 %1046, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  %1047 = trunc i64 %1046 to i32
  %1048 = and i32 %1047, 255
  %1049 = tail call i32 @llvm.ctpop.i32(i32 %1048) #10
  %1050 = trunc i32 %1049 to i8
  %1051 = and i8 %1050, 1
  %1052 = xor i8 %1051, 1
  store i8 %1052, i8* %21, align 1, !tbaa !2447
  %1053 = icmp eq i64 %1046, 0
  %1054 = zext i1 %1053 to i8
  store i8 %1054, i8* %30, align 1, !tbaa !2448
  %1055 = lshr i64 %1046, 63
  %1056 = trunc i64 %1055 to i8
  store i8 %1056, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2451
  store i64 %1046, i64* %1702, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %1057 = add i64 %1008, 35
  store i64 %1057, i64* %PC, align 8
  %1058 = load i64, i64* %1010, align 8
  store i64 %1058, i64* %RAX, align 8, !tbaa !2428
  %1059 = add i64 %1006, -32
  %1060 = add i64 %1008, 38
  store i64 %1060, i64* %PC, align 8
  %1061 = inttoptr i64 %1059 to i32*
  %1062 = load i32, i32* %1061, align 4
  %1063 = add i32 %1062, 1
  %1064 = zext i32 %1063 to i64
  store i64 %1064, i64* %RCX, align 8, !tbaa !2428
  %1065 = icmp eq i32 %1062, -1
  %1066 = icmp eq i32 %1063, 0
  %1067 = or i1 %1065, %1066
  %1068 = zext i1 %1067 to i8
  store i8 %1068, i8* %14, align 1, !tbaa !2433
  %1069 = and i32 %1063, 255
  %1070 = tail call i32 @llvm.ctpop.i32(i32 %1069) #10
  %1071 = trunc i32 %1070 to i8
  %1072 = and i8 %1071, 1
  %1073 = xor i8 %1072, 1
  store i8 %1073, i8* %21, align 1, !tbaa !2447
  %1074 = xor i32 %1063, %1062
  %1075 = lshr i32 %1074, 4
  %1076 = trunc i32 %1075 to i8
  %1077 = and i8 %1076, 1
  store i8 %1077, i8* %27, align 1, !tbaa !2451
  %1078 = zext i1 %1066 to i8
  store i8 %1078, i8* %30, align 1, !tbaa !2448
  %1079 = lshr i32 %1063, 31
  %1080 = trunc i32 %1079 to i8
  store i8 %1080, i8* %33, align 1, !tbaa !2449
  %1081 = lshr i32 %1062, 31
  %1082 = xor i32 %1079, %1081
  %1083 = add nuw nsw i32 %1082, %1079
  %1084 = icmp eq i32 %1083, 2
  %1085 = zext i1 %1084 to i8
  store i8 %1085, i8* %39, align 1, !tbaa !2450
  %1086 = sext i32 %1063 to i64
  store i64 %1086, i64* %RDX, align 8, !tbaa !2428
  %1087 = shl nsw i64 %1086, 3
  %1088 = add i64 %1058, %1087
  %1089 = add i64 %1008, 49
  store i64 %1089, i64* %PC, align 8
  %1090 = bitcast i64 %1046 to double
  %1091 = inttoptr i64 %1088 to double*
  %1092 = load double, double* %1091, align 8
  %1093 = fadd double %1090, %1092
  store double %1093, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1094 = load i64, i64* %RBP, align 8
  %1095 = add i64 %1094, -80
  %1096 = add i64 %1008, 54
  store i64 %1096, i64* %PC, align 8
  %1097 = inttoptr i64 %1095 to double*
  store double %1093, double* %1097, align 8
  %1098 = load i64, i64* %RBP, align 8
  %1099 = add i64 %1098, -16
  %1100 = load i64, i64* %PC, align 8
  %1101 = add i64 %1100, 4
  store i64 %1101, i64* %PC, align 8
  %1102 = inttoptr i64 %1099 to i64*
  %1103 = load i64, i64* %1102, align 8
  store i64 %1103, i64* %RAX, align 8, !tbaa !2428
  %1104 = add i64 %1098, -36
  %1105 = add i64 %1100, 8
  store i64 %1105, i64* %PC, align 8
  %1106 = inttoptr i64 %1104 to i32*
  %1107 = load i32, i32* %1106, align 4
  %1108 = sext i32 %1107 to i64
  store i64 %1108, i64* %RDX, align 8, !tbaa !2428
  %1109 = shl nsw i64 %1108, 3
  %1110 = add i64 %1109, %1103
  %1111 = add i64 %1100, 13
  store i64 %1111, i64* %PC, align 8
  %1112 = inttoptr i64 %1110 to i64*
  %1113 = load i64, i64* %1112, align 8
  store i64 %1113, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1114 = add i64 %1100, 17
  store i64 %1114, i64* %PC, align 8
  %1115 = load i64, i64* %1102, align 8
  store i64 %1115, i64* %RAX, align 8, !tbaa !2428
  %1116 = add i64 %1098, -40
  %1117 = add i64 %1100, 21
  store i64 %1117, i64* %PC, align 8
  %1118 = inttoptr i64 %1116 to i32*
  %1119 = load i32, i32* %1118, align 4
  %1120 = sext i32 %1119 to i64
  store i64 %1120, i64* %RDX, align 8, !tbaa !2428
  %1121 = shl nsw i64 %1120, 3
  %1122 = add i64 %1121, %1115
  %1123 = add i64 %1100, 26
  store i64 %1123, i64* %PC, align 8
  %1124 = bitcast i64 %1113 to double
  %1125 = inttoptr i64 %1122 to double*
  %1126 = load double, double* %1125, align 8
  %1127 = fadd double %1124, %1126
  store double %1127, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1128 = add i64 %1098, -88
  %1129 = add i64 %1100, 31
  store i64 %1129, i64* %PC, align 8
  %1130 = inttoptr i64 %1128 to double*
  store double %1127, double* %1130, align 8
  %1131 = load i64, i64* %RBP, align 8
  %1132 = add i64 %1131, -16
  %1133 = load i64, i64* %PC, align 8
  %1134 = add i64 %1133, 4
  store i64 %1134, i64* %PC, align 8
  %1135 = inttoptr i64 %1132 to i64*
  %1136 = load i64, i64* %1135, align 8
  store i64 %1136, i64* %RAX, align 8, !tbaa !2428
  %1137 = add i64 %1131, -36
  %1138 = add i64 %1133, 7
  store i64 %1138, i64* %PC, align 8
  %1139 = inttoptr i64 %1137 to i32*
  %1140 = load i32, i32* %1139, align 4
  %1141 = add i32 %1140, 1
  %1142 = zext i32 %1141 to i64
  store i64 %1142, i64* %RCX, align 8, !tbaa !2428
  %1143 = icmp eq i32 %1140, -1
  %1144 = icmp eq i32 %1141, 0
  %1145 = or i1 %1143, %1144
  %1146 = zext i1 %1145 to i8
  store i8 %1146, i8* %14, align 1, !tbaa !2433
  %1147 = and i32 %1141, 255
  %1148 = tail call i32 @llvm.ctpop.i32(i32 %1147) #10
  %1149 = trunc i32 %1148 to i8
  %1150 = and i8 %1149, 1
  %1151 = xor i8 %1150, 1
  store i8 %1151, i8* %21, align 1, !tbaa !2447
  %1152 = xor i32 %1141, %1140
  %1153 = lshr i32 %1152, 4
  %1154 = trunc i32 %1153 to i8
  %1155 = and i8 %1154, 1
  store i8 %1155, i8* %27, align 1, !tbaa !2451
  %1156 = zext i1 %1144 to i8
  store i8 %1156, i8* %30, align 1, !tbaa !2448
  %1157 = lshr i32 %1141, 31
  %1158 = trunc i32 %1157 to i8
  store i8 %1158, i8* %33, align 1, !tbaa !2449
  %1159 = lshr i32 %1140, 31
  %1160 = xor i32 %1157, %1159
  %1161 = add nuw nsw i32 %1160, %1157
  %1162 = icmp eq i32 %1161, 2
  %1163 = zext i1 %1162 to i8
  store i8 %1163, i8* %39, align 1, !tbaa !2450
  %1164 = sext i32 %1141 to i64
  store i64 %1164, i64* %RDX, align 8, !tbaa !2428
  %1165 = shl nsw i64 %1164, 3
  %1166 = add i64 %1136, %1165
  %1167 = add i64 %1133, 18
  store i64 %1167, i64* %PC, align 8
  %1168 = inttoptr i64 %1166 to i64*
  %1169 = load i64, i64* %1168, align 8
  store i64 %1169, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1170 = add i64 %1133, 22
  store i64 %1170, i64* %PC, align 8
  %1171 = load i64, i64* %1135, align 8
  store i64 %1171, i64* %RAX, align 8, !tbaa !2428
  %1172 = add i64 %1131, -40
  %1173 = add i64 %1133, 25
  store i64 %1173, i64* %PC, align 8
  %1174 = inttoptr i64 %1172 to i32*
  %1175 = load i32, i32* %1174, align 4
  %1176 = add i32 %1175, 1
  %1177 = zext i32 %1176 to i64
  store i64 %1177, i64* %RCX, align 8, !tbaa !2428
  %1178 = icmp eq i32 %1175, -1
  %1179 = icmp eq i32 %1176, 0
  %1180 = or i1 %1178, %1179
  %1181 = zext i1 %1180 to i8
  store i8 %1181, i8* %14, align 1, !tbaa !2433
  %1182 = and i32 %1176, 255
  %1183 = tail call i32 @llvm.ctpop.i32(i32 %1182) #10
  %1184 = trunc i32 %1183 to i8
  %1185 = and i8 %1184, 1
  %1186 = xor i8 %1185, 1
  store i8 %1186, i8* %21, align 1, !tbaa !2447
  %1187 = xor i32 %1176, %1175
  %1188 = lshr i32 %1187, 4
  %1189 = trunc i32 %1188 to i8
  %1190 = and i8 %1189, 1
  store i8 %1190, i8* %27, align 1, !tbaa !2451
  %1191 = zext i1 %1179 to i8
  store i8 %1191, i8* %30, align 1, !tbaa !2448
  %1192 = lshr i32 %1176, 31
  %1193 = trunc i32 %1192 to i8
  store i8 %1193, i8* %33, align 1, !tbaa !2449
  %1194 = lshr i32 %1175, 31
  %1195 = xor i32 %1192, %1194
  %1196 = add nuw nsw i32 %1195, %1192
  %1197 = icmp eq i32 %1196, 2
  %1198 = zext i1 %1197 to i8
  store i8 %1198, i8* %39, align 1, !tbaa !2450
  %1199 = sext i32 %1176 to i64
  store i64 %1199, i64* %RDX, align 8, !tbaa !2428
  %1200 = shl nsw i64 %1199, 3
  %1201 = add i64 %1171, %1200
  %1202 = add i64 %1133, 36
  store i64 %1202, i64* %PC, align 8
  %1203 = bitcast i64 %1169 to double
  %1204 = inttoptr i64 %1201 to double*
  %1205 = load double, double* %1204, align 8
  %1206 = fadd double %1203, %1205
  store double %1206, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1207 = load i64, i64* %RBP, align 8
  %1208 = add i64 %1207, -96
  %1209 = add i64 %1133, 41
  store i64 %1209, i64* %PC, align 8
  %1210 = inttoptr i64 %1208 to double*
  store double %1206, double* %1210, align 8
  %1211 = load i64, i64* %RBP, align 8
  %1212 = add i64 %1211, -16
  %1213 = load i64, i64* %PC, align 8
  %1214 = add i64 %1213, 4
  store i64 %1214, i64* %PC, align 8
  %1215 = inttoptr i64 %1212 to i64*
  %1216 = load i64, i64* %1215, align 8
  store i64 %1216, i64* %RAX, align 8, !tbaa !2428
  %1217 = add i64 %1211, -36
  %1218 = add i64 %1213, 8
  store i64 %1218, i64* %PC, align 8
  %1219 = inttoptr i64 %1217 to i32*
  %1220 = load i32, i32* %1219, align 4
  %1221 = sext i32 %1220 to i64
  store i64 %1221, i64* %RDX, align 8, !tbaa !2428
  %1222 = shl nsw i64 %1221, 3
  %1223 = add i64 %1222, %1216
  %1224 = add i64 %1213, 13
  store i64 %1224, i64* %PC, align 8
  %1225 = inttoptr i64 %1223 to i64*
  %1226 = load i64, i64* %1225, align 8
  store i64 %1226, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1227 = add i64 %1213, 17
  store i64 %1227, i64* %PC, align 8
  %1228 = load i64, i64* %1215, align 8
  store i64 %1228, i64* %RAX, align 8, !tbaa !2428
  %1229 = add i64 %1211, -40
  %1230 = add i64 %1213, 21
  store i64 %1230, i64* %PC, align 8
  %1231 = inttoptr i64 %1229 to i32*
  %1232 = load i32, i32* %1231, align 4
  %1233 = sext i32 %1232 to i64
  store i64 %1233, i64* %RDX, align 8, !tbaa !2428
  %1234 = shl nsw i64 %1233, 3
  %1235 = add i64 %1234, %1228
  %1236 = add i64 %1213, 26
  store i64 %1236, i64* %PC, align 8
  %1237 = bitcast i64 %1226 to double
  %1238 = inttoptr i64 %1235 to double*
  %1239 = load double, double* %1238, align 8
  %1240 = fsub double %1237, %1239
  store double %1240, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1241 = add i64 %1211, -104
  %1242 = add i64 %1213, 31
  store i64 %1242, i64* %PC, align 8
  %1243 = inttoptr i64 %1241 to double*
  store double %1240, double* %1243, align 8
  %1244 = load i64, i64* %RBP, align 8
  %1245 = add i64 %1244, -16
  %1246 = load i64, i64* %PC, align 8
  %1247 = add i64 %1246, 4
  store i64 %1247, i64* %PC, align 8
  %1248 = inttoptr i64 %1245 to i64*
  %1249 = load i64, i64* %1248, align 8
  store i64 %1249, i64* %RAX, align 8, !tbaa !2428
  %1250 = add i64 %1244, -36
  %1251 = add i64 %1246, 7
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i32*
  %1253 = load i32, i32* %1252, align 4
  %1254 = add i32 %1253, 1
  %1255 = zext i32 %1254 to i64
  store i64 %1255, i64* %RCX, align 8, !tbaa !2428
  %1256 = icmp eq i32 %1253, -1
  %1257 = icmp eq i32 %1254, 0
  %1258 = or i1 %1256, %1257
  %1259 = zext i1 %1258 to i8
  store i8 %1259, i8* %14, align 1, !tbaa !2433
  %1260 = and i32 %1254, 255
  %1261 = tail call i32 @llvm.ctpop.i32(i32 %1260) #10
  %1262 = trunc i32 %1261 to i8
  %1263 = and i8 %1262, 1
  %1264 = xor i8 %1263, 1
  store i8 %1264, i8* %21, align 1, !tbaa !2447
  %1265 = xor i32 %1254, %1253
  %1266 = lshr i32 %1265, 4
  %1267 = trunc i32 %1266 to i8
  %1268 = and i8 %1267, 1
  store i8 %1268, i8* %27, align 1, !tbaa !2451
  %1269 = zext i1 %1257 to i8
  store i8 %1269, i8* %30, align 1, !tbaa !2448
  %1270 = lshr i32 %1254, 31
  %1271 = trunc i32 %1270 to i8
  store i8 %1271, i8* %33, align 1, !tbaa !2449
  %1272 = lshr i32 %1253, 31
  %1273 = xor i32 %1270, %1272
  %1274 = add nuw nsw i32 %1273, %1270
  %1275 = icmp eq i32 %1274, 2
  %1276 = zext i1 %1275 to i8
  store i8 %1276, i8* %39, align 1, !tbaa !2450
  %1277 = sext i32 %1254 to i64
  store i64 %1277, i64* %RDX, align 8, !tbaa !2428
  %1278 = shl nsw i64 %1277, 3
  %1279 = add i64 %1249, %1278
  %1280 = add i64 %1246, 18
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to i64*
  %1282 = load i64, i64* %1281, align 8
  store i64 %1282, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1283 = add i64 %1246, 22
  store i64 %1283, i64* %PC, align 8
  %1284 = load i64, i64* %1248, align 8
  store i64 %1284, i64* %RAX, align 8, !tbaa !2428
  %1285 = add i64 %1244, -40
  %1286 = add i64 %1246, 25
  store i64 %1286, i64* %PC, align 8
  %1287 = inttoptr i64 %1285 to i32*
  %1288 = load i32, i32* %1287, align 4
  %1289 = add i32 %1288, 1
  %1290 = zext i32 %1289 to i64
  store i64 %1290, i64* %RCX, align 8, !tbaa !2428
  %1291 = icmp eq i32 %1288, -1
  %1292 = icmp eq i32 %1289, 0
  %1293 = or i1 %1291, %1292
  %1294 = zext i1 %1293 to i8
  store i8 %1294, i8* %14, align 1, !tbaa !2433
  %1295 = and i32 %1289, 255
  %1296 = tail call i32 @llvm.ctpop.i32(i32 %1295) #10
  %1297 = trunc i32 %1296 to i8
  %1298 = and i8 %1297, 1
  %1299 = xor i8 %1298, 1
  store i8 %1299, i8* %21, align 1, !tbaa !2447
  %1300 = xor i32 %1289, %1288
  %1301 = lshr i32 %1300, 4
  %1302 = trunc i32 %1301 to i8
  %1303 = and i8 %1302, 1
  store i8 %1303, i8* %27, align 1, !tbaa !2451
  %1304 = zext i1 %1292 to i8
  store i8 %1304, i8* %30, align 1, !tbaa !2448
  %1305 = lshr i32 %1289, 31
  %1306 = trunc i32 %1305 to i8
  store i8 %1306, i8* %33, align 1, !tbaa !2449
  %1307 = lshr i32 %1288, 31
  %1308 = xor i32 %1305, %1307
  %1309 = add nuw nsw i32 %1308, %1305
  %1310 = icmp eq i32 %1309, 2
  %1311 = zext i1 %1310 to i8
  store i8 %1311, i8* %39, align 1, !tbaa !2450
  %1312 = sext i32 %1289 to i64
  store i64 %1312, i64* %RDX, align 8, !tbaa !2428
  %1313 = shl nsw i64 %1312, 3
  %1314 = add i64 %1284, %1313
  %1315 = add i64 %1246, 36
  store i64 %1315, i64* %PC, align 8
  %1316 = bitcast i64 %1282 to double
  %1317 = inttoptr i64 %1314 to double*
  %1318 = load double, double* %1317, align 8
  %1319 = fsub double %1316, %1318
  store double %1319, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1320 = load i64, i64* %RBP, align 8
  %1321 = add i64 %1320, -112
  %1322 = add i64 %1246, 41
  store i64 %1322, i64* %PC, align 8
  %1323 = inttoptr i64 %1321 to double*
  store double %1319, double* %1323, align 8
  %1324 = load i64, i64* %RBP, align 8
  %1325 = add i64 %1324, -56
  %1326 = load i64, i64* %PC, align 8
  %1327 = add i64 %1326, 5
  store i64 %1327, i64* %PC, align 8
  %1328 = inttoptr i64 %1325 to i64*
  %1329 = load i64, i64* %1328, align 8
  store i64 %1329, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1330 = add i64 %1324, -88
  %1331 = add i64 %1326, 10
  store i64 %1331, i64* %PC, align 8
  %1332 = bitcast i64 %1329 to double
  %1333 = inttoptr i64 %1330 to double*
  %1334 = load double, double* %1333, align 8
  %1335 = fadd double %1332, %1334
  store double %1335, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1336 = add i64 %1324, -16
  %1337 = add i64 %1326, 14
  store i64 %1337, i64* %PC, align 8
  %1338 = inttoptr i64 %1336 to i64*
  %1339 = load i64, i64* %1338, align 8
  store i64 %1339, i64* %RAX, align 8, !tbaa !2428
  %1340 = add i64 %1324, -28
  %1341 = add i64 %1326, 18
  store i64 %1341, i64* %PC, align 8
  %1342 = inttoptr i64 %1340 to i32*
  %1343 = load i32, i32* %1342, align 4
  %1344 = sext i32 %1343 to i64
  store i64 %1344, i64* %RDX, align 8, !tbaa !2428
  %1345 = shl nsw i64 %1344, 3
  %1346 = add i64 %1345, %1339
  %1347 = add i64 %1326, 23
  store i64 %1347, i64* %PC, align 8
  %1348 = inttoptr i64 %1346 to double*
  store double %1335, double* %1348, align 8
  %1349 = load i64, i64* %RBP, align 8
  %1350 = add i64 %1349, -64
  %1351 = load i64, i64* %PC, align 8
  %1352 = add i64 %1351, 5
  store i64 %1352, i64* %PC, align 8
  %1353 = inttoptr i64 %1350 to i64*
  %1354 = load i64, i64* %1353, align 8
  store i64 %1354, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1355 = add i64 %1349, -96
  %1356 = add i64 %1351, 10
  store i64 %1356, i64* %PC, align 8
  %1357 = bitcast i64 %1354 to double
  %1358 = inttoptr i64 %1355 to double*
  %1359 = load double, double* %1358, align 8
  %1360 = fsub double %1357, %1359
  store double %1360, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1361 = add i64 %1349, -16
  %1362 = add i64 %1351, 14
  store i64 %1362, i64* %PC, align 8
  %1363 = inttoptr i64 %1361 to i64*
  %1364 = load i64, i64* %1363, align 8
  store i64 %1364, i64* %RAX, align 8, !tbaa !2428
  %1365 = add i64 %1349, -28
  %1366 = add i64 %1351, 17
  store i64 %1366, i64* %PC, align 8
  %1367 = inttoptr i64 %1365 to i32*
  %1368 = load i32, i32* %1367, align 4
  %1369 = add i32 %1368, 1
  %1370 = zext i32 %1369 to i64
  store i64 %1370, i64* %RCX, align 8, !tbaa !2428
  %1371 = icmp eq i32 %1368, -1
  %1372 = icmp eq i32 %1369, 0
  %1373 = or i1 %1371, %1372
  %1374 = zext i1 %1373 to i8
  store i8 %1374, i8* %14, align 1, !tbaa !2433
  %1375 = and i32 %1369, 255
  %1376 = tail call i32 @llvm.ctpop.i32(i32 %1375) #10
  %1377 = trunc i32 %1376 to i8
  %1378 = and i8 %1377, 1
  %1379 = xor i8 %1378, 1
  store i8 %1379, i8* %21, align 1, !tbaa !2447
  %1380 = xor i32 %1369, %1368
  %1381 = lshr i32 %1380, 4
  %1382 = trunc i32 %1381 to i8
  %1383 = and i8 %1382, 1
  store i8 %1383, i8* %27, align 1, !tbaa !2451
  %1384 = zext i1 %1372 to i8
  store i8 %1384, i8* %30, align 1, !tbaa !2448
  %1385 = lshr i32 %1369, 31
  %1386 = trunc i32 %1385 to i8
  store i8 %1386, i8* %33, align 1, !tbaa !2449
  %1387 = lshr i32 %1368, 31
  %1388 = xor i32 %1385, %1387
  %1389 = add nuw nsw i32 %1388, %1385
  %1390 = icmp eq i32 %1389, 2
  %1391 = zext i1 %1390 to i8
  store i8 %1391, i8* %39, align 1, !tbaa !2450
  %1392 = sext i32 %1369 to i64
  store i64 %1392, i64* %RDX, align 8, !tbaa !2428
  %1393 = shl nsw i64 %1392, 3
  %1394 = add i64 %1364, %1393
  %1395 = add i64 %1351, 28
  store i64 %1395, i64* %PC, align 8
  %1396 = inttoptr i64 %1394 to double*
  store double %1360, double* %1396, align 8
  %1397 = load i64, i64* %RBP, align 8
  %1398 = add i64 %1397, -56
  %1399 = load i64, i64* %PC, align 8
  %1400 = add i64 %1399, 5
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1398 to i64*
  %1402 = load i64, i64* %1401, align 8
  store i64 %1402, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1403 = add i64 %1397, -88
  %1404 = add i64 %1399, 10
  store i64 %1404, i64* %PC, align 8
  %1405 = bitcast i64 %1402 to double
  %1406 = inttoptr i64 %1403 to double*
  %1407 = load double, double* %1406, align 8
  %1408 = fsub double %1405, %1407
  store double %1408, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1409 = add i64 %1397, -16
  %1410 = add i64 %1399, 14
  store i64 %1410, i64* %PC, align 8
  %1411 = inttoptr i64 %1409 to i64*
  %1412 = load i64, i64* %1411, align 8
  store i64 %1412, i64* %RAX, align 8, !tbaa !2428
  %1413 = add i64 %1397, -36
  %1414 = add i64 %1399, 18
  store i64 %1414, i64* %PC, align 8
  %1415 = inttoptr i64 %1413 to i32*
  %1416 = load i32, i32* %1415, align 4
  %1417 = sext i32 %1416 to i64
  store i64 %1417, i64* %RDX, align 8, !tbaa !2428
  %1418 = shl nsw i64 %1417, 3
  %1419 = add i64 %1418, %1412
  %1420 = add i64 %1399, 23
  store i64 %1420, i64* %PC, align 8
  %1421 = inttoptr i64 %1419 to double*
  store double %1408, double* %1421, align 8
  %1422 = load i64, i64* %RBP, align 8
  %1423 = add i64 %1422, -64
  %1424 = load i64, i64* %PC, align 8
  %1425 = add i64 %1424, 5
  store i64 %1425, i64* %PC, align 8
  %1426 = inttoptr i64 %1423 to i64*
  %1427 = load i64, i64* %1426, align 8
  store i64 %1427, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1428 = add i64 %1422, -96
  %1429 = add i64 %1424, 10
  store i64 %1429, i64* %PC, align 8
  %1430 = bitcast i64 %1427 to double
  %1431 = inttoptr i64 %1428 to double*
  %1432 = load double, double* %1431, align 8
  %1433 = fadd double %1430, %1432
  store double %1433, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1434 = add i64 %1422, -16
  %1435 = add i64 %1424, 14
  store i64 %1435, i64* %PC, align 8
  %1436 = inttoptr i64 %1434 to i64*
  %1437 = load i64, i64* %1436, align 8
  store i64 %1437, i64* %RAX, align 8, !tbaa !2428
  %1438 = add i64 %1422, -36
  %1439 = add i64 %1424, 17
  store i64 %1439, i64* %PC, align 8
  %1440 = inttoptr i64 %1438 to i32*
  %1441 = load i32, i32* %1440, align 4
  %1442 = add i32 %1441, 1
  %1443 = zext i32 %1442 to i64
  store i64 %1443, i64* %RCX, align 8, !tbaa !2428
  %1444 = icmp eq i32 %1441, -1
  %1445 = icmp eq i32 %1442, 0
  %1446 = or i1 %1444, %1445
  %1447 = zext i1 %1446 to i8
  store i8 %1447, i8* %14, align 1, !tbaa !2433
  %1448 = and i32 %1442, 255
  %1449 = tail call i32 @llvm.ctpop.i32(i32 %1448) #10
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  %1452 = xor i8 %1451, 1
  store i8 %1452, i8* %21, align 1, !tbaa !2447
  %1453 = xor i32 %1442, %1441
  %1454 = lshr i32 %1453, 4
  %1455 = trunc i32 %1454 to i8
  %1456 = and i8 %1455, 1
  store i8 %1456, i8* %27, align 1, !tbaa !2451
  %1457 = zext i1 %1445 to i8
  store i8 %1457, i8* %30, align 1, !tbaa !2448
  %1458 = lshr i32 %1442, 31
  %1459 = trunc i32 %1458 to i8
  store i8 %1459, i8* %33, align 1, !tbaa !2449
  %1460 = lshr i32 %1441, 31
  %1461 = xor i32 %1458, %1460
  %1462 = add nuw nsw i32 %1461, %1458
  %1463 = icmp eq i32 %1462, 2
  %1464 = zext i1 %1463 to i8
  store i8 %1464, i8* %39, align 1, !tbaa !2450
  %1465 = sext i32 %1442 to i64
  store i64 %1465, i64* %RDX, align 8, !tbaa !2428
  %1466 = shl nsw i64 %1465, 3
  %1467 = add i64 %1437, %1466
  %1468 = add i64 %1424, 28
  store i64 %1468, i64* %PC, align 8
  %1469 = inttoptr i64 %1467 to double*
  store double %1433, double* %1469, align 8
  %1470 = load i64, i64* %RBP, align 8
  %1471 = add i64 %1470, -72
  %1472 = load i64, i64* %PC, align 8
  %1473 = add i64 %1472, 5
  store i64 %1473, i64* %PC, align 8
  %1474 = inttoptr i64 %1471 to i64*
  %1475 = load i64, i64* %1474, align 8
  store i64 %1475, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1476 = add i64 %1470, -112
  %1477 = add i64 %1472, 10
  store i64 %1477, i64* %PC, align 8
  %1478 = bitcast i64 %1475 to double
  %1479 = inttoptr i64 %1476 to double*
  %1480 = load double, double* %1479, align 8
  %1481 = fsub double %1478, %1480
  store double %1481, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1482 = add i64 %1470, -16
  %1483 = add i64 %1472, 14
  store i64 %1483, i64* %PC, align 8
  %1484 = inttoptr i64 %1482 to i64*
  %1485 = load i64, i64* %1484, align 8
  store i64 %1485, i64* %RAX, align 8, !tbaa !2428
  %1486 = add i64 %1470, -32
  %1487 = add i64 %1472, 18
  store i64 %1487, i64* %PC, align 8
  %1488 = inttoptr i64 %1486 to i32*
  %1489 = load i32, i32* %1488, align 4
  %1490 = sext i32 %1489 to i64
  store i64 %1490, i64* %RDX, align 8, !tbaa !2428
  %1491 = shl nsw i64 %1490, 3
  %1492 = add i64 %1491, %1485
  %1493 = add i64 %1472, 23
  store i64 %1493, i64* %PC, align 8
  %1494 = inttoptr i64 %1492 to double*
  store double %1481, double* %1494, align 8
  %1495 = load i64, i64* %RBP, align 8
  %1496 = add i64 %1495, -80
  %1497 = load i64, i64* %PC, align 8
  %1498 = add i64 %1497, 5
  store i64 %1498, i64* %PC, align 8
  %1499 = inttoptr i64 %1496 to i64*
  %1500 = load i64, i64* %1499, align 8
  store i64 %1500, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1501 = add i64 %1495, -104
  %1502 = add i64 %1497, 10
  store i64 %1502, i64* %PC, align 8
  %1503 = bitcast i64 %1500 to double
  %1504 = inttoptr i64 %1501 to double*
  %1505 = load double, double* %1504, align 8
  %1506 = fsub double %1503, %1505
  store double %1506, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1507 = add i64 %1495, -16
  %1508 = add i64 %1497, 14
  store i64 %1508, i64* %PC, align 8
  %1509 = inttoptr i64 %1507 to i64*
  %1510 = load i64, i64* %1509, align 8
  store i64 %1510, i64* %RAX, align 8, !tbaa !2428
  %1511 = add i64 %1495, -32
  %1512 = add i64 %1497, 17
  store i64 %1512, i64* %PC, align 8
  %1513 = inttoptr i64 %1511 to i32*
  %1514 = load i32, i32* %1513, align 4
  %1515 = add i32 %1514, 1
  %1516 = zext i32 %1515 to i64
  store i64 %1516, i64* %RCX, align 8, !tbaa !2428
  %1517 = icmp eq i32 %1514, -1
  %1518 = icmp eq i32 %1515, 0
  %1519 = or i1 %1517, %1518
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %14, align 1, !tbaa !2433
  %1521 = and i32 %1515, 255
  %1522 = tail call i32 @llvm.ctpop.i32(i32 %1521) #10
  %1523 = trunc i32 %1522 to i8
  %1524 = and i8 %1523, 1
  %1525 = xor i8 %1524, 1
  store i8 %1525, i8* %21, align 1, !tbaa !2447
  %1526 = xor i32 %1515, %1514
  %1527 = lshr i32 %1526, 4
  %1528 = trunc i32 %1527 to i8
  %1529 = and i8 %1528, 1
  store i8 %1529, i8* %27, align 1, !tbaa !2451
  %1530 = zext i1 %1518 to i8
  store i8 %1530, i8* %30, align 1, !tbaa !2448
  %1531 = lshr i32 %1515, 31
  %1532 = trunc i32 %1531 to i8
  store i8 %1532, i8* %33, align 1, !tbaa !2449
  %1533 = lshr i32 %1514, 31
  %1534 = xor i32 %1531, %1533
  %1535 = add nuw nsw i32 %1534, %1531
  %1536 = icmp eq i32 %1535, 2
  %1537 = zext i1 %1536 to i8
  store i8 %1537, i8* %39, align 1, !tbaa !2450
  %1538 = sext i32 %1515 to i64
  store i64 %1538, i64* %RDX, align 8, !tbaa !2428
  %1539 = shl nsw i64 %1538, 3
  %1540 = add i64 %1510, %1539
  %1541 = add i64 %1497, 28
  store i64 %1541, i64* %PC, align 8
  %1542 = inttoptr i64 %1540 to double*
  store double %1506, double* %1542, align 8
  %1543 = load i64, i64* %RBP, align 8
  %1544 = add i64 %1543, -72
  %1545 = load i64, i64* %PC, align 8
  %1546 = add i64 %1545, 5
  store i64 %1546, i64* %PC, align 8
  %1547 = inttoptr i64 %1544 to i64*
  %1548 = load i64, i64* %1547, align 8
  store i64 %1548, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1549 = add i64 %1543, -112
  %1550 = add i64 %1545, 10
  store i64 %1550, i64* %PC, align 8
  %1551 = bitcast i64 %1548 to double
  %1552 = inttoptr i64 %1549 to double*
  %1553 = load double, double* %1552, align 8
  %1554 = fadd double %1551, %1553
  store double %1554, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1555 = add i64 %1543, -16
  %1556 = add i64 %1545, 14
  store i64 %1556, i64* %PC, align 8
  %1557 = inttoptr i64 %1555 to i64*
  %1558 = load i64, i64* %1557, align 8
  store i64 %1558, i64* %RAX, align 8, !tbaa !2428
  %1559 = add i64 %1543, -40
  %1560 = add i64 %1545, 18
  store i64 %1560, i64* %PC, align 8
  %1561 = inttoptr i64 %1559 to i32*
  %1562 = load i32, i32* %1561, align 4
  %1563 = sext i32 %1562 to i64
  store i64 %1563, i64* %RDX, align 8, !tbaa !2428
  %1564 = shl nsw i64 %1563, 3
  %1565 = add i64 %1564, %1558
  %1566 = add i64 %1545, 23
  store i64 %1566, i64* %PC, align 8
  %1567 = inttoptr i64 %1565 to double*
  store double %1554, double* %1567, align 8
  %1568 = load i64, i64* %RBP, align 8
  %1569 = add i64 %1568, -80
  %1570 = load i64, i64* %PC, align 8
  %1571 = add i64 %1570, 5
  store i64 %1571, i64* %PC, align 8
  %1572 = inttoptr i64 %1569 to i64*
  %1573 = load i64, i64* %1572, align 8
  store i64 %1573, i64* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1574 = add i64 %1568, -104
  %1575 = add i64 %1570, 10
  store i64 %1575, i64* %PC, align 8
  %1576 = bitcast i64 %1573 to double
  %1577 = inttoptr i64 %1574 to double*
  %1578 = load double, double* %1577, align 8
  %1579 = fadd double %1576, %1578
  store double %1579, double* %1701, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1580 = add i64 %1568, -16
  %1581 = add i64 %1570, 14
  store i64 %1581, i64* %PC, align 8
  %1582 = inttoptr i64 %1580 to i64*
  %1583 = load i64, i64* %1582, align 8
  store i64 %1583, i64* %RAX, align 8, !tbaa !2428
  %1584 = add i64 %1568, -40
  %1585 = add i64 %1570, 17
  store i64 %1585, i64* %PC, align 8
  %1586 = inttoptr i64 %1584 to i32*
  %1587 = load i32, i32* %1586, align 4
  %1588 = add i32 %1587, 1
  %1589 = zext i32 %1588 to i64
  store i64 %1589, i64* %RCX, align 8, !tbaa !2428
  %1590 = icmp eq i32 %1587, -1
  %1591 = icmp eq i32 %1588, 0
  %1592 = or i1 %1590, %1591
  %1593 = zext i1 %1592 to i8
  store i8 %1593, i8* %14, align 1, !tbaa !2433
  %1594 = and i32 %1588, 255
  %1595 = tail call i32 @llvm.ctpop.i32(i32 %1594) #10
  %1596 = trunc i32 %1595 to i8
  %1597 = and i8 %1596, 1
  %1598 = xor i8 %1597, 1
  store i8 %1598, i8* %21, align 1, !tbaa !2447
  %1599 = xor i32 %1588, %1587
  %1600 = lshr i32 %1599, 4
  %1601 = trunc i32 %1600 to i8
  %1602 = and i8 %1601, 1
  store i8 %1602, i8* %27, align 1, !tbaa !2451
  %1603 = zext i1 %1591 to i8
  store i8 %1603, i8* %30, align 1, !tbaa !2448
  %1604 = lshr i32 %1588, 31
  %1605 = trunc i32 %1604 to i8
  store i8 %1605, i8* %33, align 1, !tbaa !2449
  %1606 = lshr i32 %1587, 31
  %1607 = xor i32 %1604, %1606
  %1608 = add nuw nsw i32 %1607, %1604
  %1609 = icmp eq i32 %1608, 2
  %1610 = zext i1 %1609 to i8
  store i8 %1610, i8* %39, align 1, !tbaa !2450
  %1611 = sext i32 %1588 to i64
  store i64 %1611, i64* %RDX, align 8, !tbaa !2428
  %1612 = shl nsw i64 %1611, 3
  %1613 = add i64 %1583, %1612
  %1614 = add i64 %1570, 28
  store i64 %1614, i64* %PC, align 8
  %1615 = inttoptr i64 %1613 to double*
  store double %1579, double* %1615, align 8
  %1616 = load i64, i64* %RBP, align 8
  %1617 = add i64 %1616, -28
  %1618 = load i64, i64* %PC, align 8
  %1619 = add i64 %1618, 3
  store i64 %1619, i64* %PC, align 8
  %1620 = inttoptr i64 %1617 to i32*
  %1621 = load i32, i32* %1620, align 4
  %1622 = add i32 %1621, 2
  %1623 = zext i32 %1622 to i64
  store i64 %1623, i64* %RAX, align 8, !tbaa !2428
  %1624 = icmp ugt i32 %1621, -3
  %1625 = zext i1 %1624 to i8
  store i8 %1625, i8* %14, align 1, !tbaa !2433
  %1626 = and i32 %1622, 255
  %1627 = tail call i32 @llvm.ctpop.i32(i32 %1626) #10
  %1628 = trunc i32 %1627 to i8
  %1629 = and i8 %1628, 1
  %1630 = xor i8 %1629, 1
  store i8 %1630, i8* %21, align 1, !tbaa !2447
  %1631 = xor i32 %1622, %1621
  %1632 = lshr i32 %1631, 4
  %1633 = trunc i32 %1632 to i8
  %1634 = and i8 %1633, 1
  store i8 %1634, i8* %27, align 1, !tbaa !2451
  %1635 = icmp eq i32 %1622, 0
  %1636 = zext i1 %1635 to i8
  store i8 %1636, i8* %30, align 1, !tbaa !2448
  %1637 = lshr i32 %1622, 31
  %1638 = trunc i32 %1637 to i8
  store i8 %1638, i8* %33, align 1, !tbaa !2449
  %1639 = lshr i32 %1621, 31
  %1640 = xor i32 %1637, %1639
  %1641 = add nuw nsw i32 %1640, %1637
  %1642 = icmp eq i32 %1641, 2
  %1643 = zext i1 %1642 to i8
  store i8 %1643, i8* %39, align 1, !tbaa !2450
  %1644 = add i64 %1618, 9
  store i64 %1644, i64* %PC, align 8
  store i32 %1622, i32* %1620, align 4
  %1645 = load i64, i64* %PC, align 8
  %1646 = add i64 %1645, -576
  store i64 %1646, i64* %PC, align 8, !tbaa !2428
  br label %block_402526

block_402510:                                     ; preds = %block_40250b, %block_4024a0
  %1647 = phi i64 [ %91, %block_4024a0 ], [ %729, %block_40250b ]
  %1648 = phi i64 [ %61, %block_4024a0 ], [ %131, %block_40250b ]
  %MEMORY.4 = phi %struct.Memory* [ %2, %block_4024a0 ], [ %723, %block_40250b ]
  %1649 = add i64 %1648, -44
  %1650 = add i64 %1647, 3
  store i64 %1650, i64* %PC, align 8
  %1651 = inttoptr i64 %1649 to i32*
  %1652 = load i32, i32* %1651, align 4
  %1653 = shl i32 %1652, 2
  %1654 = zext i32 %1653 to i64
  store i64 %1654, i64* %RAX, align 8, !tbaa !2428
  %1655 = lshr i32 %1652, 30
  %1656 = trunc i32 %1655 to i8
  %1657 = and i8 %1656, 1
  store i8 %1657, i8* %14, align 1, !tbaa !2432
  %1658 = and i32 %1653, 252
  %1659 = tail call i32 @llvm.ctpop.i32(i32 %1658) #10
  %1660 = trunc i32 %1659 to i8
  %1661 = and i8 %1660, 1
  %1662 = xor i8 %1661, 1
  store i8 %1662, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %1663 = icmp eq i32 %1653, 0
  %1664 = zext i1 %1663 to i8
  store i8 %1664, i8* %30, align 1, !tbaa !2432
  %1665 = lshr i32 %1652, 29
  %1666 = trunc i32 %1665 to i8
  %1667 = and i8 %1666, 1
  store i8 %1667, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %1668 = add i64 %1648, -4
  %1669 = add i64 %1647, 9
  store i64 %1669, i64* %PC, align 8
  %1670 = inttoptr i64 %1668 to i32*
  %1671 = load i32, i32* %1670, align 4
  %1672 = sub i32 %1653, %1671
  %1673 = icmp ult i32 %1653, %1671
  %1674 = zext i1 %1673 to i8
  store i8 %1674, i8* %14, align 1, !tbaa !2433
  %1675 = and i32 %1672, 255
  %1676 = tail call i32 @llvm.ctpop.i32(i32 %1675) #10
  %1677 = trunc i32 %1676 to i8
  %1678 = and i8 %1677, 1
  %1679 = xor i8 %1678, 1
  store i8 %1679, i8* %21, align 1, !tbaa !2447
  %1680 = xor i32 %1671, %1653
  %1681 = xor i32 %1680, %1672
  %1682 = lshr i32 %1681, 4
  %1683 = trunc i32 %1682 to i8
  %1684 = and i8 %1683, 1
  store i8 %1684, i8* %27, align 1, !tbaa !2451
  %1685 = icmp eq i32 %1672, 0
  %1686 = zext i1 %1685 to i8
  store i8 %1686, i8* %30, align 1, !tbaa !2448
  %1687 = lshr i32 %1672, 31
  %1688 = trunc i32 %1687 to i8
  store i8 %1688, i8* %33, align 1, !tbaa !2449
  %1689 = lshr i32 %1652, 29
  %1690 = and i32 %1689, 1
  %1691 = lshr i32 %1671, 31
  %1692 = xor i32 %1691, %1690
  %1693 = xor i32 %1687, %1690
  %1694 = add nuw nsw i32 %1693, %1692
  %1695 = icmp eq i32 %1694, 2
  %1696 = zext i1 %1695 to i8
  store i8 %1696, i8* %39, align 1, !tbaa !2450
  %.v = select i1 %1685, i64 15, i64 608
  %1697 = add i64 %1647, %.v
  %1698 = add i64 %1648, -28
  %1699 = add i64 %1697, 7
  store i64 %1699, i64* %PC, align 8
  %1700 = inttoptr i64 %1698 to i32*
  store i32 0, i32* %1700, align 4
  %1701 = bitcast %union.VectorReg* %4 to double*
  %1702 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %1703 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1704 = bitcast i64* %1703 to double*
  %.pre12 = load i64, i64* %PC, align 8
  br i1 %1685, label %block_402526.preheader, label %block_402777.preheader

block_402777.preheader:                           ; preds = %block_402510
  br label %block_402777

block_402526.preheader:                           ; preds = %block_402510
  br label %block_402526
}

; Function Attrs: noinline
declare void @__mcsema_attach_call() #6

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_400830_frame_dummy() #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400830;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @1, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @callback_sub_400830_frame_dummy_wrapper(%struct.State*, i64, %struct.Memory*) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400830_frame_dummy(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_400800___do_global_dtors_aux() #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400800;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @3, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @callback_sub_400800___do_global_dtors_aux_wrapper(%struct.State*, i64, %struct.Memory*) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400800___do_global_dtors_aux(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006e0_gettimeofday(%struct.State*, %struct.Memory*) unnamed_addr #11 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @gettimeofday to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006d0_printf(%struct.State*, %struct.Memory*) unnamed_addr #11 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)* @printf to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_6050f0_abort(%struct.State*, %struct.Memory*) unnamed_addr #11 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 ()* @abort to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_6050e8_free(%struct.State*, %struct.Memory*) unnamed_addr #11 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64)* @free to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_605140_sqrt(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #12 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sqrt(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_400720_memalign(%struct.State*, %struct.Memory*) unnamed_addr #11 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @memalign to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_605128_memcpy(%struct.State*, %struct.Memory*) unnamed_addr #11 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memcpy to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006f0_memset(%struct.State*, %struct.Memory*) unnamed_addr #11 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memset to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_404080___libc_csu_fini() #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404080;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @4, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: norecurse nounwind
define internal %struct.Memory* @callback_sub_404080___libc_csu_fini_wrapper(%struct.State* nocapture, i64, %struct.Memory* readnone returned) #13 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404080___libc_csu_fini(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_404010___libc_csu_init() #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404010;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @5, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @callback_sub_404010___libc_csu_init_wrapper(%struct.State*, i64, %struct.Memory*) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404010___libc_csu_init(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @main() #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400840;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @6, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @main_wrapper(%struct.State*, i64, %struct.Memory*) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400840_main(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State*, %struct.Memory*) unnamed_addr #11 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_6050b8_cos(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #12 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @cos(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_400730_sin(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #12 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sin(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_6050f8_atan(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #12 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @atan(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @cdft() local_unnamed_addr #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x401050;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @7, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @cdft_wrapper(%struct.State*, i64, %struct.Memory* readnone) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_401050_cdft(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @errorcheck() local_unnamed_addr #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4010f0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @8, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @errorcheck_wrapper(%struct.State*, i64, %struct.Memory*) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4010f0_errorcheck(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @.term_proc() local_unnamed_addr #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404084;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @9, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @.term_proc_wrapper(%struct.State* nocapture, i64, %struct.Memory* readnone returned) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404084__term_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @get_time() local_unnamed_addr #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400e20;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @10, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @get_time_wrapper(%struct.State*, i64, %struct.Memory*) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400e20_get_time(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @putdata() local_unnamed_addr #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400fd0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @11, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @putdata_wrapper(%struct.State*, i64, %struct.Memory*) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400fd0_putdata(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @.init_proc() local_unnamed_addr #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400678;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @12, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @.init_proc_wrapper(%struct.State*, i64, %struct.Memory*) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400678__init_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @makewt() local_unnamed_addr #9 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400e60;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @13, void ()** nonnull @2) #10
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @makewt_wrapper(%struct.State*, i64, %struct.Memory* readnone) #10 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400e60_makewt(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: nounwind
define internal void @__mcsema_constructor() #10 {
  %1 = load volatile i1, i1* @0, align 1
  br i1 %1, label %__mcsema_early_init.exit, label %2

; <label>:2:                                      ; preds = %0
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %0, %2
  tail call void @callback_sub_404010___libc_csu_init()
  ret void
}

; Function Attrs: nounwind
define internal void @__mcsema_destructor() #10 {
  tail call void @callback_sub_404080___libc_csu_fini()
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i32, i1) #14

attributes #0 = { nounwind readnone }
attributes #1 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind readnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { noinline }
attributes #7 = { noinline nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { noinline norecurse nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { naked nobuiltin noinline nounwind }
attributes #10 = { nounwind }
attributes #11 = { noinline nounwind }
attributes #12 = { alwaysinline inlinehint nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #13 = { norecurse nounwind }
attributes #14 = { argmemonly nounwind }
attributes #15 = { alwaysinline nobuiltin nounwind }

!llvm.ident = !{!0, !0}
!llvm.dbg.cu = !{!1}
!llvm.module.flags = !{!1259, !1260}

!0 = !{!"clang version 4.0.1 (tags/RELEASE_401/final)"}
!1 = distinct !DICompileUnit(language: DW_LANG_C_plus_plus, file: !2, producer: "clang version 4.0.1 (tags/RELEASE_401/final)", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !3, retainedTypes: !67, imports: !70)
!2 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/BasicBlock.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!3 = !{!4, !26, !35, !39, !45, !51, !55, !61}
!4 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "Name", scope: !6, file: !5, line: 70, baseType: !8, size: 32, elements: !11, identifier: "_ZTSN14AsyncHyperCall4NameE")
!5 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/HyperCall.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!6 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "AsyncHyperCall", file: !5, line: 68, size: 8, elements: !7, identifier: "_ZTS14AsyncHyperCall")
!7 = !{}
!8 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint32_t", file: !9, line: 183, baseType: !10)
!9 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stdint.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!10 = !DIBasicType(name: "unsigned int", size: 32, encoding: DW_ATE_unsigned)
!11 = !{!12, !13, !14, !15, !16, !17, !18, !19, !20, !21, !22, !23, !24, !25}
!12 = !DIEnumerator(name: "kInvalid", value: 0)
!13 = !DIEnumerator(name: "kX86Int1", value: 1)
!14 = !DIEnumerator(name: "kX86Int3", value: 2)
!15 = !DIEnumerator(name: "kX86IntO", value: 3)
!16 = !DIEnumerator(name: "kX86IntN", value: 4)
!17 = !DIEnumerator(name: "kX86Bound", value: 5)
!18 = !DIEnumerator(name: "kX86IRet", value: 6)
!19 = !DIEnumerator(name: "kX86SysCall", value: 7)
!20 = !DIEnumerator(name: "kX86SysRet", value: 8)
!21 = !DIEnumerator(name: "kX86SysEnter", value: 9)
!22 = !DIEnumerator(name: "kX86SysExit", value: 10)
!23 = !DIEnumerator(name: "kX86JmpFar", value: 11)
!24 = !DIEnumerator(name: "kAArch64SupervisorCall", value: 12)
!25 = !DIEnumerator(name: "kInvalidInstruction", value: 13)
!26 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "RequestPrivilegeLevel", file: !27, line: 64, baseType: !28, size: 16, elements: !30, identifier: "_ZTS21RequestPrivilegeLevel")
!27 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!28 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint16_t", file: !9, line: 218, baseType: !29)
!29 = !DIBasicType(name: "unsigned short", size: 16, encoding: DW_ATE_unsigned)
!30 = !{!31, !32, !33, !34}
!31 = !DIEnumerator(name: "kRPLRingZero", value: 0)
!32 = !DIEnumerator(name: "kRPLRingOne", value: 1)
!33 = !DIEnumerator(name: "kRPLRingTwo", value: 2)
!34 = !DIEnumerator(name: "kRPLRingThree", value: 3)
!35 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "TableIndicator", file: !27, line: 71, baseType: !28, size: 16, elements: !36, identifier: "_ZTS14TableIndicator")
!36 = !{!37, !38}
!37 = !DIEnumerator(name: "kGlobalDescriptorTable", value: 0)
!38 = !DIEnumerator(name: "kLocalDescriptorTable", value: 1)
!39 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUPrecisionControl", file: !27, line: 123, baseType: !28, size: 16, elements: !40, identifier: "_ZTS19FPUPrecisionControl")
!40 = !{!41, !42, !43, !44}
!41 = !DIEnumerator(name: "kPrecisionSingle", value: 0)
!42 = !DIEnumerator(name: "kPrecisionReserved", value: 1)
!43 = !DIEnumerator(name: "kPrecisionDouble", value: 2)
!44 = !DIEnumerator(name: "kPrecisionExtended", value: 3)
!45 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPURoundingControl", file: !27, line: 130, baseType: !28, size: 16, elements: !46, identifier: "_ZTS18FPURoundingControl")
!46 = !{!47, !48, !49, !50}
!47 = !DIEnumerator(name: "kFPURoundToNearestEven", value: 0)
!48 = !DIEnumerator(name: "kFPURoundDownNegInf", value: 1)
!49 = !DIEnumerator(name: "kFPURoundUpInf", value: 2)
!50 = !DIEnumerator(name: "kFPURoundToZero", value: 3)
!51 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUInfinityControl", file: !27, line: 137, baseType: !28, size: 16, elements: !52, identifier: "_ZTS18FPUInfinityControl")
!52 = !{!53, !54}
!53 = !DIEnumerator(name: "kInfinityProjective", value: 0)
!54 = !DIEnumerator(name: "kInfinityAffine", value: 1)
!55 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUTag", file: !27, line: 214, baseType: !28, size: 16, elements: !56, identifier: "_ZTS6FPUTag")
!56 = !{!57, !58, !59, !60}
!57 = !DIEnumerator(name: "kFPUTagNonZero", value: 0)
!58 = !DIEnumerator(name: "kFPUTagZero", value: 1)
!59 = !DIEnumerator(name: "kFPUTagSpecial", value: 2)
!60 = !DIEnumerator(name: "kFPUTagEmpty", value: 3)
!61 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUAbridgedTag", file: !27, line: 221, baseType: !62, size: 8, elements: !64, identifier: "_ZTS14FPUAbridgedTag")
!62 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint8_t", file: !9, line: 237, baseType: !63)
!63 = !DIBasicType(name: "unsigned char", size: 8, encoding: DW_ATE_unsigned_char)
!64 = !{!65, !66}
!65 = !DIEnumerator(name: "kFPUAbridgedTagEmpty", value: 0)
!66 = !DIEnumerator(name: "kFPUAbridgedTagValid", value: 1)
!67 = !{!68}
!68 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !69, size: 64)
!69 = !DIDerivedType(tag: DW_TAG_const_type, baseType: null)
!70 = !{!71, !77, !83, !86, !93, !97, !102, !104, !112, !116, !120, !132, !136, !140, !144, !148, !153, !157, !161, !165, !169, !177, !181, !185, !187, !191, !195, !199, !205, !209, !213, !215, !223, !227, !235, !237, !241, !245, !249, !253, !258, !263, !268, !269, !270, !271, !274, !275, !276, !277, !278, !279, !280, !335, !339, !355, !358, !363, !371, !376, !380, !384, !388, !392, !394, !396, !400, !406, !410, !416, !422, !424, !428, !432, !436, !440, !451, !453, !457, !461, !465, !467, !471, !475, !479, !481, !483, !487, !495, !499, !503, !507, !509, !515, !517, !523, !527, !531, !535, !539, !543, !547, !549, !551, !555, !559, !563, !565, !569, !573, !575, !577, !581, !585, !589, !593, !594, !595, !596, !597, !598, !599, !600, !601, !602, !603, !606, !609, !611, !613, !615, !617, !619, !621, !623, !625, !627, !629, !631, !633, !634, !635, !636, !638, !640, !642, !644, !646, !648, !650, !652, !654, !656, !658, !660, !662, !665, !669, !674, !677, !679, !681, !683, !685, !687, !689, !691, !693, !695, !697, !699, !701, !703, !706, !712, !717, !721, !723, !725, !727, !729, !736, !740, !744, !748, !752, !756, !761, !765, !767, !771, !777, !781, !786, !788, !790, !794, !798, !802, !804, !806, !808, !810, !814, !816, !818, !822, !826, !830, !834, !838, !840, !842, !846, !850, !854, !858, !860, !862, !866, !870, !871, !872, !873, !874, !875, !880, !882, !884, !888, !890, !892, !894, !896, !898, !900, !902, !907, !911, !913, !915, !920, !922, !924, !926, !928, !930, !932, !935, !937, !939, !943, !947, !949, !951, !953, !955, !957, !959, !961, !963, !965, !967, !971, !975, !977, !979, !981, !983, !985, !987, !989, !991, !993, !995, !997, !999, !1001, !1003, !1005, !1009, !1013, !1017, !1019, !1021, !1023, !1025, !1027, !1029, !1031, !1033, !1035, !1039, !1043, !1047, !1049, !1051, !1053, !1057, !1061, !1065, !1067, !1069, !1071, !1073, !1075, !1077, !1079, !1081, !1083, !1085, !1087, !1089, !1093, !1097, !1101, !1103, !1105, !1107, !1109, !1113, !1117, !1119, !1121, !1123, !1125, !1127, !1129, !1133, !1137, !1139, !1141, !1143, !1145, !1149, !1153, !1157, !1159, !1161, !1163, !1165, !1167, !1169, !1173, !1177, !1181, !1183, !1187, !1191, !1193, !1195, !1197, !1199, !1201, !1203, !1207, !1209, !1212, !1217, !1219, !1225, !1227, !1229, !1231, !1236, !1238, !1244, !1246, !1247, !1248, !1249, !1250, !1251, !1252, !1253, !1254, !1255, !1256, !1257, !1258}
!71 = !DIImportedEntity(tag: DW_TAG_imported_module, scope: !72, entity: !74, line: 58)
!72 = !DINamespace(name: "__gnu_debug", scope: null, file: !73, line: 56)
!73 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/debug/debug.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!74 = !DINamespace(name: "__debug", scope: !75, file: !73, line: 50)
!75 = !DINamespace(name: "std", scope: null, file: !76, line: 229)
!76 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/x86_64-linux-gnu/c++/7.4.0/bits/c++config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!77 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !78, line: 52)
!78 = !DISubprogram(name: "abs", scope: !79, file: !79, line: 837, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!79 = !DIFile(filename: "/usr/include/stdlib.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!80 = !DISubroutineType(types: !81)
!81 = !{!82, !82}
!82 = !DIBasicType(name: "int", size: 32, encoding: DW_ATE_signed)
!83 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !84, line: 127)
!84 = !DIDerivedType(tag: DW_TAG_typedef, name: "div_t", file: !79, line: 62, baseType: !85)
!85 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 58, flags: DIFlagFwdDecl, identifier: "_ZTS5div_t")
!86 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !87, line: 128)
!87 = !DIDerivedType(tag: DW_TAG_typedef, name: "ldiv_t", file: !79, line: 70, baseType: !88)
!88 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 66, size: 128, elements: !89, identifier: "_ZTS6ldiv_t")
!89 = !{!90, !92}
!90 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !88, file: !79, line: 68, baseType: !91, size: 64)
!91 = !DIBasicType(name: "long int", size: 64, encoding: DW_ATE_signed)
!92 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !88, file: !79, line: 69, baseType: !91, size: 64, offset: 64)
!93 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !94, line: 130)
!94 = !DISubprogram(name: "abort", scope: !79, file: !79, line: 588, type: !95, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!95 = !DISubroutineType(types: !96)
!96 = !{null}
!97 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !98, line: 134)
!98 = !DISubprogram(name: "atexit", scope: !79, file: !79, line: 592, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!99 = !DISubroutineType(types: !100)
!100 = !{!82, !101}
!101 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !95, size: 64)
!102 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !103, line: 137)
!103 = !DISubprogram(name: "at_quick_exit", scope: !79, file: !79, line: 597, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!104 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !105, line: 140)
!105 = !DISubprogram(name: "atof", scope: !79, file: !79, line: 101, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!106 = !DISubroutineType(types: !107)
!107 = !{!108, !109}
!108 = !DIBasicType(name: "double", size: 64, encoding: DW_ATE_float)
!109 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !110, size: 64)
!110 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !111)
!111 = !DIBasicType(name: "char", size: 8, encoding: DW_ATE_signed_char)
!112 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !113, line: 141)
!113 = !DISubprogram(name: "atoi", scope: !79, file: !79, line: 104, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!114 = !DISubroutineType(types: !115)
!115 = !{!82, !109}
!116 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !117, line: 142)
!117 = !DISubprogram(name: "atol", scope: !79, file: !79, line: 107, type: !118, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!118 = !DISubroutineType(types: !119)
!119 = !{!91, !109}
!120 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !121, line: 143)
!121 = !DISubprogram(name: "bsearch", scope: !79, file: !79, line: 817, type: !122, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!122 = !DISubroutineType(types: !123)
!123 = !{!124, !68, !68, !125, !125, !128}
!124 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: null, size: 64)
!125 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", file: !126, line: 62, baseType: !127)
!126 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stddef.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!127 = !DIBasicType(name: "long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!128 = !DIDerivedType(tag: DW_TAG_typedef, name: "__compar_fn_t", file: !79, line: 805, baseType: !129)
!129 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !130, size: 64)
!130 = !DISubroutineType(types: !131)
!131 = !{!82, !68, !68}
!132 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !133, line: 144)
!133 = !DISubprogram(name: "calloc", scope: !79, file: !79, line: 541, type: !134, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!134 = !DISubroutineType(types: !135)
!135 = !{!124, !125, !125}
!136 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !137, line: 145)
!137 = !DISubprogram(name: "div", scope: !79, file: !79, line: 849, type: !138, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!138 = !DISubroutineType(types: !139)
!139 = !{!84, !82, !82}
!140 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !141, line: 146)
!141 = !DISubprogram(name: "exit", scope: !79, file: !79, line: 614, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!142 = !DISubroutineType(types: !143)
!143 = !{null, !82}
!144 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !145, line: 147)
!145 = !DISubprogram(name: "free", scope: !79, file: !79, line: 563, type: !146, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!146 = !DISubroutineType(types: !147)
!147 = !{null, !124}
!148 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !149, line: 148)
!149 = !DISubprogram(name: "getenv", scope: !79, file: !79, line: 631, type: !150, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!150 = !DISubroutineType(types: !151)
!151 = !{!152, !109}
!152 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !111, size: 64)
!153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !154, line: 149)
!154 = !DISubprogram(name: "labs", scope: !79, file: !79, line: 838, type: !155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!155 = !DISubroutineType(types: !156)
!156 = !{!91, !91}
!157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !158, line: 150)
!158 = !DISubprogram(name: "ldiv", scope: !79, file: !79, line: 851, type: !159, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!159 = !DISubroutineType(types: !160)
!160 = !{!87, !91, !91}
!161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !162, line: 151)
!162 = !DISubprogram(name: "malloc", scope: !79, file: !79, line: 539, type: !163, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!163 = !DISubroutineType(types: !164)
!164 = !{!124, !125}
!165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !166, line: 153)
!166 = !DISubprogram(name: "mblen", scope: !79, file: !79, line: 919, type: !167, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!167 = !DISubroutineType(types: !168)
!168 = !{!82, !109, !125}
!169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !170, line: 154)
!170 = !DISubprogram(name: "mbstowcs", scope: !79, file: !79, line: 930, type: !171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!171 = !DISubroutineType(types: !172)
!172 = !{!125, !173, !176, !125}
!173 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !174)
!174 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !175, size: 64)
!175 = !DIBasicType(name: "wchar_t", size: 32, encoding: DW_ATE_signed)
!176 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !109)
!177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !178, line: 155)
!178 = !DISubprogram(name: "mbtowc", scope: !79, file: !79, line: 922, type: !179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!179 = !DISubroutineType(types: !180)
!180 = !{!82, !173, !176, !125}
!181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !182, line: 157)
!182 = !DISubprogram(name: "qsort", scope: !79, file: !79, line: 827, type: !183, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!183 = !DISubroutineType(types: !184)
!184 = !{null, !124, !125, !125, !128}
!185 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !186, line: 160)
!186 = !DISubprogram(name: "quick_exit", scope: !79, file: !79, line: 620, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !188, line: 163)
!188 = !DISubprogram(name: "rand", scope: !79, file: !79, line: 453, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!189 = !DISubroutineType(types: !190)
!190 = !{!82}
!191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !192, line: 164)
!192 = !DISubprogram(name: "realloc", scope: !79, file: !79, line: 549, type: !193, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!193 = !DISubroutineType(types: !194)
!194 = !{!124, !124, !125}
!195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !196, line: 165)
!196 = !DISubprogram(name: "srand", scope: !79, file: !79, line: 455, type: !197, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!197 = !DISubroutineType(types: !198)
!198 = !{null, !10}
!199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !200, line: 166)
!200 = !DISubprogram(name: "strtod", scope: !79, file: !79, line: 117, type: !201, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!201 = !DISubroutineType(types: !202)
!202 = !{!108, !176, !203}
!203 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !204)
!204 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !152, size: 64)
!205 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !206, line: 167)
!206 = !DISubprogram(name: "strtol", scope: !79, file: !79, line: 176, type: !207, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!207 = !DISubroutineType(types: !208)
!208 = !{!91, !176, !203, !82}
!209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !210, line: 168)
!210 = !DISubprogram(name: "strtoul", scope: !79, file: !79, line: 180, type: !211, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!211 = !DISubroutineType(types: !212)
!212 = !{!127, !176, !203, !82}
!213 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !214, line: 169)
!214 = !DISubprogram(name: "system", scope: !79, file: !79, line: 781, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!215 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !216, line: 171)
!216 = !DISubprogram(name: "wcstombs", scope: !79, file: !79, line: 933, type: !217, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!217 = !DISubroutineType(types: !218)
!218 = !{!125, !219, !220, !125}
!219 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !152)
!220 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !221)
!221 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !222, size: 64)
!222 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !175)
!223 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !224, line: 172)
!224 = !DISubprogram(name: "wctomb", scope: !79, file: !79, line: 926, type: !225, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!225 = !DISubroutineType(types: !226)
!226 = !{!82, !152, !175}
!227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !229, line: 200)
!228 = !DINamespace(name: "__gnu_cxx", scope: null, file: !76, line: 255)
!229 = !DIDerivedType(tag: DW_TAG_typedef, name: "lldiv_t", file: !79, line: 80, baseType: !230)
!230 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 76, size: 128, elements: !231, identifier: "_ZTS7lldiv_t")
!231 = !{!232, !234}
!232 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !230, file: !79, line: 78, baseType: !233, size: 64)
!233 = !DIBasicType(name: "long long int", size: 64, encoding: DW_ATE_signed)
!234 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !230, file: !79, line: 79, baseType: !233, size: 64, offset: 64)
!235 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !236, line: 206)
!236 = !DISubprogram(name: "_Exit", scope: !79, file: !79, line: 626, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!237 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !238, line: 210)
!238 = !DISubprogram(name: "llabs", scope: !79, file: !79, line: 841, type: !239, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!239 = !DISubroutineType(types: !240)
!240 = !{!233, !233}
!241 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !242, line: 216)
!242 = !DISubprogram(name: "lldiv", scope: !79, file: !79, line: 855, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!243 = !DISubroutineType(types: !244)
!244 = !{!229, !233, !233}
!245 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !246, line: 227)
!246 = !DISubprogram(name: "atoll", scope: !79, file: !79, line: 112, type: !247, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!247 = !DISubroutineType(types: !248)
!248 = !{!233, !109}
!249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !250, line: 228)
!250 = !DISubprogram(name: "strtoll", scope: !79, file: !79, line: 200, type: !251, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!251 = !DISubroutineType(types: !252)
!252 = !{!233, !176, !203, !82}
!253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !254, line: 229)
!254 = !DISubprogram(name: "strtoull", scope: !79, file: !79, line: 205, type: !255, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!255 = !DISubroutineType(types: !256)
!256 = !{!257, !176, !203, !82}
!257 = !DIBasicType(name: "long long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !259, line: 231)
!259 = !DISubprogram(name: "strtof", scope: !79, file: !79, line: 123, type: !260, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!260 = !DISubroutineType(types: !261)
!261 = !{!262, !176, !203}
!262 = !DIBasicType(name: "float", size: 32, encoding: DW_ATE_float)
!263 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !264, line: 232)
!264 = !DISubprogram(name: "strtold", scope: !79, file: !79, line: 126, type: !265, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!265 = !DISubroutineType(types: !266)
!266 = !{!267, !176, !203}
!267 = !DIBasicType(name: "long double", size: 128, encoding: DW_ATE_float)
!268 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !229, line: 240)
!269 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !236, line: 242)
!270 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !238, line: 244)
!271 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !272, line: 245)
!272 = !DISubprogram(name: "div", linkageName: "_ZN9__gnu_cxx3divExx", scope: !228, file: !273, line: 213, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!273 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/cstdlib", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!274 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !242, line: 246)
!275 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !246, line: 248)
!276 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !259, line: 249)
!277 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !250, line: 250)
!278 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !254, line: 251)
!279 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !264, line: 252)
!280 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !281, line: 57)
!281 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "exception_ptr", scope: !283, file: !282, line: 79, size: 64, elements: !284, identifier: "_ZTSNSt15__exception_ptr13exception_ptrE")
!282 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/bits/exception_ptr.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!283 = !DINamespace(name: "__exception_ptr", scope: !75, file: !282, line: 52)
!284 = !{!285, !286, !290, !293, !294, !299, !300, !304, !309, !313, !317, !320, !321, !324, !328}
!285 = !DIDerivedType(tag: DW_TAG_member, name: "_M_exception_object", scope: !281, file: !282, line: 81, baseType: !124, size: 64)
!286 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 83, type: !287, isLocal: false, isDefinition: false, scopeLine: 83, flags: DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!287 = !DISubroutineType(types: !288)
!288 = !{null, !289, !124}
!289 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !281, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!290 = !DISubprogram(name: "_M_addref", linkageName: "_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv", scope: !281, file: !282, line: 85, type: !291, isLocal: false, isDefinition: false, scopeLine: 85, flags: DIFlagPrototyped, isOptimized: false)
!291 = !DISubroutineType(types: !292)
!292 = !{null, !289}
!293 = !DISubprogram(name: "_M_release", linkageName: "_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv", scope: !281, file: !282, line: 86, type: !291, isLocal: false, isDefinition: false, scopeLine: 86, flags: DIFlagPrototyped, isOptimized: false)
!294 = !DISubprogram(name: "_M_get", linkageName: "_ZNKSt15__exception_ptr13exception_ptr6_M_getEv", scope: !281, file: !282, line: 88, type: !295, isLocal: false, isDefinition: false, scopeLine: 88, flags: DIFlagPrototyped, isOptimized: false)
!295 = !DISubroutineType(types: !296)
!296 = !{!124, !297}
!297 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !298, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!298 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !281)
!299 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 96, type: !291, isLocal: false, isDefinition: false, scopeLine: 96, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!300 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 98, type: !301, isLocal: false, isDefinition: false, scopeLine: 98, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!301 = !DISubroutineType(types: !302)
!302 = !{null, !289, !303}
!303 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !298, size: 64)
!304 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 101, type: !305, isLocal: false, isDefinition: false, scopeLine: 101, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!305 = !DISubroutineType(types: !306)
!306 = !{null, !289, !307}
!307 = !DIDerivedType(tag: DW_TAG_typedef, name: "nullptr_t", scope: !75, file: !76, line: 235, baseType: !308)
!308 = !DIBasicType(tag: DW_TAG_unspecified_type, name: "decltype(nullptr)")
!309 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 105, type: !310, isLocal: false, isDefinition: false, scopeLine: 105, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!310 = !DISubroutineType(types: !311)
!311 = !{null, !289, !312}
!312 = !DIDerivedType(tag: DW_TAG_rvalue_reference_type, baseType: !281, size: 64)
!313 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSERKS0_", scope: !281, file: !282, line: 118, type: !314, isLocal: false, isDefinition: false, scopeLine: 118, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!314 = !DISubroutineType(types: !315)
!315 = !{!316, !289, !303}
!316 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !281, size: 64)
!317 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSEOS0_", scope: !281, file: !282, line: 122, type: !318, isLocal: false, isDefinition: false, scopeLine: 122, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!318 = !DISubroutineType(types: !319)
!319 = !{!316, !289, !312}
!320 = !DISubprogram(name: "~exception_ptr", scope: !281, file: !282, line: 129, type: !291, isLocal: false, isDefinition: false, scopeLine: 129, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!321 = !DISubprogram(name: "swap", linkageName: "_ZNSt15__exception_ptr13exception_ptr4swapERS0_", scope: !281, file: !282, line: 132, type: !322, isLocal: false, isDefinition: false, scopeLine: 132, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!322 = !DISubroutineType(types: !323)
!323 = !{null, !289, !316}
!324 = !DISubprogram(name: "operator bool", linkageName: "_ZNKSt15__exception_ptr13exception_ptrcvbEv", scope: !281, file: !282, line: 144, type: !325, isLocal: false, isDefinition: false, scopeLine: 144, flags: DIFlagPublic | DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!325 = !DISubroutineType(types: !326)
!326 = !{!327, !297}
!327 = !DIBasicType(name: "bool", size: 8, encoding: DW_ATE_boolean)
!328 = !DISubprogram(name: "__cxa_exception_type", linkageName: "_ZNKSt15__exception_ptr13exception_ptr20__cxa_exception_typeEv", scope: !281, file: !282, line: 153, type: !329, isLocal: false, isDefinition: false, scopeLine: 153, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!329 = !DISubroutineType(types: !330)
!330 = !{!331, !297}
!331 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !332, size: 64)
!332 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !333)
!333 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "type_info", scope: !75, file: !334, line: 88, flags: DIFlagFwdDecl, identifier: "_ZTSSt9type_info")
!334 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/typeinfo", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!335 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !283, entity: !336, line: 73)
!336 = !DISubprogram(name: "rethrow_exception", linkageName: "_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE", scope: !75, file: !282, line: 69, type: !337, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!337 = !DISubroutineType(types: !338)
!338 = !{null, !281}
!339 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !340, line: 64)
!340 = !DIDerivedType(tag: DW_TAG_typedef, name: "mbstate_t", file: !341, line: 6, baseType: !342)
!341 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!342 = !DIDerivedType(tag: DW_TAG_typedef, name: "__mbstate_t", file: !343, line: 21, baseType: !344)
!343 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!344 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !343, line: 13, size: 64, elements: !345, identifier: "_ZTS11__mbstate_t")
!345 = !{!346, !347}
!346 = !DIDerivedType(tag: DW_TAG_member, name: "__count", scope: !344, file: !343, line: 15, baseType: !82, size: 32)
!347 = !DIDerivedType(tag: DW_TAG_member, name: "__value", scope: !344, file: !343, line: 20, baseType: !348, size: 32, offset: 32)
!348 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !344, file: !343, line: 16, size: 32, elements: !349, identifier: "_ZTSN11__mbstate_tUt_E")
!349 = !{!350, !351}
!350 = !DIDerivedType(tag: DW_TAG_member, name: "__wch", scope: !348, file: !343, line: 18, baseType: !10, size: 32)
!351 = !DIDerivedType(tag: DW_TAG_member, name: "__wchb", scope: !348, file: !343, line: 19, baseType: !352, size: 32)
!352 = !DICompositeType(tag: DW_TAG_array_type, baseType: !111, size: 32, elements: !353)
!353 = !{!354}
!354 = !DISubrange(count: 4)
!355 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !356, line: 139)
!356 = !DIDerivedType(tag: DW_TAG_typedef, name: "wint_t", file: !357, line: 20, baseType: !10)
!357 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/wint_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!358 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !359, line: 141)
!359 = !DISubprogram(name: "btowc", scope: !360, file: !360, line: 284, type: !361, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!360 = !DIFile(filename: "/usr/include/wchar.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!361 = !DISubroutineType(types: !362)
!362 = !{!356, !82}
!363 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !364, line: 142)
!364 = !DISubprogram(name: "fgetwc", scope: !360, file: !360, line: 727, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!365 = !DISubroutineType(types: !366)
!366 = !{!356, !367}
!367 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !368, size: 64)
!368 = !DIDerivedType(tag: DW_TAG_typedef, name: "__FILE", file: !369, line: 5, baseType: !370)
!369 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!370 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "_IO_FILE", file: !369, line: 4, flags: DIFlagFwdDecl, identifier: "_ZTS8_IO_FILE")
!371 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !372, line: 143)
!372 = !DISubprogram(name: "fgetws", scope: !360, file: !360, line: 756, type: !373, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!373 = !DISubroutineType(types: !374)
!374 = !{!174, !173, !82, !375}
!375 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !367)
!376 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !377, line: 144)
!377 = !DISubprogram(name: "fputwc", scope: !360, file: !360, line: 741, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!378 = !DISubroutineType(types: !379)
!379 = !{!356, !175, !367}
!380 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !381, line: 145)
!381 = !DISubprogram(name: "fputws", scope: !360, file: !360, line: 763, type: !382, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!382 = !DISubroutineType(types: !383)
!383 = !{!82, !220, !375}
!384 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !385, line: 146)
!385 = !DISubprogram(name: "fwide", scope: !360, file: !360, line: 573, type: !386, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!386 = !DISubroutineType(types: !387)
!387 = !{!82, !367, !82}
!388 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !389, line: 147)
!389 = !DISubprogram(name: "fwprintf", scope: !360, file: !360, line: 580, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!390 = !DISubroutineType(types: !391)
!391 = !{!82, !375, !220, null}
!392 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !393, line: 148)
!393 = !DISubprogram(name: "fwscanf", scope: !360, file: !360, line: 621, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!394 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !395, line: 149)
!395 = !DISubprogram(name: "getwc", scope: !360, file: !360, line: 728, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!396 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !397, line: 150)
!397 = !DISubprogram(name: "getwchar", scope: !360, file: !360, line: 734, type: !398, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!398 = !DISubroutineType(types: !399)
!399 = !{!356}
!400 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !401, line: 151)
!401 = !DISubprogram(name: "mbrlen", scope: !360, file: !360, line: 307, type: !402, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!402 = !DISubroutineType(types: !403)
!403 = !{!125, !176, !125, !404}
!404 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !405)
!405 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !340, size: 64)
!406 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !407, line: 152)
!407 = !DISubprogram(name: "mbrtowc", scope: !360, file: !360, line: 296, type: !408, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!408 = !DISubroutineType(types: !409)
!409 = !{!125, !173, !176, !125, !404}
!410 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !411, line: 153)
!411 = !DISubprogram(name: "mbsinit", scope: !360, file: !360, line: 292, type: !412, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!412 = !DISubroutineType(types: !413)
!413 = !{!82, !414}
!414 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !415, size: 64)
!415 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !340)
!416 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !417, line: 154)
!417 = !DISubprogram(name: "mbsrtowcs", scope: !360, file: !360, line: 337, type: !418, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!418 = !DISubroutineType(types: !419)
!419 = !{!125, !173, !420, !125, !404}
!420 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !421)
!421 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !109, size: 64)
!422 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !423, line: 155)
!423 = !DISubprogram(name: "putwc", scope: !360, file: !360, line: 742, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!424 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !425, line: 156)
!425 = !DISubprogram(name: "putwchar", scope: !360, file: !360, line: 748, type: !426, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!426 = !DISubroutineType(types: !427)
!427 = !{!356, !175}
!428 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !429, line: 158)
!429 = !DISubprogram(name: "swprintf", scope: !360, file: !360, line: 590, type: !430, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!430 = !DISubroutineType(types: !431)
!431 = !{!82, !173, !125, !220, null}
!432 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !433, line: 160)
!433 = !DISubprogram(name: "swscanf", scope: !360, file: !360, line: 631, type: !434, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!434 = !DISubroutineType(types: !435)
!435 = !{!82, !220, !220, null}
!436 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !437, line: 161)
!437 = !DISubprogram(name: "ungetwc", scope: !360, file: !360, line: 771, type: !438, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!438 = !DISubroutineType(types: !439)
!439 = !{!356, !356, !367}
!440 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !441, line: 162)
!441 = !DISubprogram(name: "vfwprintf", scope: !360, file: !360, line: 598, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!442 = !DISubroutineType(types: !443)
!443 = !{!82, !375, !220, !444}
!444 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !445, size: 64)
!445 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "__va_list_tag", file: !2, size: 192, elements: !446, identifier: "_ZTS13__va_list_tag")
!446 = !{!447, !448, !449, !450}
!447 = !DIDerivedType(tag: DW_TAG_member, name: "gp_offset", scope: !445, file: !2, baseType: !10, size: 32)
!448 = !DIDerivedType(tag: DW_TAG_member, name: "fp_offset", scope: !445, file: !2, baseType: !10, size: 32, offset: 32)
!449 = !DIDerivedType(tag: DW_TAG_member, name: "overflow_arg_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 64)
!450 = !DIDerivedType(tag: DW_TAG_member, name: "reg_save_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 128)
!451 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 164)
!452 = !DISubprogram(name: "vfwscanf", scope: !360, file: !360, line: 673, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!453 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !454, line: 167)
!454 = !DISubprogram(name: "vswprintf", scope: !360, file: !360, line: 611, type: !455, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!455 = !DISubroutineType(types: !456)
!456 = !{!82, !173, !125, !220, !444}
!457 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 170)
!458 = !DISubprogram(name: "vswscanf", scope: !360, file: !360, line: 685, type: !459, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!459 = !DISubroutineType(types: !460)
!460 = !{!82, !220, !220, !444}
!461 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !462, line: 172)
!462 = !DISubprogram(name: "vwprintf", scope: !360, file: !360, line: 606, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!463 = !DISubroutineType(types: !464)
!464 = !{!82, !220, !444}
!465 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 174)
!466 = !DISubprogram(name: "vwscanf", scope: !360, file: !360, line: 681, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!467 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !468, line: 176)
!468 = !DISubprogram(name: "wcrtomb", scope: !360, file: !360, line: 301, type: !469, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!469 = !DISubroutineType(types: !470)
!470 = !{!125, !219, !175, !404}
!471 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !472, line: 177)
!472 = !DISubprogram(name: "wcscat", scope: !360, file: !360, line: 97, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!473 = !DISubroutineType(types: !474)
!474 = !{!174, !173, !220}
!475 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !476, line: 178)
!476 = !DISubprogram(name: "wcscmp", scope: !360, file: !360, line: 106, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!477 = !DISubroutineType(types: !478)
!478 = !{!82, !221, !221}
!479 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !480, line: 179)
!480 = !DISubprogram(name: "wcscoll", scope: !360, file: !360, line: 131, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!481 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !482, line: 180)
!482 = !DISubprogram(name: "wcscpy", scope: !360, file: !360, line: 87, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!483 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !484, line: 181)
!484 = !DISubprogram(name: "wcscspn", scope: !360, file: !360, line: 187, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!485 = !DISubroutineType(types: !486)
!486 = !{!125, !221, !221}
!487 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !488, line: 182)
!488 = !DISubprogram(name: "wcsftime", scope: !360, file: !360, line: 835, type: !489, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!489 = !DISubroutineType(types: !490)
!490 = !{!125, !173, !125, !220, !491}
!491 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !492)
!492 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !493, size: 64)
!493 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !494)
!494 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "tm", file: !360, line: 83, flags: DIFlagFwdDecl, identifier: "_ZTS2tm")
!495 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !496, line: 183)
!496 = !DISubprogram(name: "wcslen", scope: !360, file: !360, line: 222, type: !497, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!497 = !DISubroutineType(types: !498)
!498 = !{!125, !221}
!499 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !500, line: 184)
!500 = !DISubprogram(name: "wcsncat", scope: !360, file: !360, line: 101, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!501 = !DISubroutineType(types: !502)
!502 = !{!174, !173, !220, !125}
!503 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !504, line: 185)
!504 = !DISubprogram(name: "wcsncmp", scope: !360, file: !360, line: 109, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!505 = !DISubroutineType(types: !506)
!506 = !{!82, !221, !221, !125}
!507 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !508, line: 186)
!508 = !DISubprogram(name: "wcsncpy", scope: !360, file: !360, line: 92, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!509 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !510, line: 187)
!510 = !DISubprogram(name: "wcsrtombs", scope: !360, file: !360, line: 343, type: !511, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!511 = !DISubroutineType(types: !512)
!512 = !{!125, !219, !513, !125, !404}
!513 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !514)
!514 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !221, size: 64)
!515 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !516, line: 188)
!516 = !DISubprogram(name: "wcsspn", scope: !360, file: !360, line: 191, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!517 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !518, line: 189)
!518 = !DISubprogram(name: "wcstod", scope: !360, file: !360, line: 377, type: !519, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!519 = !DISubroutineType(types: !520)
!520 = !{!108, !220, !521}
!521 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !522)
!522 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !174, size: 64)
!523 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 191)
!524 = !DISubprogram(name: "wcstof", scope: !360, file: !360, line: 382, type: !525, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!525 = !DISubroutineType(types: !526)
!526 = !{!262, !220, !521}
!527 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !528, line: 193)
!528 = !DISubprogram(name: "wcstok", scope: !360, file: !360, line: 217, type: !529, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!529 = !DISubroutineType(types: !530)
!530 = !{!174, !173, !220, !521}
!531 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !532, line: 194)
!532 = !DISubprogram(name: "wcstol", scope: !360, file: !360, line: 428, type: !533, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!533 = !DISubroutineType(types: !534)
!534 = !{!91, !220, !521, !82}
!535 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !536, line: 195)
!536 = !DISubprogram(name: "wcstoul", scope: !360, file: !360, line: 433, type: !537, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!537 = !DISubroutineType(types: !538)
!538 = !{!127, !220, !521, !82}
!539 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !540, line: 196)
!540 = !DISubprogram(name: "wcsxfrm", scope: !360, file: !360, line: 135, type: !541, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!541 = !DISubroutineType(types: !542)
!542 = !{!125, !173, !220, !125}
!543 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !544, line: 197)
!544 = !DISubprogram(name: "wctob", scope: !360, file: !360, line: 288, type: !545, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!545 = !DISubroutineType(types: !546)
!546 = !{!82, !356}
!547 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !548, line: 198)
!548 = !DISubprogram(name: "wmemcmp", scope: !360, file: !360, line: 258, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!549 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !550, line: 199)
!550 = !DISubprogram(name: "wmemcpy", scope: !360, file: !360, line: 262, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!551 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !552, line: 200)
!552 = !DISubprogram(name: "wmemmove", scope: !360, file: !360, line: 267, type: !553, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!553 = !DISubroutineType(types: !554)
!554 = !{!174, !174, !221, !125}
!555 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !556, line: 201)
!556 = !DISubprogram(name: "wmemset", scope: !360, file: !360, line: 271, type: !557, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!557 = !DISubroutineType(types: !558)
!558 = !{!174, !174, !175, !125}
!559 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !560, line: 202)
!560 = !DISubprogram(name: "wprintf", scope: !360, file: !360, line: 587, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!561 = !DISubroutineType(types: !562)
!562 = !{!82, !220, null}
!563 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !564, line: 203)
!564 = !DISubprogram(name: "wscanf", scope: !360, file: !360, line: 628, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!565 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !566, line: 204)
!566 = !DISubprogram(name: "wcschr", scope: !360, file: !360, line: 164, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!567 = !DISubroutineType(types: !568)
!568 = !{!174, !221, !175}
!569 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !570, line: 205)
!570 = !DISubprogram(name: "wcspbrk", scope: !360, file: !360, line: 201, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!571 = !DISubroutineType(types: !572)
!572 = !{!174, !221, !221}
!573 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !574, line: 206)
!574 = !DISubprogram(name: "wcsrchr", scope: !360, file: !360, line: 174, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!575 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !576, line: 207)
!576 = !DISubprogram(name: "wcsstr", scope: !360, file: !360, line: 212, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!577 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !578, line: 208)
!578 = !DISubprogram(name: "wmemchr", scope: !360, file: !360, line: 253, type: !579, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!579 = !DISubroutineType(types: !580)
!580 = !{!174, !221, !175, !125}
!581 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !582, line: 248)
!582 = !DISubprogram(name: "wcstold", scope: !360, file: !360, line: 384, type: !583, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!583 = !DISubroutineType(types: !584)
!584 = !{!267, !220, !521}
!585 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !586, line: 257)
!586 = !DISubprogram(name: "wcstoll", scope: !360, file: !360, line: 441, type: !587, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!587 = !DISubroutineType(types: !588)
!588 = !{!233, !220, !521, !82}
!589 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !590, line: 258)
!590 = !DISubprogram(name: "wcstoull", scope: !360, file: !360, line: 448, type: !591, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!591 = !DISubroutineType(types: !592)
!592 = !{!257, !220, !521, !82}
!593 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 264)
!594 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 265)
!595 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 266)
!596 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 280)
!597 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 283)
!598 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 286)
!599 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 289)
!600 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 293)
!601 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 294)
!602 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 295)
!603 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !604, line: 48)
!604 = !DIDerivedType(tag: DW_TAG_typedef, name: "int8_t", file: !9, line: 235, baseType: !605)
!605 = !DIBasicType(name: "signed char", size: 8, encoding: DW_ATE_signed_char)
!606 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !607, line: 49)
!607 = !DIDerivedType(tag: DW_TAG_typedef, name: "int16_t", file: !9, line: 216, baseType: !608)
!608 = !DIBasicType(name: "short", size: 16, encoding: DW_ATE_signed)
!609 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !610, line: 50)
!610 = !DIDerivedType(tag: DW_TAG_typedef, name: "int32_t", file: !9, line: 178, baseType: !82)
!611 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !612, line: 51)
!612 = !DIDerivedType(tag: DW_TAG_typedef, name: "int64_t", file: !9, line: 107, baseType: !91)
!613 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !614, line: 53)
!614 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast8_t", file: !9, line: 245, baseType: !604)
!615 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !616, line: 54)
!616 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast16_t", file: !9, line: 228, baseType: !607)
!617 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !618, line: 55)
!618 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast32_t", file: !9, line: 197, baseType: !610)
!619 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !620, line: 56)
!620 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast64_t", file: !9, line: 123, baseType: !612)
!621 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !622, line: 58)
!622 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least8_t", file: !9, line: 243, baseType: !604)
!623 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !624, line: 59)
!624 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least16_t", file: !9, line: 226, baseType: !607)
!625 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !626, line: 60)
!626 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least32_t", file: !9, line: 195, baseType: !610)
!627 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !628, line: 61)
!628 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least64_t", file: !9, line: 121, baseType: !612)
!629 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !630, line: 63)
!630 = !DIDerivedType(tag: DW_TAG_typedef, name: "intmax_t", file: !9, line: 276, baseType: !91)
!631 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !632, line: 64)
!632 = !DIDerivedType(tag: DW_TAG_typedef, name: "intptr_t", file: !9, line: 263, baseType: !612)
!633 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !62, line: 66)
!634 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !28, line: 67)
!635 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !8, line: 68)
!636 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !637, line: 69)
!637 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint64_t", file: !9, line: 109, baseType: !127)
!638 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !639, line: 71)
!639 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast8_t", file: !9, line: 246, baseType: !62)
!640 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !641, line: 72)
!641 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast16_t", file: !9, line: 229, baseType: !28)
!642 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !643, line: 73)
!643 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast32_t", file: !9, line: 198, baseType: !8)
!644 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !645, line: 74)
!645 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast64_t", file: !9, line: 124, baseType: !637)
!646 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !647, line: 76)
!647 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least8_t", file: !9, line: 244, baseType: !62)
!648 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !649, line: 77)
!649 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least16_t", file: !9, line: 227, baseType: !28)
!650 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !651, line: 78)
!651 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least32_t", file: !9, line: 196, baseType: !8)
!652 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !653, line: 79)
!653 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least64_t", file: !9, line: 122, baseType: !637)
!654 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !655, line: 81)
!655 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintmax_t", file: !9, line: 277, baseType: !127)
!656 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !657, line: 82)
!657 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintptr_t", file: !9, line: 270, baseType: !637)
!658 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !659, line: 44)
!659 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", scope: !75, file: !76, line: 231, baseType: !127)
!660 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !661, line: 45)
!661 = !DIDerivedType(tag: DW_TAG_typedef, name: "ptrdiff_t", scope: !75, file: !76, line: 232, baseType: !91)
!662 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !663, line: 53)
!663 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "lconv", file: !664, line: 51, flags: DIFlagFwdDecl, identifier: "_ZTS5lconv")
!664 = !DIFile(filename: "/usr/include/locale.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!665 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !666, line: 54)
!666 = !DISubprogram(name: "setlocale", scope: !664, file: !664, line: 122, type: !667, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!667 = !DISubroutineType(types: !668)
!668 = !{!152, !82, !109}
!669 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !670, line: 55)
!670 = !DISubprogram(name: "localeconv", scope: !664, file: !664, line: 125, type: !671, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!671 = !DISubroutineType(types: !672)
!672 = !{!673}
!673 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !663, size: 64)
!674 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !675, line: 64)
!675 = !DISubprogram(name: "isalnum", scope: !676, file: !676, line: 108, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!676 = !DIFile(filename: "/usr/include/ctype.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!677 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !678, line: 65)
!678 = !DISubprogram(name: "isalpha", scope: !676, file: !676, line: 109, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!679 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !680, line: 66)
!680 = !DISubprogram(name: "iscntrl", scope: !676, file: !676, line: 110, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!681 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !682, line: 67)
!682 = !DISubprogram(name: "isdigit", scope: !676, file: !676, line: 111, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!683 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !684, line: 68)
!684 = !DISubprogram(name: "isgraph", scope: !676, file: !676, line: 113, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!685 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !686, line: 69)
!686 = !DISubprogram(name: "islower", scope: !676, file: !676, line: 112, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!687 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !688, line: 70)
!688 = !DISubprogram(name: "isprint", scope: !676, file: !676, line: 114, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!689 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !690, line: 71)
!690 = !DISubprogram(name: "ispunct", scope: !676, file: !676, line: 115, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!691 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !692, line: 72)
!692 = !DISubprogram(name: "isspace", scope: !676, file: !676, line: 116, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!693 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !694, line: 73)
!694 = !DISubprogram(name: "isupper", scope: !676, file: !676, line: 117, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!695 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !696, line: 74)
!696 = !DISubprogram(name: "isxdigit", scope: !676, file: !676, line: 118, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!697 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !698, line: 75)
!698 = !DISubprogram(name: "tolower", scope: !676, file: !676, line: 122, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!699 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !700, line: 76)
!700 = !DISubprogram(name: "toupper", scope: !676, file: !676, line: 125, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!701 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !702, line: 87)
!702 = !DISubprogram(name: "isblank", scope: !676, file: !676, line: 130, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!703 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !704, line: 98)
!704 = !DIDerivedType(tag: DW_TAG_typedef, name: "FILE", file: !705, line: 7, baseType: !370)
!705 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!706 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !707, line: 99)
!707 = !DIDerivedType(tag: DW_TAG_typedef, name: "fpos_t", file: !708, line: 78, baseType: !709)
!708 = !DIFile(filename: "/usr/include/stdio.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!709 = !DIDerivedType(tag: DW_TAG_typedef, name: "_G_fpos_t", file: !710, line: 30, baseType: !711)
!710 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/_G_config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!711 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !710, line: 26, flags: DIFlagFwdDecl, identifier: "_ZTS9_G_fpos_t")
!712 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !713, line: 101)
!713 = !DISubprogram(name: "clearerr", scope: !708, file: !708, line: 757, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!714 = !DISubroutineType(types: !715)
!715 = !{null, !716}
!716 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !704, size: 64)
!717 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !718, line: 102)
!718 = !DISubprogram(name: "fclose", scope: !708, file: !708, line: 199, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!719 = !DISubroutineType(types: !720)
!720 = !{!82, !716}
!721 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !722, line: 103)
!722 = !DISubprogram(name: "feof", scope: !708, file: !708, line: 759, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!723 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !724, line: 104)
!724 = !DISubprogram(name: "ferror", scope: !708, file: !708, line: 761, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!725 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !726, line: 105)
!726 = !DISubprogram(name: "fflush", scope: !708, file: !708, line: 204, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!727 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !728, line: 106)
!728 = !DISubprogram(name: "fgetc", scope: !708, file: !708, line: 477, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!729 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !730, line: 107)
!730 = !DISubprogram(name: "fgetpos", scope: !708, file: !708, line: 731, type: !731, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!731 = !DISubroutineType(types: !732)
!732 = !{!82, !733, !734}
!733 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !716)
!734 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !735)
!735 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !707, size: 64)
!736 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !737, line: 108)
!737 = !DISubprogram(name: "fgets", scope: !708, file: !708, line: 564, type: !738, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!738 = !DISubroutineType(types: !739)
!739 = !{!152, !219, !82, !733}
!740 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !741, line: 109)
!741 = !DISubprogram(name: "fopen", scope: !708, file: !708, line: 232, type: !742, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!742 = !DISubroutineType(types: !743)
!743 = !{!716, !176, !176}
!744 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !745, line: 110)
!745 = !DISubprogram(name: "fprintf", scope: !708, file: !708, line: 312, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!746 = !DISubroutineType(types: !747)
!747 = !{!82, !733, !176, null}
!748 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !749, line: 111)
!749 = !DISubprogram(name: "fputc", scope: !708, file: !708, line: 517, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!750 = !DISubroutineType(types: !751)
!751 = !{!82, !82, !716}
!752 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !753, line: 112)
!753 = !DISubprogram(name: "fputs", scope: !708, file: !708, line: 626, type: !754, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!754 = !DISubroutineType(types: !755)
!755 = !{!82, !176, !733}
!756 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !757, line: 113)
!757 = !DISubprogram(name: "fread", scope: !708, file: !708, line: 646, type: !758, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!758 = !DISubroutineType(types: !759)
!759 = !{!125, !760, !125, !125, !733}
!760 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !124)
!761 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !762, line: 114)
!762 = !DISubprogram(name: "freopen", scope: !708, file: !708, line: 238, type: !763, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!763 = !DISubroutineType(types: !764)
!764 = !{!716, !176, !176, !733}
!765 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !766, line: 115)
!766 = !DISubprogram(name: "fscanf", scope: !708, file: !708, line: 377, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!767 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !768, line: 116)
!768 = !DISubprogram(name: "fseek", scope: !708, file: !708, line: 684, type: !769, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!769 = !DISubroutineType(types: !770)
!770 = !{!82, !716, !91, !82}
!771 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !772, line: 117)
!772 = !DISubprogram(name: "fsetpos", scope: !708, file: !708, line: 736, type: !773, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!773 = !DISubroutineType(types: !774)
!774 = !{!82, !716, !775}
!775 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !776, size: 64)
!776 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !707)
!777 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !778, line: 118)
!778 = !DISubprogram(name: "ftell", scope: !708, file: !708, line: 689, type: !779, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!779 = !DISubroutineType(types: !780)
!780 = !{!91, !716}
!781 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !782, line: 119)
!782 = !DISubprogram(name: "fwrite", scope: !708, file: !708, line: 652, type: !783, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!783 = !DISubroutineType(types: !784)
!784 = !{!125, !785, !125, !125, !733}
!785 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !68)
!786 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !787, line: 120)
!787 = !DISubprogram(name: "getc", scope: !708, file: !708, line: 478, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!788 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !789, line: 121)
!789 = !DISubprogram(name: "getchar", scope: !708, file: !708, line: 484, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!790 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !791, line: 124)
!791 = !DISubprogram(name: "gets", scope: !708, file: !708, line: 577, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!792 = !DISubroutineType(types: !793)
!793 = !{!152, !152}
!794 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !795, line: 126)
!795 = !DISubprogram(name: "perror", scope: !708, file: !708, line: 775, type: !796, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!796 = !DISubroutineType(types: !797)
!797 = !{null, !109}
!798 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !799, line: 127)
!799 = !DISubprogram(name: "printf", scope: !708, file: !708, line: 318, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!800 = !DISubroutineType(types: !801)
!801 = !{!82, !176, null}
!802 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !803, line: 128)
!803 = !DISubprogram(name: "putc", scope: !708, file: !708, line: 518, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!804 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !805, line: 129)
!805 = !DISubprogram(name: "putchar", scope: !708, file: !708, line: 524, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!806 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !807, line: 130)
!807 = !DISubprogram(name: "puts", scope: !708, file: !708, line: 632, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!808 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !809, line: 131)
!809 = !DISubprogram(name: "remove", scope: !708, file: !708, line: 144, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!810 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !811, line: 132)
!811 = !DISubprogram(name: "rename", scope: !708, file: !708, line: 146, type: !812, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!812 = !DISubroutineType(types: !813)
!813 = !{!82, !109, !109}
!814 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !815, line: 133)
!815 = !DISubprogram(name: "rewind", scope: !708, file: !708, line: 694, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!816 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !817, line: 134)
!817 = !DISubprogram(name: "scanf", scope: !708, file: !708, line: 383, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!818 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !819, line: 135)
!819 = !DISubprogram(name: "setbuf", scope: !708, file: !708, line: 290, type: !820, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!820 = !DISubroutineType(types: !821)
!821 = !{null, !733, !219}
!822 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !823, line: 136)
!823 = !DISubprogram(name: "setvbuf", scope: !708, file: !708, line: 294, type: !824, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!824 = !DISubroutineType(types: !825)
!825 = !{!82, !733, !219, !82, !125}
!826 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !827, line: 137)
!827 = !DISubprogram(name: "sprintf", scope: !708, file: !708, line: 320, type: !828, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!828 = !DISubroutineType(types: !829)
!829 = !{!82, !219, !176, null}
!830 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !831, line: 138)
!831 = !DISubprogram(name: "sscanf", scope: !708, file: !708, line: 385, type: !832, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!832 = !DISubroutineType(types: !833)
!833 = !{!82, !176, !176, null}
!834 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !835, line: 139)
!835 = !DISubprogram(name: "tmpfile", scope: !708, file: !708, line: 159, type: !836, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!836 = !DISubroutineType(types: !837)
!837 = !{!716}
!838 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !839, line: 141)
!839 = !DISubprogram(name: "tmpnam", scope: !708, file: !708, line: 173, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!840 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !841, line: 143)
!841 = !DISubprogram(name: "ungetc", scope: !708, file: !708, line: 639, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!842 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !843, line: 144)
!843 = !DISubprogram(name: "vfprintf", scope: !708, file: !708, line: 327, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!844 = !DISubroutineType(types: !845)
!845 = !{!82, !733, !176, !444}
!846 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !847, line: 145)
!847 = !DISubprogram(name: "vprintf", scope: !708, file: !708, line: 333, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!848 = !DISubroutineType(types: !849)
!849 = !{!82, !176, !444}
!850 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !851, line: 146)
!851 = !DISubprogram(name: "vsprintf", scope: !708, file: !708, line: 335, type: !852, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!852 = !DISubroutineType(types: !853)
!853 = !{!82, !219, !176, !444}
!854 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !855, line: 175)
!855 = !DISubprogram(name: "snprintf", scope: !708, file: !708, line: 340, type: !856, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!856 = !DISubroutineType(types: !857)
!857 = !{!82, !219, !125, !176, null}
!858 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !859, line: 176)
!859 = !DISubprogram(name: "vfscanf", scope: !708, file: !708, line: 420, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!860 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !861, line: 177)
!861 = !DISubprogram(name: "vscanf", scope: !708, file: !708, line: 428, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!862 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !863, line: 178)
!863 = !DISubprogram(name: "vsnprintf", scope: !708, file: !708, line: 344, type: !864, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!864 = !DISubroutineType(types: !865)
!865 = !{!82, !219, !125, !176, !444}
!866 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !867, line: 179)
!867 = !DISubprogram(name: "vsscanf", scope: !708, file: !708, line: 432, type: !868, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!868 = !DISubroutineType(types: !869)
!869 = !{!82, !176, !176, !444}
!870 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !855, line: 185)
!871 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !859, line: 186)
!872 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !861, line: 187)
!873 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !863, line: 188)
!874 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !867, line: 189)
!875 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !876, line: 83)
!876 = !DISubprogram(name: "acos", scope: !877, file: !877, line: 53, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!877 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/mathcalls.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!878 = !DISubroutineType(types: !879)
!879 = !{!108, !108}
!880 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !881, line: 102)
!881 = !DISubprogram(name: "asin", scope: !877, file: !877, line: 55, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!882 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !883, line: 121)
!883 = !DISubprogram(name: "atan", scope: !877, file: !877, line: 57, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!884 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !885, line: 140)
!885 = !DISubprogram(name: "atan2", scope: !877, file: !877, line: 59, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!886 = !DISubroutineType(types: !887)
!887 = !{!108, !108, !108}
!888 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !889, line: 161)
!889 = !DISubprogram(name: "ceil", scope: !877, file: !877, line: 159, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!890 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !891, line: 180)
!891 = !DISubprogram(name: "cos", scope: !877, file: !877, line: 62, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!892 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !893, line: 199)
!893 = !DISubprogram(name: "cosh", scope: !877, file: !877, line: 71, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!894 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !895, line: 218)
!895 = !DISubprogram(name: "exp", scope: !877, file: !877, line: 95, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!896 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !897, line: 237)
!897 = !DISubprogram(name: "fabs", scope: !877, file: !877, line: 162, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!898 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !899, line: 256)
!899 = !DISubprogram(name: "floor", scope: !877, file: !877, line: 165, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!900 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !901, line: 275)
!901 = !DISubprogram(name: "fmod", scope: !877, file: !877, line: 168, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!902 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !903, line: 296)
!903 = !DISubprogram(name: "frexp", scope: !877, file: !877, line: 98, type: !904, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!904 = !DISubroutineType(types: !905)
!905 = !{!108, !108, !906}
!906 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !82, size: 64)
!907 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !908, line: 315)
!908 = !DISubprogram(name: "ldexp", scope: !877, file: !877, line: 101, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!909 = !DISubroutineType(types: !910)
!910 = !{!108, !108, !82}
!911 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !912, line: 334)
!912 = !DISubprogram(name: "log", scope: !877, file: !877, line: 104, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!913 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !914, line: 353)
!914 = !DISubprogram(name: "log10", scope: !877, file: !877, line: 107, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!915 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !916, line: 372)
!916 = !DISubprogram(name: "modf", scope: !877, file: !877, line: 110, type: !917, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!917 = !DISubroutineType(types: !918)
!918 = !{!108, !108, !919}
!919 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !108, size: 64)
!920 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !921, line: 384)
!921 = !DISubprogram(name: "pow", scope: !877, file: !877, line: 140, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!922 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !923, line: 421)
!923 = !DISubprogram(name: "sin", scope: !877, file: !877, line: 64, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!924 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !925, line: 440)
!925 = !DISubprogram(name: "sinh", scope: !877, file: !877, line: 73, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!926 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !927, line: 459)
!927 = !DISubprogram(name: "sqrt", scope: !877, file: !877, line: 143, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!928 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !929, line: 478)
!929 = !DISubprogram(name: "tan", scope: !877, file: !877, line: 66, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!930 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !931, line: 497)
!931 = !DISubprogram(name: "tanh", scope: !877, file: !877, line: 75, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!932 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !933, line: 1080)
!933 = !DIDerivedType(tag: DW_TAG_typedef, name: "double_t", file: !934, line: 150, baseType: !108)
!934 = !DIFile(filename: "/usr/include/math.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!935 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !936, line: 1081)
!936 = !DIDerivedType(tag: DW_TAG_typedef, name: "float_t", file: !934, line: 149, baseType: !262)
!937 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !938, line: 1084)
!938 = !DISubprogram(name: "acosh", scope: !877, file: !877, line: 85, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!939 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !940, line: 1085)
!940 = !DISubprogram(name: "acoshf", scope: !877, file: !877, line: 85, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!941 = !DISubroutineType(types: !942)
!942 = !{!262, !262}
!943 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !944, line: 1086)
!944 = !DISubprogram(name: "acoshl", scope: !877, file: !877, line: 85, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!945 = !DISubroutineType(types: !946)
!946 = !{!267, !267}
!947 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !948, line: 1088)
!948 = !DISubprogram(name: "asinh", scope: !877, file: !877, line: 87, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!949 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !950, line: 1089)
!950 = !DISubprogram(name: "asinhf", scope: !877, file: !877, line: 87, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!951 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !952, line: 1090)
!952 = !DISubprogram(name: "asinhl", scope: !877, file: !877, line: 87, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!953 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !954, line: 1092)
!954 = !DISubprogram(name: "atanh", scope: !877, file: !877, line: 89, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!955 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !956, line: 1093)
!956 = !DISubprogram(name: "atanhf", scope: !877, file: !877, line: 89, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!957 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !958, line: 1094)
!958 = !DISubprogram(name: "atanhl", scope: !877, file: !877, line: 89, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!959 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !960, line: 1096)
!960 = !DISubprogram(name: "cbrt", scope: !877, file: !877, line: 152, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!961 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !962, line: 1097)
!962 = !DISubprogram(name: "cbrtf", scope: !877, file: !877, line: 152, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!963 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !964, line: 1098)
!964 = !DISubprogram(name: "cbrtl", scope: !877, file: !877, line: 152, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!965 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !966, line: 1100)
!966 = !DISubprogram(name: "copysign", scope: !877, file: !877, line: 196, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!967 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !968, line: 1101)
!968 = !DISubprogram(name: "copysignf", scope: !877, file: !877, line: 196, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!969 = !DISubroutineType(types: !970)
!970 = !{!262, !262, !262}
!971 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !972, line: 1102)
!972 = !DISubprogram(name: "copysignl", scope: !877, file: !877, line: 196, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!973 = !DISubroutineType(types: !974)
!974 = !{!267, !267, !267}
!975 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !976, line: 1104)
!976 = !DISubprogram(name: "erf", scope: !877, file: !877, line: 228, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!977 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !978, line: 1105)
!978 = !DISubprogram(name: "erff", scope: !877, file: !877, line: 228, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!979 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !980, line: 1106)
!980 = !DISubprogram(name: "erfl", scope: !877, file: !877, line: 228, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!981 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !982, line: 1108)
!982 = !DISubprogram(name: "erfc", scope: !877, file: !877, line: 229, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!983 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !984, line: 1109)
!984 = !DISubprogram(name: "erfcf", scope: !877, file: !877, line: 229, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!985 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !986, line: 1110)
!986 = !DISubprogram(name: "erfcl", scope: !877, file: !877, line: 229, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!987 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !988, line: 1112)
!988 = !DISubprogram(name: "exp2", scope: !877, file: !877, line: 130, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!989 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !990, line: 1113)
!990 = !DISubprogram(name: "exp2f", scope: !877, file: !877, line: 130, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!991 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !992, line: 1114)
!992 = !DISubprogram(name: "exp2l", scope: !877, file: !877, line: 130, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!993 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !994, line: 1116)
!994 = !DISubprogram(name: "expm1", scope: !877, file: !877, line: 119, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!995 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !996, line: 1117)
!996 = !DISubprogram(name: "expm1f", scope: !877, file: !877, line: 119, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!997 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !998, line: 1118)
!998 = !DISubprogram(name: "expm1l", scope: !877, file: !877, line: 119, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!999 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1000, line: 1120)
!1000 = !DISubprogram(name: "fdim", scope: !877, file: !877, line: 326, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1001 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1002, line: 1121)
!1002 = !DISubprogram(name: "fdimf", scope: !877, file: !877, line: 326, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1003 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1004, line: 1122)
!1004 = !DISubprogram(name: "fdiml", scope: !877, file: !877, line: 326, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1005 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1006, line: 1124)
!1006 = !DISubprogram(name: "fma", scope: !877, file: !877, line: 335, type: !1007, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1007 = !DISubroutineType(types: !1008)
!1008 = !{!108, !108, !108, !108}
!1009 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1010, line: 1125)
!1010 = !DISubprogram(name: "fmaf", scope: !877, file: !877, line: 335, type: !1011, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1011 = !DISubroutineType(types: !1012)
!1012 = !{!262, !262, !262, !262}
!1013 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1014, line: 1126)
!1014 = !DISubprogram(name: "fmal", scope: !877, file: !877, line: 335, type: !1015, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1015 = !DISubroutineType(types: !1016)
!1016 = !{!267, !267, !267, !267}
!1017 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1018, line: 1128)
!1018 = !DISubprogram(name: "fmax", scope: !877, file: !877, line: 329, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1019 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1020, line: 1129)
!1020 = !DISubprogram(name: "fmaxf", scope: !877, file: !877, line: 329, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1021 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1022, line: 1130)
!1022 = !DISubprogram(name: "fmaxl", scope: !877, file: !877, line: 329, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1023 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1024, line: 1132)
!1024 = !DISubprogram(name: "fmin", scope: !877, file: !877, line: 332, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1025 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1026, line: 1133)
!1026 = !DISubprogram(name: "fminf", scope: !877, file: !877, line: 332, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1027 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1028, line: 1134)
!1028 = !DISubprogram(name: "fminl", scope: !877, file: !877, line: 332, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1029 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1030, line: 1136)
!1030 = !DISubprogram(name: "hypot", scope: !877, file: !877, line: 147, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1031 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1032, line: 1137)
!1032 = !DISubprogram(name: "hypotf", scope: !877, file: !877, line: 147, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1033 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1034, line: 1138)
!1034 = !DISubprogram(name: "hypotl", scope: !877, file: !877, line: 147, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1035 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1036, line: 1140)
!1036 = !DISubprogram(name: "ilogb", scope: !877, file: !877, line: 280, type: !1037, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1037 = !DISubroutineType(types: !1038)
!1038 = !{!82, !108}
!1039 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1040, line: 1141)
!1040 = !DISubprogram(name: "ilogbf", scope: !877, file: !877, line: 280, type: !1041, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1041 = !DISubroutineType(types: !1042)
!1042 = !{!82, !262}
!1043 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1044, line: 1142)
!1044 = !DISubprogram(name: "ilogbl", scope: !877, file: !877, line: 280, type: !1045, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1045 = !DISubroutineType(types: !1046)
!1046 = !{!82, !267}
!1047 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1048, line: 1144)
!1048 = !DISubprogram(name: "lgamma", scope: !877, file: !877, line: 230, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1049 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1050, line: 1145)
!1050 = !DISubprogram(name: "lgammaf", scope: !877, file: !877, line: 230, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1051 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1052, line: 1146)
!1052 = !DISubprogram(name: "lgammal", scope: !877, file: !877, line: 230, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1053 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1054, line: 1149)
!1054 = !DISubprogram(name: "llrint", scope: !877, file: !877, line: 316, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1055 = !DISubroutineType(types: !1056)
!1056 = !{!233, !108}
!1057 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1058, line: 1150)
!1058 = !DISubprogram(name: "llrintf", scope: !877, file: !877, line: 316, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1059 = !DISubroutineType(types: !1060)
!1060 = !{!233, !262}
!1061 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1062, line: 1151)
!1062 = !DISubprogram(name: "llrintl", scope: !877, file: !877, line: 316, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1063 = !DISubroutineType(types: !1064)
!1064 = !{!233, !267}
!1065 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1066, line: 1153)
!1066 = !DISubprogram(name: "llround", scope: !877, file: !877, line: 322, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1067 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1068, line: 1154)
!1068 = !DISubprogram(name: "llroundf", scope: !877, file: !877, line: 322, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1069 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1070, line: 1155)
!1070 = !DISubprogram(name: "llroundl", scope: !877, file: !877, line: 322, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1071 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1072, line: 1158)
!1072 = !DISubprogram(name: "log1p", scope: !877, file: !877, line: 122, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1073 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1074, line: 1159)
!1074 = !DISubprogram(name: "log1pf", scope: !877, file: !877, line: 122, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1075 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1076, line: 1160)
!1076 = !DISubprogram(name: "log1pl", scope: !877, file: !877, line: 122, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1077 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1078, line: 1162)
!1078 = !DISubprogram(name: "log2", scope: !877, file: !877, line: 133, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1079 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1080, line: 1163)
!1080 = !DISubprogram(name: "log2f", scope: !877, file: !877, line: 133, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1081 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1082, line: 1164)
!1082 = !DISubprogram(name: "log2l", scope: !877, file: !877, line: 133, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1083 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1084, line: 1166)
!1084 = !DISubprogram(name: "logb", scope: !877, file: !877, line: 125, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1085 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1086, line: 1167)
!1086 = !DISubprogram(name: "logbf", scope: !877, file: !877, line: 125, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1087 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1088, line: 1168)
!1088 = !DISubprogram(name: "logbl", scope: !877, file: !877, line: 125, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1089 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1090, line: 1170)
!1090 = !DISubprogram(name: "lrint", scope: !877, file: !877, line: 314, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1091 = !DISubroutineType(types: !1092)
!1092 = !{!91, !108}
!1093 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1094, line: 1171)
!1094 = !DISubprogram(name: "lrintf", scope: !877, file: !877, line: 314, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1095 = !DISubroutineType(types: !1096)
!1096 = !{!91, !262}
!1097 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1098, line: 1172)
!1098 = !DISubprogram(name: "lrintl", scope: !877, file: !877, line: 314, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1099 = !DISubroutineType(types: !1100)
!1100 = !{!91, !267}
!1101 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1102, line: 1174)
!1102 = !DISubprogram(name: "lround", scope: !877, file: !877, line: 320, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1103 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1104, line: 1175)
!1104 = !DISubprogram(name: "lroundf", scope: !877, file: !877, line: 320, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1105 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1106, line: 1176)
!1106 = !DISubprogram(name: "lroundl", scope: !877, file: !877, line: 320, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1107 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1108, line: 1178)
!1108 = !DISubprogram(name: "nan", scope: !877, file: !877, line: 201, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1109 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1110, line: 1179)
!1110 = !DISubprogram(name: "nanf", scope: !877, file: !877, line: 201, type: !1111, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1111 = !DISubroutineType(types: !1112)
!1112 = !{!262, !109}
!1113 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1114, line: 1180)
!1114 = !DISubprogram(name: "nanl", scope: !877, file: !877, line: 201, type: !1115, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1115 = !DISubroutineType(types: !1116)
!1116 = !{!267, !109}
!1117 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1118, line: 1182)
!1118 = !DISubprogram(name: "nearbyint", scope: !877, file: !877, line: 294, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1119 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1120, line: 1183)
!1120 = !DISubprogram(name: "nearbyintf", scope: !877, file: !877, line: 294, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1121 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1122, line: 1184)
!1122 = !DISubprogram(name: "nearbyintl", scope: !877, file: !877, line: 294, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1123 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1124, line: 1186)
!1124 = !DISubprogram(name: "nextafter", scope: !877, file: !877, line: 259, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1125 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1126, line: 1187)
!1126 = !DISubprogram(name: "nextafterf", scope: !877, file: !877, line: 259, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1127 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1128, line: 1188)
!1128 = !DISubprogram(name: "nextafterl", scope: !877, file: !877, line: 259, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1129 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1130, line: 1190)
!1130 = !DISubprogram(name: "nexttoward", scope: !877, file: !877, line: 261, type: !1131, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1131 = !DISubroutineType(types: !1132)
!1132 = !{!108, !108, !267}
!1133 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1134, line: 1191)
!1134 = !DISubprogram(name: "nexttowardf", scope: !877, file: !877, line: 261, type: !1135, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1135 = !DISubroutineType(types: !1136)
!1136 = !{!262, !262, !267}
!1137 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1138, line: 1192)
!1138 = !DISubprogram(name: "nexttowardl", scope: !877, file: !877, line: 261, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1139 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1140, line: 1194)
!1140 = !DISubprogram(name: "remainder", scope: !877, file: !877, line: 272, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1141 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1142, line: 1195)
!1142 = !DISubprogram(name: "remainderf", scope: !877, file: !877, line: 272, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1143 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1144, line: 1196)
!1144 = !DISubprogram(name: "remainderl", scope: !877, file: !877, line: 272, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1145 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1146, line: 1198)
!1146 = !DISubprogram(name: "remquo", scope: !877, file: !877, line: 307, type: !1147, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1147 = !DISubroutineType(types: !1148)
!1148 = !{!108, !108, !108, !906}
!1149 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1150, line: 1199)
!1150 = !DISubprogram(name: "remquof", scope: !877, file: !877, line: 307, type: !1151, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1151 = !DISubroutineType(types: !1152)
!1152 = !{!262, !262, !262, !906}
!1153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1154, line: 1200)
!1154 = !DISubprogram(name: "remquol", scope: !877, file: !877, line: 307, type: !1155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1155 = !DISubroutineType(types: !1156)
!1156 = !{!267, !267, !267, !906}
!1157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1158, line: 1202)
!1158 = !DISubprogram(name: "rint", scope: !877, file: !877, line: 256, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1159 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1160, line: 1203)
!1160 = !DISubprogram(name: "rintf", scope: !877, file: !877, line: 256, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1162, line: 1204)
!1162 = !DISubprogram(name: "rintl", scope: !877, file: !877, line: 256, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1163 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1164, line: 1206)
!1164 = !DISubprogram(name: "round", scope: !877, file: !877, line: 298, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1166, line: 1207)
!1166 = !DISubprogram(name: "roundf", scope: !877, file: !877, line: 298, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1167 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1168, line: 1208)
!1168 = !DISubprogram(name: "roundl", scope: !877, file: !877, line: 298, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1170, line: 1210)
!1170 = !DISubprogram(name: "scalbln", scope: !877, file: !877, line: 290, type: !1171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1171 = !DISubroutineType(types: !1172)
!1172 = !{!108, !108, !91}
!1173 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1174, line: 1211)
!1174 = !DISubprogram(name: "scalblnf", scope: !877, file: !877, line: 290, type: !1175, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1175 = !DISubroutineType(types: !1176)
!1176 = !{!262, !262, !91}
!1177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1178, line: 1212)
!1178 = !DISubprogram(name: "scalblnl", scope: !877, file: !877, line: 290, type: !1179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1179 = !DISubroutineType(types: !1180)
!1180 = !{!267, !267, !91}
!1181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1182, line: 1214)
!1182 = !DISubprogram(name: "scalbn", scope: !877, file: !877, line: 276, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1183 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1184, line: 1215)
!1184 = !DISubprogram(name: "scalbnf", scope: !877, file: !877, line: 276, type: !1185, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1185 = !DISubroutineType(types: !1186)
!1186 = !{!262, !262, !82}
!1187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1188, line: 1216)
!1188 = !DISubprogram(name: "scalbnl", scope: !877, file: !877, line: 276, type: !1189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1189 = !DISubroutineType(types: !1190)
!1190 = !{!267, !267, !82}
!1191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1192, line: 1218)
!1192 = !DISubprogram(name: "tgamma", scope: !877, file: !877, line: 235, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1193 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1194, line: 1219)
!1194 = !DISubprogram(name: "tgammaf", scope: !877, file: !877, line: 235, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1196, line: 1220)
!1196 = !DISubprogram(name: "tgammal", scope: !877, file: !877, line: 235, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1197 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1198, line: 1222)
!1198 = !DISubprogram(name: "trunc", scope: !877, file: !877, line: 302, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1200, line: 1223)
!1200 = !DISubprogram(name: "truncf", scope: !877, file: !877, line: 302, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1201 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1202, line: 1224)
!1202 = !DISubprogram(name: "truncl", scope: !877, file: !877, line: 302, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1203 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 58)
!1204 = !DIDerivedType(tag: DW_TAG_typedef, name: "fenv_t", file: !1205, line: 94, baseType: !1206)
!1205 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1206 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !1205, line: 75, flags: DIFlagFwdDecl, identifier: "_ZTS6fenv_t")
!1207 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 59)
!1208 = !DIDerivedType(tag: DW_TAG_typedef, name: "fexcept_t", file: !1205, line: 68, baseType: !29)
!1209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 62)
!1210 = !DISubprogram(name: "feclearexcept", scope: !1211, file: !1211, line: 71, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1211 = !DIFile(filename: "/usr/include/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1212 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 63)
!1213 = !DISubprogram(name: "fegetexceptflag", scope: !1211, file: !1211, line: 75, type: !1214, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1214 = !DISubroutineType(types: !1215)
!1215 = !{!82, !1216, !82}
!1216 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1208, size: 64)
!1217 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 64)
!1218 = !DISubprogram(name: "feraiseexcept", scope: !1211, file: !1211, line: 78, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1219 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 65)
!1220 = !DISubprogram(name: "fesetexceptflag", scope: !1211, file: !1211, line: 88, type: !1221, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1221 = !DISubroutineType(types: !1222)
!1222 = !{!82, !1223, !82}
!1223 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1224, size: 64)
!1224 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1208)
!1225 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 66)
!1226 = !DISubprogram(name: "fetestexcept", scope: !1211, file: !1211, line: 92, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 68)
!1228 = !DISubprogram(name: "fegetround", scope: !1211, file: !1211, line: 104, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1229 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 69)
!1230 = !DISubprogram(name: "fesetround", scope: !1211, file: !1211, line: 107, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1231 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 71)
!1232 = !DISubprogram(name: "fegetenv", scope: !1211, file: !1211, line: 114, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1233 = !DISubroutineType(types: !1234)
!1234 = !{!82, !1235}
!1235 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1204, size: 64)
!1236 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 72)
!1237 = !DISubprogram(name: "feholdexcept", scope: !1211, file: !1211, line: 119, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1238 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 73)
!1239 = !DISubprogram(name: "fesetenv", scope: !1211, file: !1211, line: 123, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1240 = !DISubroutineType(types: !1241)
!1241 = !{!82, !1242}
!1242 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1243, size: 64)
!1243 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1204)
!1244 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 74)
!1245 = !DISubprogram(name: "feupdateenv", scope: !1211, file: !1211, line: 128, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1246 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 61)
!1247 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 62)
!1248 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 65)
!1249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 66)
!1250 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 67)
!1251 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 68)
!1252 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 69)
!1253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 71)
!1254 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 72)
!1255 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 74)
!1256 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 75)
!1257 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 76)
!1258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 77)
!1259 = !{i32 2, !"Dwarf Version", i32 4}
!1260 = !{i32 2, !"Debug Info Version", i32 3}
!1261 = distinct !DISubprogram(name: "__remill_basic_block", scope: !2, file: !2, line: 52, type: !1262, isLocal: false, isDefinition: true, scopeLine: 52, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!1262 = !DISubroutineType(types: !1263)
!1263 = !{!1264, !1267, !1950, !1264}
!1264 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1265, size: 64)
!1265 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Memory", file: !1266, line: 36, flags: DIFlagFwdDecl, identifier: "_ZTS6Memory")
!1266 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Types.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1267 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !1268, size: 64)
!1268 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "State", file: !27, line: 742, size: 27008, align: 128, elements: !1269, identifier: "_ZTS5State")
!1269 = !{!1270, !1282, !1491, !1511, !1541, !1566, !1595, !1632, !1642, !1703, !1728, !1752, !1932}
!1270 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1268, baseType: !1271)
!1271 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArchState", file: !1272, line: 21, size: 128, elements: !1273, identifier: "_ZTS9ArchState")
!1272 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1273 = !{!1274, !1275, !1276}
!1274 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call", scope: !1271, file: !1272, line: 23, baseType: !4, size: 32)
!1275 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1271, file: !1272, line: 25, baseType: !8, size: 32, offset: 32)
!1276 = !DIDerivedType(tag: DW_TAG_member, scope: !1271, file: !1272, line: 31, baseType: !1277, size: 64, offset: 64)
!1277 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1271, file: !1272, line: 31, size: 64, elements: !1278, identifier: "_ZTSN9ArchStateUt_E")
!1278 = !{!1279, !1280, !1281}
!1279 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_load", scope: !1277, file: !1272, line: 32, baseType: !637, size: 64)
!1280 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_store", scope: !1277, file: !1272, line: 33, baseType: !637, size: 64)
!1281 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call_vector", scope: !1277, file: !1272, line: 34, baseType: !8, size: 32)
!1282 = !DIDerivedType(tag: DW_TAG_member, name: "vec", scope: !1268, file: !27, line: 747, baseType: !1283, size: 16384, offset: 128)
!1283 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1284, size: 16384, elements: !1369)
!1284 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "VectorReg", file: !27, line: 636, size: 512, align: 128, elements: !1285, identifier: "_ZTS9VectorReg")
!1285 = !{!1286, !1361, !1426}
!1286 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1284, file: !27, line: 637, baseType: !1287, size: 128, align: 128)
!1287 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec128_t", file: !1266, line: 317, size: 128, elements: !1288, identifier: "_ZTS8vec128_t")
!1288 = !{!1289, !1298, !1305, !1312, !1317, !1324, !1329, !1334, !1339, !1344, !1349, !1354}
!1289 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1287, file: !1266, line: 321, baseType: !1290, size: 128)
!1290 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v1_t", file: !1266, line: 205, size: 128, elements: !1291, identifier: "_ZTS11uint128v1_t")
!1291 = !{!1292}
!1292 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1290, file: !1266, line: 205, baseType: !1293, size: 128)
!1293 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 128, elements: !1296)
!1294 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint128_t", file: !1266, line: 46, baseType: !1295)
!1295 = !DIBasicType(name: "unsigned __int128", size: 128, encoding: DW_ATE_unsigned)
!1296 = !{!1297}
!1297 = !DISubrange(count: 1)
!1298 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1287, file: !1266, line: 323, baseType: !1299, size: 128)
!1299 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v16_t", file: !1266, line: 182, size: 128, elements: !1300, identifier: "_ZTS10uint8v16_t")
!1300 = !{!1301}
!1301 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1299, file: !1266, line: 182, baseType: !1302, size: 128)
!1302 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 128, elements: !1303)
!1303 = !{!1304}
!1304 = !DISubrange(count: 16)
!1305 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1287, file: !1266, line: 324, baseType: !1306, size: 128)
!1306 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v8_t", file: !1266, line: 189, size: 128, elements: !1307, identifier: "_ZTS10uint16v8_t")
!1307 = !{!1308}
!1308 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1306, file: !1266, line: 189, baseType: !1309, size: 128)
!1309 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 128, elements: !1310)
!1310 = !{!1311}
!1311 = !DISubrange(count: 8)
!1312 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1287, file: !1266, line: 325, baseType: !1313, size: 128)
!1313 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v4_t", file: !1266, line: 195, size: 128, elements: !1314, identifier: "_ZTS10uint32v4_t")
!1314 = !{!1315}
!1315 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1313, file: !1266, line: 195, baseType: !1316, size: 128)
!1316 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 128, elements: !353)
!1317 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1287, file: !1266, line: 326, baseType: !1318, size: 128)
!1318 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v2_t", file: !1266, line: 200, size: 128, elements: !1319, identifier: "_ZTS10uint64v2_t")
!1319 = !{!1320}
!1320 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1318, file: !1266, line: 200, baseType: !1321, size: 128)
!1321 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 128, elements: !1322)
!1322 = !{!1323}
!1323 = !DISubrange(count: 2)
!1324 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1287, file: !1266, line: 327, baseType: !1325, size: 128)
!1325 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v4_t", file: !1266, line: 242, size: 128, elements: !1326, identifier: "_ZTS11float32v4_t")
!1326 = !{!1327}
!1327 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1325, file: !1266, line: 242, baseType: !1328, size: 128)
!1328 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 128, elements: !353)
!1329 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1287, file: !1266, line: 328, baseType: !1330, size: 128)
!1330 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v2_t", file: !1266, line: 247, size: 128, elements: !1331, identifier: "_ZTS11float64v2_t")
!1331 = !{!1332}
!1332 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1330, file: !1266, line: 247, baseType: !1333, size: 128)
!1333 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 128, elements: !1322)
!1334 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1287, file: !1266, line: 330, baseType: !1335, size: 128)
!1335 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v16_t", file: !1266, line: 213, size: 128, elements: !1336, identifier: "_ZTS9int8v16_t")
!1336 = !{!1337}
!1337 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1335, file: !1266, line: 213, baseType: !1338, size: 128)
!1338 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 128, elements: !1303)
!1339 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1287, file: !1266, line: 331, baseType: !1340, size: 128)
!1340 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v8_t", file: !1266, line: 220, size: 128, elements: !1341, identifier: "_ZTS9int16v8_t")
!1341 = !{!1342}
!1342 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1340, file: !1266, line: 220, baseType: !1343, size: 128)
!1343 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 128, elements: !1310)
!1344 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1287, file: !1266, line: 332, baseType: !1345, size: 128)
!1345 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v4_t", file: !1266, line: 226, size: 128, elements: !1346, identifier: "_ZTS9int32v4_t")
!1346 = !{!1347}
!1347 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1345, file: !1266, line: 226, baseType: !1348, size: 128)
!1348 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 128, elements: !353)
!1349 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1287, file: !1266, line: 333, baseType: !1350, size: 128)
!1350 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v2_t", file: !1266, line: 231, size: 128, elements: !1351, identifier: "_ZTS9int64v2_t")
!1351 = !{!1352}
!1352 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1350, file: !1266, line: 231, baseType: !1353, size: 128)
!1353 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 128, elements: !1322)
!1354 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1287, file: !1266, line: 334, baseType: !1355, size: 128)
!1355 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v1_t", file: !1266, line: 236, size: 128, elements: !1356, identifier: "_ZTS10int128v1_t")
!1356 = !{!1357}
!1357 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1355, file: !1266, line: 236, baseType: !1358, size: 128)
!1358 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 128, elements: !1296)
!1359 = !DIDerivedType(tag: DW_TAG_typedef, name: "int128_t", file: !1266, line: 47, baseType: !1360)
!1360 = !DIBasicType(name: "__int128", size: 128, encoding: DW_ATE_signed)
!1361 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1284, file: !27, line: 638, baseType: !1362, size: 256, align: 128)
!1362 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec256_t", file: !1266, line: 340, size: 256, elements: !1363, identifier: "_ZTS8vec256_t")
!1363 = !{!1364, !1371, !1376, !1381, !1386, !1391, !1396, !1401, !1406, !1411, !1416, !1421}
!1364 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1362, file: !1266, line: 341, baseType: !1365, size: 256)
!1365 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v32_t", file: !1266, line: 183, size: 256, elements: !1366, identifier: "_ZTS10uint8v32_t")
!1366 = !{!1367}
!1367 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1365, file: !1266, line: 183, baseType: !1368, size: 256)
!1368 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 256, elements: !1369)
!1369 = !{!1370}
!1370 = !DISubrange(count: 32)
!1371 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1362, file: !1266, line: 342, baseType: !1372, size: 256)
!1372 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v16_t", file: !1266, line: 190, size: 256, elements: !1373, identifier: "_ZTS11uint16v16_t")
!1373 = !{!1374}
!1374 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1372, file: !1266, line: 190, baseType: !1375, size: 256)
!1375 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 256, elements: !1303)
!1376 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1362, file: !1266, line: 343, baseType: !1377, size: 256)
!1377 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v8_t", file: !1266, line: 196, size: 256, elements: !1378, identifier: "_ZTS10uint32v8_t")
!1378 = !{!1379}
!1379 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1377, file: !1266, line: 196, baseType: !1380, size: 256)
!1380 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 256, elements: !1310)
!1381 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1362, file: !1266, line: 344, baseType: !1382, size: 256)
!1382 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v4_t", file: !1266, line: 201, size: 256, elements: !1383, identifier: "_ZTS10uint64v4_t")
!1383 = !{!1384}
!1384 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1382, file: !1266, line: 201, baseType: !1385, size: 256)
!1385 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 256, elements: !353)
!1386 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1362, file: !1266, line: 345, baseType: !1387, size: 256)
!1387 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v2_t", file: !1266, line: 206, size: 256, elements: !1388, identifier: "_ZTS11uint128v2_t")
!1388 = !{!1389}
!1389 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1387, file: !1266, line: 206, baseType: !1390, size: 256)
!1390 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 256, elements: !1322)
!1391 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1362, file: !1266, line: 346, baseType: !1392, size: 256)
!1392 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v8_t", file: !1266, line: 243, size: 256, elements: !1393, identifier: "_ZTS11float32v8_t")
!1393 = !{!1394}
!1394 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1392, file: !1266, line: 243, baseType: !1395, size: 256)
!1395 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 256, elements: !1310)
!1396 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1362, file: !1266, line: 347, baseType: !1397, size: 256)
!1397 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v4_t", file: !1266, line: 248, size: 256, elements: !1398, identifier: "_ZTS11float64v4_t")
!1398 = !{!1399}
!1399 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1397, file: !1266, line: 248, baseType: !1400, size: 256)
!1400 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 256, elements: !353)
!1401 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1362, file: !1266, line: 349, baseType: !1402, size: 256)
!1402 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v32_t", file: !1266, line: 214, size: 256, elements: !1403, identifier: "_ZTS9int8v32_t")
!1403 = !{!1404}
!1404 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1402, file: !1266, line: 214, baseType: !1405, size: 256)
!1405 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 256, elements: !1369)
!1406 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1362, file: !1266, line: 350, baseType: !1407, size: 256)
!1407 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v16_t", file: !1266, line: 221, size: 256, elements: !1408, identifier: "_ZTS10int16v16_t")
!1408 = !{!1409}
!1409 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1407, file: !1266, line: 221, baseType: !1410, size: 256)
!1410 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 256, elements: !1303)
!1411 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1362, file: !1266, line: 351, baseType: !1412, size: 256)
!1412 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v8_t", file: !1266, line: 227, size: 256, elements: !1413, identifier: "_ZTS9int32v8_t")
!1413 = !{!1414}
!1414 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1412, file: !1266, line: 227, baseType: !1415, size: 256)
!1415 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 256, elements: !1310)
!1416 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1362, file: !1266, line: 352, baseType: !1417, size: 256)
!1417 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v4_t", file: !1266, line: 232, size: 256, elements: !1418, identifier: "_ZTS9int64v4_t")
!1418 = !{!1419}
!1419 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1417, file: !1266, line: 232, baseType: !1420, size: 256)
!1420 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 256, elements: !353)
!1421 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1362, file: !1266, line: 353, baseType: !1422, size: 256)
!1422 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v2_t", file: !1266, line: 237, size: 256, elements: !1423, identifier: "_ZTS10int128v2_t")
!1423 = !{!1424}
!1424 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1422, file: !1266, line: 237, baseType: !1425, size: 256)
!1425 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 256, elements: !1322)
!1426 = !DIDerivedType(tag: DW_TAG_member, name: "zmm", scope: !1284, file: !27, line: 639, baseType: !1427, size: 512, align: 128)
!1427 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec512_t", file: !1266, line: 359, size: 512, elements: !1428, identifier: "_ZTS8vec512_t")
!1428 = !{!1429, !1436, !1441, !1446, !1451, !1456, !1461, !1466, !1471, !1476, !1481, !1486}
!1429 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1427, file: !1266, line: 360, baseType: !1430, size: 512)
!1430 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v64_t", file: !1266, line: 184, size: 512, elements: !1431, identifier: "_ZTS10uint8v64_t")
!1431 = !{!1432}
!1432 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1430, file: !1266, line: 184, baseType: !1433, size: 512)
!1433 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 512, elements: !1434)
!1434 = !{!1435}
!1435 = !DISubrange(count: 64)
!1436 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1427, file: !1266, line: 361, baseType: !1437, size: 512)
!1437 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v32_t", file: !1266, line: 191, size: 512, elements: !1438, identifier: "_ZTS11uint16v32_t")
!1438 = !{!1439}
!1439 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1437, file: !1266, line: 191, baseType: !1440, size: 512)
!1440 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 512, elements: !1369)
!1441 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1427, file: !1266, line: 362, baseType: !1442, size: 512)
!1442 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v16_t", file: !1266, line: 197, size: 512, elements: !1443, identifier: "_ZTS11uint32v16_t")
!1443 = !{!1444}
!1444 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1442, file: !1266, line: 197, baseType: !1445, size: 512)
!1445 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 512, elements: !1303)
!1446 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1427, file: !1266, line: 363, baseType: !1447, size: 512)
!1447 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v8_t", file: !1266, line: 202, size: 512, elements: !1448, identifier: "_ZTS10uint64v8_t")
!1448 = !{!1449}
!1449 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1447, file: !1266, line: 202, baseType: !1450, size: 512)
!1450 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 512, elements: !1310)
!1451 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1427, file: !1266, line: 364, baseType: !1452, size: 512)
!1452 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v4_t", file: !1266, line: 207, size: 512, elements: !1453, identifier: "_ZTS11uint128v4_t")
!1453 = !{!1454}
!1454 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1452, file: !1266, line: 207, baseType: !1455, size: 512)
!1455 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 512, elements: !353)
!1456 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1427, file: !1266, line: 365, baseType: !1457, size: 512)
!1457 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v16_t", file: !1266, line: 244, size: 512, elements: !1458, identifier: "_ZTS12float32v16_t")
!1458 = !{!1459}
!1459 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1457, file: !1266, line: 244, baseType: !1460, size: 512)
!1460 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 512, elements: !1303)
!1461 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1427, file: !1266, line: 366, baseType: !1462, size: 512)
!1462 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v8_t", file: !1266, line: 249, size: 512, elements: !1463, identifier: "_ZTS11float64v8_t")
!1463 = !{!1464}
!1464 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1462, file: !1266, line: 249, baseType: !1465, size: 512)
!1465 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 512, elements: !1310)
!1466 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1427, file: !1266, line: 368, baseType: !1467, size: 512)
!1467 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v64_t", file: !1266, line: 215, size: 512, elements: !1468, identifier: "_ZTS9int8v64_t")
!1468 = !{!1469}
!1469 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1467, file: !1266, line: 215, baseType: !1470, size: 512)
!1470 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 512, elements: !1434)
!1471 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1427, file: !1266, line: 369, baseType: !1472, size: 512)
!1472 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v32_t", file: !1266, line: 222, size: 512, elements: !1473, identifier: "_ZTS10int16v32_t")
!1473 = !{!1474}
!1474 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1472, file: !1266, line: 222, baseType: !1475, size: 512)
!1475 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 512, elements: !1369)
!1476 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1427, file: !1266, line: 370, baseType: !1477, size: 512)
!1477 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v16_t", file: !1266, line: 228, size: 512, elements: !1478, identifier: "_ZTS10int32v16_t")
!1478 = !{!1479}
!1479 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1477, file: !1266, line: 228, baseType: !1480, size: 512)
!1480 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 512, elements: !1303)
!1481 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1427, file: !1266, line: 371, baseType: !1482, size: 512)
!1482 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v8_t", file: !1266, line: 233, size: 512, elements: !1483, identifier: "_ZTS9int64v8_t")
!1483 = !{!1484}
!1484 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1482, file: !1266, line: 233, baseType: !1485, size: 512)
!1485 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 512, elements: !1310)
!1486 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1427, file: !1266, line: 372, baseType: !1487, size: 512)
!1487 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v4_t", file: !1266, line: 238, size: 512, elements: !1488, identifier: "_ZTS10int128v4_t")
!1488 = !{!1489}
!1489 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1487, file: !1266, line: 238, baseType: !1490, size: 512)
!1490 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 512, elements: !353)
!1491 = !DIDerivedType(tag: DW_TAG_member, name: "aflag", scope: !1268, file: !27, line: 751, baseType: !1492, size: 128, align: 64, offset: 16512)
!1492 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArithFlags", file: !27, line: 402, size: 128, align: 64, elements: !1493, identifier: "_ZTS10ArithFlags")
!1493 = !{!1494, !1496, !1497, !1498, !1499, !1500, !1501, !1502, !1503, !1504, !1505, !1506, !1507, !1508, !1509, !1510}
!1494 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1492, file: !27, line: 404, baseType: !1495, size: 8)
!1495 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !62)
!1496 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1492, file: !27, line: 405, baseType: !62, size: 8, offset: 8)
!1497 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1492, file: !27, line: 406, baseType: !1495, size: 8, offset: 16)
!1498 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1492, file: !27, line: 407, baseType: !62, size: 8, offset: 24)
!1499 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1492, file: !27, line: 408, baseType: !1495, size: 8, offset: 32)
!1500 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1492, file: !27, line: 409, baseType: !62, size: 8, offset: 40)
!1501 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1492, file: !27, line: 410, baseType: !1495, size: 8, offset: 48)
!1502 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1492, file: !27, line: 411, baseType: !62, size: 8, offset: 56)
!1503 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1492, file: !27, line: 412, baseType: !1495, size: 8, offset: 64)
!1504 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1492, file: !27, line: 413, baseType: !62, size: 8, offset: 72)
!1505 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1492, file: !27, line: 414, baseType: !1495, size: 8, offset: 80)
!1506 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1492, file: !27, line: 415, baseType: !62, size: 8, offset: 88)
!1507 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1492, file: !27, line: 416, baseType: !1495, size: 8, offset: 96)
!1508 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1492, file: !27, line: 417, baseType: !62, size: 8, offset: 104)
!1509 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1492, file: !27, line: 418, baseType: !1495, size: 8, offset: 112)
!1510 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1492, file: !27, line: 419, baseType: !1495, size: 8, offset: 120)
!1511 = !DIDerivedType(tag: DW_TAG_member, name: "rflag", scope: !1268, file: !27, line: 752, baseType: !1512, size: 64, align: 64, offset: 16640)
!1512 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "Flags", file: !27, line: 366, size: 64, align: 64, elements: !1513, identifier: "_ZTS5Flags")
!1513 = !{!1514, !1515}
!1514 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1512, file: !27, line: 367, baseType: !637, size: 64)
!1515 = !DIDerivedType(tag: DW_TAG_member, scope: !1512, file: !27, line: 368, baseType: !1516, size: 64)
!1516 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1512, file: !27, line: 368, size: 64, elements: !1517, identifier: "_ZTSN5FlagsUt_E")
!1517 = !{!1518, !1519, !1520, !1521, !1522, !1523, !1524, !1525, !1526, !1527, !1528, !1529, !1530, !1531, !1532, !1533, !1534, !1535, !1536, !1537, !1538, !1539, !1540}
!1518 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1516, file: !27, line: 369, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1519 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_1", scope: !1516, file: !27, line: 370, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1520 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1516, file: !27, line: 371, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1521 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0a", scope: !1516, file: !27, line: 372, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1522 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1516, file: !27, line: 374, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1523 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0b", scope: !1516, file: !27, line: 375, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1524 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1516, file: !27, line: 376, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1525 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1516, file: !27, line: 377, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1526 = !DIDerivedType(tag: DW_TAG_member, name: "tf", scope: !1516, file: !27, line: 379, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1527 = !DIDerivedType(tag: DW_TAG_member, name: "_if", scope: !1516, file: !27, line: 380, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1528 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1516, file: !27, line: 381, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1529 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1516, file: !27, line: 382, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1530 = !DIDerivedType(tag: DW_TAG_member, name: "iopl", scope: !1516, file: !27, line: 384, baseType: !8, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1531 = !DIDerivedType(tag: DW_TAG_member, name: "nt", scope: !1516, file: !27, line: 385, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1532 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0c", scope: !1516, file: !27, line: 386, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1533 = !DIDerivedType(tag: DW_TAG_member, name: "rf", scope: !1516, file: !27, line: 388, baseType: !8, size: 1, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1534 = !DIDerivedType(tag: DW_TAG_member, name: "vm", scope: !1516, file: !27, line: 389, baseType: !8, size: 1, offset: 17, flags: DIFlagBitField, extraData: i64 0)
!1535 = !DIDerivedType(tag: DW_TAG_member, name: "ac", scope: !1516, file: !27, line: 390, baseType: !8, size: 1, offset: 18, flags: DIFlagBitField, extraData: i64 0)
!1536 = !DIDerivedType(tag: DW_TAG_member, name: "vif", scope: !1516, file: !27, line: 391, baseType: !8, size: 1, offset: 19, flags: DIFlagBitField, extraData: i64 0)
!1537 = !DIDerivedType(tag: DW_TAG_member, name: "vip", scope: !1516, file: !27, line: 393, baseType: !8, size: 1, offset: 20, flags: DIFlagBitField, extraData: i64 0)
!1538 = !DIDerivedType(tag: DW_TAG_member, name: "id", scope: !1516, file: !27, line: 394, baseType: !8, size: 1, offset: 21, flags: DIFlagBitField, extraData: i64 0)
!1539 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_eflags", scope: !1516, file: !27, line: 395, baseType: !8, size: 10, offset: 22, flags: DIFlagBitField, extraData: i64 0)
!1540 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_rflags", scope: !1516, file: !27, line: 396, baseType: !8, size: 32, offset: 32)
!1541 = !DIDerivedType(tag: DW_TAG_member, name: "seg", scope: !1268, file: !27, line: 753, baseType: !1542, size: 192, align: 64, offset: 16704)
!1542 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Segments", file: !27, line: 451, size: 192, align: 64, elements: !1543, identifier: "_ZTS8Segments")
!1543 = !{!1544, !1546, !1556, !1557, !1558, !1559, !1560, !1561, !1562, !1563, !1564, !1565}
!1544 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1542, file: !27, line: 452, baseType: !1545, size: 16)
!1545 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !28)
!1546 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1542, file: !27, line: 453, baseType: !1547, size: 16, offset: 16)
!1547 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "SegmentSelector", file: !27, line: 76, size: 16, elements: !1548, identifier: "_ZTS15SegmentSelector")
!1548 = !{!1549, !1550}
!1549 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1547, file: !27, line: 77, baseType: !28, size: 16)
!1550 = !DIDerivedType(tag: DW_TAG_member, scope: !1547, file: !27, line: 78, baseType: !1551, size: 16)
!1551 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1547, file: !27, line: 78, size: 16, elements: !1552, identifier: "_ZTSN15SegmentSelectorUt_E")
!1552 = !{!1553, !1554, !1555}
!1553 = !DIDerivedType(tag: DW_TAG_member, name: "rpi", scope: !1551, file: !27, line: 79, baseType: !26, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1554 = !DIDerivedType(tag: DW_TAG_member, name: "ti", scope: !1551, file: !27, line: 80, baseType: !35, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1555 = !DIDerivedType(tag: DW_TAG_member, name: "index", scope: !1551, file: !27, line: 81, baseType: !28, size: 13, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1556 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1542, file: !27, line: 454, baseType: !1545, size: 16, offset: 32)
!1557 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1542, file: !27, line: 455, baseType: !1547, size: 16, offset: 48)
!1558 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1542, file: !27, line: 456, baseType: !1545, size: 16, offset: 64)
!1559 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1542, file: !27, line: 457, baseType: !1547, size: 16, offset: 80)
!1560 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1542, file: !27, line: 458, baseType: !1545, size: 16, offset: 96)
!1561 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1542, file: !27, line: 459, baseType: !1547, size: 16, offset: 112)
!1562 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1542, file: !27, line: 460, baseType: !1545, size: 16, offset: 128)
!1563 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1542, file: !27, line: 461, baseType: !1547, size: 16, offset: 144)
!1564 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1542, file: !27, line: 462, baseType: !1545, size: 16, offset: 160)
!1565 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1542, file: !27, line: 463, baseType: !1547, size: 16, offset: 176)
!1566 = !DIDerivedType(tag: DW_TAG_member, name: "addr", scope: !1268, file: !27, line: 754, baseType: !1567, size: 768, align: 64, offset: 16896)
!1567 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "AddressSpace", file: !27, line: 654, size: 768, align: 64, elements: !1568, identifier: "_ZTS12AddressSpace")
!1568 = !{!1569, !1571, !1585, !1586, !1587, !1588, !1589, !1590, !1591, !1592, !1593, !1594}
!1569 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1567, file: !27, line: 655, baseType: !1570, size: 64)
!1570 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !637)
!1571 = !DIDerivedType(tag: DW_TAG_member, name: "ss_base", scope: !1567, file: !27, line: 656, baseType: !1572, size: 64, offset: 64)
!1572 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Reg", file: !27, line: 610, size: 64, elements: !1573, identifier: "_ZTS3Reg")
!1573 = !{!1574}
!1574 = !DIDerivedType(tag: DW_TAG_member, scope: !1572, file: !27, line: 611, baseType: !1575, size: 64)
!1575 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1572, file: !27, line: 611, size: 64, elements: !1576, identifier: "_ZTSN3RegUt_E")
!1576 = !{!1577, !1582, !1583, !1584}
!1577 = !DIDerivedType(tag: DW_TAG_member, name: "byte", scope: !1575, file: !27, line: 615, baseType: !1578, size: 16, align: 8)
!1578 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1575, file: !27, line: 612, size: 16, elements: !1579, identifier: "_ZTSN3RegUt_Ut_E")
!1579 = !{!1580, !1581}
!1580 = !DIDerivedType(tag: DW_TAG_member, name: "low", scope: !1578, file: !27, line: 613, baseType: !62, size: 8)
!1581 = !DIDerivedType(tag: DW_TAG_member, name: "high", scope: !1578, file: !27, line: 614, baseType: !62, size: 8, offset: 8)
!1582 = !DIDerivedType(tag: DW_TAG_member, name: "word", scope: !1575, file: !27, line: 616, baseType: !28, size: 16, align: 16)
!1583 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1575, file: !27, line: 617, baseType: !8, size: 32, align: 32)
!1584 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1575, file: !27, line: 618, baseType: !637, size: 64, align: 64)
!1585 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1567, file: !27, line: 657, baseType: !1570, size: 64, offset: 128)
!1586 = !DIDerivedType(tag: DW_TAG_member, name: "es_base", scope: !1567, file: !27, line: 658, baseType: !1572, size: 64, offset: 192)
!1587 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1567, file: !27, line: 659, baseType: !1570, size: 64, offset: 256)
!1588 = !DIDerivedType(tag: DW_TAG_member, name: "gs_base", scope: !1567, file: !27, line: 660, baseType: !1572, size: 64, offset: 320)
!1589 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1567, file: !27, line: 661, baseType: !1570, size: 64, offset: 384)
!1590 = !DIDerivedType(tag: DW_TAG_member, name: "fs_base", scope: !1567, file: !27, line: 662, baseType: !1572, size: 64, offset: 448)
!1591 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1567, file: !27, line: 663, baseType: !1570, size: 64, offset: 512)
!1592 = !DIDerivedType(tag: DW_TAG_member, name: "ds_base", scope: !1567, file: !27, line: 664, baseType: !1572, size: 64, offset: 576)
!1593 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1567, file: !27, line: 665, baseType: !1570, size: 64, offset: 640)
!1594 = !DIDerivedType(tag: DW_TAG_member, name: "cs_base", scope: !1567, file: !27, line: 666, baseType: !1572, size: 64, offset: 704)
!1595 = !DIDerivedType(tag: DW_TAG_member, name: "gpr", scope: !1268, file: !27, line: 755, baseType: !1596, size: 2176, align: 64, offset: 17664)
!1596 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "GPR", file: !27, line: 677, size: 2176, align: 64, elements: !1597, identifier: "_ZTS3GPR")
!1597 = !{!1598, !1599, !1600, !1601, !1602, !1603, !1604, !1605, !1606, !1607, !1608, !1609, !1610, !1611, !1612, !1613, !1614, !1615, !1616, !1617, !1618, !1619, !1620, !1621, !1622, !1623, !1624, !1625, !1626, !1627, !1628, !1629, !1630, !1631}
!1598 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1596, file: !27, line: 679, baseType: !1570, size: 64)
!1599 = !DIDerivedType(tag: DW_TAG_member, name: "rax", scope: !1596, file: !27, line: 680, baseType: !1572, size: 64, offset: 64)
!1600 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1596, file: !27, line: 681, baseType: !1570, size: 64, offset: 128)
!1601 = !DIDerivedType(tag: DW_TAG_member, name: "rbx", scope: !1596, file: !27, line: 682, baseType: !1572, size: 64, offset: 192)
!1602 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1596, file: !27, line: 683, baseType: !1570, size: 64, offset: 256)
!1603 = !DIDerivedType(tag: DW_TAG_member, name: "rcx", scope: !1596, file: !27, line: 684, baseType: !1572, size: 64, offset: 320)
!1604 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1596, file: !27, line: 685, baseType: !1570, size: 64, offset: 384)
!1605 = !DIDerivedType(tag: DW_TAG_member, name: "rdx", scope: !1596, file: !27, line: 686, baseType: !1572, size: 64, offset: 448)
!1606 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1596, file: !27, line: 687, baseType: !1570, size: 64, offset: 512)
!1607 = !DIDerivedType(tag: DW_TAG_member, name: "rsi", scope: !1596, file: !27, line: 688, baseType: !1572, size: 64, offset: 576)
!1608 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1596, file: !27, line: 689, baseType: !1570, size: 64, offset: 640)
!1609 = !DIDerivedType(tag: DW_TAG_member, name: "rdi", scope: !1596, file: !27, line: 690, baseType: !1572, size: 64, offset: 704)
!1610 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1596, file: !27, line: 691, baseType: !1570, size: 64, offset: 768)
!1611 = !DIDerivedType(tag: DW_TAG_member, name: "rsp", scope: !1596, file: !27, line: 692, baseType: !1572, size: 64, offset: 832)
!1612 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1596, file: !27, line: 693, baseType: !1570, size: 64, offset: 896)
!1613 = !DIDerivedType(tag: DW_TAG_member, name: "rbp", scope: !1596, file: !27, line: 694, baseType: !1572, size: 64, offset: 960)
!1614 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1596, file: !27, line: 695, baseType: !1570, size: 64, offset: 1024)
!1615 = !DIDerivedType(tag: DW_TAG_member, name: "r8", scope: !1596, file: !27, line: 696, baseType: !1572, size: 64, offset: 1088)
!1616 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1596, file: !27, line: 697, baseType: !1570, size: 64, offset: 1152)
!1617 = !DIDerivedType(tag: DW_TAG_member, name: "r9", scope: !1596, file: !27, line: 698, baseType: !1572, size: 64, offset: 1216)
!1618 = !DIDerivedType(tag: DW_TAG_member, name: "_10", scope: !1596, file: !27, line: 699, baseType: !1570, size: 64, offset: 1280)
!1619 = !DIDerivedType(tag: DW_TAG_member, name: "r10", scope: !1596, file: !27, line: 700, baseType: !1572, size: 64, offset: 1344)
!1620 = !DIDerivedType(tag: DW_TAG_member, name: "_11", scope: !1596, file: !27, line: 701, baseType: !1570, size: 64, offset: 1408)
!1621 = !DIDerivedType(tag: DW_TAG_member, name: "r11", scope: !1596, file: !27, line: 702, baseType: !1572, size: 64, offset: 1472)
!1622 = !DIDerivedType(tag: DW_TAG_member, name: "_12", scope: !1596, file: !27, line: 703, baseType: !1570, size: 64, offset: 1536)
!1623 = !DIDerivedType(tag: DW_TAG_member, name: "r12", scope: !1596, file: !27, line: 704, baseType: !1572, size: 64, offset: 1600)
!1624 = !DIDerivedType(tag: DW_TAG_member, name: "_13", scope: !1596, file: !27, line: 705, baseType: !1570, size: 64, offset: 1664)
!1625 = !DIDerivedType(tag: DW_TAG_member, name: "r13", scope: !1596, file: !27, line: 706, baseType: !1572, size: 64, offset: 1728)
!1626 = !DIDerivedType(tag: DW_TAG_member, name: "_14", scope: !1596, file: !27, line: 707, baseType: !1570, size: 64, offset: 1792)
!1627 = !DIDerivedType(tag: DW_TAG_member, name: "r14", scope: !1596, file: !27, line: 708, baseType: !1572, size: 64, offset: 1856)
!1628 = !DIDerivedType(tag: DW_TAG_member, name: "_15", scope: !1596, file: !27, line: 709, baseType: !1570, size: 64, offset: 1920)
!1629 = !DIDerivedType(tag: DW_TAG_member, name: "r15", scope: !1596, file: !27, line: 710, baseType: !1572, size: 64, offset: 1984)
!1630 = !DIDerivedType(tag: DW_TAG_member, name: "_16", scope: !1596, file: !27, line: 711, baseType: !1570, size: 64, offset: 2048)
!1631 = !DIDerivedType(tag: DW_TAG_member, name: "rip", scope: !1596, file: !27, line: 714, baseType: !1572, size: 64, offset: 2112)
!1632 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1268, file: !27, line: 756, baseType: !1633, size: 1024, align: 64, offset: 19840)
!1633 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "X87Stack", file: !27, line: 719, size: 1024, align: 64, elements: !1634, identifier: "_ZTS8X87Stack")
!1634 = !{!1635}
!1635 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1633, file: !27, line: 723, baseType: !1636, size: 1024)
!1636 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1637, size: 1024, elements: !1310)
!1637 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1633, file: !27, line: 720, size: 128, align: 64, elements: !1638, identifier: "_ZTSN8X87StackUt_E")
!1638 = !{!1639, !1640}
!1639 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1637, file: !27, line: 721, baseType: !637, size: 64)
!1640 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1637, file: !27, line: 722, baseType: !1641, size: 64, offset: 64)
!1641 = !DIDerivedType(tag: DW_TAG_typedef, name: "float64_t", file: !1266, line: 61, baseType: !108)
!1642 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1268, file: !27, line: 757, baseType: !1643, size: 1024, align: 64, offset: 20864)
!1643 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "MMX", file: !27, line: 729, size: 1024, align: 64, elements: !1644, identifier: "_ZTS3MMX")
!1644 = !{!1645}
!1645 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1643, file: !27, line: 733, baseType: !1646, size: 1024)
!1646 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1647, size: 1024, elements: !1310)
!1647 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1643, file: !27, line: 730, size: 128, align: 64, elements: !1648, identifier: "_ZTSN3MMXUt_E")
!1648 = !{!1649, !1650}
!1649 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1647, file: !27, line: 731, baseType: !637, size: 64)
!1650 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1647, file: !27, line: 732, baseType: !1651, size: 64, offset: 64)
!1651 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec64_t", file: !1266, line: 294, size: 64, elements: !1652, identifier: "_ZTS7vec64_t")
!1652 = !{!1653, !1658, !1663, !1668, !1673, !1678, !1683, !1688, !1693, !1698}
!1653 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1651, file: !1266, line: 298, baseType: !1654, size: 64)
!1654 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v1_t", file: !1266, line: 199, size: 64, elements: !1655, identifier: "_ZTS10uint64v1_t")
!1655 = !{!1656}
!1656 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1654, file: !1266, line: 199, baseType: !1657, size: 64)
!1657 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 64, elements: !1296)
!1658 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1651, file: !1266, line: 300, baseType: !1659, size: 64)
!1659 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v8_t", file: !1266, line: 181, size: 64, elements: !1660, identifier: "_ZTS9uint8v8_t")
!1660 = !{!1661}
!1661 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1659, file: !1266, line: 181, baseType: !1662, size: 64)
!1662 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 64, elements: !1310)
!1663 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1651, file: !1266, line: 301, baseType: !1664, size: 64)
!1664 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v4_t", file: !1266, line: 188, size: 64, elements: !1665, identifier: "_ZTS10uint16v4_t")
!1665 = !{!1666}
!1666 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1664, file: !1266, line: 188, baseType: !1667, size: 64)
!1667 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 64, elements: !353)
!1668 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1651, file: !1266, line: 302, baseType: !1669, size: 64)
!1669 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v2_t", file: !1266, line: 194, size: 64, elements: !1670, identifier: "_ZTS10uint32v2_t")
!1670 = !{!1671}
!1671 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1669, file: !1266, line: 194, baseType: !1672, size: 64)
!1672 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 64, elements: !1322)
!1673 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1651, file: !1266, line: 303, baseType: !1674, size: 64)
!1674 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v2_t", file: !1266, line: 241, size: 64, elements: !1675, identifier: "_ZTS11float32v2_t")
!1675 = !{!1676}
!1676 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1674, file: !1266, line: 241, baseType: !1677, size: 64)
!1677 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 64, elements: !1322)
!1678 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1651, file: !1266, line: 304, baseType: !1679, size: 64)
!1679 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v1_t", file: !1266, line: 246, size: 64, elements: !1680, identifier: "_ZTS11float64v1_t")
!1680 = !{!1681}
!1681 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1679, file: !1266, line: 246, baseType: !1682, size: 64)
!1682 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 64, elements: !1296)
!1683 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1651, file: !1266, line: 306, baseType: !1684, size: 64)
!1684 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v8_t", file: !1266, line: 212, size: 64, elements: !1685, identifier: "_ZTS8int8v8_t")
!1685 = !{!1686}
!1686 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1684, file: !1266, line: 212, baseType: !1687, size: 64)
!1687 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 64, elements: !1310)
!1688 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1651, file: !1266, line: 307, baseType: !1689, size: 64)
!1689 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v4_t", file: !1266, line: 219, size: 64, elements: !1690, identifier: "_ZTS9int16v4_t")
!1690 = !{!1691}
!1691 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1689, file: !1266, line: 219, baseType: !1692, size: 64)
!1692 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 64, elements: !353)
!1693 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1651, file: !1266, line: 308, baseType: !1694, size: 64)
!1694 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v2_t", file: !1266, line: 225, size: 64, elements: !1695, identifier: "_ZTS9int32v2_t")
!1695 = !{!1696}
!1696 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1694, file: !1266, line: 225, baseType: !1697, size: 64)
!1697 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 64, elements: !1322)
!1698 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1651, file: !1266, line: 309, baseType: !1699, size: 64)
!1699 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v1_t", file: !1266, line: 230, size: 64, elements: !1700, identifier: "_ZTS9int64v1_t")
!1700 = !{!1701}
!1701 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1699, file: !1266, line: 230, baseType: !1702, size: 64)
!1702 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 64, elements: !1296)
!1703 = !DIDerivedType(tag: DW_TAG_member, name: "sw", scope: !1268, file: !27, line: 758, baseType: !1704, size: 192, offset: 21888)
!1704 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStatusFlags", file: !27, line: 332, size: 192, elements: !1705, identifier: "_ZTS14FPUStatusFlags")
!1705 = !{!1706, !1707, !1708, !1709, !1710, !1711, !1712, !1713, !1714, !1715, !1716, !1717, !1718, !1719, !1720, !1721, !1722, !1723, !1724, !1725, !1726}
!1706 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1704, file: !27, line: 333, baseType: !62, size: 8)
!1707 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1704, file: !27, line: 334, baseType: !62, size: 8, offset: 8)
!1708 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1704, file: !27, line: 335, baseType: !62, size: 8, offset: 16)
!1709 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1704, file: !27, line: 336, baseType: !62, size: 8, offset: 24)
!1710 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1704, file: !27, line: 337, baseType: !62, size: 8, offset: 32)
!1711 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1704, file: !27, line: 338, baseType: !62, size: 8, offset: 40)
!1712 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1704, file: !27, line: 339, baseType: !62, size: 8, offset: 48)
!1713 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1704, file: !27, line: 340, baseType: !62, size: 8, offset: 56)
!1714 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1704, file: !27, line: 342, baseType: !62, size: 8, offset: 64)
!1715 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1704, file: !27, line: 343, baseType: !62, size: 8, offset: 72)
!1716 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1704, file: !27, line: 345, baseType: !62, size: 8, offset: 80)
!1717 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1704, file: !27, line: 346, baseType: !62, size: 8, offset: 88)
!1718 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1704, file: !27, line: 348, baseType: !62, size: 8, offset: 96)
!1719 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1704, file: !27, line: 349, baseType: !62, size: 8, offset: 104)
!1720 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1704, file: !27, line: 351, baseType: !62, size: 8, offset: 112)
!1721 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1704, file: !27, line: 352, baseType: !62, size: 8, offset: 120)
!1722 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1704, file: !27, line: 354, baseType: !62, size: 8, offset: 128)
!1723 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1704, file: !27, line: 355, baseType: !62, size: 8, offset: 136)
!1724 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1704, file: !27, line: 357, baseType: !62, size: 8, offset: 144)
!1725 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1704, file: !27, line: 358, baseType: !62, size: 8, offset: 152)
!1726 = !DIDerivedType(tag: DW_TAG_member, name: "_padding", scope: !1704, file: !27, line: 360, baseType: !1727, size: 32, offset: 160)
!1727 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 32, elements: !353)
!1728 = !DIDerivedType(tag: DW_TAG_member, name: "xcr0", scope: !1268, file: !27, line: 759, baseType: !1729, size: 64, offset: 22080)
!1729 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "XCR0", file: !27, line: 424, size: 64, elements: !1730, identifier: "_ZTS4XCR0")
!1730 = !{!1731, !1732, !1737}
!1731 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1729, file: !27, line: 425, baseType: !637, size: 64)
!1732 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 427, baseType: !1733, size: 64)
!1733 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 427, size: 64, elements: !1734, identifier: "_ZTSN4XCR0Ut_E")
!1734 = !{!1735, !1736}
!1735 = !DIDerivedType(tag: DW_TAG_member, name: "eax", scope: !1733, file: !27, line: 428, baseType: !8, size: 32)
!1736 = !DIDerivedType(tag: DW_TAG_member, name: "edx", scope: !1733, file: !27, line: 429, baseType: !8, size: 32, offset: 32)
!1737 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 433, baseType: !1738, size: 64)
!1738 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 433, size: 64, elements: !1739, identifier: "_ZTSN4XCR0Ut0_E")
!1739 = !{!1740, !1741, !1742, !1743, !1744, !1745, !1746, !1747, !1748, !1749, !1750, !1751}
!1740 = !DIDerivedType(tag: DW_TAG_member, name: "x87_fpu_mmx", scope: !1738, file: !27, line: 434, baseType: !637, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1741 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1738, file: !27, line: 435, baseType: !637, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1742 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1738, file: !27, line: 436, baseType: !637, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1743 = !DIDerivedType(tag: DW_TAG_member, name: "bndreg", scope: !1738, file: !27, line: 437, baseType: !637, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1744 = !DIDerivedType(tag: DW_TAG_member, name: "bndcsr", scope: !1738, file: !27, line: 438, baseType: !637, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1745 = !DIDerivedType(tag: DW_TAG_member, name: "opmask", scope: !1738, file: !27, line: 439, baseType: !637, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1746 = !DIDerivedType(tag: DW_TAG_member, name: "zmm_hi256", scope: !1738, file: !27, line: 440, baseType: !637, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1747 = !DIDerivedType(tag: DW_TAG_member, name: "hi16_zmm", scope: !1738, file: !27, line: 441, baseType: !637, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1748 = !DIDerivedType(tag: DW_TAG_member, name: "pkru", scope: !1738, file: !27, line: 442, baseType: !637, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1749 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved0", scope: !1738, file: !27, line: 443, baseType: !637, size: 53, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1750 = !DIDerivedType(tag: DW_TAG_member, name: "lwp", scope: !1738, file: !27, line: 444, baseType: !637, size: 1, offset: 62, flags: DIFlagBitField, extraData: i64 0)
!1751 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved1", scope: !1738, file: !27, line: 445, baseType: !637, size: 1, offset: 63, flags: DIFlagBitField, extraData: i64 0)
!1752 = !DIDerivedType(tag: DW_TAG_member, name: "x87", scope: !1268, file: !27, line: 760, baseType: !1753, size: 4096, align: 128, offset: 22144)
!1753 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPU", file: !27, line: 314, size: 4096, align: 128, elements: !1754, identifier: "_ZTS3FPU")
!1754 = !{!1755, !1851, !1914}
!1755 = !DIDerivedType(tag: DW_TAG_member, name: "fsave", scope: !1753, file: !27, line: 317, baseType: !1756, size: 4096)
!1756 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 315, size: 4096, elements: !1757, identifier: "_ZTSN3FPUUt_E")
!1757 = !{!1758, !1847}
!1758 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1756, baseType: !1759)
!1759 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFSAVE", file: !27, line: 263, size: 1248, elements: !1760, identifier: "_ZTS8FpuFSAVE")
!1760 = !{!1761, !1779, !1780, !1801, !1802, !1817, !1818, !1819, !1820, !1821, !1822, !1823, !1824}
!1761 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1759, file: !27, line: 264, baseType: !1762, size: 16)
!1762 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlWord", file: !27, line: 142, size: 16, elements: !1763, identifier: "_ZTS14FPUControlWord")
!1763 = !{!1764, !1765}
!1764 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1762, file: !27, line: 143, baseType: !28, size: 16)
!1765 = !DIDerivedType(tag: DW_TAG_member, scope: !1762, file: !27, line: 144, baseType: !1766, size: 16)
!1766 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1762, file: !27, line: 144, size: 16, elements: !1767, identifier: "_ZTSN14FPUControlWordUt_E")
!1767 = !{!1768, !1769, !1770, !1771, !1772, !1773, !1774, !1775, !1776, !1777, !1778}
!1768 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1766, file: !27, line: 145, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1769 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1766, file: !27, line: 146, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1770 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1766, file: !27, line: 147, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1771 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1766, file: !27, line: 148, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1772 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1766, file: !27, line: 149, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1773 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1766, file: !27, line: 150, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1774 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1766, file: !27, line: 151, baseType: !28, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1775 = !DIDerivedType(tag: DW_TAG_member, name: "pc", scope: !1766, file: !27, line: 152, baseType: !39, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1776 = !DIDerivedType(tag: DW_TAG_member, name: "rc", scope: !1766, file: !27, line: 153, baseType: !45, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1777 = !DIDerivedType(tag: DW_TAG_member, name: "x", scope: !1766, file: !27, line: 154, baseType: !51, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1778 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1766, file: !27, line: 155, baseType: !28, size: 3, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1779 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1759, file: !27, line: 265, baseType: !28, size: 16, offset: 16)
!1780 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1759, file: !27, line: 266, baseType: !1781, size: 16, offset: 32)
!1781 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUStatusWord", file: !27, line: 100, size: 16, elements: !1782, identifier: "_ZTS13FPUStatusWord")
!1782 = !{!1783, !1784}
!1783 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1781, file: !27, line: 101, baseType: !28, size: 16)
!1784 = !DIDerivedType(tag: DW_TAG_member, scope: !1781, file: !27, line: 102, baseType: !1785, size: 16)
!1785 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1781, file: !27, line: 102, size: 16, elements: !1786, identifier: "_ZTSN13FPUStatusWordUt_E")
!1786 = !{!1787, !1788, !1789, !1790, !1791, !1792, !1793, !1794, !1795, !1796, !1797, !1798, !1799, !1800}
!1787 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1785, file: !27, line: 103, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1788 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1785, file: !27, line: 104, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1789 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1785, file: !27, line: 105, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1790 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1785, file: !27, line: 106, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1791 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1785, file: !27, line: 107, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1792 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1785, file: !27, line: 108, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1793 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1785, file: !27, line: 109, baseType: !28, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1794 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1785, file: !27, line: 110, baseType: !28, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1795 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1785, file: !27, line: 111, baseType: !28, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1796 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1785, file: !27, line: 112, baseType: !28, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1797 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1785, file: !27, line: 113, baseType: !28, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1798 = !DIDerivedType(tag: DW_TAG_member, name: "top", scope: !1785, file: !27, line: 114, baseType: !28, size: 3, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1799 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1785, file: !27, line: 115, baseType: !28, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1800 = !DIDerivedType(tag: DW_TAG_member, name: "b", scope: !1785, file: !27, line: 116, baseType: !28, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1801 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1759, file: !27, line: 267, baseType: !28, size: 16, offset: 48)
!1802 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1759, file: !27, line: 268, baseType: !1803, size: 16, offset: 64)
!1803 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUTagWord", file: !27, line: 227, size: 16, elements: !1804, identifier: "_ZTS10FPUTagWord")
!1804 = !{!1805, !1806}
!1805 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1803, file: !27, line: 228, baseType: !28, size: 16)
!1806 = !DIDerivedType(tag: DW_TAG_member, scope: !1803, file: !27, line: 229, baseType: !1807, size: 16)
!1807 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1803, file: !27, line: 229, size: 16, elements: !1808, identifier: "_ZTSN10FPUTagWordUt_E")
!1808 = !{!1809, !1810, !1811, !1812, !1813, !1814, !1815, !1816}
!1809 = !DIDerivedType(tag: DW_TAG_member, name: "tag0", scope: !1807, file: !27, line: 230, baseType: !55, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1810 = !DIDerivedType(tag: DW_TAG_member, name: "tag1", scope: !1807, file: !27, line: 231, baseType: !55, size: 2, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1811 = !DIDerivedType(tag: DW_TAG_member, name: "tag2", scope: !1807, file: !27, line: 232, baseType: !55, size: 2, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1812 = !DIDerivedType(tag: DW_TAG_member, name: "tag3", scope: !1807, file: !27, line: 233, baseType: !55, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1813 = !DIDerivedType(tag: DW_TAG_member, name: "tag4", scope: !1807, file: !27, line: 234, baseType: !55, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1814 = !DIDerivedType(tag: DW_TAG_member, name: "tag5", scope: !1807, file: !27, line: 235, baseType: !55, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1815 = !DIDerivedType(tag: DW_TAG_member, name: "tag6", scope: !1807, file: !27, line: 236, baseType: !55, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1816 = !DIDerivedType(tag: DW_TAG_member, name: "tag7", scope: !1807, file: !27, line: 237, baseType: !55, size: 2, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1817 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1759, file: !27, line: 269, baseType: !28, size: 16, offset: 80)
!1818 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1759, file: !27, line: 270, baseType: !8, size: 32, offset: 96)
!1819 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1759, file: !27, line: 271, baseType: !1547, size: 16, offset: 128)
!1820 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1759, file: !27, line: 272, baseType: !28, size: 16, offset: 144)
!1821 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1759, file: !27, line: 273, baseType: !8, size: 32, offset: 160)
!1822 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1759, file: !27, line: 274, baseType: !1547, size: 16, offset: 192)
!1823 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd3", scope: !1759, file: !27, line: 275, baseType: !28, size: 16, offset: 208)
!1824 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1759, file: !27, line: 276, baseType: !1825, size: 1024, offset: 224)
!1825 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1826, size: 1024, elements: !1310)
!1826 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStackElem", file: !27, line: 162, size: 128, elements: !1827, identifier: "_ZTS12FPUStackElem")
!1827 = !{!1828, !1843}
!1828 = !DIDerivedType(tag: DW_TAG_member, scope: !1826, file: !27, line: 163, baseType: !1829, size: 80)
!1829 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1826, file: !27, line: 163, size: 80, elements: !1830, identifier: "_ZTSN12FPUStackElemUt_E")
!1830 = !{!1831, !1838}
!1831 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1829, file: !27, line: 164, baseType: !1832, size: 80)
!1832 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float80_t", file: !1266, line: 65, size: 80, elements: !1833, identifier: "_ZTS9float80_t")
!1833 = !{!1834}
!1834 = !DIDerivedType(tag: DW_TAG_member, name: "data", scope: !1832, file: !1266, line: 66, baseType: !1835, size: 80)
!1835 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 80, elements: !1836)
!1836 = !{!1837}
!1837 = !DISubrange(count: 10)
!1838 = !DIDerivedType(tag: DW_TAG_member, scope: !1829, file: !27, line: 165, baseType: !1839, size: 80)
!1839 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1829, file: !27, line: 165, size: 80, elements: !1840, identifier: "_ZTSN12FPUStackElemUt_Ut_E")
!1840 = !{!1841, !1842}
!1841 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1839, file: !27, line: 166, baseType: !637, size: 64)
!1842 = !DIDerivedType(tag: DW_TAG_member, name: "infinity", scope: !1839, file: !27, line: 167, baseType: !28, size: 16, offset: 64)
!1843 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1826, file: !27, line: 170, baseType: !1844, size: 48, offset: 80)
!1844 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 48, elements: !1845)
!1845 = !{!1846}
!1846 = !DISubrange(count: 6)
!1847 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1756, file: !27, line: 316, baseType: !1848, size: 2848, offset: 1248)
!1848 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 2848, elements: !1849)
!1849 = !{!1850}
!1850 = !DISubrange(count: 356)
!1851 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave32", scope: !1753, file: !27, line: 321, baseType: !1852, size: 4096)
!1852 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 319, size: 4096, elements: !1853, identifier: "_ZTSN3FPUUt0_E")
!1853 = !{!1854, !1910}
!1854 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1852, baseType: !1855)
!1855 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE", file: !27, line: 280, size: 3328, elements: !1856, identifier: "_ZTS9FpuFXSAVE")
!1856 = !{!1857, !1858, !1859, !1874, !1875, !1876, !1877, !1878, !1879, !1880, !1881, !1882, !1906, !1907, !1908}
!1857 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1855, file: !27, line: 281, baseType: !1762, size: 16)
!1858 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1855, file: !27, line: 282, baseType: !1781, size: 16, offset: 16)
!1859 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1855, file: !27, line: 283, baseType: !1860, size: 8, offset: 32)
!1860 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUAbridgedTagWord", file: !27, line: 245, size: 8, elements: !1861, identifier: "_ZTS18FPUAbridgedTagWord")
!1861 = !{!1862, !1863}
!1862 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1860, file: !27, line: 246, baseType: !62, size: 8)
!1863 = !DIDerivedType(tag: DW_TAG_member, scope: !1860, file: !27, line: 247, baseType: !1864, size: 8)
!1864 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1860, file: !27, line: 247, size: 8, elements: !1865, identifier: "_ZTSN18FPUAbridgedTagWordUt_E")
!1865 = !{!1866, !1867, !1868, !1869, !1870, !1871, !1872, !1873}
!1866 = !DIDerivedType(tag: DW_TAG_member, name: "r0", scope: !1864, file: !27, line: 248, baseType: !61, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1867 = !DIDerivedType(tag: DW_TAG_member, name: "r1", scope: !1864, file: !27, line: 249, baseType: !61, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1868 = !DIDerivedType(tag: DW_TAG_member, name: "r2", scope: !1864, file: !27, line: 250, baseType: !61, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1869 = !DIDerivedType(tag: DW_TAG_member, name: "r3", scope: !1864, file: !27, line: 251, baseType: !61, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1870 = !DIDerivedType(tag: DW_TAG_member, name: "r4", scope: !1864, file: !27, line: 252, baseType: !61, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1871 = !DIDerivedType(tag: DW_TAG_member, name: "r5", scope: !1864, file: !27, line: 253, baseType: !61, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1872 = !DIDerivedType(tag: DW_TAG_member, name: "r6", scope: !1864, file: !27, line: 254, baseType: !61, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1873 = !DIDerivedType(tag: DW_TAG_member, name: "r7", scope: !1864, file: !27, line: 255, baseType: !61, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1874 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1855, file: !27, line: 284, baseType: !62, size: 8, offset: 40)
!1875 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1855, file: !27, line: 285, baseType: !28, size: 16, offset: 48)
!1876 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1855, file: !27, line: 286, baseType: !8, size: 32, offset: 64)
!1877 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1855, file: !27, line: 287, baseType: !1547, size: 16, offset: 96)
!1878 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1855, file: !27, line: 288, baseType: !28, size: 16, offset: 112)
!1879 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1855, file: !27, line: 289, baseType: !8, size: 32, offset: 128)
!1880 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1855, file: !27, line: 290, baseType: !1547, size: 16, offset: 160)
!1881 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1855, file: !27, line: 291, baseType: !28, size: 16, offset: 176)
!1882 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1855, file: !27, line: 292, baseType: !1883, size: 32, offset: 192)
!1883 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlStatus", file: !27, line: 188, size: 32, elements: !1884, identifier: "_ZTS16FPUControlStatus")
!1884 = !{!1885, !1886}
!1885 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1883, file: !27, line: 189, baseType: !8, size: 32)
!1886 = !DIDerivedType(tag: DW_TAG_member, scope: !1883, file: !27, line: 190, baseType: !1887, size: 32)
!1887 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1883, file: !27, line: 190, size: 32, elements: !1888, identifier: "_ZTSN16FPUControlStatusUt_E")
!1888 = !{!1889, !1890, !1891, !1892, !1893, !1894, !1895, !1896, !1897, !1898, !1899, !1900, !1901, !1902, !1903, !1904, !1905}
!1889 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1887, file: !27, line: 191, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1890 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1887, file: !27, line: 192, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1891 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1887, file: !27, line: 193, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1892 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1887, file: !27, line: 194, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1893 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1887, file: !27, line: 195, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1894 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1887, file: !27, line: 196, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1895 = !DIDerivedType(tag: DW_TAG_member, name: "daz", scope: !1887, file: !27, line: 197, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1896 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1887, file: !27, line: 198, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1897 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1887, file: !27, line: 199, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1898 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1887, file: !27, line: 200, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1899 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1887, file: !27, line: 201, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1900 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1887, file: !27, line: 202, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1901 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1887, file: !27, line: 203, baseType: !8, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1902 = !DIDerivedType(tag: DW_TAG_member, name: "rn", scope: !1887, file: !27, line: 204, baseType: !8, size: 1, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1903 = !DIDerivedType(tag: DW_TAG_member, name: "rp", scope: !1887, file: !27, line: 205, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1904 = !DIDerivedType(tag: DW_TAG_member, name: "fz", scope: !1887, file: !27, line: 206, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1905 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1887, file: !27, line: 207, baseType: !8, size: 16, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1906 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1855, file: !27, line: 293, baseType: !1883, size: 32, offset: 224)
!1907 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1855, file: !27, line: 294, baseType: !1825, size: 1024, offset: 256)
!1908 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1855, file: !27, line: 295, baseType: !1909, size: 2048, offset: 1280)
!1909 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1287, size: 2048, elements: !1303)
!1910 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1852, file: !27, line: 320, baseType: !1911, size: 768, offset: 3328)
!1911 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 768, elements: !1912)
!1912 = !{!1913}
!1913 = !DISubrange(count: 96)
!1914 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave64", scope: !1753, file: !27, line: 325, baseType: !1915, size: 4096)
!1915 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 323, size: 4096, elements: !1916, identifier: "_ZTSN3FPUUt1_E")
!1916 = !{!1917, !1931}
!1917 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1915, baseType: !1918)
!1918 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE64", file: !27, line: 299, size: 3328, elements: !1919, identifier: "_ZTS11FpuFXSAVE64")
!1919 = !{!1920, !1921, !1922, !1923, !1924, !1925, !1926, !1927, !1928, !1929, !1930}
!1920 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1918, file: !27, line: 300, baseType: !1762, size: 16)
!1921 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1918, file: !27, line: 301, baseType: !1781, size: 16, offset: 16)
!1922 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1918, file: !27, line: 302, baseType: !1860, size: 8, offset: 32)
!1923 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1918, file: !27, line: 303, baseType: !62, size: 8, offset: 40)
!1924 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1918, file: !27, line: 304, baseType: !28, size: 16, offset: 48)
!1925 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1918, file: !27, line: 305, baseType: !637, size: 64, offset: 64)
!1926 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1918, file: !27, line: 306, baseType: !637, size: 64, offset: 128)
!1927 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1918, file: !27, line: 307, baseType: !1883, size: 32, offset: 192)
!1928 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1918, file: !27, line: 308, baseType: !1883, size: 32, offset: 224)
!1929 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1918, file: !27, line: 309, baseType: !1825, size: 1024, offset: 256)
!1930 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1918, file: !27, line: 310, baseType: !1909, size: 2048, offset: 1280)
!1931 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1915, file: !27, line: 324, baseType: !1911, size: 768, offset: 3328)
!1932 = !DIDerivedType(tag: DW_TAG_member, name: "seg_caches", scope: !1268, file: !27, line: 761, baseType: !1933, size: 768, align: 64, offset: 26240)
!1933 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentCaches", file: !27, line: 468, size: 768, align: 64, elements: !1934, identifier: "_ZTS13SegmentCaches")
!1934 = !{!1935, !1945, !1946, !1947, !1948, !1949}
!1935 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1933, file: !27, line: 469, baseType: !1936, size: 128)
!1936 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentShadow", file: !27, line: 88, size: 128, elements: !1937, identifier: "_ZTS13SegmentShadow")
!1937 = !{!1938, !1943, !1944}
!1938 = !DIDerivedType(tag: DW_TAG_member, name: "base", scope: !1936, file: !27, line: 92, baseType: !1939, size: 64)
!1939 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1936, file: !27, line: 89, size: 64, elements: !1940, identifier: "_ZTSN13SegmentShadowUt_E")
!1940 = !{!1941, !1942}
!1941 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1939, file: !27, line: 90, baseType: !8, size: 32)
!1942 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1939, file: !27, line: 91, baseType: !637, size: 64)
!1943 = !DIDerivedType(tag: DW_TAG_member, name: "limit", scope: !1936, file: !27, line: 93, baseType: !8, size: 32, offset: 64)
!1944 = !DIDerivedType(tag: DW_TAG_member, name: "flags", scope: !1936, file: !27, line: 94, baseType: !8, size: 32, offset: 96)
!1945 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1933, file: !27, line: 470, baseType: !1936, size: 128, offset: 128)
!1946 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1933, file: !27, line: 471, baseType: !1936, size: 128, offset: 256)
!1947 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1933, file: !27, line: 472, baseType: !1936, size: 128, offset: 384)
!1948 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1933, file: !27, line: 473, baseType: !1936, size: 128, offset: 512)
!1949 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1933, file: !27, line: 474, baseType: !1936, size: 128, offset: 640)
!1950 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr_t", file: !1266, line: 42, baseType: !1951)
!1951 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr64_t", file: !1266, line: 41, baseType: !637)
!1952 = !DILocation(line: 54, column: 8, scope: !1261)
!1953 = !DILocation(line: 55, column: 10, scope: !1261)
!1954 = !DILocation(line: 56, column: 10, scope: !1261)
!1955 = !DILocation(line: 57, column: 10, scope: !1261)
!1956 = !DILocation(line: 58, column: 10, scope: !1261)
!1957 = !DILocation(line: 61, column: 9, scope: !1261)
!1958 = !DILocation(line: 62, column: 9, scope: !1261)
!1959 = !DILocation(line: 63, column: 20, scope: !1261)
!1960 = !DILocation(line: 63, column: 24, scope: !1261)
!1961 = !DILocation(line: 63, column: 28, scope: !1261)
!1962 = !DILocation(line: 69, column: 6, scope: !1261)
!1963 = !DILocation(line: 74, column: 20, scope: !1261)
!1964 = !DILocation(line: 74, column: 24, scope: !1261)
!1965 = !DILocation(line: 74, column: 28, scope: !1261)
!1966 = !DILocation(line: 74, column: 33, scope: !1261)
!1967 = !DILocation(line: 75, column: 20, scope: !1261)
!1968 = !DILocation(line: 75, column: 24, scope: !1261)
!1969 = !DILocation(line: 75, column: 28, scope: !1261)
!1970 = !DILocation(line: 75, column: 33, scope: !1261)
!1971 = !DILocation(line: 76, column: 20, scope: !1261)
!1972 = !DILocation(line: 76, column: 24, scope: !1261)
!1973 = !DILocation(line: 76, column: 28, scope: !1261)
!1974 = !DILocation(line: 76, column: 33, scope: !1261)
!1975 = !DILocation(line: 77, column: 20, scope: !1261)
!1976 = !DILocation(line: 77, column: 24, scope: !1261)
!1977 = !DILocation(line: 77, column: 28, scope: !1261)
!1978 = !DILocation(line: 77, column: 33, scope: !1261)
!1979 = !DILocation(line: 78, column: 20, scope: !1261)
!1980 = !DILocation(line: 78, column: 24, scope: !1261)
!1981 = !DILocation(line: 78, column: 28, scope: !1261)
!1982 = !DILocation(line: 78, column: 33, scope: !1261)
!1983 = !DILocation(line: 79, column: 20, scope: !1261)
!1984 = !DILocation(line: 79, column: 24, scope: !1261)
!1985 = !DILocation(line: 79, column: 28, scope: !1261)
!1986 = !DILocation(line: 79, column: 33, scope: !1261)
!1987 = !DILocation(line: 80, column: 20, scope: !1261)
!1988 = !DILocation(line: 80, column: 24, scope: !1261)
!1989 = !DILocation(line: 80, column: 28, scope: !1261)
!1990 = !DILocation(line: 80, column: 33, scope: !1261)
!1991 = !DILocation(line: 81, column: 20, scope: !1261)
!1992 = !DILocation(line: 81, column: 24, scope: !1261)
!1993 = !DILocation(line: 81, column: 28, scope: !1261)
!1994 = !DILocation(line: 81, column: 33, scope: !1261)
!1995 = !DILocation(line: 83, column: 21, scope: !1261)
!1996 = !DILocation(line: 83, column: 25, scope: !1261)
!1997 = !DILocation(line: 83, column: 29, scope: !1261)
!1998 = !DILocation(line: 83, column: 34, scope: !1261)
!1999 = !DILocation(line: 84, column: 21, scope: !1261)
!2000 = !DILocation(line: 84, column: 25, scope: !1261)
!2001 = !DILocation(line: 84, column: 29, scope: !1261)
!2002 = !DILocation(line: 84, column: 34, scope: !1261)
!2003 = !DILocation(line: 85, column: 21, scope: !1261)
!2004 = !DILocation(line: 85, column: 25, scope: !1261)
!2005 = !DILocation(line: 85, column: 29, scope: !1261)
!2006 = !DILocation(line: 85, column: 34, scope: !1261)
!2007 = !DILocation(line: 86, column: 21, scope: !1261)
!2008 = !DILocation(line: 86, column: 25, scope: !1261)
!2009 = !DILocation(line: 86, column: 29, scope: !1261)
!2010 = !DILocation(line: 86, column: 34, scope: !1261)
!2011 = !DILocation(line: 87, column: 21, scope: !1261)
!2012 = !DILocation(line: 87, column: 25, scope: !1261)
!2013 = !DILocation(line: 87, column: 28, scope: !1261)
!2014 = !DILocation(line: 87, column: 33, scope: !1261)
!2015 = !DILocation(line: 88, column: 21, scope: !1261)
!2016 = !DILocation(line: 88, column: 25, scope: !1261)
!2017 = !DILocation(line: 88, column: 28, scope: !1261)
!2018 = !DILocation(line: 88, column: 33, scope: !1261)
!2019 = !DILocation(line: 89, column: 22, scope: !1261)
!2020 = !DILocation(line: 89, column: 26, scope: !1261)
!2021 = !DILocation(line: 89, column: 30, scope: !1261)
!2022 = !DILocation(line: 89, column: 35, scope: !1261)
!2023 = !DILocation(line: 90, column: 22, scope: !1261)
!2024 = !DILocation(line: 90, column: 26, scope: !1261)
!2025 = !DILocation(line: 90, column: 30, scope: !1261)
!2026 = !DILocation(line: 90, column: 35, scope: !1261)
!2027 = !DILocation(line: 91, column: 22, scope: !1261)
!2028 = !DILocation(line: 91, column: 26, scope: !1261)
!2029 = !DILocation(line: 91, column: 30, scope: !1261)
!2030 = !DILocation(line: 91, column: 35, scope: !1261)
!2031 = !DILocation(line: 92, column: 22, scope: !1261)
!2032 = !DILocation(line: 92, column: 26, scope: !1261)
!2033 = !DILocation(line: 92, column: 30, scope: !1261)
!2034 = !DILocation(line: 92, column: 35, scope: !1261)
!2035 = !DILocation(line: 93, column: 22, scope: !1261)
!2036 = !DILocation(line: 93, column: 26, scope: !1261)
!2037 = !DILocation(line: 93, column: 30, scope: !1261)
!2038 = !DILocation(line: 93, column: 35, scope: !1261)
!2039 = !DILocation(line: 94, column: 22, scope: !1261)
!2040 = !DILocation(line: 94, column: 26, scope: !1261)
!2041 = !DILocation(line: 94, column: 30, scope: !1261)
!2042 = !DILocation(line: 94, column: 35, scope: !1261)
!2043 = !DILocation(line: 96, column: 20, scope: !1261)
!2044 = !DILocation(line: 96, column: 24, scope: !1261)
!2045 = !DILocation(line: 96, column: 28, scope: !1261)
!2046 = !DILocation(line: 97, column: 20, scope: !1261)
!2047 = !DILocation(line: 97, column: 24, scope: !1261)
!2048 = !DILocation(line: 97, column: 28, scope: !1261)
!2049 = !DILocation(line: 98, column: 20, scope: !1261)
!2050 = !DILocation(line: 98, column: 24, scope: !1261)
!2051 = !DILocation(line: 98, column: 28, scope: !1261)
!2052 = !DILocation(line: 99, column: 20, scope: !1261)
!2053 = !DILocation(line: 99, column: 24, scope: !1261)
!2054 = !DILocation(line: 99, column: 28, scope: !1261)
!2055 = !DILocation(line: 100, column: 20, scope: !1261)
!2056 = !DILocation(line: 100, column: 24, scope: !1261)
!2057 = !DILocation(line: 100, column: 28, scope: !1261)
!2058 = !DILocation(line: 101, column: 20, scope: !1261)
!2059 = !DILocation(line: 101, column: 24, scope: !1261)
!2060 = !DILocation(line: 101, column: 28, scope: !1261)
!2061 = !DILocation(line: 102, column: 20, scope: !1261)
!2062 = !DILocation(line: 102, column: 24, scope: !1261)
!2063 = !DILocation(line: 102, column: 28, scope: !1261)
!2064 = !DILocation(line: 103, column: 20, scope: !1261)
!2065 = !DILocation(line: 103, column: 24, scope: !1261)
!2066 = !DILocation(line: 103, column: 28, scope: !1261)
!2067 = !DILocation(line: 105, column: 21, scope: !1261)
!2068 = !DILocation(line: 105, column: 25, scope: !1261)
!2069 = !DILocation(line: 105, column: 28, scope: !1261)
!2070 = !DILocation(line: 106, column: 21, scope: !1261)
!2071 = !DILocation(line: 106, column: 25, scope: !1261)
!2072 = !DILocation(line: 106, column: 28, scope: !1261)
!2073 = !DILocation(line: 107, column: 22, scope: !1261)
!2074 = !DILocation(line: 107, column: 26, scope: !1261)
!2075 = !DILocation(line: 107, column: 30, scope: !1261)
!2076 = !DILocation(line: 108, column: 22, scope: !1261)
!2077 = !DILocation(line: 108, column: 26, scope: !1261)
!2078 = !DILocation(line: 108, column: 30, scope: !1261)
!2079 = !DILocation(line: 109, column: 22, scope: !1261)
!2080 = !DILocation(line: 109, column: 26, scope: !1261)
!2081 = !DILocation(line: 109, column: 30, scope: !1261)
!2082 = !DILocation(line: 110, column: 22, scope: !1261)
!2083 = !DILocation(line: 110, column: 26, scope: !1261)
!2084 = !DILocation(line: 110, column: 30, scope: !1261)
!2085 = !DILocation(line: 111, column: 22, scope: !1261)
!2086 = !DILocation(line: 111, column: 26, scope: !1261)
!2087 = !DILocation(line: 111, column: 30, scope: !1261)
!2088 = !DILocation(line: 112, column: 22, scope: !1261)
!2089 = !DILocation(line: 112, column: 26, scope: !1261)
!2090 = !DILocation(line: 112, column: 30, scope: !1261)
!2091 = !DILocation(line: 114, column: 20, scope: !1261)
!2092 = !DILocation(line: 114, column: 24, scope: !1261)
!2093 = !DILocation(line: 114, column: 28, scope: !1261)
!2094 = !DILocation(line: 116, column: 21, scope: !1261)
!2095 = !DILocation(line: 116, column: 25, scope: !1261)
!2096 = !DILocation(line: 116, column: 29, scope: !1261)
!2097 = !DILocation(line: 117, column: 21, scope: !1261)
!2098 = !DILocation(line: 117, column: 25, scope: !1261)
!2099 = !DILocation(line: 117, column: 29, scope: !1261)
!2100 = !DILocation(line: 118, column: 21, scope: !1261)
!2101 = !DILocation(line: 118, column: 25, scope: !1261)
!2102 = !DILocation(line: 118, column: 29, scope: !1261)
!2103 = !DILocation(line: 119, column: 21, scope: !1261)
!2104 = !DILocation(line: 119, column: 25, scope: !1261)
!2105 = !DILocation(line: 119, column: 29, scope: !1261)
!2106 = !DILocation(line: 120, column: 21, scope: !1261)
!2107 = !DILocation(line: 120, column: 25, scope: !1261)
!2108 = !DILocation(line: 120, column: 29, scope: !1261)
!2109 = !DILocation(line: 121, column: 21, scope: !1261)
!2110 = !DILocation(line: 121, column: 25, scope: !1261)
!2111 = !DILocation(line: 121, column: 29, scope: !1261)
!2112 = !DILocation(line: 122, column: 21, scope: !1261)
!2113 = !DILocation(line: 122, column: 25, scope: !1261)
!2114 = !DILocation(line: 122, column: 29, scope: !1261)
!2115 = !DILocation(line: 123, column: 21, scope: !1261)
!2116 = !DILocation(line: 123, column: 25, scope: !1261)
!2117 = !DILocation(line: 123, column: 29, scope: !1261)
!2118 = !DILocation(line: 124, column: 21, scope: !1261)
!2119 = !DILocation(line: 124, column: 25, scope: !1261)
!2120 = !DILocation(line: 124, column: 29, scope: !1261)
!2121 = !DILocation(line: 127, column: 21, scope: !1261)
!2122 = !DILocation(line: 127, column: 25, scope: !1261)
!2123 = !DILocation(line: 127, column: 28, scope: !1261)
!2124 = !DILocation(line: 128, column: 21, scope: !1261)
!2125 = !DILocation(line: 128, column: 25, scope: !1261)
!2126 = !DILocation(line: 128, column: 28, scope: !1261)
!2127 = !DILocation(line: 129, column: 22, scope: !1261)
!2128 = !DILocation(line: 129, column: 26, scope: !1261)
!2129 = !DILocation(line: 129, column: 30, scope: !1261)
!2130 = !DILocation(line: 130, column: 22, scope: !1261)
!2131 = !DILocation(line: 130, column: 26, scope: !1261)
!2132 = !DILocation(line: 130, column: 30, scope: !1261)
!2133 = !DILocation(line: 131, column: 22, scope: !1261)
!2134 = !DILocation(line: 131, column: 26, scope: !1261)
!2135 = !DILocation(line: 131, column: 30, scope: !1261)
!2136 = !DILocation(line: 132, column: 22, scope: !1261)
!2137 = !DILocation(line: 132, column: 26, scope: !1261)
!2138 = !DILocation(line: 132, column: 30, scope: !1261)
!2139 = !DILocation(line: 133, column: 22, scope: !1261)
!2140 = !DILocation(line: 133, column: 26, scope: !1261)
!2141 = !DILocation(line: 133, column: 30, scope: !1261)
!2142 = !DILocation(line: 134, column: 22, scope: !1261)
!2143 = !DILocation(line: 134, column: 26, scope: !1261)
!2144 = !DILocation(line: 134, column: 30, scope: !1261)
!2145 = !DILocation(line: 136, column: 21, scope: !1261)
!2146 = !DILocation(line: 136, column: 25, scope: !1261)
!2147 = !DILocation(line: 136, column: 29, scope: !1261)
!2148 = !DILocation(line: 137, column: 21, scope: !1261)
!2149 = !DILocation(line: 137, column: 25, scope: !1261)
!2150 = !DILocation(line: 137, column: 29, scope: !1261)
!2151 = !DILocation(line: 138, column: 21, scope: !1261)
!2152 = !DILocation(line: 138, column: 25, scope: !1261)
!2153 = !DILocation(line: 138, column: 29, scope: !1261)
!2154 = !DILocation(line: 139, column: 21, scope: !1261)
!2155 = !DILocation(line: 139, column: 25, scope: !1261)
!2156 = !DILocation(line: 139, column: 29, scope: !1261)
!2157 = !DILocation(line: 140, column: 21, scope: !1261)
!2158 = !DILocation(line: 140, column: 25, scope: !1261)
!2159 = !DILocation(line: 140, column: 29, scope: !1261)
!2160 = !DILocation(line: 141, column: 21, scope: !1261)
!2161 = !DILocation(line: 141, column: 25, scope: !1261)
!2162 = !DILocation(line: 141, column: 29, scope: !1261)
!2163 = !DILocation(line: 142, column: 21, scope: !1261)
!2164 = !DILocation(line: 142, column: 25, scope: !1261)
!2165 = !DILocation(line: 142, column: 29, scope: !1261)
!2166 = !DILocation(line: 143, column: 21, scope: !1261)
!2167 = !DILocation(line: 143, column: 25, scope: !1261)
!2168 = !DILocation(line: 143, column: 29, scope: !1261)
!2169 = !DILocation(line: 144, column: 20, scope: !1261)
!2170 = !DILocation(line: 144, column: 24, scope: !1261)
!2171 = !DILocation(line: 144, column: 27, scope: !1261)
!2172 = !DILocation(line: 145, column: 20, scope: !1261)
!2173 = !DILocation(line: 145, column: 24, scope: !1261)
!2174 = !DILocation(line: 145, column: 27, scope: !1261)
!2175 = !DILocation(line: 146, column: 21, scope: !1261)
!2176 = !DILocation(line: 146, column: 25, scope: !1261)
!2177 = !DILocation(line: 146, column: 29, scope: !1261)
!2178 = !DILocation(line: 147, column: 21, scope: !1261)
!2179 = !DILocation(line: 147, column: 25, scope: !1261)
!2180 = !DILocation(line: 147, column: 29, scope: !1261)
!2181 = !DILocation(line: 148, column: 21, scope: !1261)
!2182 = !DILocation(line: 148, column: 25, scope: !1261)
!2183 = !DILocation(line: 148, column: 29, scope: !1261)
!2184 = !DILocation(line: 149, column: 21, scope: !1261)
!2185 = !DILocation(line: 149, column: 25, scope: !1261)
!2186 = !DILocation(line: 149, column: 29, scope: !1261)
!2187 = !DILocation(line: 150, column: 21, scope: !1261)
!2188 = !DILocation(line: 150, column: 25, scope: !1261)
!2189 = !DILocation(line: 150, column: 29, scope: !1261)
!2190 = !DILocation(line: 151, column: 21, scope: !1261)
!2191 = !DILocation(line: 151, column: 25, scope: !1261)
!2192 = !DILocation(line: 151, column: 29, scope: !1261)
!2193 = !DILocation(line: 152, column: 21, scope: !1261)
!2194 = !DILocation(line: 152, column: 25, scope: !1261)
!2195 = !DILocation(line: 152, column: 29, scope: !1261)
!2196 = !DILocation(line: 155, column: 20, scope: !1261)
!2197 = !DILocation(line: 155, column: 24, scope: !1261)
!2198 = !DILocation(line: 155, column: 27, scope: !1261)
!2199 = !DILocation(line: 156, column: 20, scope: !1261)
!2200 = !DILocation(line: 156, column: 24, scope: !1261)
!2201 = !DILocation(line: 156, column: 27, scope: !1261)
!2202 = !DILocation(line: 157, column: 20, scope: !1261)
!2203 = !DILocation(line: 157, column: 24, scope: !1261)
!2204 = !DILocation(line: 157, column: 27, scope: !1261)
!2205 = !DILocation(line: 158, column: 20, scope: !1261)
!2206 = !DILocation(line: 158, column: 24, scope: !1261)
!2207 = !DILocation(line: 158, column: 27, scope: !1261)
!2208 = !DILocation(line: 159, column: 20, scope: !1261)
!2209 = !DILocation(line: 159, column: 24, scope: !1261)
!2210 = !DILocation(line: 159, column: 27, scope: !1261)
!2211 = !DILocation(line: 160, column: 20, scope: !1261)
!2212 = !DILocation(line: 160, column: 24, scope: !1261)
!2213 = !DILocation(line: 160, column: 27, scope: !1261)
!2214 = !DILocation(line: 164, column: 25, scope: !1261)
!2215 = !DILocation(line: 164, column: 30, scope: !1261)
!2216 = !DILocation(line: 164, column: 38, scope: !1261)
!2217 = !DILocation(line: 165, column: 25, scope: !1261)
!2218 = !DILocation(line: 165, column: 30, scope: !1261)
!2219 = !DILocation(line: 165, column: 38, scope: !1261)
!2220 = !DILocation(line: 205, column: 22, scope: !1261)
!2221 = !DILocation(line: 205, column: 16, scope: !1261)
!2222 = !DILocation(line: 205, column: 29, scope: !1261)
!2223 = !DILocation(line: 206, column: 22, scope: !1261)
!2224 = !DILocation(line: 206, column: 16, scope: !1261)
!2225 = !DILocation(line: 206, column: 29, scope: !1261)
!2226 = !DILocation(line: 207, column: 22, scope: !1261)
!2227 = !DILocation(line: 207, column: 16, scope: !1261)
!2228 = !DILocation(line: 207, column: 29, scope: !1261)
!2229 = !DILocation(line: 208, column: 22, scope: !1261)
!2230 = !DILocation(line: 208, column: 16, scope: !1261)
!2231 = !DILocation(line: 208, column: 29, scope: !1261)
!2232 = !DILocation(line: 209, column: 22, scope: !1261)
!2233 = !DILocation(line: 209, column: 16, scope: !1261)
!2234 = !DILocation(line: 209, column: 29, scope: !1261)
!2235 = !DILocation(line: 210, column: 22, scope: !1261)
!2236 = !DILocation(line: 210, column: 16, scope: !1261)
!2237 = !DILocation(line: 210, column: 29, scope: !1261)
!2238 = !DILocation(line: 211, column: 22, scope: !1261)
!2239 = !DILocation(line: 211, column: 16, scope: !1261)
!2240 = !DILocation(line: 211, column: 29, scope: !1261)
!2241 = !DILocation(line: 212, column: 22, scope: !1261)
!2242 = !DILocation(line: 212, column: 16, scope: !1261)
!2243 = !DILocation(line: 212, column: 29, scope: !1261)
!2244 = !DILocation(line: 214, column: 22, scope: !1261)
!2245 = !DILocation(line: 214, column: 16, scope: !1261)
!2246 = !DILocation(line: 214, column: 29, scope: !1261)
!2247 = !DILocation(line: 215, column: 22, scope: !1261)
!2248 = !DILocation(line: 215, column: 16, scope: !1261)
!2249 = !DILocation(line: 215, column: 29, scope: !1261)
!2250 = !DILocation(line: 216, column: 23, scope: !1261)
!2251 = !DILocation(line: 216, column: 17, scope: !1261)
!2252 = !DILocation(line: 216, column: 31, scope: !1261)
!2253 = !DILocation(line: 217, column: 23, scope: !1261)
!2254 = !DILocation(line: 217, column: 17, scope: !1261)
!2255 = !DILocation(line: 217, column: 31, scope: !1261)
!2256 = !DILocation(line: 218, column: 23, scope: !1261)
!2257 = !DILocation(line: 218, column: 17, scope: !1261)
!2258 = !DILocation(line: 218, column: 31, scope: !1261)
!2259 = !DILocation(line: 219, column: 23, scope: !1261)
!2260 = !DILocation(line: 219, column: 17, scope: !1261)
!2261 = !DILocation(line: 219, column: 31, scope: !1261)
!2262 = !DILocation(line: 220, column: 23, scope: !1261)
!2263 = !DILocation(line: 220, column: 17, scope: !1261)
!2264 = !DILocation(line: 220, column: 31, scope: !1261)
!2265 = !DILocation(line: 221, column: 23, scope: !1261)
!2266 = !DILocation(line: 221, column: 17, scope: !1261)
!2267 = !DILocation(line: 221, column: 31, scope: !1261)
!2268 = !DILocation(line: 245, column: 22, scope: !1261)
!2269 = !DILocation(line: 245, column: 16, scope: !1261)
!2270 = !DILocation(line: 245, column: 29, scope: !1261)
!2271 = !DILocation(line: 246, column: 22, scope: !1261)
!2272 = !DILocation(line: 246, column: 16, scope: !1261)
!2273 = !DILocation(line: 246, column: 29, scope: !1261)
!2274 = !DILocation(line: 247, column: 22, scope: !1261)
!2275 = !DILocation(line: 247, column: 16, scope: !1261)
!2276 = !DILocation(line: 247, column: 29, scope: !1261)
!2277 = !DILocation(line: 248, column: 22, scope: !1261)
!2278 = !DILocation(line: 248, column: 16, scope: !1261)
!2279 = !DILocation(line: 248, column: 29, scope: !1261)
!2280 = !DILocation(line: 249, column: 22, scope: !1261)
!2281 = !DILocation(line: 249, column: 16, scope: !1261)
!2282 = !DILocation(line: 249, column: 29, scope: !1261)
!2283 = !DILocation(line: 250, column: 22, scope: !1261)
!2284 = !DILocation(line: 250, column: 16, scope: !1261)
!2285 = !DILocation(line: 250, column: 29, scope: !1261)
!2286 = !DILocation(line: 251, column: 22, scope: !1261)
!2287 = !DILocation(line: 251, column: 16, scope: !1261)
!2288 = !DILocation(line: 251, column: 29, scope: !1261)
!2289 = !DILocation(line: 252, column: 22, scope: !1261)
!2290 = !DILocation(line: 252, column: 16, scope: !1261)
!2291 = !DILocation(line: 252, column: 29, scope: !1261)
!2292 = !DILocation(line: 255, column: 22, scope: !1261)
!2293 = !DILocation(line: 255, column: 16, scope: !1261)
!2294 = !DILocation(line: 255, column: 29, scope: !1261)
!2295 = !DILocation(line: 256, column: 22, scope: !1261)
!2296 = !DILocation(line: 256, column: 16, scope: !1261)
!2297 = !DILocation(line: 256, column: 29, scope: !1261)
!2298 = !DILocation(line: 257, column: 23, scope: !1261)
!2299 = !DILocation(line: 257, column: 17, scope: !1261)
!2300 = !DILocation(line: 257, column: 31, scope: !1261)
!2301 = !DILocation(line: 258, column: 23, scope: !1261)
!2302 = !DILocation(line: 258, column: 17, scope: !1261)
!2303 = !DILocation(line: 258, column: 31, scope: !1261)
!2304 = !DILocation(line: 259, column: 23, scope: !1261)
!2305 = !DILocation(line: 259, column: 17, scope: !1261)
!2306 = !DILocation(line: 259, column: 31, scope: !1261)
!2307 = !DILocation(line: 260, column: 23, scope: !1261)
!2308 = !DILocation(line: 260, column: 17, scope: !1261)
!2309 = !DILocation(line: 260, column: 31, scope: !1261)
!2310 = !DILocation(line: 261, column: 23, scope: !1261)
!2311 = !DILocation(line: 261, column: 17, scope: !1261)
!2312 = !DILocation(line: 261, column: 31, scope: !1261)
!2313 = !DILocation(line: 262, column: 23, scope: !1261)
!2314 = !DILocation(line: 262, column: 17, scope: !1261)
!2315 = !DILocation(line: 262, column: 31, scope: !1261)
!2316 = !DILocation(line: 285, column: 21, scope: !1261)
!2317 = !DILocation(line: 285, column: 24, scope: !1261)
!2318 = !DILocation(line: 285, column: 15, scope: !1261)
!2319 = !DILocation(line: 285, column: 33, scope: !1261)
!2320 = !DILocation(line: 286, column: 21, scope: !1261)
!2321 = !DILocation(line: 286, column: 24, scope: !1261)
!2322 = !DILocation(line: 286, column: 15, scope: !1261)
!2323 = !DILocation(line: 286, column: 33, scope: !1261)
!2324 = !DILocation(line: 287, column: 21, scope: !1261)
!2325 = !DILocation(line: 287, column: 24, scope: !1261)
!2326 = !DILocation(line: 287, column: 15, scope: !1261)
!2327 = !DILocation(line: 287, column: 33, scope: !1261)
!2328 = !DILocation(line: 288, column: 21, scope: !1261)
!2329 = !DILocation(line: 288, column: 24, scope: !1261)
!2330 = !DILocation(line: 288, column: 15, scope: !1261)
!2331 = !DILocation(line: 288, column: 33, scope: !1261)
!2332 = !DILocation(line: 289, column: 21, scope: !1261)
!2333 = !DILocation(line: 289, column: 24, scope: !1261)
!2334 = !DILocation(line: 289, column: 15, scope: !1261)
!2335 = !DILocation(line: 289, column: 33, scope: !1261)
!2336 = !DILocation(line: 290, column: 21, scope: !1261)
!2337 = !DILocation(line: 290, column: 24, scope: !1261)
!2338 = !DILocation(line: 290, column: 15, scope: !1261)
!2339 = !DILocation(line: 290, column: 33, scope: !1261)
!2340 = !DILocation(line: 291, column: 21, scope: !1261)
!2341 = !DILocation(line: 291, column: 24, scope: !1261)
!2342 = !DILocation(line: 291, column: 15, scope: !1261)
!2343 = !DILocation(line: 291, column: 33, scope: !1261)
!2344 = !DILocation(line: 292, column: 21, scope: !1261)
!2345 = !DILocation(line: 292, column: 24, scope: !1261)
!2346 = !DILocation(line: 292, column: 15, scope: !1261)
!2347 = !DILocation(line: 292, column: 33, scope: !1261)
!2348 = !DILocation(line: 318, column: 21, scope: !1261)
!2349 = !DILocation(line: 318, column: 25, scope: !1261)
!2350 = !DILocation(line: 318, column: 15, scope: !1261)
!2351 = !DILocation(line: 318, column: 34, scope: !1261)
!2352 = !DILocation(line: 318, column: 38, scope: !1261)
!2353 = !DILocation(line: 318, column: 45, scope: !1261)
!2354 = !DILocation(line: 319, column: 21, scope: !1261)
!2355 = !DILocation(line: 319, column: 25, scope: !1261)
!2356 = !DILocation(line: 319, column: 15, scope: !1261)
!2357 = !DILocation(line: 319, column: 34, scope: !1261)
!2358 = !DILocation(line: 319, column: 38, scope: !1261)
!2359 = !DILocation(line: 319, column: 45, scope: !1261)
!2360 = !DILocation(line: 320, column: 21, scope: !1261)
!2361 = !DILocation(line: 320, column: 25, scope: !1261)
!2362 = !DILocation(line: 320, column: 15, scope: !1261)
!2363 = !DILocation(line: 320, column: 34, scope: !1261)
!2364 = !DILocation(line: 320, column: 38, scope: !1261)
!2365 = !DILocation(line: 320, column: 45, scope: !1261)
!2366 = !DILocation(line: 321, column: 21, scope: !1261)
!2367 = !DILocation(line: 321, column: 25, scope: !1261)
!2368 = !DILocation(line: 321, column: 15, scope: !1261)
!2369 = !DILocation(line: 321, column: 34, scope: !1261)
!2370 = !DILocation(line: 321, column: 38, scope: !1261)
!2371 = !DILocation(line: 321, column: 45, scope: !1261)
!2372 = !DILocation(line: 322, column: 21, scope: !1261)
!2373 = !DILocation(line: 322, column: 25, scope: !1261)
!2374 = !DILocation(line: 322, column: 15, scope: !1261)
!2375 = !DILocation(line: 322, column: 34, scope: !1261)
!2376 = !DILocation(line: 322, column: 38, scope: !1261)
!2377 = !DILocation(line: 322, column: 45, scope: !1261)
!2378 = !DILocation(line: 323, column: 21, scope: !1261)
!2379 = !DILocation(line: 323, column: 25, scope: !1261)
!2380 = !DILocation(line: 323, column: 15, scope: !1261)
!2381 = !DILocation(line: 323, column: 34, scope: !1261)
!2382 = !DILocation(line: 323, column: 38, scope: !1261)
!2383 = !DILocation(line: 323, column: 45, scope: !1261)
!2384 = !DILocation(line: 324, column: 21, scope: !1261)
!2385 = !DILocation(line: 324, column: 25, scope: !1261)
!2386 = !DILocation(line: 324, column: 15, scope: !1261)
!2387 = !DILocation(line: 324, column: 34, scope: !1261)
!2388 = !DILocation(line: 324, column: 38, scope: !1261)
!2389 = !DILocation(line: 324, column: 45, scope: !1261)
!2390 = !DILocation(line: 325, column: 21, scope: !1261)
!2391 = !DILocation(line: 325, column: 25, scope: !1261)
!2392 = !DILocation(line: 325, column: 15, scope: !1261)
!2393 = !DILocation(line: 325, column: 34, scope: !1261)
!2394 = !DILocation(line: 325, column: 38, scope: !1261)
!2395 = !DILocation(line: 325, column: 45, scope: !1261)
!2396 = !DILocation(line: 328, column: 20, scope: !1261)
!2397 = !DILocation(line: 328, column: 26, scope: !1261)
!2398 = !DILocation(line: 329, column: 20, scope: !1261)
!2399 = !DILocation(line: 329, column: 26, scope: !1261)
!2400 = !DILocation(line: 330, column: 20, scope: !1261)
!2401 = !DILocation(line: 330, column: 26, scope: !1261)
!2402 = !DILocation(line: 331, column: 20, scope: !1261)
!2403 = !DILocation(line: 331, column: 26, scope: !1261)
!2404 = !DILocation(line: 332, column: 20, scope: !1261)
!2405 = !DILocation(line: 332, column: 26, scope: !1261)
!2406 = !DILocation(line: 333, column: 20, scope: !1261)
!2407 = !DILocation(line: 333, column: 26, scope: !1261)
!2408 = !DILocation(line: 334, column: 20, scope: !1261)
!2409 = !DILocation(line: 334, column: 26, scope: !1261)
!2410 = !DILocation(line: 337, column: 9, scope: !1261)
!2411 = !DILocation(line: 338, column: 9, scope: !1261)
!2412 = !DILocation(line: 339, column: 9, scope: !1261)
!2413 = !DILocation(line: 340, column: 9, scope: !1261)
!2414 = !DILocation(line: 341, column: 9, scope: !1261)
!2415 = !DILocation(line: 342, column: 9, scope: !1261)
!2416 = !DILocation(line: 343, column: 9, scope: !1261)
!2417 = !DILocation(line: 344, column: 9, scope: !1261)
!2418 = !DILocation(line: 347, column: 9, scope: !1261)
!2419 = !DILocation(line: 348, column: 9, scope: !1261)
!2420 = !DILocation(line: 349, column: 9, scope: !1261)
!2421 = !DILocation(line: 350, column: 9, scope: !1261)
!2422 = !DILocation(line: 351, column: 9, scope: !1261)
!2423 = !DILocation(line: 353, column: 9, scope: !1261)
!2424 = !DILocation(line: 357, column: 3, scope: !1261)
!2425 = distinct !DISubprogram(name: "__remill_intrinsics", scope: !2426, file: !2426, line: 35, type: !95, isLocal: false, isDefinition: true, scopeLine: 35, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!2426 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Intrinsics.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!2427 = !DILocation(line: 116, column: 1, scope: !2425)
!2428 = !{!2429, !2429, i64 0}
!2429 = !{!"long", !2430, i64 0}
!2430 = !{!"omnipotent char", !2431, i64 0}
!2431 = !{!"Simple C++ TBAA"}
!2432 = !{!2430, !2430, i64 0}
!2433 = !{!2434, !2430, i64 2065}
!2434 = !{!"_ZTS5State", !2430, i64 16, !2435, i64 2064, !2430, i64 2080, !2436, i64 2088, !2438, i64 2112, !2440, i64 2208, !2441, i64 2480, !2442, i64 2608, !2443, i64 2736, !2430, i64 2760, !2430, i64 2768, !2444, i64 3280}
!2435 = !{!"_ZTS10ArithFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15}
!2436 = !{!"_ZTS8Segments", !2437, i64 0, !2430, i64 2, !2437, i64 4, !2430, i64 6, !2437, i64 8, !2430, i64 10, !2437, i64 12, !2430, i64 14, !2437, i64 16, !2430, i64 18, !2437, i64 20, !2430, i64 22}
!2437 = !{!"short", !2430, i64 0}
!2438 = !{!"_ZTS12AddressSpace", !2429, i64 0, !2439, i64 8, !2429, i64 16, !2439, i64 24, !2429, i64 32, !2439, i64 40, !2429, i64 48, !2439, i64 56, !2429, i64 64, !2439, i64 72, !2429, i64 80, !2439, i64 88}
!2439 = !{!"_ZTS3Reg", !2430, i64 0}
!2440 = !{!"_ZTS3GPR", !2429, i64 0, !2439, i64 8, !2429, i64 16, !2439, i64 24, !2429, i64 32, !2439, i64 40, !2429, i64 48, !2439, i64 56, !2429, i64 64, !2439, i64 72, !2429, i64 80, !2439, i64 88, !2429, i64 96, !2439, i64 104, !2429, i64 112, !2439, i64 120, !2429, i64 128, !2439, i64 136, !2429, i64 144, !2439, i64 152, !2429, i64 160, !2439, i64 168, !2429, i64 176, !2439, i64 184, !2429, i64 192, !2439, i64 200, !2429, i64 208, !2439, i64 216, !2429, i64 224, !2439, i64 232, !2429, i64 240, !2439, i64 248, !2429, i64 256, !2439, i64 264}
!2441 = !{!"_ZTS8X87Stack", !2430, i64 0}
!2442 = !{!"_ZTS3MMX", !2430, i64 0}
!2443 = !{!"_ZTS14FPUStatusFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15, !2430, i64 16, !2430, i64 17, !2430, i64 18, !2430, i64 19, !2430, i64 20}
!2444 = !{!"_ZTS13SegmentCaches", !2445, i64 0, !2445, i64 16, !2445, i64 32, !2445, i64 48, !2445, i64 64, !2445, i64 80}
!2445 = !{!"_ZTS13SegmentShadow", !2430, i64 0, !2446, i64 8, !2446, i64 12}
!2446 = !{!"int", !2430, i64 0}
!2447 = !{!2434, !2430, i64 2067}
!2448 = !{!2434, !2430, i64 2071}
!2449 = !{!2434, !2430, i64 2073}
!2450 = !{!2434, !2430, i64 2077}
!2451 = !{!2434, !2430, i64 2069}
!2452 = !{!2453, !2453, i64 0}
!2453 = !{!"double", !2430, i64 0}
!2454 = !{!2455, !2455, i64 0}
!2455 = !{!"float", !2430, i64 0}
!2456 = !{!2457}
!2457 = distinct !{!2457, !2458, !"ext_605140_sqrt: argument 0"}
!2458 = distinct !{!2458, !"ext_605140_sqrt"}
!2459 = !{!2460}
!2460 = distinct !{!2460, !2458, !"ext_605140_sqrt: argument 1"}
!2461 = !{!2446, !2446, i64 0}
!2462 = !{!2463}
!2463 = distinct !{!2463, !2464, !"ext_6050b8_cos: argument 0"}
!2464 = distinct !{!2464, !"ext_6050b8_cos"}
!2465 = !{!2466}
!2466 = distinct !{!2466, !2464, !"ext_6050b8_cos: argument 1"}
!2467 = !{!2468}
!2468 = distinct !{!2468, !2469, !"ext_400730_sin: argument 0"}
!2469 = distinct !{!2469, !"ext_400730_sin"}
!2470 = !{!2471}
!2471 = distinct !{!2471, !2469, !"ext_400730_sin: argument 1"}
!2472 = !{!2473}
!2473 = distinct !{!2473, !2474, !"ext_6050f8_atan: argument 0"}
!2474 = distinct !{!2474, !"ext_6050f8_atan"}
!2475 = !{!2476}
!2476 = distinct !{!2476, !2474, !"ext_6050f8_atan: argument 1"}
!2477 = !{!2478}
!2478 = distinct !{!2478, !2479, !"ext_6050b8_cos: argument 0"}
!2479 = distinct !{!2479, !"ext_6050b8_cos"}
!2480 = !{!2481}
!2481 = distinct !{!2481, !2479, !"ext_6050b8_cos: argument 1"}
